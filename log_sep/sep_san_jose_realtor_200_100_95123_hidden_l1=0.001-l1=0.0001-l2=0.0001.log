I 2015-05-26 03:35:25 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 03:35:25 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95123-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl
I 2015-05-26 03:35:25 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 03:35:25 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 03:35:25 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 03:35:25 theanets.main:89 --batch_size = 1024
I 2015-05-26 03:35:25 theanets.main:89 --gradient_clip = 1
I 2015-05-26 03:35:25 theanets.main:89 --hidden_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 03:35:25 theanets.main:89 --train_batches = 30
I 2015-05-26 03:35:25 theanets.main:89 --valid_batches = 3
I 2015-05-26 03:35:25 theanets.main:89 --weight_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --weight_l2 = None
I 2015-05-26 03:35:25 theanets.trainer:134 compiling evaluation function
I 2015-05-26 03:35:40 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 03:38:57 theanets.trainer:168 validation 0 loss=14150.459961 err=14150.459961 *
I 2015-05-26 03:39:57 theanets.trainer:168 RmsProp 1 loss=13160.694336 err=13160.694336
I 2015-05-26 03:40:57 theanets.trainer:168 RmsProp 2 loss=13186.400391 err=13186.400391
I 2015-05-26 03:41:58 theanets.trainer:168 RmsProp 3 loss=13134.100586 err=13134.100586
I 2015-05-26 03:42:58 theanets.trainer:168 RmsProp 4 loss=12550.753906 err=12550.753906
I 2015-05-26 03:43:57 theanets.trainer:168 RmsProp 5 loss=11108.552734 err=11108.552734
I 2015-05-26 03:44:56 theanets.trainer:168 RmsProp 6 loss=10154.303711 err=10154.303711
I 2015-05-26 03:45:56 theanets.trainer:168 RmsProp 7 loss=9724.875000 err=9724.875000
I 2015-05-26 03:46:57 theanets.trainer:168 RmsProp 8 loss=9244.779297 err=9244.779297
I 2015-05-26 03:47:57 theanets.trainer:168 RmsProp 9 loss=8279.891602 err=8279.891602
I 2015-05-26 03:48:57 theanets.trainer:168 RmsProp 10 loss=7739.017090 err=7739.017090
I 2015-05-26 03:48:59 theanets.trainer:168 validation 1 loss=6613.722168 err=6613.722168 *
I 2015-05-26 03:49:59 theanets.trainer:168 RmsProp 11 loss=7139.820801 err=7139.820801
I 2015-05-26 03:51:00 theanets.trainer:168 RmsProp 12 loss=6567.141113 err=6567.141113
I 2015-05-26 03:52:01 theanets.trainer:168 RmsProp 13 loss=6014.997070 err=6014.997070
I 2015-05-26 03:53:02 theanets.trainer:168 RmsProp 14 loss=5692.322266 err=5692.322266
I 2015-05-26 03:54:03 theanets.trainer:168 RmsProp 15 loss=5318.493164 err=5318.493164
I 2015-05-26 03:55:04 theanets.trainer:168 RmsProp 16 loss=5504.868652 err=5504.868652
I 2015-05-26 03:56:06 theanets.trainer:168 RmsProp 17 loss=5310.616699 err=5310.616699
I 2015-05-26 03:57:07 theanets.trainer:168 RmsProp 18 loss=5134.747559 err=5134.747559
I 2015-05-26 03:58:09 theanets.trainer:168 RmsProp 19 loss=4624.440430 err=4624.440430
I 2015-05-26 03:59:09 theanets.trainer:168 RmsProp 20 loss=4893.030762 err=4893.030762
I 2015-05-26 03:59:10 theanets.trainer:168 validation 2 loss=4561.554199 err=4561.554199 *
I 2015-05-26 04:00:11 theanets.trainer:168 RmsProp 21 loss=4587.521973 err=4587.521973
I 2015-05-26 04:01:13 theanets.trainer:168 RmsProp 22 loss=4306.511230 err=4306.511230
I 2015-05-26 04:02:14 theanets.trainer:168 RmsProp 23 loss=4019.699707 err=4019.699707
I 2015-05-26 04:03:15 theanets.trainer:168 RmsProp 24 loss=3776.046875 err=3776.046875
I 2015-05-26 04:04:16 theanets.trainer:168 RmsProp 25 loss=3559.159668 err=3559.159668
I 2015-05-26 04:05:16 theanets.trainer:168 RmsProp 26 loss=3425.050293 err=3425.050293
I 2015-05-26 04:06:17 theanets.trainer:168 RmsProp 27 loss=3360.366455 err=3360.366455
I 2015-05-26 04:07:18 theanets.trainer:168 RmsProp 28 loss=3172.609131 err=3172.609131
I 2015-05-26 04:08:19 theanets.trainer:168 RmsProp 29 loss=3061.744629 err=3061.744629
I 2015-05-26 04:09:20 theanets.trainer:168 RmsProp 30 loss=2883.571777 err=2883.571777
I 2015-05-26 04:09:21 theanets.trainer:168 validation 3 loss=2847.266357 err=2847.266357 *
I 2015-05-26 04:10:21 theanets.trainer:168 RmsProp 31 loss=2688.713135 err=2688.713135
I 2015-05-26 04:11:21 theanets.trainer:168 RmsProp 32 loss=2544.176514 err=2544.176514
I 2015-05-26 04:12:21 theanets.trainer:168 RmsProp 33 loss=2447.094971 err=2447.094971
I 2015-05-26 04:13:20 theanets.trainer:168 RmsProp 34 loss=2433.420410 err=2433.420410
I 2015-05-26 04:14:18 theanets.trainer:168 RmsProp 35 loss=2302.747070 err=2302.747070
I 2015-05-26 04:15:14 theanets.trainer:168 RmsProp 36 loss=2210.871826 err=2210.871826
I 2015-05-26 04:16:10 theanets.trainer:168 RmsProp 37 loss=2085.854248 err=2085.854248
I 2015-05-26 04:17:07 theanets.trainer:168 RmsProp 38 loss=1956.976685 err=1956.976685
I 2015-05-26 04:18:03 theanets.trainer:168 RmsProp 39 loss=1882.947632 err=1882.947632
I 2015-05-26 04:18:59 theanets.trainer:168 RmsProp 40 loss=1858.260498 err=1858.260498
I 2015-05-26 04:19:00 theanets.trainer:168 validation 4 loss=2470.429688 err=2470.429688 *
I 2015-05-26 04:19:56 theanets.trainer:168 RmsProp 41 loss=1762.071899 err=1762.071899
I 2015-05-26 04:20:53 theanets.trainer:168 RmsProp 42 loss=1717.734375 err=1717.734375
I 2015-05-26 04:21:51 theanets.trainer:168 RmsProp 43 loss=1649.525024 err=1649.525024
I 2015-05-26 04:22:46 theanets.trainer:168 RmsProp 44 loss=1604.423340 err=1604.423340
I 2015-05-26 04:23:39 theanets.trainer:168 RmsProp 45 loss=1647.583740 err=1647.583740
I 2015-05-26 04:24:32 theanets.trainer:168 RmsProp 46 loss=1530.460938 err=1530.460938
I 2015-05-26 04:25:25 theanets.trainer:168 RmsProp 47 loss=1403.517578 err=1403.517578
I 2015-05-26 04:26:19 theanets.trainer:168 RmsProp 48 loss=1372.296143 err=1372.296143
I 2015-05-26 04:27:12 theanets.trainer:168 RmsProp 49 loss=1326.703979 err=1326.703979
I 2015-05-26 04:28:06 theanets.trainer:168 RmsProp 50 loss=1313.814453 err=1313.814453
I 2015-05-26 04:28:07 theanets.trainer:168 validation 5 loss=2217.978271 err=2217.978271 *
I 2015-05-26 04:28:59 theanets.trainer:168 RmsProp 51 loss=1253.192261 err=1253.192261
I 2015-05-26 04:29:52 theanets.trainer:168 RmsProp 52 loss=1222.640991 err=1222.640991
I 2015-05-26 04:30:45 theanets.trainer:168 RmsProp 53 loss=1201.008423 err=1201.008423
I 2015-05-26 04:31:39 theanets.trainer:168 RmsProp 54 loss=1143.988647 err=1143.988647
I 2015-05-26 04:32:32 theanets.trainer:168 RmsProp 55 loss=1112.685059 err=1112.685059
I 2015-05-26 04:33:24 theanets.trainer:168 RmsProp 56 loss=1073.357178 err=1073.357178
I 2015-05-26 04:34:18 theanets.trainer:168 RmsProp 57 loss=1055.537476 err=1055.537476
I 2015-05-26 04:35:12 theanets.trainer:168 RmsProp 58 loss=998.183350 err=998.183350
I 2015-05-26 04:36:05 theanets.trainer:168 RmsProp 59 loss=981.522400 err=981.522400
I 2015-05-26 04:36:59 theanets.trainer:168 RmsProp 60 loss=960.621521 err=960.621521
I 2015-05-26 04:37:01 theanets.trainer:168 validation 6 loss=1893.610229 err=1893.610229 *
I 2015-05-26 04:37:54 theanets.trainer:168 RmsProp 61 loss=914.767761 err=914.767761
I 2015-05-26 04:38:49 theanets.trainer:168 RmsProp 62 loss=939.414917 err=939.414917
I 2015-05-26 04:39:43 theanets.trainer:168 RmsProp 63 loss=949.638306 err=949.638306
I 2015-05-26 04:40:38 theanets.trainer:168 RmsProp 64 loss=893.142517 err=893.142517
I 2015-05-26 04:41:32 theanets.trainer:168 RmsProp 65 loss=858.311646 err=858.311646
I 2015-05-26 04:42:26 theanets.trainer:168 RmsProp 66 loss=818.902161 err=818.902161
I 2015-05-26 04:43:20 theanets.trainer:168 RmsProp 67 loss=874.502747 err=874.502747
I 2015-05-26 04:44:15 theanets.trainer:168 RmsProp 68 loss=856.974304 err=856.974304
I 2015-05-26 04:45:08 theanets.trainer:168 RmsProp 69 loss=805.169128 err=805.169128
I 2015-05-26 04:46:03 theanets.trainer:168 RmsProp 70 loss=810.396362 err=810.396362
I 2015-05-26 04:46:04 theanets.trainer:168 validation 7 loss=1817.003296 err=1817.003296 *
I 2015-05-26 04:46:58 theanets.trainer:168 RmsProp 71 loss=761.980408 err=761.980408
I 2015-05-26 04:47:51 theanets.trainer:168 RmsProp 72 loss=725.666992 err=725.666992
I 2015-05-26 04:48:45 theanets.trainer:168 RmsProp 73 loss=695.731140 err=695.731140
I 2015-05-26 04:49:39 theanets.trainer:168 RmsProp 74 loss=682.995789 err=682.995789
I 2015-05-26 04:50:33 theanets.trainer:168 RmsProp 75 loss=676.531860 err=676.531860
I 2015-05-26 04:51:27 theanets.trainer:168 RmsProp 76 loss=689.270447 err=689.270447
I 2015-05-26 04:52:22 theanets.trainer:168 RmsProp 77 loss=666.881104 err=666.881104
I 2015-05-26 04:53:17 theanets.trainer:168 RmsProp 78 loss=667.128601 err=667.128601
I 2015-05-26 04:54:10 theanets.trainer:168 RmsProp 79 loss=642.394165 err=642.394165
I 2015-05-26 04:55:03 theanets.trainer:168 RmsProp 80 loss=611.427368 err=611.427368
I 2015-05-26 04:55:04 theanets.trainer:168 validation 8 loss=1655.705444 err=1655.705444 *
I 2015-05-26 04:55:57 theanets.trainer:168 RmsProp 81 loss=612.970947 err=612.970947
I 2015-05-26 04:56:49 theanets.trainer:168 RmsProp 82 loss=607.707275 err=607.707275
I 2015-05-26 04:57:42 theanets.trainer:168 RmsProp 83 loss=568.775635 err=568.775635
I 2015-05-26 04:58:34 theanets.trainer:168 RmsProp 84 loss=560.354553 err=560.354553
I 2015-05-26 04:59:27 theanets.trainer:168 RmsProp 85 loss=540.265991 err=540.265991
I 2015-05-26 05:00:20 theanets.trainer:168 RmsProp 86 loss=521.337585 err=521.337585
I 2015-05-26 05:01:13 theanets.trainer:168 RmsProp 87 loss=506.207642 err=506.207642
I 2015-05-26 05:02:05 theanets.trainer:168 RmsProp 88 loss=494.945618 err=494.945618
I 2015-05-26 05:02:58 theanets.trainer:168 RmsProp 89 loss=466.629425 err=466.629425
I 2015-05-26 05:03:51 theanets.trainer:168 RmsProp 90 loss=461.922028 err=461.922028
I 2015-05-26 05:03:52 theanets.trainer:168 validation 9 loss=1589.578979 err=1589.578979 *
I 2015-05-26 05:04:45 theanets.trainer:168 RmsProp 91 loss=452.412811 err=452.412811
I 2015-05-26 05:05:38 theanets.trainer:168 RmsProp 92 loss=441.862793 err=441.862793
I 2015-05-26 05:06:31 theanets.trainer:168 RmsProp 93 loss=438.201813 err=438.201813
I 2015-05-26 05:07:25 theanets.trainer:168 RmsProp 94 loss=430.701874 err=430.701874
I 2015-05-26 05:08:16 theanets.trainer:168 RmsProp 95 loss=416.339417 err=416.339417
I 2015-05-26 05:09:07 theanets.trainer:168 RmsProp 96 loss=396.810608 err=396.810608
I 2015-05-26 05:09:58 theanets.trainer:168 RmsProp 97 loss=386.515533 err=386.515533
I 2015-05-26 05:10:48 theanets.trainer:168 RmsProp 98 loss=391.798492 err=391.798492
I 2015-05-26 05:11:37 theanets.trainer:168 RmsProp 99 loss=385.198730 err=385.198730
I 2015-05-26 05:12:27 theanets.trainer:168 RmsProp 100 loss=391.464905 err=391.464905
I 2015-05-26 05:12:28 theanets.trainer:168 validation 10 loss=1561.543823 err=1561.543823 *
I 2015-05-26 05:13:17 theanets.trainer:168 RmsProp 101 loss=373.256561 err=373.256561
I 2015-05-26 05:14:08 theanets.trainer:168 RmsProp 102 loss=368.074677 err=368.074677
I 2015-05-26 05:14:58 theanets.trainer:168 RmsProp 103 loss=359.088837 err=359.088837
I 2015-05-26 05:15:49 theanets.trainer:168 RmsProp 104 loss=348.832825 err=348.832825
I 2015-05-26 05:16:39 theanets.trainer:168 RmsProp 105 loss=337.617981 err=337.617981
I 2015-05-26 05:17:30 theanets.trainer:168 RmsProp 106 loss=331.500702 err=331.500702
I 2015-05-26 05:18:20 theanets.trainer:168 RmsProp 107 loss=321.632294 err=321.632294
I 2015-05-26 05:19:11 theanets.trainer:168 RmsProp 108 loss=310.395630 err=310.395630
I 2015-05-26 05:20:01 theanets.trainer:168 RmsProp 109 loss=295.457916 err=295.457916
I 2015-05-26 05:20:52 theanets.trainer:168 RmsProp 110 loss=300.278778 err=300.278778
I 2015-05-26 05:20:53 theanets.trainer:168 validation 11 loss=1532.600952 err=1532.600952 *
I 2015-05-26 05:21:44 theanets.trainer:168 RmsProp 111 loss=291.758636 err=291.758636
I 2015-05-26 05:22:34 theanets.trainer:168 RmsProp 112 loss=300.312836 err=300.312836
I 2015-05-26 05:23:25 theanets.trainer:168 RmsProp 113 loss=286.500702 err=286.500702
I 2015-05-26 05:24:16 theanets.trainer:168 RmsProp 114 loss=273.234314 err=273.234314
I 2015-05-26 05:25:06 theanets.trainer:168 RmsProp 115 loss=260.826050 err=260.826050
I 2015-05-26 05:25:57 theanets.trainer:168 RmsProp 116 loss=243.530762 err=243.530762
I 2015-05-26 05:26:47 theanets.trainer:168 RmsProp 117 loss=166.873291 err=166.873291
I 2015-05-26 05:27:38 theanets.trainer:168 RmsProp 118 loss=169.524704 err=169.524704
I 2015-05-26 05:28:29 theanets.trainer:168 RmsProp 119 loss=154.304169 err=154.304169
I 2015-05-26 05:29:19 theanets.trainer:168 RmsProp 120 loss=133.256393 err=133.256393
I 2015-05-26 05:29:20 theanets.trainer:168 validation 12 loss=1321.488281 err=1321.488281 *
I 2015-05-26 05:30:11 theanets.trainer:168 RmsProp 121 loss=124.473427 err=124.473427
I 2015-05-26 05:31:02 theanets.trainer:168 RmsProp 122 loss=118.890022 err=118.890022
I 2015-05-26 05:31:53 theanets.trainer:168 RmsProp 123 loss=113.742592 err=113.742592
I 2015-05-26 05:32:43 theanets.trainer:168 RmsProp 124 loss=107.087639 err=107.087639
I 2015-05-26 05:33:34 theanets.trainer:168 RmsProp 125 loss=105.448120 err=105.448120
I 2015-05-26 05:34:25 theanets.trainer:168 RmsProp 126 loss=98.862160 err=98.862160
I 2015-05-26 05:35:16 theanets.trainer:168 RmsProp 127 loss=96.973495 err=96.973495
I 2015-05-26 05:36:07 theanets.trainer:168 RmsProp 128 loss=91.757149 err=91.757149
I 2015-05-26 05:36:57 theanets.trainer:168 RmsProp 129 loss=88.999344 err=88.999344
I 2015-05-26 05:37:47 theanets.trainer:168 RmsProp 130 loss=85.293221 err=85.293221
I 2015-05-26 05:37:48 theanets.trainer:168 validation 13 loss=1319.335205 err=1319.335205 *
I 2015-05-26 05:38:36 theanets.trainer:168 RmsProp 131 loss=85.894753 err=85.894753
I 2015-05-26 05:39:24 theanets.trainer:168 RmsProp 132 loss=79.888191 err=79.888191
I 2015-05-26 05:40:12 theanets.trainer:168 RmsProp 133 loss=78.237923 err=78.237923
I 2015-05-26 05:41:01 theanets.trainer:168 RmsProp 134 loss=76.015045 err=76.015045
I 2015-05-26 05:41:50 theanets.trainer:168 RmsProp 135 loss=73.245926 err=73.245926
I 2015-05-26 05:42:39 theanets.trainer:168 RmsProp 136 loss=71.360016 err=71.360016
I 2015-05-26 05:43:28 theanets.trainer:168 RmsProp 137 loss=68.483681 err=68.483681
I 2015-05-26 05:44:17 theanets.trainer:168 RmsProp 138 loss=68.586510 err=68.586510
I 2015-05-26 05:45:07 theanets.trainer:168 RmsProp 139 loss=65.815399 err=65.815399
I 2015-05-26 05:45:56 theanets.trainer:168 RmsProp 140 loss=64.715889 err=64.715889
I 2015-05-26 05:45:57 theanets.trainer:168 validation 14 loss=1355.830933 err=1355.830933
I 2015-05-26 05:46:46 theanets.trainer:168 RmsProp 141 loss=60.319046 err=60.319046
I 2015-05-26 05:47:36 theanets.trainer:168 RmsProp 142 loss=59.686783 err=59.686783
I 2015-05-26 05:48:26 theanets.trainer:168 RmsProp 143 loss=60.047932 err=60.047932
I 2015-05-26 05:49:15 theanets.trainer:168 RmsProp 144 loss=57.615276 err=57.615276
I 2015-05-26 05:50:05 theanets.trainer:168 RmsProp 145 loss=56.414440 err=56.414440
I 2015-05-26 05:50:55 theanets.trainer:168 RmsProp 146 loss=54.308937 err=54.308937
I 2015-05-26 05:51:44 theanets.trainer:168 RmsProp 147 loss=53.140453 err=53.140453
I 2015-05-26 05:52:33 theanets.trainer:168 RmsProp 148 loss=51.487793 err=51.487793
I 2015-05-26 05:53:22 theanets.trainer:168 RmsProp 149 loss=51.137558 err=51.137558
I 2015-05-26 05:54:12 theanets.trainer:168 RmsProp 150 loss=49.511345 err=49.511345
I 2015-05-26 05:54:13 theanets.trainer:168 validation 15 loss=1306.860229 err=1306.860229 *
I 2015-05-26 05:55:02 theanets.trainer:168 RmsProp 151 loss=48.100712 err=48.100712
I 2015-05-26 05:55:52 theanets.trainer:168 RmsProp 152 loss=46.684620 err=46.684620
I 2015-05-26 05:56:41 theanets.trainer:168 RmsProp 153 loss=45.384190 err=45.384190
I 2015-05-26 05:57:31 theanets.trainer:168 RmsProp 154 loss=44.958805 err=44.958805
I 2015-05-26 05:58:20 theanets.trainer:168 RmsProp 155 loss=43.711277 err=43.711277
I 2015-05-26 05:59:09 theanets.trainer:168 RmsProp 156 loss=42.492859 err=42.492859
I 2015-05-26 05:59:58 theanets.trainer:168 RmsProp 157 loss=40.061443 err=40.061443
I 2015-05-26 06:00:48 theanets.trainer:168 RmsProp 158 loss=40.733070 err=40.733070
I 2015-05-26 06:01:37 theanets.trainer:168 RmsProp 159 loss=39.754295 err=39.754295
I 2015-05-26 06:02:27 theanets.trainer:168 RmsProp 160 loss=40.001400 err=40.001400
I 2015-05-26 06:02:28 theanets.trainer:168 validation 16 loss=1312.661011 err=1312.661011
I 2015-05-26 06:03:17 theanets.trainer:168 RmsProp 161 loss=38.450314 err=38.450314
I 2015-05-26 06:04:07 theanets.trainer:168 RmsProp 162 loss=37.186729 err=37.186729
I 2015-05-26 06:04:56 theanets.trainer:168 RmsProp 163 loss=35.902637 err=35.902637
I 2015-05-26 06:05:46 theanets.trainer:168 RmsProp 164 loss=35.628674 err=35.628674
I 2015-05-26 06:06:35 theanets.trainer:168 RmsProp 165 loss=35.809166 err=35.809166
I 2015-05-26 06:07:22 theanets.trainer:168 RmsProp 166 loss=34.932030 err=34.932030
I 2015-05-26 06:08:10 theanets.trainer:168 RmsProp 167 loss=33.335289 err=33.335289
I 2015-05-26 06:08:59 theanets.trainer:168 RmsProp 168 loss=32.718193 err=32.718193
I 2015-05-26 06:09:48 theanets.trainer:168 RmsProp 169 loss=32.444733 err=32.444733
I 2015-05-26 06:10:37 theanets.trainer:168 RmsProp 170 loss=30.989052 err=30.989052
I 2015-05-26 06:10:38 theanets.trainer:168 validation 17 loss=1313.287109 err=1313.287109
I 2015-05-26 06:11:27 theanets.trainer:168 RmsProp 171 loss=31.024988 err=31.024988
I 2015-05-26 06:12:17 theanets.trainer:168 RmsProp 172 loss=30.261095 err=30.261095
I 2015-05-26 06:13:07 theanets.trainer:168 RmsProp 173 loss=29.046045 err=29.046045
I 2015-05-26 06:13:57 theanets.trainer:168 RmsProp 174 loss=29.496000 err=29.496000
I 2015-05-26 06:14:46 theanets.trainer:168 RmsProp 175 loss=28.854975 err=28.854975
I 2015-05-26 06:15:36 theanets.trainer:168 RmsProp 176 loss=28.101719 err=28.101719
I 2015-05-26 06:16:25 theanets.trainer:168 RmsProp 177 loss=27.619448 err=27.619448
I 2015-05-26 06:17:15 theanets.trainer:168 RmsProp 178 loss=27.089247 err=27.089247
I 2015-05-26 06:18:06 theanets.trainer:168 RmsProp 179 loss=26.908844 err=26.908844
I 2015-05-26 06:18:55 theanets.trainer:168 RmsProp 180 loss=25.780567 err=25.780567
I 2015-05-26 06:18:57 theanets.trainer:168 validation 18 loss=1325.647095 err=1325.647095
I 2015-05-26 06:19:45 theanets.trainer:168 RmsProp 181 loss=26.005024 err=26.005024
I 2015-05-26 06:20:32 theanets.trainer:168 RmsProp 182 loss=25.929859 err=25.929859
I 2015-05-26 06:21:20 theanets.trainer:168 RmsProp 183 loss=25.856421 err=25.856421
I 2015-05-26 06:22:10 theanets.trainer:168 RmsProp 184 loss=24.536009 err=24.536009
I 2015-05-26 06:22:59 theanets.trainer:168 RmsProp 185 loss=24.393923 err=24.393923
I 2015-05-26 06:23:47 theanets.trainer:168 RmsProp 186 loss=23.706661 err=23.706661
I 2015-05-26 06:24:36 theanets.trainer:168 RmsProp 187 loss=22.835157 err=22.835157
I 2015-05-26 06:25:25 theanets.trainer:168 RmsProp 188 loss=23.067669 err=23.067669
I 2015-05-26 06:26:14 theanets.trainer:168 RmsProp 189 loss=22.870876 err=22.870876
I 2015-05-26 06:27:03 theanets.trainer:168 RmsProp 190 loss=22.126060 err=22.126060
I 2015-05-26 06:27:04 theanets.trainer:168 validation 19 loss=1327.568726 err=1327.568726
I 2015-05-26 06:27:53 theanets.trainer:168 RmsProp 191 loss=22.047678 err=22.047678
I 2015-05-26 06:28:43 theanets.trainer:168 RmsProp 192 loss=20.893755 err=20.893755
I 2015-05-26 06:29:32 theanets.trainer:168 RmsProp 193 loss=20.605307 err=20.605307
I 2015-05-26 06:30:22 theanets.trainer:168 RmsProp 194 loss=20.053680 err=20.053680
I 2015-05-26 06:31:11 theanets.trainer:168 RmsProp 195 loss=20.250605 err=20.250605
I 2015-05-26 06:32:01 theanets.trainer:168 RmsProp 196 loss=20.231564 err=20.231564
I 2015-05-26 06:32:51 theanets.trainer:168 RmsProp 197 loss=19.954412 err=19.954412
I 2015-05-26 06:33:41 theanets.trainer:168 RmsProp 198 loss=19.782900 err=19.782900
I 2015-05-26 06:34:29 theanets.trainer:168 RmsProp 199 loss=18.565374 err=18.565374
I 2015-05-26 06:35:15 theanets.trainer:168 RmsProp 200 loss=18.975992 err=18.975992
I 2015-05-26 06:35:16 theanets.trainer:168 validation 20 loss=1304.323975 err=1304.323975 *
I 2015-05-26 06:36:02 theanets.trainer:168 RmsProp 201 loss=18.669353 err=18.669353
I 2015-05-26 06:36:47 theanets.trainer:168 RmsProp 202 loss=17.835264 err=17.835264
I 2015-05-26 06:37:34 theanets.trainer:168 RmsProp 203 loss=18.366535 err=18.366535
I 2015-05-26 06:38:21 theanets.trainer:168 RmsProp 204 loss=17.593151 err=17.593151
I 2015-05-26 06:39:08 theanets.trainer:168 RmsProp 205 loss=17.395775 err=17.395775
I 2015-05-26 06:39:55 theanets.trainer:168 RmsProp 206 loss=17.113012 err=17.113012
I 2015-05-26 06:40:40 theanets.trainer:168 RmsProp 207 loss=17.169544 err=17.169544
I 2015-05-26 06:41:26 theanets.trainer:168 RmsProp 208 loss=16.121984 err=16.121984
I 2015-05-26 06:42:11 theanets.trainer:168 RmsProp 209 loss=16.973839 err=16.973839
I 2015-05-26 06:42:55 theanets.trainer:168 RmsProp 210 loss=15.236007 err=15.236007
I 2015-05-26 06:42:56 theanets.trainer:168 validation 21 loss=1355.916992 err=1355.916992
I 2015-05-26 06:43:41 theanets.trainer:168 RmsProp 211 loss=16.718756 err=16.718756
I 2015-05-26 06:44:26 theanets.trainer:168 RmsProp 212 loss=15.911204 err=15.911204
I 2015-05-26 06:45:11 theanets.trainer:168 RmsProp 213 loss=15.477612 err=15.477612
I 2015-05-26 06:45:56 theanets.trainer:168 RmsProp 214 loss=14.785810 err=14.785810
I 2015-05-26 06:46:41 theanets.trainer:168 RmsProp 215 loss=16.506477 err=16.506477
I 2015-05-26 06:47:26 theanets.trainer:168 RmsProp 216 loss=14.874289 err=14.874289
I 2015-05-26 06:48:11 theanets.trainer:168 RmsProp 217 loss=13.180783 err=13.180783
I 2015-05-26 06:48:55 theanets.trainer:168 RmsProp 218 loss=13.054828 err=13.054828
I 2015-05-26 06:49:40 theanets.trainer:168 RmsProp 219 loss=11.250613 err=11.250613
I 2015-05-26 06:50:25 theanets.trainer:168 RmsProp 220 loss=10.147385 err=10.147385
I 2015-05-26 06:50:26 theanets.trainer:168 validation 22 loss=1240.472534 err=1240.472534 *
I 2015-05-26 06:51:11 theanets.trainer:168 RmsProp 221 loss=10.022676 err=10.022676
I 2015-05-26 06:51:56 theanets.trainer:168 RmsProp 222 loss=9.120336 err=9.120336
I 2015-05-26 06:52:41 theanets.trainer:168 RmsProp 223 loss=8.790519 err=8.790519
I 2015-05-26 06:53:26 theanets.trainer:168 RmsProp 224 loss=8.855300 err=8.855300
I 2015-05-26 06:54:10 theanets.trainer:168 RmsProp 225 loss=8.666291 err=8.666291
I 2015-05-26 06:54:55 theanets.trainer:168 RmsProp 226 loss=8.222120 err=8.222120
I 2015-05-26 06:55:41 theanets.trainer:168 RmsProp 227 loss=7.326044 err=7.326044
I 2015-05-26 06:56:26 theanets.trainer:168 RmsProp 228 loss=7.219078 err=7.219078
I 2015-05-26 06:57:11 theanets.trainer:168 RmsProp 229 loss=7.070288 err=7.070288
I 2015-05-26 06:57:55 theanets.trainer:168 RmsProp 230 loss=7.925151 err=7.925151
I 2015-05-26 06:57:56 theanets.trainer:168 validation 23 loss=1269.505493 err=1269.505493
I 2015-05-26 06:58:36 theanets.trainer:168 RmsProp 231 loss=8.136726 err=8.136726
I 2015-05-26 06:59:17 theanets.trainer:168 RmsProp 232 loss=7.106275 err=7.106275
I 2015-05-26 06:59:58 theanets.trainer:168 RmsProp 233 loss=6.790273 err=6.790273
I 2015-05-26 07:00:38 theanets.trainer:168 RmsProp 234 loss=6.633844 err=6.633844
I 2015-05-26 07:01:19 theanets.trainer:168 RmsProp 235 loss=6.240866 err=6.240866
I 2015-05-26 07:02:00 theanets.trainer:168 RmsProp 236 loss=6.025720 err=6.025720
I 2015-05-26 07:02:41 theanets.trainer:168 RmsProp 237 loss=6.208666 err=6.208666
I 2015-05-26 07:03:23 theanets.trainer:168 RmsProp 238 loss=5.974338 err=5.974338
I 2015-05-26 07:04:04 theanets.trainer:168 RmsProp 239 loss=5.895602 err=5.895602
I 2015-05-26 07:04:45 theanets.trainer:168 RmsProp 240 loss=6.819255 err=6.819255
I 2015-05-26 07:04:46 theanets.trainer:168 validation 24 loss=1204.809937 err=1204.809937 *
I 2015-05-26 07:05:25 theanets.trainer:168 RmsProp 241 loss=6.365884 err=6.365884
I 2015-05-26 07:06:04 theanets.trainer:168 RmsProp 242 loss=6.246328 err=6.246328
I 2015-05-26 07:06:43 theanets.trainer:168 RmsProp 243 loss=7.125829 err=7.125829
I 2015-05-26 07:07:25 theanets.trainer:168 RmsProp 244 loss=6.201577 err=6.201577
I 2015-05-26 07:08:07 theanets.trainer:168 RmsProp 245 loss=6.051388 err=6.051388
I 2015-05-26 07:08:48 theanets.trainer:168 RmsProp 246 loss=5.779084 err=5.779084
I 2015-05-26 07:09:29 theanets.trainer:168 RmsProp 247 loss=5.477453 err=5.477453
I 2015-05-26 07:10:10 theanets.trainer:168 RmsProp 248 loss=5.373933 err=5.373933
I 2015-05-26 07:10:51 theanets.trainer:168 RmsProp 249 loss=5.174987 err=5.174987
I 2015-05-26 07:11:32 theanets.trainer:168 RmsProp 250 loss=4.935122 err=4.935122
I 2015-05-26 07:11:33 theanets.trainer:168 validation 25 loss=1213.570557 err=1213.570557
I 2015-05-26 07:12:12 theanets.trainer:168 RmsProp 251 loss=4.927008 err=4.927008
I 2015-05-26 07:12:51 theanets.trainer:168 RmsProp 252 loss=4.972693 err=4.972693
I 2015-05-26 07:13:30 theanets.trainer:168 RmsProp 253 loss=5.114093 err=5.114093
I 2015-05-26 07:14:10 theanets.trainer:168 RmsProp 254 loss=5.133391 err=5.133391
I 2015-05-26 07:14:51 theanets.trainer:168 RmsProp 255 loss=6.228547 err=6.228547
I 2015-05-26 07:15:32 theanets.trainer:168 RmsProp 256 loss=5.203134 err=5.203134
I 2015-05-26 07:16:13 theanets.trainer:168 RmsProp 257 loss=4.770731 err=4.770731
I 2015-05-26 07:16:54 theanets.trainer:168 RmsProp 258 loss=5.000929 err=5.000929
I 2015-05-26 07:17:34 theanets.trainer:168 RmsProp 259 loss=5.366885 err=5.366885
I 2015-05-26 07:18:15 theanets.trainer:168 RmsProp 260 loss=5.523278 err=5.523278
I 2015-05-26 07:18:16 theanets.trainer:168 validation 26 loss=1182.183350 err=1182.183350 *
I 2015-05-26 07:18:56 theanets.trainer:168 RmsProp 261 loss=4.412412 err=4.412412
I 2015-05-26 07:19:37 theanets.trainer:168 RmsProp 262 loss=4.315053 err=4.315053
I 2015-05-26 07:20:19 theanets.trainer:168 RmsProp 263 loss=5.545270 err=5.545270
I 2015-05-26 07:20:59 theanets.trainer:168 RmsProp 264 loss=5.013133 err=5.013133
I 2015-05-26 07:21:41 theanets.trainer:168 RmsProp 265 loss=4.474214 err=4.474214
I 2015-05-26 07:22:21 theanets.trainer:168 RmsProp 266 loss=4.219680 err=4.219680
I 2015-05-26 07:23:02 theanets.trainer:168 RmsProp 267 loss=4.231541 err=4.231541
I 2015-05-26 07:23:43 theanets.trainer:168 RmsProp 268 loss=4.282937 err=4.282937
I 2015-05-26 07:24:25 theanets.trainer:168 RmsProp 269 loss=4.078718 err=4.078718
I 2015-05-26 07:25:05 theanets.trainer:168 RmsProp 270 loss=4.378662 err=4.378662
I 2015-05-26 07:25:06 theanets.trainer:168 validation 27 loss=1173.745483 err=1173.745483 *
I 2015-05-26 07:25:45 theanets.trainer:168 RmsProp 271 loss=4.530307 err=4.530307
I 2015-05-26 07:26:24 theanets.trainer:168 RmsProp 272 loss=4.388349 err=4.388349
I 2015-05-26 07:27:02 theanets.trainer:168 RmsProp 273 loss=4.108685 err=4.108685
I 2015-05-26 07:27:39 theanets.trainer:168 RmsProp 274 loss=5.169485 err=5.169485
I 2015-05-26 07:28:17 theanets.trainer:168 RmsProp 275 loss=4.725731 err=4.725731
I 2015-05-26 07:28:55 theanets.trainer:168 RmsProp 276 loss=4.170029 err=4.170029
I 2015-05-26 07:29:32 theanets.trainer:168 RmsProp 277 loss=3.990830 err=3.990830
I 2015-05-26 07:30:10 theanets.trainer:168 RmsProp 278 loss=4.481272 err=4.481272
I 2015-05-26 07:30:48 theanets.trainer:168 RmsProp 279 loss=4.256070 err=4.256070
I 2015-05-26 07:31:25 theanets.trainer:168 RmsProp 280 loss=3.590651 err=3.590651
I 2015-05-26 07:31:26 theanets.trainer:168 validation 28 loss=1178.805908 err=1178.805908
I 2015-05-26 07:32:02 theanets.trainer:168 RmsProp 281 loss=3.980798 err=3.980798
I 2015-05-26 07:32:38 theanets.trainer:168 RmsProp 282 loss=4.576491 err=4.576491
I 2015-05-26 07:33:13 theanets.trainer:168 RmsProp 283 loss=3.938372 err=3.938372
I 2015-05-26 07:33:51 theanets.trainer:168 RmsProp 284 loss=3.656727 err=3.656727
I 2015-05-26 07:34:28 theanets.trainer:168 RmsProp 285 loss=3.614616 err=3.614616
I 2015-05-26 07:35:05 theanets.trainer:168 RmsProp 286 loss=3.583951 err=3.583951
I 2015-05-26 07:35:42 theanets.trainer:168 RmsProp 287 loss=3.354238 err=3.354238
I 2015-05-26 07:36:20 theanets.trainer:168 RmsProp 288 loss=3.283169 err=3.283169
I 2015-05-26 07:36:57 theanets.trainer:168 RmsProp 289 loss=3.523968 err=3.523968
I 2015-05-26 07:37:34 theanets.trainer:168 RmsProp 290 loss=3.855693 err=3.855693
I 2015-05-26 07:37:35 theanets.trainer:168 validation 29 loss=1172.026733 err=1172.026733 *
I 2015-05-26 07:38:13 theanets.trainer:168 RmsProp 291 loss=3.596678 err=3.596678
I 2015-05-26 07:38:50 theanets.trainer:168 RmsProp 292 loss=3.368189 err=3.368189
I 2015-05-26 07:39:27 theanets.trainer:168 RmsProp 293 loss=2.971451 err=2.971451
I 2015-05-26 07:40:06 theanets.trainer:168 RmsProp 294 loss=3.339111 err=3.339111
I 2015-05-26 07:40:45 theanets.trainer:168 RmsProp 295 loss=3.474788 err=3.474788
I 2015-05-26 07:41:24 theanets.trainer:168 RmsProp 296 loss=3.521487 err=3.521487
I 2015-05-26 07:42:02 theanets.trainer:168 RmsProp 297 loss=3.215108 err=3.215108
I 2015-05-26 07:42:40 theanets.trainer:168 RmsProp 298 loss=3.433243 err=3.433243
I 2015-05-26 07:43:18 theanets.trainer:168 RmsProp 299 loss=3.503814 err=3.503814
I 2015-05-26 07:43:55 theanets.trainer:168 RmsProp 300 loss=3.397792 err=3.397792
I 2015-05-26 07:43:56 theanets.trainer:168 validation 30 loss=1189.605103 err=1189.605103
I 2015-05-26 07:44:32 theanets.trainer:168 RmsProp 301 loss=3.591442 err=3.591442
I 2015-05-26 07:45:09 theanets.trainer:168 RmsProp 302 loss=3.238703 err=3.238703
I 2015-05-26 07:45:45 theanets.trainer:168 RmsProp 303 loss=3.320915 err=3.320915
I 2015-05-26 07:46:21 theanets.trainer:168 RmsProp 304 loss=3.078468 err=3.078468
I 2015-05-26 07:46:58 theanets.trainer:168 RmsProp 305 loss=3.550116 err=3.550116
I 2015-05-26 07:47:35 theanets.trainer:168 RmsProp 306 loss=3.502053 err=3.502053
I 2015-05-26 07:48:11 theanets.trainer:168 RmsProp 307 loss=3.522392 err=3.522392
I 2015-05-26 07:48:48 theanets.trainer:168 RmsProp 308 loss=3.396432 err=3.396432
I 2015-05-26 07:49:24 theanets.trainer:168 RmsProp 309 loss=3.810249 err=3.810249
I 2015-05-26 07:50:00 theanets.trainer:168 RmsProp 310 loss=3.797522 err=3.797522
I 2015-05-26 07:50:01 theanets.trainer:168 validation 31 loss=1193.222046 err=1193.222046
I 2015-05-26 07:50:34 theanets.trainer:168 RmsProp 311 loss=4.191072 err=4.191072
I 2015-05-26 07:51:08 theanets.trainer:168 RmsProp 312 loss=3.739688 err=3.739688
I 2015-05-26 07:51:41 theanets.trainer:168 RmsProp 313 loss=3.573910 err=3.573910
I 2015-05-26 07:52:17 theanets.trainer:168 RmsProp 314 loss=3.642178 err=3.642178
I 2015-05-26 07:52:53 theanets.trainer:168 RmsProp 315 loss=3.058647 err=3.058647
I 2015-05-26 07:53:30 theanets.trainer:168 RmsProp 316 loss=2.879291 err=2.879291
I 2015-05-26 07:54:07 theanets.trainer:168 RmsProp 317 loss=3.413570 err=3.413570
I 2015-05-26 07:54:44 theanets.trainer:168 RmsProp 318 loss=3.430664 err=3.430664
I 2015-05-26 07:55:21 theanets.trainer:168 RmsProp 319 loss=3.592368 err=3.592368
I 2015-05-26 07:55:57 theanets.trainer:168 RmsProp 320 loss=3.746395 err=3.746395
I 2015-05-26 07:55:58 theanets.trainer:168 validation 32 loss=1222.436279 err=1222.436279
I 2015-05-26 07:56:35 theanets.trainer:168 RmsProp 321 loss=3.582119 err=3.582119
I 2015-05-26 07:57:12 theanets.trainer:168 RmsProp 322 loss=2.955503 err=2.955503
I 2015-05-26 07:57:49 theanets.trainer:168 RmsProp 323 loss=2.548241 err=2.548241
I 2015-05-26 07:58:24 theanets.trainer:168 RmsProp 324 loss=2.660645 err=2.660645
I 2015-05-26 07:58:59 theanets.trainer:168 RmsProp 325 loss=2.952587 err=2.952587
I 2015-05-26 07:59:33 theanets.trainer:168 RmsProp 326 loss=2.760094 err=2.760094
I 2015-05-26 08:00:09 theanets.trainer:168 RmsProp 327 loss=2.691022 err=2.691022
I 2015-05-26 08:00:46 theanets.trainer:168 RmsProp 328 loss=2.887652 err=2.887652
I 2015-05-26 08:01:23 theanets.trainer:168 RmsProp 329 loss=2.900233 err=2.900233
I 2015-05-26 08:01:58 theanets.trainer:168 RmsProp 330 loss=2.900886 err=2.900886
I 2015-05-26 08:01:59 theanets.trainer:168 validation 33 loss=1182.015625 err=1182.015625
I 2015-05-26 08:02:30 theanets.trainer:168 RmsProp 331 loss=2.797340 err=2.797340
I 2015-05-26 08:03:01 theanets.trainer:168 RmsProp 332 loss=3.012753 err=3.012753
I 2015-05-26 08:03:32 theanets.trainer:168 RmsProp 333 loss=3.572731 err=3.572731
I 2015-05-26 08:04:04 theanets.trainer:168 RmsProp 334 loss=3.631473 err=3.631473
I 2015-05-26 08:04:37 theanets.trainer:168 RmsProp 335 loss=3.092981 err=3.092981
I 2015-05-26 08:05:11 theanets.trainer:168 RmsProp 336 loss=3.059555 err=3.059555
I 2015-05-26 08:05:43 theanets.trainer:168 RmsProp 337 loss=3.559103 err=3.559103
I 2015-05-26 08:06:16 theanets.trainer:168 RmsProp 338 loss=3.031741 err=3.031741
I 2015-05-26 08:06:50 theanets.trainer:168 RmsProp 339 loss=2.968742 err=2.968742
I 2015-05-26 08:07:23 theanets.trainer:168 RmsProp 340 loss=3.123929 err=3.123929
I 2015-05-26 08:07:24 theanets.trainer:168 validation 34 loss=1230.273315 err=1230.273315
I 2015-05-26 08:07:24 theanets.trainer:252 patience elapsed!
I 2015-05-26 08:07:24 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 08:07:24 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 08:07:24 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 08:07:24 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 08:07:24 theanets.main:89 --batch_size = 1024
I 2015-05-26 08:07:24 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 08:07:24 theanets.main:89 --hidden_l1 = None
I 2015-05-26 08:07:24 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 08:07:24 theanets.main:89 --train_batches = 10
I 2015-05-26 08:07:24 theanets.main:89 --valid_batches = 2
I 2015-05-26 08:07:24 theanets.main:89 --weight_l1 = None
I 2015-05-26 08:07:24 theanets.main:89 --weight_l2 = None
I 2015-05-26 08:07:24 theanets.trainer:134 compiling evaluation function
I 2015-05-26 08:07:32 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 08:09:08 theanets.trainer:168 validation 0 loss=1021.103821 err=1021.103821 *
I 2015-05-26 08:09:19 theanets.trainer:168 RmsProp 1 loss=1.633820 err=1.633820
I 2015-05-26 08:09:30 theanets.trainer:168 RmsProp 2 loss=1.051641 err=1.051641
I 2015-05-26 08:09:41 theanets.trainer:168 RmsProp 3 loss=0.827300 err=0.827300
I 2015-05-26 08:09:53 theanets.trainer:168 RmsProp 4 loss=0.748685 err=0.748685
I 2015-05-26 08:10:04 theanets.trainer:168 RmsProp 5 loss=0.687626 err=0.687626
I 2015-05-26 08:10:15 theanets.trainer:168 RmsProp 6 loss=0.647398 err=0.647398
I 2015-05-26 08:10:26 theanets.trainer:168 RmsProp 7 loss=0.609444 err=0.609444
I 2015-05-26 08:10:37 theanets.trainer:168 RmsProp 8 loss=0.584752 err=0.584752
I 2015-05-26 08:10:48 theanets.trainer:168 RmsProp 9 loss=0.583417 err=0.583417
I 2015-05-26 08:10:59 theanets.trainer:168 RmsProp 10 loss=0.556020 err=0.556020
I 2015-05-26 08:11:00 theanets.trainer:168 validation 1 loss=1008.802063 err=1008.802063 *
I 2015-05-26 08:11:11 theanets.trainer:168 RmsProp 11 loss=0.536013 err=0.536013
I 2015-05-26 08:11:22 theanets.trainer:168 RmsProp 12 loss=0.540794 err=0.540794
I 2015-05-26 08:11:33 theanets.trainer:168 RmsProp 13 loss=0.519365 err=0.519365
I 2015-05-26 08:11:44 theanets.trainer:168 RmsProp 14 loss=0.504994 err=0.504994
I 2015-05-26 08:11:55 theanets.trainer:168 RmsProp 15 loss=0.489064 err=0.489064
I 2015-05-26 08:12:06 theanets.trainer:168 RmsProp 16 loss=0.484390 err=0.484390
I 2015-05-26 08:12:17 theanets.trainer:168 RmsProp 17 loss=0.453670 err=0.453670
I 2015-05-26 08:12:29 theanets.trainer:168 RmsProp 18 loss=0.451002 err=0.451002
I 2015-05-26 08:12:40 theanets.trainer:168 RmsProp 19 loss=0.452615 err=0.452615
I 2015-05-26 08:12:51 theanets.trainer:168 RmsProp 20 loss=0.446724 err=0.446724
I 2015-05-26 08:12:51 theanets.trainer:168 validation 2 loss=1007.774414 err=1007.774414 *
I 2015-05-26 08:13:02 theanets.trainer:168 RmsProp 21 loss=0.445467 err=0.445467
I 2015-05-26 08:13:13 theanets.trainer:168 RmsProp 22 loss=0.443014 err=0.443014
I 2015-05-26 08:13:25 theanets.trainer:168 RmsProp 23 loss=0.420972 err=0.420972
I 2015-05-26 08:13:36 theanets.trainer:168 RmsProp 24 loss=0.422113 err=0.422113
I 2015-05-26 08:13:47 theanets.trainer:168 RmsProp 25 loss=0.413667 err=0.413667
I 2015-05-26 08:13:58 theanets.trainer:168 RmsProp 26 loss=0.401455 err=0.401455
I 2015-05-26 08:14:09 theanets.trainer:168 RmsProp 27 loss=0.395675 err=0.395675
I 2015-05-26 08:14:20 theanets.trainer:168 RmsProp 28 loss=0.399322 err=0.399322
I 2015-05-26 08:14:31 theanets.trainer:168 RmsProp 29 loss=0.388648 err=0.388648
I 2015-05-26 08:14:42 theanets.trainer:168 RmsProp 30 loss=0.385195 err=0.385195
I 2015-05-26 08:14:43 theanets.trainer:168 validation 3 loss=1006.758240 err=1006.758240 *
I 2015-05-26 08:14:54 theanets.trainer:168 RmsProp 31 loss=0.389911 err=0.389911
I 2015-05-26 08:15:05 theanets.trainer:168 RmsProp 32 loss=0.373454 err=0.373454
I 2015-05-26 08:15:16 theanets.trainer:168 RmsProp 33 loss=0.372406 err=0.372406
I 2015-05-26 08:15:27 theanets.trainer:168 RmsProp 34 loss=0.363174 err=0.363174
I 2015-05-26 08:15:39 theanets.trainer:168 RmsProp 35 loss=0.362171 err=0.362171
I 2015-05-26 08:15:50 theanets.trainer:168 RmsProp 36 loss=0.351479 err=0.351479
I 2015-05-26 08:16:01 theanets.trainer:168 RmsProp 37 loss=0.363146 err=0.363146
I 2015-05-26 08:16:13 theanets.trainer:168 RmsProp 38 loss=0.363740 err=0.363740
I 2015-05-26 08:16:24 theanets.trainer:168 RmsProp 39 loss=0.353532 err=0.353532
I 2015-05-26 08:16:35 theanets.trainer:168 RmsProp 40 loss=0.343738 err=0.343738
I 2015-05-26 08:16:35 theanets.trainer:168 validation 4 loss=1005.424438 err=1005.424438 *
I 2015-05-26 08:16:46 theanets.trainer:168 RmsProp 41 loss=0.347695 err=0.347695
I 2015-05-26 08:16:57 theanets.trainer:168 RmsProp 42 loss=0.336403 err=0.336403
I 2015-05-26 08:17:08 theanets.trainer:168 RmsProp 43 loss=0.335876 err=0.335876
I 2015-05-26 08:17:19 theanets.trainer:168 RmsProp 44 loss=0.337805 err=0.337805
I 2015-05-26 08:17:30 theanets.trainer:168 RmsProp 45 loss=0.330784 err=0.330784
I 2015-05-26 08:17:41 theanets.trainer:168 RmsProp 46 loss=0.328376 err=0.328376
I 2015-05-26 08:17:52 theanets.trainer:168 RmsProp 47 loss=0.323463 err=0.323463
I 2015-05-26 08:18:03 theanets.trainer:168 RmsProp 48 loss=0.316802 err=0.316802
I 2015-05-26 08:18:14 theanets.trainer:168 RmsProp 49 loss=0.311732 err=0.311732
I 2015-05-26 08:18:26 theanets.trainer:168 RmsProp 50 loss=0.308516 err=0.308516
I 2015-05-26 08:18:26 theanets.trainer:168 validation 5 loss=1003.029724 err=1003.029724 *
I 2015-05-26 08:18:37 theanets.trainer:168 RmsProp 51 loss=0.313688 err=0.313688
I 2015-05-26 08:18:48 theanets.trainer:168 RmsProp 52 loss=0.314530 err=0.314530
I 2015-05-26 08:18:59 theanets.trainer:168 RmsProp 53 loss=0.313372 err=0.313372
I 2015-05-26 08:19:10 theanets.trainer:168 RmsProp 54 loss=0.307433 err=0.307433
I 2015-05-26 08:19:21 theanets.trainer:168 RmsProp 55 loss=0.302698 err=0.302698
I 2015-05-26 08:19:32 theanets.trainer:168 RmsProp 56 loss=0.303834 err=0.303834
I 2015-05-26 08:19:44 theanets.trainer:168 RmsProp 57 loss=0.297903 err=0.297903
I 2015-05-26 08:19:55 theanets.trainer:168 RmsProp 58 loss=0.293532 err=0.293532
I 2015-05-26 08:20:07 theanets.trainer:168 RmsProp 59 loss=0.299256 err=0.299256
I 2015-05-26 08:20:18 theanets.trainer:168 RmsProp 60 loss=0.295818 err=0.295818
I 2015-05-26 08:20:19 theanets.trainer:168 validation 6 loss=1001.944275 err=1001.944275 *
I 2015-05-26 08:20:30 theanets.trainer:168 RmsProp 61 loss=0.295177 err=0.295177
I 2015-05-26 08:20:42 theanets.trainer:168 RmsProp 62 loss=0.292193 err=0.292193
I 2015-05-26 08:20:53 theanets.trainer:168 RmsProp 63 loss=0.288880 err=0.288880
I 2015-05-26 08:21:04 theanets.trainer:168 RmsProp 64 loss=0.277728 err=0.277728
I 2015-05-26 08:21:16 theanets.trainer:168 RmsProp 65 loss=0.286385 err=0.286385
I 2015-05-26 08:21:27 theanets.trainer:168 RmsProp 66 loss=0.281659 err=0.281659
I 2015-05-26 08:21:39 theanets.trainer:168 RmsProp 67 loss=0.282398 err=0.282398
I 2015-05-26 08:21:50 theanets.trainer:168 RmsProp 68 loss=0.272769 err=0.272769
I 2015-05-26 08:22:01 theanets.trainer:168 RmsProp 69 loss=0.276610 err=0.276610
I 2015-05-26 08:22:13 theanets.trainer:168 RmsProp 70 loss=0.275250 err=0.275250
I 2015-05-26 08:22:13 theanets.trainer:168 validation 7 loss=1003.017212 err=1003.017212
I 2015-05-26 08:22:25 theanets.trainer:168 RmsProp 71 loss=0.271978 err=0.271978
I 2015-05-26 08:22:36 theanets.trainer:168 RmsProp 72 loss=0.271933 err=0.271933
I 2015-05-26 08:22:48 theanets.trainer:168 RmsProp 73 loss=0.276746 err=0.276746
I 2015-05-26 08:22:59 theanets.trainer:168 RmsProp 74 loss=0.265835 err=0.265835
I 2015-05-26 08:23:10 theanets.trainer:168 RmsProp 75 loss=0.260562 err=0.260562
I 2015-05-26 08:23:22 theanets.trainer:168 RmsProp 76 loss=0.261627 err=0.261627
I 2015-05-26 08:23:33 theanets.trainer:168 RmsProp 77 loss=0.259561 err=0.259561
I 2015-05-26 08:23:44 theanets.trainer:168 RmsProp 78 loss=0.261461 err=0.261461
I 2015-05-26 08:23:56 theanets.trainer:168 RmsProp 79 loss=0.257453 err=0.257453
I 2015-05-26 08:24:07 theanets.trainer:168 RmsProp 80 loss=0.258529 err=0.258529
I 2015-05-26 08:24:08 theanets.trainer:168 validation 8 loss=1001.125977 err=1001.125977 *
I 2015-05-26 08:24:19 theanets.trainer:168 RmsProp 81 loss=0.257189 err=0.257189
I 2015-05-26 08:24:30 theanets.trainer:168 RmsProp 82 loss=0.258012 err=0.258012
I 2015-05-26 08:24:42 theanets.trainer:168 RmsProp 83 loss=0.254859 err=0.254859
I 2015-05-26 08:24:53 theanets.trainer:168 RmsProp 84 loss=0.256999 err=0.256999
I 2015-05-26 08:25:04 theanets.trainer:168 RmsProp 85 loss=0.257043 err=0.257043
I 2015-05-26 08:25:16 theanets.trainer:168 RmsProp 86 loss=0.248157 err=0.248157
I 2015-05-26 08:25:27 theanets.trainer:168 RmsProp 87 loss=0.242078 err=0.242078
I 2015-05-26 08:25:39 theanets.trainer:168 RmsProp 88 loss=0.248291 err=0.248291
I 2015-05-26 08:25:50 theanets.trainer:168 RmsProp 89 loss=0.243189 err=0.243189
I 2015-05-26 08:26:02 theanets.trainer:168 RmsProp 90 loss=0.244718 err=0.244718
I 2015-05-26 08:26:02 theanets.trainer:168 validation 9 loss=1000.942017 err=1000.942017 *
I 2015-05-26 08:26:14 theanets.trainer:168 RmsProp 91 loss=0.242357 err=0.242357
I 2015-05-26 08:26:25 theanets.trainer:168 RmsProp 92 loss=0.244808 err=0.244808
I 2015-05-26 08:26:37 theanets.trainer:168 RmsProp 93 loss=0.238452 err=0.238452
I 2015-05-26 08:26:49 theanets.trainer:168 RmsProp 94 loss=0.241233 err=0.241233
I 2015-05-26 08:27:00 theanets.trainer:168 RmsProp 95 loss=0.240737 err=0.240737
I 2015-05-26 08:27:12 theanets.trainer:168 RmsProp 96 loss=0.228187 err=0.228187
I 2015-05-26 08:27:23 theanets.trainer:168 RmsProp 97 loss=0.232856 err=0.232856
I 2015-05-26 08:27:35 theanets.trainer:168 RmsProp 98 loss=0.233712 err=0.233712
I 2015-05-26 08:27:46 theanets.trainer:168 RmsProp 99 loss=0.232705 err=0.232705
I 2015-05-26 08:27:58 theanets.trainer:168 RmsProp 100 loss=0.227108 err=0.227108
I 2015-05-26 08:27:58 theanets.trainer:168 validation 10 loss=999.234192 err=999.234192 *
I 2015-05-26 08:28:10 theanets.trainer:168 RmsProp 101 loss=0.238458 err=0.238458
I 2015-05-26 08:28:21 theanets.trainer:168 RmsProp 102 loss=0.230247 err=0.230247
I 2015-05-26 08:28:32 theanets.trainer:168 RmsProp 103 loss=0.230414 err=0.230414
I 2015-05-26 08:28:43 theanets.trainer:168 RmsProp 104 loss=0.223456 err=0.223456
I 2015-05-26 08:28:55 theanets.trainer:168 RmsProp 105 loss=0.223993 err=0.223993
I 2015-05-26 08:29:06 theanets.trainer:168 RmsProp 106 loss=0.216839 err=0.216839
I 2015-05-26 08:29:18 theanets.trainer:168 RmsProp 107 loss=0.222086 err=0.222086
I 2015-05-26 08:29:29 theanets.trainer:168 RmsProp 108 loss=0.225369 err=0.225369
I 2015-05-26 08:29:41 theanets.trainer:168 RmsProp 109 loss=0.223983 err=0.223983
I 2015-05-26 08:29:52 theanets.trainer:168 RmsProp 110 loss=0.215878 err=0.215878
I 2015-05-26 08:29:52 theanets.trainer:168 validation 11 loss=999.582336 err=999.582336
I 2015-05-26 08:30:04 theanets.trainer:168 RmsProp 111 loss=0.223446 err=0.223446
I 2015-05-26 08:30:16 theanets.trainer:168 RmsProp 112 loss=0.218422 err=0.218422
I 2015-05-26 08:30:27 theanets.trainer:168 RmsProp 113 loss=0.217236 err=0.217236
I 2015-05-26 08:30:39 theanets.trainer:168 RmsProp 114 loss=0.215988 err=0.215988
I 2015-05-26 08:30:51 theanets.trainer:168 RmsProp 115 loss=0.218890 err=0.218890
I 2015-05-26 08:31:02 theanets.trainer:168 RmsProp 116 loss=0.212747 err=0.212747
I 2015-05-26 08:31:14 theanets.trainer:168 RmsProp 117 loss=0.208535 err=0.208535
I 2015-05-26 08:31:25 theanets.trainer:168 RmsProp 118 loss=0.210312 err=0.210312
I 2015-05-26 08:31:35 theanets.trainer:168 RmsProp 119 loss=0.213000 err=0.213000
I 2015-05-26 08:31:46 theanets.trainer:168 RmsProp 120 loss=0.207380 err=0.207380
I 2015-05-26 08:31:46 theanets.trainer:168 validation 12 loss=999.460571 err=999.460571
I 2015-05-26 08:31:57 theanets.trainer:168 RmsProp 121 loss=0.215771 err=0.215771
I 2015-05-26 08:32:07 theanets.trainer:168 RmsProp 122 loss=0.212527 err=0.212527
I 2015-05-26 08:32:17 theanets.trainer:168 RmsProp 123 loss=0.207409 err=0.207409
I 2015-05-26 08:32:28 theanets.trainer:168 RmsProp 124 loss=0.208800 err=0.208800
I 2015-05-26 08:32:39 theanets.trainer:168 RmsProp 125 loss=0.208066 err=0.208066
I 2015-05-26 08:32:49 theanets.trainer:168 RmsProp 126 loss=0.203757 err=0.203757
I 2015-05-26 08:33:00 theanets.trainer:168 RmsProp 127 loss=0.203718 err=0.203718
I 2015-05-26 08:33:11 theanets.trainer:168 RmsProp 128 loss=0.201969 err=0.201969
I 2015-05-26 08:33:21 theanets.trainer:168 RmsProp 129 loss=0.205583 err=0.205583
I 2015-05-26 08:33:32 theanets.trainer:168 RmsProp 130 loss=0.203321 err=0.203321
I 2015-05-26 08:33:32 theanets.trainer:168 validation 13 loss=999.403931 err=999.403931
I 2015-05-26 08:33:42 theanets.trainer:168 RmsProp 131 loss=0.202689 err=0.202689
I 2015-05-26 08:33:53 theanets.trainer:168 RmsProp 132 loss=0.200947 err=0.200947
I 2015-05-26 08:34:03 theanets.trainer:168 RmsProp 133 loss=0.197654 err=0.197654
I 2015-05-26 08:34:13 theanets.trainer:168 RmsProp 134 loss=0.199853 err=0.199853
I 2015-05-26 08:34:24 theanets.trainer:168 RmsProp 135 loss=0.203225 err=0.203225
I 2015-05-26 08:34:34 theanets.trainer:168 RmsProp 136 loss=0.194978 err=0.194978
I 2015-05-26 08:34:45 theanets.trainer:168 RmsProp 137 loss=0.197406 err=0.197406
I 2015-05-26 08:34:55 theanets.trainer:168 RmsProp 138 loss=0.200508 err=0.200508
I 2015-05-26 08:35:06 theanets.trainer:168 RmsProp 139 loss=0.194922 err=0.194922
I 2015-05-26 08:35:16 theanets.trainer:168 RmsProp 140 loss=0.197642 err=0.197642
I 2015-05-26 08:35:17 theanets.trainer:168 validation 14 loss=998.800720 err=998.800720 *
I 2015-05-26 08:35:27 theanets.trainer:168 RmsProp 141 loss=0.194410 err=0.194410
I 2015-05-26 08:35:38 theanets.trainer:168 RmsProp 142 loss=0.192981 err=0.192981
I 2015-05-26 08:35:48 theanets.trainer:168 RmsProp 143 loss=0.195596 err=0.195596
I 2015-05-26 08:35:58 theanets.trainer:168 RmsProp 144 loss=0.196834 err=0.196834
I 2015-05-26 08:36:09 theanets.trainer:168 RmsProp 145 loss=0.195465 err=0.195465
I 2015-05-26 08:36:19 theanets.trainer:168 RmsProp 146 loss=0.189683 err=0.189683
I 2015-05-26 08:36:30 theanets.trainer:168 RmsProp 147 loss=0.187998 err=0.187998
I 2015-05-26 08:36:40 theanets.trainer:168 RmsProp 148 loss=0.186985 err=0.186985
I 2015-05-26 08:36:50 theanets.trainer:168 RmsProp 149 loss=0.189394 err=0.189394
I 2015-05-26 08:37:01 theanets.trainer:168 RmsProp 150 loss=0.195382 err=0.195382
I 2015-05-26 08:37:01 theanets.trainer:168 validation 15 loss=998.184998 err=998.184998 *
I 2015-05-26 08:37:12 theanets.trainer:168 RmsProp 151 loss=0.186053 err=0.186053
I 2015-05-26 08:37:23 theanets.trainer:168 RmsProp 152 loss=0.184188 err=0.184188
I 2015-05-26 08:37:33 theanets.trainer:168 RmsProp 153 loss=0.184800 err=0.184800
I 2015-05-26 08:37:44 theanets.trainer:168 RmsProp 154 loss=0.187684 err=0.187684
I 2015-05-26 08:37:54 theanets.trainer:168 RmsProp 155 loss=0.179836 err=0.179836
I 2015-05-26 08:38:04 theanets.trainer:168 RmsProp 156 loss=0.183376 err=0.183376
I 2015-05-26 08:38:15 theanets.trainer:168 RmsProp 157 loss=0.186046 err=0.186046
I 2015-05-26 08:38:26 theanets.trainer:168 RmsProp 158 loss=0.180658 err=0.180658
I 2015-05-26 08:38:36 theanets.trainer:168 RmsProp 159 loss=0.184442 err=0.184442
I 2015-05-26 08:38:46 theanets.trainer:168 RmsProp 160 loss=0.179886 err=0.179886
I 2015-05-26 08:38:47 theanets.trainer:168 validation 16 loss=997.212341 err=997.212341 *
I 2015-05-26 08:38:57 theanets.trainer:168 RmsProp 161 loss=0.175867 err=0.175867
I 2015-05-26 08:39:07 theanets.trainer:168 RmsProp 162 loss=0.182567 err=0.182567
I 2015-05-26 08:39:18 theanets.trainer:168 RmsProp 163 loss=0.182949 err=0.182949
I 2015-05-26 08:39:28 theanets.trainer:168 RmsProp 164 loss=0.181104 err=0.181104
I 2015-05-26 08:39:39 theanets.trainer:168 RmsProp 165 loss=0.176975 err=0.176975
I 2015-05-26 08:39:50 theanets.trainer:168 RmsProp 166 loss=0.175424 err=0.175424
I 2015-05-26 08:40:00 theanets.trainer:168 RmsProp 167 loss=0.173052 err=0.173052
I 2015-05-26 08:40:11 theanets.trainer:168 RmsProp 168 loss=0.179835 err=0.179835
I 2015-05-26 08:40:22 theanets.trainer:168 RmsProp 169 loss=0.180140 err=0.180140
I 2015-05-26 08:40:32 theanets.trainer:168 RmsProp 170 loss=0.172244 err=0.172244
I 2015-05-26 08:40:33 theanets.trainer:168 validation 17 loss=997.660278 err=997.660278
I 2015-05-26 08:40:43 theanets.trainer:168 RmsProp 171 loss=0.172982 err=0.172982
I 2015-05-26 08:40:53 theanets.trainer:168 RmsProp 172 loss=0.179049 err=0.179049
I 2015-05-26 08:41:04 theanets.trainer:168 RmsProp 173 loss=0.175044 err=0.175044
I 2015-05-26 08:41:14 theanets.trainer:168 RmsProp 174 loss=0.170462 err=0.170462
I 2015-05-26 08:41:25 theanets.trainer:168 RmsProp 175 loss=0.170348 err=0.170348
I 2015-05-26 08:41:35 theanets.trainer:168 RmsProp 176 loss=0.173111 err=0.173111
I 2015-05-26 08:41:46 theanets.trainer:168 RmsProp 177 loss=0.167481 err=0.167481
I 2015-05-26 08:41:56 theanets.trainer:168 RmsProp 178 loss=0.165263 err=0.165263
I 2015-05-26 08:42:06 theanets.trainer:168 RmsProp 179 loss=0.172390 err=0.172390
I 2015-05-26 08:42:17 theanets.trainer:168 RmsProp 180 loss=0.181043 err=0.181043
I 2015-05-26 08:42:17 theanets.trainer:168 validation 18 loss=997.080505 err=997.080505 *
I 2015-05-26 08:42:28 theanets.trainer:168 RmsProp 181 loss=0.170336 err=0.170336
I 2015-05-26 08:42:38 theanets.trainer:168 RmsProp 182 loss=0.165436 err=0.165436
I 2015-05-26 08:42:48 theanets.trainer:168 RmsProp 183 loss=0.170918 err=0.170918
I 2015-05-26 08:42:58 theanets.trainer:168 RmsProp 184 loss=0.172379 err=0.172379
I 2015-05-26 08:43:09 theanets.trainer:168 RmsProp 185 loss=0.169437 err=0.169437
I 2015-05-26 08:43:19 theanets.trainer:168 RmsProp 186 loss=0.167095 err=0.167095
I 2015-05-26 08:43:30 theanets.trainer:168 RmsProp 187 loss=0.163713 err=0.163713
I 2015-05-26 08:43:40 theanets.trainer:168 RmsProp 188 loss=0.165687 err=0.165687
I 2015-05-26 08:43:50 theanets.trainer:168 RmsProp 189 loss=0.168801 err=0.168801
I 2015-05-26 08:44:01 theanets.trainer:168 RmsProp 190 loss=0.164428 err=0.164428
I 2015-05-26 08:44:01 theanets.trainer:168 validation 19 loss=997.277344 err=997.277344
I 2015-05-26 08:44:12 theanets.trainer:168 RmsProp 191 loss=0.163940 err=0.163940
I 2015-05-26 08:44:22 theanets.trainer:168 RmsProp 192 loss=0.164331 err=0.164331
I 2015-05-26 08:44:33 theanets.trainer:168 RmsProp 193 loss=0.161530 err=0.161530
I 2015-05-26 08:44:43 theanets.trainer:168 RmsProp 194 loss=0.158942 err=0.158942
I 2015-05-26 08:44:54 theanets.trainer:168 RmsProp 195 loss=0.165321 err=0.165321
I 2015-05-26 08:45:04 theanets.trainer:168 RmsProp 196 loss=0.163590 err=0.163590
I 2015-05-26 08:45:14 theanets.trainer:168 RmsProp 197 loss=0.155693 err=0.155693
I 2015-05-26 08:45:25 theanets.trainer:168 RmsProp 198 loss=0.157159 err=0.157159
I 2015-05-26 08:45:35 theanets.trainer:168 RmsProp 199 loss=0.164597 err=0.164597
I 2015-05-26 08:45:46 theanets.trainer:168 RmsProp 200 loss=0.166957 err=0.166957
I 2015-05-26 08:45:46 theanets.trainer:168 validation 20 loss=996.185181 err=996.185181 *
I 2015-05-26 08:45:57 theanets.trainer:168 RmsProp 201 loss=0.156112 err=0.156112
I 2015-05-26 08:46:07 theanets.trainer:168 RmsProp 202 loss=0.154838 err=0.154838
I 2015-05-26 08:46:17 theanets.trainer:168 RmsProp 203 loss=0.155573 err=0.155573
I 2015-05-26 08:46:27 theanets.trainer:168 RmsProp 204 loss=0.158204 err=0.158204
I 2015-05-26 08:46:37 theanets.trainer:168 RmsProp 205 loss=0.159459 err=0.159459
I 2015-05-26 08:46:47 theanets.trainer:168 RmsProp 206 loss=0.155746 err=0.155746
I 2015-05-26 08:46:57 theanets.trainer:168 RmsProp 207 loss=0.156075 err=0.156075
I 2015-05-26 08:47:07 theanets.trainer:168 RmsProp 208 loss=0.156317 err=0.156317
I 2015-05-26 08:47:17 theanets.trainer:168 RmsProp 209 loss=0.154918 err=0.154918
I 2015-05-26 08:47:26 theanets.trainer:168 RmsProp 210 loss=0.153662 err=0.153662
I 2015-05-26 08:47:27 theanets.trainer:168 validation 21 loss=995.330566 err=995.330566 *
I 2015-05-26 08:47:37 theanets.trainer:168 RmsProp 211 loss=0.155004 err=0.155004
I 2015-05-26 08:47:47 theanets.trainer:168 RmsProp 212 loss=0.152080 err=0.152080
I 2015-05-26 08:47:57 theanets.trainer:168 RmsProp 213 loss=0.153631 err=0.153631
I 2015-05-26 08:48:07 theanets.trainer:168 RmsProp 214 loss=0.157330 err=0.157330
I 2015-05-26 08:48:18 theanets.trainer:168 RmsProp 215 loss=0.152134 err=0.152134
I 2015-05-26 08:48:28 theanets.trainer:168 RmsProp 216 loss=0.153374 err=0.153374
I 2015-05-26 08:48:38 theanets.trainer:168 RmsProp 217 loss=0.151206 err=0.151206
I 2015-05-26 08:48:48 theanets.trainer:168 RmsProp 218 loss=0.151061 err=0.151061
I 2015-05-26 08:48:58 theanets.trainer:168 RmsProp 219 loss=0.154135 err=0.154135
I 2015-05-26 08:49:08 theanets.trainer:168 RmsProp 220 loss=0.152462 err=0.152462
I 2015-05-26 08:49:09 theanets.trainer:168 validation 22 loss=993.650391 err=993.650391 *
I 2015-05-26 08:49:19 theanets.trainer:168 RmsProp 221 loss=0.149346 err=0.149346
I 2015-05-26 08:49:29 theanets.trainer:168 RmsProp 222 loss=0.149458 err=0.149458
I 2015-05-26 08:49:39 theanets.trainer:168 RmsProp 223 loss=0.155719 err=0.155719
I 2015-05-26 08:49:49 theanets.trainer:168 RmsProp 224 loss=0.155462 err=0.155462
I 2015-05-26 08:49:59 theanets.trainer:168 RmsProp 225 loss=0.148527 err=0.148527
I 2015-05-26 08:50:09 theanets.trainer:168 RmsProp 226 loss=0.147152 err=0.147152
I 2015-05-26 08:50:18 theanets.trainer:168 RmsProp 227 loss=0.152163 err=0.152163
I 2015-05-26 08:50:28 theanets.trainer:168 RmsProp 228 loss=0.145460 err=0.145460
I 2015-05-26 08:50:38 theanets.trainer:168 RmsProp 229 loss=0.145791 err=0.145791
I 2015-05-26 08:50:48 theanets.trainer:168 RmsProp 230 loss=0.148615 err=0.148615
I 2015-05-26 08:50:48 theanets.trainer:168 validation 23 loss=993.700195 err=993.700195
I 2015-05-26 08:50:56 theanets.trainer:168 RmsProp 231 loss=0.153252 err=0.153252
I 2015-05-26 08:51:05 theanets.trainer:168 RmsProp 232 loss=0.145545 err=0.145545
I 2015-05-26 08:51:13 theanets.trainer:168 RmsProp 233 loss=0.144681 err=0.144681
I 2015-05-26 08:51:22 theanets.trainer:168 RmsProp 234 loss=0.146754 err=0.146754
I 2015-05-26 08:51:31 theanets.trainer:168 RmsProp 235 loss=0.146820 err=0.146820
I 2015-05-26 08:51:40 theanets.trainer:168 RmsProp 236 loss=0.144158 err=0.144158
I 2015-05-26 08:51:48 theanets.trainer:168 RmsProp 237 loss=0.144552 err=0.144552
I 2015-05-26 08:51:57 theanets.trainer:168 RmsProp 238 loss=0.146659 err=0.146659
I 2015-05-26 08:52:05 theanets.trainer:168 RmsProp 239 loss=0.142467 err=0.142467
I 2015-05-26 08:52:14 theanets.trainer:168 RmsProp 240 loss=0.145154 err=0.145154
I 2015-05-26 08:52:14 theanets.trainer:168 validation 24 loss=993.544739 err=993.544739 *
I 2015-05-26 08:52:22 theanets.trainer:168 RmsProp 241 loss=0.144483 err=0.144483
I 2015-05-26 08:52:31 theanets.trainer:168 RmsProp 242 loss=0.140830 err=0.140830
I 2015-05-26 08:52:39 theanets.trainer:168 RmsProp 243 loss=0.144336 err=0.144336
I 2015-05-26 08:52:48 theanets.trainer:168 RmsProp 244 loss=0.139765 err=0.139765
I 2015-05-26 08:52:56 theanets.trainer:168 RmsProp 245 loss=0.138611 err=0.138611
I 2015-05-26 08:53:05 theanets.trainer:168 RmsProp 246 loss=0.140986 err=0.140986
I 2015-05-26 08:53:13 theanets.trainer:168 RmsProp 247 loss=0.141563 err=0.141563
I 2015-05-26 08:53:21 theanets.trainer:168 RmsProp 248 loss=0.141761 err=0.141761
I 2015-05-26 08:53:30 theanets.trainer:168 RmsProp 249 loss=0.141159 err=0.141159
I 2015-05-26 08:53:38 theanets.trainer:168 RmsProp 250 loss=0.140082 err=0.140082
I 2015-05-26 08:53:39 theanets.trainer:168 validation 25 loss=994.792175 err=994.792175
I 2015-05-26 08:53:47 theanets.trainer:168 RmsProp 251 loss=0.141187 err=0.141187
I 2015-05-26 08:53:55 theanets.trainer:168 RmsProp 252 loss=0.139665 err=0.139665
I 2015-05-26 08:54:04 theanets.trainer:168 RmsProp 253 loss=0.136204 err=0.136204
I 2015-05-26 08:54:11 theanets.trainer:168 RmsProp 254 loss=0.143695 err=0.143695
I 2015-05-26 08:54:18 theanets.trainer:168 RmsProp 255 loss=0.137563 err=0.137563
I 2015-05-26 08:54:26 theanets.trainer:168 RmsProp 256 loss=0.133009 err=0.133009
I 2015-05-26 08:54:34 theanets.trainer:168 RmsProp 257 loss=0.135853 err=0.135853
I 2015-05-26 08:54:41 theanets.trainer:168 RmsProp 258 loss=0.139093 err=0.139093
I 2015-05-26 08:54:48 theanets.trainer:168 RmsProp 259 loss=0.137822 err=0.137822
I 2015-05-26 08:54:55 theanets.trainer:168 RmsProp 260 loss=0.134956 err=0.134956
I 2015-05-26 08:54:56 theanets.trainer:168 validation 26 loss=993.465820 err=993.465820 *
I 2015-05-26 08:55:02 theanets.trainer:168 RmsProp 261 loss=0.132995 err=0.132995
I 2015-05-26 08:55:10 theanets.trainer:168 RmsProp 262 loss=0.140746 err=0.140746
I 2015-05-26 08:55:18 theanets.trainer:168 RmsProp 263 loss=0.138013 err=0.138013
I 2015-05-26 08:55:26 theanets.trainer:168 RmsProp 264 loss=0.136332 err=0.136332
I 2015-05-26 08:55:34 theanets.trainer:168 RmsProp 265 loss=0.136109 err=0.136109
I 2015-05-26 08:55:41 theanets.trainer:168 RmsProp 266 loss=0.137508 err=0.137508
I 2015-05-26 08:55:48 theanets.trainer:168 RmsProp 267 loss=0.132772 err=0.132772
I 2015-05-26 08:55:55 theanets.trainer:168 RmsProp 268 loss=0.132591 err=0.132591
I 2015-05-26 08:56:03 theanets.trainer:168 RmsProp 269 loss=0.134854 err=0.134854
I 2015-05-26 08:56:10 theanets.trainer:168 RmsProp 270 loss=0.131857 err=0.131857
I 2015-05-26 08:56:10 theanets.trainer:168 validation 27 loss=993.636169 err=993.636169
I 2015-05-26 08:56:18 theanets.trainer:168 RmsProp 271 loss=0.138856 err=0.138856
I 2015-05-26 08:56:25 theanets.trainer:168 RmsProp 272 loss=0.134893 err=0.134893
I 2015-05-26 08:56:33 theanets.trainer:168 RmsProp 273 loss=0.133127 err=0.133127
I 2015-05-26 08:56:40 theanets.trainer:168 RmsProp 274 loss=0.133459 err=0.133459
I 2015-05-26 08:56:47 theanets.trainer:168 RmsProp 275 loss=0.132400 err=0.132400
I 2015-05-26 08:56:55 theanets.trainer:168 RmsProp 276 loss=0.128647 err=0.128647
I 2015-05-26 08:57:03 theanets.trainer:168 RmsProp 277 loss=0.131867 err=0.131867
I 2015-05-26 08:57:10 theanets.trainer:168 RmsProp 278 loss=0.130253 err=0.130253
I 2015-05-26 08:57:18 theanets.trainer:168 RmsProp 279 loss=0.130716 err=0.130716
I 2015-05-26 08:57:26 theanets.trainer:168 RmsProp 280 loss=0.131238 err=0.131238
I 2015-05-26 08:57:26 theanets.trainer:168 validation 28 loss=992.175720 err=992.175720 *
I 2015-05-26 08:57:33 theanets.trainer:168 RmsProp 281 loss=0.131476 err=0.131476
I 2015-05-26 08:57:40 theanets.trainer:168 RmsProp 282 loss=0.131726 err=0.131726
I 2015-05-26 08:57:49 theanets.trainer:168 RmsProp 283 loss=0.126084 err=0.126084
I 2015-05-26 08:57:57 theanets.trainer:168 RmsProp 284 loss=0.129539 err=0.129539
I 2015-05-26 08:58:04 theanets.trainer:168 RmsProp 285 loss=0.130303 err=0.130303
I 2015-05-26 08:58:12 theanets.trainer:168 RmsProp 286 loss=0.129073 err=0.129073
I 2015-05-26 08:58:20 theanets.trainer:168 RmsProp 287 loss=0.125560 err=0.125560
I 2015-05-26 08:58:27 theanets.trainer:168 RmsProp 288 loss=0.129444 err=0.129444
I 2015-05-26 08:58:35 theanets.trainer:168 RmsProp 289 loss=0.130286 err=0.130286
I 2015-05-26 08:58:43 theanets.trainer:168 RmsProp 290 loss=0.126111 err=0.126111
I 2015-05-26 08:58:44 theanets.trainer:168 validation 29 loss=993.192566 err=993.192566
I 2015-05-26 08:58:51 theanets.trainer:168 RmsProp 291 loss=0.128900 err=0.128900
I 2015-05-26 08:58:58 theanets.trainer:168 RmsProp 292 loss=0.130752 err=0.130752
I 2015-05-26 08:59:06 theanets.trainer:168 RmsProp 293 loss=0.123830 err=0.123830
I 2015-05-26 08:59:14 theanets.trainer:168 RmsProp 294 loss=0.124444 err=0.124444
I 2015-05-26 08:59:22 theanets.trainer:168 RmsProp 295 loss=0.131735 err=0.131735
I 2015-05-26 08:59:29 theanets.trainer:168 RmsProp 296 loss=0.125511 err=0.125511
I 2015-05-26 08:59:37 theanets.trainer:168 RmsProp 297 loss=0.126765 err=0.126765
I 2015-05-26 08:59:45 theanets.trainer:168 RmsProp 298 loss=0.120537 err=0.120537
I 2015-05-26 08:59:52 theanets.trainer:168 RmsProp 299 loss=0.124396 err=0.124396
I 2015-05-26 09:00:00 theanets.trainer:168 RmsProp 300 loss=0.124338 err=0.124338
I 2015-05-26 09:00:01 theanets.trainer:168 validation 30 loss=991.375305 err=991.375305 *
I 2015-05-26 09:00:08 theanets.trainer:168 RmsProp 301 loss=0.124494 err=0.124494
I 2015-05-26 09:00:15 theanets.trainer:168 RmsProp 302 loss=0.125076 err=0.125076
I 2015-05-26 09:00:23 theanets.trainer:168 RmsProp 303 loss=0.123949 err=0.123949
I 2015-05-26 09:00:31 theanets.trainer:168 RmsProp 304 loss=0.123577 err=0.123577
I 2015-05-26 09:00:38 theanets.trainer:168 RmsProp 305 loss=0.123023 err=0.123023
I 2015-05-26 09:00:46 theanets.trainer:168 RmsProp 306 loss=0.124983 err=0.124983
I 2015-05-26 09:00:54 theanets.trainer:168 RmsProp 307 loss=0.122304 err=0.122304
I 2015-05-26 09:01:02 theanets.trainer:168 RmsProp 308 loss=0.120340 err=0.120340
I 2015-05-26 09:01:09 theanets.trainer:168 RmsProp 309 loss=0.124409 err=0.124409
I 2015-05-26 09:01:17 theanets.trainer:168 RmsProp 310 loss=0.118886 err=0.118886
I 2015-05-26 09:01:18 theanets.trainer:168 validation 31 loss=991.442810 err=991.442810
I 2015-05-26 09:01:25 theanets.trainer:168 RmsProp 311 loss=0.120485 err=0.120485
I 2015-05-26 09:01:33 theanets.trainer:168 RmsProp 312 loss=0.118839 err=0.118839
I 2015-05-26 09:01:40 theanets.trainer:168 RmsProp 313 loss=0.124831 err=0.124831
I 2015-05-26 09:01:49 theanets.trainer:168 RmsProp 314 loss=0.124091 err=0.124091
I 2015-05-26 09:01:56 theanets.trainer:168 RmsProp 315 loss=0.121452 err=0.121452
I 2015-05-26 09:02:03 theanets.trainer:168 RmsProp 316 loss=0.119958 err=0.119958
I 2015-05-26 09:02:10 theanets.trainer:168 RmsProp 317 loss=0.120488 err=0.120488
I 2015-05-26 09:02:17 theanets.trainer:168 RmsProp 318 loss=0.122742 err=0.122742
I 2015-05-26 09:02:24 theanets.trainer:168 RmsProp 319 loss=0.126003 err=0.126003
I 2015-05-26 09:02:32 theanets.trainer:168 RmsProp 320 loss=0.120757 err=0.120757
I 2015-05-26 09:02:32 theanets.trainer:168 validation 32 loss=991.264282 err=991.264282 *
I 2015-05-26 09:02:40 theanets.trainer:168 RmsProp 321 loss=0.117104 err=0.117104
I 2015-05-26 09:02:48 theanets.trainer:168 RmsProp 322 loss=0.119533 err=0.119533
I 2015-05-26 09:02:56 theanets.trainer:168 RmsProp 323 loss=0.118940 err=0.118940
I 2015-05-26 09:03:03 theanets.trainer:168 RmsProp 324 loss=0.119635 err=0.119635
I 2015-05-26 09:03:11 theanets.trainer:168 RmsProp 325 loss=0.116677 err=0.116677
I 2015-05-26 09:03:19 theanets.trainer:168 RmsProp 326 loss=0.116899 err=0.116899
I 2015-05-26 09:03:26 theanets.trainer:168 RmsProp 327 loss=0.120165 err=0.120165
I 2015-05-26 09:03:34 theanets.trainer:168 RmsProp 328 loss=0.118093 err=0.118093
I 2015-05-26 09:03:42 theanets.trainer:168 RmsProp 329 loss=0.116232 err=0.116232
I 2015-05-26 09:03:49 theanets.trainer:168 RmsProp 330 loss=0.118346 err=0.118346
I 2015-05-26 09:03:50 theanets.trainer:168 validation 33 loss=990.847290 err=990.847290 *
I 2015-05-26 09:03:56 theanets.trainer:168 RmsProp 331 loss=0.114595 err=0.114595
I 2015-05-26 09:04:04 theanets.trainer:168 RmsProp 332 loss=0.121945 err=0.121945
I 2015-05-26 09:04:11 theanets.trainer:168 RmsProp 333 loss=0.120008 err=0.120008
I 2015-05-26 09:04:19 theanets.trainer:168 RmsProp 334 loss=0.116911 err=0.116911
I 2015-05-26 09:04:27 theanets.trainer:168 RmsProp 335 loss=0.115959 err=0.115959
I 2015-05-26 09:04:34 theanets.trainer:168 RmsProp 336 loss=0.115981 err=0.115981
I 2015-05-26 09:04:42 theanets.trainer:168 RmsProp 337 loss=0.114117 err=0.114117
I 2015-05-26 09:04:50 theanets.trainer:168 RmsProp 338 loss=0.114323 err=0.114323
I 2015-05-26 09:04:57 theanets.trainer:168 RmsProp 339 loss=0.119191 err=0.119191
I 2015-05-26 09:05:05 theanets.trainer:168 RmsProp 340 loss=0.115949 err=0.115949
I 2015-05-26 09:05:05 theanets.trainer:168 validation 34 loss=992.137146 err=992.137146
I 2015-05-26 09:05:13 theanets.trainer:168 RmsProp 341 loss=0.117251 err=0.117251
I 2015-05-26 09:05:21 theanets.trainer:168 RmsProp 342 loss=0.115119 err=0.115119
I 2015-05-26 09:05:29 theanets.trainer:168 RmsProp 343 loss=0.113497 err=0.113497
I 2015-05-26 09:05:37 theanets.trainer:168 RmsProp 344 loss=0.115354 err=0.115354
I 2015-05-26 09:05:44 theanets.trainer:168 RmsProp 345 loss=0.114963 err=0.114963
I 2015-05-26 09:05:53 theanets.trainer:168 RmsProp 346 loss=0.113398 err=0.113398
I 2015-05-26 09:06:00 theanets.trainer:168 RmsProp 347 loss=0.113060 err=0.113060
I 2015-05-26 09:06:07 theanets.trainer:168 RmsProp 348 loss=0.114357 err=0.114357
I 2015-05-26 09:06:14 theanets.trainer:168 RmsProp 349 loss=0.116932 err=0.116932
I 2015-05-26 09:06:21 theanets.trainer:168 RmsProp 350 loss=0.109217 err=0.109217
I 2015-05-26 09:06:21 theanets.trainer:168 validation 35 loss=991.938904 err=991.938904
I 2015-05-26 09:06:28 theanets.trainer:168 RmsProp 351 loss=0.113536 err=0.113536
I 2015-05-26 09:06:35 theanets.trainer:168 RmsProp 352 loss=0.109396 err=0.109396
I 2015-05-26 09:06:42 theanets.trainer:168 RmsProp 353 loss=0.112265 err=0.112265
I 2015-05-26 09:06:50 theanets.trainer:168 RmsProp 354 loss=0.112886 err=0.112886
I 2015-05-26 09:06:58 theanets.trainer:168 RmsProp 355 loss=0.110168 err=0.110168
I 2015-05-26 09:07:06 theanets.trainer:168 RmsProp 356 loss=0.114290 err=0.114290
I 2015-05-26 09:07:13 theanets.trainer:168 RmsProp 357 loss=0.113813 err=0.113813
I 2015-05-26 09:07:20 theanets.trainer:168 RmsProp 358 loss=0.113232 err=0.113232
I 2015-05-26 09:07:28 theanets.trainer:168 RmsProp 359 loss=0.110472 err=0.110472
I 2015-05-26 09:07:35 theanets.trainer:168 RmsProp 360 loss=0.111140 err=0.111140
I 2015-05-26 09:07:35 theanets.trainer:168 validation 36 loss=991.783508 err=991.783508
I 2015-05-26 09:07:43 theanets.trainer:168 RmsProp 361 loss=0.112220 err=0.112220
I 2015-05-26 09:07:50 theanets.trainer:168 RmsProp 362 loss=0.112824 err=0.112824
I 2015-05-26 09:07:58 theanets.trainer:168 RmsProp 363 loss=0.108995 err=0.108995
I 2015-05-26 09:08:06 theanets.trainer:168 RmsProp 364 loss=0.115644 err=0.115644
I 2015-05-26 09:08:14 theanets.trainer:168 RmsProp 365 loss=0.110010 err=0.110010
I 2015-05-26 09:08:21 theanets.trainer:168 RmsProp 366 loss=0.107660 err=0.107660
I 2015-05-26 09:08:28 theanets.trainer:168 RmsProp 367 loss=0.113643 err=0.113643
I 2015-05-26 09:08:36 theanets.trainer:168 RmsProp 368 loss=0.118421 err=0.118421
I 2015-05-26 09:08:44 theanets.trainer:168 RmsProp 369 loss=0.107441 err=0.107441
I 2015-05-26 09:08:52 theanets.trainer:168 RmsProp 370 loss=0.106952 err=0.106952
I 2015-05-26 09:08:53 theanets.trainer:168 validation 37 loss=991.271423 err=991.271423
I 2015-05-26 09:09:00 theanets.trainer:168 RmsProp 371 loss=0.115288 err=0.115288
I 2015-05-26 09:09:07 theanets.trainer:168 RmsProp 372 loss=0.107885 err=0.107885
I 2015-05-26 09:09:14 theanets.trainer:168 RmsProp 373 loss=0.107731 err=0.107731
I 2015-05-26 09:09:22 theanets.trainer:168 RmsProp 374 loss=0.106986 err=0.106986
I 2015-05-26 09:09:30 theanets.trainer:168 RmsProp 375 loss=0.111246 err=0.111246
I 2015-05-26 09:09:37 theanets.trainer:168 RmsProp 376 loss=0.110347 err=0.110347
I 2015-05-26 09:09:44 theanets.trainer:168 RmsProp 377 loss=0.104662 err=0.104662
I 2015-05-26 09:09:52 theanets.trainer:168 RmsProp 378 loss=0.107462 err=0.107462
I 2015-05-26 09:09:59 theanets.trainer:168 RmsProp 379 loss=0.107073 err=0.107073
I 2015-05-26 09:10:06 theanets.trainer:168 RmsProp 380 loss=0.104270 err=0.104270
I 2015-05-26 09:10:07 theanets.trainer:168 validation 38 loss=989.360291 err=989.360291 *
I 2015-05-26 09:10:14 theanets.trainer:168 RmsProp 381 loss=0.109322 err=0.109322
I 2015-05-26 09:10:21 theanets.trainer:168 RmsProp 382 loss=0.105532 err=0.105532
I 2015-05-26 09:10:29 theanets.trainer:168 RmsProp 383 loss=0.105283 err=0.105283
I 2015-05-26 09:10:37 theanets.trainer:168 RmsProp 384 loss=0.107843 err=0.107843
I 2015-05-26 09:10:45 theanets.trainer:168 RmsProp 385 loss=0.103167 err=0.103167
I 2015-05-26 09:10:52 theanets.trainer:168 RmsProp 386 loss=0.106661 err=0.106661
I 2015-05-26 09:10:59 theanets.trainer:168 RmsProp 387 loss=0.106893 err=0.106893
I 2015-05-26 09:11:07 theanets.trainer:168 RmsProp 388 loss=0.103445 err=0.103445
I 2015-05-26 09:11:14 theanets.trainer:168 RmsProp 389 loss=0.103344 err=0.103344
I 2015-05-26 09:11:21 theanets.trainer:168 RmsProp 390 loss=0.106071 err=0.106071
I 2015-05-26 09:11:21 theanets.trainer:168 validation 39 loss=988.848633 err=988.848633 *
I 2015-05-26 09:11:27 theanets.trainer:168 RmsProp 391 loss=0.106087 err=0.106087
I 2015-05-26 09:11:33 theanets.trainer:168 RmsProp 392 loss=0.105074 err=0.105074
I 2015-05-26 09:11:39 theanets.trainer:168 RmsProp 393 loss=0.102682 err=0.102682
I 2015-05-26 09:11:45 theanets.trainer:168 RmsProp 394 loss=0.104920 err=0.104920
I 2015-05-26 09:11:51 theanets.trainer:168 RmsProp 395 loss=0.102747 err=0.102747
I 2015-05-26 09:11:57 theanets.trainer:168 RmsProp 396 loss=0.106205 err=0.106205
I 2015-05-26 09:12:03 theanets.trainer:168 RmsProp 397 loss=0.104297 err=0.104297
I 2015-05-26 09:12:09 theanets.trainer:168 RmsProp 398 loss=0.100902 err=0.100902
I 2015-05-26 09:12:15 theanets.trainer:168 RmsProp 399 loss=0.111628 err=0.111628
I 2015-05-26 09:12:21 theanets.trainer:168 RmsProp 400 loss=0.106071 err=0.106071
I 2015-05-26 09:12:22 theanets.trainer:168 validation 40 loss=989.808044 err=989.808044
I 2015-05-26 09:12:27 theanets.trainer:168 RmsProp 401 loss=0.102065 err=0.102065
I 2015-05-26 09:12:33 theanets.trainer:168 RmsProp 402 loss=0.103475 err=0.103475
I 2015-05-26 09:12:39 theanets.trainer:168 RmsProp 403 loss=0.102144 err=0.102144
I 2015-05-26 09:12:46 theanets.trainer:168 RmsProp 404 loss=0.101643 err=0.101643
I 2015-05-26 09:12:52 theanets.trainer:168 RmsProp 405 loss=0.103968 err=0.103968
I 2015-05-26 09:12:59 theanets.trainer:168 RmsProp 406 loss=0.102226 err=0.102226
I 2015-05-26 09:13:05 theanets.trainer:168 RmsProp 407 loss=0.100849 err=0.100849
I 2015-05-26 09:13:11 theanets.trainer:168 RmsProp 408 loss=0.112149 err=0.112149
I 2015-05-26 09:13:18 theanets.trainer:168 RmsProp 409 loss=0.103732 err=0.103732
I 2015-05-26 09:13:25 theanets.trainer:168 RmsProp 410 loss=0.100178 err=0.100178
I 2015-05-26 09:13:26 theanets.trainer:168 validation 41 loss=990.445740 err=990.445740
I 2015-05-26 09:13:32 theanets.trainer:168 RmsProp 411 loss=0.099300 err=0.099300
I 2015-05-26 09:13:37 theanets.trainer:168 RmsProp 412 loss=0.103328 err=0.103328
I 2015-05-26 09:13:44 theanets.trainer:168 RmsProp 413 loss=0.098448 err=0.098448
I 2015-05-26 09:13:50 theanets.trainer:168 RmsProp 414 loss=0.102669 err=0.102669
I 2015-05-26 09:13:56 theanets.trainer:168 RmsProp 415 loss=0.098737 err=0.098737
I 2015-05-26 09:14:01 theanets.trainer:168 RmsProp 416 loss=0.101443 err=0.101443
I 2015-05-26 09:14:07 theanets.trainer:168 RmsProp 417 loss=0.101638 err=0.101638
I 2015-05-26 09:14:12 theanets.trainer:168 RmsProp 418 loss=0.100303 err=0.100303
I 2015-05-26 09:14:18 theanets.trainer:168 RmsProp 419 loss=0.101676 err=0.101676
I 2015-05-26 09:14:24 theanets.trainer:168 RmsProp 420 loss=0.099925 err=0.099925
I 2015-05-26 09:14:24 theanets.trainer:168 validation 42 loss=990.559204 err=990.559204
I 2015-05-26 09:14:29 theanets.trainer:168 RmsProp 421 loss=0.101796 err=0.101796
I 2015-05-26 09:14:34 theanets.trainer:168 RmsProp 422 loss=0.102136 err=0.102136
I 2015-05-26 09:14:40 theanets.trainer:168 RmsProp 423 loss=0.101563 err=0.101563
I 2015-05-26 09:14:45 theanets.trainer:168 RmsProp 424 loss=0.100539 err=0.100539
I 2015-05-26 09:14:50 theanets.trainer:168 RmsProp 425 loss=0.097359 err=0.097359
I 2015-05-26 09:14:55 theanets.trainer:168 RmsProp 426 loss=0.098995 err=0.098995
I 2015-05-26 09:15:01 theanets.trainer:168 RmsProp 427 loss=0.098873 err=0.098873
I 2015-05-26 09:15:06 theanets.trainer:168 RmsProp 428 loss=0.098804 err=0.098804
I 2015-05-26 09:15:11 theanets.trainer:168 RmsProp 429 loss=0.097740 err=0.097740
I 2015-05-26 09:15:16 theanets.trainer:168 RmsProp 430 loss=0.098684 err=0.098684
I 2015-05-26 09:15:17 theanets.trainer:168 validation 43 loss=989.971313 err=989.971313
I 2015-05-26 09:15:22 theanets.trainer:168 RmsProp 431 loss=0.103922 err=0.103922
I 2015-05-26 09:15:27 theanets.trainer:168 RmsProp 432 loss=0.098072 err=0.098072
I 2015-05-26 09:15:33 theanets.trainer:168 RmsProp 433 loss=0.098776 err=0.098776
I 2015-05-26 09:15:39 theanets.trainer:168 RmsProp 434 loss=0.095961 err=0.095961
I 2015-05-26 09:15:45 theanets.trainer:168 RmsProp 435 loss=0.097817 err=0.097817
I 2015-05-26 09:15:52 theanets.trainer:168 RmsProp 436 loss=0.099570 err=0.099570
I 2015-05-26 09:15:59 theanets.trainer:168 RmsProp 437 loss=0.093977 err=0.093977
I 2015-05-26 09:16:06 theanets.trainer:168 RmsProp 438 loss=0.096725 err=0.096725
I 2015-05-26 09:16:12 theanets.trainer:168 RmsProp 439 loss=0.099287 err=0.099287
I 2015-05-26 09:16:18 theanets.trainer:168 RmsProp 440 loss=0.096099 err=0.096099
I 2015-05-26 09:16:18 theanets.trainer:168 validation 44 loss=987.882751 err=987.882751 *
I 2015-05-26 09:16:25 theanets.trainer:168 RmsProp 441 loss=0.099406 err=0.099406
I 2015-05-26 09:16:32 theanets.trainer:168 RmsProp 442 loss=0.097113 err=0.097113
I 2015-05-26 09:16:38 theanets.trainer:168 RmsProp 443 loss=0.093750 err=0.093750
I 2015-05-26 09:16:45 theanets.trainer:168 RmsProp 444 loss=0.097565 err=0.097565
I 2015-05-26 09:16:52 theanets.trainer:168 RmsProp 445 loss=0.096417 err=0.096417
I 2015-05-26 09:16:58 theanets.trainer:168 RmsProp 446 loss=0.095885 err=0.095885
I 2015-05-26 09:17:05 theanets.trainer:168 RmsProp 447 loss=0.092568 err=0.092568
I 2015-05-26 09:17:11 theanets.trainer:168 RmsProp 448 loss=0.107137 err=0.107137
I 2015-05-26 09:17:17 theanets.trainer:168 RmsProp 449 loss=0.095035 err=0.095035
I 2015-05-26 09:17:23 theanets.trainer:168 RmsProp 450 loss=0.093420 err=0.093420
I 2015-05-26 09:17:23 theanets.trainer:168 validation 45 loss=989.130859 err=989.130859
I 2015-05-26 09:17:29 theanets.trainer:168 RmsProp 451 loss=0.098027 err=0.098027
I 2015-05-26 09:17:35 theanets.trainer:168 RmsProp 452 loss=0.095129 err=0.095129
I 2015-05-26 09:17:41 theanets.trainer:168 RmsProp 453 loss=0.100500 err=0.100500
I 2015-05-26 09:17:47 theanets.trainer:168 RmsProp 454 loss=0.097613 err=0.097613
I 2015-05-26 09:17:53 theanets.trainer:168 RmsProp 455 loss=0.095584 err=0.095584
I 2015-05-26 09:17:59 theanets.trainer:168 RmsProp 456 loss=0.095988 err=0.095988
I 2015-05-26 09:18:06 theanets.trainer:168 RmsProp 457 loss=0.094296 err=0.094296
I 2015-05-26 09:18:13 theanets.trainer:168 RmsProp 458 loss=0.095454 err=0.095454
I 2015-05-26 09:18:19 theanets.trainer:168 RmsProp 459 loss=0.094249 err=0.094249
I 2015-05-26 09:18:25 theanets.trainer:168 RmsProp 460 loss=0.094945 err=0.094945
I 2015-05-26 09:18:26 theanets.trainer:168 validation 46 loss=989.457031 err=989.457031
I 2015-05-26 09:18:32 theanets.trainer:168 RmsProp 461 loss=0.093119 err=0.093119
I 2015-05-26 09:18:39 theanets.trainer:168 RmsProp 462 loss=0.097695 err=0.097695
I 2015-05-26 09:18:45 theanets.trainer:168 RmsProp 463 loss=0.096661 err=0.096661
I 2015-05-26 09:18:52 theanets.trainer:168 RmsProp 464 loss=0.090674 err=0.090674
I 2015-05-26 09:18:58 theanets.trainer:168 RmsProp 465 loss=0.098508 err=0.098508
I 2015-05-26 09:19:04 theanets.trainer:168 RmsProp 466 loss=0.093822 err=0.093822
I 2015-05-26 09:19:11 theanets.trainer:168 RmsProp 467 loss=0.094282 err=0.094282
I 2015-05-26 09:19:17 theanets.trainer:168 RmsProp 468 loss=0.093117 err=0.093117
I 2015-05-26 09:19:23 theanets.trainer:168 RmsProp 469 loss=0.088782 err=0.088782
I 2015-05-26 09:19:29 theanets.trainer:168 RmsProp 470 loss=0.092047 err=0.092047
I 2015-05-26 09:19:30 theanets.trainer:168 validation 47 loss=988.004395 err=988.004395
I 2015-05-26 09:19:36 theanets.trainer:168 RmsProp 471 loss=0.093439 err=0.093439
I 2015-05-26 09:19:42 theanets.trainer:168 RmsProp 472 loss=0.090264 err=0.090264
I 2015-05-26 09:19:49 theanets.trainer:168 RmsProp 473 loss=0.092165 err=0.092165
I 2015-05-26 09:19:55 theanets.trainer:168 RmsProp 474 loss=0.094596 err=0.094596
I 2015-05-26 09:20:01 theanets.trainer:168 RmsProp 475 loss=0.091386 err=0.091386
I 2015-05-26 09:20:08 theanets.trainer:168 RmsProp 476 loss=0.092634 err=0.092634
I 2015-05-26 09:20:14 theanets.trainer:168 RmsProp 477 loss=0.091440 err=0.091440
I 2015-05-26 09:20:21 theanets.trainer:168 RmsProp 478 loss=0.092978 err=0.092978
I 2015-05-26 09:20:28 theanets.trainer:168 RmsProp 479 loss=0.092130 err=0.092130
I 2015-05-26 09:20:35 theanets.trainer:168 RmsProp 480 loss=0.089689 err=0.089689
I 2015-05-26 09:20:36 theanets.trainer:168 validation 48 loss=987.886414 err=987.886414
I 2015-05-26 09:20:42 theanets.trainer:168 RmsProp 481 loss=0.092596 err=0.092596
I 2015-05-26 09:20:47 theanets.trainer:168 RmsProp 482 loss=0.093157 err=0.093157
I 2015-05-26 09:20:54 theanets.trainer:168 RmsProp 483 loss=0.090646 err=0.090646
I 2015-05-26 09:21:00 theanets.trainer:168 RmsProp 484 loss=0.090525 err=0.090525
I 2015-05-26 09:21:06 theanets.trainer:168 RmsProp 485 loss=0.090105 err=0.090105
I 2015-05-26 09:21:12 theanets.trainer:168 RmsProp 486 loss=0.090062 err=0.090062
I 2015-05-26 09:21:19 theanets.trainer:168 RmsProp 487 loss=0.088480 err=0.088480
I 2015-05-26 09:21:25 theanets.trainer:168 RmsProp 488 loss=0.097293 err=0.097293
I 2015-05-26 09:21:32 theanets.trainer:168 RmsProp 489 loss=0.092877 err=0.092877
I 2015-05-26 09:21:38 theanets.trainer:168 RmsProp 490 loss=0.086042 err=0.086042
I 2015-05-26 09:21:38 theanets.trainer:168 validation 49 loss=987.367371 err=987.367371 *
I 2015-05-26 09:21:44 theanets.trainer:168 RmsProp 491 loss=0.090989 err=0.090989
I 2015-05-26 09:21:50 theanets.trainer:168 RmsProp 492 loss=0.091456 err=0.091456
I 2015-05-26 09:21:55 theanets.trainer:168 RmsProp 493 loss=0.089028 err=0.089028
I 2015-05-26 09:22:00 theanets.trainer:168 RmsProp 494 loss=0.090559 err=0.090559
I 2015-05-26 09:22:05 theanets.trainer:168 RmsProp 495 loss=0.089220 err=0.089220
I 2015-05-26 09:22:10 theanets.trainer:168 RmsProp 496 loss=0.092324 err=0.092324
I 2015-05-26 09:22:15 theanets.trainer:168 RmsProp 497 loss=0.089576 err=0.089576
I 2015-05-26 09:22:20 theanets.trainer:168 RmsProp 498 loss=0.088472 err=0.088472
I 2015-05-26 09:22:26 theanets.trainer:168 RmsProp 499 loss=0.090414 err=0.090414
I 2015-05-26 09:22:32 theanets.trainer:168 RmsProp 500 loss=0.090708 err=0.090708
I 2015-05-26 09:22:32 theanets.trainer:168 validation 50 loss=986.310669 err=986.310669 *
I 2015-05-26 09:22:37 theanets.trainer:168 RmsProp 501 loss=0.086575 err=0.086575
I 2015-05-26 09:22:42 theanets.trainer:168 RmsProp 502 loss=0.087991 err=0.087991
I 2015-05-26 09:22:47 theanets.trainer:168 RmsProp 503 loss=0.093170 err=0.093170
I 2015-05-26 09:22:52 theanets.trainer:168 RmsProp 504 loss=0.087141 err=0.087141
I 2015-05-26 09:22:56 theanets.trainer:168 RmsProp 505 loss=0.086896 err=0.086896
I 2015-05-26 09:23:01 theanets.trainer:168 RmsProp 506 loss=0.089976 err=0.089976
I 2015-05-26 09:23:04 theanets.trainer:168 RmsProp 507 loss=0.086011 err=0.086011
I 2015-05-26 09:23:08 theanets.trainer:168 RmsProp 508 loss=0.089645 err=0.089645
I 2015-05-26 09:23:12 theanets.trainer:168 RmsProp 509 loss=0.092271 err=0.092271
I 2015-05-26 09:23:17 theanets.trainer:168 RmsProp 510 loss=0.085557 err=0.085557
I 2015-05-26 09:23:17 theanets.trainer:168 validation 51 loss=987.088379 err=987.088379
I 2015-05-26 09:23:21 theanets.trainer:168 RmsProp 511 loss=0.087810 err=0.087810
I 2015-05-26 09:23:25 theanets.trainer:168 RmsProp 512 loss=0.087734 err=0.087734
I 2015-05-26 09:23:29 theanets.trainer:168 RmsProp 513 loss=0.089320 err=0.089320
I 2015-05-26 09:23:33 theanets.trainer:168 RmsProp 514 loss=0.088975 err=0.088975
I 2015-05-26 09:23:37 theanets.trainer:168 RmsProp 515 loss=0.087239 err=0.087239
I 2015-05-26 09:23:41 theanets.trainer:168 RmsProp 516 loss=0.086120 err=0.086120
I 2015-05-26 09:23:45 theanets.trainer:168 RmsProp 517 loss=0.085698 err=0.085698
I 2015-05-26 09:23:49 theanets.trainer:168 RmsProp 518 loss=0.090641 err=0.090641
I 2015-05-26 09:23:53 theanets.trainer:168 RmsProp 519 loss=0.083855 err=0.083855
I 2015-05-26 09:23:57 theanets.trainer:168 RmsProp 520 loss=0.086669 err=0.086669
I 2015-05-26 09:23:58 theanets.trainer:168 validation 52 loss=986.554871 err=986.554871
I 2015-05-26 09:24:02 theanets.trainer:168 RmsProp 521 loss=0.084555 err=0.084555
I 2015-05-26 09:24:06 theanets.trainer:168 RmsProp 522 loss=0.087622 err=0.087622
I 2015-05-26 09:24:10 theanets.trainer:168 RmsProp 523 loss=0.087114 err=0.087114
I 2015-05-26 09:24:15 theanets.trainer:168 RmsProp 524 loss=0.090146 err=0.090146
I 2015-05-26 09:24:19 theanets.trainer:168 RmsProp 525 loss=0.086601 err=0.086601
I 2015-05-26 09:24:24 theanets.trainer:168 RmsProp 526 loss=0.086130 err=0.086130
I 2015-05-26 09:24:28 theanets.trainer:168 RmsProp 527 loss=0.084637 err=0.084637
I 2015-05-26 09:24:32 theanets.trainer:168 RmsProp 528 loss=0.086638 err=0.086638
I 2015-05-26 09:24:36 theanets.trainer:168 RmsProp 529 loss=0.084081 err=0.084081
I 2015-05-26 09:24:40 theanets.trainer:168 RmsProp 530 loss=0.089013 err=0.089013
I 2015-05-26 09:24:41 theanets.trainer:168 validation 53 loss=987.231079 err=987.231079
I 2015-05-26 09:24:45 theanets.trainer:168 RmsProp 531 loss=0.085245 err=0.085245
I 2015-05-26 09:24:50 theanets.trainer:168 RmsProp 532 loss=0.083858 err=0.083858
I 2015-05-26 09:24:54 theanets.trainer:168 RmsProp 533 loss=0.086513 err=0.086513
I 2015-05-26 09:24:58 theanets.trainer:168 RmsProp 534 loss=0.083543 err=0.083543
I 2015-05-26 09:25:02 theanets.trainer:168 RmsProp 535 loss=0.085523 err=0.085523
I 2015-05-26 09:25:06 theanets.trainer:168 RmsProp 536 loss=0.086066 err=0.086066
I 2015-05-26 09:25:10 theanets.trainer:168 RmsProp 537 loss=0.085064 err=0.085064
I 2015-05-26 09:25:14 theanets.trainer:168 RmsProp 538 loss=0.085218 err=0.085218
I 2015-05-26 09:25:18 theanets.trainer:168 RmsProp 539 loss=0.082075 err=0.082075
I 2015-05-26 09:25:22 theanets.trainer:168 RmsProp 540 loss=0.084987 err=0.084987
I 2015-05-26 09:25:22 theanets.trainer:168 validation 54 loss=985.369568 err=985.369568 *
I 2015-05-26 09:25:26 theanets.trainer:168 RmsProp 541 loss=0.085320 err=0.085320
I 2015-05-26 09:25:30 theanets.trainer:168 RmsProp 542 loss=0.083697 err=0.083697
I 2015-05-26 09:25:34 theanets.trainer:168 RmsProp 543 loss=0.082306 err=0.082306
I 2015-05-26 09:25:38 theanets.trainer:168 RmsProp 544 loss=0.083557 err=0.083557
I 2015-05-26 09:25:42 theanets.trainer:168 RmsProp 545 loss=0.087001 err=0.087001
I 2015-05-26 09:25:46 theanets.trainer:168 RmsProp 546 loss=0.084486 err=0.084486
I 2015-05-26 09:25:50 theanets.trainer:168 RmsProp 547 loss=0.081969 err=0.081969
I 2015-05-26 09:25:54 theanets.trainer:168 RmsProp 548 loss=0.086493 err=0.086493
I 2015-05-26 09:25:58 theanets.trainer:168 RmsProp 549 loss=0.082459 err=0.082459
I 2015-05-26 09:26:02 theanets.trainer:168 RmsProp 550 loss=0.080876 err=0.080876
I 2015-05-26 09:26:02 theanets.trainer:168 validation 55 loss=986.734985 err=986.734985
I 2015-05-26 09:26:06 theanets.trainer:168 RmsProp 551 loss=0.090597 err=0.090597
I 2015-05-26 09:26:10 theanets.trainer:168 RmsProp 552 loss=0.082880 err=0.082880
I 2015-05-26 09:26:13 theanets.trainer:168 RmsProp 553 loss=0.080783 err=0.080783
I 2015-05-26 09:26:17 theanets.trainer:168 RmsProp 554 loss=0.084711 err=0.084711
I 2015-05-26 09:26:21 theanets.trainer:168 RmsProp 555 loss=0.080554 err=0.080554
I 2015-05-26 09:26:25 theanets.trainer:168 RmsProp 556 loss=0.085087 err=0.085087
I 2015-05-26 09:26:30 theanets.trainer:168 RmsProp 557 loss=0.083761 err=0.083761
I 2015-05-26 09:26:33 theanets.trainer:168 RmsProp 558 loss=0.082634 err=0.082634
I 2015-05-26 09:26:38 theanets.trainer:168 RmsProp 559 loss=0.081523 err=0.081523
I 2015-05-26 09:26:42 theanets.trainer:168 RmsProp 560 loss=0.080111 err=0.080111
I 2015-05-26 09:26:42 theanets.trainer:168 validation 56 loss=986.927185 err=986.927185
I 2015-05-26 09:26:46 theanets.trainer:168 RmsProp 561 loss=0.085184 err=0.085184
I 2015-05-26 09:26:50 theanets.trainer:168 RmsProp 562 loss=0.080884 err=0.080884
I 2015-05-26 09:26:53 theanets.trainer:168 RmsProp 563 loss=0.088924 err=0.088924
I 2015-05-26 09:26:57 theanets.trainer:168 RmsProp 564 loss=0.089025 err=0.089025
I 2015-05-26 09:27:01 theanets.trainer:168 RmsProp 565 loss=0.081022 err=0.081022
I 2015-05-26 09:27:06 theanets.trainer:168 RmsProp 566 loss=0.082771 err=0.082771
I 2015-05-26 09:27:10 theanets.trainer:168 RmsProp 567 loss=0.082877 err=0.082877
I 2015-05-26 09:27:14 theanets.trainer:168 RmsProp 568 loss=0.082084 err=0.082084
I 2015-05-26 09:27:19 theanets.trainer:168 RmsProp 569 loss=0.079228 err=0.079228
I 2015-05-26 09:27:23 theanets.trainer:168 RmsProp 570 loss=0.085717 err=0.085717
I 2015-05-26 09:27:23 theanets.trainer:168 validation 57 loss=986.740173 err=986.740173
I 2015-05-26 09:27:27 theanets.trainer:168 RmsProp 571 loss=0.080944 err=0.080944
I 2015-05-26 09:27:31 theanets.trainer:168 RmsProp 572 loss=0.080468 err=0.080468
I 2015-05-26 09:27:35 theanets.trainer:168 RmsProp 573 loss=0.081986 err=0.081986
I 2015-05-26 09:27:40 theanets.trainer:168 RmsProp 574 loss=0.083157 err=0.083157
I 2015-05-26 09:27:44 theanets.trainer:168 RmsProp 575 loss=0.079779 err=0.079779
I 2015-05-26 09:27:47 theanets.trainer:168 RmsProp 576 loss=0.078269 err=0.078269
I 2015-05-26 09:27:51 theanets.trainer:168 RmsProp 577 loss=0.081695 err=0.081695
I 2015-05-26 09:27:55 theanets.trainer:168 RmsProp 578 loss=0.081675 err=0.081675
I 2015-05-26 09:27:59 theanets.trainer:168 RmsProp 579 loss=0.079102 err=0.079102
I 2015-05-26 09:28:04 theanets.trainer:168 RmsProp 580 loss=0.078121 err=0.078121
I 2015-05-26 09:28:04 theanets.trainer:168 validation 58 loss=984.794922 err=984.794922 *
I 2015-05-26 09:28:09 theanets.trainer:168 RmsProp 581 loss=0.082407 err=0.082407
I 2015-05-26 09:28:12 theanets.trainer:168 RmsProp 582 loss=0.081703 err=0.081703
I 2015-05-26 09:28:17 theanets.trainer:168 RmsProp 583 loss=0.081480 err=0.081480
I 2015-05-26 09:28:21 theanets.trainer:168 RmsProp 584 loss=0.079933 err=0.079933
I 2015-05-26 09:28:25 theanets.trainer:168 RmsProp 585 loss=0.082896 err=0.082896
I 2015-05-26 09:28:29 theanets.trainer:168 RmsProp 586 loss=0.078269 err=0.078269
I 2015-05-26 09:28:34 theanets.trainer:168 RmsProp 587 loss=0.081085 err=0.081085
I 2015-05-26 09:28:38 theanets.trainer:168 RmsProp 588 loss=0.078405 err=0.078405
I 2015-05-26 09:28:43 theanets.trainer:168 RmsProp 589 loss=0.078990 err=0.078990
I 2015-05-26 09:28:47 theanets.trainer:168 RmsProp 590 loss=0.078645 err=0.078645
I 2015-05-26 09:28:47 theanets.trainer:168 validation 59 loss=985.014099 err=985.014099
I 2015-05-26 09:28:52 theanets.trainer:168 RmsProp 591 loss=0.078676 err=0.078676
I 2015-05-26 09:28:56 theanets.trainer:168 RmsProp 592 loss=0.082573 err=0.082573
I 2015-05-26 09:29:00 theanets.trainer:168 RmsProp 593 loss=0.080323 err=0.080323
I 2015-05-26 09:29:05 theanets.trainer:168 RmsProp 594 loss=0.078329 err=0.078329
I 2015-05-26 09:29:09 theanets.trainer:168 RmsProp 595 loss=0.079343 err=0.079343
I 2015-05-26 09:29:13 theanets.trainer:168 RmsProp 596 loss=0.080465 err=0.080465
I 2015-05-26 09:29:18 theanets.trainer:168 RmsProp 597 loss=0.078819 err=0.078819
I 2015-05-26 09:29:22 theanets.trainer:168 RmsProp 598 loss=0.076326 err=0.076326
I 2015-05-26 09:29:26 theanets.trainer:168 RmsProp 599 loss=0.080268 err=0.080268
I 2015-05-26 09:29:30 theanets.trainer:168 RmsProp 600 loss=0.079816 err=0.079816
I 2015-05-26 09:29:30 theanets.trainer:168 validation 60 loss=985.406738 err=985.406738
I 2015-05-26 09:29:34 theanets.trainer:168 RmsProp 601 loss=0.074485 err=0.074485
I 2015-05-26 09:29:39 theanets.trainer:168 RmsProp 602 loss=0.077952 err=0.077952
I 2015-05-26 09:29:43 theanets.trainer:168 RmsProp 603 loss=0.077217 err=0.077217
I 2015-05-26 09:29:48 theanets.trainer:168 RmsProp 604 loss=0.077654 err=0.077654
I 2015-05-26 09:29:52 theanets.trainer:168 RmsProp 605 loss=0.080337 err=0.080337
I 2015-05-26 09:29:56 theanets.trainer:168 RmsProp 606 loss=0.076251 err=0.076251
I 2015-05-26 09:30:00 theanets.trainer:168 RmsProp 607 loss=0.079294 err=0.079294
I 2015-05-26 09:30:04 theanets.trainer:168 RmsProp 608 loss=0.074610 err=0.074610
I 2015-05-26 09:30:08 theanets.trainer:168 RmsProp 609 loss=0.081307 err=0.081307
I 2015-05-26 09:30:12 theanets.trainer:168 RmsProp 610 loss=0.077750 err=0.077750
I 2015-05-26 09:30:13 theanets.trainer:168 validation 61 loss=985.412292 err=985.412292
I 2015-05-26 09:30:16 theanets.trainer:168 RmsProp 611 loss=0.074774 err=0.074774
I 2015-05-26 09:30:21 theanets.trainer:168 RmsProp 612 loss=0.077032 err=0.077032
I 2015-05-26 09:30:24 theanets.trainer:168 RmsProp 613 loss=0.078726 err=0.078726
I 2015-05-26 09:30:28 theanets.trainer:168 RmsProp 614 loss=0.077208 err=0.077208
I 2015-05-26 09:30:33 theanets.trainer:168 RmsProp 615 loss=0.076002 err=0.076002
I 2015-05-26 09:30:37 theanets.trainer:168 RmsProp 616 loss=0.076854 err=0.076854
I 2015-05-26 09:30:42 theanets.trainer:168 RmsProp 617 loss=0.075703 err=0.075703
I 2015-05-26 09:30:46 theanets.trainer:168 RmsProp 618 loss=0.076912 err=0.076912
I 2015-05-26 09:30:51 theanets.trainer:168 RmsProp 619 loss=0.075424 err=0.075424
I 2015-05-26 09:30:56 theanets.trainer:168 RmsProp 620 loss=0.080138 err=0.080138
I 2015-05-26 09:30:56 theanets.trainer:168 validation 62 loss=984.162292 err=984.162292 *
I 2015-05-26 09:31:00 theanets.trainer:168 RmsProp 621 loss=0.075369 err=0.075369
I 2015-05-26 09:31:04 theanets.trainer:168 RmsProp 622 loss=0.077208 err=0.077208
I 2015-05-26 09:31:09 theanets.trainer:168 RmsProp 623 loss=0.074175 err=0.074175
I 2015-05-26 09:31:13 theanets.trainer:168 RmsProp 624 loss=0.075351 err=0.075351
I 2015-05-26 09:31:17 theanets.trainer:168 RmsProp 625 loss=0.075188 err=0.075188
I 2015-05-26 09:31:21 theanets.trainer:168 RmsProp 626 loss=0.076121 err=0.076121
I 2015-05-26 09:31:25 theanets.trainer:168 RmsProp 627 loss=0.075948 err=0.075948
I 2015-05-26 09:31:29 theanets.trainer:168 RmsProp 628 loss=0.074994 err=0.074994
I 2015-05-26 09:31:33 theanets.trainer:168 RmsProp 629 loss=0.079412 err=0.079412
I 2015-05-26 09:31:38 theanets.trainer:168 RmsProp 630 loss=0.081376 err=0.081376
I 2015-05-26 09:31:38 theanets.trainer:168 validation 63 loss=985.418152 err=985.418152
I 2015-05-26 09:31:42 theanets.trainer:168 RmsProp 631 loss=0.078589 err=0.078589
I 2015-05-26 09:31:46 theanets.trainer:168 RmsProp 632 loss=0.075318 err=0.075318
I 2015-05-26 09:31:50 theanets.trainer:168 RmsProp 633 loss=0.075668 err=0.075668
I 2015-05-26 09:31:54 theanets.trainer:168 RmsProp 634 loss=0.074530 err=0.074530
I 2015-05-26 09:31:58 theanets.trainer:168 RmsProp 635 loss=0.074776 err=0.074776
I 2015-05-26 09:32:01 theanets.trainer:168 RmsProp 636 loss=0.074062 err=0.074062
I 2015-05-26 09:32:05 theanets.trainer:168 RmsProp 637 loss=0.074959 err=0.074959
I 2015-05-26 09:32:08 theanets.trainer:168 RmsProp 638 loss=0.077056 err=0.077056
I 2015-05-26 09:32:11 theanets.trainer:168 RmsProp 639 loss=0.073000 err=0.073000
I 2015-05-26 09:32:15 theanets.trainer:168 RmsProp 640 loss=0.076074 err=0.076074
I 2015-05-26 09:32:15 theanets.trainer:168 validation 64 loss=985.222107 err=985.222107
I 2015-05-26 09:32:18 theanets.trainer:168 RmsProp 641 loss=0.073559 err=0.073559
I 2015-05-26 09:32:22 theanets.trainer:168 RmsProp 642 loss=0.076729 err=0.076729
I 2015-05-26 09:32:25 theanets.trainer:168 RmsProp 643 loss=0.076415 err=0.076415
I 2015-05-26 09:32:28 theanets.trainer:168 RmsProp 644 loss=0.075678 err=0.075678
I 2015-05-26 09:32:32 theanets.trainer:168 RmsProp 645 loss=0.077411 err=0.077411
I 2015-05-26 09:32:36 theanets.trainer:168 RmsProp 646 loss=0.072816 err=0.072816
I 2015-05-26 09:32:39 theanets.trainer:168 RmsProp 647 loss=0.074676 err=0.074676
I 2015-05-26 09:32:42 theanets.trainer:168 RmsProp 648 loss=0.074382 err=0.074382
I 2015-05-26 09:32:45 theanets.trainer:168 RmsProp 649 loss=0.072787 err=0.072787
I 2015-05-26 09:32:48 theanets.trainer:168 RmsProp 650 loss=0.074227 err=0.074227
I 2015-05-26 09:32:48 theanets.trainer:168 validation 65 loss=986.200623 err=986.200623
I 2015-05-26 09:32:51 theanets.trainer:168 RmsProp 651 loss=0.074501 err=0.074501
I 2015-05-26 09:32:55 theanets.trainer:168 RmsProp 652 loss=0.071969 err=0.071969
I 2015-05-26 09:32:58 theanets.trainer:168 RmsProp 653 loss=0.074689 err=0.074689
I 2015-05-26 09:33:01 theanets.trainer:168 RmsProp 654 loss=0.070898 err=0.070898
I 2015-05-26 09:33:04 theanets.trainer:168 RmsProp 655 loss=0.073449 err=0.073449
I 2015-05-26 09:33:07 theanets.trainer:168 RmsProp 656 loss=0.073152 err=0.073152
I 2015-05-26 09:33:10 theanets.trainer:168 RmsProp 657 loss=0.075981 err=0.075981
I 2015-05-26 09:33:14 theanets.trainer:168 RmsProp 658 loss=0.071641 err=0.071641
I 2015-05-26 09:33:17 theanets.trainer:168 RmsProp 659 loss=0.073488 err=0.073488
I 2015-05-26 09:33:20 theanets.trainer:168 RmsProp 660 loss=0.073349 err=0.073349
I 2015-05-26 09:33:21 theanets.trainer:168 validation 66 loss=984.005981 err=984.005981 *
I 2015-05-26 09:33:24 theanets.trainer:168 RmsProp 661 loss=0.077227 err=0.077227
I 2015-05-26 09:33:27 theanets.trainer:168 RmsProp 662 loss=0.074075 err=0.074075
I 2015-05-26 09:33:30 theanets.trainer:168 RmsProp 663 loss=0.071418 err=0.071418
I 2015-05-26 09:33:34 theanets.trainer:168 RmsProp 664 loss=0.072270 err=0.072270
I 2015-05-26 09:33:37 theanets.trainer:168 RmsProp 665 loss=0.074053 err=0.074053
I 2015-05-26 09:33:40 theanets.trainer:168 RmsProp 666 loss=0.071710 err=0.071710
I 2015-05-26 09:33:43 theanets.trainer:168 RmsProp 667 loss=0.072399 err=0.072399
I 2015-05-26 09:33:47 theanets.trainer:168 RmsProp 668 loss=0.073297 err=0.073297
I 2015-05-26 09:33:50 theanets.trainer:168 RmsProp 669 loss=0.071693 err=0.071693
I 2015-05-26 09:33:53 theanets.trainer:168 RmsProp 670 loss=0.073559 err=0.073559
I 2015-05-26 09:33:53 theanets.trainer:168 validation 67 loss=983.882812 err=983.882812 *
I 2015-05-26 09:33:56 theanets.trainer:168 RmsProp 671 loss=0.070984 err=0.070984
I 2015-05-26 09:34:00 theanets.trainer:168 RmsProp 672 loss=0.071973 err=0.071973
I 2015-05-26 09:34:02 theanets.trainer:168 RmsProp 673 loss=0.073849 err=0.073849
I 2015-05-26 09:34:05 theanets.trainer:168 RmsProp 674 loss=0.071979 err=0.071979
I 2015-05-26 09:34:08 theanets.trainer:168 RmsProp 675 loss=0.072387 err=0.072387
I 2015-05-26 09:34:12 theanets.trainer:168 RmsProp 676 loss=0.071736 err=0.071736
I 2015-05-26 09:34:15 theanets.trainer:168 RmsProp 677 loss=0.071636 err=0.071636
I 2015-05-26 09:34:18 theanets.trainer:168 RmsProp 678 loss=0.073211 err=0.073211
I 2015-05-26 09:34:21 theanets.trainer:168 RmsProp 679 loss=0.069550 err=0.069550
I 2015-05-26 09:34:24 theanets.trainer:168 RmsProp 680 loss=0.070886 err=0.070886
I 2015-05-26 09:34:25 theanets.trainer:168 validation 68 loss=985.454407 err=985.454407
I 2015-05-26 09:34:28 theanets.trainer:168 RmsProp 681 loss=0.071743 err=0.071743
I 2015-05-26 09:34:31 theanets.trainer:168 RmsProp 682 loss=0.072302 err=0.072302
I 2015-05-26 09:34:34 theanets.trainer:168 RmsProp 683 loss=0.073210 err=0.073210
I 2015-05-26 09:34:38 theanets.trainer:168 RmsProp 684 loss=0.071672 err=0.071672
I 2015-05-26 09:34:40 theanets.trainer:168 RmsProp 685 loss=0.069932 err=0.069932
I 2015-05-26 09:34:44 theanets.trainer:168 RmsProp 686 loss=0.071737 err=0.071737
I 2015-05-26 09:34:47 theanets.trainer:168 RmsProp 687 loss=0.071371 err=0.071371
I 2015-05-26 09:34:50 theanets.trainer:168 RmsProp 688 loss=0.070448 err=0.070448
I 2015-05-26 09:34:53 theanets.trainer:168 RmsProp 689 loss=0.068414 err=0.068414
I 2015-05-26 09:34:56 theanets.trainer:168 RmsProp 690 loss=0.069223 err=0.069223
I 2015-05-26 09:34:56 theanets.trainer:168 validation 69 loss=984.091431 err=984.091431
I 2015-05-26 09:35:00 theanets.trainer:168 RmsProp 691 loss=0.073157 err=0.073157
I 2015-05-26 09:35:03 theanets.trainer:168 RmsProp 692 loss=0.069689 err=0.069689
I 2015-05-26 09:35:06 theanets.trainer:168 RmsProp 693 loss=0.072825 err=0.072825
I 2015-05-26 09:35:10 theanets.trainer:168 RmsProp 694 loss=0.077783 err=0.077783
I 2015-05-26 09:35:13 theanets.trainer:168 RmsProp 695 loss=0.071119 err=0.071119
I 2015-05-26 09:35:16 theanets.trainer:168 RmsProp 696 loss=0.068111 err=0.068111
I 2015-05-26 09:35:19 theanets.trainer:168 RmsProp 697 loss=0.070797 err=0.070797
I 2015-05-26 09:35:23 theanets.trainer:168 RmsProp 698 loss=0.075506 err=0.075506
I 2015-05-26 09:35:26 theanets.trainer:168 RmsProp 699 loss=0.067722 err=0.067722
I 2015-05-26 09:35:29 theanets.trainer:168 RmsProp 700 loss=0.068737 err=0.068737
I 2015-05-26 09:35:29 theanets.trainer:168 validation 70 loss=984.075378 err=984.075378
I 2015-05-26 09:35:32 theanets.trainer:168 RmsProp 701 loss=0.069639 err=0.069639
I 2015-05-26 09:35:35 theanets.trainer:168 RmsProp 702 loss=0.070270 err=0.070270
I 2015-05-26 09:35:38 theanets.trainer:168 RmsProp 703 loss=0.070719 err=0.070719
I 2015-05-26 09:35:42 theanets.trainer:168 RmsProp 704 loss=0.069603 err=0.069603
I 2015-05-26 09:35:45 theanets.trainer:168 RmsProp 705 loss=0.070980 err=0.070980
I 2015-05-26 09:35:49 theanets.trainer:168 RmsProp 706 loss=0.068241 err=0.068241
I 2015-05-26 09:35:52 theanets.trainer:168 RmsProp 707 loss=0.066929 err=0.066929
I 2015-05-26 09:35:55 theanets.trainer:168 RmsProp 708 loss=0.074364 err=0.074364
I 2015-05-26 09:35:58 theanets.trainer:168 RmsProp 709 loss=0.070434 err=0.070434
I 2015-05-26 09:36:02 theanets.trainer:168 RmsProp 710 loss=0.067935 err=0.067935
I 2015-05-26 09:36:02 theanets.trainer:168 validation 71 loss=983.990234 err=983.990234
I 2015-05-26 09:36:05 theanets.trainer:168 RmsProp 711 loss=0.070515 err=0.070515
I 2015-05-26 09:36:08 theanets.trainer:168 RmsProp 712 loss=0.074051 err=0.074051
I 2015-05-26 09:36:12 theanets.trainer:168 RmsProp 713 loss=0.070266 err=0.070266
I 2015-05-26 09:36:15 theanets.trainer:168 RmsProp 714 loss=0.065302 err=0.065302
I 2015-05-26 09:36:18 theanets.trainer:168 RmsProp 715 loss=0.071030 err=0.071030
I 2015-05-26 09:36:21 theanets.trainer:168 RmsProp 716 loss=0.068517 err=0.068517
I 2015-05-26 09:36:24 theanets.trainer:168 RmsProp 717 loss=0.070945 err=0.070945
I 2015-05-26 09:36:27 theanets.trainer:168 RmsProp 718 loss=0.067758 err=0.067758
I 2015-05-26 09:36:31 theanets.trainer:168 RmsProp 719 loss=0.070376 err=0.070376
I 2015-05-26 09:36:34 theanets.trainer:168 RmsProp 720 loss=0.068808 err=0.068808
I 2015-05-26 09:36:34 theanets.trainer:168 validation 72 loss=983.457153 err=983.457153 *
I 2015-05-26 09:36:37 theanets.trainer:168 RmsProp 721 loss=0.066518 err=0.066518
I 2015-05-26 09:36:40 theanets.trainer:168 RmsProp 722 loss=0.065278 err=0.065278
I 2015-05-26 09:36:43 theanets.trainer:168 RmsProp 723 loss=0.077820 err=0.077820
I 2015-05-26 09:36:47 theanets.trainer:168 RmsProp 724 loss=0.070187 err=0.070187
I 2015-05-26 09:36:50 theanets.trainer:168 RmsProp 725 loss=0.067899 err=0.067899
I 2015-05-26 09:36:54 theanets.trainer:168 RmsProp 726 loss=0.067191 err=0.067191
I 2015-05-26 09:36:57 theanets.trainer:168 RmsProp 727 loss=0.070684 err=0.070684
I 2015-05-26 09:37:00 theanets.trainer:168 RmsProp 728 loss=0.070672 err=0.070672
I 2015-05-26 09:37:03 theanets.trainer:168 RmsProp 729 loss=0.069074 err=0.069074
I 2015-05-26 09:37:07 theanets.trainer:168 RmsProp 730 loss=0.067889 err=0.067889
I 2015-05-26 09:37:07 theanets.trainer:168 validation 73 loss=983.175110 err=983.175110 *
I 2015-05-26 09:37:10 theanets.trainer:168 RmsProp 731 loss=0.066770 err=0.066770
I 2015-05-26 09:37:14 theanets.trainer:168 RmsProp 732 loss=0.071001 err=0.071001
I 2015-05-26 09:37:17 theanets.trainer:168 RmsProp 733 loss=0.065125 err=0.065125
I 2015-05-26 09:37:20 theanets.trainer:168 RmsProp 734 loss=0.072139 err=0.072139
I 2015-05-26 09:37:24 theanets.trainer:168 RmsProp 735 loss=0.069767 err=0.069767
I 2015-05-26 09:37:27 theanets.trainer:168 RmsProp 736 loss=0.066229 err=0.066229
I 2015-05-26 09:37:30 theanets.trainer:168 RmsProp 737 loss=0.073542 err=0.073542
I 2015-05-26 09:37:34 theanets.trainer:168 RmsProp 738 loss=0.070162 err=0.070162
I 2015-05-26 09:37:37 theanets.trainer:168 RmsProp 739 loss=0.065374 err=0.065374
I 2015-05-26 09:37:40 theanets.trainer:168 RmsProp 740 loss=0.065191 err=0.065191
I 2015-05-26 09:37:40 theanets.trainer:168 validation 74 loss=982.962891 err=982.962891 *
I 2015-05-26 09:37:43 theanets.trainer:168 RmsProp 741 loss=0.067836 err=0.067836
I 2015-05-26 09:37:46 theanets.trainer:168 RmsProp 742 loss=0.065934 err=0.065934
I 2015-05-26 09:37:49 theanets.trainer:168 RmsProp 743 loss=0.069117 err=0.069117
I 2015-05-26 09:37:53 theanets.trainer:168 RmsProp 744 loss=0.066236 err=0.066236
I 2015-05-26 09:37:56 theanets.trainer:168 RmsProp 745 loss=0.066746 err=0.066746
I 2015-05-26 09:38:00 theanets.trainer:168 RmsProp 746 loss=0.064508 err=0.064508
I 2015-05-26 09:38:03 theanets.trainer:168 RmsProp 747 loss=0.069314 err=0.069314
I 2015-05-26 09:38:06 theanets.trainer:168 RmsProp 748 loss=0.068669 err=0.068669
I 2015-05-26 09:38:10 theanets.trainer:168 RmsProp 749 loss=0.066785 err=0.066785
I 2015-05-26 09:38:13 theanets.trainer:168 RmsProp 750 loss=0.066889 err=0.066889
I 2015-05-26 09:38:13 theanets.trainer:168 validation 75 loss=983.350281 err=983.350281
I 2015-05-26 09:38:17 theanets.trainer:168 RmsProp 751 loss=0.068601 err=0.068601
I 2015-05-26 09:38:20 theanets.trainer:168 RmsProp 752 loss=0.066657 err=0.066657
I 2015-05-26 09:38:23 theanets.trainer:168 RmsProp 753 loss=0.066592 err=0.066592
I 2015-05-26 09:38:26 theanets.trainer:168 RmsProp 754 loss=0.069224 err=0.069224
I 2015-05-26 09:38:30 theanets.trainer:168 RmsProp 755 loss=0.067182 err=0.067182
I 2015-05-26 09:38:33 theanets.trainer:168 RmsProp 756 loss=0.065965 err=0.065965
I 2015-05-26 09:38:36 theanets.trainer:168 RmsProp 757 loss=0.064145 err=0.064145
I 2015-05-26 09:38:40 theanets.trainer:168 RmsProp 758 loss=0.066076 err=0.066076
I 2015-05-26 09:38:43 theanets.trainer:168 RmsProp 759 loss=0.066857 err=0.066857
I 2015-05-26 09:38:46 theanets.trainer:168 RmsProp 760 loss=0.063760 err=0.063760
I 2015-05-26 09:38:47 theanets.trainer:168 validation 76 loss=982.190063 err=982.190063 *
I 2015-05-26 09:38:50 theanets.trainer:168 RmsProp 761 loss=0.067157 err=0.067157
I 2015-05-26 09:38:53 theanets.trainer:168 RmsProp 762 loss=0.063864 err=0.063864
I 2015-05-26 09:38:56 theanets.trainer:168 RmsProp 763 loss=0.072807 err=0.072807
I 2015-05-26 09:39:00 theanets.trainer:168 RmsProp 764 loss=0.066840 err=0.066840
I 2015-05-26 09:39:03 theanets.trainer:168 RmsProp 765 loss=0.066156 err=0.066156
I 2015-05-26 09:39:06 theanets.trainer:168 RmsProp 766 loss=0.063973 err=0.063973
I 2015-05-26 09:39:10 theanets.trainer:168 RmsProp 767 loss=0.063710 err=0.063710
I 2015-05-26 09:39:13 theanets.trainer:168 RmsProp 768 loss=0.068281 err=0.068281
I 2015-05-26 09:39:16 theanets.trainer:168 RmsProp 769 loss=0.066333 err=0.066333
I 2015-05-26 09:39:19 theanets.trainer:168 RmsProp 770 loss=0.065004 err=0.065004
I 2015-05-26 09:39:19 theanets.trainer:168 validation 77 loss=983.648743 err=983.648743
I 2015-05-26 09:39:23 theanets.trainer:168 RmsProp 771 loss=0.066793 err=0.066793
I 2015-05-26 09:39:26 theanets.trainer:168 RmsProp 772 loss=0.065954 err=0.065954
I 2015-05-26 09:39:29 theanets.trainer:168 RmsProp 773 loss=0.065809 err=0.065809
I 2015-05-26 09:39:32 theanets.trainer:168 RmsProp 774 loss=0.065663 err=0.065663
I 2015-05-26 09:39:35 theanets.trainer:168 RmsProp 775 loss=0.063959 err=0.063959
I 2015-05-26 09:39:39 theanets.trainer:168 RmsProp 776 loss=0.063382 err=0.063382
I 2015-05-26 09:39:42 theanets.trainer:168 RmsProp 777 loss=0.065148 err=0.065148
I 2015-05-26 09:39:45 theanets.trainer:168 RmsProp 778 loss=0.065781 err=0.065781
I 2015-05-26 09:39:49 theanets.trainer:168 RmsProp 779 loss=0.064356 err=0.064356
I 2015-05-26 09:39:52 theanets.trainer:168 RmsProp 780 loss=0.064234 err=0.064234
I 2015-05-26 09:39:52 theanets.trainer:168 validation 78 loss=983.223572 err=983.223572
I 2015-05-26 09:39:55 theanets.trainer:168 RmsProp 781 loss=0.064144 err=0.064144
I 2015-05-26 09:39:58 theanets.trainer:168 RmsProp 782 loss=0.064913 err=0.064913
I 2015-05-26 09:40:02 theanets.trainer:168 RmsProp 783 loss=0.064641 err=0.064641
I 2015-05-26 09:40:05 theanets.trainer:168 RmsProp 784 loss=0.064996 err=0.064996
I 2015-05-26 09:40:08 theanets.trainer:168 RmsProp 785 loss=0.067469 err=0.067469
I 2015-05-26 09:40:11 theanets.trainer:168 RmsProp 786 loss=0.065539 err=0.065539
I 2015-05-26 09:40:15 theanets.trainer:168 RmsProp 787 loss=0.062309 err=0.062309
I 2015-05-26 09:40:18 theanets.trainer:168 RmsProp 788 loss=0.065007 err=0.065007
I 2015-05-26 09:40:22 theanets.trainer:168 RmsProp 789 loss=0.067168 err=0.067168
I 2015-05-26 09:40:25 theanets.trainer:168 RmsProp 790 loss=0.062325 err=0.062325
I 2015-05-26 09:40:25 theanets.trainer:168 validation 79 loss=981.423645 err=981.423645 *
I 2015-05-26 09:40:28 theanets.trainer:168 RmsProp 791 loss=0.066110 err=0.066110
I 2015-05-26 09:40:32 theanets.trainer:168 RmsProp 792 loss=0.064989 err=0.064989
I 2015-05-26 09:40:35 theanets.trainer:168 RmsProp 793 loss=0.062209 err=0.062209
I 2015-05-26 09:40:39 theanets.trainer:168 RmsProp 794 loss=0.063365 err=0.063365
I 2015-05-26 09:40:42 theanets.trainer:168 RmsProp 795 loss=0.066253 err=0.066253
I 2015-05-26 09:40:45 theanets.trainer:168 RmsProp 796 loss=0.063384 err=0.063384
I 2015-05-26 09:40:49 theanets.trainer:168 RmsProp 797 loss=0.064672 err=0.064672
I 2015-05-26 09:40:52 theanets.trainer:168 RmsProp 798 loss=0.064266 err=0.064266
I 2015-05-26 09:40:55 theanets.trainer:168 RmsProp 799 loss=0.062602 err=0.062602
I 2015-05-26 09:40:59 theanets.trainer:168 RmsProp 800 loss=0.062121 err=0.062121
I 2015-05-26 09:40:59 theanets.trainer:168 validation 80 loss=982.125977 err=982.125977
I 2015-05-26 09:41:02 theanets.trainer:168 RmsProp 801 loss=0.062816 err=0.062816
I 2015-05-26 09:41:05 theanets.trainer:168 RmsProp 802 loss=0.064847 err=0.064847
I 2015-05-26 09:41:08 theanets.trainer:168 RmsProp 803 loss=0.061425 err=0.061425
I 2015-05-26 09:41:12 theanets.trainer:168 RmsProp 804 loss=0.064728 err=0.064728
I 2015-05-26 09:41:15 theanets.trainer:168 RmsProp 805 loss=0.066060 err=0.066060
I 2015-05-26 09:41:18 theanets.trainer:168 RmsProp 806 loss=0.061368 err=0.061368
I 2015-05-26 09:41:21 theanets.trainer:168 RmsProp 807 loss=0.064594 err=0.064594
I 2015-05-26 09:41:24 theanets.trainer:168 RmsProp 808 loss=0.062576 err=0.062576
I 2015-05-26 09:41:27 theanets.trainer:168 RmsProp 809 loss=0.062940 err=0.062940
I 2015-05-26 09:41:30 theanets.trainer:168 RmsProp 810 loss=0.064940 err=0.064940
I 2015-05-26 09:41:31 theanets.trainer:168 validation 81 loss=982.103333 err=982.103333
I 2015-05-26 09:41:34 theanets.trainer:168 RmsProp 811 loss=0.060499 err=0.060499
I 2015-05-26 09:41:37 theanets.trainer:168 RmsProp 812 loss=0.063705 err=0.063705
I 2015-05-26 09:41:41 theanets.trainer:168 RmsProp 813 loss=0.061256 err=0.061256
I 2015-05-26 09:41:44 theanets.trainer:168 RmsProp 814 loss=0.063820 err=0.063820
I 2015-05-26 09:41:47 theanets.trainer:168 RmsProp 815 loss=0.064925 err=0.064925
I 2015-05-26 09:41:50 theanets.trainer:168 RmsProp 816 loss=0.064485 err=0.064485
I 2015-05-26 09:41:54 theanets.trainer:168 RmsProp 817 loss=0.063889 err=0.063889
I 2015-05-26 09:41:57 theanets.trainer:168 RmsProp 818 loss=0.060409 err=0.060409
I 2015-05-26 09:42:00 theanets.trainer:168 RmsProp 819 loss=0.062284 err=0.062284
I 2015-05-26 09:42:03 theanets.trainer:168 RmsProp 820 loss=0.062614 err=0.062614
I 2015-05-26 09:42:04 theanets.trainer:168 validation 82 loss=982.409973 err=982.409973
I 2015-05-26 09:42:07 theanets.trainer:168 RmsProp 821 loss=0.063485 err=0.063485
I 2015-05-26 09:42:10 theanets.trainer:168 RmsProp 822 loss=0.062732 err=0.062732
I 2015-05-26 09:42:13 theanets.trainer:168 RmsProp 823 loss=0.063310 err=0.063310
I 2015-05-26 09:42:16 theanets.trainer:168 RmsProp 824 loss=0.061809 err=0.061809
I 2015-05-26 09:42:20 theanets.trainer:168 RmsProp 825 loss=0.061886 err=0.061886
I 2015-05-26 09:42:23 theanets.trainer:168 RmsProp 826 loss=0.065419 err=0.065419
I 2015-05-26 09:42:26 theanets.trainer:168 RmsProp 827 loss=0.063077 err=0.063077
I 2015-05-26 09:42:30 theanets.trainer:168 RmsProp 828 loss=0.061345 err=0.061345
I 2015-05-26 09:42:33 theanets.trainer:168 RmsProp 829 loss=0.062864 err=0.062864
I 2015-05-26 09:42:36 theanets.trainer:168 RmsProp 830 loss=0.064123 err=0.064123
I 2015-05-26 09:42:36 theanets.trainer:168 validation 83 loss=981.585388 err=981.585388
I 2015-05-26 09:42:40 theanets.trainer:168 RmsProp 831 loss=0.061436 err=0.061436
I 2015-05-26 09:42:43 theanets.trainer:168 RmsProp 832 loss=0.061720 err=0.061720
I 2015-05-26 09:42:46 theanets.trainer:168 RmsProp 833 loss=0.061088 err=0.061088
I 2015-05-26 09:42:49 theanets.trainer:168 RmsProp 834 loss=0.061518 err=0.061518
I 2015-05-26 09:42:53 theanets.trainer:168 RmsProp 835 loss=0.062460 err=0.062460
I 2015-05-26 09:42:56 theanets.trainer:168 RmsProp 836 loss=0.061568 err=0.061568
I 2015-05-26 09:42:59 theanets.trainer:168 RmsProp 837 loss=0.063089 err=0.063089
I 2015-05-26 09:43:02 theanets.trainer:168 RmsProp 838 loss=0.061356 err=0.061356
I 2015-05-26 09:43:05 theanets.trainer:168 RmsProp 839 loss=0.060359 err=0.060359
I 2015-05-26 09:43:09 theanets.trainer:168 RmsProp 840 loss=0.061393 err=0.061393
I 2015-05-26 09:43:09 theanets.trainer:168 validation 84 loss=981.964661 err=981.964661
I 2015-05-26 09:43:09 theanets.trainer:252 patience elapsed!
I 2015-05-26 09:43:09 theanets.main:237 models_deep_post_code_sep/95123-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saving model
I 2015-05-26 09:43:09 theanets.graph:477 models_deep_post_code_sep/95123-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saved model parameters
