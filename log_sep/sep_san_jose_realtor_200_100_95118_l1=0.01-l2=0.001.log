I 2015-05-26 22:05:11 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:11 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95118-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:11 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:11 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:11 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:11 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:11 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:11 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:11 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:11 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:11 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:11 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:11 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:28 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:07:59 theano.gof.compilelock:266 Waiting for existing lock by process '29907' (I am process '29928')
I 2015-05-26 22:07:59 theano.gof.compilelock:268 To manually release the lock, delete /localdisk/qyou/.theano/compiledir_Linux-3.19-fc20.x86_64-x86_64-with-fedora-20-Heisenbug-x86_64-2.7.5-64/lock_dir
I 2015-05-26 22:08:04 theano.gof.compilelock:266 Waiting for existing lock by process '29907' (I am process '29928')
I 2015-05-26 22:08:04 theano.gof.compilelock:268 To manually release the lock, delete /localdisk/qyou/.theano/compiledir_Linux-3.19-fc20.x86_64-x86_64-with-fedora-20-Heisenbug-x86_64-2.7.5-64/lock_dir
I 2015-05-26 22:08:24 theanets.trainer:168 validation 0 loss=14394.769531 err=14152.229492 *
I 2015-05-26 22:08:58 theanets.trainer:168 RmsProp 1 loss=13179.189453 err=13085.723633
I 2015-05-26 22:09:34 theanets.trainer:168 RmsProp 2 loss=13197.139648 err=13177.441406
I 2015-05-26 22:10:11 theanets.trainer:168 RmsProp 3 loss=13186.656250 err=13166.870117
I 2015-05-26 22:10:48 theanets.trainer:168 RmsProp 4 loss=12506.530273 err=12466.069336
I 2015-05-26 22:11:25 theanets.trainer:168 RmsProp 5 loss=11016.166016 err=10947.988281
I 2015-05-26 22:12:02 theanets.trainer:168 RmsProp 6 loss=10310.962891 err=10207.431641
I 2015-05-26 22:12:38 theanets.trainer:168 RmsProp 7 loss=9627.569336 err=9502.415039
I 2015-05-26 22:13:15 theanets.trainer:168 RmsProp 8 loss=9142.894531 err=8992.998047
I 2015-05-26 22:13:52 theanets.trainer:168 RmsProp 9 loss=8707.877930 err=8547.948242
I 2015-05-26 22:14:30 theanets.trainer:168 RmsProp 10 loss=8356.202148 err=8191.455566
I 2015-05-26 22:14:31 theanets.trainer:168 validation 1 loss=7881.142090 err=7711.433105 *
I 2015-05-26 22:15:08 theanets.trainer:168 RmsProp 11 loss=8020.431641 err=7845.045410
I 2015-05-26 22:15:46 theanets.trainer:168 RmsProp 12 loss=7814.001465 err=7621.742676
I 2015-05-26 22:16:23 theanets.trainer:168 RmsProp 13 loss=7596.602539 err=7386.444336
I 2015-05-26 22:17:00 theanets.trainer:168 RmsProp 14 loss=7333.576172 err=7107.809570
I 2015-05-26 22:17:38 theanets.trainer:168 RmsProp 15 loss=7136.899414 err=6895.399902
I 2015-05-26 22:18:14 theanets.trainer:168 RmsProp 16 loss=7006.404785 err=6739.626953
I 2015-05-26 22:18:50 theanets.trainer:168 RmsProp 17 loss=6839.158203 err=6553.829590
I 2015-05-26 22:19:27 theanets.trainer:168 RmsProp 18 loss=6635.364258 err=6336.540039
I 2015-05-26 22:20:04 theanets.trainer:168 RmsProp 19 loss=6362.330566 err=6050.083008
I 2015-05-26 22:20:41 theanets.trainer:168 RmsProp 20 loss=6053.290527 err=5720.601562
I 2015-05-26 22:20:42 theanets.trainer:168 validation 2 loss=5218.844238 err=4875.021973 *
I 2015-05-26 22:21:19 theanets.trainer:168 RmsProp 21 loss=5634.338379 err=5282.855957
I 2015-05-26 22:21:56 theanets.trainer:168 RmsProp 22 loss=5244.484375 err=4884.048340
I 2015-05-26 22:22:33 theanets.trainer:168 RmsProp 23 loss=5056.316895 err=4684.155762
I 2015-05-26 22:23:09 theanets.trainer:168 RmsProp 24 loss=4947.164551 err=4567.344238
I 2015-05-26 22:23:46 theanets.trainer:168 RmsProp 25 loss=4778.682129 err=4390.352539
I 2015-05-26 22:24:22 theanets.trainer:168 RmsProp 26 loss=4669.428223 err=4269.657715
I 2015-05-26 22:24:59 theanets.trainer:168 RmsProp 27 loss=4483.287598 err=4072.109863
I 2015-05-26 22:25:36 theanets.trainer:168 RmsProp 28 loss=4469.346680 err=4046.792725
I 2015-05-26 22:26:13 theanets.trainer:168 RmsProp 29 loss=4324.076660 err=3890.214111
I 2015-05-26 22:26:50 theanets.trainer:168 RmsProp 30 loss=4225.601074 err=3779.945312
I 2015-05-26 22:26:51 theanets.trainer:168 validation 3 loss=3959.527588 err=3508.591064 *
I 2015-05-26 22:27:28 theanets.trainer:168 RmsProp 31 loss=4112.765137 err=3657.181396
I 2015-05-26 22:28:04 theanets.trainer:168 RmsProp 32 loss=3988.885254 err=3525.544189
I 2015-05-26 22:28:42 theanets.trainer:168 RmsProp 33 loss=3850.915527 err=3379.538574
I 2015-05-26 22:29:20 theanets.trainer:168 RmsProp 34 loss=3854.897705 err=3373.715576
I 2015-05-26 22:29:58 theanets.trainer:168 RmsProp 35 loss=3801.756104 err=3312.054688
I 2015-05-26 22:30:36 theanets.trainer:168 RmsProp 36 loss=3673.829102 err=3175.395264
I 2015-05-26 22:31:13 theanets.trainer:168 RmsProp 37 loss=3603.443848 err=3096.070557
I 2015-05-26 22:31:50 theanets.trainer:168 RmsProp 38 loss=3630.785645 err=3110.159424
I 2015-05-26 22:32:28 theanets.trainer:168 RmsProp 39 loss=3663.871338 err=3129.629150
I 2015-05-26 22:33:05 theanets.trainer:168 RmsProp 40 loss=3500.827637 err=2960.467773
I 2015-05-26 22:33:05 theanets.trainer:168 validation 4 loss=3694.968018 err=3154.173584 *
I 2015-05-26 22:33:43 theanets.trainer:168 RmsProp 41 loss=3381.261475 err=2839.541992
I 2015-05-26 22:34:19 theanets.trainer:168 RmsProp 42 loss=3347.115723 err=2799.206787
I 2015-05-26 22:34:56 theanets.trainer:168 RmsProp 43 loss=3460.433105 err=2902.097900
I 2015-05-26 22:35:33 theanets.trainer:168 RmsProp 44 loss=3330.641113 err=2765.931396
I 2015-05-26 22:36:10 theanets.trainer:168 RmsProp 45 loss=3281.112061 err=2712.899902
I 2015-05-26 22:36:46 theanets.trainer:168 RmsProp 46 loss=3237.644287 err=2665.169434
I 2015-05-26 22:37:22 theanets.trainer:168 RmsProp 47 loss=3212.093506 err=2631.603027
I 2015-05-26 22:37:59 theanets.trainer:168 RmsProp 48 loss=3126.002930 err=2542.211670
I 2015-05-26 22:38:35 theanets.trainer:168 RmsProp 49 loss=3057.805420 err=2469.156250
I 2015-05-26 22:39:12 theanets.trainer:168 RmsProp 50 loss=2991.323975 err=2397.381104
I 2015-05-26 22:39:13 theanets.trainer:168 validation 5 loss=3490.221924 err=2892.664795 *
I 2015-05-26 22:39:50 theanets.trainer:168 RmsProp 51 loss=2912.184082 err=2312.430908
I 2015-05-26 22:40:26 theanets.trainer:168 RmsProp 52 loss=3002.065918 err=2391.784180
I 2015-05-26 22:41:02 theanets.trainer:168 RmsProp 53 loss=3023.138428 err=2400.666992
I 2015-05-26 22:41:39 theanets.trainer:168 RmsProp 54 loss=2965.174072 err=2337.650146
I 2015-05-26 22:42:16 theanets.trainer:168 RmsProp 55 loss=2853.536865 err=2223.283936
I 2015-05-26 22:42:53 theanets.trainer:168 RmsProp 56 loss=2791.892090 err=2158.712646
I 2015-05-26 22:43:29 theanets.trainer:168 RmsProp 57 loss=2728.234863 err=2090.889893
I 2015-05-26 22:44:06 theanets.trainer:168 RmsProp 58 loss=2647.370605 err=2007.147583
I 2015-05-26 22:44:44 theanets.trainer:168 RmsProp 59 loss=2601.081299 err=1959.201294
I 2015-05-26 22:45:22 theanets.trainer:168 RmsProp 60 loss=2700.467041 err=2050.104248
I 2015-05-26 22:45:23 theanets.trainer:168 validation 6 loss=3672.520752 err=3010.522217
I 2015-05-26 22:45:59 theanets.trainer:168 RmsProp 61 loss=2743.032959 err=2078.651855
I 2015-05-26 22:46:34 theanets.trainer:168 RmsProp 62 loss=2615.328857 err=1949.822266
I 2015-05-26 22:47:10 theanets.trainer:168 RmsProp 63 loss=2524.408691 err=1858.984009
I 2015-05-26 22:47:47 theanets.trainer:168 RmsProp 64 loss=2515.334473 err=1847.783691
I 2015-05-26 22:48:23 theanets.trainer:168 RmsProp 65 loss=2483.055664 err=1812.855713
I 2015-05-26 22:48:59 theanets.trainer:168 RmsProp 66 loss=2487.871094 err=1812.423462
I 2015-05-26 22:49:36 theanets.trainer:168 RmsProp 67 loss=2428.314209 err=1749.362549
I 2015-05-26 22:50:13 theanets.trainer:168 RmsProp 68 loss=2431.805176 err=1748.915527
I 2015-05-26 22:50:50 theanets.trainer:168 RmsProp 69 loss=2417.808105 err=1730.191528
I 2015-05-26 22:51:27 theanets.trainer:168 RmsProp 70 loss=2378.115967 err=1688.353516
I 2015-05-26 22:51:28 theanets.trainer:168 validation 7 loss=3425.862549 err=2734.480713 *
I 2015-05-26 22:52:05 theanets.trainer:168 RmsProp 71 loss=2310.559082 err=1619.654541
I 2015-05-26 22:52:41 theanets.trainer:168 RmsProp 72 loss=2276.341064 err=1584.808105
I 2015-05-26 22:53:18 theanets.trainer:168 RmsProp 73 loss=2254.126465 err=1560.160889
I 2015-05-26 22:53:57 theanets.trainer:168 RmsProp 74 loss=2244.554688 err=1548.738281
I 2015-05-26 22:54:35 theanets.trainer:168 RmsProp 75 loss=2206.740723 err=1509.601929
I 2015-05-26 22:55:12 theanets.trainer:168 RmsProp 76 loss=2190.484375 err=1490.683594
I 2015-05-26 22:55:49 theanets.trainer:168 RmsProp 77 loss=2156.403564 err=1454.311035
I 2015-05-26 22:56:26 theanets.trainer:168 RmsProp 78 loss=2164.922119 err=1460.298706
I 2015-05-26 22:57:04 theanets.trainer:168 RmsProp 79 loss=2125.223145 err=1416.830566
I 2015-05-26 22:57:41 theanets.trainer:168 RmsProp 80 loss=2081.631348 err=1372.636475
I 2015-05-26 22:57:42 theanets.trainer:168 validation 8 loss=3162.914062 err=2453.700928 *
I 2015-05-26 22:58:20 theanets.trainer:168 RmsProp 81 loss=2076.338623 err=1366.401001
I 2015-05-26 22:58:58 theanets.trainer:168 RmsProp 82 loss=2075.591309 err=1362.252563
I 2015-05-26 22:59:35 theanets.trainer:168 RmsProp 83 loss=2075.091309 err=1357.474854
I 2015-05-26 23:00:10 theanets.trainer:168 RmsProp 84 loss=2019.075439 err=1301.754517
I 2015-05-26 23:00:46 theanets.trainer:168 RmsProp 85 loss=2005.758423 err=1288.416138
I 2015-05-26 23:01:23 theanets.trainer:168 RmsProp 86 loss=2048.786377 err=1326.852661
I 2015-05-26 23:02:01 theanets.trainer:168 RmsProp 87 loss=2055.930908 err=1329.879028
I 2015-05-26 23:02:38 theanets.trainer:168 RmsProp 88 loss=2075.664307 err=1344.286621
I 2015-05-26 23:03:16 theanets.trainer:168 RmsProp 89 loss=2024.956909 err=1289.887207
I 2015-05-26 23:03:53 theanets.trainer:168 RmsProp 90 loss=1987.283203 err=1252.435303
I 2015-05-26 23:03:54 theanets.trainer:168 validation 9 loss=3061.459717 err=2327.408691 *
I 2015-05-26 23:04:32 theanets.trainer:168 RmsProp 91 loss=1973.397949 err=1239.093994
I 2015-05-26 23:05:08 theanets.trainer:168 RmsProp 92 loss=1942.341553 err=1206.684204
I 2015-05-26 23:05:45 theanets.trainer:168 RmsProp 93 loss=1912.810425 err=1176.344482
I 2015-05-26 23:06:20 theanets.trainer:168 RmsProp 94 loss=1864.145020 err=1129.350220
I 2015-05-26 23:06:57 theanets.trainer:168 RmsProp 95 loss=1866.352051 err=1131.751099
I 2015-05-26 23:07:35 theanets.trainer:168 RmsProp 96 loss=1920.211792 err=1180.519165
I 2015-05-26 23:08:11 theanets.trainer:168 RmsProp 97 loss=1889.645142 err=1146.188721
I 2015-05-26 23:08:50 theanets.trainer:168 RmsProp 98 loss=1869.172363 err=1125.546753
I 2015-05-26 23:09:27 theanets.trainer:168 RmsProp 99 loss=1886.869141 err=1140.574707
I 2015-05-26 23:10:04 theanets.trainer:168 RmsProp 100 loss=1886.120239 err=1138.064697
I 2015-05-26 23:10:05 theanets.trainer:168 validation 10 loss=3106.137451 err=2356.738037
I 2015-05-26 23:10:41 theanets.trainer:168 RmsProp 101 loss=1866.053101 err=1116.166260
I 2015-05-26 23:11:17 theanets.trainer:168 RmsProp 102 loss=1878.697998 err=1126.904907
I 2015-05-26 23:11:53 theanets.trainer:168 RmsProp 103 loss=1910.103638 err=1154.670166
I 2015-05-26 23:12:29 theanets.trainer:168 RmsProp 104 loss=1842.081299 err=1084.915405
I 2015-05-26 23:13:06 theanets.trainer:168 RmsProp 105 loss=1808.136597 err=1053.298584
I 2015-05-26 23:13:43 theanets.trainer:168 RmsProp 106 loss=1779.651978 err=1025.507690
I 2015-05-26 23:14:20 theanets.trainer:168 RmsProp 107 loss=1773.879028 err=1020.346252
I 2015-05-26 23:14:58 theanets.trainer:168 RmsProp 108 loss=1757.509155 err=1003.201904
I 2015-05-26 23:15:35 theanets.trainer:168 RmsProp 109 loss=1773.920410 err=1017.805054
I 2015-05-26 23:16:12 theanets.trainer:168 RmsProp 110 loss=1760.878174 err=1002.313416
I 2015-05-26 23:16:12 theanets.trainer:168 validation 11 loss=3034.004883 err=2275.277832 *
I 2015-05-26 23:16:50 theanets.trainer:168 RmsProp 111 loss=1780.068848 err=1020.209839
I 2015-05-26 23:17:26 theanets.trainer:168 RmsProp 112 loss=1799.583496 err=1035.480469
I 2015-05-26 23:18:02 theanets.trainer:168 RmsProp 113 loss=1726.830200 err=963.287109
I 2015-05-26 23:18:37 theanets.trainer:168 RmsProp 114 loss=1692.240356 err=932.728638
I 2015-05-26 23:19:13 theanets.trainer:168 RmsProp 115 loss=1662.636230 err=905.151123
I 2015-05-26 23:19:48 theanets.trainer:168 RmsProp 116 loss=1671.757202 err=916.199158
I 2015-05-26 23:20:23 theanets.trainer:168 RmsProp 117 loss=1689.497437 err=933.472900
I 2015-05-26 23:20:59 theanets.trainer:168 RmsProp 118 loss=1718.139282 err=959.149353
I 2015-05-26 23:21:35 theanets.trainer:168 RmsProp 119 loss=1733.406982 err=971.943237
I 2015-05-26 23:22:11 theanets.trainer:168 RmsProp 120 loss=1701.641724 err=938.202515
I 2015-05-26 23:22:11 theanets.trainer:168 validation 12 loss=3104.552734 err=2342.560059
I 2015-05-26 23:22:48 theanets.trainer:168 RmsProp 121 loss=1645.680298 err=884.807190
I 2015-05-26 23:23:25 theanets.trainer:168 RmsProp 122 loss=1634.758911 err=875.869141
I 2015-05-26 23:24:03 theanets.trainer:168 RmsProp 123 loss=1620.611816 err=862.783813
I 2015-05-26 23:24:40 theanets.trainer:168 RmsProp 124 loss=1615.500610 err=857.324890
I 2015-05-26 23:25:16 theanets.trainer:168 RmsProp 125 loss=1612.485474 err=854.456665
I 2015-05-26 23:25:52 theanets.trainer:168 RmsProp 126 loss=1620.959351 err=861.810364
I 2015-05-26 23:26:29 theanets.trainer:168 RmsProp 127 loss=1599.700439 err=842.371643
I 2015-05-26 23:27:05 theanets.trainer:168 RmsProp 128 loss=1577.557007 err=820.912170
I 2015-05-26 23:27:42 theanets.trainer:168 RmsProp 129 loss=1582.192017 err=825.280457
I 2015-05-26 23:28:19 theanets.trainer:168 RmsProp 130 loss=1594.884033 err=836.947693
I 2015-05-26 23:28:20 theanets.trainer:168 validation 13 loss=3069.114502 err=2311.490234
I 2015-05-26 23:28:56 theanets.trainer:168 RmsProp 131 loss=1574.608765 err=817.132385
I 2015-05-26 23:29:33 theanets.trainer:168 RmsProp 132 loss=1591.863037 err=833.639038
I 2015-05-26 23:30:10 theanets.trainer:168 RmsProp 133 loss=1606.231689 err=846.495056
I 2015-05-26 23:30:47 theanets.trainer:168 RmsProp 134 loss=1573.011230 err=812.764038
I 2015-05-26 23:31:24 theanets.trainer:168 RmsProp 135 loss=1528.783813 err=772.590698
I 2015-05-26 23:32:00 theanets.trainer:168 RmsProp 136 loss=1523.278198 err=769.693665
I 2015-05-26 23:32:37 theanets.trainer:168 RmsProp 137 loss=1507.181274 err=755.114197
I 2015-05-26 23:33:13 theanets.trainer:168 RmsProp 138 loss=1520.708618 err=769.002625
I 2015-05-26 23:33:50 theanets.trainer:168 RmsProp 139 loss=1502.018677 err=750.321289
I 2015-05-26 23:34:26 theanets.trainer:168 RmsProp 140 loss=1497.337891 err=747.005066
I 2015-05-26 23:34:27 theanets.trainer:168 validation 14 loss=3050.290039 err=2300.692139
I 2015-05-26 23:35:03 theanets.trainer:168 RmsProp 141 loss=1492.492920 err=743.492310
I 2015-05-26 23:35:39 theanets.trainer:168 RmsProp 142 loss=1493.601807 err=744.523987
I 2015-05-26 23:36:15 theanets.trainer:168 RmsProp 143 loss=1500.570801 err=751.027100
I 2015-05-26 23:36:52 theanets.trainer:168 RmsProp 144 loss=1469.341553 err=721.145508
I 2015-05-26 23:37:28 theanets.trainer:168 RmsProp 145 loss=1492.184937 err=744.115845
I 2015-05-26 23:38:06 theanets.trainer:168 RmsProp 146 loss=1581.532593 err=828.147339
I 2015-05-26 23:38:43 theanets.trainer:168 RmsProp 147 loss=1621.678589 err=861.803711
I 2015-05-26 23:39:20 theanets.trainer:168 RmsProp 148 loss=1539.442505 err=779.181335
I 2015-05-26 23:39:56 theanets.trainer:168 RmsProp 149 loss=1499.683228 err=743.413330
I 2015-05-26 23:40:32 theanets.trainer:168 RmsProp 150 loss=1489.495239 err=735.833557
I 2015-05-26 23:40:33 theanets.trainer:168 validation 15 loss=2912.199951 err=2159.046143 *
I 2015-05-26 23:41:10 theanets.trainer:168 RmsProp 151 loss=1466.120239 err=714.176392
I 2015-05-26 23:41:47 theanets.trainer:168 RmsProp 152 loss=1449.648315 err=700.769348
I 2015-05-26 23:42:24 theanets.trainer:168 RmsProp 153 loss=1488.580322 err=739.709778
I 2015-05-26 23:43:00 theanets.trainer:168 RmsProp 154 loss=1573.288330 err=815.589111
I 2015-05-26 23:43:37 theanets.trainer:168 RmsProp 155 loss=1475.176514 err=719.494568
I 2015-05-26 23:44:13 theanets.trainer:168 RmsProp 156 loss=1468.306519 err=716.704346
I 2015-05-26 23:44:49 theanets.trainer:168 RmsProp 157 loss=1435.879517 err=686.676086
I 2015-05-26 23:45:26 theanets.trainer:168 RmsProp 158 loss=1426.997925 err=680.400574
I 2015-05-26 23:46:03 theanets.trainer:168 RmsProp 159 loss=1436.515137 err=689.932678
I 2015-05-26 23:46:38 theanets.trainer:168 RmsProp 160 loss=1451.166626 err=702.767334
I 2015-05-26 23:46:39 theanets.trainer:168 validation 16 loss=2851.800049 err=2104.240967 *
I 2015-05-26 23:47:14 theanets.trainer:168 RmsProp 161 loss=1421.415405 err=674.686829
I 2015-05-26 23:47:48 theanets.trainer:168 RmsProp 162 loss=1400.485107 err=656.130493
I 2015-05-26 23:48:22 theanets.trainer:168 RmsProp 163 loss=1372.077637 err=630.436707
I 2015-05-26 23:48:57 theanets.trainer:168 RmsProp 164 loss=1373.500366 err=633.591492
I 2015-05-26 23:49:33 theanets.trainer:168 RmsProp 165 loss=1382.347412 err=642.930603
I 2015-05-26 23:50:09 theanets.trainer:168 RmsProp 166 loss=1376.730957 err=638.060303
I 2015-05-26 23:50:44 theanets.trainer:168 RmsProp 167 loss=1359.927612 err=622.962219
I 2015-05-26 23:51:20 theanets.trainer:168 RmsProp 168 loss=1363.424316 err=626.208862
I 2015-05-26 23:51:54 theanets.trainer:168 RmsProp 169 loss=1352.355835 err=616.268494
I 2015-05-26 23:52:29 theanets.trainer:168 RmsProp 170 loss=1333.895630 err=600.308472
I 2015-05-26 23:52:30 theanets.trainer:168 validation 17 loss=2932.657959 err=2200.710205
I 2015-05-26 23:53:05 theanets.trainer:168 RmsProp 171 loss=1304.088257 err=574.170349
I 2015-05-26 23:53:40 theanets.trainer:168 RmsProp 172 loss=1292.652710 err=566.368164
I 2015-05-26 23:54:15 theanets.trainer:168 RmsProp 173 loss=1303.097046 err=578.744934
I 2015-05-26 23:54:51 theanets.trainer:168 RmsProp 174 loss=1293.572388 err=570.290771
I 2015-05-26 23:55:27 theanets.trainer:168 RmsProp 175 loss=1294.384766 err=572.620544
I 2015-05-26 23:56:03 theanets.trainer:168 RmsProp 176 loss=1298.457031 err=577.156433
I 2015-05-26 23:56:38 theanets.trainer:168 RmsProp 177 loss=1292.494385 err=571.660767
I 2015-05-26 23:57:13 theanets.trainer:168 RmsProp 178 loss=1280.960083 err=561.805725
I 2015-05-26 23:57:48 theanets.trainer:168 RmsProp 179 loss=1267.697876 err=550.799866
I 2015-05-26 23:58:23 theanets.trainer:168 RmsProp 180 loss=1282.262939 err=564.861633
I 2015-05-26 23:58:24 theanets.trainer:168 validation 18 loss=2863.689209 err=2145.789795
I 2015-05-26 23:58:59 theanets.trainer:168 RmsProp 181 loss=1284.458618 err=566.747070
I 2015-05-26 23:59:36 theanets.trainer:168 RmsProp 182 loss=1287.581177 err=570.148254
I 2015-05-27 00:00:12 theanets.trainer:168 RmsProp 183 loss=1284.376465 err=566.399292
I 2015-05-27 00:00:48 theanets.trainer:168 RmsProp 184 loss=1281.198486 err=564.218384
I 2015-05-27 00:01:24 theanets.trainer:168 RmsProp 185 loss=1275.064331 err=558.620483
I 2015-05-27 00:02:00 theanets.trainer:168 RmsProp 186 loss=1256.026489 err=541.667114
I 2015-05-27 00:02:35 theanets.trainer:168 RmsProp 187 loss=1252.050293 err=539.164612
I 2015-05-27 00:03:10 theanets.trainer:168 RmsProp 188 loss=1258.559692 err=545.533386
I 2015-05-27 00:03:46 theanets.trainer:168 RmsProp 189 loss=1260.798828 err=547.819397
I 2015-05-27 00:04:22 theanets.trainer:168 RmsProp 190 loss=1249.868286 err=537.557190
I 2015-05-27 00:04:22 theanets.trainer:168 validation 19 loss=2911.331787 err=2199.819580
I 2015-05-27 00:04:57 theanets.trainer:168 RmsProp 191 loss=1245.885864 err=534.873230
I 2015-05-27 00:05:32 theanets.trainer:168 RmsProp 192 loss=1254.914429 err=543.481384
I 2015-05-27 00:06:06 theanets.trainer:168 RmsProp 193 loss=1223.404663 err=514.222717
I 2015-05-27 00:06:43 theanets.trainer:168 RmsProp 194 loss=1216.930542 err=510.099884
I 2015-05-27 00:07:19 theanets.trainer:168 RmsProp 195 loss=1237.906982 err=531.041870
I 2015-05-27 00:07:55 theanets.trainer:168 RmsProp 196 loss=1216.260620 err=510.362976
I 2015-05-27 00:08:30 theanets.trainer:168 RmsProp 197 loss=1207.415283 err=503.415985
I 2015-05-27 00:09:05 theanets.trainer:168 RmsProp 198 loss=1204.880005 err=501.422577
I 2015-05-27 00:09:41 theanets.trainer:168 RmsProp 199 loss=1214.713623 err=512.058960
I 2015-05-27 00:10:17 theanets.trainer:168 RmsProp 200 loss=1237.693359 err=533.377930
I 2015-05-27 00:10:17 theanets.trainer:168 validation 20 loss=2861.896484 err=2156.981201
I 2015-05-27 00:10:52 theanets.trainer:168 RmsProp 201 loss=1217.324951 err=513.755920
I 2015-05-27 00:11:26 theanets.trainer:168 RmsProp 202 loss=1202.287109 err=501.080200
I 2015-05-27 00:11:59 theanets.trainer:168 RmsProp 203 loss=1200.013550 err=500.793945
I 2015-05-27 00:12:32 theanets.trainer:168 RmsProp 204 loss=1217.529053 err=516.841064
I 2015-05-27 00:13:06 theanets.trainer:168 RmsProp 205 loss=1195.183594 err=495.728424
I 2015-05-27 00:13:40 theanets.trainer:168 RmsProp 206 loss=1185.921631 err=488.324341
I 2015-05-27 00:14:13 theanets.trainer:168 RmsProp 207 loss=1190.804199 err=493.316895
I 2015-05-27 00:14:46 theanets.trainer:168 RmsProp 208 loss=1180.792358 err=484.258392
I 2015-05-27 00:15:19 theanets.trainer:168 RmsProp 209 loss=1169.144775 err=473.891968
I 2015-05-27 00:15:52 theanets.trainer:168 RmsProp 210 loss=1159.448120 err=466.660004
I 2015-05-27 00:15:53 theanets.trainer:168 validation 21 loss=2676.059082 err=1984.277222 *
I 2015-05-27 00:16:25 theanets.trainer:168 RmsProp 211 loss=1187.362549 err=494.111298
I 2015-05-27 00:16:58 theanets.trainer:168 RmsProp 212 loss=1211.574951 err=515.829956
I 2015-05-27 00:17:32 theanets.trainer:168 RmsProp 213 loss=1195.849121 err=499.774414
I 2015-05-27 00:18:05 theanets.trainer:168 RmsProp 214 loss=1213.350220 err=516.492310
I 2015-05-27 00:18:38 theanets.trainer:168 RmsProp 215 loss=1184.545288 err=487.369476
I 2015-05-27 00:19:11 theanets.trainer:168 RmsProp 216 loss=1175.947632 err=481.414368
I 2015-05-27 00:19:45 theanets.trainer:168 RmsProp 217 loss=1163.725220 err=469.568390
I 2015-05-27 00:20:18 theanets.trainer:168 RmsProp 218 loss=1166.096924 err=473.977997
I 2015-05-27 00:20:52 theanets.trainer:168 RmsProp 219 loss=1160.799561 err=468.597351
I 2015-05-27 00:21:25 theanets.trainer:168 RmsProp 220 loss=1154.279907 err=463.964996
I 2015-05-27 00:21:26 theanets.trainer:168 validation 22 loss=2701.629150 err=2011.729492
I 2015-05-27 00:22:00 theanets.trainer:168 RmsProp 221 loss=1170.308838 err=479.830231
I 2015-05-27 00:22:33 theanets.trainer:168 RmsProp 222 loss=1165.963989 err=473.904999
I 2015-05-27 00:23:07 theanets.trainer:168 RmsProp 223 loss=1180.347412 err=488.612274
I 2015-05-27 00:23:40 theanets.trainer:168 RmsProp 224 loss=1193.606934 err=500.590118
I 2015-05-27 00:24:14 theanets.trainer:168 RmsProp 225 loss=1232.241455 err=536.100586
I 2015-05-27 00:24:47 theanets.trainer:168 RmsProp 226 loss=1212.064209 err=512.602234
I 2015-05-27 00:25:20 theanets.trainer:168 RmsProp 227 loss=1169.207886 err=472.031860
I 2015-05-27 00:25:53 theanets.trainer:168 RmsProp 228 loss=1149.589966 err=456.395294
I 2015-05-27 00:26:27 theanets.trainer:168 RmsProp 229 loss=1146.936646 err=456.703644
I 2015-05-27 00:26:59 theanets.trainer:168 RmsProp 230 loss=1164.066528 err=472.882843
I 2015-05-27 00:27:00 theanets.trainer:168 validation 23 loss=2855.406250 err=2163.283936
I 2015-05-27 00:27:31 theanets.trainer:168 RmsProp 231 loss=1142.432861 err=451.907806
I 2015-05-27 00:28:03 theanets.trainer:168 RmsProp 232 loss=1140.489380 err=452.046021
I 2015-05-27 00:28:34 theanets.trainer:168 RmsProp 233 loss=1122.474731 err=436.062317
I 2015-05-27 00:29:07 theanets.trainer:168 RmsProp 234 loss=1115.095093 err=431.140961
I 2015-05-27 00:29:40 theanets.trainer:168 RmsProp 235 loss=1121.869995 err=438.472565
I 2015-05-27 00:30:13 theanets.trainer:168 RmsProp 236 loss=1128.281250 err=444.477936
I 2015-05-27 00:30:45 theanets.trainer:168 RmsProp 237 loss=1139.440552 err=455.522522
I 2015-05-27 00:31:18 theanets.trainer:168 RmsProp 238 loss=1128.681030 err=443.946136
I 2015-05-27 00:31:51 theanets.trainer:168 RmsProp 239 loss=1136.231323 err=451.468750
I 2015-05-27 00:32:24 theanets.trainer:168 RmsProp 240 loss=1123.207764 err=439.357056
I 2015-05-27 00:32:25 theanets.trainer:168 validation 24 loss=2869.111328 err=2185.801514
I 2015-05-27 00:32:58 theanets.trainer:168 RmsProp 241 loss=1127.574951 err=444.167694
I 2015-05-27 00:33:31 theanets.trainer:168 RmsProp 242 loss=1118.754150 err=435.584930
I 2015-05-27 00:34:04 theanets.trainer:168 RmsProp 243 loss=1109.602905 err=426.906525
I 2015-05-27 00:34:38 theanets.trainer:168 RmsProp 244 loss=1098.846924 err=417.937561
I 2015-05-27 00:35:11 theanets.trainer:168 RmsProp 245 loss=1088.574463 err=409.537323
I 2015-05-27 00:35:45 theanets.trainer:168 RmsProp 246 loss=1114.670288 err=434.948334
I 2015-05-27 00:36:18 theanets.trainer:168 RmsProp 247 loss=1113.521606 err=432.633698
I 2015-05-27 00:36:50 theanets.trainer:168 RmsProp 248 loss=1083.977661 err=405.125000
I 2015-05-27 00:37:23 theanets.trainer:168 RmsProp 249 loss=1072.547607 err=396.775360
I 2015-05-27 00:37:57 theanets.trainer:168 RmsProp 250 loss=1082.410889 err=407.780945
I 2015-05-27 00:37:58 theanets.trainer:168 validation 25 loss=2811.312256 err=2137.324463
I 2015-05-27 00:38:31 theanets.trainer:168 RmsProp 251 loss=1070.214844 err=397.257751
I 2015-05-27 00:39:04 theanets.trainer:168 RmsProp 252 loss=1060.641357 err=389.685425
I 2015-05-27 00:39:37 theanets.trainer:168 RmsProp 253 loss=1089.627075 err=418.097229
I 2015-05-27 00:40:10 theanets.trainer:168 RmsProp 254 loss=1079.472656 err=407.696259
I 2015-05-27 00:40:43 theanets.trainer:168 RmsProp 255 loss=1054.961304 err=385.367462
I 2015-05-27 00:41:16 theanets.trainer:168 RmsProp 256 loss=1040.917236 err=374.360229
I 2015-05-27 00:41:48 theanets.trainer:168 RmsProp 257 loss=1053.252930 err=388.401703
I 2015-05-27 00:42:21 theanets.trainer:168 RmsProp 258 loss=1057.980347 err=392.988159
I 2015-05-27 00:42:54 theanets.trainer:168 RmsProp 259 loss=1071.476807 err=405.554321
I 2015-05-27 00:43:27 theanets.trainer:168 RmsProp 260 loss=1057.913452 err=392.343475
I 2015-05-27 00:43:28 theanets.trainer:168 validation 26 loss=2853.449219 err=2189.266846
I 2015-05-27 00:43:28 theanets.trainer:252 patience elapsed!
I 2015-05-27 00:43:28 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 00:43:28 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 00:43:28 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 00:43:28 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 00:43:28 theanets.main:89 --batch_size = 1024
I 2015-05-27 00:43:28 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 00:43:28 theanets.main:89 --hidden_l1 = None
I 2015-05-27 00:43:28 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 00:43:28 theanets.main:89 --train_batches = 10
I 2015-05-27 00:43:28 theanets.main:89 --valid_batches = 2
I 2015-05-27 00:43:28 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 00:43:28 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 00:43:28 theanets.trainer:134 compiling evaluation function
I 2015-05-27 00:43:37 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 00:45:18 theanets.trainer:168 validation 0 loss=2442.855957 err=1751.074097 *
I 2015-05-27 00:45:28 theanets.trainer:168 RmsProp 1 loss=1104.284790 err=415.780182
I 2015-05-27 00:45:39 theanets.trainer:168 RmsProp 2 loss=945.686890 err=259.633301
I 2015-05-27 00:45:49 theanets.trainer:168 RmsProp 3 loss=873.933594 err=189.740616
I 2015-05-27 00:45:59 theanets.trainer:168 RmsProp 4 loss=832.398254 err=150.016144
I 2015-05-27 00:46:10 theanets.trainer:168 RmsProp 5 loss=804.209290 err=123.724197
I 2015-05-27 00:46:20 theanets.trainer:168 RmsProp 6 loss=780.998474 err=102.662003
I 2015-05-27 00:46:31 theanets.trainer:168 RmsProp 7 loss=762.445435 err=86.650238
I 2015-05-27 00:46:41 theanets.trainer:168 RmsProp 8 loss=747.109009 err=74.276848
I 2015-05-27 00:46:51 theanets.trainer:168 RmsProp 9 loss=732.450562 err=62.933971
I 2015-05-27 00:47:02 theanets.trainer:168 RmsProp 10 loss=723.863892 err=57.879566
I 2015-05-27 00:47:02 theanets.trainer:168 validation 1 loss=1713.038330 err=1048.969971 *
I 2015-05-27 00:47:13 theanets.trainer:168 RmsProp 11 loss=712.728638 err=50.151382
I 2015-05-27 00:47:24 theanets.trainer:168 RmsProp 12 loss=703.651184 err=44.407997
I 2015-05-27 00:47:34 theanets.trainer:168 RmsProp 13 loss=697.902222 err=42.232544
I 2015-05-27 00:47:45 theanets.trainer:168 RmsProp 14 loss=689.885010 err=37.999916
I 2015-05-27 00:47:55 theanets.trainer:168 RmsProp 15 loss=683.411377 err=35.318233
I 2015-05-27 00:48:06 theanets.trainer:168 RmsProp 16 loss=677.210510 err=32.965069
I 2015-05-27 00:48:17 theanets.trainer:168 RmsProp 17 loss=671.408569 err=31.014612
I 2015-05-27 00:48:27 theanets.trainer:168 RmsProp 18 loss=666.094360 err=29.611370
I 2015-05-27 00:48:38 theanets.trainer:168 RmsProp 19 loss=660.106567 err=27.394903
I 2015-05-27 00:48:49 theanets.trainer:168 RmsProp 20 loss=655.076355 err=26.091171
I 2015-05-27 00:48:49 theanets.trainer:168 validation 2 loss=1624.170654 err=997.236450 *
I 2015-05-27 00:49:00 theanets.trainer:168 RmsProp 21 loss=649.856750 err=24.572300
I 2015-05-27 00:49:11 theanets.trainer:168 RmsProp 22 loss=645.293152 err=23.665188
I 2015-05-27 00:49:22 theanets.trainer:168 RmsProp 23 loss=640.832642 err=22.858456
I 2015-05-27 00:49:32 theanets.trainer:168 RmsProp 24 loss=635.847168 err=21.494080
I 2015-05-27 00:49:43 theanets.trainer:168 RmsProp 25 loss=631.908447 err=21.211632
I 2015-05-27 00:49:53 theanets.trainer:168 RmsProp 26 loss=627.466675 err=20.318872
I 2015-05-27 00:50:04 theanets.trainer:168 RmsProp 27 loss=622.386719 err=18.667646
I 2015-05-27 00:50:14 theanets.trainer:168 RmsProp 28 loss=619.079712 err=18.826853
I 2015-05-27 00:50:25 theanets.trainer:168 RmsProp 29 loss=615.128479 err=18.391184
I 2015-05-27 00:50:35 theanets.trainer:168 RmsProp 30 loss=610.949829 err=17.619114
I 2015-05-27 00:50:36 theanets.trainer:168 validation 3 loss=1576.229614 err=984.700806 *
I 2015-05-27 00:50:47 theanets.trainer:168 RmsProp 31 loss=607.196411 err=17.159508
I 2015-05-27 00:50:57 theanets.trainer:168 RmsProp 32 loss=603.659302 err=16.960779
I 2015-05-27 00:51:08 theanets.trainer:168 RmsProp 33 loss=599.617615 err=16.223040
I 2015-05-27 00:51:18 theanets.trainer:168 RmsProp 34 loss=596.032471 err=15.915616
I 2015-05-27 00:51:29 theanets.trainer:168 RmsProp 35 loss=592.048157 err=15.137219
I 2015-05-27 00:51:39 theanets.trainer:168 RmsProp 36 loss=588.101990 err=14.337443
I 2015-05-27 00:51:49 theanets.trainer:168 RmsProp 37 loss=585.765503 err=15.211426
I 2015-05-27 00:52:00 theanets.trainer:168 RmsProp 38 loss=581.669922 err=14.234022
I 2015-05-27 00:52:10 theanets.trainer:168 RmsProp 39 loss=578.345032 err=13.956863
I 2015-05-27 00:52:21 theanets.trainer:168 RmsProp 40 loss=574.476990 err=13.169586
I 2015-05-27 00:52:21 theanets.trainer:168 validation 4 loss=1533.645752 err=974.064880 *
I 2015-05-27 00:52:31 theanets.trainer:168 RmsProp 41 loss=572.916138 err=14.743521
I 2015-05-27 00:52:42 theanets.trainer:168 RmsProp 42 loss=568.670227 err=13.379849
I 2015-05-27 00:52:53 theanets.trainer:168 RmsProp 43 loss=565.001099 err=12.388549
I 2015-05-27 00:53:03 theanets.trainer:168 RmsProp 44 loss=562.551819 err=12.701139
I 2015-05-27 00:53:13 theanets.trainer:168 RmsProp 45 loss=559.735107 err=12.727587
I 2015-05-27 00:53:24 theanets.trainer:168 RmsProp 46 loss=556.388794 err=12.147931
I 2015-05-27 00:53:34 theanets.trainer:168 RmsProp 47 loss=553.853333 err=12.340990
I 2015-05-27 00:53:44 theanets.trainer:168 RmsProp 48 loss=550.495239 err=11.679449
I 2015-05-27 00:53:55 theanets.trainer:168 RmsProp 49 loss=547.676758 err=11.536870
I 2015-05-27 00:54:05 theanets.trainer:168 RmsProp 50 loss=545.140381 err=11.661492
I 2015-05-27 00:54:06 theanets.trainer:168 validation 5 loss=1496.696289 err=964.670410 *
I 2015-05-27 00:54:16 theanets.trainer:168 RmsProp 51 loss=541.854797 err=11.005168
I 2015-05-27 00:54:27 theanets.trainer:168 RmsProp 52 loss=539.505493 err=11.308224
I 2015-05-27 00:54:37 theanets.trainer:168 RmsProp 53 loss=537.368713 err=11.824727
I 2015-05-27 00:54:48 theanets.trainer:168 RmsProp 54 loss=533.649109 err=10.574356
I 2015-05-27 00:54:58 theanets.trainer:168 RmsProp 55 loss=531.016479 err=10.392138
I 2015-05-27 00:55:08 theanets.trainer:168 RmsProp 56 loss=528.693726 err=10.579198
I 2015-05-27 00:55:19 theanets.trainer:168 RmsProp 57 loss=525.711792 err=10.113634
I 2015-05-27 00:55:29 theanets.trainer:168 RmsProp 58 loss=523.349365 err=10.308037
I 2015-05-27 00:55:40 theanets.trainer:168 RmsProp 59 loss=520.628784 err=10.118561
I 2015-05-27 00:55:50 theanets.trainer:168 RmsProp 60 loss=517.720032 err=9.710005
I 2015-05-27 00:55:51 theanets.trainer:168 validation 6 loss=1468.629639 err=961.984558 *
I 2015-05-27 00:56:01 theanets.trainer:168 RmsProp 61 loss=515.681702 err=10.164380
I 2015-05-27 00:56:12 theanets.trainer:168 RmsProp 62 loss=512.816528 err=9.712868
I 2015-05-27 00:56:22 theanets.trainer:168 RmsProp 63 loss=510.149170 err=9.381899
I 2015-05-27 00:56:33 theanets.trainer:168 RmsProp 64 loss=507.988586 err=9.558802
I 2015-05-27 00:56:43 theanets.trainer:168 RmsProp 65 loss=505.633881 err=9.533460
I 2015-05-27 00:56:53 theanets.trainer:168 RmsProp 66 loss=502.981750 err=9.151861
I 2015-05-27 00:57:04 theanets.trainer:168 RmsProp 67 loss=500.635986 err=9.075392
I 2015-05-27 00:57:14 theanets.trainer:168 RmsProp 68 loss=498.578125 err=9.280695
I 2015-05-27 00:57:25 theanets.trainer:168 RmsProp 69 loss=495.752625 err=8.675097
I 2015-05-27 00:57:35 theanets.trainer:168 RmsProp 70 loss=493.563629 err=8.707163
I 2015-05-27 00:57:35 theanets.trainer:168 validation 7 loss=1444.676514 err=961.053894 *
I 2015-05-27 00:57:46 theanets.trainer:168 RmsProp 71 loss=491.603363 err=8.990953
I 2015-05-27 00:57:56 theanets.trainer:168 RmsProp 72 loss=488.831970 err=8.421586
I 2015-05-27 00:58:06 theanets.trainer:168 RmsProp 73 loss=486.747498 err=8.513440
I 2015-05-27 00:58:17 theanets.trainer:168 RmsProp 74 loss=484.267517 err=8.223728
I 2015-05-27 00:58:27 theanets.trainer:168 RmsProp 75 loss=482.608002 err=8.720255
I 2015-05-27 00:58:37 theanets.trainer:168 RmsProp 76 loss=480.072601 err=8.278687
I 2015-05-27 00:58:47 theanets.trainer:168 RmsProp 77 loss=477.715240 err=7.998122
I 2015-05-27 00:58:58 theanets.trainer:168 RmsProp 78 loss=475.852722 err=8.181925
I 2015-05-27 00:59:08 theanets.trainer:168 RmsProp 79 loss=473.539642 err=7.903879
I 2015-05-27 00:59:19 theanets.trainer:168 RmsProp 80 loss=472.038513 err=8.440894
I 2015-05-27 00:59:19 theanets.trainer:168 validation 8 loss=1410.428467 err=947.936523 *
I 2015-05-27 00:59:30 theanets.trainer:168 RmsProp 81 loss=469.767578 err=8.151707
I 2015-05-27 00:59:40 theanets.trainer:168 RmsProp 82 loss=467.248932 err=7.552929
I 2015-05-27 00:59:51 theanets.trainer:168 RmsProp 83 loss=465.695740 err=7.934864
I 2015-05-27 01:00:01 theanets.trainer:168 RmsProp 84 loss=463.244080 err=7.428989
I 2015-05-27 01:00:11 theanets.trainer:168 RmsProp 85 loss=461.643890 err=7.789203
I 2015-05-27 01:00:20 theanets.trainer:168 RmsProp 86 loss=459.384216 err=7.490556
I 2015-05-27 01:00:30 theanets.trainer:168 RmsProp 87 loss=457.499603 err=7.531909
I 2015-05-27 01:00:40 theanets.trainer:168 RmsProp 88 loss=455.482239 err=7.412637
I 2015-05-27 01:00:50 theanets.trainer:168 RmsProp 89 loss=453.374420 err=7.170602
I 2015-05-27 01:01:00 theanets.trainer:168 RmsProp 90 loss=451.928131 err=7.594223
I 2015-05-27 01:01:00 theanets.trainer:168 validation 9 loss=1384.481689 err=941.163269 *
I 2015-05-27 01:01:10 theanets.trainer:168 RmsProp 91 loss=450.116699 err=7.605733
I 2015-05-27 01:01:20 theanets.trainer:168 RmsProp 92 loss=447.654968 err=6.913635
I 2015-05-27 01:01:30 theanets.trainer:168 RmsProp 93 loss=446.389160 err=7.426364
I 2015-05-27 01:01:40 theanets.trainer:168 RmsProp 94 loss=444.752380 err=7.558762
I 2015-05-27 01:01:50 theanets.trainer:168 RmsProp 95 loss=442.561951 err=7.087729
I 2015-05-27 01:02:00 theanets.trainer:168 RmsProp 96 loss=440.877502 err=7.103899
I 2015-05-27 01:02:10 theanets.trainer:168 RmsProp 97 loss=438.937500 err=6.891580
I 2015-05-27 01:02:21 theanets.trainer:168 RmsProp 98 loss=437.335297 err=7.017334
I 2015-05-27 01:02:31 theanets.trainer:168 RmsProp 99 loss=435.470856 err=6.869708
I 2015-05-27 01:02:41 theanets.trainer:168 RmsProp 100 loss=433.214355 err=6.310098
I 2015-05-27 01:02:42 theanets.trainer:168 validation 10 loss=1376.606201 err=950.650024 *
I 2015-05-27 01:02:52 theanets.trainer:168 RmsProp 101 loss=433.340424 err=8.138472
I 2015-05-27 01:03:03 theanets.trainer:168 RmsProp 102 loss=430.451752 err=6.846039
I 2015-05-27 01:03:13 theanets.trainer:168 RmsProp 103 loss=428.178314 err=6.116539
I 2015-05-27 01:03:23 theanets.trainer:168 RmsProp 104 loss=428.644836 err=8.193694
I 2015-05-27 01:03:33 theanets.trainer:168 RmsProp 105 loss=425.646637 err=6.736897
I 2015-05-27 01:03:44 theanets.trainer:168 RmsProp 106 loss=423.476624 err=6.050105
I 2015-05-27 01:03:54 theanets.trainer:168 RmsProp 107 loss=422.732422 err=6.857992
I 2015-05-27 01:04:05 theanets.trainer:168 RmsProp 108 loss=421.050293 err=6.749146
I 2015-05-27 01:04:15 theanets.trainer:168 RmsProp 109 loss=419.283691 err=6.513881
I 2015-05-27 01:04:26 theanets.trainer:168 RmsProp 110 loss=417.955017 err=6.681971
I 2015-05-27 01:04:27 theanets.trainer:168 validation 11 loss=1358.616577 err=948.162598 *
I 2015-05-27 01:04:38 theanets.trainer:168 RmsProp 111 loss=416.054535 err=6.279004
I 2015-05-27 01:04:48 theanets.trainer:168 RmsProp 112 loss=414.556732 err=6.286423
I 2015-05-27 01:04:59 theanets.trainer:168 RmsProp 113 loss=413.566071 err=6.804227
I 2015-05-27 01:05:10 theanets.trainer:168 RmsProp 114 loss=411.625397 err=6.348189
I 2015-05-27 01:05:21 theanets.trainer:168 RmsProp 115 loss=409.880768 err=6.053257
I 2015-05-27 01:05:32 theanets.trainer:168 RmsProp 116 loss=408.955597 err=6.595312
I 2015-05-27 01:05:42 theanets.trainer:168 RmsProp 117 loss=407.385468 err=6.469523
I 2015-05-27 01:05:52 theanets.trainer:168 RmsProp 118 loss=405.957214 err=6.457024
I 2015-05-27 01:06:03 theanets.trainer:168 RmsProp 119 loss=404.029846 err=5.913174
I 2015-05-27 01:06:13 theanets.trainer:168 RmsProp 120 loss=402.859222 err=6.126715
I 2015-05-27 01:06:14 theanets.trainer:168 validation 12 loss=1353.808960 err=957.849060 *
I 2015-05-27 01:06:24 theanets.trainer:168 RmsProp 121 loss=401.688416 err=6.359083
I 2015-05-27 01:06:35 theanets.trainer:168 RmsProp 122 loss=399.853180 err=5.917150
I 2015-05-27 01:06:45 theanets.trainer:168 RmsProp 123 loss=398.473694 err=5.944557
I 2015-05-27 01:06:55 theanets.trainer:168 RmsProp 124 loss=397.338684 err=6.206464
I 2015-05-27 01:07:06 theanets.trainer:168 RmsProp 125 loss=395.594330 err=5.827041
I 2015-05-27 01:07:17 theanets.trainer:168 RmsProp 126 loss=394.300873 err=5.885174
I 2015-05-27 01:07:27 theanets.trainer:168 RmsProp 127 loss=392.988251 err=5.928752
I 2015-05-27 01:07:38 theanets.trainer:168 RmsProp 128 loss=391.602417 err=5.910723
I 2015-05-27 01:07:48 theanets.trainer:168 RmsProp 129 loss=390.307373 err=5.963828
I 2015-05-27 01:07:59 theanets.trainer:168 RmsProp 130 loss=388.781158 err=5.761210
I 2015-05-27 01:07:59 theanets.trainer:168 validation 13 loss=1320.695923 err=938.388489 *
I 2015-05-27 01:08:10 theanets.trainer:168 RmsProp 131 loss=387.648163 err=5.914409
I 2015-05-27 01:08:21 theanets.trainer:168 RmsProp 132 loss=385.910797 err=5.464357
I 2015-05-27 01:08:31 theanets.trainer:168 RmsProp 133 loss=384.997864 err=5.852969
I 2015-05-27 01:08:42 theanets.trainer:168 RmsProp 134 loss=383.624359 err=5.776655
I 2015-05-27 01:08:53 theanets.trainer:168 RmsProp 135 loss=382.086578 err=5.517222
I 2015-05-27 01:09:04 theanets.trainer:168 RmsProp 136 loss=381.150787 err=5.845244
I 2015-05-27 01:09:15 theanets.trainer:168 RmsProp 137 loss=379.342224 err=5.289823
I 2015-05-27 01:09:25 theanets.trainer:168 RmsProp 138 loss=378.574738 err=5.764698
I 2015-05-27 01:09:36 theanets.trainer:168 RmsProp 139 loss=377.151764 err=5.576457
I 2015-05-27 01:09:47 theanets.trainer:168 RmsProp 140 loss=376.238251 err=5.882151
I 2015-05-27 01:09:48 theanets.trainer:168 validation 14 loss=1317.301392 err=947.604919 *
I 2015-05-27 01:09:59 theanets.trainer:168 RmsProp 141 loss=374.678955 err=5.519740
I 2015-05-27 01:10:09 theanets.trainer:168 RmsProp 142 loss=373.463104 err=5.489726
I 2015-05-27 01:10:20 theanets.trainer:168 RmsProp 143 loss=372.471252 err=5.691691
I 2015-05-27 01:10:31 theanets.trainer:168 RmsProp 144 loss=371.008118 err=5.401505
I 2015-05-27 01:10:41 theanets.trainer:168 RmsProp 145 loss=369.777832 err=5.334687
I 2015-05-27 01:10:52 theanets.trainer:168 RmsProp 146 loss=368.935760 err=5.668509
I 2015-05-27 01:11:03 theanets.trainer:168 RmsProp 147 loss=367.380127 err=5.279899
I 2015-05-27 01:11:14 theanets.trainer:168 RmsProp 148 loss=366.254089 err=5.296203
I 2015-05-27 01:11:25 theanets.trainer:168 RmsProp 149 loss=365.371155 err=5.551095
I 2015-05-27 01:11:36 theanets.trainer:168 RmsProp 150 loss=364.125793 err=5.419836
I 2015-05-27 01:11:37 theanets.trainer:168 validation 15 loss=1297.526855 err=939.423523 *
I 2015-05-27 01:11:48 theanets.trainer:168 RmsProp 151 loss=363.124542 err=5.525003
I 2015-05-27 01:11:58 theanets.trainer:168 RmsProp 152 loss=361.603394 err=5.101505
I 2015-05-27 01:12:09 theanets.trainer:168 RmsProp 153 loss=360.942688 err=5.534187
I 2015-05-27 01:12:20 theanets.trainer:168 RmsProp 154 loss=359.578918 err=5.244142
I 2015-05-27 01:12:31 theanets.trainer:168 RmsProp 155 loss=358.400269 err=5.133552
I 2015-05-27 01:12:42 theanets.trainer:168 RmsProp 156 loss=357.542419 err=5.351149
I 2015-05-27 01:12:52 theanets.trainer:168 RmsProp 157 loss=356.372009 err=5.266902
I 2015-05-27 01:13:03 theanets.trainer:168 RmsProp 158 loss=355.162415 err=5.124801
I 2015-05-27 01:13:14 theanets.trainer:168 RmsProp 159 loss=354.095062 err=5.114929
I 2015-05-27 01:13:25 theanets.trainer:168 RmsProp 160 loss=353.724945 err=5.818498
I 2015-05-27 01:13:25 theanets.trainer:168 validation 16 loss=1297.638794 err=950.316589
I 2015-05-27 01:13:36 theanets.trainer:168 RmsProp 161 loss=352.497986 err=5.623068
I 2015-05-27 01:13:46 theanets.trainer:168 RmsProp 162 loss=350.905579 err=4.998512
I 2015-05-27 01:13:57 theanets.trainer:168 RmsProp 163 loss=350.011017 err=5.065524
I 2015-05-27 01:14:07 theanets.trainer:168 RmsProp 164 loss=348.952332 err=5.005860
I 2015-05-27 01:14:18 theanets.trainer:168 RmsProp 165 loss=348.217834 err=5.289130
I 2015-05-27 01:14:28 theanets.trainer:168 RmsProp 166 loss=346.939789 err=5.020117
I 2015-05-27 01:14:38 theanets.trainer:168 RmsProp 167 loss=346.058533 err=5.133267
I 2015-05-27 01:14:49 theanets.trainer:168 RmsProp 168 loss=344.995850 err=5.042117
I 2015-05-27 01:14:59 theanets.trainer:168 RmsProp 169 loss=343.982391 err=5.005933
I 2015-05-27 01:15:10 theanets.trainer:168 RmsProp 170 loss=342.964050 err=4.971026
I 2015-05-27 01:15:10 theanets.trainer:168 validation 17 loss=1272.467896 err=935.012512 *
I 2015-05-27 01:15:21 theanets.trainer:168 RmsProp 171 loss=342.018860 err=5.008637
I 2015-05-27 01:15:31 theanets.trainer:168 RmsProp 172 loss=340.624542 err=4.592214
I 2015-05-27 01:15:41 theanets.trainer:168 RmsProp 173 loss=341.143250 err=6.107303
I 2015-05-27 01:15:51 theanets.trainer:168 RmsProp 174 loss=339.827576 err=5.728797
I 2015-05-27 01:16:02 theanets.trainer:168 RmsProp 175 loss=337.984192 err=4.738225
I 2015-05-27 01:16:13 theanets.trainer:168 RmsProp 176 loss=337.070160 err=4.677258
I 2015-05-27 01:16:23 theanets.trainer:168 RmsProp 177 loss=336.544037 err=5.042218
I 2015-05-27 01:16:34 theanets.trainer:168 RmsProp 178 loss=335.525269 err=4.944910
I 2015-05-27 01:16:45 theanets.trainer:168 RmsProp 179 loss=334.630951 err=4.964089
I 2015-05-27 01:16:56 theanets.trainer:168 RmsProp 180 loss=333.370667 err=4.610347
I 2015-05-27 01:16:56 theanets.trainer:168 validation 18 loss=1282.128052 err=953.866638
I 2015-05-27 01:17:07 theanets.trainer:168 RmsProp 181 loss=332.913574 err=5.077010
I 2015-05-27 01:17:17 theanets.trainer:168 RmsProp 182 loss=332.071838 err=5.154178
I 2015-05-27 01:17:27 theanets.trainer:168 RmsProp 183 loss=330.713776 err=4.678856
I 2015-05-27 01:17:38 theanets.trainer:168 RmsProp 184 loss=329.973846 err=4.800317
I 2015-05-27 01:17:49 theanets.trainer:168 RmsProp 185 loss=329.026062 err=4.725038
I 2015-05-27 01:18:00 theanets.trainer:168 RmsProp 186 loss=328.224548 err=4.805087
I 2015-05-27 01:18:11 theanets.trainer:168 RmsProp 187 loss=327.250427 err=4.713357
I 2015-05-27 01:18:22 theanets.trainer:168 RmsProp 188 loss=326.470764 err=4.814787
I 2015-05-27 01:18:32 theanets.trainer:168 RmsProp 189 loss=325.413818 err=4.629008
I 2015-05-27 01:18:43 theanets.trainer:168 RmsProp 190 loss=324.708588 err=4.790534
I 2015-05-27 01:18:44 theanets.trainer:168 validation 19 loss=1254.032227 err=934.598633 *
I 2015-05-27 01:18:55 theanets.trainer:168 RmsProp 191 loss=323.567627 err=4.509992
I 2015-05-27 01:19:05 theanets.trainer:168 RmsProp 192 loss=323.285828 err=5.078269
I 2015-05-27 01:19:16 theanets.trainer:168 RmsProp 193 loss=322.216614 err=4.846479
I 2015-05-27 01:19:27 theanets.trainer:168 RmsProp 194 loss=321.297119 err=4.740044
I 2015-05-27 01:19:38 theanets.trainer:168 RmsProp 195 loss=320.275208 err=4.537534
I 2015-05-27 01:19:49 theanets.trainer:168 RmsProp 196 loss=319.900787 err=4.980646
I 2015-05-27 01:20:00 theanets.trainer:168 RmsProp 197 loss=318.609375 err=4.506582
I 2015-05-27 01:20:11 theanets.trainer:168 RmsProp 198 loss=317.857117 err=4.567740
I 2015-05-27 01:20:22 theanets.trainer:168 RmsProp 199 loss=317.097198 err=4.624516
I 2015-05-27 01:20:33 theanets.trainer:168 RmsProp 200 loss=316.146729 err=4.493020
I 2015-05-27 01:20:33 theanets.trainer:168 validation 20 loss=1247.886108 err=936.677246 *
I 2015-05-27 01:20:44 theanets.trainer:168 RmsProp 201 loss=315.734009 err=4.879378
I 2015-05-27 01:20:55 theanets.trainer:168 RmsProp 202 loss=314.763763 err=4.695036
I 2015-05-27 01:21:05 theanets.trainer:168 RmsProp 203 loss=313.179565 err=3.893659
I 2015-05-27 01:21:15 theanets.trainer:168 RmsProp 204 loss=315.010315 err=6.543063
I 2015-05-27 01:21:26 theanets.trainer:168 RmsProp 205 loss=313.962585 err=6.256100
I 2015-05-27 01:21:36 theanets.trainer:168 RmsProp 206 loss=311.493164 err=4.459165
I 2015-05-27 01:21:47 theanets.trainer:168 RmsProp 207 loss=310.424286 err=4.053862
I 2015-05-27 01:21:57 theanets.trainer:168 RmsProp 208 loss=310.662476 err=5.007190
I 2015-05-27 01:22:08 theanets.trainer:168 RmsProp 209 loss=309.324799 err=4.414930
I 2015-05-27 01:22:19 theanets.trainer:168 RmsProp 210 loss=308.280182 err=4.115876
I 2015-05-27 01:22:19 theanets.trainer:168 validation 21 loss=1252.083984 err=948.334290
I 2015-05-27 01:22:30 theanets.trainer:168 RmsProp 211 loss=308.297638 err=4.889285
I 2015-05-27 01:22:41 theanets.trainer:168 RmsProp 212 loss=306.970154 err=4.319002
I 2015-05-27 01:22:52 theanets.trainer:168 RmsProp 213 loss=306.419617 err=4.514977
I 2015-05-27 01:23:02 theanets.trainer:168 RmsProp 214 loss=305.267303 err=4.114467
I 2015-05-27 01:23:13 theanets.trainer:168 RmsProp 215 loss=305.515778 err=5.106473
I 2015-05-27 01:23:24 theanets.trainer:168 RmsProp 216 loss=303.933594 err=4.260035
I 2015-05-27 01:23:35 theanets.trainer:168 RmsProp 217 loss=303.541931 err=4.585566
I 2015-05-27 01:23:46 theanets.trainer:168 RmsProp 218 loss=302.642303 err=4.400134
I 2015-05-27 01:23:56 theanets.trainer:168 RmsProp 219 loss=301.861572 err=4.343117
I 2015-05-27 01:24:07 theanets.trainer:168 RmsProp 220 loss=301.165344 err=4.374133
I 2015-05-27 01:24:07 theanets.trainer:168 validation 22 loss=1231.262207 err=934.870728 *
I 2015-05-27 01:24:18 theanets.trainer:168 RmsProp 221 loss=300.484863 err=4.417938
I 2015-05-27 01:24:29 theanets.trainer:168 RmsProp 222 loss=299.820496 err=4.462622
I 2015-05-27 01:24:40 theanets.trainer:168 RmsProp 223 loss=298.863708 err=4.213383
I 2015-05-27 01:24:51 theanets.trainer:168 RmsProp 224 loss=298.335785 err=4.395169
I 2015-05-27 01:25:02 theanets.trainer:168 RmsProp 225 loss=297.861938 err=4.625980
I 2015-05-27 01:25:12 theanets.trainer:168 RmsProp 226 loss=296.783325 err=4.243273
I 2015-05-27 01:25:23 theanets.trainer:168 RmsProp 227 loss=296.214600 err=4.369684
I 2015-05-27 01:25:33 theanets.trainer:168 RmsProp 228 loss=295.432587 err=4.288763
I 2015-05-27 01:25:44 theanets.trainer:168 RmsProp 229 loss=294.587311 err=4.136802
I 2015-05-27 01:25:55 theanets.trainer:168 RmsProp 230 loss=294.179749 err=4.423881
I 2015-05-27 01:25:55 theanets.trainer:168 validation 23 loss=1240.178223 err=950.803528
I 2015-05-27 01:26:06 theanets.trainer:168 RmsProp 231 loss=293.717224 err=4.642077
I 2015-05-27 01:26:17 theanets.trainer:168 RmsProp 232 loss=292.531982 err=4.117705
I 2015-05-27 01:26:27 theanets.trainer:168 RmsProp 233 loss=292.060913 err=4.306364
I 2015-05-27 01:26:38 theanets.trainer:168 RmsProp 234 loss=291.408905 err=4.320232
I 2015-05-27 01:26:48 theanets.trainer:168 RmsProp 235 loss=290.810974 err=4.384179
I 2015-05-27 01:26:59 theanets.trainer:168 RmsProp 236 loss=290.093811 err=4.314563
I 2015-05-27 01:27:09 theanets.trainer:168 RmsProp 237 loss=288.922394 err=3.797299
I 2015-05-27 01:27:20 theanets.trainer:168 RmsProp 238 loss=288.934448 err=4.470536
I 2015-05-27 01:27:30 theanets.trainer:168 RmsProp 239 loss=288.312286 err=4.501538
I 2015-05-27 01:27:40 theanets.trainer:168 RmsProp 240 loss=287.239105 err=4.072031
I 2015-05-27 01:27:41 theanets.trainer:168 validation 24 loss=1219.003052 err=936.177734 *
I 2015-05-27 01:27:51 theanets.trainer:168 RmsProp 241 loss=286.602264 err=4.078046
I 2015-05-27 01:28:02 theanets.trainer:168 RmsProp 242 loss=286.165527 err=4.291668
I 2015-05-27 01:28:12 theanets.trainer:168 RmsProp 243 loss=285.291290 err=4.058909
I 2015-05-27 01:28:22 theanets.trainer:168 RmsProp 244 loss=284.895569 err=4.301263
I 2015-05-27 01:28:33 theanets.trainer:168 RmsProp 245 loss=284.177307 err=4.218194
I 2015-05-27 01:28:43 theanets.trainer:168 RmsProp 246 loss=283.270599 err=3.937853
I 2015-05-27 01:28:54 theanets.trainer:168 RmsProp 247 loss=283.092499 err=4.381352
I 2015-05-27 01:29:04 theanets.trainer:168 RmsProp 248 loss=282.052551 err=3.958553
I 2015-05-27 01:29:15 theanets.trainer:168 RmsProp 249 loss=281.659973 err=4.183486
I 2015-05-27 01:29:25 theanets.trainer:168 RmsProp 250 loss=280.967682 err=4.110474
I 2015-05-27 01:29:25 theanets.trainer:168 validation 25 loss=1227.208984 err=950.697693
I 2015-05-27 01:29:36 theanets.trainer:168 RmsProp 251 loss=280.531799 err=4.288879
I 2015-05-27 01:29:46 theanets.trainer:168 RmsProp 252 loss=279.724304 err=4.085481
I 2015-05-27 01:29:57 theanets.trainer:168 RmsProp 253 loss=279.202332 err=4.163314
I 2015-05-27 01:30:08 theanets.trainer:168 RmsProp 254 loss=278.568817 err=4.131208
I 2015-05-27 01:30:18 theanets.trainer:168 RmsProp 255 loss=277.942627 err=4.104499
I 2015-05-27 01:30:28 theanets.trainer:168 RmsProp 256 loss=277.403442 err=4.157921
I 2015-05-27 01:30:39 theanets.trainer:168 RmsProp 257 loss=276.732239 err=4.072367
I 2015-05-27 01:30:50 theanets.trainer:168 RmsProp 258 loss=276.380219 err=4.291856
I 2015-05-27 01:31:00 theanets.trainer:168 RmsProp 259 loss=275.492004 err=3.976157
I 2015-05-27 01:31:11 theanets.trainer:168 RmsProp 260 loss=274.908997 err=3.973973
I 2015-05-27 01:31:11 theanets.trainer:168 validation 26 loss=1205.363037 err=934.750183 *
I 2015-05-27 01:31:22 theanets.trainer:168 RmsProp 261 loss=274.404358 err=4.052948
I 2015-05-27 01:31:33 theanets.trainer:168 RmsProp 262 loss=273.643799 err=3.870245
I 2015-05-27 01:31:43 theanets.trainer:168 RmsProp 263 loss=273.232513 err=4.038558
I 2015-05-27 01:31:53 theanets.trainer:168 RmsProp 264 loss=272.655670 err=4.045469
I 2015-05-27 01:32:04 theanets.trainer:168 RmsProp 265 loss=272.156525 err=4.130376
I 2015-05-27 01:32:14 theanets.trainer:168 RmsProp 266 loss=271.366882 err=3.916332
I 2015-05-27 01:32:25 theanets.trainer:168 RmsProp 267 loss=270.989166 err=4.111217
I 2015-05-27 01:32:35 theanets.trainer:168 RmsProp 268 loss=270.265991 err=3.951885
I 2015-05-27 01:32:46 theanets.trainer:168 RmsProp 269 loss=269.689911 err=3.930778
I 2015-05-27 01:32:56 theanets.trainer:168 RmsProp 270 loss=269.084961 err=3.876922
I 2015-05-27 01:32:57 theanets.trainer:168 validation 27 loss=1201.523315 err=936.612915 *
I 2015-05-27 01:33:07 theanets.trainer:168 RmsProp 271 loss=268.780670 err=4.125161
I 2015-05-27 01:33:17 theanets.trainer:168 RmsProp 272 loss=268.265137 err=4.160637
I 2015-05-27 01:33:28 theanets.trainer:168 RmsProp 273 loss=267.370300 err=3.807464
I 2015-05-27 01:33:38 theanets.trainer:168 RmsProp 274 loss=266.851746 err=3.831190
I 2015-05-27 01:33:49 theanets.trainer:168 RmsProp 275 loss=266.728699 err=4.252465
I 2015-05-27 01:34:00 theanets.trainer:168 RmsProp 276 loss=265.806702 err=3.862355
I 2015-05-27 01:34:10 theanets.trainer:168 RmsProp 277 loss=265.320984 err=3.906871
I 2015-05-27 01:34:21 theanets.trainer:168 RmsProp 278 loss=264.863251 err=3.986802
I 2015-05-27 01:34:32 theanets.trainer:168 RmsProp 279 loss=264.161438 err=3.824658
I 2015-05-27 01:34:42 theanets.trainer:168 RmsProp 280 loss=263.648743 err=3.840005
I 2015-05-27 01:34:43 theanets.trainer:168 validation 28 loss=1200.277466 err=940.762146 *
I 2015-05-27 01:34:53 theanets.trainer:168 RmsProp 281 loss=263.390045 err=4.110529
I 2015-05-27 01:35:03 theanets.trainer:168 RmsProp 282 loss=262.646912 err=3.896786
I 2015-05-27 01:35:14 theanets.trainer:168 RmsProp 283 loss=262.155823 err=3.925928
I 2015-05-27 01:35:24 theanets.trainer:168 RmsProp 284 loss=261.470612 err=3.754770
I 2015-05-27 01:35:35 theanets.trainer:168 RmsProp 285 loss=261.323364 err=4.118171
I 2015-05-27 01:35:45 theanets.trainer:168 RmsProp 286 loss=260.830261 err=4.128781
I 2015-05-27 01:35:55 theanets.trainer:168 RmsProp 287 loss=260.050873 err=3.848996
I 2015-05-27 01:36:06 theanets.trainer:168 RmsProp 288 loss=259.535919 err=3.832536
I 2015-05-27 01:36:16 theanets.trainer:168 RmsProp 289 loss=259.124847 err=3.923718
I 2015-05-27 01:36:27 theanets.trainer:168 RmsProp 290 loss=258.481812 err=3.782809
I 2015-05-27 01:36:27 theanets.trainer:168 validation 29 loss=1194.022217 err=939.605896 *
I 2015-05-27 01:36:38 theanets.trainer:168 RmsProp 291 loss=257.969757 err=3.774033
I 2015-05-27 01:36:49 theanets.trainer:168 RmsProp 292 loss=257.494781 err=3.796190
I 2015-05-27 01:37:00 theanets.trainer:168 RmsProp 293 loss=257.319641 err=4.122333
I 2015-05-27 01:37:11 theanets.trainer:168 RmsProp 294 loss=256.442902 err=3.738920
I 2015-05-27 01:37:21 theanets.trainer:168 RmsProp 295 loss=255.928635 err=3.714638
I 2015-05-27 01:37:32 theanets.trainer:168 RmsProp 296 loss=255.585236 err=3.865480
I 2015-05-27 01:37:43 theanets.trainer:168 RmsProp 297 loss=255.066940 err=3.840781
I 2015-05-27 01:37:53 theanets.trainer:168 RmsProp 298 loss=254.956223 err=4.216393
I 2015-05-27 01:38:04 theanets.trainer:168 RmsProp 299 loss=253.967331 err=3.699605
I 2015-05-27 01:38:15 theanets.trainer:168 RmsProp 300 loss=253.595306 err=3.793261
I 2015-05-27 01:38:16 theanets.trainer:168 validation 30 loss=1206.220093 err=956.669556
I 2015-05-27 01:38:27 theanets.trainer:168 RmsProp 301 loss=253.035599 err=3.702869
I 2015-05-27 01:38:37 theanets.trainer:168 RmsProp 302 loss=252.629547 err=3.770398
I 2015-05-27 01:38:48 theanets.trainer:168 RmsProp 303 loss=252.545746 err=4.160055
I 2015-05-27 01:38:59 theanets.trainer:168 RmsProp 304 loss=251.498001 err=3.584624
I 2015-05-27 01:39:09 theanets.trainer:168 RmsProp 305 loss=251.348587 err=3.902558
I 2015-05-27 01:39:19 theanets.trainer:168 RmsProp 306 loss=250.726288 err=3.750786
I 2015-05-27 01:39:30 theanets.trainer:168 RmsProp 307 loss=250.203903 err=3.694982
I 2015-05-27 01:39:40 theanets.trainer:168 RmsProp 308 loss=249.887054 err=3.841625
I 2015-05-27 01:39:51 theanets.trainer:168 RmsProp 309 loss=249.199066 err=3.618133
I 2015-05-27 01:40:02 theanets.trainer:168 RmsProp 310 loss=248.916901 err=3.799535
I 2015-05-27 01:40:02 theanets.trainer:168 validation 31 loss=1183.625610 err=938.763855 *
I 2015-05-27 01:40:13 theanets.trainer:168 RmsProp 311 loss=248.313843 err=3.655375
I 2015-05-27 01:40:24 theanets.trainer:168 RmsProp 312 loss=247.978958 err=3.784018
I 2015-05-27 01:40:35 theanets.trainer:168 RmsProp 313 loss=247.488251 err=3.752818
I 2015-05-27 01:40:46 theanets.trainer:168 RmsProp 314 loss=247.005341 err=3.726954
I 2015-05-27 01:40:57 theanets.trainer:168 RmsProp 315 loss=246.482452 err=3.658496
I 2015-05-27 01:41:07 theanets.trainer:168 RmsProp 316 loss=245.989944 err=3.619096
I 2015-05-27 01:41:18 theanets.trainer:168 RmsProp 317 loss=245.431610 err=3.518508
I 2015-05-27 01:41:28 theanets.trainer:168 RmsProp 318 loss=245.320755 err=3.859056
I 2015-05-27 01:41:38 theanets.trainer:168 RmsProp 319 loss=244.685638 err=3.666444
I 2015-05-27 01:41:49 theanets.trainer:168 RmsProp 320 loss=244.221954 err=3.641863
I 2015-05-27 01:41:49 theanets.trainer:168 validation 32 loss=1198.543579 err=958.195740
I 2015-05-27 01:41:59 theanets.trainer:168 RmsProp 321 loss=244.033859 err=3.889401
I 2015-05-27 01:42:09 theanets.trainer:168 RmsProp 322 loss=243.359985 err=3.655200
I 2015-05-27 01:42:20 theanets.trainer:168 RmsProp 323 loss=242.927200 err=3.656882
I 2015-05-27 01:42:29 theanets.trainer:168 RmsProp 324 loss=242.464432 err=3.629485
I 2015-05-27 01:42:39 theanets.trainer:168 RmsProp 325 loss=242.109283 err=3.701265
I 2015-05-27 01:42:49 theanets.trainer:168 RmsProp 326 loss=241.561646 err=3.583377
I 2015-05-27 01:42:59 theanets.trainer:168 RmsProp 327 loss=241.325439 err=3.772465
I 2015-05-27 01:43:09 theanets.trainer:168 RmsProp 328 loss=240.793579 err=3.662891
I 2015-05-27 01:43:19 theanets.trainer:168 RmsProp 329 loss=240.320999 err=3.608789
I 2015-05-27 01:43:30 theanets.trainer:168 RmsProp 330 loss=239.777863 err=3.489156
I 2015-05-27 01:43:30 theanets.trainer:168 validation 33 loss=1169.509888 err=933.449341 *
I 2015-05-27 01:43:40 theanets.trainer:168 RmsProp 331 loss=239.683273 err=3.816234
I 2015-05-27 01:43:50 theanets.trainer:168 RmsProp 332 loss=239.151489 err=3.706125
I 2015-05-27 01:44:00 theanets.trainer:168 RmsProp 333 loss=238.664017 err=3.636015
I 2015-05-27 01:44:10 theanets.trainer:168 RmsProp 334 loss=238.324432 err=3.704340
I 2015-05-27 01:44:20 theanets.trainer:168 RmsProp 335 loss=237.706451 err=3.498233
I 2015-05-27 01:44:30 theanets.trainer:168 RmsProp 336 loss=237.511154 err=3.712952
I 2015-05-27 01:44:41 theanets.trainer:168 RmsProp 337 loss=236.904373 err=3.515270
I 2015-05-27 01:44:51 theanets.trainer:168 RmsProp 338 loss=236.754440 err=3.777016
I 2015-05-27 01:45:01 theanets.trainer:168 RmsProp 339 loss=236.144989 err=3.573509
I 2015-05-27 01:45:11 theanets.trainer:168 RmsProp 340 loss=235.927444 err=3.755004
I 2015-05-27 01:45:12 theanets.trainer:168 validation 34 loss=1187.067383 err=955.109375
I 2015-05-27 01:45:22 theanets.trainer:168 RmsProp 341 loss=235.502167 err=3.723262
I 2015-05-27 01:45:32 theanets.trainer:168 RmsProp 342 loss=234.887421 err=3.498601
I 2015-05-27 01:45:43 theanets.trainer:168 RmsProp 343 loss=234.524216 err=3.523682
I 2015-05-27 01:45:54 theanets.trainer:168 RmsProp 344 loss=234.213623 err=3.608435
I 2015-05-27 01:46:04 theanets.trainer:168 RmsProp 345 loss=233.740021 err=3.530722
I 2015-05-27 01:46:14 theanets.trainer:168 RmsProp 346 loss=233.217606 err=3.405148
I 2015-05-27 01:46:24 theanets.trainer:168 RmsProp 347 loss=233.308304 err=3.888980
I 2015-05-27 01:46:34 theanets.trainer:168 RmsProp 348 loss=232.678131 err=3.644039
I 2015-05-27 01:46:44 theanets.trainer:168 RmsProp 349 loss=231.831818 err=3.184823
I 2015-05-27 01:46:54 theanets.trainer:168 RmsProp 350 loss=232.306442 err=4.048976
I 2015-05-27 01:46:54 theanets.trainer:168 validation 35 loss=1164.487549 err=936.442993 *
I 2015-05-27 01:47:04 theanets.trainer:168 RmsProp 351 loss=231.253021 err=3.387150
I 2015-05-27 01:47:14 theanets.trainer:168 RmsProp 352 loss=231.088287 err=3.608502
I 2015-05-27 01:47:24 theanets.trainer:168 RmsProp 353 loss=230.440521 err=3.348373
I 2015-05-27 01:47:35 theanets.trainer:168 RmsProp 354 loss=230.599777 err=3.885841
I 2015-05-27 01:47:45 theanets.trainer:168 RmsProp 355 loss=229.732101 err=3.397447
I 2015-05-27 01:47:55 theanets.trainer:168 RmsProp 356 loss=229.203659 err=3.253164
I 2015-05-27 01:48:05 theanets.trainer:168 RmsProp 357 loss=229.130173 err=3.564019
I 2015-05-27 01:48:15 theanets.trainer:168 RmsProp 358 loss=228.642380 err=3.458916
I 2015-05-27 01:48:25 theanets.trainer:168 RmsProp 359 loss=228.662033 err=3.854307
I 2015-05-27 01:48:36 theanets.trainer:168 RmsProp 360 loss=228.008392 err=3.569017
I 2015-05-27 01:48:36 theanets.trainer:168 validation 36 loss=1168.568726 err=944.328918
I 2015-05-27 01:48:46 theanets.trainer:168 RmsProp 361 loss=227.576096 err=3.504655
I 2015-05-27 01:48:56 theanets.trainer:168 RmsProp 362 loss=227.136383 err=3.433729
I 2015-05-27 01:49:07 theanets.trainer:168 RmsProp 363 loss=226.703537 err=3.369692
I 2015-05-27 01:49:17 theanets.trainer:168 RmsProp 364 loss=226.789062 err=3.813412
I 2015-05-27 01:49:27 theanets.trainer:168 RmsProp 365 loss=226.159515 err=3.543651
I 2015-05-27 01:49:37 theanets.trainer:168 RmsProp 366 loss=225.802948 err=3.545758
I 2015-05-27 01:49:46 theanets.trainer:168 RmsProp 367 loss=225.437225 err=3.537555
I 2015-05-27 01:49:56 theanets.trainer:168 RmsProp 368 loss=225.090820 err=3.547105
I 2015-05-27 01:50:06 theanets.trainer:168 RmsProp 369 loss=224.675629 err=3.483874
I 2015-05-27 01:50:16 theanets.trainer:168 RmsProp 370 loss=224.406738 err=3.570552
I 2015-05-27 01:50:17 theanets.trainer:168 validation 37 loss=1157.409180 err=936.765137 *
I 2015-05-27 01:50:27 theanets.trainer:168 RmsProp 371 loss=223.877777 err=3.395141
I 2015-05-27 01:50:36 theanets.trainer:168 RmsProp 372 loss=223.530365 err=3.402360
I 2015-05-27 01:50:46 theanets.trainer:168 RmsProp 373 loss=223.248703 err=3.473298
I 2015-05-27 01:50:56 theanets.trainer:168 RmsProp 374 loss=222.891159 err=3.467433
I 2015-05-27 01:51:06 theanets.trainer:168 RmsProp 375 loss=222.382477 err=3.312531
I 2015-05-27 01:51:16 theanets.trainer:168 RmsProp 376 loss=222.530670 err=3.807574
I 2015-05-27 01:51:27 theanets.trainer:168 RmsProp 377 loss=221.800751 err=3.429883
I 2015-05-27 01:51:37 theanets.trainer:168 RmsProp 378 loss=221.589935 err=3.566983
I 2015-05-27 01:51:47 theanets.trainer:168 RmsProp 379 loss=221.285324 err=3.603632
I 2015-05-27 01:51:57 theanets.trainer:168 RmsProp 380 loss=220.813446 err=3.464859
I 2015-05-27 01:51:58 theanets.trainer:168 validation 38 loss=1158.303711 err=941.141052
I 2015-05-27 01:52:08 theanets.trainer:168 RmsProp 381 loss=220.457321 err=3.447156
I 2015-05-27 01:52:18 theanets.trainer:168 RmsProp 382 loss=220.015503 err=3.345973
I 2015-05-27 01:52:28 theanets.trainer:168 RmsProp 383 loss=219.832733 err=3.502467
I 2015-05-27 01:52:38 theanets.trainer:168 RmsProp 384 loss=219.468842 err=3.474223
I 2015-05-27 01:52:48 theanets.trainer:168 RmsProp 385 loss=219.203766 err=3.543966
I 2015-05-27 01:52:58 theanets.trainer:168 RmsProp 386 loss=218.773605 err=3.446307
I 2015-05-27 01:53:08 theanets.trainer:168 RmsProp 387 loss=218.340973 err=3.350157
I 2015-05-27 01:53:18 theanets.trainer:168 RmsProp 388 loss=218.132782 err=3.476135
I 2015-05-27 01:53:28 theanets.trainer:168 RmsProp 389 loss=217.830566 err=3.511978
I 2015-05-27 01:53:38 theanets.trainer:168 RmsProp 390 loss=217.261261 err=3.274920
I 2015-05-27 01:53:38 theanets.trainer:168 validation 39 loss=1157.138428 err=943.335938 *
I 2015-05-27 01:53:48 theanets.trainer:168 RmsProp 391 loss=216.965179 err=3.311144
I 2015-05-27 01:53:58 theanets.trainer:168 RmsProp 392 loss=216.778320 err=3.453676
I 2015-05-27 01:54:09 theanets.trainer:168 RmsProp 393 loss=216.218719 err=3.226351
I 2015-05-27 01:54:18 theanets.trainer:168 RmsProp 394 loss=216.085739 err=3.422315
I 2015-05-27 01:54:28 theanets.trainer:168 RmsProp 395 loss=215.786713 err=3.444255
I 2015-05-27 01:54:38 theanets.trainer:168 RmsProp 396 loss=215.223480 err=3.209451
I 2015-05-27 01:54:48 theanets.trainer:168 RmsProp 397 loss=215.213043 err=3.527092
I 2015-05-27 01:54:58 theanets.trainer:168 RmsProp 398 loss=214.585892 err=3.228969
I 2015-05-27 01:55:08 theanets.trainer:168 RmsProp 399 loss=214.655319 err=3.619895
I 2015-05-27 01:55:18 theanets.trainer:168 RmsProp 400 loss=214.166290 err=3.452432
I 2015-05-27 01:55:19 theanets.trainer:168 validation 40 loss=1150.976196 err=940.444763 *
I 2015-05-27 01:55:29 theanets.trainer:168 RmsProp 401 loss=213.551361 err=3.159482
I 2015-05-27 01:55:39 theanets.trainer:168 RmsProp 402 loss=213.748001 err=3.671216
I 2015-05-27 01:55:49 theanets.trainer:168 RmsProp 403 loss=212.995895 err=3.232879
I 2015-05-27 01:55:59 theanets.trainer:168 RmsProp 404 loss=213.035202 err=3.577893
I 2015-05-27 01:56:09 theanets.trainer:168 RmsProp 405 loss=212.547684 err=3.402989
I 2015-05-27 01:56:19 theanets.trainer:168 RmsProp 406 loss=212.172485 err=3.337027
I 2015-05-27 01:56:29 theanets.trainer:168 RmsProp 407 loss=211.938385 err=3.410186
I 2015-05-27 01:56:39 theanets.trainer:168 RmsProp 408 loss=211.786621 err=3.561947
I 2015-05-27 01:56:49 theanets.trainer:168 RmsProp 409 loss=211.119751 err=3.204124
I 2015-05-27 01:56:59 theanets.trainer:168 RmsProp 410 loss=210.906403 err=3.300496
I 2015-05-27 01:56:59 theanets.trainer:168 validation 41 loss=1148.137329 err=940.701843 *
I 2015-05-27 01:57:10 theanets.trainer:168 RmsProp 411 loss=210.688324 err=3.391760
I 2015-05-27 01:57:20 theanets.trainer:168 RmsProp 412 loss=210.371185 err=3.380284
I 2015-05-27 01:57:30 theanets.trainer:168 RmsProp 413 loss=209.932983 err=3.246774
I 2015-05-27 01:57:41 theanets.trainer:168 RmsProp 414 loss=209.848022 err=3.464049
I 2015-05-27 01:57:51 theanets.trainer:168 RmsProp 415 loss=209.454391 err=3.370218
I 2015-05-27 01:58:01 theanets.trainer:168 RmsProp 416 loss=209.060944 err=3.277637
I 2015-05-27 01:58:10 theanets.trainer:168 RmsProp 417 loss=208.901825 err=3.422069
I 2015-05-27 01:58:20 theanets.trainer:168 RmsProp 418 loss=208.570724 err=3.383731
I 2015-05-27 01:58:31 theanets.trainer:168 RmsProp 419 loss=208.344391 err=3.451534
I 2015-05-27 01:58:41 theanets.trainer:168 RmsProp 420 loss=207.787308 err=3.186698
I 2015-05-27 01:58:41 theanets.trainer:168 validation 42 loss=1155.862793 err=951.421509
I 2015-05-27 01:58:52 theanets.trainer:168 RmsProp 421 loss=207.549759 err=3.245283
I 2015-05-27 01:59:02 theanets.trainer:168 RmsProp 422 loss=207.398712 err=3.392378
I 2015-05-27 01:59:12 theanets.trainer:168 RmsProp 423 loss=206.952927 err=3.241863
I 2015-05-27 01:59:22 theanets.trainer:168 RmsProp 424 loss=206.759979 err=3.340370
I 2015-05-27 01:59:32 theanets.trainer:168 RmsProp 425 loss=206.358322 err=3.235463
I 2015-05-27 01:59:42 theanets.trainer:168 RmsProp 426 loss=206.172806 err=3.343547
I 2015-05-27 01:59:52 theanets.trainer:168 RmsProp 427 loss=205.771896 err=3.228975
I 2015-05-27 02:00:03 theanets.trainer:168 RmsProp 428 loss=205.415039 err=3.164922
I 2015-05-27 02:00:12 theanets.trainer:168 RmsProp 429 loss=205.261719 err=3.305933
I 2015-05-27 02:00:22 theanets.trainer:168 RmsProp 430 loss=204.824860 err=3.161000
I 2015-05-27 02:00:23 theanets.trainer:168 validation 43 loss=1160.520996 err=959.027344
I 2015-05-27 02:00:33 theanets.trainer:168 RmsProp 431 loss=204.692520 err=3.322045
I 2015-05-27 02:00:44 theanets.trainer:168 RmsProp 432 loss=204.325104 err=3.247222
I 2015-05-27 02:00:55 theanets.trainer:168 RmsProp 433 loss=204.099487 err=3.312611
I 2015-05-27 02:01:05 theanets.trainer:168 RmsProp 434 loss=203.700439 err=3.203109
I 2015-05-27 02:01:15 theanets.trainer:168 RmsProp 435 loss=203.431458 err=3.220521
I 2015-05-27 02:01:25 theanets.trainer:168 RmsProp 436 loss=203.217804 err=3.292221
I 2015-05-27 02:01:35 theanets.trainer:168 RmsProp 437 loss=202.973068 err=3.327542
I 2015-05-27 02:01:45 theanets.trainer:168 RmsProp 438 loss=202.764526 err=3.395894
I 2015-05-27 02:01:55 theanets.trainer:168 RmsProp 439 loss=202.480713 err=3.383975
I 2015-05-27 02:02:05 theanets.trainer:168 RmsProp 440 loss=201.979889 err=3.157279
I 2015-05-27 02:02:05 theanets.trainer:168 validation 44 loss=1144.230347 err=945.561462 *
I 2015-05-27 02:02:16 theanets.trainer:168 RmsProp 441 loss=201.719543 err=3.171728
I 2015-05-27 02:02:26 theanets.trainer:168 RmsProp 442 loss=201.660934 err=3.389504
I 2015-05-27 02:02:36 theanets.trainer:168 RmsProp 443 loss=201.134293 err=3.138018
I 2015-05-27 02:02:47 theanets.trainer:168 RmsProp 444 loss=200.893646 err=3.171472
I 2015-05-27 02:02:57 theanets.trainer:168 RmsProp 445 loss=200.740021 err=3.292868
I 2015-05-27 02:03:07 theanets.trainer:168 RmsProp 446 loss=200.421204 err=3.243749
I 2015-05-27 02:03:17 theanets.trainer:168 RmsProp 447 loss=200.270523 err=3.363649
I 2015-05-27 02:03:27 theanets.trainer:168 RmsProp 448 loss=199.625504 err=2.988551
I 2015-05-27 02:03:37 theanets.trainer:168 RmsProp 449 loss=200.091095 err=3.714030
I 2015-05-27 02:03:48 theanets.trainer:168 RmsProp 450 loss=199.014008 err=2.906426
I 2015-05-27 02:03:48 theanets.trainer:168 validation 45 loss=1147.934570 err=951.972473
I 2015-05-27 02:03:59 theanets.trainer:168 RmsProp 451 loss=199.260330 err=3.419982
I 2015-05-27 02:04:09 theanets.trainer:168 RmsProp 452 loss=198.816742 err=3.240301
I 2015-05-27 02:04:19 theanets.trainer:168 RmsProp 453 loss=198.324203 err=3.015774
I 2015-05-27 02:04:30 theanets.trainer:168 RmsProp 454 loss=198.325577 err=3.288120
I 2015-05-27 02:04:40 theanets.trainer:168 RmsProp 455 loss=197.790268 err=3.022300
I 2015-05-27 02:04:50 theanets.trainer:168 RmsProp 456 loss=197.929474 err=3.428378
I 2015-05-27 02:05:01 theanets.trainer:168 RmsProp 457 loss=197.337860 err=3.106158
I 2015-05-27 02:05:11 theanets.trainer:168 RmsProp 458 loss=197.217560 err=3.251688
I 2015-05-27 02:05:21 theanets.trainer:168 RmsProp 459 loss=196.878815 err=3.175214
I 2015-05-27 02:05:32 theanets.trainer:168 RmsProp 460 loss=197.019135 err=3.566283
I 2015-05-27 02:05:32 theanets.trainer:168 validation 46 loss=1154.542969 err=961.231079
I 2015-05-27 02:05:43 theanets.trainer:168 RmsProp 461 loss=196.292816 err=3.095716
I 2015-05-27 02:05:53 theanets.trainer:168 RmsProp 462 loss=195.942413 err=3.003431
I 2015-05-27 02:06:03 theanets.trainer:168 RmsProp 463 loss=196.144257 err=3.461928
I 2015-05-27 02:06:14 theanets.trainer:168 RmsProp 464 loss=195.616730 err=3.193203
I 2015-05-27 02:06:24 theanets.trainer:168 RmsProp 465 loss=195.407425 err=3.238054
I 2015-05-27 02:06:34 theanets.trainer:168 RmsProp 466 loss=195.011871 err=3.095379
I 2015-05-27 02:06:45 theanets.trainer:168 RmsProp 467 loss=194.826691 err=3.159512
I 2015-05-27 02:06:55 theanets.trainer:168 RmsProp 468 loss=194.667297 err=3.253247
I 2015-05-27 02:07:05 theanets.trainer:168 RmsProp 469 loss=194.144974 err=2.991780
I 2015-05-27 02:07:16 theanets.trainer:168 RmsProp 470 loss=193.920197 err=3.021532
I 2015-05-27 02:07:16 theanets.trainer:168 validation 47 loss=1134.763672 err=944.004333 *
I 2015-05-27 02:07:27 theanets.trainer:168 RmsProp 471 loss=193.810638 err=3.169131
I 2015-05-27 02:07:37 theanets.trainer:168 RmsProp 472 loss=193.796783 err=3.406658
I 2015-05-27 02:07:48 theanets.trainer:168 RmsProp 473 loss=193.289230 err=3.154671
I 2015-05-27 02:07:58 theanets.trainer:168 RmsProp 474 loss=193.046326 err=3.160294
I 2015-05-27 02:08:08 theanets.trainer:168 RmsProp 475 loss=192.576462 err=2.939589
I 2015-05-27 02:08:18 theanets.trainer:168 RmsProp 476 loss=192.655655 err=3.264518
I 2015-05-27 02:08:29 theanets.trainer:168 RmsProp 477 loss=192.341919 err=3.198843
I 2015-05-27 02:08:39 theanets.trainer:168 RmsProp 478 loss=191.741196 err=2.847222
I 2015-05-27 02:08:49 theanets.trainer:168 RmsProp 479 loss=192.036057 err=3.385744
I 2015-05-27 02:08:59 theanets.trainer:168 RmsProp 480 loss=191.584732 err=3.182785
I 2015-05-27 02:09:00 theanets.trainer:168 validation 48 loss=1157.261963 err=968.987793
I 2015-05-27 02:09:10 theanets.trainer:168 RmsProp 481 loss=191.036896 err=2.878472
I 2015-05-27 02:09:21 theanets.trainer:168 RmsProp 482 loss=191.068268 err=3.157159
I 2015-05-27 02:09:31 theanets.trainer:168 RmsProp 483 loss=191.333710 err=3.666029
I 2015-05-27 02:09:41 theanets.trainer:168 RmsProp 484 loss=190.335358 err=2.911251
I 2015-05-27 02:09:51 theanets.trainer:168 RmsProp 485 loss=190.655487 err=3.465615
I 2015-05-27 02:10:01 theanets.trainer:168 RmsProp 486 loss=189.825928 err=2.873428
I 2015-05-27 02:10:10 theanets.trainer:168 RmsProp 487 loss=190.065002 err=3.350706
I 2015-05-27 02:10:20 theanets.trainer:168 RmsProp 488 loss=189.577454 err=3.097882
I 2015-05-27 02:10:30 theanets.trainer:168 RmsProp 489 loss=189.453949 err=3.206790
I 2015-05-27 02:10:40 theanets.trainer:168 RmsProp 490 loss=189.145737 err=3.129325
I 2015-05-27 02:10:41 theanets.trainer:168 validation 49 loss=1159.457642 err=973.563110
I 2015-05-27 02:10:51 theanets.trainer:168 RmsProp 491 loss=188.771729 err=2.991148
I 2015-05-27 02:11:01 theanets.trainer:168 RmsProp 492 loss=188.668015 err=3.123915
I 2015-05-27 02:11:11 theanets.trainer:168 RmsProp 493 loss=188.672043 err=3.360784
I 2015-05-27 02:11:22 theanets.trainer:168 RmsProp 494 loss=188.077118 err=3.003847
I 2015-05-27 02:11:32 theanets.trainer:168 RmsProp 495 loss=187.888107 err=3.048282
I 2015-05-27 02:11:42 theanets.trainer:168 RmsProp 496 loss=187.722839 err=3.113812
I 2015-05-27 02:11:52 theanets.trainer:168 RmsProp 497 loss=187.530762 err=3.156043
I 2015-05-27 02:12:02 theanets.trainer:168 RmsProp 498 loss=187.183441 err=3.044836
I 2015-05-27 02:12:13 theanets.trainer:168 RmsProp 499 loss=186.920532 err=3.016647
I 2015-05-27 02:12:23 theanets.trainer:168 RmsProp 500 loss=186.814835 err=3.141933
I 2015-05-27 02:12:23 theanets.trainer:168 validation 50 loss=1152.590820 err=969.042786
I 2015-05-27 02:12:34 theanets.trainer:168 RmsProp 501 loss=186.498169 err=3.054093
I 2015-05-27 02:12:44 theanets.trainer:168 RmsProp 502 loss=186.247208 err=3.031185
I 2015-05-27 02:12:54 theanets.trainer:168 RmsProp 503 loss=185.939011 err=2.951189
I 2015-05-27 02:13:05 theanets.trainer:168 RmsProp 504 loss=186.030060 err=3.268911
I 2015-05-27 02:13:15 theanets.trainer:168 RmsProp 505 loss=185.628983 err=3.091021
I 2015-05-27 02:13:25 theanets.trainer:168 RmsProp 506 loss=185.439194 err=3.126314
I 2015-05-27 02:13:36 theanets.trainer:168 RmsProp 507 loss=185.062393 err=2.974855
I 2015-05-27 02:13:46 theanets.trainer:168 RmsProp 508 loss=185.400543 err=3.535139
I 2015-05-27 02:13:56 theanets.trainer:168 RmsProp 509 loss=184.569183 err=2.923930
I 2015-05-27 02:14:06 theanets.trainer:168 RmsProp 510 loss=184.524399 err=3.097592
I 2015-05-27 02:14:07 theanets.trainer:168 validation 51 loss=1156.468262 err=975.153931
I 2015-05-27 02:14:17 theanets.trainer:168 RmsProp 511 loss=184.410248 err=3.202696
I 2015-05-27 02:14:27 theanets.trainer:168 RmsProp 512 loss=183.977142 err=2.986986
I 2015-05-27 02:14:37 theanets.trainer:168 RmsProp 513 loss=183.735168 err=2.963627
I 2015-05-27 02:14:47 theanets.trainer:168 RmsProp 514 loss=183.677002 err=3.124699
I 2015-05-27 02:14:57 theanets.trainer:168 RmsProp 515 loss=183.434235 err=3.107443
I 2015-05-27 02:15:08 theanets.trainer:168 RmsProp 516 loss=183.112396 err=3.003888
I 2015-05-27 02:15:18 theanets.trainer:168 RmsProp 517 loss=183.018158 err=3.123332
I 2015-05-27 02:15:28 theanets.trainer:168 RmsProp 518 loss=182.975861 err=3.297422
I 2015-05-27 02:15:38 theanets.trainer:168 RmsProp 519 loss=182.542755 err=3.079854
I 2015-05-27 02:15:48 theanets.trainer:168 RmsProp 520 loss=182.133194 err=2.882848
I 2015-05-27 02:15:49 theanets.trainer:168 validation 52 loss=1156.719849 err=977.579285
I 2015-05-27 02:15:49 theanets.trainer:252 patience elapsed!
I 2015-05-27 02:15:49 theanets.main:237 models_deep_post_code_sep/95118-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 02:15:49 theanets.graph:477 models_deep_post_code_sep/95118-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
