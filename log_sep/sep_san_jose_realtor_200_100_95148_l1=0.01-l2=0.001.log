I 2015-05-26 22:05:12 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:12 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95148-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:12 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:12 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:12 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:12 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:12 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:12 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:12 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:12 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:12 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:12 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:12 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:29 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:04 theano.gof.compilelock:266 Waiting for existing lock by process '29907' (I am process '30032')
I 2015-05-26 22:08:04 theano.gof.compilelock:268 To manually release the lock, delete /localdisk/qyou/.theano/compiledir_Linux-3.19-fc20.x86_64-x86_64-with-fedora-20-Heisenbug-x86_64-2.7.5-64/lock_dir
I 2015-05-26 22:08:25 theanets.trainer:168 validation 0 loss=14415.117188 err=14172.596680 *
I 2015-05-26 22:09:01 theanets.trainer:168 RmsProp 1 loss=13281.011719 err=13186.338867
I 2015-05-26 22:09:40 theanets.trainer:168 RmsProp 2 loss=13258.747070 err=13237.363281
I 2015-05-26 22:10:19 theanets.trainer:168 RmsProp 3 loss=12945.536133 err=12908.576172
I 2015-05-26 22:10:57 theanets.trainer:168 RmsProp 4 loss=11880.506836 err=11823.911133
I 2015-05-26 22:11:35 theanets.trainer:168 RmsProp 5 loss=10503.612305 err=10418.456055
I 2015-05-26 22:12:13 theanets.trainer:168 RmsProp 6 loss=9899.920898 err=9781.783203
I 2015-05-26 22:12:51 theanets.trainer:168 RmsProp 7 loss=9435.747070 err=9306.638672
I 2015-05-26 22:13:29 theanets.trainer:168 RmsProp 8 loss=8844.194336 err=8698.951172
I 2015-05-26 22:14:09 theanets.trainer:168 RmsProp 9 loss=8339.056641 err=8173.403809
I 2015-05-26 22:14:47 theanets.trainer:168 RmsProp 10 loss=7907.686523 err=7723.325195
I 2015-05-26 22:14:48 theanets.trainer:168 validation 1 loss=6875.893066 err=6681.378906 *
I 2015-05-26 22:15:27 theanets.trainer:168 RmsProp 11 loss=7535.507812 err=7333.876465
I 2015-05-26 22:16:06 theanets.trainer:168 RmsProp 12 loss=7237.567871 err=7019.286133
I 2015-05-26 22:16:45 theanets.trainer:168 RmsProp 13 loss=7034.784668 err=6799.535645
I 2015-05-26 22:17:24 theanets.trainer:168 RmsProp 14 loss=6714.274414 err=6462.666992
I 2015-05-26 22:18:03 theanets.trainer:168 RmsProp 15 loss=6406.685059 err=6137.819824
I 2015-05-26 22:18:40 theanets.trainer:168 RmsProp 16 loss=6295.611328 err=6010.931152
I 2015-05-26 22:19:18 theanets.trainer:168 RmsProp 17 loss=6057.140137 err=5757.028809
I 2015-05-26 22:19:57 theanets.trainer:168 RmsProp 18 loss=5813.177734 err=5499.760254
I 2015-05-26 22:20:35 theanets.trainer:168 RmsProp 19 loss=5701.081055 err=5371.026855
I 2015-05-26 22:21:14 theanets.trainer:168 RmsProp 20 loss=5603.963379 err=5258.301758
I 2015-05-26 22:21:15 theanets.trainer:168 validation 2 loss=4736.758789 err=4380.295898 *
I 2015-05-26 22:21:53 theanets.trainer:168 RmsProp 21 loss=5477.458984 err=5116.038086
I 2015-05-26 22:22:32 theanets.trainer:168 RmsProp 22 loss=5371.769043 err=5001.270996
I 2015-05-26 22:23:10 theanets.trainer:168 RmsProp 23 loss=5137.662109 err=4761.570312
I 2015-05-26 22:23:47 theanets.trainer:168 RmsProp 24 loss=4884.159180 err=4496.424316
I 2015-05-26 22:24:26 theanets.trainer:168 RmsProp 25 loss=4582.072754 err=4184.172852
I 2015-05-26 22:25:04 theanets.trainer:168 RmsProp 26 loss=4372.329590 err=3970.278076
I 2015-05-26 22:25:43 theanets.trainer:168 RmsProp 27 loss=4251.199707 err=3842.903564
I 2015-05-26 22:26:20 theanets.trainer:168 RmsProp 28 loss=4144.283691 err=3728.083008
I 2015-05-26 22:27:00 theanets.trainer:168 RmsProp 29 loss=4160.391113 err=3730.240967
I 2015-05-26 22:27:39 theanets.trainer:168 RmsProp 30 loss=4060.116699 err=3621.759277
I 2015-05-26 22:27:39 theanets.trainer:168 validation 3 loss=3958.751221 err=3517.075928 *
I 2015-05-26 22:28:18 theanets.trainer:168 RmsProp 31 loss=3933.738281 err=3491.338623
I 2015-05-26 22:28:57 theanets.trainer:168 RmsProp 32 loss=3816.912842 err=3371.018311
I 2015-05-26 22:29:36 theanets.trainer:168 RmsProp 33 loss=3770.547119 err=3317.517334
I 2015-05-26 22:30:14 theanets.trainer:168 RmsProp 34 loss=3712.140381 err=3253.085693
I 2015-05-26 22:30:54 theanets.trainer:168 RmsProp 35 loss=3732.682129 err=3264.677490
I 2015-05-26 22:31:32 theanets.trainer:168 RmsProp 36 loss=3642.098633 err=3167.514893
I 2015-05-26 22:32:10 theanets.trainer:168 RmsProp 37 loss=3679.173584 err=3194.392090
I 2015-05-26 22:32:49 theanets.trainer:168 RmsProp 38 loss=3681.542969 err=3183.718262
I 2015-05-26 22:33:28 theanets.trainer:168 RmsProp 39 loss=5068.575195 err=4545.796875
I 2015-05-26 22:34:05 theanets.trainer:168 RmsProp 40 loss=4755.276855 err=4205.048340
I 2015-05-26 22:34:06 theanets.trainer:168 validation 4 loss=4094.820557 err=3543.460693
I 2015-05-26 22:34:45 theanets.trainer:168 RmsProp 41 loss=4407.594238 err=3854.473877
I 2015-05-26 22:35:24 theanets.trainer:168 RmsProp 42 loss=4277.732910 err=3723.268066
I 2015-05-26 22:36:02 theanets.trainer:168 RmsProp 43 loss=4282.180176 err=3719.427246
I 2015-05-26 22:36:40 theanets.trainer:168 RmsProp 44 loss=4185.896484 err=3614.456787
I 2015-05-26 22:37:18 theanets.trainer:168 RmsProp 45 loss=3995.759033 err=3416.879883
I 2015-05-26 22:37:56 theanets.trainer:168 RmsProp 46 loss=3941.507080 err=3352.836182
I 2015-05-26 22:38:34 theanets.trainer:168 RmsProp 47 loss=3813.693115 err=3220.738037
I 2015-05-26 22:39:12 theanets.trainer:168 RmsProp 48 loss=3719.880127 err=3121.527588
I 2015-05-26 22:39:50 theanets.trainer:168 RmsProp 49 loss=3591.457764 err=2991.481201
I 2015-05-26 22:40:27 theanets.trainer:168 RmsProp 50 loss=3375.658936 err=2773.568115
I 2015-05-26 22:40:28 theanets.trainer:168 validation 5 loss=3442.919189 err=2838.402100 *
I 2015-05-26 22:41:06 theanets.trainer:168 RmsProp 51 loss=3528.385254 err=2915.585693
I 2015-05-26 22:41:44 theanets.trainer:168 RmsProp 52 loss=3893.313232 err=3266.979492
I 2015-05-26 22:42:22 theanets.trainer:168 RmsProp 53 loss=4075.123291 err=3429.038086
I 2015-05-26 22:43:00 theanets.trainer:168 RmsProp 54 loss=3683.379150 err=3035.731689
I 2015-05-26 22:43:38 theanets.trainer:168 RmsProp 55 loss=3449.920166 err=2803.980713
I 2015-05-26 22:44:17 theanets.trainer:168 RmsProp 56 loss=3450.328125 err=2803.505615
I 2015-05-26 22:44:57 theanets.trainer:168 RmsProp 57 loss=3525.578857 err=2871.421387
I 2015-05-26 22:45:36 theanets.trainer:168 RmsProp 58 loss=3094.136475 err=2431.867676
I 2015-05-26 22:46:14 theanets.trainer:168 RmsProp 59 loss=2486.255127 err=1829.005615
I 2015-05-26 22:46:52 theanets.trainer:168 RmsProp 60 loss=2271.034424 err=1629.579956
I 2015-05-26 22:46:53 theanets.trainer:168 validation 6 loss=2958.351562 err=2323.980225 *
I 2015-05-26 22:47:31 theanets.trainer:168 RmsProp 61 loss=2152.761475 err=1523.640259
I 2015-05-26 22:48:09 theanets.trainer:168 RmsProp 62 loss=2080.961426 err=1460.109131
I 2015-05-26 22:48:46 theanets.trainer:168 RmsProp 63 loss=2031.252808 err=1415.179077
I 2015-05-26 22:49:24 theanets.trainer:168 RmsProp 64 loss=1975.315308 err=1363.028442
I 2015-05-26 22:50:02 theanets.trainer:168 RmsProp 65 loss=1939.641968 err=1330.310913
I 2015-05-26 22:50:41 theanets.trainer:168 RmsProp 66 loss=1900.612915 err=1293.746826
I 2015-05-26 22:51:19 theanets.trainer:168 RmsProp 67 loss=1872.410156 err=1266.221313
I 2015-05-26 22:51:58 theanets.trainer:168 RmsProp 68 loss=1828.098755 err=1223.146362
I 2015-05-26 22:52:36 theanets.trainer:168 RmsProp 69 loss=1807.818848 err=1203.639038
I 2015-05-26 22:53:15 theanets.trainer:168 RmsProp 70 loss=1786.265259 err=1182.902710
I 2015-05-26 22:53:16 theanets.trainer:168 validation 7 loss=2650.818604 err=2047.442749 *
I 2015-05-26 22:53:56 theanets.trainer:168 RmsProp 71 loss=1752.696533 err=1149.731812
I 2015-05-26 22:54:36 theanets.trainer:168 RmsProp 72 loss=1741.557983 err=1138.620728
I 2015-05-26 22:55:15 theanets.trainer:168 RmsProp 73 loss=1701.729248 err=1098.808716
I 2015-05-26 22:55:53 theanets.trainer:168 RmsProp 74 loss=1680.111816 err=1076.523071
I 2015-05-26 22:56:31 theanets.trainer:168 RmsProp 75 loss=1669.218872 err=1065.838989
I 2015-05-26 22:57:10 theanets.trainer:168 RmsProp 76 loss=1670.152466 err=1066.269409
I 2015-05-26 22:57:50 theanets.trainer:168 RmsProp 77 loss=1644.647705 err=1040.179688
I 2015-05-26 22:58:30 theanets.trainer:168 RmsProp 78 loss=1635.869263 err=1031.138550
I 2015-05-26 22:59:09 theanets.trainer:168 RmsProp 79 loss=1620.619385 err=1015.702454
I 2015-05-26 22:59:47 theanets.trainer:168 RmsProp 80 loss=1618.906738 err=1012.206482
I 2015-05-26 22:59:47 theanets.trainer:168 validation 8 loss=2564.531250 err=1957.281616 *
I 2015-05-26 23:00:25 theanets.trainer:168 RmsProp 81 loss=1584.114868 err=977.352600
I 2015-05-26 23:01:02 theanets.trainer:168 RmsProp 82 loss=1579.266479 err=973.526245
I 2015-05-26 23:01:41 theanets.trainer:168 RmsProp 83 loss=1568.648560 err=963.216431
I 2015-05-26 23:02:19 theanets.trainer:168 RmsProp 84 loss=1538.836792 err=933.516785
I 2015-05-26 23:02:58 theanets.trainer:168 RmsProp 85 loss=1546.662598 err=940.272644
I 2015-05-26 23:03:37 theanets.trainer:168 RmsProp 86 loss=1529.866699 err=922.588989
I 2015-05-26 23:04:15 theanets.trainer:168 RmsProp 87 loss=1505.805176 err=898.590576
I 2015-05-26 23:04:54 theanets.trainer:168 RmsProp 88 loss=1504.067749 err=896.258911
I 2015-05-26 23:05:32 theanets.trainer:168 RmsProp 89 loss=1492.796509 err=885.123169
I 2015-05-26 23:06:09 theanets.trainer:168 RmsProp 90 loss=1465.933594 err=858.727905
I 2015-05-26 23:06:09 theanets.trainer:168 validation 9 loss=2465.179932 err=1858.224976 *
I 2015-05-26 23:06:47 theanets.trainer:168 RmsProp 91 loss=1464.859253 err=856.859497
I 2015-05-26 23:07:26 theanets.trainer:168 RmsProp 92 loss=1455.654663 err=845.906921
I 2015-05-26 23:08:05 theanets.trainer:168 RmsProp 93 loss=1446.923340 err=837.202759
I 2015-05-26 23:08:45 theanets.trainer:168 RmsProp 94 loss=1434.506104 err=825.568054
I 2015-05-26 23:09:23 theanets.trainer:168 RmsProp 95 loss=1419.999756 err=811.759705
I 2015-05-26 23:10:02 theanets.trainer:168 RmsProp 96 loss=1427.181030 err=818.605591
I 2015-05-26 23:10:39 theanets.trainer:168 RmsProp 97 loss=1405.056152 err=796.033630
I 2015-05-26 23:11:17 theanets.trainer:168 RmsProp 98 loss=1407.250366 err=797.239441
I 2015-05-26 23:11:54 theanets.trainer:168 RmsProp 99 loss=1407.063354 err=796.298157
I 2015-05-26 23:12:32 theanets.trainer:168 RmsProp 100 loss=1427.412964 err=815.168579
I 2015-05-26 23:12:33 theanets.trainer:168 validation 10 loss=2361.000488 err=1747.873413 *
I 2015-05-26 23:13:12 theanets.trainer:168 RmsProp 101 loss=1405.319458 err=791.763916
I 2015-05-26 23:13:50 theanets.trainer:168 RmsProp 102 loss=1379.806396 err=767.287476
I 2015-05-26 23:14:29 theanets.trainer:168 RmsProp 103 loss=1369.389282 err=757.617859
I 2015-05-26 23:15:07 theanets.trainer:168 RmsProp 104 loss=1383.498169 err=770.939148
I 2015-05-26 23:15:45 theanets.trainer:168 RmsProp 105 loss=1383.181274 err=770.076599
I 2015-05-26 23:16:24 theanets.trainer:168 RmsProp 106 loss=1367.475952 err=752.783264
I 2015-05-26 23:17:02 theanets.trainer:168 RmsProp 107 loss=1372.950928 err=757.600403
I 2015-05-26 23:17:39 theanets.trainer:168 RmsProp 108 loss=1384.759399 err=768.142456
I 2015-05-26 23:18:16 theanets.trainer:168 RmsProp 109 loss=1380.549561 err=761.660706
I 2015-05-26 23:18:53 theanets.trainer:168 RmsProp 110 loss=1364.251221 err=744.655396
I 2015-05-26 23:18:54 theanets.trainer:168 validation 11 loss=2335.597656 err=1716.671753 *
I 2015-05-26 23:19:31 theanets.trainer:168 RmsProp 111 loss=1351.456909 err=732.907898
I 2015-05-26 23:20:08 theanets.trainer:168 RmsProp 112 loss=1346.250366 err=727.155029
I 2015-05-26 23:20:46 theanets.trainer:168 RmsProp 113 loss=1334.073608 err=715.284790
I 2015-05-26 23:21:24 theanets.trainer:168 RmsProp 114 loss=1328.174561 err=709.087708
I 2015-05-26 23:22:02 theanets.trainer:168 RmsProp 115 loss=1321.520996 err=702.400696
I 2015-05-26 23:22:40 theanets.trainer:168 RmsProp 116 loss=1330.296143 err=710.387390
I 2015-05-26 23:23:19 theanets.trainer:168 RmsProp 117 loss=1318.927612 err=698.831055
I 2015-05-26 23:23:57 theanets.trainer:168 RmsProp 118 loss=1305.119995 err=684.903015
I 2015-05-26 23:24:36 theanets.trainer:168 RmsProp 119 loss=1311.686401 err=691.344666
I 2015-05-26 23:25:14 theanets.trainer:168 RmsProp 120 loss=1314.372559 err=692.863464
I 2015-05-26 23:25:14 theanets.trainer:168 validation 12 loss=2274.209961 err=1651.544922 *
I 2015-05-26 23:25:52 theanets.trainer:168 RmsProp 121 loss=1324.399536 err=701.518860
I 2015-05-26 23:26:29 theanets.trainer:168 RmsProp 122 loss=1324.056641 err=700.367859
I 2015-05-26 23:27:07 theanets.trainer:168 RmsProp 123 loss=1323.413208 err=698.961304
I 2015-05-26 23:27:45 theanets.trainer:168 RmsProp 124 loss=1305.311768 err=680.609253
I 2015-05-26 23:28:24 theanets.trainer:168 RmsProp 125 loss=1297.026489 err=672.518188
I 2015-05-26 23:29:02 theanets.trainer:168 RmsProp 126 loss=1299.106323 err=674.019958
I 2015-05-26 23:29:40 theanets.trainer:168 RmsProp 127 loss=1311.835815 err=685.616577
I 2015-05-26 23:30:18 theanets.trainer:168 RmsProp 128 loss=1309.953247 err=681.949524
I 2015-05-26 23:30:57 theanets.trainer:168 RmsProp 129 loss=1296.140015 err=667.361450
I 2015-05-26 23:31:34 theanets.trainer:168 RmsProp 130 loss=1293.865601 err=665.518127
I 2015-05-26 23:31:35 theanets.trainer:168 validation 13 loss=2320.603271 err=1691.512695
I 2015-05-26 23:32:12 theanets.trainer:168 RmsProp 131 loss=1305.775513 err=676.018311
I 2015-05-26 23:32:48 theanets.trainer:168 RmsProp 132 loss=1295.982300 err=665.559875
I 2015-05-26 23:33:25 theanets.trainer:168 RmsProp 133 loss=1280.235962 err=650.249329
I 2015-05-26 23:34:03 theanets.trainer:168 RmsProp 134 loss=1285.828857 err=654.846313
I 2015-05-26 23:34:41 theanets.trainer:168 RmsProp 135 loss=1286.196167 err=654.560791
I 2015-05-26 23:35:19 theanets.trainer:168 RmsProp 136 loss=1274.767822 err=643.390259
I 2015-05-26 23:35:56 theanets.trainer:168 RmsProp 137 loss=1283.069580 err=650.541321
I 2015-05-26 23:36:33 theanets.trainer:168 RmsProp 138 loss=1273.814575 err=641.754944
I 2015-05-26 23:37:12 theanets.trainer:168 RmsProp 139 loss=1278.281006 err=645.715149
I 2015-05-26 23:37:50 theanets.trainer:168 RmsProp 140 loss=1288.380859 err=654.388428
I 2015-05-26 23:37:51 theanets.trainer:168 validation 14 loss=2222.176025 err=1586.868774 *
I 2015-05-26 23:38:29 theanets.trainer:168 RmsProp 141 loss=1278.076050 err=642.533936
I 2015-05-26 23:39:07 theanets.trainer:168 RmsProp 142 loss=1270.030518 err=633.418213
I 2015-05-26 23:39:45 theanets.trainer:168 RmsProp 143 loss=1264.242188 err=627.595337
I 2015-05-26 23:40:22 theanets.trainer:168 RmsProp 144 loss=1263.867920 err=626.693542
I 2015-05-26 23:41:01 theanets.trainer:168 RmsProp 145 loss=1269.022827 err=631.669617
I 2015-05-26 23:41:40 theanets.trainer:168 RmsProp 146 loss=1251.591675 err=613.448547
I 2015-05-26 23:42:19 theanets.trainer:168 RmsProp 147 loss=1248.370605 err=611.011719
I 2015-05-26 23:42:57 theanets.trainer:168 RmsProp 148 loss=1276.457031 err=638.027283
I 2015-05-26 23:43:36 theanets.trainer:168 RmsProp 149 loss=1268.475830 err=627.785095
I 2015-05-26 23:44:14 theanets.trainer:168 RmsProp 150 loss=1261.925781 err=620.941772
I 2015-05-26 23:44:15 theanets.trainer:168 validation 15 loss=2182.222168 err=1541.073608 *
I 2015-05-26 23:44:52 theanets.trainer:168 RmsProp 151 loss=1259.741943 err=618.155945
I 2015-05-26 23:45:30 theanets.trainer:168 RmsProp 152 loss=1255.644409 err=613.604248
I 2015-05-26 23:46:09 theanets.trainer:168 RmsProp 153 loss=1263.986328 err=621.268860
I 2015-05-26 23:46:46 theanets.trainer:168 RmsProp 154 loss=1249.748291 err=606.714294
I 2015-05-26 23:47:23 theanets.trainer:168 RmsProp 155 loss=1241.279907 err=598.480713
I 2015-05-26 23:48:00 theanets.trainer:168 RmsProp 156 loss=1238.207397 err=596.074646
I 2015-05-26 23:48:36 theanets.trainer:168 RmsProp 157 loss=1244.069092 err=601.263855
I 2015-05-26 23:49:14 theanets.trainer:168 RmsProp 158 loss=1240.096191 err=596.945435
I 2015-05-26 23:49:52 theanets.trainer:168 RmsProp 159 loss=1226.276733 err=583.872009
I 2015-05-26 23:50:29 theanets.trainer:168 RmsProp 160 loss=1218.816162 err=577.454468
I 2015-05-26 23:50:30 theanets.trainer:168 validation 16 loss=2154.205811 err=1513.115601 *
I 2015-05-26 23:51:05 theanets.trainer:168 RmsProp 161 loss=1217.968994 err=577.061768
I 2015-05-26 23:51:39 theanets.trainer:168 RmsProp 162 loss=1220.684448 err=579.442017
I 2015-05-26 23:52:13 theanets.trainer:168 RmsProp 163 loss=1210.530640 err=568.518799
I 2015-05-26 23:52:50 theanets.trainer:168 RmsProp 164 loss=1216.812866 err=575.225281
I 2015-05-26 23:53:26 theanets.trainer:168 RmsProp 165 loss=1223.977905 err=582.041626
I 2015-05-26 23:54:04 theanets.trainer:168 RmsProp 166 loss=1213.659302 err=571.199829
I 2015-05-26 23:54:41 theanets.trainer:168 RmsProp 167 loss=1204.388916 err=563.062195
I 2015-05-26 23:55:20 theanets.trainer:168 RmsProp 168 loss=1204.463257 err=563.598389
I 2015-05-26 23:55:57 theanets.trainer:168 RmsProp 169 loss=1224.078369 err=582.603882
I 2015-05-26 23:56:34 theanets.trainer:168 RmsProp 170 loss=1223.000122 err=580.158142
I 2015-05-26 23:56:35 theanets.trainer:168 validation 17 loss=2142.642090 err=1498.696777 *
I 2015-05-26 23:57:11 theanets.trainer:168 RmsProp 171 loss=1217.527588 err=573.902771
I 2015-05-26 23:57:46 theanets.trainer:168 RmsProp 172 loss=1195.668823 err=553.315430
I 2015-05-26 23:58:22 theanets.trainer:168 RmsProp 173 loss=1194.737549 err=553.424744
I 2015-05-26 23:58:58 theanets.trainer:168 RmsProp 174 loss=1205.651611 err=564.112305
I 2015-05-26 23:59:36 theanets.trainer:168 RmsProp 175 loss=1209.924927 err=567.037720
I 2015-05-27 00:00:14 theanets.trainer:168 RmsProp 176 loss=1201.334839 err=558.234009
I 2015-05-27 00:00:52 theanets.trainer:168 RmsProp 177 loss=1209.440796 err=565.406372
I 2015-05-27 00:01:29 theanets.trainer:168 RmsProp 178 loss=1192.912109 err=549.223511
I 2015-05-27 00:02:07 theanets.trainer:168 RmsProp 179 loss=1199.014526 err=554.777161
I 2015-05-27 00:02:43 theanets.trainer:168 RmsProp 180 loss=1196.435913 err=550.979431
I 2015-05-27 00:02:44 theanets.trainer:168 validation 18 loss=2148.498291 err=1503.963379
I 2015-05-27 00:03:21 theanets.trainer:168 RmsProp 181 loss=1182.945190 err=538.765869
I 2015-05-27 00:03:59 theanets.trainer:168 RmsProp 182 loss=1193.019531 err=548.673523
I 2015-05-27 00:04:36 theanets.trainer:168 RmsProp 183 loss=1199.327393 err=554.323608
I 2015-05-27 00:05:13 theanets.trainer:168 RmsProp 184 loss=1192.743408 err=548.473511
I 2015-05-27 00:05:50 theanets.trainer:168 RmsProp 185 loss=1201.616699 err=556.117798
I 2015-05-27 00:06:27 theanets.trainer:168 RmsProp 186 loss=1182.010498 err=537.440674
I 2015-05-27 00:07:04 theanets.trainer:168 RmsProp 187 loss=1176.895996 err=533.734009
I 2015-05-27 00:07:41 theanets.trainer:168 RmsProp 188 loss=1165.680176 err=523.389099
I 2015-05-27 00:08:18 theanets.trainer:168 RmsProp 189 loss=1157.311890 err=516.305115
I 2015-05-27 00:08:54 theanets.trainer:168 RmsProp 190 loss=1157.080444 err=517.262207
I 2015-05-27 00:08:55 theanets.trainer:168 validation 19 loss=2168.263428 err=1528.834351
I 2015-05-27 00:09:31 theanets.trainer:168 RmsProp 191 loss=1166.069580 err=526.429626
I 2015-05-27 00:10:08 theanets.trainer:168 RmsProp 192 loss=1152.084839 err=513.304382
I 2015-05-27 00:10:45 theanets.trainer:168 RmsProp 193 loss=1147.900757 err=510.677216
I 2015-05-27 00:11:22 theanets.trainer:168 RmsProp 194 loss=1149.082886 err=512.388062
I 2015-05-27 00:11:57 theanets.trainer:168 RmsProp 195 loss=1153.270874 err=515.420166
I 2015-05-27 00:12:30 theanets.trainer:168 RmsProp 196 loss=1149.887329 err=512.070862
I 2015-05-27 00:13:05 theanets.trainer:168 RmsProp 197 loss=1155.706665 err=518.069641
I 2015-05-27 00:13:39 theanets.trainer:168 RmsProp 198 loss=1149.049438 err=511.544464
I 2015-05-27 00:14:13 theanets.trainer:168 RmsProp 199 loss=1138.243286 err=501.860046
I 2015-05-27 00:14:46 theanets.trainer:168 RmsProp 200 loss=1133.219604 err=497.440247
I 2015-05-27 00:14:46 theanets.trainer:168 validation 20 loss=2133.439453 err=1497.661987 *
I 2015-05-27 00:15:18 theanets.trainer:168 RmsProp 201 loss=1146.805298 err=510.900818
I 2015-05-27 00:15:50 theanets.trainer:168 RmsProp 202 loss=1148.863892 err=511.938538
I 2015-05-27 00:16:23 theanets.trainer:168 RmsProp 203 loss=1165.790527 err=526.793152
I 2015-05-27 00:16:56 theanets.trainer:168 RmsProp 204 loss=1155.271118 err=516.182922
I 2015-05-27 00:17:30 theanets.trainer:168 RmsProp 205 loss=1160.477295 err=520.885864
I 2015-05-27 00:18:04 theanets.trainer:168 RmsProp 206 loss=1155.229370 err=516.154114
I 2015-05-27 00:18:37 theanets.trainer:168 RmsProp 207 loss=1155.499268 err=515.636902
I 2015-05-27 00:19:10 theanets.trainer:168 RmsProp 208 loss=1161.228271 err=520.125244
I 2015-05-27 00:19:44 theanets.trainer:168 RmsProp 209 loss=1144.409302 err=504.243378
I 2015-05-27 00:20:17 theanets.trainer:168 RmsProp 210 loss=1150.011597 err=509.048340
I 2015-05-27 00:20:18 theanets.trainer:168 validation 21 loss=2087.724365 err=1447.191284 *
I 2015-05-27 00:20:52 theanets.trainer:168 RmsProp 211 loss=1133.256714 err=493.725403
I 2015-05-27 00:21:25 theanets.trainer:168 RmsProp 212 loss=1136.171021 err=497.344208
I 2015-05-27 00:22:00 theanets.trainer:168 RmsProp 213 loss=1126.183960 err=487.683472
I 2015-05-27 00:22:33 theanets.trainer:168 RmsProp 214 loss=1133.639526 err=496.032318
I 2015-05-27 00:23:07 theanets.trainer:168 RmsProp 215 loss=1147.591064 err=508.750854
I 2015-05-27 00:23:40 theanets.trainer:168 RmsProp 216 loss=1140.847168 err=501.519073
I 2015-05-27 00:24:14 theanets.trainer:168 RmsProp 217 loss=1130.694092 err=492.154022
I 2015-05-27 00:24:47 theanets.trainer:168 RmsProp 218 loss=1131.509766 err=493.000427
I 2015-05-27 00:25:20 theanets.trainer:168 RmsProp 219 loss=1124.009644 err=485.578735
I 2015-05-27 00:25:54 theanets.trainer:168 RmsProp 220 loss=1121.833252 err=483.769989
I 2015-05-27 00:25:55 theanets.trainer:168 validation 22 loss=2092.723877 err=1454.433960
I 2015-05-27 00:26:28 theanets.trainer:168 RmsProp 221 loss=1123.244019 err=485.381714
I 2015-05-27 00:27:01 theanets.trainer:168 RmsProp 222 loss=1117.853882 err=480.783478
I 2015-05-27 00:27:34 theanets.trainer:168 RmsProp 223 loss=1109.470337 err=473.548981
I 2015-05-27 00:28:06 theanets.trainer:168 RmsProp 224 loss=1118.692993 err=482.892120
I 2015-05-27 00:28:39 theanets.trainer:168 RmsProp 225 loss=1115.195190 err=478.744690
I 2015-05-27 00:29:13 theanets.trainer:168 RmsProp 226 loss=1119.608276 err=483.238678
I 2015-05-27 00:29:46 theanets.trainer:168 RmsProp 227 loss=1120.353760 err=483.668488
I 2015-05-27 00:30:19 theanets.trainer:168 RmsProp 228 loss=1125.800903 err=488.682281
I 2015-05-27 00:30:52 theanets.trainer:168 RmsProp 229 loss=1111.508545 err=474.851685
I 2015-05-27 00:31:25 theanets.trainer:168 RmsProp 230 loss=1114.115112 err=477.108032
I 2015-05-27 00:31:26 theanets.trainer:168 validation 23 loss=2085.491943 err=1448.607788 *
I 2015-05-27 00:31:58 theanets.trainer:168 RmsProp 231 loss=1111.451904 err=475.082031
I 2015-05-27 00:32:32 theanets.trainer:168 RmsProp 232 loss=1118.539551 err=481.999084
I 2015-05-27 00:33:05 theanets.trainer:168 RmsProp 233 loss=1138.161499 err=498.806671
I 2015-05-27 00:33:38 theanets.trainer:168 RmsProp 234 loss=1123.752075 err=483.259705
I 2015-05-27 00:34:11 theanets.trainer:168 RmsProp 235 loss=1119.412598 err=480.081879
I 2015-05-27 00:34:45 theanets.trainer:168 RmsProp 236 loss=1116.063232 err=477.240570
I 2015-05-27 00:35:20 theanets.trainer:168 RmsProp 237 loss=1115.021851 err=476.339874
I 2015-05-27 00:35:53 theanets.trainer:168 RmsProp 238 loss=1116.972656 err=478.746033
I 2015-05-27 00:36:26 theanets.trainer:168 RmsProp 239 loss=1115.688599 err=476.692505
I 2015-05-27 00:37:00 theanets.trainer:168 RmsProp 240 loss=1109.666382 err=471.565918
I 2015-05-27 00:37:00 theanets.trainer:168 validation 24 loss=2056.892822 err=1418.727173 *
I 2015-05-27 00:37:34 theanets.trainer:168 RmsProp 241 loss=1097.234009 err=460.285461
I 2015-05-27 00:38:08 theanets.trainer:168 RmsProp 242 loss=1123.287231 err=486.712830
I 2015-05-27 00:38:41 theanets.trainer:168 RmsProp 243 loss=1168.366821 err=524.659058
I 2015-05-27 00:39:14 theanets.trainer:168 RmsProp 244 loss=1112.492798 err=470.499725
I 2015-05-27 00:39:47 theanets.trainer:168 RmsProp 245 loss=1119.813721 err=479.072693
I 2015-05-27 00:40:20 theanets.trainer:168 RmsProp 246 loss=1103.016724 err=463.049316
I 2015-05-27 00:40:53 theanets.trainer:168 RmsProp 247 loss=1105.708740 err=466.738831
I 2015-05-27 00:41:26 theanets.trainer:168 RmsProp 248 loss=1095.565308 err=457.584534
I 2015-05-27 00:41:59 theanets.trainer:168 RmsProp 249 loss=1093.368774 err=457.095032
I 2015-05-27 00:42:32 theanets.trainer:168 RmsProp 250 loss=1094.971191 err=458.692719
I 2015-05-27 00:42:33 theanets.trainer:168 validation 25 loss=2046.318359 err=1409.963013 *
I 2015-05-27 00:43:07 theanets.trainer:168 RmsProp 251 loss=1090.685669 err=454.906250
I 2015-05-27 00:43:40 theanets.trainer:168 RmsProp 252 loss=1081.542236 err=446.810333
I 2015-05-27 00:44:14 theanets.trainer:168 RmsProp 253 loss=1081.515015 err=447.977814
I 2015-05-27 00:44:47 theanets.trainer:168 RmsProp 254 loss=1082.975830 err=449.306122
I 2015-05-27 00:45:21 theanets.trainer:168 RmsProp 255 loss=1084.506592 err=451.136719
I 2015-05-27 00:45:54 theanets.trainer:168 RmsProp 256 loss=1074.858765 err=442.208710
I 2015-05-27 00:46:28 theanets.trainer:168 RmsProp 257 loss=1075.892822 err=443.841309
I 2015-05-27 00:47:01 theanets.trainer:168 RmsProp 258 loss=1075.901001 err=444.273163
I 2015-05-27 00:47:35 theanets.trainer:168 RmsProp 259 loss=1079.820801 err=447.966400
I 2015-05-27 00:48:09 theanets.trainer:168 RmsProp 260 loss=1084.960083 err=452.712799
I 2015-05-27 00:48:10 theanets.trainer:168 validation 26 loss=2003.852173 err=1370.640015 *
I 2015-05-27 00:48:44 theanets.trainer:168 RmsProp 261 loss=1088.925903 err=456.198273
I 2015-05-27 00:49:18 theanets.trainer:168 RmsProp 262 loss=1084.328613 err=451.500946
I 2015-05-27 00:49:52 theanets.trainer:168 RmsProp 263 loss=1075.537720 err=443.849609
I 2015-05-27 00:50:26 theanets.trainer:168 RmsProp 264 loss=1078.522705 err=446.939148
I 2015-05-27 00:51:00 theanets.trainer:168 RmsProp 265 loss=1070.811035 err=440.198456
I 2015-05-27 00:51:34 theanets.trainer:168 RmsProp 266 loss=1072.844604 err=442.491821
I 2015-05-27 00:52:08 theanets.trainer:168 RmsProp 267 loss=1069.876221 err=440.270050
I 2015-05-27 00:52:42 theanets.trainer:168 RmsProp 268 loss=1066.431763 err=437.202301
I 2015-05-27 00:53:16 theanets.trainer:168 RmsProp 269 loss=1062.298218 err=433.971130
I 2015-05-27 00:53:49 theanets.trainer:168 RmsProp 270 loss=1057.127808 err=429.021667
I 2015-05-27 00:53:50 theanets.trainer:168 validation 27 loss=1950.681030 err=1323.251831 *
I 2015-05-27 00:54:24 theanets.trainer:168 RmsProp 271 loss=1058.503418 err=431.394928
I 2015-05-27 00:54:58 theanets.trainer:168 RmsProp 272 loss=1062.631104 err=435.086365
I 2015-05-27 00:55:32 theanets.trainer:168 RmsProp 273 loss=1050.020264 err=423.237122
I 2015-05-27 00:56:05 theanets.trainer:168 RmsProp 274 loss=1045.015869 err=419.360657
I 2015-05-27 00:56:39 theanets.trainer:168 RmsProp 275 loss=1041.683838 err=416.967377
I 2015-05-27 00:57:12 theanets.trainer:168 RmsProp 276 loss=1047.444214 err=423.383362
I 2015-05-27 00:57:46 theanets.trainer:168 RmsProp 277 loss=1052.836548 err=428.310516
I 2015-05-27 00:58:19 theanets.trainer:168 RmsProp 278 loss=1047.597290 err=422.190247
I 2015-05-27 00:58:52 theanets.trainer:168 RmsProp 279 loss=1051.867554 err=427.510773
I 2015-05-27 00:59:24 theanets.trainer:168 RmsProp 280 loss=1081.164185 err=452.835052
I 2015-05-27 00:59:25 theanets.trainer:168 validation 28 loss=1992.068726 err=1362.034546
I 2015-05-27 00:59:58 theanets.trainer:168 RmsProp 281 loss=1056.899658 err=429.505829
I 2015-05-27 01:00:31 theanets.trainer:168 RmsProp 282 loss=1066.248413 err=440.444366
I 2015-05-27 01:01:04 theanets.trainer:168 RmsProp 283 loss=1049.370972 err=424.606018
I 2015-05-27 01:01:37 theanets.trainer:168 RmsProp 284 loss=1040.264038 err=416.236877
I 2015-05-27 01:02:10 theanets.trainer:168 RmsProp 285 loss=1043.233032 err=420.109924
I 2015-05-27 01:02:43 theanets.trainer:168 RmsProp 286 loss=1038.335571 err=415.371063
I 2015-05-27 01:03:16 theanets.trainer:168 RmsProp 287 loss=1042.893311 err=420.185730
I 2015-05-27 01:03:50 theanets.trainer:168 RmsProp 288 loss=1057.983643 err=434.613831
I 2015-05-27 01:04:23 theanets.trainer:168 RmsProp 289 loss=1057.614380 err=433.540344
I 2015-05-27 01:04:57 theanets.trainer:168 RmsProp 290 loss=1043.513306 err=420.023407
I 2015-05-27 01:04:58 theanets.trainer:168 validation 29 loss=1970.556519 err=1347.098145
I 2015-05-27 01:05:32 theanets.trainer:168 RmsProp 291 loss=1046.218872 err=422.638153
I 2015-05-27 01:06:05 theanets.trainer:168 RmsProp 292 loss=1046.028809 err=422.650299
I 2015-05-27 01:06:39 theanets.trainer:168 RmsProp 293 loss=1042.688232 err=419.362823
I 2015-05-27 01:07:12 theanets.trainer:168 RmsProp 294 loss=1064.028564 err=439.701813
I 2015-05-27 01:07:46 theanets.trainer:168 RmsProp 295 loss=1072.948364 err=446.826691
I 2015-05-27 01:08:20 theanets.trainer:168 RmsProp 296 loss=1058.061646 err=431.803131
I 2015-05-27 01:08:54 theanets.trainer:168 RmsProp 297 loss=1044.233765 err=418.752930
I 2015-05-27 01:09:28 theanets.trainer:168 RmsProp 298 loss=1051.260498 err=425.970520
I 2015-05-27 01:10:03 theanets.trainer:168 RmsProp 299 loss=1046.080200 err=420.110626
I 2015-05-27 01:10:37 theanets.trainer:168 RmsProp 300 loss=1044.780518 err=419.550598
I 2015-05-27 01:10:38 theanets.trainer:168 validation 30 loss=1974.237671 err=1349.505371
I 2015-05-27 01:11:12 theanets.trainer:168 RmsProp 301 loss=1037.341675 err=413.187866
I 2015-05-27 01:11:47 theanets.trainer:168 RmsProp 302 loss=1032.197876 err=408.605865
I 2015-05-27 01:12:22 theanets.trainer:168 RmsProp 303 loss=1042.301880 err=418.879700
I 2015-05-27 01:12:56 theanets.trainer:168 RmsProp 304 loss=1037.248169 err=413.625519
I 2015-05-27 01:13:29 theanets.trainer:168 RmsProp 305 loss=1030.677368 err=408.371887
I 2015-05-27 01:14:03 theanets.trainer:168 RmsProp 306 loss=1037.217163 err=414.884552
I 2015-05-27 01:14:36 theanets.trainer:168 RmsProp 307 loss=1035.460083 err=412.556274
I 2015-05-27 01:15:10 theanets.trainer:168 RmsProp 308 loss=1035.364746 err=412.909363
I 2015-05-27 01:15:43 theanets.trainer:168 RmsProp 309 loss=1053.004150 err=427.689423
I 2015-05-27 01:16:17 theanets.trainer:168 RmsProp 310 loss=1043.010986 err=418.552094
I 2015-05-27 01:16:18 theanets.trainer:168 validation 31 loss=1974.347534 err=1350.823364
I 2015-05-27 01:16:51 theanets.trainer:168 RmsProp 311 loss=1032.207153 err=409.175262
I 2015-05-27 01:17:25 theanets.trainer:168 RmsProp 312 loss=1025.671265 err=404.576843
I 2015-05-27 01:17:59 theanets.trainer:168 RmsProp 313 loss=1067.668701 err=443.414368
I 2015-05-27 01:18:33 theanets.trainer:168 RmsProp 314 loss=1046.114014 err=421.699493
I 2015-05-27 01:19:07 theanets.trainer:168 RmsProp 315 loss=1035.057983 err=411.882050
I 2015-05-27 01:19:40 theanets.trainer:168 RmsProp 316 loss=1022.904602 err=401.533508
I 2015-05-27 01:20:15 theanets.trainer:168 RmsProp 317 loss=1025.141602 err=404.323334
I 2015-05-27 01:20:50 theanets.trainer:168 RmsProp 318 loss=1019.402283 err=399.203339
I 2015-05-27 01:21:23 theanets.trainer:168 RmsProp 319 loss=1039.710571 err=416.593109
I 2015-05-27 01:21:57 theanets.trainer:168 RmsProp 320 loss=1040.555420 err=417.898010
I 2015-05-27 01:21:58 theanets.trainer:168 validation 32 loss=1928.349731 err=1306.344360 *
I 2015-05-27 01:22:32 theanets.trainer:168 RmsProp 321 loss=1033.365601 err=411.104828
I 2015-05-27 01:23:06 theanets.trainer:168 RmsProp 322 loss=1026.293823 err=404.710175
I 2015-05-27 01:23:41 theanets.trainer:168 RmsProp 323 loss=1071.491699 err=447.140045
I 2015-05-27 01:24:15 theanets.trainer:168 RmsProp 324 loss=1049.642944 err=424.749023
I 2015-05-27 01:24:50 theanets.trainer:168 RmsProp 325 loss=1057.672241 err=431.808746
I 2015-05-27 01:25:24 theanets.trainer:168 RmsProp 326 loss=1055.770874 err=429.228210
I 2015-05-27 01:25:59 theanets.trainer:168 RmsProp 327 loss=1040.943237 err=415.609772
I 2015-05-27 01:26:33 theanets.trainer:168 RmsProp 328 loss=1044.441040 err=418.831329
I 2015-05-27 01:27:05 theanets.trainer:168 RmsProp 329 loss=1032.609497 err=408.290741
I 2015-05-27 01:27:38 theanets.trainer:168 RmsProp 330 loss=1050.611816 err=425.985809
I 2015-05-27 01:27:38 theanets.trainer:168 validation 33 loss=1990.909058 err=1365.827515
I 2015-05-27 01:28:10 theanets.trainer:168 RmsProp 331 loss=1030.374268 err=405.578583
I 2015-05-27 01:28:43 theanets.trainer:168 RmsProp 332 loss=1038.115967 err=414.223907
I 2015-05-27 01:29:17 theanets.trainer:168 RmsProp 333 loss=1044.528687 err=419.024231
I 2015-05-27 01:29:50 theanets.trainer:168 RmsProp 334 loss=1036.945435 err=411.340027
I 2015-05-27 01:30:23 theanets.trainer:168 RmsProp 335 loss=1036.335815 err=411.438416
I 2015-05-27 01:30:57 theanets.trainer:168 RmsProp 336 loss=1033.523193 err=408.399475
I 2015-05-27 01:31:30 theanets.trainer:168 RmsProp 337 loss=1041.392700 err=415.883392
I 2015-05-27 01:32:03 theanets.trainer:168 RmsProp 338 loss=1046.895264 err=419.768982
I 2015-05-27 01:32:37 theanets.trainer:168 RmsProp 339 loss=1054.295410 err=425.931519
I 2015-05-27 01:33:10 theanets.trainer:168 RmsProp 340 loss=1055.399658 err=425.178741
I 2015-05-27 01:33:11 theanets.trainer:168 validation 34 loss=1959.399048 err=1328.928589
I 2015-05-27 01:33:45 theanets.trainer:168 RmsProp 341 loss=1054.944702 err=423.768585
I 2015-05-27 01:34:18 theanets.trainer:168 RmsProp 342 loss=1043.536987 err=412.969177
I 2015-05-27 01:34:51 theanets.trainer:168 RmsProp 343 loss=1065.274902 err=431.042389
I 2015-05-27 01:35:24 theanets.trainer:168 RmsProp 344 loss=1041.811157 err=410.348633
I 2015-05-27 01:35:57 theanets.trainer:168 RmsProp 345 loss=1040.572510 err=410.860992
I 2015-05-27 01:36:31 theanets.trainer:168 RmsProp 346 loss=1039.874512 err=410.104187
I 2015-05-27 01:37:05 theanets.trainer:168 RmsProp 347 loss=1025.858765 err=397.549408
I 2015-05-27 01:37:39 theanets.trainer:168 RmsProp 348 loss=1028.171143 err=401.066467
I 2015-05-27 01:38:13 theanets.trainer:168 RmsProp 349 loss=1028.032593 err=400.537689
I 2015-05-27 01:38:47 theanets.trainer:168 RmsProp 350 loss=1028.772217 err=401.607605
I 2015-05-27 01:38:48 theanets.trainer:168 validation 35 loss=1943.708130 err=1315.942261
I 2015-05-27 01:39:21 theanets.trainer:168 RmsProp 351 loss=1036.418701 err=408.355316
I 2015-05-27 01:39:55 theanets.trainer:168 RmsProp 352 loss=1046.249634 err=416.597229
I 2015-05-27 01:40:29 theanets.trainer:168 RmsProp 353 loss=1041.758667 err=410.964996
I 2015-05-27 01:41:03 theanets.trainer:168 RmsProp 354 loss=1039.502441 err=407.610931
I 2015-05-27 01:41:34 theanets.trainer:168 RmsProp 355 loss=1035.828369 err=405.794830
I 2015-05-27 01:42:05 theanets.trainer:168 RmsProp 356 loss=1036.975586 err=407.010742
I 2015-05-27 01:42:35 theanets.trainer:168 RmsProp 357 loss=1028.665527 err=398.748688
I 2015-05-27 01:43:06 theanets.trainer:168 RmsProp 358 loss=1014.343994 err=386.675323
I 2015-05-27 01:43:36 theanets.trainer:168 RmsProp 359 loss=1039.928833 err=411.966431
I 2015-05-27 01:44:06 theanets.trainer:168 RmsProp 360 loss=1029.394043 err=401.476990
I 2015-05-27 01:44:07 theanets.trainer:168 validation 36 loss=1992.787598 err=1365.329590
I 2015-05-27 01:44:37 theanets.trainer:168 RmsProp 361 loss=1040.101074 err=411.381165
I 2015-05-27 01:45:07 theanets.trainer:168 RmsProp 362 loss=1029.098145 err=399.918304
I 2015-05-27 01:45:38 theanets.trainer:168 RmsProp 363 loss=1022.112671 err=394.216949
I 2015-05-27 01:46:09 theanets.trainer:168 RmsProp 364 loss=1043.642212 err=415.478882
I 2015-05-27 01:46:40 theanets.trainer:168 RmsProp 365 loss=1049.535278 err=418.177338
I 2015-05-27 01:47:10 theanets.trainer:168 RmsProp 366 loss=1027.338745 err=397.978882
I 2015-05-27 01:47:40 theanets.trainer:168 RmsProp 367 loss=1022.984253 err=395.376404
I 2015-05-27 01:48:10 theanets.trainer:168 RmsProp 368 loss=1027.156982 err=399.611053
I 2015-05-27 01:48:41 theanets.trainer:168 RmsProp 369 loss=1035.927002 err=407.584686
I 2015-05-27 01:49:11 theanets.trainer:168 RmsProp 370 loss=1067.664795 err=436.555115
I 2015-05-27 01:49:12 theanets.trainer:168 validation 37 loss=1957.067993 err=1325.380859
I 2015-05-27 01:49:12 theanets.trainer:252 patience elapsed!
I 2015-05-27 01:49:12 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 01:49:12 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 01:49:12 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 01:49:12 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 01:49:12 theanets.main:89 --batch_size = 1024
I 2015-05-27 01:49:12 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 01:49:12 theanets.main:89 --hidden_l1 = None
I 2015-05-27 01:49:12 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 01:49:12 theanets.main:89 --train_batches = 10
I 2015-05-27 01:49:12 theanets.main:89 --valid_batches = 2
I 2015-05-27 01:49:12 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 01:49:12 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 01:49:12 theanets.trainer:134 compiling evaluation function
I 2015-05-27 01:49:21 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 01:50:59 theanets.trainer:168 validation 0 loss=2297.136963 err=1675.131714 *
I 2015-05-27 01:51:09 theanets.trainer:168 RmsProp 1 loss=971.791199 err=352.813812
I 2015-05-27 01:51:18 theanets.trainer:168 RmsProp 2 loss=836.465210 err=219.809860
I 2015-05-27 01:51:28 theanets.trainer:168 RmsProp 3 loss=762.576782 err=147.464981
I 2015-05-27 01:51:38 theanets.trainer:168 RmsProp 4 loss=722.334900 err=108.819595
I 2015-05-27 01:51:48 theanets.trainer:168 RmsProp 5 loss=697.671509 err=86.018478
I 2015-05-27 01:51:58 theanets.trainer:168 RmsProp 6 loss=680.859009 err=71.412758
I 2015-05-27 01:52:08 theanets.trainer:168 RmsProp 7 loss=666.000305 err=59.158863
I 2015-05-27 01:52:18 theanets.trainer:168 RmsProp 8 loss=654.702271 err=50.748486
I 2015-05-27 01:52:27 theanets.trainer:168 RmsProp 9 loss=644.263794 err=43.291283
I 2015-05-27 01:52:37 theanets.trainer:168 RmsProp 10 loss=636.120361 err=38.242882
I 2015-05-27 01:52:38 theanets.trainer:168 validation 1 loss=1851.882080 err=1255.750977 *
I 2015-05-27 01:52:47 theanets.trainer:168 RmsProp 11 loss=629.331909 err=34.634068
I 2015-05-27 01:52:57 theanets.trainer:168 RmsProp 12 loss=622.514771 err=30.998993
I 2015-05-27 01:53:07 theanets.trainer:168 RmsProp 13 loss=616.825867 err=28.579670
I 2015-05-27 01:53:16 theanets.trainer:168 RmsProp 14 loss=612.718872 err=27.812458
I 2015-05-27 01:53:26 theanets.trainer:168 RmsProp 15 loss=607.312927 err=25.542412
I 2015-05-27 01:53:35 theanets.trainer:168 RmsProp 16 loss=602.607544 err=23.681406
I 2015-05-27 01:53:45 theanets.trainer:168 RmsProp 17 loss=597.753052 err=21.639835
I 2015-05-27 01:53:55 theanets.trainer:168 RmsProp 18 loss=594.583252 err=21.451363
I 2015-05-27 01:54:04 theanets.trainer:168 RmsProp 19 loss=589.775574 err=19.733585
I 2015-05-27 01:54:14 theanets.trainer:168 RmsProp 20 loss=587.453491 err=20.531139
I 2015-05-27 01:54:15 theanets.trainer:168 validation 2 loss=1684.338013 err=1119.083374 *
I 2015-05-27 01:54:24 theanets.trainer:168 RmsProp 21 loss=582.317993 err=18.344177
I 2015-05-27 01:54:34 theanets.trainer:168 RmsProp 22 loss=578.216614 err=17.048428
I 2015-05-27 01:54:44 theanets.trainer:168 RmsProp 23 loss=574.988708 err=16.726683
I 2015-05-27 01:54:53 theanets.trainer:168 RmsProp 24 loss=571.292908 err=16.018440
I 2015-05-27 01:55:03 theanets.trainer:168 RmsProp 25 loss=568.294128 err=16.008991
I 2015-05-27 01:55:12 theanets.trainer:168 RmsProp 26 loss=564.047668 err=14.670842
I 2015-05-27 01:55:22 theanets.trainer:168 RmsProp 27 loss=561.007446 err=14.598773
I 2015-05-27 01:55:31 theanets.trainer:168 RmsProp 28 loss=558.872437 err=15.381902
I 2015-05-27 01:55:41 theanets.trainer:168 RmsProp 29 loss=554.422485 err=13.574697
I 2015-05-27 01:55:51 theanets.trainer:168 RmsProp 30 loss=551.444336 err=13.189293
I 2015-05-27 01:55:52 theanets.trainer:168 validation 3 loss=1598.947632 err=1062.170654 *
I 2015-05-27 01:56:01 theanets.trainer:168 RmsProp 31 loss=548.697449 err=13.146637
I 2015-05-27 01:56:11 theanets.trainer:168 RmsProp 32 loss=544.962524 err=12.108456
I 2015-05-27 01:56:20 theanets.trainer:168 RmsProp 33 loss=542.380493 err=12.268057
I 2015-05-27 01:56:30 theanets.trainer:168 RmsProp 34 loss=539.326477 err=11.909595
I 2015-05-27 01:56:40 theanets.trainer:168 RmsProp 35 loss=536.157593 err=11.373881
I 2015-05-27 01:56:49 theanets.trainer:168 RmsProp 36 loss=533.633850 err=11.488363
I 2015-05-27 01:56:59 theanets.trainer:168 RmsProp 37 loss=531.123169 err=11.603553
I 2015-05-27 01:57:09 theanets.trainer:168 RmsProp 38 loss=527.977173 err=10.967361
I 2015-05-27 01:57:19 theanets.trainer:168 RmsProp 39 loss=524.797607 err=10.289354
I 2015-05-27 01:57:29 theanets.trainer:168 RmsProp 40 loss=523.032410 err=11.058736
I 2015-05-27 01:57:29 theanets.trainer:168 validation 4 loss=1533.171997 err=1022.568176 *
I 2015-05-27 01:57:39 theanets.trainer:168 RmsProp 41 loss=519.876831 err=10.377668
I 2015-05-27 01:57:49 theanets.trainer:168 RmsProp 42 loss=517.051941 err=9.978173
I 2015-05-27 01:57:58 theanets.trainer:168 RmsProp 43 loss=514.240784 err=9.596037
I 2015-05-27 01:58:08 theanets.trainer:168 RmsProp 44 loss=512.512085 err=10.349745
I 2015-05-27 01:58:18 theanets.trainer:168 RmsProp 45 loss=508.742371 err=8.995517
I 2015-05-27 01:58:27 theanets.trainer:168 RmsProp 46 loss=507.420166 err=10.091989
I 2015-05-27 01:58:37 theanets.trainer:168 RmsProp 47 loss=504.707947 err=9.733338
I 2015-05-27 01:58:47 theanets.trainer:168 RmsProp 48 loss=501.684662 err=8.901785
I 2015-05-27 01:58:57 theanets.trainer:168 RmsProp 49 loss=499.510437 err=8.922799
I 2015-05-27 01:59:07 theanets.trainer:168 RmsProp 50 loss=496.989349 err=8.678252
I 2015-05-27 01:59:07 theanets.trainer:168 validation 5 loss=1463.449463 err=976.415649 *
I 2015-05-27 01:59:17 theanets.trainer:168 RmsProp 51 loss=494.384125 err=8.401994
I 2015-05-27 01:59:26 theanets.trainer:168 RmsProp 52 loss=492.326813 err=8.698897
I 2015-05-27 01:59:36 theanets.trainer:168 RmsProp 53 loss=490.362122 err=9.044294
I 2015-05-27 01:59:46 theanets.trainer:168 RmsProp 54 loss=487.085754 err=7.924822
I 2015-05-27 01:59:56 theanets.trainer:168 RmsProp 55 loss=485.080566 err=8.095203
I 2015-05-27 02:00:05 theanets.trainer:168 RmsProp 56 loss=482.702454 err=7.953782
I 2015-05-27 02:00:15 theanets.trainer:168 RmsProp 57 loss=480.280090 err=7.765246
I 2015-05-27 02:00:25 theanets.trainer:168 RmsProp 58 loss=478.347992 err=8.064919
I 2015-05-27 02:00:35 theanets.trainer:168 RmsProp 59 loss=475.844635 err=7.712325
I 2015-05-27 02:00:45 theanets.trainer:168 RmsProp 60 loss=473.774231 err=7.767968
I 2015-05-27 02:00:46 theanets.trainer:168 validation 6 loss=1406.083862 err=941.228638 *
I 2015-05-27 02:00:56 theanets.trainer:168 RmsProp 61 loss=471.584167 err=7.661397
I 2015-05-27 02:01:06 theanets.trainer:168 RmsProp 62 loss=469.069092 err=7.189079
I 2015-05-27 02:01:15 theanets.trainer:168 RmsProp 63 loss=467.106293 err=7.273089
I 2015-05-27 02:01:25 theanets.trainer:168 RmsProp 64 loss=465.221100 err=7.457252
I 2015-05-27 02:01:35 theanets.trainer:168 RmsProp 65 loss=463.015778 err=7.319267
I 2015-05-27 02:01:45 theanets.trainer:168 RmsProp 66 loss=460.983551 err=7.277533
I 2015-05-27 02:01:54 theanets.trainer:168 RmsProp 67 loss=458.680603 err=6.919826
I 2015-05-27 02:02:04 theanets.trainer:168 RmsProp 68 loss=456.645599 err=6.849477
I 2015-05-27 02:02:13 theanets.trainer:168 RmsProp 69 loss=454.809143 err=6.988944
I 2015-05-27 02:02:23 theanets.trainer:168 RmsProp 70 loss=452.764343 err=6.918763
I 2015-05-27 02:02:24 theanets.trainer:168 validation 7 loss=1361.078979 err=916.301575 *
I 2015-05-27 02:02:34 theanets.trainer:168 RmsProp 71 loss=450.745026 err=6.831080
I 2015-05-27 02:02:44 theanets.trainer:168 RmsProp 72 loss=448.222595 err=6.221054
I 2015-05-27 02:02:54 theanets.trainer:168 RmsProp 73 loss=447.172211 err=7.104856
I 2015-05-27 02:03:03 theanets.trainer:168 RmsProp 74 loss=444.736633 err=6.563735
I 2015-05-27 02:03:13 theanets.trainer:168 RmsProp 75 loss=442.531250 err=6.210753
I 2015-05-27 02:03:23 theanets.trainer:168 RmsProp 76 loss=440.803223 err=6.370013
I 2015-05-27 02:03:32 theanets.trainer:168 RmsProp 77 loss=439.403961 err=6.863547
I 2015-05-27 02:03:42 theanets.trainer:168 RmsProp 78 loss=437.092865 err=6.365081
I 2015-05-27 02:03:52 theanets.trainer:168 RmsProp 79 loss=434.766907 err=5.807573
I 2015-05-27 02:04:02 theanets.trainer:168 RmsProp 80 loss=434.241608 err=7.090827
I 2015-05-27 02:04:02 theanets.trainer:168 validation 8 loss=1337.058594 err=910.886902 *
I 2015-05-27 02:04:12 theanets.trainer:168 RmsProp 81 loss=431.555847 err=6.141578
I 2015-05-27 02:04:22 theanets.trainer:168 RmsProp 82 loss=429.564026 err=5.833875
I 2015-05-27 02:04:32 theanets.trainer:168 RmsProp 83 loss=428.481445 err=6.480969
I 2015-05-27 02:04:41 theanets.trainer:168 RmsProp 84 loss=426.185944 err=5.886910
I 2015-05-27 02:04:52 theanets.trainer:168 RmsProp 85 loss=424.514069 err=5.913040
I 2015-05-27 02:05:02 theanets.trainer:168 RmsProp 86 loss=423.054138 err=6.170674
I 2015-05-27 02:05:11 theanets.trainer:168 RmsProp 87 loss=421.125793 err=5.933105
I 2015-05-27 02:05:21 theanets.trainer:168 RmsProp 88 loss=419.232330 err=5.715008
I 2015-05-27 02:05:31 theanets.trainer:168 RmsProp 89 loss=417.761780 err=5.933743
I 2015-05-27 02:05:41 theanets.trainer:168 RmsProp 90 loss=415.672363 err=5.517171
I 2015-05-27 02:05:42 theanets.trainer:168 validation 9 loss=1304.536255 err=895.291809 *
I 2015-05-27 02:05:51 theanets.trainer:168 RmsProp 91 loss=414.511902 err=6.039113
I 2015-05-27 02:06:01 theanets.trainer:168 RmsProp 92 loss=412.965424 err=6.135883
I 2015-05-27 02:06:11 theanets.trainer:168 RmsProp 93 loss=410.585052 err=5.302677
I 2015-05-27 02:06:21 theanets.trainer:168 RmsProp 94 loss=409.449860 err=5.725320
I 2015-05-27 02:06:31 theanets.trainer:168 RmsProp 95 loss=407.777710 err=5.644771
I 2015-05-27 02:06:40 theanets.trainer:168 RmsProp 96 loss=406.281281 err=5.704033
I 2015-05-27 02:06:50 theanets.trainer:168 RmsProp 97 loss=404.511261 err=5.468395
I 2015-05-27 02:07:00 theanets.trainer:168 RmsProp 98 loss=402.832092 err=5.316180
I 2015-05-27 02:07:10 theanets.trainer:168 RmsProp 99 loss=401.705627 err=5.748139
I 2015-05-27 02:07:20 theanets.trainer:168 RmsProp 100 loss=400.017975 err=5.592397
I 2015-05-27 02:07:21 theanets.trainer:168 validation 10 loss=1272.111206 err=878.501465 *
I 2015-05-27 02:07:30 theanets.trainer:168 RmsProp 101 loss=398.064301 err=5.122252
I 2015-05-27 02:07:40 theanets.trainer:168 RmsProp 102 loss=397.081268 err=5.654826
I 2015-05-27 02:07:50 theanets.trainer:168 RmsProp 103 loss=395.040497 err=5.109084
I 2015-05-27 02:08:00 theanets.trainer:168 RmsProp 104 loss=393.796356 err=5.338284
I 2015-05-27 02:08:10 theanets.trainer:168 RmsProp 105 loss=392.284027 err=5.293229
I 2015-05-27 02:08:19 theanets.trainer:168 RmsProp 106 loss=390.971436 err=5.437504
I 2015-05-27 02:08:29 theanets.trainer:168 RmsProp 107 loss=389.462494 err=5.351991
I 2015-05-27 02:08:39 theanets.trainer:168 RmsProp 108 loss=387.798370 err=5.094602
I 2015-05-27 02:08:49 theanets.trainer:168 RmsProp 109 loss=386.386047 err=5.099212
I 2015-05-27 02:08:59 theanets.trainer:168 RmsProp 110 loss=385.093750 err=5.217107
I 2015-05-27 02:09:00 theanets.trainer:168 validation 11 loss=1255.901733 err=876.794739 *
I 2015-05-27 02:09:09 theanets.trainer:168 RmsProp 111 loss=383.316254 err=4.849965
I 2015-05-27 02:09:19 theanets.trainer:168 RmsProp 112 loss=382.319153 err=5.259273
I 2015-05-27 02:09:29 theanets.trainer:168 RmsProp 113 loss=380.807983 err=5.138682
I 2015-05-27 02:09:39 theanets.trainer:168 RmsProp 114 loss=378.974579 err=4.679258
I 2015-05-27 02:09:49 theanets.trainer:168 RmsProp 115 loss=378.285004 err=5.370112
I 2015-05-27 02:09:58 theanets.trainer:168 RmsProp 116 loss=376.538910 err=4.973619
I 2015-05-27 02:10:08 theanets.trainer:168 RmsProp 117 loss=375.111237 err=4.866300
I 2015-05-27 02:10:18 theanets.trainer:168 RmsProp 118 loss=373.835968 err=4.921620
I 2015-05-27 02:10:28 theanets.trainer:168 RmsProp 119 loss=372.492401 err=4.916254
I 2015-05-27 02:10:38 theanets.trainer:168 RmsProp 120 loss=371.113861 err=4.873010
I 2015-05-27 02:10:38 theanets.trainer:168 validation 12 loss=1213.811523 err=848.295227 *
I 2015-05-27 02:10:47 theanets.trainer:168 RmsProp 121 loss=370.072601 err=5.137345
I 2015-05-27 02:10:57 theanets.trainer:168 RmsProp 122 loss=368.425171 err=4.769003
I 2015-05-27 02:11:07 theanets.trainer:168 RmsProp 123 loss=367.397125 err=5.009203
I 2015-05-27 02:11:17 theanets.trainer:168 RmsProp 124 loss=365.699188 err=4.572689
I 2015-05-27 02:11:26 theanets.trainer:168 RmsProp 125 loss=364.769196 err=4.925570
I 2015-05-27 02:11:36 theanets.trainer:168 RmsProp 126 loss=363.240540 err=4.665347
I 2015-05-27 02:11:46 theanets.trainer:168 RmsProp 127 loss=361.833038 err=4.503854
I 2015-05-27 02:11:56 theanets.trainer:168 RmsProp 128 loss=360.935730 err=4.863617
I 2015-05-27 02:12:05 theanets.trainer:168 RmsProp 129 loss=359.464539 err=4.636867
I 2015-05-27 02:12:15 theanets.trainer:168 RmsProp 130 loss=358.466461 err=4.863885
I 2015-05-27 02:12:15 theanets.trainer:168 validation 13 loss=1190.233154 err=837.294373 *
I 2015-05-27 02:12:25 theanets.trainer:168 RmsProp 131 loss=357.046967 err=4.657758
I 2015-05-27 02:12:35 theanets.trainer:168 RmsProp 132 loss=355.660126 err=4.485703
I 2015-05-27 02:12:45 theanets.trainer:168 RmsProp 133 loss=354.860260 err=4.904185
I 2015-05-27 02:12:55 theanets.trainer:168 RmsProp 134 loss=353.287903 err=4.527640
I 2015-05-27 02:13:05 theanets.trainer:168 RmsProp 135 loss=352.113586 err=4.539308
I 2015-05-27 02:13:14 theanets.trainer:168 RmsProp 136 loss=351.031403 err=4.647875
I 2015-05-27 02:13:24 theanets.trainer:168 RmsProp 137 loss=349.621674 err=4.431471
I 2015-05-27 02:13:34 theanets.trainer:168 RmsProp 138 loss=348.570953 err=4.555094
I 2015-05-27 02:13:44 theanets.trainer:168 RmsProp 139 loss=347.403320 err=4.562265
I 2015-05-27 02:13:54 theanets.trainer:168 RmsProp 140 loss=346.074799 err=4.391807
I 2015-05-27 02:13:54 theanets.trainer:168 validation 14 loss=1171.567749 err=830.513794 *
I 2015-05-27 02:14:04 theanets.trainer:168 RmsProp 141 loss=344.991547 err=4.455685
I 2015-05-27 02:14:14 theanets.trainer:168 RmsProp 142 loss=343.810791 err=4.423449
I 2015-05-27 02:14:23 theanets.trainer:168 RmsProp 143 loss=342.543365 err=4.299305
I 2015-05-27 02:14:32 theanets.trainer:168 RmsProp 144 loss=341.564301 err=4.461211
I 2015-05-27 02:14:42 theanets.trainer:168 RmsProp 145 loss=340.483826 err=4.504079
I 2015-05-27 02:14:51 theanets.trainer:168 RmsProp 146 loss=339.313019 err=4.449075
I 2015-05-27 02:15:01 theanets.trainer:168 RmsProp 147 loss=338.016663 err=4.266373
I 2015-05-27 02:15:10 theanets.trainer:168 RmsProp 148 loss=336.995636 err=4.354310
I 2015-05-27 02:15:19 theanets.trainer:168 RmsProp 149 loss=335.925507 err=4.384932
I 2015-05-27 02:15:29 theanets.trainer:168 RmsProp 150 loss=334.686096 err=4.227827
I 2015-05-27 02:15:29 theanets.trainer:168 validation 15 loss=1154.414795 err=824.544922 *
I 2015-05-27 02:15:39 theanets.trainer:168 RmsProp 151 loss=333.739502 err=4.353145
I 2015-05-27 02:15:49 theanets.trainer:168 RmsProp 152 loss=332.607147 err=4.286633
I 2015-05-27 02:15:57 theanets.trainer:168 RmsProp 153 loss=331.541504 err=4.287686
I 2015-05-27 02:16:06 theanets.trainer:168 RmsProp 154 loss=330.440247 err=4.246900
I 2015-05-27 02:16:15 theanets.trainer:168 RmsProp 155 loss=329.472717 err=4.328976
I 2015-05-27 02:16:23 theanets.trainer:168 RmsProp 156 loss=328.166168 err=4.066957
I 2015-05-27 02:16:31 theanets.trainer:168 RmsProp 157 loss=327.359589 err=4.297389
I 2015-05-27 02:16:40 theanets.trainer:168 RmsProp 158 loss=326.256042 err=4.228158
I 2015-05-27 02:16:48 theanets.trainer:168 RmsProp 159 loss=325.052734 err=4.044508
I 2015-05-27 02:16:57 theanets.trainer:168 RmsProp 160 loss=324.247437 err=4.252709
I 2015-05-27 02:16:57 theanets.trainer:168 validation 16 loss=1135.129639 err=815.697205 *
I 2015-05-27 02:17:05 theanets.trainer:168 RmsProp 161 loss=323.145813 err=4.160995
I 2015-05-27 02:17:14 theanets.trainer:168 RmsProp 162 loss=322.135071 err=4.144425
I 2015-05-27 02:17:22 theanets.trainer:168 RmsProp 163 loss=321.357483 err=4.348212
I 2015-05-27 02:17:31 theanets.trainer:168 RmsProp 164 loss=320.065979 err=4.022226
I 2015-05-27 02:17:38 theanets.trainer:168 RmsProp 165 loss=319.271912 err=4.192054
I 2015-05-27 02:17:47 theanets.trainer:168 RmsProp 166 loss=318.321838 err=4.187841
I 2015-05-27 02:17:55 theanets.trainer:168 RmsProp 167 loss=317.192383 err=4.012540
I 2015-05-27 02:18:02 theanets.trainer:168 RmsProp 168 loss=316.309570 err=4.089807
I 2015-05-27 02:18:09 theanets.trainer:168 RmsProp 169 loss=315.558411 err=4.285898
I 2015-05-27 02:18:18 theanets.trainer:168 RmsProp 170 loss=314.412201 err=4.078013
I 2015-05-27 02:18:18 theanets.trainer:168 validation 17 loss=1109.641357 err=799.820740 *
I 2015-05-27 02:18:25 theanets.trainer:168 RmsProp 171 loss=313.386078 err=3.984292
I 2015-05-27 02:18:34 theanets.trainer:168 RmsProp 172 loss=312.559265 err=4.091543
I 2015-05-27 02:18:42 theanets.trainer:168 RmsProp 173 loss=311.548492 err=4.003699
I 2015-05-27 02:18:49 theanets.trainer:168 RmsProp 174 loss=310.559265 err=3.928320
I 2015-05-27 02:18:58 theanets.trainer:168 RmsProp 175 loss=309.708496 err=3.980610
I 2015-05-27 02:19:05 theanets.trainer:168 RmsProp 176 loss=308.921417 err=4.102123
I 2015-05-27 02:19:14 theanets.trainer:168 RmsProp 177 loss=307.940674 err=4.015687
I 2015-05-27 02:19:22 theanets.trainer:168 RmsProp 178 loss=307.041229 err=4.002676
I 2015-05-27 02:19:30 theanets.trainer:168 RmsProp 179 loss=306.306580 err=4.153682
I 2015-05-27 02:19:38 theanets.trainer:168 RmsProp 180 loss=305.186798 err=3.907548
I 2015-05-27 02:19:38 theanets.trainer:168 validation 18 loss=1090.663940 err=789.857849 *
I 2015-05-27 02:19:45 theanets.trainer:168 RmsProp 181 loss=304.267883 err=3.862947
I 2015-05-27 02:19:54 theanets.trainer:168 RmsProp 182 loss=303.612061 err=4.084146
I 2015-05-27 02:20:02 theanets.trainer:168 RmsProp 183 loss=302.465027 err=3.812581
I 2015-05-27 02:20:09 theanets.trainer:168 RmsProp 184 loss=301.701019 err=3.906080
I 2015-05-27 02:20:17 theanets.trainer:168 RmsProp 185 loss=300.844879 err=3.910990
I 2015-05-27 02:20:25 theanets.trainer:168 RmsProp 186 loss=299.877380 err=3.799874
I 2015-05-27 02:20:33 theanets.trainer:168 RmsProp 187 loss=299.143738 err=3.916993
I 2015-05-27 02:20:41 theanets.trainer:168 RmsProp 188 loss=298.238220 err=3.857644
I 2015-05-27 02:20:49 theanets.trainer:168 RmsProp 189 loss=297.211060 err=3.666600
I 2015-05-27 02:20:57 theanets.trainer:168 RmsProp 190 loss=296.819427 err=4.114543
I 2015-05-27 02:20:57 theanets.trainer:168 validation 19 loss=1070.731567 err=778.488892 *
I 2015-05-27 02:21:04 theanets.trainer:168 RmsProp 191 loss=295.808838 err=3.927470
I 2015-05-27 02:21:12 theanets.trainer:168 RmsProp 192 loss=294.735229 err=3.669532
I 2015-05-27 02:21:20 theanets.trainer:168 RmsProp 193 loss=294.223083 err=3.981022
I 2015-05-27 02:21:27 theanets.trainer:168 RmsProp 194 loss=293.190704 err=3.760770
I 2015-05-27 02:21:35 theanets.trainer:168 RmsProp 195 loss=292.487854 err=3.872429
I 2015-05-27 02:21:43 theanets.trainer:168 RmsProp 196 loss=291.548096 err=3.735854
I 2015-05-27 02:21:51 theanets.trainer:168 RmsProp 197 loss=290.862976 err=3.841225
I 2015-05-27 02:21:59 theanets.trainer:168 RmsProp 198 loss=290.018738 err=3.784810
I 2015-05-27 02:22:07 theanets.trainer:168 RmsProp 199 loss=289.103058 err=3.656145
I 2015-05-27 02:22:15 theanets.trainer:168 RmsProp 200 loss=288.531677 err=3.879548
I 2015-05-27 02:22:16 theanets.trainer:168 validation 20 loss=1067.243774 err=783.017761 *
I 2015-05-27 02:22:23 theanets.trainer:168 RmsProp 201 loss=287.634460 err=3.765200
I 2015-05-27 02:22:31 theanets.trainer:168 RmsProp 202 loss=286.861115 err=3.773245
I 2015-05-27 02:22:39 theanets.trainer:168 RmsProp 203 loss=285.848328 err=3.538445
I 2015-05-27 02:22:46 theanets.trainer:168 RmsProp 204 loss=285.385925 err=3.850275
I 2015-05-27 02:22:54 theanets.trainer:168 RmsProp 205 loss=284.549347 err=3.782518
I 2015-05-27 02:23:02 theanets.trainer:168 RmsProp 206 loss=283.689545 err=3.675755
I 2015-05-27 02:23:09 theanets.trainer:168 RmsProp 207 loss=282.811646 err=3.549925
I 2015-05-27 02:23:17 theanets.trainer:168 RmsProp 208 loss=282.200043 err=3.681325
I 2015-05-27 02:23:26 theanets.trainer:168 RmsProp 209 loss=281.446808 err=3.681271
I 2015-05-27 02:23:33 theanets.trainer:168 RmsProp 210 loss=280.675018 err=3.659653
I 2015-05-27 02:23:33 theanets.trainer:168 validation 21 loss=1039.098877 err=762.490845 *
I 2015-05-27 02:23:41 theanets.trainer:168 RmsProp 211 loss=279.902100 err=3.637208
I 2015-05-27 02:23:49 theanets.trainer:168 RmsProp 212 loss=279.164368 err=3.649009
I 2015-05-27 02:23:56 theanets.trainer:168 RmsProp 213 loss=278.418396 err=3.645282
I 2015-05-27 02:24:04 theanets.trainer:168 RmsProp 214 loss=277.662170 err=3.625280
I 2015-05-27 02:24:12 theanets.trainer:168 RmsProp 215 loss=276.930969 err=3.622087
I 2015-05-27 02:24:20 theanets.trainer:168 RmsProp 216 loss=276.165100 err=3.584099
I 2015-05-27 02:24:28 theanets.trainer:168 RmsProp 217 loss=275.514008 err=3.648702
I 2015-05-27 02:24:37 theanets.trainer:168 RmsProp 218 loss=274.699707 err=3.545007
I 2015-05-27 02:24:45 theanets.trainer:168 RmsProp 219 loss=274.054382 err=3.611246
I 2015-05-27 02:24:54 theanets.trainer:168 RmsProp 220 loss=273.293091 err=3.551315
I 2015-05-27 02:24:54 theanets.trainer:168 validation 22 loss=1018.285767 err=748.931580 *
I 2015-05-27 02:25:01 theanets.trainer:168 RmsProp 221 loss=272.726288 err=3.683829
I 2015-05-27 02:25:08 theanets.trainer:168 RmsProp 222 loss=271.998779 err=3.645307
I 2015-05-27 02:25:14 theanets.trainer:168 RmsProp 223 loss=271.202881 err=3.536959
I 2015-05-27 02:25:21 theanets.trainer:168 RmsProp 224 loss=270.549713 err=3.567684
I 2015-05-27 02:25:28 theanets.trainer:168 RmsProp 225 loss=269.911194 err=3.615302
I 2015-05-27 02:25:34 theanets.trainer:168 RmsProp 226 loss=269.086090 err=3.472282
I 2015-05-27 02:25:41 theanets.trainer:168 RmsProp 227 loss=268.484619 err=3.548735
I 2015-05-27 02:25:47 theanets.trainer:168 RmsProp 228 loss=267.772339 err=3.513342
I 2015-05-27 02:25:54 theanets.trainer:168 RmsProp 229 loss=267.090088 err=3.499267
I 2015-05-27 02:26:01 theanets.trainer:168 RmsProp 230 loss=266.411224 err=3.484671
I 2015-05-27 02:26:01 theanets.trainer:168 validation 23 loss=1015.563232 err=753.003113 *
I 2015-05-27 02:26:07 theanets.trainer:168 RmsProp 231 loss=265.760925 err=3.491911
I 2015-05-27 02:26:14 theanets.trainer:168 RmsProp 232 loss=265.034821 err=3.418121
I 2015-05-27 02:26:21 theanets.trainer:168 RmsProp 233 loss=264.476868 err=3.512122
I 2015-05-27 02:26:29 theanets.trainer:168 RmsProp 234 loss=263.851562 err=3.535676
I 2015-05-27 02:26:35 theanets.trainer:168 RmsProp 235 loss=263.146393 err=3.477910
I 2015-05-27 02:26:41 theanets.trainer:168 RmsProp 236 loss=262.454895 err=3.430302
I 2015-05-27 02:26:47 theanets.trainer:168 RmsProp 237 loss=261.814301 err=3.436042
I 2015-05-27 02:26:53 theanets.trainer:168 RmsProp 238 loss=261.251953 err=3.515355
I 2015-05-27 02:26:59 theanets.trainer:168 RmsProp 239 loss=260.725891 err=3.629029
I 2015-05-27 02:27:05 theanets.trainer:168 RmsProp 240 loss=259.889069 err=3.421189
I 2015-05-27 02:27:06 theanets.trainer:168 validation 24 loss=992.819275 err=736.690125 *
I 2015-05-27 02:27:12 theanets.trainer:168 RmsProp 241 loss=259.209656 err=3.366116
I 2015-05-27 02:27:19 theanets.trainer:168 RmsProp 242 loss=258.705139 err=3.493030
I 2015-05-27 02:27:25 theanets.trainer:168 RmsProp 243 loss=257.966797 err=3.381187
I 2015-05-27 02:27:31 theanets.trainer:168 RmsProp 244 loss=257.341675 err=3.376323
I 2015-05-27 02:27:38 theanets.trainer:168 RmsProp 245 loss=256.911194 err=3.564043
I 2015-05-27 02:27:44 theanets.trainer:168 RmsProp 246 loss=256.197235 err=3.466548
I 2015-05-27 02:27:50 theanets.trainer:168 RmsProp 247 loss=255.519821 err=3.397763
I 2015-05-27 02:27:57 theanets.trainer:168 RmsProp 248 loss=254.867798 err=3.357061
I 2015-05-27 02:28:03 theanets.trainer:168 RmsProp 249 loss=254.297409 err=3.400732
I 2015-05-27 02:28:09 theanets.trainer:168 RmsProp 250 loss=253.612427 err=3.318363
I 2015-05-27 02:28:09 theanets.trainer:168 validation 25 loss=994.715332 err=744.751221
I 2015-05-27 02:28:16 theanets.trainer:168 RmsProp 251 loss=253.122482 err=3.426621
I 2015-05-27 02:28:22 theanets.trainer:168 RmsProp 252 loss=252.351364 err=3.254990
I 2015-05-27 02:28:28 theanets.trainer:168 RmsProp 253 loss=251.885208 err=3.391958
I 2015-05-27 02:28:34 theanets.trainer:168 RmsProp 254 loss=251.169556 err=3.284082
I 2015-05-27 02:28:40 theanets.trainer:168 RmsProp 255 loss=250.619217 err=3.335584
I 2015-05-27 02:28:47 theanets.trainer:168 RmsProp 256 loss=250.042633 err=3.361512
I 2015-05-27 02:28:52 theanets.trainer:168 RmsProp 257 loss=249.388580 err=3.302280
I 2015-05-27 02:28:59 theanets.trainer:168 RmsProp 258 loss=248.897018 err=3.405635
I 2015-05-27 02:29:05 theanets.trainer:168 RmsProp 259 loss=248.423553 err=3.506804
I 2015-05-27 02:29:11 theanets.trainer:168 RmsProp 260 loss=247.593842 err=3.252598
I 2015-05-27 02:29:12 theanets.trainer:168 validation 26 loss=979.590759 err=735.565308 *
I 2015-05-27 02:29:17 theanets.trainer:168 RmsProp 261 loss=246.998734 err=3.236205
I 2015-05-27 02:29:24 theanets.trainer:168 RmsProp 262 loss=246.505814 err=3.318129
I 2015-05-27 02:29:30 theanets.trainer:168 RmsProp 263 loss=245.733185 err=3.124641
I 2015-05-27 02:29:36 theanets.trainer:168 RmsProp 264 loss=245.337067 err=3.304011
I 2015-05-27 02:29:42 theanets.trainer:168 RmsProp 265 loss=244.865799 err=3.406102
I 2015-05-27 02:29:48 theanets.trainer:168 RmsProp 266 loss=244.184906 err=3.288293
I 2015-05-27 02:29:54 theanets.trainer:168 RmsProp 267 loss=243.416824 err=3.087895
I 2015-05-27 02:30:01 theanets.trainer:168 RmsProp 268 loss=243.195770 err=3.429519
I 2015-05-27 02:30:07 theanets.trainer:168 RmsProp 269 loss=242.425949 err=3.221290
I 2015-05-27 02:30:13 theanets.trainer:168 RmsProp 270 loss=242.006302 err=3.352595
I 2015-05-27 02:30:13 theanets.trainer:168 validation 27 loss=970.569763 err=732.205444 *
I 2015-05-27 02:30:20 theanets.trainer:168 RmsProp 271 loss=241.464447 err=3.356073
I 2015-05-27 02:30:26 theanets.trainer:168 RmsProp 272 loss=240.787384 err=3.227445
I 2015-05-27 02:30:32 theanets.trainer:168 RmsProp 273 loss=240.339569 err=3.322467
I 2015-05-27 02:30:39 theanets.trainer:168 RmsProp 274 loss=239.655426 err=3.176312
I 2015-05-27 02:30:45 theanets.trainer:168 RmsProp 275 loss=239.181763 err=3.235144
I 2015-05-27 02:30:51 theanets.trainer:168 RmsProp 276 loss=238.930130 err=3.509979
I 2015-05-27 02:30:57 theanets.trainer:168 RmsProp 277 loss=238.024368 err=3.130641
I 2015-05-27 02:31:03 theanets.trainer:168 RmsProp 278 loss=237.598755 err=3.228205
I 2015-05-27 02:31:09 theanets.trainer:168 RmsProp 279 loss=237.147141 err=3.307521
I 2015-05-27 02:31:16 theanets.trainer:168 RmsProp 280 loss=236.563080 err=3.245409
I 2015-05-27 02:31:16 theanets.trainer:168 validation 28 loss=960.771118 err=727.730286 *
I 2015-05-27 02:31:22 theanets.trainer:168 RmsProp 281 loss=236.234497 err=3.426333
I 2015-05-27 02:31:29 theanets.trainer:168 RmsProp 282 loss=235.405029 err=3.112450
I 2015-05-27 02:31:35 theanets.trainer:168 RmsProp 283 loss=235.030640 err=3.252895
I 2015-05-27 02:31:41 theanets.trainer:168 RmsProp 284 loss=234.438568 err=3.177309
I 2015-05-27 02:31:47 theanets.trainer:168 RmsProp 285 loss=233.858932 err=3.104553
I 2015-05-27 02:31:53 theanets.trainer:168 RmsProp 286 loss=233.487183 err=3.238870
I 2015-05-27 02:31:59 theanets.trainer:168 RmsProp 287 loss=232.962372 err=3.221232
I 2015-05-27 02:32:06 theanets.trainer:168 RmsProp 288 loss=232.533035 err=3.291192
I 2015-05-27 02:32:12 theanets.trainer:168 RmsProp 289 loss=231.844391 err=3.098393
I 2015-05-27 02:32:19 theanets.trainer:168 RmsProp 290 loss=231.531082 err=3.282867
I 2015-05-27 02:32:20 theanets.trainer:168 validation 29 loss=931.346985 err=703.374512 *
I 2015-05-27 02:32:25 theanets.trainer:168 RmsProp 291 loss=230.782501 err=3.036969
I 2015-05-27 02:32:31 theanets.trainer:168 RmsProp 292 loss=230.610886 err=3.356802
I 2015-05-27 02:32:38 theanets.trainer:168 RmsProp 293 loss=230.021637 err=3.259287
I 2015-05-27 02:32:44 theanets.trainer:168 RmsProp 294 loss=229.360107 err=3.085545
I 2015-05-27 02:32:50 theanets.trainer:168 RmsProp 295 loss=229.002594 err=3.212411
I 2015-05-27 02:32:56 theanets.trainer:168 RmsProp 296 loss=228.431854 err=3.127415
I 2015-05-27 02:33:03 theanets.trainer:168 RmsProp 297 loss=227.899139 err=3.076300
I 2015-05-27 02:33:09 theanets.trainer:168 RmsProp 298 loss=227.611237 err=3.267179
I 2015-05-27 02:33:16 theanets.trainer:168 RmsProp 299 loss=226.915680 err=3.046233
I 2015-05-27 02:33:22 theanets.trainer:168 RmsProp 300 loss=226.426147 err=3.030712
I 2015-05-27 02:33:22 theanets.trainer:168 validation 30 loss=935.001465 err=711.864014
I 2015-05-27 02:33:29 theanets.trainer:168 RmsProp 301 loss=226.185181 err=3.260849
I 2015-05-27 02:33:35 theanets.trainer:168 RmsProp 302 loss=225.654739 err=3.203385
I 2015-05-27 02:33:41 theanets.trainer:168 RmsProp 303 loss=225.209320 err=3.223379
I 2015-05-27 02:33:47 theanets.trainer:168 RmsProp 304 loss=224.613190 err=3.090837
I 2015-05-27 02:33:53 theanets.trainer:168 RmsProp 305 loss=224.119232 err=3.058426
I 2015-05-27 02:34:00 theanets.trainer:168 RmsProp 306 loss=223.744476 err=3.144479
I 2015-05-27 02:34:06 theanets.trainer:168 RmsProp 307 loss=223.215744 err=3.078167
I 2015-05-27 02:34:12 theanets.trainer:168 RmsProp 308 loss=222.707443 err=3.027865
I 2015-05-27 02:34:18 theanets.trainer:168 RmsProp 309 loss=222.326584 err=3.103393
I 2015-05-27 02:34:24 theanets.trainer:168 RmsProp 310 loss=221.931396 err=3.158536
I 2015-05-27 02:34:24 theanets.trainer:168 validation 31 loss=914.589722 err=696.058594 *
I 2015-05-27 02:34:30 theanets.trainer:168 RmsProp 311 loss=221.573532 err=3.247553
I 2015-05-27 02:34:37 theanets.trainer:168 RmsProp 312 loss=220.918976 err=3.045220
I 2015-05-27 02:34:43 theanets.trainer:168 RmsProp 313 loss=220.403107 err=2.972294
I 2015-05-27 02:34:50 theanets.trainer:168 RmsProp 314 loss=220.152069 err=3.171127
I 2015-05-27 02:34:56 theanets.trainer:168 RmsProp 315 loss=219.634308 err=3.101366
I 2015-05-27 02:35:03 theanets.trainer:168 RmsProp 316 loss=219.136673 err=3.044038
I 2015-05-27 02:35:10 theanets.trainer:168 RmsProp 317 loss=218.722855 err=3.074379
I 2015-05-27 02:35:16 theanets.trainer:168 RmsProp 318 loss=218.185455 err=2.978595
I 2015-05-27 02:35:22 theanets.trainer:168 RmsProp 319 loss=217.816742 err=3.046170
I 2015-05-27 02:35:28 theanets.trainer:168 RmsProp 320 loss=217.377640 err=3.042557
I 2015-05-27 02:35:29 theanets.trainer:168 validation 32 loss=912.305115 err=698.212585 *
I 2015-05-27 02:35:35 theanets.trainer:168 RmsProp 321 loss=216.901947 err=3.003753
I 2015-05-27 02:35:41 theanets.trainer:168 RmsProp 322 loss=216.601807 err=3.135616
I 2015-05-27 02:35:48 theanets.trainer:168 RmsProp 323 loss=215.944061 err=2.912263
I 2015-05-27 02:35:54 theanets.trainer:168 RmsProp 324 loss=215.632721 err=3.034300
I 2015-05-27 02:36:01 theanets.trainer:168 RmsProp 325 loss=215.288086 err=3.121072
I 2015-05-27 02:36:07 theanets.trainer:168 RmsProp 326 loss=214.624802 err=2.886364
I 2015-05-27 02:36:13 theanets.trainer:168 RmsProp 327 loss=214.350922 err=3.032989
I 2015-05-27 02:36:19 theanets.trainer:168 RmsProp 328 loss=213.998535 err=3.093150
I 2015-05-27 02:36:26 theanets.trainer:168 RmsProp 329 loss=213.597900 err=3.105943
I 2015-05-27 02:36:33 theanets.trainer:168 RmsProp 330 loss=213.025482 err=2.948575
I 2015-05-27 02:36:33 theanets.trainer:168 validation 33 loss=905.923340 err=696.076843 *
I 2015-05-27 02:36:39 theanets.trainer:168 RmsProp 331 loss=212.731354 err=3.068448
I 2015-05-27 02:36:46 theanets.trainer:168 RmsProp 332 loss=212.225784 err=2.972313
I 2015-05-27 02:36:52 theanets.trainer:168 RmsProp 333 loss=211.788284 err=2.939234
I 2015-05-27 02:36:57 theanets.trainer:168 RmsProp 334 loss=211.433441 err=2.987224
I 2015-05-27 02:37:03 theanets.trainer:168 RmsProp 335 loss=211.084351 err=3.045916
I 2015-05-27 02:37:09 theanets.trainer:168 RmsProp 336 loss=210.753342 err=3.119826
I 2015-05-27 02:37:16 theanets.trainer:168 RmsProp 337 loss=210.303802 err=3.067645
I 2015-05-27 02:37:23 theanets.trainer:168 RmsProp 338 loss=209.715607 err=2.871947
I 2015-05-27 02:37:29 theanets.trainer:168 RmsProp 339 loss=209.430084 err=2.985010
I 2015-05-27 02:37:35 theanets.trainer:168 RmsProp 340 loss=209.133392 err=3.087975
I 2015-05-27 02:37:35 theanets.trainer:168 validation 34 loss=891.970886 err=686.143677 *
I 2015-05-27 02:37:41 theanets.trainer:168 RmsProp 341 loss=208.516159 err=2.861586
I 2015-05-27 02:37:47 theanets.trainer:168 RmsProp 342 loss=208.256668 err=2.996341
I 2015-05-27 02:37:53 theanets.trainer:168 RmsProp 343 loss=207.909744 err=3.038338
I 2015-05-27 02:37:59 theanets.trainer:168 RmsProp 344 loss=207.469940 err=2.985268
I 2015-05-27 02:38:05 theanets.trainer:168 RmsProp 345 loss=206.933014 err=2.836723
I 2015-05-27 02:38:11 theanets.trainer:168 RmsProp 346 loss=206.728683 err=3.012426
I 2015-05-27 02:38:17 theanets.trainer:168 RmsProp 347 loss=206.324371 err=2.990126
I 2015-05-27 02:38:24 theanets.trainer:168 RmsProp 348 loss=205.979828 err=3.018166
I 2015-05-27 02:38:30 theanets.trainer:168 RmsProp 349 loss=205.491425 err=2.905851
I 2015-05-27 02:38:36 theanets.trainer:168 RmsProp 350 loss=205.266083 err=3.059682
I 2015-05-27 02:38:36 theanets.trainer:168 validation 35 loss=895.599548 err=693.596252
I 2015-05-27 02:38:42 theanets.trainer:168 RmsProp 351 loss=204.827927 err=3.000783
I 2015-05-27 02:38:48 theanets.trainer:168 RmsProp 352 loss=204.375275 err=2.921135
I 2015-05-27 02:38:54 theanets.trainer:168 RmsProp 353 loss=204.125687 err=3.042264
I 2015-05-27 02:39:01 theanets.trainer:168 RmsProp 354 loss=203.512375 err=2.802806
I 2015-05-27 02:39:06 theanets.trainer:168 RmsProp 355 loss=203.406082 err=3.063775
I 2015-05-27 02:39:13 theanets.trainer:168 RmsProp 356 loss=202.964508 err=2.989546
I 2015-05-27 02:39:19 theanets.trainer:168 RmsProp 357 loss=202.440979 err=2.826233
I 2015-05-27 02:39:25 theanets.trainer:168 RmsProp 358 loss=201.987564 err=2.736087
I 2015-05-27 02:39:30 theanets.trainer:168 RmsProp 359 loss=202.047287 err=3.163049
I 2015-05-27 02:39:36 theanets.trainer:168 RmsProp 360 loss=201.389709 err=2.872467
I 2015-05-27 02:39:37 theanets.trainer:168 validation 36 loss=874.616455 err=676.294128 *
I 2015-05-27 02:39:43 theanets.trainer:168 RmsProp 361 loss=201.143753 err=2.986187
I 2015-05-27 02:39:49 theanets.trainer:168 RmsProp 362 loss=200.722473 err=2.922717
I 2015-05-27 02:39:55 theanets.trainer:168 RmsProp 363 loss=200.243439 err=2.802884
I 2015-05-27 02:40:01 theanets.trainer:168 RmsProp 364 loss=199.914429 err=2.829430
I 2015-05-27 02:40:07 theanets.trainer:168 RmsProp 365 loss=199.677200 err=2.949082
I 2015-05-27 02:40:14 theanets.trainer:168 RmsProp 366 loss=199.199127 err=2.831704
I 2015-05-27 02:40:20 theanets.trainer:168 RmsProp 367 loss=198.906433 err=2.896673
I 2015-05-27 02:40:26 theanets.trainer:168 RmsProp 368 loss=198.527344 err=2.875327
I 2015-05-27 02:40:32 theanets.trainer:168 RmsProp 369 loss=198.081436 err=2.782619
I 2015-05-27 02:40:38 theanets.trainer:168 RmsProp 370 loss=197.908264 err=2.961616
I 2015-05-27 02:40:39 theanets.trainer:168 validation 37 loss=881.840942 err=687.090942
I 2015-05-27 02:40:45 theanets.trainer:168 RmsProp 371 loss=197.465179 err=2.869539
I 2015-05-27 02:40:51 theanets.trainer:168 RmsProp 372 loss=197.366089 err=3.116304
I 2015-05-27 02:40:57 theanets.trainer:168 RmsProp 373 loss=196.847229 err=2.939258
I 2015-05-27 02:41:04 theanets.trainer:168 RmsProp 374 loss=196.306625 err=2.738345
I 2015-05-27 02:41:10 theanets.trainer:168 RmsProp 375 loss=196.095520 err=2.866740
I 2015-05-27 02:41:16 theanets.trainer:168 RmsProp 376 loss=195.749588 err=2.857312
I 2015-05-27 02:41:23 theanets.trainer:168 RmsProp 377 loss=195.668671 err=3.110712
I 2015-05-27 02:41:29 theanets.trainer:168 RmsProp 378 loss=195.048706 err=2.825833
I 2015-05-27 02:41:36 theanets.trainer:168 RmsProp 379 loss=194.672150 err=2.785071
I 2015-05-27 02:41:42 theanets.trainer:168 RmsProp 380 loss=194.521896 err=2.970592
I 2015-05-27 02:41:43 theanets.trainer:168 validation 38 loss=862.463379 err=671.095703 *
I 2015-05-27 02:41:48 theanets.trainer:168 RmsProp 381 loss=194.078613 err=2.860487
I 2015-05-27 02:41:55 theanets.trainer:168 RmsProp 382 loss=193.528793 err=2.640798
I 2015-05-27 02:42:01 theanets.trainer:168 RmsProp 383 loss=193.595062 err=3.031499
I 2015-05-27 02:42:06 theanets.trainer:168 RmsProp 384 loss=193.104095 err=2.872242
I 2015-05-27 02:42:12 theanets.trainer:168 RmsProp 385 loss=192.609222 err=2.706048
I 2015-05-27 02:42:19 theanets.trainer:168 RmsProp 386 loss=192.583908 err=3.006161
I 2015-05-27 02:42:25 theanets.trainer:168 RmsProp 387 loss=192.103973 err=2.855507
I 2015-05-27 02:42:31 theanets.trainer:168 RmsProp 388 loss=191.522125 err=2.604604
I 2015-05-27 02:42:37 theanets.trainer:168 RmsProp 389 loss=191.411972 err=2.823842
I 2015-05-27 02:42:44 theanets.trainer:168 RmsProp 390 loss=191.094315 err=2.833323
I 2015-05-27 02:42:44 theanets.trainer:168 validation 39 loss=871.653748 err=683.556946
I 2015-05-27 02:42:51 theanets.trainer:168 RmsProp 391 loss=191.047531 err=3.104639
I 2015-05-27 02:42:58 theanets.trainer:168 RmsProp 392 loss=190.319901 err=2.692495
I 2015-05-27 02:43:04 theanets.trainer:168 RmsProp 393 loss=190.075775 err=2.765259
I 2015-05-27 02:43:10 theanets.trainer:168 RmsProp 394 loss=189.759827 err=2.767882
I 2015-05-27 02:43:16 theanets.trainer:168 RmsProp 395 loss=189.514221 err=2.837056
I 2015-05-27 02:43:23 theanets.trainer:168 RmsProp 396 loss=189.297089 err=2.935000
I 2015-05-27 02:43:29 theanets.trainer:168 RmsProp 397 loss=188.638824 err=2.589818
I 2015-05-27 02:43:35 theanets.trainer:168 RmsProp 398 loss=188.604858 err=2.870983
I 2015-05-27 02:43:41 theanets.trainer:168 RmsProp 399 loss=188.156464 err=2.739372
I 2015-05-27 02:43:47 theanets.trainer:168 RmsProp 400 loss=187.973114 err=2.868968
I 2015-05-27 02:43:47 theanets.trainer:168 validation 40 loss=850.758240 err=665.831970 *
I 2015-05-27 02:43:53 theanets.trainer:168 RmsProp 401 loss=187.548981 err=2.757589
I 2015-05-27 02:44:00 theanets.trainer:168 RmsProp 402 loss=187.248138 err=2.765944
I 2015-05-27 02:44:05 theanets.trainer:168 RmsProp 403 loss=186.953217 err=2.781635
I 2015-05-27 02:44:12 theanets.trainer:168 RmsProp 404 loss=186.925339 err=3.059968
I 2015-05-27 02:44:19 theanets.trainer:168 RmsProp 405 loss=186.276657 err=2.715497
I 2015-05-27 02:44:25 theanets.trainer:168 RmsProp 406 loss=185.848297 err=2.588866
I 2015-05-27 02:44:31 theanets.trainer:168 RmsProp 407 loss=186.115158 err=3.155485
I 2015-05-27 02:44:37 theanets.trainer:168 RmsProp 408 loss=185.366989 err=2.708825
I 2015-05-27 02:44:44 theanets.trainer:168 RmsProp 409 loss=185.002686 err=2.641504
I 2015-05-27 02:44:51 theanets.trainer:168 RmsProp 410 loss=184.992996 err=2.929563
I 2015-05-27 02:44:51 theanets.trainer:168 validation 41 loss=854.797424 err=672.896118
I 2015-05-27 02:44:57 theanets.trainer:168 RmsProp 411 loss=184.559387 err=2.792218
I 2015-05-27 02:45:03 theanets.trainer:168 RmsProp 412 loss=184.157013 err=2.686644
I 2015-05-27 02:45:09 theanets.trainer:168 RmsProp 413 loss=184.163437 err=2.984216
I 2015-05-27 02:45:15 theanets.trainer:168 RmsProp 414 loss=183.640778 err=2.756498
I 2015-05-27 02:45:21 theanets.trainer:168 RmsProp 415 loss=183.353394 err=2.758938
I 2015-05-27 02:45:28 theanets.trainer:168 RmsProp 416 loss=183.017914 err=2.715528
I 2015-05-27 02:45:34 theanets.trainer:168 RmsProp 417 loss=182.827026 err=2.817783
I 2015-05-27 02:45:41 theanets.trainer:168 RmsProp 418 loss=182.460968 err=2.739203
I 2015-05-27 02:45:48 theanets.trainer:168 RmsProp 419 loss=182.083878 err=2.649701
I 2015-05-27 02:45:54 theanets.trainer:168 RmsProp 420 loss=181.866943 err=2.720375
I 2015-05-27 02:45:55 theanets.trainer:168 validation 42 loss=843.035950 err=664.049744 *
I 2015-05-27 02:46:01 theanets.trainer:168 RmsProp 421 loss=181.661118 err=2.806388
I 2015-05-27 02:46:07 theanets.trainer:168 RmsProp 422 loss=181.268463 err=2.707535
I 2015-05-27 02:46:13 theanets.trainer:168 RmsProp 423 loss=181.097260 err=2.828091
I 2015-05-27 02:46:20 theanets.trainer:168 RmsProp 424 loss=180.607330 err=2.627855
I 2015-05-27 02:46:26 theanets.trainer:168 RmsProp 425 loss=180.458832 err=2.766773
I 2015-05-27 02:46:33 theanets.trainer:168 RmsProp 426 loss=180.140411 err=2.737749
I 2015-05-27 02:46:38 theanets.trainer:168 RmsProp 427 loss=179.855118 err=2.735979
I 2015-05-27 02:46:45 theanets.trainer:168 RmsProp 428 loss=179.559891 err=2.728677
I 2015-05-27 02:46:52 theanets.trainer:168 RmsProp 429 loss=179.309784 err=2.762338
I 2015-05-27 02:46:58 theanets.trainer:168 RmsProp 430 loss=178.851212 err=2.581642
I 2015-05-27 02:46:58 theanets.trainer:168 validation 43 loss=837.847961 err=661.730713 *
I 2015-05-27 02:47:04 theanets.trainer:168 RmsProp 431 loss=178.935394 err=2.938035
I 2015-05-27 02:47:10 theanets.trainer:168 RmsProp 432 loss=178.348083 err=2.626039
I 2015-05-27 02:47:17 theanets.trainer:168 RmsProp 433 loss=178.283203 err=2.833937
I 2015-05-27 02:47:23 theanets.trainer:168 RmsProp 434 loss=178.027237 err=2.850317
I 2015-05-27 02:47:30 theanets.trainer:168 RmsProp 435 loss=177.503708 err=2.600070
I 2015-05-27 02:47:37 theanets.trainer:168 RmsProp 436 loss=177.328812 err=2.690921
I 2015-05-27 02:47:43 theanets.trainer:168 RmsProp 437 loss=177.112320 err=2.744509
I 2015-05-27 02:47:50 theanets.trainer:168 RmsProp 438 loss=176.854477 err=2.758033
I 2015-05-27 02:47:56 theanets.trainer:168 RmsProp 439 loss=176.519318 err=2.694000
I 2015-05-27 02:48:02 theanets.trainer:168 RmsProp 440 loss=176.369583 err=2.812118
I 2015-05-27 02:48:02 theanets.trainer:168 validation 44 loss=842.277710 err=668.860168
I 2015-05-27 02:48:08 theanets.trainer:168 RmsProp 441 loss=176.122223 err=2.828597
I 2015-05-27 02:48:14 theanets.trainer:168 RmsProp 442 loss=175.701492 err=2.677125
I 2015-05-27 02:48:21 theanets.trainer:168 RmsProp 443 loss=175.463959 err=2.703318
I 2015-05-27 02:48:27 theanets.trainer:168 RmsProp 444 loss=175.123886 err=2.624703
I 2015-05-27 02:48:33 theanets.trainer:168 RmsProp 445 loss=174.919861 err=2.683918
I 2015-05-27 02:48:40 theanets.trainer:168 RmsProp 446 loss=174.621735 err=2.648982
I 2015-05-27 02:48:46 theanets.trainer:168 RmsProp 447 loss=174.480621 err=2.774433
I 2015-05-27 02:48:52 theanets.trainer:168 RmsProp 448 loss=174.051254 err=2.608854
I 2015-05-27 02:48:59 theanets.trainer:168 RmsProp 449 loss=174.021530 err=2.839111
I 2015-05-27 02:49:05 theanets.trainer:168 RmsProp 450 loss=173.779129 err=2.857338
I 2015-05-27 02:49:06 theanets.trainer:168 validation 45 loss=828.470886 err=657.684692 *
I 2015-05-27 02:49:12 theanets.trainer:168 RmsProp 451 loss=173.262894 err=2.599644
I 2015-05-27 02:49:18 theanets.trainer:168 RmsProp 452 loss=173.046936 err=2.643742
I 2015-05-27 02:49:24 theanets.trainer:168 RmsProp 453 loss=172.769577 err=2.624731
I 2015-05-27 02:49:30 theanets.trainer:168 RmsProp 454 loss=172.495270 err=2.609520
I 2015-05-27 02:49:37 theanets.trainer:168 RmsProp 455 loss=172.265549 err=2.640048
I 2015-05-27 02:49:43 theanets.trainer:168 RmsProp 456 loss=172.188324 err=2.818983
I 2015-05-27 02:49:49 theanets.trainer:168 RmsProp 457 loss=171.761261 err=2.648679
I 2015-05-27 02:49:55 theanets.trainer:168 RmsProp 458 loss=171.513382 err=2.651970
I 2015-05-27 02:50:01 theanets.trainer:168 RmsProp 459 loss=171.210358 err=2.603704
I 2015-05-27 02:50:08 theanets.trainer:168 RmsProp 460 loss=171.027588 err=2.668904
I 2015-05-27 02:50:08 theanets.trainer:168 validation 46 loss=837.603210 err=669.376770
I 2015-05-27 02:50:15 theanets.trainer:168 RmsProp 461 loss=170.955490 err=2.844318
I 2015-05-27 02:50:21 theanets.trainer:168 RmsProp 462 loss=170.628464 err=2.764184
I 2015-05-27 02:50:27 theanets.trainer:168 RmsProp 463 loss=170.207581 err=2.591474
I 2015-05-27 02:50:33 theanets.trainer:168 RmsProp 464 loss=169.975586 err=2.606450
I 2015-05-27 02:50:40 theanets.trainer:168 RmsProp 465 loss=169.846817 err=2.725017
I 2015-05-27 02:50:46 theanets.trainer:168 RmsProp 466 loss=169.424438 err=2.553054
I 2015-05-27 02:50:52 theanets.trainer:168 RmsProp 467 loss=169.354126 err=2.726571
I 2015-05-27 02:50:59 theanets.trainer:168 RmsProp 468 loss=168.918106 err=2.534513
I 2015-05-27 02:51:05 theanets.trainer:168 RmsProp 469 loss=168.714737 err=2.574597
I 2015-05-27 02:51:12 theanets.trainer:168 RmsProp 470 loss=168.629517 err=2.730198
I 2015-05-27 02:51:12 theanets.trainer:168 validation 47 loss=820.449341 err=654.688110 *
I 2015-05-27 02:51:18 theanets.trainer:168 RmsProp 471 loss=168.264313 err=2.610239
I 2015-05-27 02:51:25 theanets.trainer:168 RmsProp 472 loss=168.038239 err=2.626928
I 2015-05-27 02:51:31 theanets.trainer:168 RmsProp 473 loss=167.924728 err=2.756906
I 2015-05-27 02:51:37 theanets.trainer:168 RmsProp 474 loss=167.668060 err=2.737397
I 2015-05-27 02:51:44 theanets.trainer:168 RmsProp 475 loss=167.513611 err=2.821777
I 2015-05-27 02:51:50 theanets.trainer:168 RmsProp 476 loss=166.996368 err=2.537548
I 2015-05-27 02:51:56 theanets.trainer:168 RmsProp 477 loss=166.684525 err=2.462001
I 2015-05-27 02:52:02 theanets.trainer:168 RmsProp 478 loss=166.675705 err=2.689339
I 2015-05-27 02:52:09 theanets.trainer:168 RmsProp 479 loss=166.268707 err=2.520434
I 2015-05-27 02:52:16 theanets.trainer:168 RmsProp 480 loss=166.151031 err=2.644385
I 2015-05-27 02:52:16 theanets.trainer:168 validation 48 loss=824.185364 err=660.814392
I 2015-05-27 02:52:22 theanets.trainer:168 RmsProp 481 loss=165.988342 err=2.723461
I 2015-05-27 02:52:28 theanets.trainer:168 RmsProp 482 loss=165.640839 err=2.611869
I 2015-05-27 02:52:35 theanets.trainer:168 RmsProp 483 loss=165.537659 err=2.738642
I 2015-05-27 02:52:41 theanets.trainer:168 RmsProp 484 loss=165.273087 err=2.706038
I 2015-05-27 02:52:46 theanets.trainer:168 RmsProp 485 loss=164.961685 err=2.627778
I 2015-05-27 02:52:52 theanets.trainer:168 RmsProp 486 loss=164.716019 err=2.613148
I 2015-05-27 02:52:59 theanets.trainer:168 RmsProp 487 loss=164.459442 err=2.581558
I 2015-05-27 02:53:06 theanets.trainer:168 RmsProp 488 loss=164.168823 err=2.519132
I 2015-05-27 02:53:12 theanets.trainer:168 RmsProp 489 loss=163.973145 err=2.554779
I 2015-05-27 02:53:18 theanets.trainer:168 RmsProp 490 loss=163.849594 err=2.660500
I 2015-05-27 02:53:19 theanets.trainer:168 validation 49 loss=818.963562 err=657.902832 *
I 2015-05-27 02:53:25 theanets.trainer:168 RmsProp 491 loss=163.507797 err=2.549139
I 2015-05-27 02:53:31 theanets.trainer:168 RmsProp 492 loss=163.315765 err=2.588116
I 2015-05-27 02:53:38 theanets.trainer:168 RmsProp 493 loss=163.313324 err=2.808856
I 2015-05-27 02:53:44 theanets.trainer:168 RmsProp 494 loss=162.933746 err=2.653656
I 2015-05-27 02:53:51 theanets.trainer:168 RmsProp 495 loss=162.581406 err=2.524146
I 2015-05-27 02:53:57 theanets.trainer:168 RmsProp 496 loss=162.376251 err=2.543479
I 2015-05-27 02:54:02 theanets.trainer:168 RmsProp 497 loss=162.284149 err=2.673192
I 2015-05-27 02:54:08 theanets.trainer:168 RmsProp 498 loss=161.931061 err=2.541673
I 2015-05-27 02:54:14 theanets.trainer:168 RmsProp 499 loss=161.695755 err=2.532004
I 2015-05-27 02:54:20 theanets.trainer:168 RmsProp 500 loss=161.757553 err=2.813610
I 2015-05-27 02:54:20 theanets.trainer:168 validation 50 loss=818.949158 err=660.124207 *
I 2015-05-27 02:54:27 theanets.trainer:168 RmsProp 501 loss=161.375290 err=2.648457
I 2015-05-27 02:54:33 theanets.trainer:168 RmsProp 502 loss=160.955658 err=2.444959
I 2015-05-27 02:54:39 theanets.trainer:168 RmsProp 503 loss=160.806366 err=2.514024
I 2015-05-27 02:54:45 theanets.trainer:168 RmsProp 504 loss=160.717926 err=2.642421
I 2015-05-27 02:54:51 theanets.trainer:168 RmsProp 505 loss=160.604568 err=2.743719
I 2015-05-27 02:54:57 theanets.trainer:168 RmsProp 506 loss=160.301544 err=2.653756
I 2015-05-27 02:55:04 theanets.trainer:168 RmsProp 507 loss=159.941101 err=2.510620
I 2015-05-27 02:55:10 theanets.trainer:168 RmsProp 508 loss=159.740616 err=2.526134
I 2015-05-27 02:55:16 theanets.trainer:168 RmsProp 509 loss=159.508591 err=2.511987
I 2015-05-27 02:55:22 theanets.trainer:168 RmsProp 510 loss=159.206757 err=2.430731
I 2015-05-27 02:55:22 theanets.trainer:168 validation 51 loss=808.787170 err=652.119263 *
I 2015-05-27 02:55:28 theanets.trainer:168 RmsProp 511 loss=159.050690 err=2.493708
I 2015-05-27 02:55:35 theanets.trainer:168 RmsProp 512 loss=158.991119 err=2.652317
I 2015-05-27 02:55:41 theanets.trainer:168 RmsProp 513 loss=158.837524 err=2.715550
I 2015-05-27 02:55:47 theanets.trainer:168 RmsProp 514 loss=158.387177 err=2.477096
I 2015-05-27 02:55:53 theanets.trainer:168 RmsProp 515 loss=158.329651 err=2.631705
I 2015-05-27 02:55:59 theanets.trainer:168 RmsProp 516 loss=157.860596 err=2.371922
I 2015-05-27 02:56:05 theanets.trainer:168 RmsProp 517 loss=157.853607 err=2.578013
I 2015-05-27 02:56:12 theanets.trainer:168 RmsProp 518 loss=157.587906 err=2.526411
I 2015-05-27 02:56:18 theanets.trainer:168 RmsProp 519 loss=157.408340 err=2.560735
I 2015-05-27 02:56:24 theanets.trainer:168 RmsProp 520 loss=157.115753 err=2.483777
I 2015-05-27 02:56:25 theanets.trainer:168 validation 52 loss=807.328186 err=652.807129 *
I 2015-05-27 02:56:31 theanets.trainer:168 RmsProp 521 loss=156.873932 err=2.453493
I 2015-05-27 02:56:37 theanets.trainer:168 RmsProp 522 loss=156.627350 err=2.422628
I 2015-05-27 02:56:43 theanets.trainer:168 RmsProp 523 loss=156.623459 err=2.629427
I 2015-05-27 02:56:50 theanets.trainer:168 RmsProp 524 loss=156.316193 err=2.532859
I 2015-05-27 02:56:57 theanets.trainer:168 RmsProp 525 loss=156.258347 err=2.680535
I 2015-05-27 02:57:03 theanets.trainer:168 RmsProp 526 loss=155.835968 err=2.465727
I 2015-05-27 02:57:10 theanets.trainer:168 RmsProp 527 loss=155.647949 err=2.486496
I 2015-05-27 02:57:16 theanets.trainer:168 RmsProp 528 loss=155.535645 err=2.582943
I 2015-05-27 02:57:22 theanets.trainer:168 RmsProp 529 loss=155.311325 err=2.565961
I 2015-05-27 02:57:28 theanets.trainer:168 RmsProp 530 loss=155.020294 err=2.477372
I 2015-05-27 02:57:29 theanets.trainer:168 validation 53 loss=811.979614 err=659.553772
I 2015-05-27 02:57:35 theanets.trainer:168 RmsProp 531 loss=154.900604 err=2.566087
I 2015-05-27 02:57:41 theanets.trainer:168 RmsProp 532 loss=154.634094 err=2.503281
I 2015-05-27 02:57:48 theanets.trainer:168 RmsProp 533 loss=154.728561 err=2.798396
I 2015-05-27 02:57:54 theanets.trainer:168 RmsProp 534 loss=154.191528 err=2.463847
I 2015-05-27 02:58:01 theanets.trainer:168 RmsProp 535 loss=153.992447 err=2.462906
I 2015-05-27 02:58:07 theanets.trainer:168 RmsProp 536 loss=153.855316 err=2.527205
I 2015-05-27 02:58:14 theanets.trainer:168 RmsProp 537 loss=153.532227 err=2.405688
I 2015-05-27 02:58:20 theanets.trainer:168 RmsProp 538 loss=153.515686 err=2.589553
I 2015-05-27 02:58:26 theanets.trainer:168 RmsProp 539 loss=153.188980 err=2.462037
I 2015-05-27 02:58:32 theanets.trainer:168 RmsProp 540 loss=153.022919 err=2.499009
I 2015-05-27 02:58:33 theanets.trainer:168 validation 54 loss=803.848145 err=653.434021 *
I 2015-05-27 02:58:39 theanets.trainer:168 RmsProp 541 loss=153.044678 err=2.718946
I 2015-05-27 02:58:45 theanets.trainer:168 RmsProp 542 loss=152.781296 err=2.649767
I 2015-05-27 02:58:52 theanets.trainer:168 RmsProp 543 loss=152.420822 err=2.484904
I 2015-05-27 02:58:59 theanets.trainer:168 RmsProp 544 loss=152.219864 err=2.472311
I 2015-05-27 02:59:05 theanets.trainer:168 RmsProp 545 loss=152.382843 err=2.824769
I 2015-05-27 02:59:11 theanets.trainer:168 RmsProp 546 loss=151.797318 err=2.431723
I 2015-05-27 02:59:17 theanets.trainer:168 RmsProp 547 loss=151.543793 err=2.371850
I 2015-05-27 02:59:23 theanets.trainer:168 RmsProp 548 loss=151.623581 err=2.643550
I 2015-05-27 02:59:29 theanets.trainer:168 RmsProp 549 loss=151.184174 err=2.399089
I 2015-05-27 02:59:36 theanets.trainer:168 RmsProp 550 loss=151.025238 err=2.436506
I 2015-05-27 02:59:36 theanets.trainer:168 validation 55 loss=814.955872 err=666.462952
I 2015-05-27 02:59:43 theanets.trainer:168 RmsProp 551 loss=151.084549 err=2.686554
I 2015-05-27 02:59:49 theanets.trainer:168 RmsProp 552 loss=150.641159 err=2.436733
I 2015-05-27 02:59:55 theanets.trainer:168 RmsProp 553 loss=150.494293 err=2.476389
I 2015-05-27 03:00:01 theanets.trainer:168 RmsProp 554 loss=150.436646 err=2.604124
I 2015-05-27 03:00:07 theanets.trainer:168 RmsProp 555 loss=150.098801 err=2.455682
I 2015-05-27 03:00:13 theanets.trainer:168 RmsProp 556 loss=150.165176 err=2.704104
I 2015-05-27 03:00:19 theanets.trainer:168 RmsProp 557 loss=149.528641 err=2.259519
I 2015-05-27 03:00:25 theanets.trainer:168 RmsProp 558 loss=149.683716 err=2.603386
I 2015-05-27 03:00:31 theanets.trainer:168 RmsProp 559 loss=149.492096 err=2.597615
I 2015-05-27 03:00:37 theanets.trainer:168 RmsProp 560 loss=149.274628 err=2.561393
I 2015-05-27 03:00:37 theanets.trainer:168 validation 56 loss=807.592041 err=660.973450
I 2015-05-27 03:00:42 theanets.trainer:168 RmsProp 561 loss=149.051483 err=2.524588
I 2015-05-27 03:00:47 theanets.trainer:168 RmsProp 562 loss=148.803268 err=2.464217
I 2015-05-27 03:00:52 theanets.trainer:168 RmsProp 563 loss=148.683411 err=2.526956
I 2015-05-27 03:00:56 theanets.trainer:168 RmsProp 564 loss=148.476074 err=2.503970
I 2015-05-27 03:01:01 theanets.trainer:168 RmsProp 565 loss=148.289505 err=2.497355
I 2015-05-27 03:01:05 theanets.trainer:168 RmsProp 566 loss=147.912537 err=2.301916
I 2015-05-27 03:01:09 theanets.trainer:168 RmsProp 567 loss=147.978714 err=2.550853
I 2015-05-27 03:01:13 theanets.trainer:168 RmsProp 568 loss=147.868866 err=2.622618
I 2015-05-27 03:01:17 theanets.trainer:168 RmsProp 569 loss=147.576523 err=2.513165
I 2015-05-27 03:01:21 theanets.trainer:168 RmsProp 570 loss=147.240005 err=2.358677
I 2015-05-27 03:01:21 theanets.trainer:168 validation 57 loss=802.289185 err=657.509277 *
I 2015-05-27 03:01:25 theanets.trainer:168 RmsProp 571 loss=147.157288 err=2.455567
I 2015-05-27 03:01:29 theanets.trainer:168 RmsProp 572 loss=147.031799 err=2.507958
I 2015-05-27 03:01:34 theanets.trainer:168 RmsProp 573 loss=146.782883 err=2.440314
I 2015-05-27 03:01:37 theanets.trainer:168 RmsProp 574 loss=146.834808 err=2.665314
I 2015-05-27 03:01:41 theanets.trainer:168 RmsProp 575 loss=146.480667 err=2.489441
I 2015-05-27 03:01:45 theanets.trainer:168 RmsProp 576 loss=146.275543 err=2.460859
I 2015-05-27 03:01:50 theanets.trainer:168 RmsProp 577 loss=145.997467 err=2.359941
I 2015-05-27 03:01:53 theanets.trainer:168 RmsProp 578 loss=145.867279 err=2.405764
I 2015-05-27 03:01:58 theanets.trainer:168 RmsProp 579 loss=145.640228 err=2.354117
I 2015-05-27 03:02:02 theanets.trainer:168 RmsProp 580 loss=145.544098 err=2.432910
I 2015-05-27 03:02:02 theanets.trainer:168 validation 58 loss=795.816284 err=652.807434 *
I 2015-05-27 03:02:06 theanets.trainer:168 RmsProp 581 loss=145.564056 err=2.627256
I 2015-05-27 03:02:11 theanets.trainer:168 RmsProp 582 loss=145.231537 err=2.470966
I 2015-05-27 03:02:15 theanets.trainer:168 RmsProp 583 loss=145.065338 err=2.478233
I 2015-05-27 03:02:19 theanets.trainer:168 RmsProp 584 loss=144.736755 err=2.323505
I 2015-05-27 03:02:23 theanets.trainer:168 RmsProp 585 loss=144.783432 err=2.542879
I 2015-05-27 03:02:27 theanets.trainer:168 RmsProp 586 loss=144.573730 err=2.503070
I 2015-05-27 03:02:31 theanets.trainer:168 RmsProp 587 loss=144.515121 err=2.613500
I 2015-05-27 03:02:35 theanets.trainer:168 RmsProp 588 loss=144.065948 err=2.338479
I 2015-05-27 03:02:39 theanets.trainer:168 RmsProp 589 loss=144.017731 err=2.456481
I 2015-05-27 03:02:43 theanets.trainer:168 RmsProp 590 loss=143.680893 err=2.289294
I 2015-05-27 03:02:43 theanets.trainer:168 validation 59 loss=801.224731 err=659.928162
I 2015-05-27 03:02:47 theanets.trainer:168 RmsProp 591 loss=143.742020 err=2.518894
I 2015-05-27 03:02:51 theanets.trainer:168 RmsProp 592 loss=143.515289 err=2.463385
I 2015-05-27 03:02:55 theanets.trainer:168 RmsProp 593 loss=143.503830 err=2.614706
I 2015-05-27 03:02:59 theanets.trainer:168 RmsProp 594 loss=143.178452 err=2.456439
I 2015-05-27 03:03:03 theanets.trainer:168 RmsProp 595 loss=142.895615 err=2.340567
I 2015-05-27 03:03:07 theanets.trainer:168 RmsProp 596 loss=142.888519 err=2.498916
I 2015-05-27 03:03:12 theanets.trainer:168 RmsProp 597 loss=142.568436 err=2.348752
I 2015-05-27 03:03:16 theanets.trainer:168 RmsProp 598 loss=142.390915 err=2.338789
I 2015-05-27 03:03:21 theanets.trainer:168 RmsProp 599 loss=142.442780 err=2.556523
I 2015-05-27 03:03:25 theanets.trainer:168 RmsProp 600 loss=142.391449 err=2.668223
I 2015-05-27 03:03:25 theanets.trainer:168 validation 60 loss=795.353333 err=655.719360 *
I 2015-05-27 03:03:29 theanets.trainer:168 RmsProp 601 loss=141.845383 err=2.285084
I 2015-05-27 03:03:33 theanets.trainer:168 RmsProp 602 loss=141.822723 err=2.420899
I 2015-05-27 03:03:38 theanets.trainer:168 RmsProp 603 loss=141.590744 err=2.351888
I 2015-05-27 03:03:42 theanets.trainer:168 RmsProp 604 loss=141.613602 err=2.536396
I 2015-05-27 03:03:46 theanets.trainer:168 RmsProp 605 loss=141.323639 err=2.409086
I 2015-05-27 03:03:50 theanets.trainer:168 RmsProp 606 loss=141.128448 err=2.376679
I 2015-05-27 03:03:54 theanets.trainer:168 RmsProp 607 loss=141.079239 err=2.491760
I 2015-05-27 03:03:58 theanets.trainer:168 RmsProp 608 loss=140.918915 err=2.494211
I 2015-05-27 03:04:02 theanets.trainer:168 RmsProp 609 loss=140.680313 err=2.413140
I 2015-05-27 03:04:06 theanets.trainer:168 RmsProp 610 loss=140.606491 err=2.500213
I 2015-05-27 03:04:06 theanets.trainer:168 validation 61 loss=794.821716 err=656.812683 *
I 2015-05-27 03:04:10 theanets.trainer:168 RmsProp 611 loss=140.249481 err=2.304039
I 2015-05-27 03:04:15 theanets.trainer:168 RmsProp 612 loss=140.121201 err=2.335120
I 2015-05-27 03:04:18 theanets.trainer:168 RmsProp 613 loss=140.123489 err=2.493969
I 2015-05-27 03:04:22 theanets.trainer:168 RmsProp 614 loss=139.841293 err=2.368693
I 2015-05-27 03:04:26 theanets.trainer:168 RmsProp 615 loss=139.722137 err=2.407826
I 2015-05-27 03:04:30 theanets.trainer:168 RmsProp 616 loss=139.654587 err=2.495912
I 2015-05-27 03:04:34 theanets.trainer:168 RmsProp 617 loss=139.340912 err=2.342836
I 2015-05-27 03:04:38 theanets.trainer:168 RmsProp 618 loss=139.346008 err=2.504205
I 2015-05-27 03:04:42 theanets.trainer:168 RmsProp 619 loss=139.055054 err=2.370539
I 2015-05-27 03:04:45 theanets.trainer:168 RmsProp 620 loss=138.902344 err=2.374954
I 2015-05-27 03:04:46 theanets.trainer:168 validation 62 loss=796.687561 err=660.247742
I 2015-05-27 03:04:49 theanets.trainer:168 RmsProp 621 loss=138.840668 err=2.466867
I 2015-05-27 03:04:53 theanets.trainer:168 RmsProp 622 loss=138.639648 err=2.420377
I 2015-05-27 03:04:57 theanets.trainer:168 RmsProp 623 loss=138.542816 err=2.480905
I 2015-05-27 03:05:02 theanets.trainer:168 RmsProp 624 loss=138.323227 err=2.412957
I 2015-05-27 03:05:06 theanets.trainer:168 RmsProp 625 loss=138.160889 err=2.405041
I 2015-05-27 03:05:10 theanets.trainer:168 RmsProp 626 loss=137.888977 err=2.285272
I 2015-05-27 03:05:14 theanets.trainer:168 RmsProp 627 loss=137.818665 err=2.369188
I 2015-05-27 03:05:17 theanets.trainer:168 RmsProp 628 loss=137.678101 err=2.380657
I 2015-05-27 03:05:21 theanets.trainer:168 RmsProp 629 loss=137.808777 err=2.662968
I 2015-05-27 03:05:26 theanets.trainer:168 RmsProp 630 loss=137.415192 err=2.416653
I 2015-05-27 03:05:26 theanets.trainer:168 validation 63 loss=797.087524 err=662.166443
I 2015-05-27 03:05:30 theanets.trainer:168 RmsProp 631 loss=137.126617 err=2.277843
I 2015-05-27 03:05:34 theanets.trainer:168 RmsProp 632 loss=137.112503 err=2.413573
I 2015-05-27 03:05:38 theanets.trainer:168 RmsProp 633 loss=137.039825 err=2.490885
I 2015-05-27 03:05:42 theanets.trainer:168 RmsProp 634 loss=136.646469 err=2.250930
I 2015-05-27 03:05:46 theanets.trainer:168 RmsProp 635 loss=136.489838 err=2.243792
I 2015-05-27 03:05:50 theanets.trainer:168 RmsProp 636 loss=136.520691 err=2.427549
I 2015-05-27 03:05:54 theanets.trainer:168 RmsProp 637 loss=136.148438 err=2.209662
I 2015-05-27 03:05:57 theanets.trainer:168 RmsProp 638 loss=136.391022 err=2.602491
I 2015-05-27 03:06:01 theanets.trainer:168 RmsProp 639 loss=136.146088 err=2.505761
I 2015-05-27 03:06:04 theanets.trainer:168 RmsProp 640 loss=135.895996 err=2.402152
I 2015-05-27 03:06:04 theanets.trainer:168 validation 64 loss=791.774841 err=658.366028 *
I 2015-05-27 03:06:07 theanets.trainer:168 RmsProp 641 loss=135.648834 err=2.302384
I 2015-05-27 03:06:10 theanets.trainer:168 RmsProp 642 loss=135.598663 err=2.401596
I 2015-05-27 03:06:13 theanets.trainer:168 RmsProp 643 loss=135.461029 err=2.406164
I 2015-05-27 03:06:16 theanets.trainer:168 RmsProp 644 loss=135.045456 err=2.143084
I 2015-05-27 03:06:18 theanets.trainer:168 RmsProp 645 loss=135.239899 err=2.485806
I 2015-05-27 03:06:21 theanets.trainer:168 RmsProp 646 loss=135.030960 err=2.423594
I 2015-05-27 03:06:24 theanets.trainer:168 RmsProp 647 loss=134.741089 err=2.279883
I 2015-05-27 03:06:26 theanets.trainer:168 RmsProp 648 loss=134.639664 err=2.327625
I 2015-05-27 03:06:29 theanets.trainer:168 RmsProp 649 loss=134.755600 err=2.586646
I 2015-05-27 03:06:32 theanets.trainer:168 RmsProp 650 loss=134.460312 err=2.436085
I 2015-05-27 03:06:32 theanets.trainer:168 validation 65 loss=795.099731 err=663.160278
I 2015-05-27 03:06:35 theanets.trainer:168 RmsProp 651 loss=134.141281 err=2.260581
I 2015-05-27 03:06:38 theanets.trainer:168 RmsProp 652 loss=133.936996 err=2.199879
I 2015-05-27 03:06:42 theanets.trainer:168 RmsProp 653 loss=133.994720 err=2.400133
I 2015-05-27 03:06:45 theanets.trainer:168 RmsProp 654 loss=133.887070 err=2.437366
I 2015-05-27 03:06:48 theanets.trainer:168 RmsProp 655 loss=133.510651 err=2.206817
I 2015-05-27 03:06:51 theanets.trainer:168 RmsProp 656 loss=133.555634 err=2.396002
I 2015-05-27 03:06:54 theanets.trainer:168 RmsProp 657 loss=133.397781 err=2.387208
I 2015-05-27 03:06:57 theanets.trainer:168 RmsProp 658 loss=133.322754 err=2.450699
I 2015-05-27 03:07:00 theanets.trainer:168 RmsProp 659 loss=133.148773 err=2.418863
I 2015-05-27 03:07:02 theanets.trainer:168 RmsProp 660 loss=132.796127 err=2.216955
I 2015-05-27 03:07:03 theanets.trainer:168 validation 66 loss=802.034363 err=671.514099
I 2015-05-27 03:07:06 theanets.trainer:168 RmsProp 661 loss=132.944229 err=2.500700
I 2015-05-27 03:07:09 theanets.trainer:168 RmsProp 662 loss=132.621063 err=2.321328
I 2015-05-27 03:07:12 theanets.trainer:168 RmsProp 663 loss=132.307831 err=2.149101
I 2015-05-27 03:07:16 theanets.trainer:168 RmsProp 664 loss=132.637909 err=2.617189
I 2015-05-27 03:07:19 theanets.trainer:168 RmsProp 665 loss=132.268509 err=2.387347
I 2015-05-27 03:07:22 theanets.trainer:168 RmsProp 666 loss=132.059402 err=2.320140
I 2015-05-27 03:07:25 theanets.trainer:168 RmsProp 667 loss=131.965057 err=2.363409
I 2015-05-27 03:07:28 theanets.trainer:168 RmsProp 668 loss=131.778763 err=2.312333
I 2015-05-27 03:07:31 theanets.trainer:168 RmsProp 669 loss=131.897156 err=2.568733
I 2015-05-27 03:07:34 theanets.trainer:168 RmsProp 670 loss=131.444839 err=2.254926
I 2015-05-27 03:07:35 theanets.trainer:168 validation 67 loss=794.771484 err=665.662231
I 2015-05-27 03:07:38 theanets.trainer:168 RmsProp 671 loss=131.360260 err=2.313424
I 2015-05-27 03:07:41 theanets.trainer:168 RmsProp 672 loss=131.236481 err=2.326959
I 2015-05-27 03:07:44 theanets.trainer:168 RmsProp 673 loss=131.002350 err=2.234591
I 2015-05-27 03:07:47 theanets.trainer:168 RmsProp 674 loss=130.899536 err=2.270650
I 2015-05-27 03:07:50 theanets.trainer:168 RmsProp 675 loss=130.695923 err=2.207637
I 2015-05-27 03:07:53 theanets.trainer:168 RmsProp 676 loss=130.620819 err=2.276299
I 2015-05-27 03:07:56 theanets.trainer:168 RmsProp 677 loss=130.613861 err=2.408917
I 2015-05-27 03:08:00 theanets.trainer:168 RmsProp 678 loss=130.558411 err=2.491189
I 2015-05-27 03:08:03 theanets.trainer:168 RmsProp 679 loss=130.141327 err=2.210313
I 2015-05-27 03:08:06 theanets.trainer:168 RmsProp 680 loss=130.067596 err=2.270508
I 2015-05-27 03:08:07 theanets.trainer:168 validation 68 loss=788.515259 err=660.794617 *
I 2015-05-27 03:08:09 theanets.trainer:168 RmsProp 681 loss=129.847305 err=2.188288
I 2015-05-27 03:08:12 theanets.trainer:168 RmsProp 682 loss=130.011993 err=2.485302
I 2015-05-27 03:08:16 theanets.trainer:168 RmsProp 683 loss=129.822830 err=2.435192
I 2015-05-27 03:08:19 theanets.trainer:168 RmsProp 684 loss=129.617279 err=2.363103
I 2015-05-27 03:08:22 theanets.trainer:168 RmsProp 685 loss=129.375092 err=2.255761
I 2015-05-27 03:08:25 theanets.trainer:168 RmsProp 686 loss=129.262543 err=2.278772
I 2015-05-27 03:08:28 theanets.trainer:168 RmsProp 687 loss=129.072830 err=2.225935
I 2015-05-27 03:08:31 theanets.trainer:168 RmsProp 688 loss=129.071747 err=2.359392
I 2015-05-27 03:08:34 theanets.trainer:168 RmsProp 689 loss=128.887497 err=2.308867
I 2015-05-27 03:08:37 theanets.trainer:168 RmsProp 690 loss=128.728836 err=2.287176
I 2015-05-27 03:08:37 theanets.trainer:168 validation 69 loss=795.959778 err=669.588379
I 2015-05-27 03:08:40 theanets.trainer:168 RmsProp 691 loss=128.740952 err=2.427983
I 2015-05-27 03:08:43 theanets.trainer:168 RmsProp 692 loss=128.485062 err=2.305664
I 2015-05-27 03:08:46 theanets.trainer:168 RmsProp 693 loss=128.460449 err=2.410204
I 2015-05-27 03:08:49 theanets.trainer:168 RmsProp 694 loss=128.207764 err=2.288270
I 2015-05-27 03:08:53 theanets.trainer:168 RmsProp 695 loss=128.085419 err=2.293597
I 2015-05-27 03:08:56 theanets.trainer:168 RmsProp 696 loss=127.794800 err=2.131186
I 2015-05-27 03:08:59 theanets.trainer:168 RmsProp 697 loss=128.184235 err=2.645632
I 2015-05-27 03:09:02 theanets.trainer:168 RmsProp 698 loss=127.681175 err=2.270826
I 2015-05-27 03:09:05 theanets.trainer:168 RmsProp 699 loss=127.542015 err=2.263975
I 2015-05-27 03:09:08 theanets.trainer:168 RmsProp 700 loss=127.508034 err=2.357283
I 2015-05-27 03:09:08 theanets.trainer:168 validation 70 loss=791.328857 err=666.251648
I 2015-05-27 03:09:11 theanets.trainer:168 RmsProp 701 loss=127.280197 err=2.257821
I 2015-05-27 03:09:14 theanets.trainer:168 RmsProp 702 loss=127.174904 err=2.282094
I 2015-05-27 03:09:17 theanets.trainer:168 RmsProp 703 loss=127.000046 err=2.237526
I 2015-05-27 03:09:21 theanets.trainer:168 RmsProp 704 loss=126.791336 err=2.161193
I 2015-05-27 03:09:24 theanets.trainer:168 RmsProp 705 loss=126.888390 err=2.385794
I 2015-05-27 03:09:27 theanets.trainer:168 RmsProp 706 loss=126.598312 err=2.224234
I 2015-05-27 03:09:30 theanets.trainer:168 RmsProp 707 loss=126.507217 err=2.260923
I 2015-05-27 03:09:33 theanets.trainer:168 RmsProp 708 loss=126.290993 err=2.173096
I 2015-05-27 03:09:36 theanets.trainer:168 RmsProp 709 loss=126.340759 err=2.350790
I 2015-05-27 03:09:40 theanets.trainer:168 RmsProp 710 loss=126.134605 err=2.274024
I 2015-05-27 03:09:40 theanets.trainer:168 validation 71 loss=790.449951 err=666.665100
I 2015-05-27 03:09:43 theanets.trainer:168 RmsProp 711 loss=126.080032 err=2.351046
I 2015-05-27 03:09:46 theanets.trainer:168 RmsProp 712 loss=125.995750 err=2.390102
I 2015-05-27 03:09:49 theanets.trainer:168 RmsProp 713 loss=125.908386 err=2.426352
I 2015-05-27 03:09:52 theanets.trainer:168 RmsProp 714 loss=125.560463 err=2.201701
I 2015-05-27 03:09:56 theanets.trainer:168 RmsProp 715 loss=125.567589 err=2.330868
I 2015-05-27 03:09:59 theanets.trainer:168 RmsProp 716 loss=125.298645 err=2.186128
I 2015-05-27 03:10:02 theanets.trainer:168 RmsProp 717 loss=125.360367 err=2.371347
I 2015-05-27 03:10:05 theanets.trainer:168 RmsProp 718 loss=125.084511 err=2.218863
I 2015-05-27 03:10:08 theanets.trainer:168 RmsProp 719 loss=125.027222 err=2.281121
I 2015-05-27 03:10:11 theanets.trainer:168 RmsProp 720 loss=124.864182 err=2.242123
I 2015-05-27 03:10:11 theanets.trainer:168 validation 72 loss=791.885376 err=669.327271
I 2015-05-27 03:10:14 theanets.trainer:168 RmsProp 721 loss=124.780716 err=2.282229
I 2015-05-27 03:10:17 theanets.trainer:168 RmsProp 722 loss=124.754898 err=2.379427
I 2015-05-27 03:10:20 theanets.trainer:168 RmsProp 723 loss=124.807861 err=2.553241
I 2015-05-27 03:10:23 theanets.trainer:168 RmsProp 724 loss=124.156288 err=2.024721
I 2015-05-27 03:10:27 theanets.trainer:168 RmsProp 725 loss=124.307335 err=2.298340
I 2015-05-27 03:10:30 theanets.trainer:168 RmsProp 726 loss=124.239563 err=2.349863
I 2015-05-27 03:10:33 theanets.trainer:168 RmsProp 727 loss=123.934921 err=2.170634
I 2015-05-27 03:10:36 theanets.trainer:168 RmsProp 728 loss=124.005188 err=2.359813
I 2015-05-27 03:10:40 theanets.trainer:168 RmsProp 729 loss=123.640160 err=2.117471
I 2015-05-27 03:10:43 theanets.trainer:168 RmsProp 730 loss=123.721947 err=2.323025
I 2015-05-27 03:10:43 theanets.trainer:168 validation 73 loss=793.685242 err=672.354309
I 2015-05-27 03:10:43 theanets.trainer:252 patience elapsed!
I 2015-05-27 03:10:43 theanets.main:237 models_deep_post_code_sep/95148-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 03:10:43 theanets.graph:477 models_deep_post_code_sep/95148-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
