I 2015-05-26 03:35:25 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 03:35:25 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95116-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl
I 2015-05-26 03:35:25 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 03:35:25 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 03:35:25 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 03:35:25 theanets.main:89 --batch_size = 1024
I 2015-05-26 03:35:25 theanets.main:89 --gradient_clip = 1
I 2015-05-26 03:35:25 theanets.main:89 --hidden_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 03:35:25 theanets.main:89 --train_batches = 30
I 2015-05-26 03:35:25 theanets.main:89 --valid_batches = 3
I 2015-05-26 03:35:25 theanets.main:89 --weight_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --weight_l2 = None
I 2015-05-26 03:35:25 theanets.trainer:134 compiling evaluation function
I 2015-05-26 03:35:41 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 03:38:56 theanets.trainer:168 validation 0 loss=14151.584961 err=14151.584961 *
I 2015-05-26 03:39:54 theanets.trainer:168 RmsProp 1 loss=13197.754883 err=13197.754883
I 2015-05-26 03:40:53 theanets.trainer:168 RmsProp 2 loss=13229.278320 err=13229.278320
I 2015-05-26 03:41:53 theanets.trainer:168 RmsProp 3 loss=12649.142578 err=12649.142578
I 2015-05-26 03:42:52 theanets.trainer:168 RmsProp 4 loss=11615.576172 err=11615.576172
I 2015-05-26 03:43:50 theanets.trainer:168 RmsProp 5 loss=10460.251953 err=10460.251953
I 2015-05-26 03:44:48 theanets.trainer:168 RmsProp 6 loss=9930.323242 err=9930.323242
I 2015-05-26 03:45:46 theanets.trainer:168 RmsProp 7 loss=9448.092773 err=9448.092773
I 2015-05-26 03:46:45 theanets.trainer:168 RmsProp 8 loss=8935.939453 err=8935.939453
I 2015-05-26 03:47:44 theanets.trainer:168 RmsProp 9 loss=8303.128906 err=8303.128906
I 2015-05-26 03:48:42 theanets.trainer:168 RmsProp 10 loss=7435.680176 err=7435.680176
I 2015-05-26 03:48:43 theanets.trainer:168 validation 1 loss=7297.188965 err=7297.188965 *
I 2015-05-26 03:49:42 theanets.trainer:168 RmsProp 11 loss=6693.670898 err=6693.670898
I 2015-05-26 03:50:41 theanets.trainer:168 RmsProp 12 loss=6075.145996 err=6075.145996
I 2015-05-26 03:51:41 theanets.trainer:168 RmsProp 13 loss=5457.007324 err=5457.007324
I 2015-05-26 03:52:41 theanets.trainer:168 RmsProp 14 loss=4833.945801 err=4833.945801
I 2015-05-26 03:53:41 theanets.trainer:168 RmsProp 15 loss=4352.013184 err=4352.013184
I 2015-05-26 03:54:41 theanets.trainer:168 RmsProp 16 loss=4043.498535 err=4043.498535
I 2015-05-26 03:55:41 theanets.trainer:168 RmsProp 17 loss=3790.467773 err=3790.467773
I 2015-05-26 03:56:41 theanets.trainer:168 RmsProp 18 loss=3623.895996 err=3623.895996
I 2015-05-26 03:57:41 theanets.trainer:168 RmsProp 19 loss=3415.957031 err=3415.957031
I 2015-05-26 03:58:41 theanets.trainer:168 RmsProp 20 loss=3179.900635 err=3179.900635
I 2015-05-26 03:58:42 theanets.trainer:168 validation 2 loss=3436.760498 err=3436.760498 *
I 2015-05-26 03:59:41 theanets.trainer:168 RmsProp 21 loss=2995.135742 err=2995.135742
I 2015-05-26 04:00:40 theanets.trainer:168 RmsProp 22 loss=2786.623291 err=2786.623291
I 2015-05-26 04:01:40 theanets.trainer:168 RmsProp 23 loss=2725.552490 err=2725.552490
I 2015-05-26 04:02:40 theanets.trainer:168 RmsProp 24 loss=2574.829102 err=2574.829102
I 2015-05-26 04:03:40 theanets.trainer:168 RmsProp 25 loss=2374.644531 err=2374.644531
I 2015-05-26 04:04:40 theanets.trainer:168 RmsProp 26 loss=2227.844238 err=2227.844238
I 2015-05-26 04:05:39 theanets.trainer:168 RmsProp 27 loss=2091.421631 err=2091.421631
I 2015-05-26 04:06:39 theanets.trainer:168 RmsProp 28 loss=1970.427368 err=1970.427368
I 2015-05-26 04:07:38 theanets.trainer:168 RmsProp 29 loss=1865.461548 err=1865.461548
I 2015-05-26 04:08:38 theanets.trainer:168 RmsProp 30 loss=1769.442871 err=1769.442871
I 2015-05-26 04:08:39 theanets.trainer:168 validation 3 loss=2549.113281 err=2549.113281 *
I 2015-05-26 04:09:39 theanets.trainer:168 RmsProp 31 loss=1641.283813 err=1641.283813
I 2015-05-26 04:10:37 theanets.trainer:168 RmsProp 32 loss=1545.297241 err=1545.297241
I 2015-05-26 04:11:37 theanets.trainer:168 RmsProp 33 loss=1505.979370 err=1505.979370
I 2015-05-26 04:12:34 theanets.trainer:168 RmsProp 34 loss=1420.789917 err=1420.789917
I 2015-05-26 04:13:31 theanets.trainer:168 RmsProp 35 loss=1340.406860 err=1340.406860
I 2015-05-26 04:14:27 theanets.trainer:168 RmsProp 36 loss=1284.285522 err=1284.285522
I 2015-05-26 04:15:22 theanets.trainer:168 RmsProp 37 loss=1217.636475 err=1217.636475
I 2015-05-26 04:16:16 theanets.trainer:168 RmsProp 38 loss=1212.106567 err=1212.106567
I 2015-05-26 04:17:12 theanets.trainer:168 RmsProp 39 loss=1148.565063 err=1148.565063
I 2015-05-26 04:18:07 theanets.trainer:168 RmsProp 40 loss=1103.886230 err=1103.886230
I 2015-05-26 04:18:08 theanets.trainer:168 validation 4 loss=2329.710938 err=2329.710938 *
I 2015-05-26 04:19:03 theanets.trainer:168 RmsProp 41 loss=1070.982788 err=1070.982788
I 2015-05-26 04:19:59 theanets.trainer:168 RmsProp 42 loss=1012.943542 err=1012.943542
I 2015-05-26 04:20:55 theanets.trainer:168 RmsProp 43 loss=963.820679 err=963.820679
I 2015-05-26 04:21:51 theanets.trainer:168 RmsProp 44 loss=935.021790 err=935.021790
I 2015-05-26 04:22:45 theanets.trainer:168 RmsProp 45 loss=881.198669 err=881.198669
I 2015-05-26 04:23:37 theanets.trainer:168 RmsProp 46 loss=855.626648 err=855.626648
I 2015-05-26 04:24:29 theanets.trainer:168 RmsProp 47 loss=821.650818 err=821.650818
I 2015-05-26 04:25:21 theanets.trainer:168 RmsProp 48 loss=796.493591 err=796.493591
I 2015-05-26 04:26:13 theanets.trainer:168 RmsProp 49 loss=760.404175 err=760.404175
I 2015-05-26 04:27:06 theanets.trainer:168 RmsProp 50 loss=737.435608 err=737.435608
I 2015-05-26 04:27:07 theanets.trainer:168 validation 5 loss=2082.584717 err=2082.584717 *
I 2015-05-26 04:27:58 theanets.trainer:168 RmsProp 51 loss=731.354492 err=731.354492
I 2015-05-26 04:28:49 theanets.trainer:168 RmsProp 52 loss=696.288391 err=696.288391
I 2015-05-26 04:29:40 theanets.trainer:168 RmsProp 53 loss=670.704346 err=670.704346
I 2015-05-26 04:30:32 theanets.trainer:168 RmsProp 54 loss=637.888733 err=637.888733
I 2015-05-26 04:31:24 theanets.trainer:168 RmsProp 55 loss=640.581848 err=640.581848
I 2015-05-26 04:32:15 theanets.trainer:168 RmsProp 56 loss=610.602356 err=610.602356
I 2015-05-26 04:33:06 theanets.trainer:168 RmsProp 57 loss=593.412537 err=593.412537
I 2015-05-26 04:33:57 theanets.trainer:168 RmsProp 58 loss=570.009644 err=570.009644
I 2015-05-26 04:34:50 theanets.trainer:168 RmsProp 59 loss=573.872498 err=573.872498
I 2015-05-26 04:35:42 theanets.trainer:168 RmsProp 60 loss=549.948242 err=549.948242
I 2015-05-26 04:35:43 theanets.trainer:168 validation 6 loss=1918.743530 err=1918.743530 *
I 2015-05-26 04:36:35 theanets.trainer:168 RmsProp 61 loss=539.519714 err=539.519714
I 2015-05-26 04:37:27 theanets.trainer:168 RmsProp 62 loss=540.315918 err=540.315918
I 2015-05-26 04:38:19 theanets.trainer:168 RmsProp 63 loss=506.125336 err=506.125336
I 2015-05-26 04:39:12 theanets.trainer:168 RmsProp 64 loss=487.993225 err=487.993225
I 2015-05-26 04:40:06 theanets.trainer:168 RmsProp 65 loss=489.938568 err=489.938568
I 2015-05-26 04:40:58 theanets.trainer:168 RmsProp 66 loss=472.542877 err=472.542877
I 2015-05-26 04:41:51 theanets.trainer:168 RmsProp 67 loss=451.897827 err=451.897827
I 2015-05-26 04:42:44 theanets.trainer:168 RmsProp 68 loss=440.520691 err=440.520691
I 2015-05-26 04:43:37 theanets.trainer:168 RmsProp 69 loss=428.415100 err=428.415100
I 2015-05-26 04:44:30 theanets.trainer:168 RmsProp 70 loss=430.492798 err=430.492798
I 2015-05-26 04:44:31 theanets.trainer:168 validation 7 loss=1859.478149 err=1859.478149 *
I 2015-05-26 04:45:23 theanets.trainer:168 RmsProp 71 loss=422.531097 err=422.531097
I 2015-05-26 04:46:16 theanets.trainer:168 RmsProp 72 loss=423.721832 err=423.721832
I 2015-05-26 04:47:08 theanets.trainer:168 RmsProp 73 loss=409.732910 err=409.732910
I 2015-05-26 04:48:00 theanets.trainer:168 RmsProp 74 loss=382.539337 err=382.539337
I 2015-05-26 04:48:53 theanets.trainer:168 RmsProp 75 loss=365.416962 err=365.416962
I 2015-05-26 04:49:46 theanets.trainer:168 RmsProp 76 loss=353.436310 err=353.436310
I 2015-05-26 04:50:38 theanets.trainer:168 RmsProp 77 loss=360.544830 err=360.544830
I 2015-05-26 04:51:30 theanets.trainer:168 RmsProp 78 loss=343.023956 err=343.023956
I 2015-05-26 04:52:23 theanets.trainer:168 RmsProp 79 loss=338.846680 err=338.846680
I 2015-05-26 04:53:16 theanets.trainer:168 RmsProp 80 loss=326.269073 err=326.269073
I 2015-05-26 04:53:17 theanets.trainer:168 validation 8 loss=1653.115234 err=1653.115234 *
I 2015-05-26 04:54:09 theanets.trainer:168 RmsProp 81 loss=316.842468 err=316.842468
I 2015-05-26 04:55:01 theanets.trainer:168 RmsProp 82 loss=313.861908 err=313.861908
I 2015-05-26 04:55:52 theanets.trainer:168 RmsProp 83 loss=295.917419 err=295.917419
I 2015-05-26 04:56:42 theanets.trainer:168 RmsProp 84 loss=276.274719 err=276.274719
I 2015-05-26 04:57:33 theanets.trainer:168 RmsProp 85 loss=266.830383 err=266.830383
I 2015-05-26 04:58:24 theanets.trainer:168 RmsProp 86 loss=262.917816 err=262.917816
I 2015-05-26 04:59:15 theanets.trainer:168 RmsProp 87 loss=261.224792 err=261.224792
I 2015-05-26 05:00:06 theanets.trainer:168 RmsProp 88 loss=260.934021 err=260.934021
I 2015-05-26 05:00:56 theanets.trainer:168 RmsProp 89 loss=254.424622 err=254.424622
I 2015-05-26 05:01:47 theanets.trainer:168 RmsProp 90 loss=255.489456 err=255.489456
I 2015-05-26 05:01:48 theanets.trainer:168 validation 9 loss=1615.094604 err=1615.094604 *
I 2015-05-26 05:02:39 theanets.trainer:168 RmsProp 91 loss=229.588074 err=229.588074
I 2015-05-26 05:03:30 theanets.trainer:168 RmsProp 92 loss=225.123718 err=225.123718
I 2015-05-26 05:04:22 theanets.trainer:168 RmsProp 93 loss=229.343719 err=229.343719
I 2015-05-26 05:05:13 theanets.trainer:168 RmsProp 94 loss=221.003983 err=221.003983
I 2015-05-26 05:06:05 theanets.trainer:168 RmsProp 95 loss=207.151260 err=207.151260
I 2015-05-26 05:06:57 theanets.trainer:168 RmsProp 96 loss=200.988480 err=200.988480
I 2015-05-26 05:07:48 theanets.trainer:168 RmsProp 97 loss=197.057907 err=197.057907
I 2015-05-26 05:08:38 theanets.trainer:168 RmsProp 98 loss=191.236786 err=191.236786
I 2015-05-26 05:09:28 theanets.trainer:168 RmsProp 99 loss=201.644012 err=201.644012
I 2015-05-26 05:10:18 theanets.trainer:168 RmsProp 100 loss=193.674011 err=193.674011
I 2015-05-26 05:10:19 theanets.trainer:168 validation 10 loss=1624.369751 err=1624.369751
I 2015-05-26 05:11:08 theanets.trainer:168 RmsProp 101 loss=186.343018 err=186.343018
I 2015-05-26 05:11:57 theanets.trainer:168 RmsProp 102 loss=182.882675 err=182.882675
I 2015-05-26 05:12:46 theanets.trainer:168 RmsProp 103 loss=175.294113 err=175.294113
I 2015-05-26 05:13:35 theanets.trainer:168 RmsProp 104 loss=171.350311 err=171.350311
I 2015-05-26 05:14:24 theanets.trainer:168 RmsProp 105 loss=173.432129 err=173.432129
I 2015-05-26 05:15:14 theanets.trainer:168 RmsProp 106 loss=166.605240 err=166.605240
I 2015-05-26 05:16:04 theanets.trainer:168 RmsProp 107 loss=167.884979 err=167.884979
I 2015-05-26 05:16:54 theanets.trainer:168 RmsProp 108 loss=156.711487 err=156.711487
I 2015-05-26 05:17:44 theanets.trainer:168 RmsProp 109 loss=155.009552 err=155.009552
I 2015-05-26 05:18:33 theanets.trainer:168 RmsProp 110 loss=150.326767 err=150.326767
I 2015-05-26 05:18:34 theanets.trainer:168 validation 11 loss=1574.479370 err=1574.479370 *
I 2015-05-26 05:19:24 theanets.trainer:168 RmsProp 111 loss=141.353729 err=141.353729
I 2015-05-26 05:20:13 theanets.trainer:168 RmsProp 112 loss=143.956619 err=143.956619
I 2015-05-26 05:21:02 theanets.trainer:168 RmsProp 113 loss=144.713531 err=144.713531
I 2015-05-26 05:21:52 theanets.trainer:168 RmsProp 114 loss=136.608429 err=136.608429
I 2015-05-26 05:22:42 theanets.trainer:168 RmsProp 115 loss=133.956955 err=133.956955
I 2015-05-26 05:23:32 theanets.trainer:168 RmsProp 116 loss=132.479584 err=132.479584
I 2015-05-26 05:24:22 theanets.trainer:168 RmsProp 117 loss=127.559738 err=127.559738
I 2015-05-26 05:25:12 theanets.trainer:168 RmsProp 118 loss=120.776276 err=120.776276
I 2015-05-26 05:26:01 theanets.trainer:168 RmsProp 119 loss=122.001976 err=122.001976
I 2015-05-26 05:26:51 theanets.trainer:168 RmsProp 120 loss=121.334488 err=121.334488
I 2015-05-26 05:26:52 theanets.trainer:168 validation 12 loss=1397.963379 err=1397.963379 *
I 2015-05-26 05:27:42 theanets.trainer:168 RmsProp 121 loss=118.188217 err=118.188217
I 2015-05-26 05:28:32 theanets.trainer:168 RmsProp 122 loss=114.480873 err=114.480873
I 2015-05-26 05:29:22 theanets.trainer:168 RmsProp 123 loss=112.841866 err=112.841866
I 2015-05-26 05:30:12 theanets.trainer:168 RmsProp 124 loss=110.638313 err=110.638313
I 2015-05-26 05:31:02 theanets.trainer:168 RmsProp 125 loss=106.688873 err=106.688873
I 2015-05-26 05:31:52 theanets.trainer:168 RmsProp 126 loss=101.978012 err=101.978012
I 2015-05-26 05:32:42 theanets.trainer:168 RmsProp 127 loss=101.208107 err=101.208107
I 2015-05-26 05:33:32 theanets.trainer:168 RmsProp 128 loss=96.556297 err=96.556297
I 2015-05-26 05:34:22 theanets.trainer:168 RmsProp 129 loss=109.795692 err=109.795692
I 2015-05-26 05:35:13 theanets.trainer:168 RmsProp 130 loss=97.103973 err=97.103973
I 2015-05-26 05:35:14 theanets.trainer:168 validation 13 loss=1317.344360 err=1317.344360 *
I 2015-05-26 05:36:04 theanets.trainer:168 RmsProp 131 loss=93.993042 err=93.993042
I 2015-05-26 05:36:53 theanets.trainer:168 RmsProp 132 loss=93.003876 err=93.003876
I 2015-05-26 05:37:41 theanets.trainer:168 RmsProp 133 loss=90.253036 err=90.253036
I 2015-05-26 05:38:28 theanets.trainer:168 RmsProp 134 loss=93.902977 err=93.902977
I 2015-05-26 05:39:16 theanets.trainer:168 RmsProp 135 loss=89.736183 err=89.736183
I 2015-05-26 05:40:03 theanets.trainer:168 RmsProp 136 loss=86.856346 err=86.856346
I 2015-05-26 05:40:50 theanets.trainer:168 RmsProp 137 loss=79.519844 err=79.519844
I 2015-05-26 05:41:37 theanets.trainer:168 RmsProp 138 loss=80.984940 err=80.984940
I 2015-05-26 05:42:24 theanets.trainer:168 RmsProp 139 loss=81.020683 err=81.020683
I 2015-05-26 05:43:12 theanets.trainer:168 RmsProp 140 loss=77.814178 err=77.814178
I 2015-05-26 05:43:13 theanets.trainer:168 validation 14 loss=1213.122437 err=1213.122437 *
I 2015-05-26 05:44:00 theanets.trainer:168 RmsProp 141 loss=72.695389 err=72.695389
I 2015-05-26 05:44:47 theanets.trainer:168 RmsProp 142 loss=70.652763 err=70.652763
I 2015-05-26 05:45:34 theanets.trainer:168 RmsProp 143 loss=69.526085 err=69.526085
I 2015-05-26 05:46:22 theanets.trainer:168 RmsProp 144 loss=69.614250 err=69.614250
I 2015-05-26 05:47:10 theanets.trainer:168 RmsProp 145 loss=67.023064 err=67.023064
I 2015-05-26 05:47:58 theanets.trainer:168 RmsProp 146 loss=69.012787 err=69.012787
I 2015-05-26 05:48:46 theanets.trainer:168 RmsProp 147 loss=67.105301 err=67.105301
I 2015-05-26 05:49:33 theanets.trainer:168 RmsProp 148 loss=64.973076 err=64.973076
I 2015-05-26 05:50:21 theanets.trainer:168 RmsProp 149 loss=62.250954 err=62.250954
I 2015-05-26 05:51:09 theanets.trainer:168 RmsProp 150 loss=62.729362 err=62.729362
I 2015-05-26 05:51:10 theanets.trainer:168 validation 15 loss=1172.279663 err=1172.279663 *
I 2015-05-26 05:51:57 theanets.trainer:168 RmsProp 151 loss=60.932999 err=60.932999
I 2015-05-26 05:52:44 theanets.trainer:168 RmsProp 152 loss=56.956585 err=56.956585
I 2015-05-26 05:53:31 theanets.trainer:168 RmsProp 153 loss=57.580261 err=57.580261
I 2015-05-26 05:54:18 theanets.trainer:168 RmsProp 154 loss=55.210835 err=55.210835
I 2015-05-26 05:55:05 theanets.trainer:168 RmsProp 155 loss=59.893349 err=59.893349
I 2015-05-26 05:55:53 theanets.trainer:168 RmsProp 156 loss=54.365131 err=54.365131
I 2015-05-26 05:56:40 theanets.trainer:168 RmsProp 157 loss=53.559452 err=53.559452
I 2015-05-26 05:57:28 theanets.trainer:168 RmsProp 158 loss=49.797859 err=49.797859
I 2015-05-26 05:58:15 theanets.trainer:168 RmsProp 159 loss=51.606251 err=51.606251
I 2015-05-26 05:59:02 theanets.trainer:168 RmsProp 160 loss=55.009392 err=55.009392
I 2015-05-26 05:59:03 theanets.trainer:168 validation 16 loss=1208.114014 err=1208.114014
I 2015-05-26 05:59:51 theanets.trainer:168 RmsProp 161 loss=51.024536 err=51.024536
I 2015-05-26 06:00:38 theanets.trainer:168 RmsProp 162 loss=47.341660 err=47.341660
I 2015-05-26 06:01:26 theanets.trainer:168 RmsProp 163 loss=46.076694 err=46.076694
I 2015-05-26 06:02:14 theanets.trainer:168 RmsProp 164 loss=52.947521 err=52.947521
I 2015-05-26 06:03:01 theanets.trainer:168 RmsProp 165 loss=48.446239 err=48.446239
I 2015-05-26 06:03:49 theanets.trainer:168 RmsProp 166 loss=44.213745 err=44.213745
I 2015-05-26 06:04:36 theanets.trainer:168 RmsProp 167 loss=43.956997 err=43.956997
I 2015-05-26 06:05:24 theanets.trainer:168 RmsProp 168 loss=42.256577 err=42.256577
I 2015-05-26 06:06:11 theanets.trainer:168 RmsProp 169 loss=42.815426 err=42.815426
I 2015-05-26 06:06:57 theanets.trainer:168 RmsProp 170 loss=42.136650 err=42.136650
I 2015-05-26 06:06:58 theanets.trainer:168 validation 17 loss=1167.002808 err=1167.002808 *
I 2015-05-26 06:07:45 theanets.trainer:168 RmsProp 171 loss=38.981483 err=38.981483
I 2015-05-26 06:08:31 theanets.trainer:168 RmsProp 172 loss=40.403126 err=40.403126
I 2015-05-26 06:09:19 theanets.trainer:168 RmsProp 173 loss=39.476665 err=39.476665
I 2015-05-26 06:10:06 theanets.trainer:168 RmsProp 174 loss=36.620201 err=36.620201
I 2015-05-26 06:10:53 theanets.trainer:168 RmsProp 175 loss=38.002239 err=38.002239
I 2015-05-26 06:11:41 theanets.trainer:168 RmsProp 176 loss=37.370094 err=37.370094
I 2015-05-26 06:12:29 theanets.trainer:168 RmsProp 177 loss=35.428051 err=35.428051
I 2015-05-26 06:13:17 theanets.trainer:168 RmsProp 178 loss=35.121765 err=35.121765
I 2015-05-26 06:14:05 theanets.trainer:168 RmsProp 179 loss=36.340588 err=36.340588
I 2015-05-26 06:14:52 theanets.trainer:168 RmsProp 180 loss=34.139866 err=34.139866
I 2015-05-26 06:14:53 theanets.trainer:168 validation 18 loss=1142.190430 err=1142.190430 *
I 2015-05-26 06:15:40 theanets.trainer:168 RmsProp 181 loss=31.769773 err=31.769773
I 2015-05-26 06:16:28 theanets.trainer:168 RmsProp 182 loss=33.992596 err=33.992596
I 2015-05-26 06:17:16 theanets.trainer:168 RmsProp 183 loss=31.486452 err=31.486452
I 2015-05-26 06:18:05 theanets.trainer:168 RmsProp 184 loss=34.851421 err=34.851421
I 2015-05-26 06:18:52 theanets.trainer:168 RmsProp 185 loss=29.265419 err=29.265419
I 2015-05-26 06:19:39 theanets.trainer:168 RmsProp 186 loss=31.950891 err=31.950891
I 2015-05-26 06:20:26 theanets.trainer:168 RmsProp 187 loss=34.630978 err=34.630978
I 2015-05-26 06:21:13 theanets.trainer:168 RmsProp 188 loss=29.562374 err=29.562374
I 2015-05-26 06:22:00 theanets.trainer:168 RmsProp 189 loss=29.324434 err=29.324434
I 2015-05-26 06:22:48 theanets.trainer:168 RmsProp 190 loss=29.007763 err=29.007763
I 2015-05-26 06:22:49 theanets.trainer:168 validation 19 loss=1125.267944 err=1125.267944 *
I 2015-05-26 06:23:35 theanets.trainer:168 RmsProp 191 loss=32.025429 err=32.025429
I 2015-05-26 06:24:20 theanets.trainer:168 RmsProp 192 loss=30.924747 err=30.924747
I 2015-05-26 06:25:07 theanets.trainer:168 RmsProp 193 loss=28.667738 err=28.667738
I 2015-05-26 06:25:54 theanets.trainer:168 RmsProp 194 loss=28.162531 err=28.162531
I 2015-05-26 06:26:41 theanets.trainer:168 RmsProp 195 loss=26.592196 err=26.592196
I 2015-05-26 06:27:29 theanets.trainer:168 RmsProp 196 loss=26.657040 err=26.657040
I 2015-05-26 06:28:17 theanets.trainer:168 RmsProp 197 loss=26.193460 err=26.193460
I 2015-05-26 06:29:04 theanets.trainer:168 RmsProp 198 loss=25.336546 err=25.336546
I 2015-05-26 06:29:52 theanets.trainer:168 RmsProp 199 loss=25.942366 err=25.942366
I 2015-05-26 06:30:40 theanets.trainer:168 RmsProp 200 loss=25.075151 err=25.075151
I 2015-05-26 06:30:41 theanets.trainer:168 validation 20 loss=1119.107788 err=1119.107788 *
I 2015-05-26 06:31:28 theanets.trainer:168 RmsProp 201 loss=22.540382 err=22.540382
I 2015-05-26 06:32:17 theanets.trainer:168 RmsProp 202 loss=23.201443 err=23.201443
I 2015-05-26 06:33:05 theanets.trainer:168 RmsProp 203 loss=20.681520 err=20.681520
I 2015-05-26 06:33:52 theanets.trainer:168 RmsProp 204 loss=20.039356 err=20.039356
I 2015-05-26 06:34:39 theanets.trainer:168 RmsProp 205 loss=21.346975 err=21.346975
I 2015-05-26 06:35:24 theanets.trainer:168 RmsProp 206 loss=19.834541 err=19.834541
I 2015-05-26 06:36:10 theanets.trainer:168 RmsProp 207 loss=24.967569 err=24.967569
I 2015-05-26 06:36:55 theanets.trainer:168 RmsProp 208 loss=24.106686 err=24.106686
I 2015-05-26 06:37:41 theanets.trainer:168 RmsProp 209 loss=15.252158 err=15.252158
I 2015-05-26 06:38:27 theanets.trainer:168 RmsProp 210 loss=14.823941 err=14.823941
I 2015-05-26 06:38:28 theanets.trainer:168 validation 21 loss=1065.840332 err=1065.840332 *
I 2015-05-26 06:39:14 theanets.trainer:168 RmsProp 211 loss=14.723159 err=14.723159
I 2015-05-26 06:39:59 theanets.trainer:168 RmsProp 212 loss=14.689215 err=14.689215
I 2015-05-26 06:40:43 theanets.trainer:168 RmsProp 213 loss=21.923651 err=21.923651
I 2015-05-26 06:41:26 theanets.trainer:168 RmsProp 214 loss=26.955330 err=26.955330
I 2015-05-26 06:42:09 theanets.trainer:168 RmsProp 215 loss=22.653557 err=22.653557
I 2015-05-26 06:42:51 theanets.trainer:168 RmsProp 216 loss=19.581581 err=19.581581
I 2015-05-26 06:43:34 theanets.trainer:168 RmsProp 217 loss=17.707027 err=17.707027
I 2015-05-26 06:44:17 theanets.trainer:168 RmsProp 218 loss=16.045349 err=16.045349
I 2015-05-26 06:45:00 theanets.trainer:168 RmsProp 219 loss=16.671902 err=16.671902
I 2015-05-26 06:45:43 theanets.trainer:168 RmsProp 220 loss=19.223314 err=19.223314
I 2015-05-26 06:45:44 theanets.trainer:168 validation 22 loss=1028.419556 err=1028.419556 *
I 2015-05-26 06:46:27 theanets.trainer:168 RmsProp 221 loss=17.653553 err=17.653553
I 2015-05-26 06:47:09 theanets.trainer:168 RmsProp 222 loss=17.007427 err=17.007427
I 2015-05-26 06:47:51 theanets.trainer:168 RmsProp 223 loss=16.347128 err=16.347128
I 2015-05-26 06:48:33 theanets.trainer:168 RmsProp 224 loss=14.868341 err=14.868341
I 2015-05-26 06:49:16 theanets.trainer:168 RmsProp 225 loss=14.376383 err=14.376383
I 2015-05-26 06:49:59 theanets.trainer:168 RmsProp 226 loss=11.829805 err=11.829805
I 2015-05-26 06:50:42 theanets.trainer:168 RmsProp 227 loss=10.661041 err=10.661041
I 2015-05-26 06:51:25 theanets.trainer:168 RmsProp 228 loss=11.757342 err=11.757342
I 2015-05-26 06:52:08 theanets.trainer:168 RmsProp 229 loss=13.135631 err=13.135631
I 2015-05-26 06:52:51 theanets.trainer:168 RmsProp 230 loss=15.466589 err=15.466589
I 2015-05-26 06:52:52 theanets.trainer:168 validation 23 loss=1055.978882 err=1055.978882
I 2015-05-26 06:53:34 theanets.trainer:168 RmsProp 231 loss=14.298008 err=14.298008
I 2015-05-26 06:54:16 theanets.trainer:168 RmsProp 232 loss=11.554846 err=11.554846
I 2015-05-26 06:54:58 theanets.trainer:168 RmsProp 233 loss=13.618269 err=13.618269
I 2015-05-26 06:55:41 theanets.trainer:168 RmsProp 234 loss=13.808576 err=13.808576
I 2015-05-26 06:56:24 theanets.trainer:168 RmsProp 235 loss=14.671716 err=14.671716
I 2015-05-26 06:57:08 theanets.trainer:168 RmsProp 236 loss=14.187544 err=14.187544
I 2015-05-26 06:57:47 theanets.trainer:168 RmsProp 237 loss=11.584311 err=11.584311
I 2015-05-26 06:58:26 theanets.trainer:168 RmsProp 238 loss=10.439222 err=10.439222
I 2015-05-26 06:59:03 theanets.trainer:168 RmsProp 239 loss=12.581192 err=12.581192
I 2015-05-26 06:59:41 theanets.trainer:168 RmsProp 240 loss=17.672966 err=17.672966
I 2015-05-26 06:59:42 theanets.trainer:168 validation 24 loss=1015.608398 err=1015.608398 *
I 2015-05-26 07:00:20 theanets.trainer:168 RmsProp 241 loss=11.364986 err=11.364986
I 2015-05-26 07:00:56 theanets.trainer:168 RmsProp 242 loss=9.506309 err=9.506309
I 2015-05-26 07:01:34 theanets.trainer:168 RmsProp 243 loss=10.090424 err=10.090424
I 2015-05-26 07:02:13 theanets.trainer:168 RmsProp 244 loss=7.915764 err=7.915764
I 2015-05-26 07:02:51 theanets.trainer:168 RmsProp 245 loss=7.651883 err=7.651883
I 2015-05-26 07:03:30 theanets.trainer:168 RmsProp 246 loss=7.972756 err=7.972756
I 2015-05-26 07:04:09 theanets.trainer:168 RmsProp 247 loss=7.578103 err=7.578103
I 2015-05-26 07:04:47 theanets.trainer:168 RmsProp 248 loss=8.336111 err=8.336111
I 2015-05-26 07:05:25 theanets.trainer:168 RmsProp 249 loss=7.838198 err=7.838198
I 2015-05-26 07:06:03 theanets.trainer:168 RmsProp 250 loss=8.267160 err=8.267160
I 2015-05-26 07:06:04 theanets.trainer:168 validation 25 loss=996.999023 err=996.999023 *
I 2015-05-26 07:06:41 theanets.trainer:168 RmsProp 251 loss=9.458867 err=9.458867
I 2015-05-26 07:07:20 theanets.trainer:168 RmsProp 252 loss=8.660951 err=8.660951
I 2015-05-26 07:08:00 theanets.trainer:168 RmsProp 253 loss=10.482060 err=10.482060
I 2015-05-26 07:08:39 theanets.trainer:168 RmsProp 254 loss=8.537180 err=8.537180
I 2015-05-26 07:09:17 theanets.trainer:168 RmsProp 255 loss=7.366359 err=7.366359
I 2015-05-26 07:09:56 theanets.trainer:168 RmsProp 256 loss=6.984623 err=6.984623
I 2015-05-26 07:10:34 theanets.trainer:168 RmsProp 257 loss=8.161922 err=8.161922
I 2015-05-26 07:11:13 theanets.trainer:168 RmsProp 258 loss=7.541921 err=7.541921
I 2015-05-26 07:11:52 theanets.trainer:168 RmsProp 259 loss=6.649940 err=6.649940
I 2015-05-26 07:12:29 theanets.trainer:168 RmsProp 260 loss=6.646806 err=6.646806
I 2015-05-26 07:12:30 theanets.trainer:168 validation 26 loss=1055.044556 err=1055.044556
I 2015-05-26 07:13:06 theanets.trainer:168 RmsProp 261 loss=7.067959 err=7.067959
I 2015-05-26 07:13:43 theanets.trainer:168 RmsProp 262 loss=6.805191 err=6.805191
I 2015-05-26 07:14:20 theanets.trainer:168 RmsProp 263 loss=7.793580 err=7.793580
I 2015-05-26 07:14:58 theanets.trainer:168 RmsProp 264 loss=7.821216 err=7.821216
I 2015-05-26 07:15:36 theanets.trainer:168 RmsProp 265 loss=7.393273 err=7.393273
I 2015-05-26 07:16:13 theanets.trainer:168 RmsProp 266 loss=6.219415 err=6.219415
I 2015-05-26 07:16:52 theanets.trainer:168 RmsProp 267 loss=7.118554 err=7.118554
I 2015-05-26 07:17:30 theanets.trainer:168 RmsProp 268 loss=8.548336 err=8.548336
I 2015-05-26 07:18:08 theanets.trainer:168 RmsProp 269 loss=9.541922 err=9.541922
I 2015-05-26 07:18:45 theanets.trainer:168 RmsProp 270 loss=10.192636 err=10.192636
I 2015-05-26 07:18:46 theanets.trainer:168 validation 27 loss=992.726013 err=992.726013 *
I 2015-05-26 07:19:24 theanets.trainer:168 RmsProp 271 loss=7.456494 err=7.456494
I 2015-05-26 07:20:03 theanets.trainer:168 RmsProp 272 loss=5.942502 err=5.942502
I 2015-05-26 07:20:41 theanets.trainer:168 RmsProp 273 loss=5.855306 err=5.855306
I 2015-05-26 07:21:20 theanets.trainer:168 RmsProp 274 loss=7.556417 err=7.556417
I 2015-05-26 07:21:58 theanets.trainer:168 RmsProp 275 loss=9.663259 err=9.663259
I 2015-05-26 07:22:36 theanets.trainer:168 RmsProp 276 loss=7.285718 err=7.285718
I 2015-05-26 07:23:15 theanets.trainer:168 RmsProp 277 loss=5.640854 err=5.640854
I 2015-05-26 07:23:54 theanets.trainer:168 RmsProp 278 loss=6.355797 err=6.355797
I 2015-05-26 07:24:33 theanets.trainer:168 RmsProp 279 loss=6.821056 err=6.821056
I 2015-05-26 07:25:10 theanets.trainer:168 RmsProp 280 loss=5.712166 err=5.712166
I 2015-05-26 07:25:11 theanets.trainer:168 validation 28 loss=1002.921875 err=1002.921875
I 2015-05-26 07:25:47 theanets.trainer:168 RmsProp 281 loss=6.009163 err=6.009163
I 2015-05-26 07:26:24 theanets.trainer:168 RmsProp 282 loss=6.611642 err=6.611642
I 2015-05-26 07:26:59 theanets.trainer:168 RmsProp 283 loss=6.282077 err=6.282077
I 2015-05-26 07:27:35 theanets.trainer:168 RmsProp 284 loss=5.993266 err=5.993266
I 2015-05-26 07:28:11 theanets.trainer:168 RmsProp 285 loss=6.228621 err=6.228621
I 2015-05-26 07:28:46 theanets.trainer:168 RmsProp 286 loss=5.853189 err=5.853189
I 2015-05-26 07:29:22 theanets.trainer:168 RmsProp 287 loss=6.005254 err=6.005254
I 2015-05-26 07:29:58 theanets.trainer:168 RmsProp 288 loss=6.149058 err=6.149058
I 2015-05-26 07:30:35 theanets.trainer:168 RmsProp 289 loss=6.826137 err=6.826137
I 2015-05-26 07:31:10 theanets.trainer:168 RmsProp 290 loss=6.733269 err=6.733269
I 2015-05-26 07:31:11 theanets.trainer:168 validation 29 loss=999.996094 err=999.996094
I 2015-05-26 07:31:45 theanets.trainer:168 RmsProp 291 loss=6.695998 err=6.695998
I 2015-05-26 07:32:20 theanets.trainer:168 RmsProp 292 loss=6.420729 err=6.420729
I 2015-05-26 07:32:55 theanets.trainer:168 RmsProp 293 loss=5.587830 err=5.587830
I 2015-05-26 07:33:30 theanets.trainer:168 RmsProp 294 loss=5.708228 err=5.708228
I 2015-05-26 07:34:06 theanets.trainer:168 RmsProp 295 loss=5.833361 err=5.833361
I 2015-05-26 07:34:41 theanets.trainer:168 RmsProp 296 loss=7.050448 err=7.050448
I 2015-05-26 07:35:17 theanets.trainer:168 RmsProp 297 loss=5.907847 err=5.907847
I 2015-05-26 07:35:52 theanets.trainer:168 RmsProp 298 loss=5.352534 err=5.352534
I 2015-05-26 07:36:28 theanets.trainer:168 RmsProp 299 loss=4.967517 err=4.967517
I 2015-05-26 07:37:03 theanets.trainer:168 RmsProp 300 loss=5.611151 err=5.611151
I 2015-05-26 07:37:04 theanets.trainer:168 validation 30 loss=1027.858765 err=1027.858765
I 2015-05-26 07:37:40 theanets.trainer:168 RmsProp 301 loss=4.727405 err=4.727405
I 2015-05-26 07:38:16 theanets.trainer:168 RmsProp 302 loss=4.853224 err=4.853224
I 2015-05-26 07:38:52 theanets.trainer:168 RmsProp 303 loss=4.639836 err=4.639836
I 2015-05-26 07:39:27 theanets.trainer:168 RmsProp 304 loss=4.414393 err=4.414393
I 2015-05-26 07:40:04 theanets.trainer:168 RmsProp 305 loss=5.282976 err=5.282976
I 2015-05-26 07:40:42 theanets.trainer:168 RmsProp 306 loss=5.537261 err=5.537261
I 2015-05-26 07:41:18 theanets.trainer:168 RmsProp 307 loss=5.407579 err=5.407579
I 2015-05-26 07:41:55 theanets.trainer:168 RmsProp 308 loss=5.754774 err=5.754774
I 2015-05-26 07:42:31 theanets.trainer:168 RmsProp 309 loss=5.880823 err=5.880823
I 2015-05-26 07:43:07 theanets.trainer:168 RmsProp 310 loss=6.686339 err=6.686339
I 2015-05-26 07:43:07 theanets.trainer:168 validation 31 loss=1019.320129 err=1019.320129
I 2015-05-26 07:43:41 theanets.trainer:168 RmsProp 311 loss=6.040993 err=6.040993
I 2015-05-26 07:44:15 theanets.trainer:168 RmsProp 312 loss=4.189281 err=4.189281
I 2015-05-26 07:44:48 theanets.trainer:168 RmsProp 313 loss=3.990103 err=3.990103
I 2015-05-26 07:45:21 theanets.trainer:168 RmsProp 314 loss=4.172925 err=4.172925
I 2015-05-26 07:45:54 theanets.trainer:168 RmsProp 315 loss=4.445244 err=4.445244
I 2015-05-26 07:46:28 theanets.trainer:168 RmsProp 316 loss=4.195723 err=4.195723
I 2015-05-26 07:47:01 theanets.trainer:168 RmsProp 317 loss=4.054744 err=4.054744
I 2015-05-26 07:47:34 theanets.trainer:168 RmsProp 318 loss=3.985053 err=3.985053
I 2015-05-26 07:48:08 theanets.trainer:168 RmsProp 319 loss=4.120804 err=4.120804
I 2015-05-26 07:48:41 theanets.trainer:168 RmsProp 320 loss=4.653360 err=4.653360
I 2015-05-26 07:48:42 theanets.trainer:168 validation 32 loss=1078.737183 err=1078.737183
I 2015-05-26 07:48:42 theanets.trainer:252 patience elapsed!
I 2015-05-26 07:48:42 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 07:48:42 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 07:48:42 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 07:48:42 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 07:48:42 theanets.main:89 --batch_size = 1024
I 2015-05-26 07:48:42 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 07:48:42 theanets.main:89 --hidden_l1 = None
I 2015-05-26 07:48:42 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 07:48:42 theanets.main:89 --train_batches = 10
I 2015-05-26 07:48:42 theanets.main:89 --valid_batches = 2
I 2015-05-26 07:48:42 theanets.main:89 --weight_l1 = None
I 2015-05-26 07:48:42 theanets.main:89 --weight_l2 = None
I 2015-05-26 07:48:42 theanets.trainer:134 compiling evaluation function
I 2015-05-26 07:48:51 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 07:50:28 theanets.trainer:168 validation 0 loss=888.399231 err=888.399231 *
I 2015-05-26 07:50:39 theanets.trainer:168 RmsProp 1 loss=11.623715 err=11.623715
I 2015-05-26 07:50:50 theanets.trainer:168 RmsProp 2 loss=6.826765 err=6.826765
I 2015-05-26 07:51:01 theanets.trainer:168 RmsProp 3 loss=4.398571 err=4.398571
I 2015-05-26 07:51:11 theanets.trainer:168 RmsProp 4 loss=3.450465 err=3.450465
I 2015-05-26 07:51:22 theanets.trainer:168 RmsProp 5 loss=2.808873 err=2.808873
I 2015-05-26 07:51:32 theanets.trainer:168 RmsProp 6 loss=2.461040 err=2.461040
I 2015-05-26 07:51:43 theanets.trainer:168 RmsProp 7 loss=2.156278 err=2.156278
I 2015-05-26 07:51:53 theanets.trainer:168 RmsProp 8 loss=1.896258 err=1.896258
I 2015-05-26 07:52:04 theanets.trainer:168 RmsProp 9 loss=1.697684 err=1.697684
I 2015-05-26 07:52:15 theanets.trainer:168 RmsProp 10 loss=1.531626 err=1.531626
I 2015-05-26 07:52:15 theanets.trainer:168 validation 1 loss=855.182434 err=855.182434 *
I 2015-05-26 07:52:26 theanets.trainer:168 RmsProp 11 loss=1.383186 err=1.383186
I 2015-05-26 07:52:37 theanets.trainer:168 RmsProp 12 loss=1.334228 err=1.334228
I 2015-05-26 07:52:48 theanets.trainer:168 RmsProp 13 loss=1.204543 err=1.204543
I 2015-05-26 07:52:59 theanets.trainer:168 RmsProp 14 loss=1.145109 err=1.145109
I 2015-05-26 07:53:10 theanets.trainer:168 RmsProp 15 loss=1.125394 err=1.125394
I 2015-05-26 07:53:21 theanets.trainer:168 RmsProp 16 loss=1.054345 err=1.054345
I 2015-05-26 07:53:32 theanets.trainer:168 RmsProp 17 loss=0.996359 err=0.996359
I 2015-05-26 07:53:43 theanets.trainer:168 RmsProp 18 loss=0.956110 err=0.956110
I 2015-05-26 07:53:54 theanets.trainer:168 RmsProp 19 loss=0.908279 err=0.908279
I 2015-05-26 07:54:05 theanets.trainer:168 RmsProp 20 loss=0.855124 err=0.855124
I 2015-05-26 07:54:05 theanets.trainer:168 validation 2 loss=836.291809 err=836.291809 *
I 2015-05-26 07:54:16 theanets.trainer:168 RmsProp 21 loss=0.850045 err=0.850045
I 2015-05-26 07:54:27 theanets.trainer:168 RmsProp 22 loss=0.778379 err=0.778379
I 2015-05-26 07:54:38 theanets.trainer:168 RmsProp 23 loss=0.751086 err=0.751086
I 2015-05-26 07:54:49 theanets.trainer:168 RmsProp 24 loss=0.728441 err=0.728441
I 2015-05-26 07:54:59 theanets.trainer:168 RmsProp 25 loss=0.750704 err=0.750704
I 2015-05-26 07:55:10 theanets.trainer:168 RmsProp 26 loss=0.726290 err=0.726290
I 2015-05-26 07:55:21 theanets.trainer:168 RmsProp 27 loss=0.681169 err=0.681169
I 2015-05-26 07:55:32 theanets.trainer:168 RmsProp 28 loss=0.694938 err=0.694938
I 2015-05-26 07:55:43 theanets.trainer:168 RmsProp 29 loss=0.647382 err=0.647382
I 2015-05-26 07:55:54 theanets.trainer:168 RmsProp 30 loss=0.644684 err=0.644684
I 2015-05-26 07:55:54 theanets.trainer:168 validation 3 loss=824.011902 err=824.011902 *
I 2015-05-26 07:56:05 theanets.trainer:168 RmsProp 31 loss=0.627200 err=0.627200
I 2015-05-26 07:56:16 theanets.trainer:168 RmsProp 32 loss=0.596416 err=0.596416
I 2015-05-26 07:56:27 theanets.trainer:168 RmsProp 33 loss=0.619753 err=0.619753
I 2015-05-26 07:56:38 theanets.trainer:168 RmsProp 34 loss=0.566427 err=0.566427
I 2015-05-26 07:56:49 theanets.trainer:168 RmsProp 35 loss=0.575544 err=0.575544
I 2015-05-26 07:57:00 theanets.trainer:168 RmsProp 36 loss=0.539373 err=0.539373
I 2015-05-26 07:57:12 theanets.trainer:168 RmsProp 37 loss=0.581061 err=0.581061
I 2015-05-26 07:57:23 theanets.trainer:168 RmsProp 38 loss=0.540336 err=0.540336
I 2015-05-26 07:57:34 theanets.trainer:168 RmsProp 39 loss=0.509554 err=0.509554
I 2015-05-26 07:57:45 theanets.trainer:168 RmsProp 40 loss=0.530259 err=0.530259
I 2015-05-26 07:57:46 theanets.trainer:168 validation 4 loss=812.311646 err=812.311646 *
I 2015-05-26 07:57:57 theanets.trainer:168 RmsProp 41 loss=0.512230 err=0.512230
I 2015-05-26 07:58:09 theanets.trainer:168 RmsProp 42 loss=0.484119 err=0.484119
I 2015-05-26 07:58:20 theanets.trainer:168 RmsProp 43 loss=0.497480 err=0.497480
I 2015-05-26 07:58:30 theanets.trainer:168 RmsProp 44 loss=0.466402 err=0.466402
I 2015-05-26 07:58:41 theanets.trainer:168 RmsProp 45 loss=0.468780 err=0.468780
I 2015-05-26 07:58:52 theanets.trainer:168 RmsProp 46 loss=0.488058 err=0.488058
I 2015-05-26 07:59:03 theanets.trainer:168 RmsProp 47 loss=0.467834 err=0.467834
I 2015-05-26 07:59:14 theanets.trainer:168 RmsProp 48 loss=0.443451 err=0.443451
I 2015-05-26 07:59:24 theanets.trainer:168 RmsProp 49 loss=0.428290 err=0.428290
I 2015-05-26 07:59:35 theanets.trainer:168 RmsProp 50 loss=0.431514 err=0.431514
I 2015-05-26 07:59:36 theanets.trainer:168 validation 5 loss=806.357605 err=806.357605 *
I 2015-05-26 07:59:46 theanets.trainer:168 RmsProp 51 loss=0.451668 err=0.451668
I 2015-05-26 07:59:57 theanets.trainer:168 RmsProp 52 loss=0.436287 err=0.436287
I 2015-05-26 08:00:08 theanets.trainer:168 RmsProp 53 loss=0.427648 err=0.427648
I 2015-05-26 08:00:19 theanets.trainer:168 RmsProp 54 loss=0.406986 err=0.406986
I 2015-05-26 08:00:31 theanets.trainer:168 RmsProp 55 loss=0.399380 err=0.399380
I 2015-05-26 08:00:42 theanets.trainer:168 RmsProp 56 loss=0.414925 err=0.414925
I 2015-05-26 08:00:53 theanets.trainer:168 RmsProp 57 loss=0.402339 err=0.402339
I 2015-05-26 08:01:05 theanets.trainer:168 RmsProp 58 loss=0.380199 err=0.380199
I 2015-05-26 08:01:16 theanets.trainer:168 RmsProp 59 loss=0.379750 err=0.379750
I 2015-05-26 08:01:27 theanets.trainer:168 RmsProp 60 loss=0.380631 err=0.380631
I 2015-05-26 08:01:27 theanets.trainer:168 validation 6 loss=799.999512 err=799.999512 *
I 2015-05-26 08:01:38 theanets.trainer:168 RmsProp 61 loss=0.384282 err=0.384282
I 2015-05-26 08:01:49 theanets.trainer:168 RmsProp 62 loss=0.374881 err=0.374881
I 2015-05-26 08:02:00 theanets.trainer:168 RmsProp 63 loss=0.359260 err=0.359260
I 2015-05-26 08:02:10 theanets.trainer:168 RmsProp 64 loss=0.358664 err=0.358664
I 2015-05-26 08:02:20 theanets.trainer:168 RmsProp 65 loss=0.354240 err=0.354240
I 2015-05-26 08:02:30 theanets.trainer:168 RmsProp 66 loss=0.352275 err=0.352275
I 2015-05-26 08:02:41 theanets.trainer:168 RmsProp 67 loss=0.361162 err=0.361162
I 2015-05-26 08:02:51 theanets.trainer:168 RmsProp 68 loss=0.333305 err=0.333305
I 2015-05-26 08:03:01 theanets.trainer:168 RmsProp 69 loss=0.343620 err=0.343620
I 2015-05-26 08:03:12 theanets.trainer:168 RmsProp 70 loss=0.341359 err=0.341359
I 2015-05-26 08:03:12 theanets.trainer:168 validation 7 loss=794.397827 err=794.397827 *
I 2015-05-26 08:03:22 theanets.trainer:168 RmsProp 71 loss=0.342777 err=0.342777
I 2015-05-26 08:03:33 theanets.trainer:168 RmsProp 72 loss=0.335427 err=0.335427
I 2015-05-26 08:03:43 theanets.trainer:168 RmsProp 73 loss=0.316221 err=0.316221
I 2015-05-26 08:03:53 theanets.trainer:168 RmsProp 74 loss=0.324101 err=0.324101
I 2015-05-26 08:04:03 theanets.trainer:168 RmsProp 75 loss=0.330852 err=0.330852
I 2015-05-26 08:04:13 theanets.trainer:168 RmsProp 76 loss=0.299098 err=0.299098
I 2015-05-26 08:04:24 theanets.trainer:168 RmsProp 77 loss=0.313659 err=0.313659
I 2015-05-26 08:04:34 theanets.trainer:168 RmsProp 78 loss=0.306408 err=0.306408
I 2015-05-26 08:04:44 theanets.trainer:168 RmsProp 79 loss=0.296577 err=0.296577
I 2015-05-26 08:04:54 theanets.trainer:168 RmsProp 80 loss=0.336796 err=0.336796
I 2015-05-26 08:04:55 theanets.trainer:168 validation 8 loss=789.348083 err=789.348083 *
I 2015-05-26 08:05:05 theanets.trainer:168 RmsProp 81 loss=0.315987 err=0.315987
I 2015-05-26 08:05:16 theanets.trainer:168 RmsProp 82 loss=0.297549 err=0.297549
I 2015-05-26 08:05:26 theanets.trainer:168 RmsProp 83 loss=0.289723 err=0.289723
I 2015-05-26 08:05:36 theanets.trainer:168 RmsProp 84 loss=0.312032 err=0.312032
I 2015-05-26 08:05:47 theanets.trainer:168 RmsProp 85 loss=0.290023 err=0.290023
I 2015-05-26 08:05:57 theanets.trainer:168 RmsProp 86 loss=0.289258 err=0.289258
I 2015-05-26 08:06:07 theanets.trainer:168 RmsProp 87 loss=0.298141 err=0.298141
I 2015-05-26 08:06:17 theanets.trainer:168 RmsProp 88 loss=0.278734 err=0.278734
I 2015-05-26 08:06:27 theanets.trainer:168 RmsProp 89 loss=0.274011 err=0.274011
I 2015-05-26 08:06:38 theanets.trainer:168 RmsProp 90 loss=0.279616 err=0.279616
I 2015-05-26 08:06:38 theanets.trainer:168 validation 9 loss=786.715637 err=786.715637 *
I 2015-05-26 08:06:49 theanets.trainer:168 RmsProp 91 loss=0.278138 err=0.278138
I 2015-05-26 08:06:59 theanets.trainer:168 RmsProp 92 loss=0.287657 err=0.287657
I 2015-05-26 08:07:10 theanets.trainer:168 RmsProp 93 loss=0.248631 err=0.248631
I 2015-05-26 08:07:20 theanets.trainer:168 RmsProp 94 loss=0.283034 err=0.283034
I 2015-05-26 08:07:31 theanets.trainer:168 RmsProp 95 loss=0.279845 err=0.279845
I 2015-05-26 08:07:41 theanets.trainer:168 RmsProp 96 loss=0.272510 err=0.272510
I 2015-05-26 08:07:51 theanets.trainer:168 RmsProp 97 loss=0.246460 err=0.246460
I 2015-05-26 08:08:01 theanets.trainer:168 RmsProp 98 loss=0.268631 err=0.268631
I 2015-05-26 08:08:11 theanets.trainer:168 RmsProp 99 loss=0.253386 err=0.253386
I 2015-05-26 08:08:21 theanets.trainer:168 RmsProp 100 loss=0.257276 err=0.257276
I 2015-05-26 08:08:22 theanets.trainer:168 validation 10 loss=782.330200 err=782.330200 *
I 2015-05-26 08:08:32 theanets.trainer:168 RmsProp 101 loss=0.269134 err=0.269134
I 2015-05-26 08:08:42 theanets.trainer:168 RmsProp 102 loss=0.252409 err=0.252409
I 2015-05-26 08:08:52 theanets.trainer:168 RmsProp 103 loss=0.255360 err=0.255360
I 2015-05-26 08:09:02 theanets.trainer:168 RmsProp 104 loss=0.247355 err=0.247355
I 2015-05-26 08:09:12 theanets.trainer:168 RmsProp 105 loss=0.257153 err=0.257153
I 2015-05-26 08:09:23 theanets.trainer:168 RmsProp 106 loss=0.260661 err=0.260661
I 2015-05-26 08:09:33 theanets.trainer:168 RmsProp 107 loss=0.242418 err=0.242418
I 2015-05-26 08:09:44 theanets.trainer:168 RmsProp 108 loss=0.245529 err=0.245529
I 2015-05-26 08:09:55 theanets.trainer:168 RmsProp 109 loss=0.241915 err=0.241915
I 2015-05-26 08:10:05 theanets.trainer:168 RmsProp 110 loss=0.234496 err=0.234496
I 2015-05-26 08:10:05 theanets.trainer:168 validation 11 loss=778.819763 err=778.819763 *
I 2015-05-26 08:10:16 theanets.trainer:168 RmsProp 111 loss=0.225046 err=0.225046
I 2015-05-26 08:10:26 theanets.trainer:168 RmsProp 112 loss=0.260910 err=0.260910
I 2015-05-26 08:10:37 theanets.trainer:168 RmsProp 113 loss=0.220632 err=0.220632
I 2015-05-26 08:10:48 theanets.trainer:168 RmsProp 114 loss=0.234001 err=0.234001
I 2015-05-26 08:10:58 theanets.trainer:168 RmsProp 115 loss=0.247385 err=0.247385
I 2015-05-26 08:11:09 theanets.trainer:168 RmsProp 116 loss=0.224513 err=0.224513
I 2015-05-26 08:11:19 theanets.trainer:168 RmsProp 117 loss=0.217846 err=0.217846
I 2015-05-26 08:11:29 theanets.trainer:168 RmsProp 118 loss=0.257168 err=0.257168
I 2015-05-26 08:11:39 theanets.trainer:168 RmsProp 119 loss=0.236378 err=0.236378
I 2015-05-26 08:11:50 theanets.trainer:168 RmsProp 120 loss=0.227890 err=0.227890
I 2015-05-26 08:11:50 theanets.trainer:168 validation 12 loss=775.949524 err=775.949524 *
I 2015-05-26 08:12:00 theanets.trainer:168 RmsProp 121 loss=0.210558 err=0.210558
I 2015-05-26 08:12:10 theanets.trainer:168 RmsProp 122 loss=0.241132 err=0.241132
I 2015-05-26 08:12:20 theanets.trainer:168 RmsProp 123 loss=0.233296 err=0.233296
I 2015-05-26 08:12:31 theanets.trainer:168 RmsProp 124 loss=0.219184 err=0.219184
I 2015-05-26 08:12:41 theanets.trainer:168 RmsProp 125 loss=0.201914 err=0.201914
I 2015-05-26 08:12:52 theanets.trainer:168 RmsProp 126 loss=0.201682 err=0.201682
I 2015-05-26 08:13:02 theanets.trainer:168 RmsProp 127 loss=0.230848 err=0.230848
I 2015-05-26 08:13:13 theanets.trainer:168 RmsProp 128 loss=0.206965 err=0.206965
I 2015-05-26 08:13:24 theanets.trainer:168 RmsProp 129 loss=0.207260 err=0.207260
I 2015-05-26 08:13:34 theanets.trainer:168 RmsProp 130 loss=0.219335 err=0.219335
I 2015-05-26 08:13:35 theanets.trainer:168 validation 13 loss=772.121277 err=772.121277 *
I 2015-05-26 08:13:46 theanets.trainer:168 RmsProp 131 loss=0.220873 err=0.220873
I 2015-05-26 08:13:56 theanets.trainer:168 RmsProp 132 loss=0.200756 err=0.200756
I 2015-05-26 08:14:06 theanets.trainer:168 RmsProp 133 loss=0.208231 err=0.208231
I 2015-05-26 08:14:16 theanets.trainer:168 RmsProp 134 loss=0.204487 err=0.204487
I 2015-05-26 08:14:26 theanets.trainer:168 RmsProp 135 loss=0.210608 err=0.210608
I 2015-05-26 08:14:37 theanets.trainer:168 RmsProp 136 loss=0.202108 err=0.202108
I 2015-05-26 08:14:47 theanets.trainer:168 RmsProp 137 loss=0.194178 err=0.194178
I 2015-05-26 08:14:57 theanets.trainer:168 RmsProp 138 loss=0.219132 err=0.219132
I 2015-05-26 08:15:07 theanets.trainer:168 RmsProp 139 loss=0.205427 err=0.205427
I 2015-05-26 08:15:17 theanets.trainer:168 RmsProp 140 loss=0.196407 err=0.196407
I 2015-05-26 08:15:18 theanets.trainer:168 validation 14 loss=771.726196 err=771.726196 *
I 2015-05-26 08:15:28 theanets.trainer:168 RmsProp 141 loss=0.203455 err=0.203455
I 2015-05-26 08:15:38 theanets.trainer:168 RmsProp 142 loss=0.214192 err=0.214192
I 2015-05-26 08:15:49 theanets.trainer:168 RmsProp 143 loss=0.192206 err=0.192206
I 2015-05-26 08:15:59 theanets.trainer:168 RmsProp 144 loss=0.178819 err=0.178819
I 2015-05-26 08:16:09 theanets.trainer:168 RmsProp 145 loss=0.215914 err=0.215914
I 2015-05-26 08:16:20 theanets.trainer:168 RmsProp 146 loss=0.185813 err=0.185813
I 2015-05-26 08:16:30 theanets.trainer:168 RmsProp 147 loss=0.183915 err=0.183915
I 2015-05-26 08:16:40 theanets.trainer:168 RmsProp 148 loss=0.210625 err=0.210625
I 2015-05-26 08:16:50 theanets.trainer:168 RmsProp 149 loss=0.192419 err=0.192419
I 2015-05-26 08:17:01 theanets.trainer:168 RmsProp 150 loss=0.195959 err=0.195959
I 2015-05-26 08:17:01 theanets.trainer:168 validation 15 loss=768.496216 err=768.496216 *
I 2015-05-26 08:17:12 theanets.trainer:168 RmsProp 151 loss=0.205933 err=0.205933
I 2015-05-26 08:17:22 theanets.trainer:168 RmsProp 152 loss=0.186968 err=0.186968
I 2015-05-26 08:17:32 theanets.trainer:168 RmsProp 153 loss=0.185893 err=0.185893
I 2015-05-26 08:17:42 theanets.trainer:168 RmsProp 154 loss=0.178957 err=0.178957
I 2015-05-26 08:17:53 theanets.trainer:168 RmsProp 155 loss=0.201777 err=0.201777
I 2015-05-26 08:18:03 theanets.trainer:168 RmsProp 156 loss=0.192554 err=0.192554
I 2015-05-26 08:18:14 theanets.trainer:168 RmsProp 157 loss=0.191182 err=0.191182
I 2015-05-26 08:18:24 theanets.trainer:168 RmsProp 158 loss=0.185917 err=0.185917
I 2015-05-26 08:18:35 theanets.trainer:168 RmsProp 159 loss=0.178119 err=0.178119
I 2015-05-26 08:18:45 theanets.trainer:168 RmsProp 160 loss=0.161707 err=0.161707
I 2015-05-26 08:18:45 theanets.trainer:168 validation 16 loss=766.036804 err=766.036804 *
I 2015-05-26 08:18:56 theanets.trainer:168 RmsProp 161 loss=0.202316 err=0.202316
I 2015-05-26 08:19:06 theanets.trainer:168 RmsProp 162 loss=0.177332 err=0.177332
I 2015-05-26 08:19:17 theanets.trainer:168 RmsProp 163 loss=0.176675 err=0.176675
I 2015-05-26 08:19:28 theanets.trainer:168 RmsProp 164 loss=0.184456 err=0.184456
I 2015-05-26 08:19:38 theanets.trainer:168 RmsProp 165 loss=0.181664 err=0.181664
I 2015-05-26 08:19:49 theanets.trainer:168 RmsProp 166 loss=0.170652 err=0.170652
I 2015-05-26 08:20:00 theanets.trainer:168 RmsProp 167 loss=0.185242 err=0.185242
I 2015-05-26 08:20:10 theanets.trainer:168 RmsProp 168 loss=0.178420 err=0.178420
I 2015-05-26 08:20:20 theanets.trainer:168 RmsProp 169 loss=0.173344 err=0.173344
I 2015-05-26 08:20:31 theanets.trainer:168 RmsProp 170 loss=0.173887 err=0.173887
I 2015-05-26 08:20:31 theanets.trainer:168 validation 17 loss=764.921875 err=764.921875 *
I 2015-05-26 08:20:42 theanets.trainer:168 RmsProp 171 loss=0.168750 err=0.168750
I 2015-05-26 08:20:52 theanets.trainer:168 RmsProp 172 loss=0.180762 err=0.180762
I 2015-05-26 08:21:02 theanets.trainer:168 RmsProp 173 loss=0.163949 err=0.163949
I 2015-05-26 08:21:13 theanets.trainer:168 RmsProp 174 loss=0.175911 err=0.175911
I 2015-05-26 08:21:23 theanets.trainer:168 RmsProp 175 loss=0.165249 err=0.165249
I 2015-05-26 08:21:33 theanets.trainer:168 RmsProp 176 loss=0.179391 err=0.179391
I 2015-05-26 08:21:44 theanets.trainer:168 RmsProp 177 loss=0.169917 err=0.169917
I 2015-05-26 08:21:55 theanets.trainer:168 RmsProp 178 loss=0.178915 err=0.178915
I 2015-05-26 08:22:05 theanets.trainer:168 RmsProp 179 loss=0.161149 err=0.161149
I 2015-05-26 08:22:15 theanets.trainer:168 RmsProp 180 loss=0.180010 err=0.180010
I 2015-05-26 08:22:16 theanets.trainer:168 validation 18 loss=762.955261 err=762.955261 *
I 2015-05-26 08:22:26 theanets.trainer:168 RmsProp 181 loss=0.154321 err=0.154321
I 2015-05-26 08:22:37 theanets.trainer:168 RmsProp 182 loss=0.168584 err=0.168584
I 2015-05-26 08:22:47 theanets.trainer:168 RmsProp 183 loss=0.164188 err=0.164188
I 2015-05-26 08:22:58 theanets.trainer:168 RmsProp 184 loss=0.171459 err=0.171459
I 2015-05-26 08:23:08 theanets.trainer:168 RmsProp 185 loss=0.154923 err=0.154923
I 2015-05-26 08:23:19 theanets.trainer:168 RmsProp 186 loss=0.160720 err=0.160720
I 2015-05-26 08:23:29 theanets.trainer:168 RmsProp 187 loss=0.150478 err=0.150478
I 2015-05-26 08:23:40 theanets.trainer:168 RmsProp 188 loss=0.174688 err=0.174688
I 2015-05-26 08:23:50 theanets.trainer:168 RmsProp 189 loss=0.149551 err=0.149551
I 2015-05-26 08:24:00 theanets.trainer:168 RmsProp 190 loss=0.162055 err=0.162055
I 2015-05-26 08:24:01 theanets.trainer:168 validation 19 loss=760.975708 err=760.975708 *
I 2015-05-26 08:24:11 theanets.trainer:168 RmsProp 191 loss=0.163808 err=0.163808
I 2015-05-26 08:24:21 theanets.trainer:168 RmsProp 192 loss=0.152883 err=0.152883
I 2015-05-26 08:24:32 theanets.trainer:168 RmsProp 193 loss=0.160835 err=0.160835
I 2015-05-26 08:24:42 theanets.trainer:168 RmsProp 194 loss=0.161682 err=0.161682
I 2015-05-26 08:24:53 theanets.trainer:168 RmsProp 195 loss=0.168928 err=0.168928
I 2015-05-26 08:25:04 theanets.trainer:168 RmsProp 196 loss=0.153388 err=0.153388
I 2015-05-26 08:25:14 theanets.trainer:168 RmsProp 197 loss=0.139435 err=0.139435
I 2015-05-26 08:25:25 theanets.trainer:168 RmsProp 198 loss=0.198209 err=0.198209
I 2015-05-26 08:25:35 theanets.trainer:168 RmsProp 199 loss=0.163240 err=0.163240
I 2015-05-26 08:25:46 theanets.trainer:168 RmsProp 200 loss=0.140639 err=0.140639
I 2015-05-26 08:25:46 theanets.trainer:168 validation 20 loss=759.088196 err=759.088196 *
I 2015-05-26 08:25:57 theanets.trainer:168 RmsProp 201 loss=0.148892 err=0.148892
I 2015-05-26 08:26:07 theanets.trainer:168 RmsProp 202 loss=0.143835 err=0.143835
I 2015-05-26 08:26:18 theanets.trainer:168 RmsProp 203 loss=0.166695 err=0.166695
I 2015-05-26 08:26:28 theanets.trainer:168 RmsProp 204 loss=0.146958 err=0.146958
I 2015-05-26 08:26:39 theanets.trainer:168 RmsProp 205 loss=0.156651 err=0.156651
I 2015-05-26 08:26:49 theanets.trainer:168 RmsProp 206 loss=0.138708 err=0.138708
I 2015-05-26 08:27:00 theanets.trainer:168 RmsProp 207 loss=0.155549 err=0.155549
I 2015-05-26 08:27:11 theanets.trainer:168 RmsProp 208 loss=0.138864 err=0.138864
I 2015-05-26 08:27:22 theanets.trainer:168 RmsProp 209 loss=0.150899 err=0.150899
I 2015-05-26 08:27:33 theanets.trainer:168 RmsProp 210 loss=0.143850 err=0.143850
I 2015-05-26 08:27:33 theanets.trainer:168 validation 21 loss=757.893982 err=757.893982 *
I 2015-05-26 08:27:44 theanets.trainer:168 RmsProp 211 loss=0.138343 err=0.138343
I 2015-05-26 08:27:54 theanets.trainer:168 RmsProp 212 loss=0.149005 err=0.149005
I 2015-05-26 08:28:05 theanets.trainer:168 RmsProp 213 loss=0.152864 err=0.152864
I 2015-05-26 08:28:15 theanets.trainer:168 RmsProp 214 loss=0.143050 err=0.143050
I 2015-05-26 08:28:25 theanets.trainer:168 RmsProp 215 loss=0.137856 err=0.137856
I 2015-05-26 08:28:36 theanets.trainer:168 RmsProp 216 loss=0.168326 err=0.168326
I 2015-05-26 08:28:46 theanets.trainer:168 RmsProp 217 loss=0.135838 err=0.135838
I 2015-05-26 08:28:57 theanets.trainer:168 RmsProp 218 loss=0.143539 err=0.143539
I 2015-05-26 08:29:08 theanets.trainer:168 RmsProp 219 loss=0.135925 err=0.135925
I 2015-05-26 08:29:18 theanets.trainer:168 RmsProp 220 loss=0.148581 err=0.148581
I 2015-05-26 08:29:18 theanets.trainer:168 validation 22 loss=756.099060 err=756.099060 *
I 2015-05-26 08:29:29 theanets.trainer:168 RmsProp 221 loss=0.136055 err=0.136055
I 2015-05-26 08:29:39 theanets.trainer:168 RmsProp 222 loss=0.140781 err=0.140781
I 2015-05-26 08:29:49 theanets.trainer:168 RmsProp 223 loss=0.155666 err=0.155666
I 2015-05-26 08:30:00 theanets.trainer:168 RmsProp 224 loss=0.129117 err=0.129117
I 2015-05-26 08:30:11 theanets.trainer:168 RmsProp 225 loss=0.135732 err=0.135732
I 2015-05-26 08:30:22 theanets.trainer:168 RmsProp 226 loss=0.155397 err=0.155397
I 2015-05-26 08:30:33 theanets.trainer:168 RmsProp 227 loss=0.127965 err=0.127965
I 2015-05-26 08:30:44 theanets.trainer:168 RmsProp 228 loss=0.132986 err=0.132986
I 2015-05-26 08:30:54 theanets.trainer:168 RmsProp 229 loss=0.150811 err=0.150811
I 2015-05-26 08:31:05 theanets.trainer:168 RmsProp 230 loss=0.135582 err=0.135582
I 2015-05-26 08:31:05 theanets.trainer:168 validation 23 loss=753.940613 err=753.940613 *
I 2015-05-26 08:31:16 theanets.trainer:168 RmsProp 231 loss=0.124356 err=0.124356
I 2015-05-26 08:31:27 theanets.trainer:168 RmsProp 232 loss=0.170361 err=0.170361
I 2015-05-26 08:31:37 theanets.trainer:168 RmsProp 233 loss=0.169159 err=0.169159
I 2015-05-26 08:31:47 theanets.trainer:168 RmsProp 234 loss=0.130314 err=0.130314
I 2015-05-26 08:31:57 theanets.trainer:168 RmsProp 235 loss=0.120866 err=0.120866
I 2015-05-26 08:32:07 theanets.trainer:168 RmsProp 236 loss=0.167474 err=0.167474
I 2015-05-26 08:32:18 theanets.trainer:168 RmsProp 237 loss=0.155015 err=0.155015
I 2015-05-26 08:32:28 theanets.trainer:168 RmsProp 238 loss=0.138921 err=0.138921
I 2015-05-26 08:32:38 theanets.trainer:168 RmsProp 239 loss=0.123527 err=0.123527
I 2015-05-26 08:32:47 theanets.trainer:168 RmsProp 240 loss=0.130025 err=0.130025
I 2015-05-26 08:32:48 theanets.trainer:168 validation 24 loss=752.537781 err=752.537781 *
I 2015-05-26 08:32:58 theanets.trainer:168 RmsProp 241 loss=0.139050 err=0.139050
I 2015-05-26 08:33:08 theanets.trainer:168 RmsProp 242 loss=0.148422 err=0.148422
I 2015-05-26 08:33:18 theanets.trainer:168 RmsProp 243 loss=0.125783 err=0.125783
I 2015-05-26 08:33:28 theanets.trainer:168 RmsProp 244 loss=0.130919 err=0.130919
I 2015-05-26 08:33:38 theanets.trainer:168 RmsProp 245 loss=0.144468 err=0.144468
I 2015-05-26 08:33:48 theanets.trainer:168 RmsProp 246 loss=0.118581 err=0.118581
I 2015-05-26 08:33:58 theanets.trainer:168 RmsProp 247 loss=0.141728 err=0.141728
I 2015-05-26 08:34:08 theanets.trainer:168 RmsProp 248 loss=0.124944 err=0.124944
I 2015-05-26 08:34:18 theanets.trainer:168 RmsProp 249 loss=0.126331 err=0.126331
I 2015-05-26 08:34:28 theanets.trainer:168 RmsProp 250 loss=0.143380 err=0.143380
I 2015-05-26 08:34:28 theanets.trainer:168 validation 25 loss=750.521667 err=750.521667 *
I 2015-05-26 08:34:39 theanets.trainer:168 RmsProp 251 loss=0.128907 err=0.128907
I 2015-05-26 08:34:49 theanets.trainer:168 RmsProp 252 loss=0.124428 err=0.124428
I 2015-05-26 08:34:59 theanets.trainer:168 RmsProp 253 loss=0.131151 err=0.131151
I 2015-05-26 08:35:09 theanets.trainer:168 RmsProp 254 loss=0.121985 err=0.121985
I 2015-05-26 08:35:19 theanets.trainer:168 RmsProp 255 loss=0.119190 err=0.119190
I 2015-05-26 08:35:29 theanets.trainer:168 RmsProp 256 loss=0.136381 err=0.136381
I 2015-05-26 08:35:39 theanets.trainer:168 RmsProp 257 loss=0.123955 err=0.123955
I 2015-05-26 08:35:49 theanets.trainer:168 RmsProp 258 loss=0.130005 err=0.130005
I 2015-05-26 08:35:59 theanets.trainer:168 RmsProp 259 loss=0.128268 err=0.128268
I 2015-05-26 08:36:08 theanets.trainer:168 RmsProp 260 loss=0.114829 err=0.114829
I 2015-05-26 08:36:09 theanets.trainer:168 validation 26 loss=749.561646 err=749.561646 *
I 2015-05-26 08:36:19 theanets.trainer:168 RmsProp 261 loss=0.141003 err=0.141003
I 2015-05-26 08:36:29 theanets.trainer:168 RmsProp 262 loss=0.125980 err=0.125980
I 2015-05-26 08:36:39 theanets.trainer:168 RmsProp 263 loss=0.109243 err=0.109243
I 2015-05-26 08:36:49 theanets.trainer:168 RmsProp 264 loss=0.160255 err=0.160255
I 2015-05-26 08:36:59 theanets.trainer:168 RmsProp 265 loss=0.122062 err=0.122062
I 2015-05-26 08:37:09 theanets.trainer:168 RmsProp 266 loss=0.123346 err=0.123346
I 2015-05-26 08:37:19 theanets.trainer:168 RmsProp 267 loss=0.128689 err=0.128689
I 2015-05-26 08:37:28 theanets.trainer:168 RmsProp 268 loss=0.126863 err=0.126863
I 2015-05-26 08:37:38 theanets.trainer:168 RmsProp 269 loss=0.123237 err=0.123237
I 2015-05-26 08:37:48 theanets.trainer:168 RmsProp 270 loss=0.109857 err=0.109857
I 2015-05-26 08:37:49 theanets.trainer:168 validation 27 loss=748.564270 err=748.564270 *
I 2015-05-26 08:37:58 theanets.trainer:168 RmsProp 271 loss=0.126555 err=0.126555
I 2015-05-26 08:38:08 theanets.trainer:168 RmsProp 272 loss=0.115423 err=0.115423
I 2015-05-26 08:38:18 theanets.trainer:168 RmsProp 273 loss=0.110838 err=0.110838
I 2015-05-26 08:38:28 theanets.trainer:168 RmsProp 274 loss=0.113004 err=0.113004
I 2015-05-26 08:38:38 theanets.trainer:168 RmsProp 275 loss=0.165313 err=0.165313
I 2015-05-26 08:38:48 theanets.trainer:168 RmsProp 276 loss=0.134525 err=0.134525
I 2015-05-26 08:38:58 theanets.trainer:168 RmsProp 277 loss=0.121444 err=0.121444
I 2015-05-26 08:39:08 theanets.trainer:168 RmsProp 278 loss=0.110896 err=0.110896
I 2015-05-26 08:39:18 theanets.trainer:168 RmsProp 279 loss=0.124387 err=0.124387
I 2015-05-26 08:39:28 theanets.trainer:168 RmsProp 280 loss=0.113485 err=0.113485
I 2015-05-26 08:39:29 theanets.trainer:168 validation 28 loss=746.613586 err=746.613586 *
I 2015-05-26 08:39:39 theanets.trainer:168 RmsProp 281 loss=0.127709 err=0.127709
I 2015-05-26 08:39:48 theanets.trainer:168 RmsProp 282 loss=0.140210 err=0.140210
I 2015-05-26 08:39:58 theanets.trainer:168 RmsProp 283 loss=0.118199 err=0.118199
I 2015-05-26 08:40:08 theanets.trainer:168 RmsProp 284 loss=0.104069 err=0.104069
I 2015-05-26 08:40:18 theanets.trainer:168 RmsProp 285 loss=0.125090 err=0.125090
I 2015-05-26 08:40:28 theanets.trainer:168 RmsProp 286 loss=0.109670 err=0.109670
I 2015-05-26 08:40:38 theanets.trainer:168 RmsProp 287 loss=0.116353 err=0.116353
I 2015-05-26 08:40:48 theanets.trainer:168 RmsProp 288 loss=0.117052 err=0.117052
I 2015-05-26 08:40:57 theanets.trainer:168 RmsProp 289 loss=0.106589 err=0.106589
I 2015-05-26 08:41:07 theanets.trainer:168 RmsProp 290 loss=0.109223 err=0.109223
I 2015-05-26 08:41:07 theanets.trainer:168 validation 29 loss=744.986511 err=744.986511 *
I 2015-05-26 08:41:17 theanets.trainer:168 RmsProp 291 loss=0.131027 err=0.131027
I 2015-05-26 08:41:27 theanets.trainer:168 RmsProp 292 loss=0.121065 err=0.121065
I 2015-05-26 08:41:37 theanets.trainer:168 RmsProp 293 loss=0.106251 err=0.106251
I 2015-05-26 08:41:47 theanets.trainer:168 RmsProp 294 loss=0.130131 err=0.130131
I 2015-05-26 08:41:57 theanets.trainer:168 RmsProp 295 loss=0.112084 err=0.112084
I 2015-05-26 08:42:07 theanets.trainer:168 RmsProp 296 loss=0.114582 err=0.114582
I 2015-05-26 08:42:17 theanets.trainer:168 RmsProp 297 loss=0.121241 err=0.121241
I 2015-05-26 08:42:28 theanets.trainer:168 RmsProp 298 loss=0.111324 err=0.111324
I 2015-05-26 08:42:37 theanets.trainer:168 RmsProp 299 loss=0.122397 err=0.122397
I 2015-05-26 08:42:47 theanets.trainer:168 RmsProp 300 loss=0.107379 err=0.107379
I 2015-05-26 08:42:48 theanets.trainer:168 validation 30 loss=744.409973 err=744.409973 *
I 2015-05-26 08:42:58 theanets.trainer:168 RmsProp 301 loss=0.114846 err=0.114846
I 2015-05-26 08:43:08 theanets.trainer:168 RmsProp 302 loss=0.118845 err=0.118845
I 2015-05-26 08:43:18 theanets.trainer:168 RmsProp 303 loss=0.113365 err=0.113365
I 2015-05-26 08:43:28 theanets.trainer:168 RmsProp 304 loss=0.104330 err=0.104330
I 2015-05-26 08:43:38 theanets.trainer:168 RmsProp 305 loss=0.108913 err=0.108913
I 2015-05-26 08:43:48 theanets.trainer:168 RmsProp 306 loss=0.113299 err=0.113299
I 2015-05-26 08:43:57 theanets.trainer:168 RmsProp 307 loss=0.116001 err=0.116001
I 2015-05-26 08:44:07 theanets.trainer:168 RmsProp 308 loss=0.095928 err=0.095928
I 2015-05-26 08:44:17 theanets.trainer:168 RmsProp 309 loss=0.130567 err=0.130567
I 2015-05-26 08:44:26 theanets.trainer:168 RmsProp 310 loss=0.107731 err=0.107731
I 2015-05-26 08:44:27 theanets.trainer:168 validation 31 loss=743.317383 err=743.317383 *
I 2015-05-26 08:44:37 theanets.trainer:168 RmsProp 311 loss=0.103399 err=0.103399
I 2015-05-26 08:44:47 theanets.trainer:168 RmsProp 312 loss=0.113328 err=0.113328
I 2015-05-26 08:44:56 theanets.trainer:168 RmsProp 313 loss=0.109571 err=0.109571
I 2015-05-26 08:45:06 theanets.trainer:168 RmsProp 314 loss=0.102924 err=0.102924
I 2015-05-26 08:45:16 theanets.trainer:168 RmsProp 315 loss=0.109182 err=0.109182
I 2015-05-26 08:45:26 theanets.trainer:168 RmsProp 316 loss=0.111368 err=0.111368
I 2015-05-26 08:45:36 theanets.trainer:168 RmsProp 317 loss=0.106716 err=0.106716
I 2015-05-26 08:45:46 theanets.trainer:168 RmsProp 318 loss=0.124176 err=0.124176
I 2015-05-26 08:45:55 theanets.trainer:168 RmsProp 319 loss=0.103423 err=0.103423
I 2015-05-26 08:46:04 theanets.trainer:168 RmsProp 320 loss=0.107137 err=0.107137
I 2015-05-26 08:46:05 theanets.trainer:168 validation 32 loss=741.242004 err=741.242004 *
I 2015-05-26 08:46:14 theanets.trainer:168 RmsProp 321 loss=0.105508 err=0.105508
I 2015-05-26 08:46:23 theanets.trainer:168 RmsProp 322 loss=0.099021 err=0.099021
I 2015-05-26 08:46:31 theanets.trainer:168 RmsProp 323 loss=0.119725 err=0.119725
I 2015-05-26 08:46:40 theanets.trainer:168 RmsProp 324 loss=0.110123 err=0.110123
I 2015-05-26 08:46:48 theanets.trainer:168 RmsProp 325 loss=0.102717 err=0.102717
I 2015-05-26 08:46:57 theanets.trainer:168 RmsProp 326 loss=0.108897 err=0.108897
I 2015-05-26 08:47:06 theanets.trainer:168 RmsProp 327 loss=0.096809 err=0.096809
I 2015-05-26 08:47:15 theanets.trainer:168 RmsProp 328 loss=0.121982 err=0.121982
I 2015-05-26 08:47:23 theanets.trainer:168 RmsProp 329 loss=0.106287 err=0.106287
I 2015-05-26 08:47:32 theanets.trainer:168 RmsProp 330 loss=0.098127 err=0.098127
I 2015-05-26 08:47:32 theanets.trainer:168 validation 33 loss=740.761963 err=740.761963 *
I 2015-05-26 08:47:41 theanets.trainer:168 RmsProp 331 loss=0.118335 err=0.118335
I 2015-05-26 08:47:50 theanets.trainer:168 RmsProp 332 loss=0.098782 err=0.098782
I 2015-05-26 08:47:58 theanets.trainer:168 RmsProp 333 loss=0.101905 err=0.101905
I 2015-05-26 08:48:07 theanets.trainer:168 RmsProp 334 loss=0.113553 err=0.113553
I 2015-05-26 08:48:16 theanets.trainer:168 RmsProp 335 loss=0.114531 err=0.114531
I 2015-05-26 08:48:24 theanets.trainer:168 RmsProp 336 loss=0.091376 err=0.091376
I 2015-05-26 08:48:33 theanets.trainer:168 RmsProp 337 loss=0.114033 err=0.114033
I 2015-05-26 08:48:42 theanets.trainer:168 RmsProp 338 loss=0.098277 err=0.098277
I 2015-05-26 08:48:51 theanets.trainer:168 RmsProp 339 loss=0.097613 err=0.097613
I 2015-05-26 08:49:00 theanets.trainer:168 RmsProp 340 loss=0.102974 err=0.102974
I 2015-05-26 08:49:01 theanets.trainer:168 validation 34 loss=738.496948 err=738.496948 *
I 2015-05-26 08:49:09 theanets.trainer:168 RmsProp 341 loss=0.095069 err=0.095069
I 2015-05-26 08:49:18 theanets.trainer:168 RmsProp 342 loss=0.117103 err=0.117103
I 2015-05-26 08:49:27 theanets.trainer:168 RmsProp 343 loss=0.106923 err=0.106923
I 2015-05-26 08:49:36 theanets.trainer:168 RmsProp 344 loss=0.097077 err=0.097077
I 2015-05-26 08:49:44 theanets.trainer:168 RmsProp 345 loss=0.099909 err=0.099909
I 2015-05-26 08:49:53 theanets.trainer:168 RmsProp 346 loss=0.105822 err=0.105822
I 2015-05-26 08:50:02 theanets.trainer:168 RmsProp 347 loss=0.091698 err=0.091698
I 2015-05-26 08:50:11 theanets.trainer:168 RmsProp 348 loss=0.095237 err=0.095237
I 2015-05-26 08:50:19 theanets.trainer:168 RmsProp 349 loss=0.112153 err=0.112153
I 2015-05-26 08:50:28 theanets.trainer:168 RmsProp 350 loss=0.105728 err=0.105728
I 2015-05-26 08:50:28 theanets.trainer:168 validation 35 loss=738.999634 err=738.999634
I 2015-05-26 08:50:37 theanets.trainer:168 RmsProp 351 loss=0.088568 err=0.088568
I 2015-05-26 08:50:45 theanets.trainer:168 RmsProp 352 loss=0.118454 err=0.118454
I 2015-05-26 08:50:53 theanets.trainer:168 RmsProp 353 loss=0.094471 err=0.094471
I 2015-05-26 08:51:01 theanets.trainer:168 RmsProp 354 loss=0.096544 err=0.096544
I 2015-05-26 08:51:09 theanets.trainer:168 RmsProp 355 loss=0.099627 err=0.099627
I 2015-05-26 08:51:18 theanets.trainer:168 RmsProp 356 loss=0.101809 err=0.101809
I 2015-05-26 08:51:27 theanets.trainer:168 RmsProp 357 loss=0.105895 err=0.105895
I 2015-05-26 08:51:35 theanets.trainer:168 RmsProp 358 loss=0.106310 err=0.106310
I 2015-05-26 08:51:43 theanets.trainer:168 RmsProp 359 loss=0.095601 err=0.095601
I 2015-05-26 08:51:51 theanets.trainer:168 RmsProp 360 loss=0.095534 err=0.095534
I 2015-05-26 08:51:52 theanets.trainer:168 validation 36 loss=737.849854 err=737.849854 *
I 2015-05-26 08:52:00 theanets.trainer:168 RmsProp 361 loss=0.102113 err=0.102113
I 2015-05-26 08:52:08 theanets.trainer:168 RmsProp 362 loss=0.093645 err=0.093645
I 2015-05-26 08:52:16 theanets.trainer:168 RmsProp 363 loss=0.098849 err=0.098849
I 2015-05-26 08:52:24 theanets.trainer:168 RmsProp 364 loss=0.084497 err=0.084497
I 2015-05-26 08:52:32 theanets.trainer:168 RmsProp 365 loss=0.122736 err=0.122736
I 2015-05-26 08:52:40 theanets.trainer:168 RmsProp 366 loss=0.108127 err=0.108127
I 2015-05-26 08:52:48 theanets.trainer:168 RmsProp 367 loss=0.089709 err=0.089709
I 2015-05-26 08:52:56 theanets.trainer:168 RmsProp 368 loss=0.098978 err=0.098978
I 2015-05-26 08:53:04 theanets.trainer:168 RmsProp 369 loss=0.088360 err=0.088360
I 2015-05-26 08:53:12 theanets.trainer:168 RmsProp 370 loss=0.098327 err=0.098327
I 2015-05-26 08:53:12 theanets.trainer:168 validation 37 loss=735.368958 err=735.368958 *
I 2015-05-26 08:53:20 theanets.trainer:168 RmsProp 371 loss=0.086583 err=0.086583
I 2015-05-26 08:53:28 theanets.trainer:168 RmsProp 372 loss=0.111292 err=0.111292
I 2015-05-26 08:53:35 theanets.trainer:168 RmsProp 373 loss=0.090942 err=0.090942
I 2015-05-26 08:53:44 theanets.trainer:168 RmsProp 374 loss=0.096548 err=0.096548
I 2015-05-26 08:53:52 theanets.trainer:168 RmsProp 375 loss=0.098709 err=0.098709
I 2015-05-26 08:54:00 theanets.trainer:168 RmsProp 376 loss=0.087493 err=0.087493
I 2015-05-26 08:54:09 theanets.trainer:168 RmsProp 377 loss=0.116958 err=0.116958
I 2015-05-26 08:54:16 theanets.trainer:168 RmsProp 378 loss=0.095078 err=0.095078
I 2015-05-26 08:54:23 theanets.trainer:168 RmsProp 379 loss=0.092746 err=0.092746
I 2015-05-26 08:54:31 theanets.trainer:168 RmsProp 380 loss=0.089616 err=0.089616
I 2015-05-26 08:54:31 theanets.trainer:168 validation 38 loss=734.340759 err=734.340759 *
I 2015-05-26 08:54:39 theanets.trainer:168 RmsProp 381 loss=0.102448 err=0.102448
I 2015-05-26 08:54:47 theanets.trainer:168 RmsProp 382 loss=0.094342 err=0.094342
I 2015-05-26 08:54:55 theanets.trainer:168 RmsProp 383 loss=0.091394 err=0.091394
I 2015-05-26 08:55:03 theanets.trainer:168 RmsProp 384 loss=0.104896 err=0.104896
I 2015-05-26 08:55:10 theanets.trainer:168 RmsProp 385 loss=0.092918 err=0.092918
I 2015-05-26 08:55:18 theanets.trainer:168 RmsProp 386 loss=0.087473 err=0.087473
I 2015-05-26 08:55:25 theanets.trainer:168 RmsProp 387 loss=0.090437 err=0.090437
I 2015-05-26 08:55:32 theanets.trainer:168 RmsProp 388 loss=0.095886 err=0.095886
I 2015-05-26 08:55:39 theanets.trainer:168 RmsProp 389 loss=0.100881 err=0.100881
I 2015-05-26 08:55:46 theanets.trainer:168 RmsProp 390 loss=0.096078 err=0.096078
I 2015-05-26 08:55:47 theanets.trainer:168 validation 39 loss=733.687073 err=733.687073 *
I 2015-05-26 08:55:54 theanets.trainer:168 RmsProp 391 loss=0.086254 err=0.086254
I 2015-05-26 08:56:01 theanets.trainer:168 RmsProp 392 loss=0.092348 err=0.092348
I 2015-05-26 08:56:09 theanets.trainer:168 RmsProp 393 loss=0.098207 err=0.098207
I 2015-05-26 08:56:17 theanets.trainer:168 RmsProp 394 loss=0.092788 err=0.092788
I 2015-05-26 08:56:24 theanets.trainer:168 RmsProp 395 loss=0.097002 err=0.097002
I 2015-05-26 08:56:31 theanets.trainer:168 RmsProp 396 loss=0.083012 err=0.083012
I 2015-05-26 08:56:38 theanets.trainer:168 RmsProp 397 loss=0.085646 err=0.085646
I 2015-05-26 08:56:45 theanets.trainer:168 RmsProp 398 loss=0.095242 err=0.095242
I 2015-05-26 08:56:54 theanets.trainer:168 RmsProp 399 loss=0.085344 err=0.085344
I 2015-05-26 08:57:01 theanets.trainer:168 RmsProp 400 loss=0.093643 err=0.093643
I 2015-05-26 08:57:02 theanets.trainer:168 validation 40 loss=732.878601 err=732.878601 *
I 2015-05-26 08:57:09 theanets.trainer:168 RmsProp 401 loss=0.088019 err=0.088019
I 2015-05-26 08:57:16 theanets.trainer:168 RmsProp 402 loss=0.090325 err=0.090325
I 2015-05-26 08:57:23 theanets.trainer:168 RmsProp 403 loss=0.109024 err=0.109024
I 2015-05-26 08:57:31 theanets.trainer:168 RmsProp 404 loss=0.090023 err=0.090023
I 2015-05-26 08:57:40 theanets.trainer:168 RmsProp 405 loss=0.089402 err=0.089402
I 2015-05-26 08:57:48 theanets.trainer:168 RmsProp 406 loss=0.089699 err=0.089699
I 2015-05-26 08:57:55 theanets.trainer:168 RmsProp 407 loss=0.082135 err=0.082135
I 2015-05-26 08:58:02 theanets.trainer:168 RmsProp 408 loss=0.090289 err=0.090289
I 2015-05-26 08:58:10 theanets.trainer:168 RmsProp 409 loss=0.089812 err=0.089812
I 2015-05-26 08:58:18 theanets.trainer:168 RmsProp 410 loss=0.087390 err=0.087390
I 2015-05-26 08:58:18 theanets.trainer:168 validation 41 loss=732.399536 err=732.399536 *
I 2015-05-26 08:58:26 theanets.trainer:168 RmsProp 411 loss=0.088403 err=0.088403
I 2015-05-26 08:58:34 theanets.trainer:168 RmsProp 412 loss=0.086179 err=0.086179
I 2015-05-26 08:58:42 theanets.trainer:168 RmsProp 413 loss=0.108067 err=0.108067
I 2015-05-26 08:58:50 theanets.trainer:168 RmsProp 414 loss=0.087857 err=0.087857
I 2015-05-26 08:58:58 theanets.trainer:168 RmsProp 415 loss=0.082726 err=0.082726
I 2015-05-26 08:59:05 theanets.trainer:168 RmsProp 416 loss=0.103966 err=0.103966
I 2015-05-26 08:59:14 theanets.trainer:168 RmsProp 417 loss=0.083544 err=0.083544
I 2015-05-26 08:59:22 theanets.trainer:168 RmsProp 418 loss=0.091277 err=0.091277
I 2015-05-26 08:59:30 theanets.trainer:168 RmsProp 419 loss=0.088480 err=0.088480
I 2015-05-26 08:59:37 theanets.trainer:168 RmsProp 420 loss=0.078603 err=0.078603
I 2015-05-26 08:59:37 theanets.trainer:168 validation 42 loss=731.036804 err=731.036804 *
I 2015-05-26 08:59:44 theanets.trainer:168 RmsProp 421 loss=0.093626 err=0.093626
I 2015-05-26 08:59:52 theanets.trainer:168 RmsProp 422 loss=0.079286 err=0.079286
I 2015-05-26 09:00:00 theanets.trainer:168 RmsProp 423 loss=0.102324 err=0.102324
I 2015-05-26 09:00:08 theanets.trainer:168 RmsProp 424 loss=0.092625 err=0.092625
I 2015-05-26 09:00:16 theanets.trainer:168 RmsProp 425 loss=0.088391 err=0.088391
I 2015-05-26 09:00:23 theanets.trainer:168 RmsProp 426 loss=0.079561 err=0.079561
I 2015-05-26 09:00:31 theanets.trainer:168 RmsProp 427 loss=0.089139 err=0.089139
I 2015-05-26 09:00:40 theanets.trainer:168 RmsProp 428 loss=0.085067 err=0.085067
I 2015-05-26 09:00:47 theanets.trainer:168 RmsProp 429 loss=0.087201 err=0.087201
I 2015-05-26 09:00:53 theanets.trainer:168 RmsProp 430 loss=0.081452 err=0.081452
I 2015-05-26 09:00:54 theanets.trainer:168 validation 43 loss=729.779968 err=729.779968 *
I 2015-05-26 09:01:01 theanets.trainer:168 RmsProp 431 loss=0.087022 err=0.087022
I 2015-05-26 09:01:08 theanets.trainer:168 RmsProp 432 loss=0.088446 err=0.088446
I 2015-05-26 09:01:17 theanets.trainer:168 RmsProp 433 loss=0.082476 err=0.082476
I 2015-05-26 09:01:25 theanets.trainer:168 RmsProp 434 loss=0.097282 err=0.097282
I 2015-05-26 09:01:32 theanets.trainer:168 RmsProp 435 loss=0.084166 err=0.084166
I 2015-05-26 09:01:41 theanets.trainer:168 RmsProp 436 loss=0.085186 err=0.085186
I 2015-05-26 09:01:48 theanets.trainer:168 RmsProp 437 loss=0.078958 err=0.078958
I 2015-05-26 09:01:55 theanets.trainer:168 RmsProp 438 loss=0.082131 err=0.082131
I 2015-05-26 09:02:03 theanets.trainer:168 RmsProp 439 loss=0.097027 err=0.097027
I 2015-05-26 09:02:10 theanets.trainer:168 RmsProp 440 loss=0.092236 err=0.092236
I 2015-05-26 09:02:10 theanets.trainer:168 validation 44 loss=729.198059 err=729.198059 *
I 2015-05-26 09:02:17 theanets.trainer:168 RmsProp 441 loss=0.080489 err=0.080489
I 2015-05-26 09:02:25 theanets.trainer:168 RmsProp 442 loss=0.076970 err=0.076970
I 2015-05-26 09:02:32 theanets.trainer:168 RmsProp 443 loss=0.092405 err=0.092405
I 2015-05-26 09:02:40 theanets.trainer:168 RmsProp 444 loss=0.096016 err=0.096016
I 2015-05-26 09:02:47 theanets.trainer:168 RmsProp 445 loss=0.075607 err=0.075607
I 2015-05-26 09:02:55 theanets.trainer:168 RmsProp 446 loss=0.087563 err=0.087563
I 2015-05-26 09:03:03 theanets.trainer:168 RmsProp 447 loss=0.090804 err=0.090804
I 2015-05-26 09:03:11 theanets.trainer:168 RmsProp 448 loss=0.081392 err=0.081392
I 2015-05-26 09:03:18 theanets.trainer:168 RmsProp 449 loss=0.083311 err=0.083311
I 2015-05-26 09:03:26 theanets.trainer:168 RmsProp 450 loss=0.080044 err=0.080044
I 2015-05-26 09:03:27 theanets.trainer:168 validation 45 loss=728.289246 err=728.289246 *
I 2015-05-26 09:03:34 theanets.trainer:168 RmsProp 451 loss=0.091401 err=0.091401
I 2015-05-26 09:03:42 theanets.trainer:168 RmsProp 452 loss=0.084296 err=0.084296
I 2015-05-26 09:03:49 theanets.trainer:168 RmsProp 453 loss=0.077083 err=0.077083
I 2015-05-26 09:03:56 theanets.trainer:168 RmsProp 454 loss=0.081620 err=0.081620
I 2015-05-26 09:04:05 theanets.trainer:168 RmsProp 455 loss=0.097412 err=0.097412
I 2015-05-26 09:04:12 theanets.trainer:168 RmsProp 456 loss=0.078354 err=0.078354
I 2015-05-26 09:04:19 theanets.trainer:168 RmsProp 457 loss=0.077169 err=0.077169
I 2015-05-26 09:04:26 theanets.trainer:168 RmsProp 458 loss=0.085896 err=0.085896
I 2015-05-26 09:04:34 theanets.trainer:168 RmsProp 459 loss=0.097704 err=0.097704
I 2015-05-26 09:04:42 theanets.trainer:168 RmsProp 460 loss=0.077766 err=0.077766
I 2015-05-26 09:04:43 theanets.trainer:168 validation 46 loss=727.458923 err=727.458923 *
I 2015-05-26 09:04:50 theanets.trainer:168 RmsProp 461 loss=0.080591 err=0.080591
I 2015-05-26 09:04:59 theanets.trainer:168 RmsProp 462 loss=0.078611 err=0.078611
I 2015-05-26 09:05:07 theanets.trainer:168 RmsProp 463 loss=0.079207 err=0.079207
I 2015-05-26 09:05:15 theanets.trainer:168 RmsProp 464 loss=0.086361 err=0.086361
I 2015-05-26 09:05:23 theanets.trainer:168 RmsProp 465 loss=0.075673 err=0.075673
I 2015-05-26 09:05:31 theanets.trainer:168 RmsProp 466 loss=0.076719 err=0.076719
I 2015-05-26 09:05:38 theanets.trainer:168 RmsProp 467 loss=0.094794 err=0.094794
I 2015-05-26 09:05:46 theanets.trainer:168 RmsProp 468 loss=0.077004 err=0.077004
I 2015-05-26 09:05:54 theanets.trainer:168 RmsProp 469 loss=0.081071 err=0.081071
I 2015-05-26 09:06:01 theanets.trainer:168 RmsProp 470 loss=0.079570 err=0.079570
I 2015-05-26 09:06:01 theanets.trainer:168 validation 47 loss=727.245361 err=727.245361 *
I 2015-05-26 09:06:09 theanets.trainer:168 RmsProp 471 loss=0.075683 err=0.075683
I 2015-05-26 09:06:17 theanets.trainer:168 RmsProp 472 loss=0.076346 err=0.076346
I 2015-05-26 09:06:25 theanets.trainer:168 RmsProp 473 loss=0.079184 err=0.079184
I 2015-05-26 09:06:33 theanets.trainer:168 RmsProp 474 loss=0.075112 err=0.075112
I 2015-05-26 09:06:41 theanets.trainer:168 RmsProp 475 loss=0.092663 err=0.092663
I 2015-05-26 09:06:49 theanets.trainer:168 RmsProp 476 loss=0.078812 err=0.078812
I 2015-05-26 09:06:57 theanets.trainer:168 RmsProp 477 loss=0.070721 err=0.070721
I 2015-05-26 09:07:05 theanets.trainer:168 RmsProp 478 loss=0.081150 err=0.081150
I 2015-05-26 09:07:13 theanets.trainer:168 RmsProp 479 loss=0.087235 err=0.087235
I 2015-05-26 09:07:21 theanets.trainer:168 RmsProp 480 loss=0.085383 err=0.085383
I 2015-05-26 09:07:22 theanets.trainer:168 validation 48 loss=726.140808 err=726.140808 *
I 2015-05-26 09:07:29 theanets.trainer:168 RmsProp 481 loss=0.071636 err=0.071636
I 2015-05-26 09:07:37 theanets.trainer:168 RmsProp 482 loss=0.082564 err=0.082564
I 2015-05-26 09:07:45 theanets.trainer:168 RmsProp 483 loss=0.073190 err=0.073190
I 2015-05-26 09:07:52 theanets.trainer:168 RmsProp 484 loss=0.080702 err=0.080702
I 2015-05-26 09:08:01 theanets.trainer:168 RmsProp 485 loss=0.074408 err=0.074408
I 2015-05-26 09:08:09 theanets.trainer:168 RmsProp 486 loss=0.081645 err=0.081645
I 2015-05-26 09:08:16 theanets.trainer:168 RmsProp 487 loss=0.071774 err=0.071774
I 2015-05-26 09:08:24 theanets.trainer:168 RmsProp 488 loss=0.082346 err=0.082346
I 2015-05-26 09:08:30 theanets.trainer:168 RmsProp 489 loss=0.072559 err=0.072559
I 2015-05-26 09:08:38 theanets.trainer:168 RmsProp 490 loss=0.074798 err=0.074798
I 2015-05-26 09:08:38 theanets.trainer:168 validation 49 loss=724.274597 err=724.274597 *
I 2015-05-26 09:08:46 theanets.trainer:168 RmsProp 491 loss=0.082374 err=0.082374
I 2015-05-26 09:08:53 theanets.trainer:168 RmsProp 492 loss=0.077609 err=0.077609
I 2015-05-26 09:09:00 theanets.trainer:168 RmsProp 493 loss=0.071661 err=0.071661
I 2015-05-26 09:09:07 theanets.trainer:168 RmsProp 494 loss=0.080340 err=0.080340
I 2015-05-26 09:09:16 theanets.trainer:168 RmsProp 495 loss=0.071174 err=0.071174
I 2015-05-26 09:09:24 theanets.trainer:168 RmsProp 496 loss=0.081233 err=0.081233
I 2015-05-26 09:09:31 theanets.trainer:168 RmsProp 497 loss=0.073693 err=0.073693
I 2015-05-26 09:09:39 theanets.trainer:168 RmsProp 498 loss=0.076292 err=0.076292
I 2015-05-26 09:09:47 theanets.trainer:168 RmsProp 499 loss=0.075134 err=0.075134
I 2015-05-26 09:09:55 theanets.trainer:168 RmsProp 500 loss=0.070196 err=0.070196
I 2015-05-26 09:09:55 theanets.trainer:168 validation 50 loss=723.554626 err=723.554626 *
I 2015-05-26 09:10:03 theanets.trainer:168 RmsProp 501 loss=0.086008 err=0.086008
I 2015-05-26 09:10:10 theanets.trainer:168 RmsProp 502 loss=0.091473 err=0.091473
I 2015-05-26 09:10:18 theanets.trainer:168 RmsProp 503 loss=0.076287 err=0.076287
I 2015-05-26 09:10:27 theanets.trainer:168 RmsProp 504 loss=0.071486 err=0.071486
I 2015-05-26 09:10:34 theanets.trainer:168 RmsProp 505 loss=0.083757 err=0.083757
I 2015-05-26 09:10:41 theanets.trainer:168 RmsProp 506 loss=0.080051 err=0.080051
I 2015-05-26 09:10:49 theanets.trainer:168 RmsProp 507 loss=0.077433 err=0.077433
I 2015-05-26 09:10:57 theanets.trainer:168 RmsProp 508 loss=0.076390 err=0.076390
I 2015-05-26 09:11:05 theanets.trainer:168 RmsProp 509 loss=0.074167 err=0.074167
I 2015-05-26 09:11:12 theanets.trainer:168 RmsProp 510 loss=0.075738 err=0.075738
I 2015-05-26 09:11:13 theanets.trainer:168 validation 51 loss=723.736389 err=723.736389
I 2015-05-26 09:11:20 theanets.trainer:168 RmsProp 511 loss=0.076556 err=0.076556
I 2015-05-26 09:11:27 theanets.trainer:168 RmsProp 512 loss=0.077591 err=0.077591
I 2015-05-26 09:11:34 theanets.trainer:168 RmsProp 513 loss=0.070185 err=0.070185
I 2015-05-26 09:11:41 theanets.trainer:168 RmsProp 514 loss=0.079640 err=0.079640
I 2015-05-26 09:11:49 theanets.trainer:168 RmsProp 515 loss=0.072362 err=0.072362
I 2015-05-26 09:11:56 theanets.trainer:168 RmsProp 516 loss=0.075728 err=0.075728
I 2015-05-26 09:12:03 theanets.trainer:168 RmsProp 517 loss=0.073772 err=0.073772
I 2015-05-26 09:12:11 theanets.trainer:168 RmsProp 518 loss=0.074467 err=0.074467
I 2015-05-26 09:12:18 theanets.trainer:168 RmsProp 519 loss=0.079380 err=0.079380
I 2015-05-26 09:12:26 theanets.trainer:168 RmsProp 520 loss=0.082528 err=0.082528
I 2015-05-26 09:12:26 theanets.trainer:168 validation 52 loss=722.858826 err=722.858826 *
I 2015-05-26 09:12:34 theanets.trainer:168 RmsProp 521 loss=0.070990 err=0.070990
I 2015-05-26 09:12:41 theanets.trainer:168 RmsProp 522 loss=0.068512 err=0.068512
I 2015-05-26 09:12:48 theanets.trainer:168 RmsProp 523 loss=0.074320 err=0.074320
I 2015-05-26 09:12:56 theanets.trainer:168 RmsProp 524 loss=0.076693 err=0.076693
I 2015-05-26 09:13:04 theanets.trainer:168 RmsProp 525 loss=0.069445 err=0.069445
I 2015-05-26 09:13:12 theanets.trainer:168 RmsProp 526 loss=0.078392 err=0.078392
I 2015-05-26 09:13:18 theanets.trainer:168 RmsProp 527 loss=0.084788 err=0.084788
I 2015-05-26 09:13:25 theanets.trainer:168 RmsProp 528 loss=0.072972 err=0.072972
I 2015-05-26 09:13:32 theanets.trainer:168 RmsProp 529 loss=0.070216 err=0.070216
I 2015-05-26 09:13:39 theanets.trainer:168 RmsProp 530 loss=0.077775 err=0.077775
I 2015-05-26 09:13:40 theanets.trainer:168 validation 53 loss=722.361755 err=722.361755 *
I 2015-05-26 09:13:47 theanets.trainer:168 RmsProp 531 loss=0.073471 err=0.073471
I 2015-05-26 09:13:54 theanets.trainer:168 RmsProp 532 loss=0.073142 err=0.073142
I 2015-05-26 09:14:00 theanets.trainer:168 RmsProp 533 loss=0.076067 err=0.076067
I 2015-05-26 09:14:07 theanets.trainer:168 RmsProp 534 loss=0.065656 err=0.065656
I 2015-05-26 09:14:14 theanets.trainer:168 RmsProp 535 loss=0.073884 err=0.073884
I 2015-05-26 09:14:21 theanets.trainer:168 RmsProp 536 loss=0.071705 err=0.071705
I 2015-05-26 09:14:29 theanets.trainer:168 RmsProp 537 loss=0.069638 err=0.069638
I 2015-05-26 09:14:37 theanets.trainer:168 RmsProp 538 loss=0.077892 err=0.077892
I 2015-05-26 09:14:43 theanets.trainer:168 RmsProp 539 loss=0.079586 err=0.079586
I 2015-05-26 09:14:51 theanets.trainer:168 RmsProp 540 loss=0.067412 err=0.067412
I 2015-05-26 09:14:51 theanets.trainer:168 validation 54 loss=721.867188 err=721.867188 *
I 2015-05-26 09:14:57 theanets.trainer:168 RmsProp 541 loss=0.074711 err=0.074711
I 2015-05-26 09:15:04 theanets.trainer:168 RmsProp 542 loss=0.063202 err=0.063202
I 2015-05-26 09:15:12 theanets.trainer:168 RmsProp 543 loss=0.094811 err=0.094811
I 2015-05-26 09:15:20 theanets.trainer:168 RmsProp 544 loss=0.081457 err=0.081457
I 2015-05-26 09:15:27 theanets.trainer:168 RmsProp 545 loss=0.064603 err=0.064603
I 2015-05-26 09:15:34 theanets.trainer:168 RmsProp 546 loss=0.073122 err=0.073122
I 2015-05-26 09:15:41 theanets.trainer:168 RmsProp 547 loss=0.061632 err=0.061632
I 2015-05-26 09:15:48 theanets.trainer:168 RmsProp 548 loss=0.094358 err=0.094358
I 2015-05-26 09:15:54 theanets.trainer:168 RmsProp 549 loss=0.087832 err=0.087832
I 2015-05-26 09:16:01 theanets.trainer:168 RmsProp 550 loss=0.065325 err=0.065325
I 2015-05-26 09:16:01 theanets.trainer:168 validation 55 loss=721.000000 err=721.000000 *
I 2015-05-26 09:16:09 theanets.trainer:168 RmsProp 551 loss=0.069101 err=0.069101
I 2015-05-26 09:16:16 theanets.trainer:168 RmsProp 552 loss=0.071306 err=0.071306
I 2015-05-26 09:16:23 theanets.trainer:168 RmsProp 553 loss=0.067348 err=0.067348
I 2015-05-26 09:16:31 theanets.trainer:168 RmsProp 554 loss=0.077499 err=0.077499
I 2015-05-26 09:16:38 theanets.trainer:168 RmsProp 555 loss=0.072159 err=0.072159
I 2015-05-26 09:16:45 theanets.trainer:168 RmsProp 556 loss=0.073238 err=0.073238
I 2015-05-26 09:16:53 theanets.trainer:168 RmsProp 557 loss=0.070971 err=0.070971
I 2015-05-26 09:16:59 theanets.trainer:168 RmsProp 558 loss=0.071800 err=0.071800
I 2015-05-26 09:17:07 theanets.trainer:168 RmsProp 559 loss=0.069930 err=0.069930
I 2015-05-26 09:17:14 theanets.trainer:168 RmsProp 560 loss=0.074309 err=0.074309
I 2015-05-26 09:17:15 theanets.trainer:168 validation 56 loss=720.704773 err=720.704773 *
I 2015-05-26 09:17:22 theanets.trainer:168 RmsProp 561 loss=0.069633 err=0.069633
I 2015-05-26 09:17:30 theanets.trainer:168 RmsProp 562 loss=0.076787 err=0.076787
I 2015-05-26 09:17:36 theanets.trainer:168 RmsProp 563 loss=0.085390 err=0.085390
I 2015-05-26 09:17:44 theanets.trainer:168 RmsProp 564 loss=0.073819 err=0.073819
I 2015-05-26 09:17:52 theanets.trainer:168 RmsProp 565 loss=0.068111 err=0.068111
I 2015-05-26 09:17:59 theanets.trainer:168 RmsProp 566 loss=0.065152 err=0.065152
I 2015-05-26 09:18:06 theanets.trainer:168 RmsProp 567 loss=0.079000 err=0.079000
I 2015-05-26 09:18:13 theanets.trainer:168 RmsProp 568 loss=0.064030 err=0.064030
I 2015-05-26 09:18:20 theanets.trainer:168 RmsProp 569 loss=0.070507 err=0.070507
I 2015-05-26 09:18:28 theanets.trainer:168 RmsProp 570 loss=0.075090 err=0.075090
I 2015-05-26 09:18:29 theanets.trainer:168 validation 57 loss=720.538269 err=720.538269 *
I 2015-05-26 09:18:35 theanets.trainer:168 RmsProp 571 loss=0.068593 err=0.068593
I 2015-05-26 09:18:43 theanets.trainer:168 RmsProp 572 loss=0.070893 err=0.070893
I 2015-05-26 09:18:50 theanets.trainer:168 RmsProp 573 loss=0.071043 err=0.071043
I 2015-05-26 09:18:57 theanets.trainer:168 RmsProp 574 loss=0.072229 err=0.072229
I 2015-05-26 09:19:04 theanets.trainer:168 RmsProp 575 loss=0.072843 err=0.072843
I 2015-05-26 09:19:11 theanets.trainer:168 RmsProp 576 loss=0.062992 err=0.062992
I 2015-05-26 09:19:18 theanets.trainer:168 RmsProp 577 loss=0.071444 err=0.071444
I 2015-05-26 09:19:26 theanets.trainer:168 RmsProp 578 loss=0.066037 err=0.066037
I 2015-05-26 09:19:34 theanets.trainer:168 RmsProp 579 loss=0.072179 err=0.072179
I 2015-05-26 09:19:40 theanets.trainer:168 RmsProp 580 loss=0.074382 err=0.074382
I 2015-05-26 09:19:41 theanets.trainer:168 validation 58 loss=720.740173 err=720.740173
I 2015-05-26 09:19:48 theanets.trainer:168 RmsProp 581 loss=0.064877 err=0.064877
I 2015-05-26 09:19:55 theanets.trainer:168 RmsProp 582 loss=0.068484 err=0.068484
I 2015-05-26 09:20:02 theanets.trainer:168 RmsProp 583 loss=0.065738 err=0.065738
I 2015-05-26 09:20:09 theanets.trainer:168 RmsProp 584 loss=0.069934 err=0.069934
I 2015-05-26 09:20:17 theanets.trainer:168 RmsProp 585 loss=0.067296 err=0.067296
I 2015-05-26 09:20:24 theanets.trainer:168 RmsProp 586 loss=0.059833 err=0.059833
I 2015-05-26 09:20:31 theanets.trainer:168 RmsProp 587 loss=0.082812 err=0.082812
I 2015-05-26 09:20:38 theanets.trainer:168 RmsProp 588 loss=0.063616 err=0.063616
I 2015-05-26 09:20:45 theanets.trainer:168 RmsProp 589 loss=0.065470 err=0.065470
I 2015-05-26 09:20:52 theanets.trainer:168 RmsProp 590 loss=0.066595 err=0.066595
I 2015-05-26 09:20:52 theanets.trainer:168 validation 59 loss=719.085144 err=719.085144 *
I 2015-05-26 09:20:59 theanets.trainer:168 RmsProp 591 loss=0.072880 err=0.072880
I 2015-05-26 09:21:07 theanets.trainer:168 RmsProp 592 loss=0.072187 err=0.072187
I 2015-05-26 09:21:15 theanets.trainer:168 RmsProp 593 loss=0.062588 err=0.062588
I 2015-05-26 09:21:22 theanets.trainer:168 RmsProp 594 loss=0.062215 err=0.062215
I 2015-05-26 09:21:28 theanets.trainer:168 RmsProp 595 loss=0.078460 err=0.078460
I 2015-05-26 09:21:36 theanets.trainer:168 RmsProp 596 loss=0.077706 err=0.077706
I 2015-05-26 09:21:44 theanets.trainer:168 RmsProp 597 loss=0.076737 err=0.076737
I 2015-05-26 09:21:51 theanets.trainer:168 RmsProp 598 loss=0.060363 err=0.060363
I 2015-05-26 09:21:57 theanets.trainer:168 RmsProp 599 loss=0.065276 err=0.065276
I 2015-05-26 09:22:04 theanets.trainer:168 RmsProp 600 loss=0.075484 err=0.075484
I 2015-05-26 09:22:04 theanets.trainer:168 validation 60 loss=718.317017 err=718.317017 *
I 2015-05-26 09:22:11 theanets.trainer:168 RmsProp 601 loss=0.070847 err=0.070847
I 2015-05-26 09:22:18 theanets.trainer:168 RmsProp 602 loss=0.061578 err=0.061578
I 2015-05-26 09:22:25 theanets.trainer:168 RmsProp 603 loss=0.072237 err=0.072237
I 2015-05-26 09:22:32 theanets.trainer:168 RmsProp 604 loss=0.067319 err=0.067319
I 2015-05-26 09:22:40 theanets.trainer:168 RmsProp 605 loss=0.063827 err=0.063827
I 2015-05-26 09:22:47 theanets.trainer:168 RmsProp 606 loss=0.068535 err=0.068535
I 2015-05-26 09:22:54 theanets.trainer:168 RmsProp 607 loss=0.071692 err=0.071692
I 2015-05-26 09:23:01 theanets.trainer:168 RmsProp 608 loss=0.068114 err=0.068114
I 2015-05-26 09:23:08 theanets.trainer:168 RmsProp 609 loss=0.056959 err=0.056959
I 2015-05-26 09:23:15 theanets.trainer:168 RmsProp 610 loss=0.086713 err=0.086713
I 2015-05-26 09:23:15 theanets.trainer:168 validation 61 loss=717.824402 err=717.824402 *
I 2015-05-26 09:23:22 theanets.trainer:168 RmsProp 611 loss=0.077022 err=0.077022
I 2015-05-26 09:23:29 theanets.trainer:168 RmsProp 612 loss=0.060314 err=0.060314
I 2015-05-26 09:23:35 theanets.trainer:168 RmsProp 613 loss=0.062566 err=0.062566
I 2015-05-26 09:23:42 theanets.trainer:168 RmsProp 614 loss=0.064347 err=0.064347
I 2015-05-26 09:23:50 theanets.trainer:168 RmsProp 615 loss=0.067510 err=0.067510
I 2015-05-26 09:23:56 theanets.trainer:168 RmsProp 616 loss=0.066183 err=0.066183
I 2015-05-26 09:24:03 theanets.trainer:168 RmsProp 617 loss=0.062963 err=0.062963
I 2015-05-26 09:24:09 theanets.trainer:168 RmsProp 618 loss=0.060111 err=0.060111
I 2015-05-26 09:24:16 theanets.trainer:168 RmsProp 619 loss=0.080347 err=0.080347
I 2015-05-26 09:24:23 theanets.trainer:168 RmsProp 620 loss=0.065673 err=0.065673
I 2015-05-26 09:24:23 theanets.trainer:168 validation 62 loss=718.133789 err=718.133789
I 2015-05-26 09:24:30 theanets.trainer:168 RmsProp 621 loss=0.064556 err=0.064556
I 2015-05-26 09:24:36 theanets.trainer:168 RmsProp 622 loss=0.065532 err=0.065532
I 2015-05-26 09:24:43 theanets.trainer:168 RmsProp 623 loss=0.063588 err=0.063588
I 2015-05-26 09:24:50 theanets.trainer:168 RmsProp 624 loss=0.071748 err=0.071748
I 2015-05-26 09:24:58 theanets.trainer:168 RmsProp 625 loss=0.067188 err=0.067188
I 2015-05-26 09:25:05 theanets.trainer:168 RmsProp 626 loss=0.059234 err=0.059234
I 2015-05-26 09:25:12 theanets.trainer:168 RmsProp 627 loss=0.069176 err=0.069176
I 2015-05-26 09:25:19 theanets.trainer:168 RmsProp 628 loss=0.066530 err=0.066530
I 2015-05-26 09:25:26 theanets.trainer:168 RmsProp 629 loss=0.062360 err=0.062360
I 2015-05-26 09:25:33 theanets.trainer:168 RmsProp 630 loss=0.059259 err=0.059259
I 2015-05-26 09:25:33 theanets.trainer:168 validation 63 loss=716.256287 err=716.256287 *
I 2015-05-26 09:25:40 theanets.trainer:168 RmsProp 631 loss=0.066978 err=0.066978
I 2015-05-26 09:25:46 theanets.trainer:168 RmsProp 632 loss=0.062987 err=0.062987
I 2015-05-26 09:25:53 theanets.trainer:168 RmsProp 633 loss=0.065011 err=0.065011
I 2015-05-26 09:26:01 theanets.trainer:168 RmsProp 634 loss=0.069843 err=0.069843
I 2015-05-26 09:26:07 theanets.trainer:168 RmsProp 635 loss=0.063503 err=0.063503
I 2015-05-26 09:26:14 theanets.trainer:168 RmsProp 636 loss=0.061338 err=0.061338
I 2015-05-26 09:26:21 theanets.trainer:168 RmsProp 637 loss=0.063653 err=0.063653
I 2015-05-26 09:26:28 theanets.trainer:168 RmsProp 638 loss=0.068861 err=0.068861
I 2015-05-26 09:26:35 theanets.trainer:168 RmsProp 639 loss=0.065528 err=0.065528
I 2015-05-26 09:26:42 theanets.trainer:168 RmsProp 640 loss=0.062078 err=0.062078
I 2015-05-26 09:26:42 theanets.trainer:168 validation 64 loss=716.201782 err=716.201782 *
I 2015-05-26 09:26:49 theanets.trainer:168 RmsProp 641 loss=0.056544 err=0.056544
I 2015-05-26 09:26:56 theanets.trainer:168 RmsProp 642 loss=0.071538 err=0.071538
I 2015-05-26 09:27:03 theanets.trainer:168 RmsProp 643 loss=0.086827 err=0.086827
I 2015-05-26 09:27:09 theanets.trainer:168 RmsProp 644 loss=0.063735 err=0.063735
I 2015-05-26 09:27:15 theanets.trainer:168 RmsProp 645 loss=0.058210 err=0.058210
I 2015-05-26 09:27:22 theanets.trainer:168 RmsProp 646 loss=0.074399 err=0.074399
I 2015-05-26 09:27:28 theanets.trainer:168 RmsProp 647 loss=0.064504 err=0.064504
I 2015-05-26 09:27:35 theanets.trainer:168 RmsProp 648 loss=0.058498 err=0.058498
I 2015-05-26 09:27:42 theanets.trainer:168 RmsProp 649 loss=0.051536 err=0.051536
I 2015-05-26 09:27:49 theanets.trainer:168 RmsProp 650 loss=0.103213 err=0.103213
I 2015-05-26 09:27:49 theanets.trainer:168 validation 65 loss=716.202332 err=716.202332
I 2015-05-26 09:27:56 theanets.trainer:168 RmsProp 651 loss=0.064938 err=0.064938
I 2015-05-26 09:28:03 theanets.trainer:168 RmsProp 652 loss=0.059020 err=0.059020
I 2015-05-26 09:28:09 theanets.trainer:168 RmsProp 653 loss=0.061808 err=0.061808
I 2015-05-26 09:28:16 theanets.trainer:168 RmsProp 654 loss=0.054078 err=0.054078
I 2015-05-26 09:28:22 theanets.trainer:168 RmsProp 655 loss=0.068202 err=0.068202
I 2015-05-26 09:28:30 theanets.trainer:168 RmsProp 656 loss=0.062044 err=0.062044
I 2015-05-26 09:28:37 theanets.trainer:168 RmsProp 657 loss=0.064857 err=0.064857
I 2015-05-26 09:28:43 theanets.trainer:168 RmsProp 658 loss=0.061163 err=0.061163
I 2015-05-26 09:28:51 theanets.trainer:168 RmsProp 659 loss=0.065095 err=0.065095
I 2015-05-26 09:28:58 theanets.trainer:168 RmsProp 660 loss=0.057359 err=0.057359
I 2015-05-26 09:28:59 theanets.trainer:168 validation 66 loss=714.282715 err=714.282715 *
I 2015-05-26 09:29:05 theanets.trainer:168 RmsProp 661 loss=0.065333 err=0.065333
I 2015-05-26 09:29:12 theanets.trainer:168 RmsProp 662 loss=0.070883 err=0.070883
I 2015-05-26 09:29:19 theanets.trainer:168 RmsProp 663 loss=0.056949 err=0.056949
I 2015-05-26 09:29:25 theanets.trainer:168 RmsProp 664 loss=0.065193 err=0.065193
I 2015-05-26 09:29:32 theanets.trainer:168 RmsProp 665 loss=0.066260 err=0.066260
I 2015-05-26 09:29:38 theanets.trainer:168 RmsProp 666 loss=0.061571 err=0.061571
I 2015-05-26 09:29:45 theanets.trainer:168 RmsProp 667 loss=0.060385 err=0.060385
I 2015-05-26 09:29:51 theanets.trainer:168 RmsProp 668 loss=0.060006 err=0.060006
I 2015-05-26 09:29:58 theanets.trainer:168 RmsProp 669 loss=0.065159 err=0.065159
I 2015-05-26 09:30:05 theanets.trainer:168 RmsProp 670 loss=0.062333 err=0.062333
I 2015-05-26 09:30:05 theanets.trainer:168 validation 67 loss=714.542480 err=714.542480
I 2015-05-26 09:30:12 theanets.trainer:168 RmsProp 671 loss=0.058750 err=0.058750
I 2015-05-26 09:30:19 theanets.trainer:168 RmsProp 672 loss=0.063397 err=0.063397
I 2015-05-26 09:30:25 theanets.trainer:168 RmsProp 673 loss=0.057394 err=0.057394
I 2015-05-26 09:30:33 theanets.trainer:168 RmsProp 674 loss=0.066792 err=0.066792
I 2015-05-26 09:30:40 theanets.trainer:168 RmsProp 675 loss=0.061022 err=0.061022
I 2015-05-26 09:30:47 theanets.trainer:168 RmsProp 676 loss=0.061746 err=0.061746
I 2015-05-26 09:30:53 theanets.trainer:168 RmsProp 677 loss=0.060226 err=0.060226
I 2015-05-26 09:31:00 theanets.trainer:168 RmsProp 678 loss=0.063007 err=0.063007
I 2015-05-26 09:31:07 theanets.trainer:168 RmsProp 679 loss=0.056508 err=0.056508
I 2015-05-26 09:31:13 theanets.trainer:168 RmsProp 680 loss=0.062068 err=0.062068
I 2015-05-26 09:31:14 theanets.trainer:168 validation 68 loss=713.534241 err=713.534241 *
I 2015-05-26 09:31:21 theanets.trainer:168 RmsProp 681 loss=0.064035 err=0.064035
I 2015-05-26 09:31:27 theanets.trainer:168 RmsProp 682 loss=0.068106 err=0.068106
I 2015-05-26 09:31:34 theanets.trainer:168 RmsProp 683 loss=0.059200 err=0.059200
I 2015-05-26 09:31:41 theanets.trainer:168 RmsProp 684 loss=0.060801 err=0.060801
I 2015-05-26 09:31:47 theanets.trainer:168 RmsProp 685 loss=0.058891 err=0.058891
I 2015-05-26 09:31:55 theanets.trainer:168 RmsProp 686 loss=0.059803 err=0.059803
I 2015-05-26 09:32:01 theanets.trainer:168 RmsProp 687 loss=0.059633 err=0.059633
I 2015-05-26 09:32:08 theanets.trainer:168 RmsProp 688 loss=0.067043 err=0.067043
I 2015-05-26 09:32:14 theanets.trainer:168 RmsProp 689 loss=0.054830 err=0.054830
I 2015-05-26 09:32:21 theanets.trainer:168 RmsProp 690 loss=0.072379 err=0.072379
I 2015-05-26 09:32:21 theanets.trainer:168 validation 69 loss=712.824646 err=712.824646 *
I 2015-05-26 09:32:28 theanets.trainer:168 RmsProp 691 loss=0.062830 err=0.062830
I 2015-05-26 09:32:35 theanets.trainer:168 RmsProp 692 loss=0.052233 err=0.052233
I 2015-05-26 09:32:41 theanets.trainer:168 RmsProp 693 loss=0.077461 err=0.077461
I 2015-05-26 09:32:48 theanets.trainer:168 RmsProp 694 loss=0.063345 err=0.063345
I 2015-05-26 09:32:54 theanets.trainer:168 RmsProp 695 loss=0.056815 err=0.056815
I 2015-05-26 09:33:01 theanets.trainer:168 RmsProp 696 loss=0.061204 err=0.061204
I 2015-05-26 09:33:08 theanets.trainer:168 RmsProp 697 loss=0.059942 err=0.059942
I 2015-05-26 09:33:14 theanets.trainer:168 RmsProp 698 loss=0.057913 err=0.057913
I 2015-05-26 09:33:21 theanets.trainer:168 RmsProp 699 loss=0.061621 err=0.061621
I 2015-05-26 09:33:28 theanets.trainer:168 RmsProp 700 loss=0.055168 err=0.055168
I 2015-05-26 09:33:28 theanets.trainer:168 validation 70 loss=711.296570 err=711.296570 *
I 2015-05-26 09:33:35 theanets.trainer:168 RmsProp 701 loss=0.067639 err=0.067639
I 2015-05-26 09:33:42 theanets.trainer:168 RmsProp 702 loss=0.052210 err=0.052210
I 2015-05-26 09:33:49 theanets.trainer:168 RmsProp 703 loss=0.065449 err=0.065449
I 2015-05-26 09:33:55 theanets.trainer:168 RmsProp 704 loss=0.058739 err=0.058739
I 2015-05-26 09:34:01 theanets.trainer:168 RmsProp 705 loss=0.062857 err=0.062857
I 2015-05-26 09:34:08 theanets.trainer:168 RmsProp 706 loss=0.058708 err=0.058708
I 2015-05-26 09:34:15 theanets.trainer:168 RmsProp 707 loss=0.063798 err=0.063798
I 2015-05-26 09:34:22 theanets.trainer:168 RmsProp 708 loss=0.059865 err=0.059865
I 2015-05-26 09:34:29 theanets.trainer:168 RmsProp 709 loss=0.058165 err=0.058165
I 2015-05-26 09:34:36 theanets.trainer:168 RmsProp 710 loss=0.066994 err=0.066994
I 2015-05-26 09:34:36 theanets.trainer:168 validation 71 loss=712.157104 err=712.157104
I 2015-05-26 09:34:43 theanets.trainer:168 RmsProp 711 loss=0.070623 err=0.070623
I 2015-05-26 09:34:49 theanets.trainer:168 RmsProp 712 loss=0.054848 err=0.054848
I 2015-05-26 09:34:56 theanets.trainer:168 RmsProp 713 loss=0.057627 err=0.057627
I 2015-05-26 09:35:02 theanets.trainer:168 RmsProp 714 loss=0.056563 err=0.056563
I 2015-05-26 09:35:09 theanets.trainer:168 RmsProp 715 loss=0.065649 err=0.065649
I 2015-05-26 09:35:15 theanets.trainer:168 RmsProp 716 loss=0.066108 err=0.066108
I 2015-05-26 09:35:22 theanets.trainer:168 RmsProp 717 loss=0.054572 err=0.054572
I 2015-05-26 09:35:29 theanets.trainer:168 RmsProp 718 loss=0.059293 err=0.059293
I 2015-05-26 09:35:36 theanets.trainer:168 RmsProp 719 loss=0.062649 err=0.062649
I 2015-05-26 09:35:43 theanets.trainer:168 RmsProp 720 loss=0.059255 err=0.059255
I 2015-05-26 09:35:44 theanets.trainer:168 validation 72 loss=710.951355 err=710.951355 *
I 2015-05-26 09:35:51 theanets.trainer:168 RmsProp 721 loss=0.059528 err=0.059528
I 2015-05-26 09:35:57 theanets.trainer:168 RmsProp 722 loss=0.059755 err=0.059755
I 2015-05-26 09:36:03 theanets.trainer:168 RmsProp 723 loss=0.060216 err=0.060216
I 2015-05-26 09:36:09 theanets.trainer:168 RmsProp 724 loss=0.057327 err=0.057327
I 2015-05-26 09:36:17 theanets.trainer:168 RmsProp 725 loss=0.070395 err=0.070395
I 2015-05-26 09:36:24 theanets.trainer:168 RmsProp 726 loss=0.055556 err=0.055556
I 2015-05-26 09:36:31 theanets.trainer:168 RmsProp 727 loss=0.051609 err=0.051609
I 2015-05-26 09:36:37 theanets.trainer:168 RmsProp 728 loss=0.070336 err=0.070336
I 2015-05-26 09:36:44 theanets.trainer:168 RmsProp 729 loss=0.054224 err=0.054224
I 2015-05-26 09:36:51 theanets.trainer:168 RmsProp 730 loss=0.064208 err=0.064208
I 2015-05-26 09:36:51 theanets.trainer:168 validation 73 loss=710.949219 err=710.949219 *
I 2015-05-26 09:36:57 theanets.trainer:168 RmsProp 731 loss=0.062665 err=0.062665
I 2015-05-26 09:37:03 theanets.trainer:168 RmsProp 732 loss=0.056552 err=0.056552
I 2015-05-26 09:37:10 theanets.trainer:168 RmsProp 733 loss=0.053758 err=0.053758
I 2015-05-26 09:37:16 theanets.trainer:168 RmsProp 734 loss=0.063853 err=0.063853
I 2015-05-26 09:37:23 theanets.trainer:168 RmsProp 735 loss=0.064510 err=0.064510
I 2015-05-26 09:37:30 theanets.trainer:168 RmsProp 736 loss=0.051510 err=0.051510
I 2015-05-26 09:37:37 theanets.trainer:168 RmsProp 737 loss=0.058926 err=0.058926
I 2015-05-26 09:37:44 theanets.trainer:168 RmsProp 738 loss=0.060279 err=0.060279
I 2015-05-26 09:37:51 theanets.trainer:168 RmsProp 739 loss=0.066256 err=0.066256
I 2015-05-26 09:37:57 theanets.trainer:168 RmsProp 740 loss=0.057819 err=0.057819
I 2015-05-26 09:37:58 theanets.trainer:168 validation 74 loss=709.174744 err=709.174744 *
I 2015-05-26 09:38:04 theanets.trainer:168 RmsProp 741 loss=0.056590 err=0.056590
I 2015-05-26 09:38:11 theanets.trainer:168 RmsProp 742 loss=0.051954 err=0.051954
I 2015-05-26 09:38:18 theanets.trainer:168 RmsProp 743 loss=0.060691 err=0.060691
I 2015-05-26 09:38:25 theanets.trainer:168 RmsProp 744 loss=0.052687 err=0.052687
I 2015-05-26 09:38:32 theanets.trainer:168 RmsProp 745 loss=0.064770 err=0.064770
I 2015-05-26 09:38:39 theanets.trainer:168 RmsProp 746 loss=0.053719 err=0.053719
I 2015-05-26 09:38:46 theanets.trainer:168 RmsProp 747 loss=0.060520 err=0.060520
I 2015-05-26 09:38:53 theanets.trainer:168 RmsProp 748 loss=0.053166 err=0.053166
I 2015-05-26 09:39:01 theanets.trainer:168 RmsProp 749 loss=0.056028 err=0.056028
I 2015-05-26 09:39:07 theanets.trainer:168 RmsProp 750 loss=0.057679 err=0.057679
I 2015-05-26 09:39:07 theanets.trainer:168 validation 75 loss=709.547302 err=709.547302
I 2015-05-26 09:39:14 theanets.trainer:168 RmsProp 751 loss=0.059801 err=0.059801
I 2015-05-26 09:39:20 theanets.trainer:168 RmsProp 752 loss=0.050832 err=0.050832
I 2015-05-26 09:39:26 theanets.trainer:168 RmsProp 753 loss=0.056495 err=0.056495
I 2015-05-26 09:39:33 theanets.trainer:168 RmsProp 754 loss=0.057271 err=0.057271
I 2015-05-26 09:39:39 theanets.trainer:168 RmsProp 755 loss=0.057458 err=0.057458
I 2015-05-26 09:39:46 theanets.trainer:168 RmsProp 756 loss=0.051109 err=0.051109
I 2015-05-26 09:39:53 theanets.trainer:168 RmsProp 757 loss=0.067216 err=0.067216
I 2015-05-26 09:40:00 theanets.trainer:168 RmsProp 758 loss=0.062388 err=0.062388
I 2015-05-26 09:40:07 theanets.trainer:168 RmsProp 759 loss=0.055320 err=0.055320
I 2015-05-26 09:40:14 theanets.trainer:168 RmsProp 760 loss=0.050633 err=0.050633
I 2015-05-26 09:40:15 theanets.trainer:168 validation 76 loss=707.974060 err=707.974060 *
I 2015-05-26 09:40:21 theanets.trainer:168 RmsProp 761 loss=0.056173 err=0.056173
I 2015-05-26 09:40:28 theanets.trainer:168 RmsProp 762 loss=0.061549 err=0.061549
I 2015-05-26 09:40:34 theanets.trainer:168 RmsProp 763 loss=0.055535 err=0.055535
I 2015-05-26 09:40:41 theanets.trainer:168 RmsProp 764 loss=0.057827 err=0.057827
I 2015-05-26 09:40:47 theanets.trainer:168 RmsProp 765 loss=0.056381 err=0.056381
I 2015-05-26 09:40:54 theanets.trainer:168 RmsProp 766 loss=0.053501 err=0.053501
I 2015-05-26 09:41:01 theanets.trainer:168 RmsProp 767 loss=0.050884 err=0.050884
I 2015-05-26 09:41:08 theanets.trainer:168 RmsProp 768 loss=0.058467 err=0.058467
I 2015-05-26 09:41:15 theanets.trainer:168 RmsProp 769 loss=0.057282 err=0.057282
I 2015-05-26 09:41:22 theanets.trainer:168 RmsProp 770 loss=0.052283 err=0.052283
I 2015-05-26 09:41:22 theanets.trainer:168 validation 77 loss=708.820312 err=708.820312
I 2015-05-26 09:41:28 theanets.trainer:168 RmsProp 771 loss=0.057461 err=0.057461
I 2015-05-26 09:41:35 theanets.trainer:168 RmsProp 772 loss=0.053638 err=0.053638
I 2015-05-26 09:41:42 theanets.trainer:168 RmsProp 773 loss=0.056407 err=0.056407
I 2015-05-26 09:41:49 theanets.trainer:168 RmsProp 774 loss=0.052647 err=0.052647
I 2015-05-26 09:41:55 theanets.trainer:168 RmsProp 775 loss=0.057484 err=0.057484
I 2015-05-26 09:42:02 theanets.trainer:168 RmsProp 776 loss=0.050910 err=0.050910
I 2015-05-26 09:42:09 theanets.trainer:168 RmsProp 777 loss=0.057751 err=0.057751
I 2015-05-26 09:42:15 theanets.trainer:168 RmsProp 778 loss=0.054767 err=0.054767
I 2015-05-26 09:42:22 theanets.trainer:168 RmsProp 779 loss=0.049664 err=0.049664
I 2015-05-26 09:42:28 theanets.trainer:168 RmsProp 780 loss=0.056579 err=0.056579
I 2015-05-26 09:42:29 theanets.trainer:168 validation 78 loss=707.814819 err=707.814819 *
I 2015-05-26 09:42:36 theanets.trainer:168 RmsProp 781 loss=0.055528 err=0.055528
I 2015-05-26 09:42:42 theanets.trainer:168 RmsProp 782 loss=0.055589 err=0.055589
I 2015-05-26 09:42:49 theanets.trainer:168 RmsProp 783 loss=0.055708 err=0.055708
I 2015-05-26 09:42:56 theanets.trainer:168 RmsProp 784 loss=0.054340 err=0.054340
I 2015-05-26 09:43:03 theanets.trainer:168 RmsProp 785 loss=0.059522 err=0.059522
I 2015-05-26 09:43:10 theanets.trainer:168 RmsProp 786 loss=0.053920 err=0.053920
I 2015-05-26 09:43:16 theanets.trainer:168 RmsProp 787 loss=0.050541 err=0.050541
I 2015-05-26 09:43:23 theanets.trainer:168 RmsProp 788 loss=0.055143 err=0.055143
I 2015-05-26 09:43:29 theanets.trainer:168 RmsProp 789 loss=0.053981 err=0.053981
I 2015-05-26 09:43:36 theanets.trainer:168 RmsProp 790 loss=0.051305 err=0.051305
I 2015-05-26 09:43:36 theanets.trainer:168 validation 79 loss=706.800964 err=706.800964 *
I 2015-05-26 09:43:43 theanets.trainer:168 RmsProp 791 loss=0.056987 err=0.056987
I 2015-05-26 09:43:49 theanets.trainer:168 RmsProp 792 loss=0.054731 err=0.054731
I 2015-05-26 09:43:56 theanets.trainer:168 RmsProp 793 loss=0.062666 err=0.062666
I 2015-05-26 09:44:02 theanets.trainer:168 RmsProp 794 loss=0.051524 err=0.051524
I 2015-05-26 09:44:09 theanets.trainer:168 RmsProp 795 loss=0.055593 err=0.055593
I 2015-05-26 09:44:16 theanets.trainer:168 RmsProp 796 loss=0.055330 err=0.055330
I 2015-05-26 09:44:24 theanets.trainer:168 RmsProp 797 loss=0.049238 err=0.049238
I 2015-05-26 09:44:31 theanets.trainer:168 RmsProp 798 loss=0.061025 err=0.061025
I 2015-05-26 09:44:38 theanets.trainer:168 RmsProp 799 loss=0.051280 err=0.051280
I 2015-05-26 09:44:45 theanets.trainer:168 RmsProp 800 loss=0.054289 err=0.054289
I 2015-05-26 09:44:45 theanets.trainer:168 validation 80 loss=706.230164 err=706.230164 *
I 2015-05-26 09:44:51 theanets.trainer:168 RmsProp 801 loss=0.055833 err=0.055833
I 2015-05-26 09:44:57 theanets.trainer:168 RmsProp 802 loss=0.058265 err=0.058265
I 2015-05-26 09:45:03 theanets.trainer:168 RmsProp 803 loss=0.052657 err=0.052657
I 2015-05-26 09:45:10 theanets.trainer:168 RmsProp 804 loss=0.051518 err=0.051518
I 2015-05-26 09:45:17 theanets.trainer:168 RmsProp 805 loss=0.048908 err=0.048908
I 2015-05-26 09:45:24 theanets.trainer:168 RmsProp 806 loss=0.052334 err=0.052334
I 2015-05-26 09:45:30 theanets.trainer:168 RmsProp 807 loss=0.053609 err=0.053609
I 2015-05-26 09:45:37 theanets.trainer:168 RmsProp 808 loss=0.051758 err=0.051758
I 2015-05-26 09:45:43 theanets.trainer:168 RmsProp 809 loss=0.062532 err=0.062532
I 2015-05-26 09:45:50 theanets.trainer:168 RmsProp 810 loss=0.054111 err=0.054111
I 2015-05-26 09:45:51 theanets.trainer:168 validation 81 loss=705.869690 err=705.869690 *
I 2015-05-26 09:45:57 theanets.trainer:168 RmsProp 811 loss=0.051309 err=0.051309
I 2015-05-26 09:46:04 theanets.trainer:168 RmsProp 812 loss=0.051133 err=0.051133
I 2015-05-26 09:46:11 theanets.trainer:168 RmsProp 813 loss=0.054710 err=0.054710
I 2015-05-26 09:46:18 theanets.trainer:168 RmsProp 814 loss=0.048662 err=0.048662
I 2015-05-26 09:46:25 theanets.trainer:168 RmsProp 815 loss=0.056432 err=0.056432
I 2015-05-26 09:46:32 theanets.trainer:168 RmsProp 816 loss=0.051271 err=0.051271
I 2015-05-26 09:46:38 theanets.trainer:168 RmsProp 817 loss=0.051866 err=0.051866
I 2015-05-26 09:46:45 theanets.trainer:168 RmsProp 818 loss=0.049127 err=0.049127
I 2015-05-26 09:46:52 theanets.trainer:168 RmsProp 819 loss=0.044891 err=0.044891
I 2015-05-26 09:46:59 theanets.trainer:168 RmsProp 820 loss=0.076713 err=0.076713
I 2015-05-26 09:47:00 theanets.trainer:168 validation 82 loss=704.669434 err=704.669434 *
I 2015-05-26 09:47:06 theanets.trainer:168 RmsProp 821 loss=0.055442 err=0.055442
I 2015-05-26 09:47:13 theanets.trainer:168 RmsProp 822 loss=0.046823 err=0.046823
I 2015-05-26 09:47:20 theanets.trainer:168 RmsProp 823 loss=0.051999 err=0.051999
I 2015-05-26 09:47:27 theanets.trainer:168 RmsProp 824 loss=0.060599 err=0.060599
I 2015-05-26 09:47:34 theanets.trainer:168 RmsProp 825 loss=0.050729 err=0.050729
I 2015-05-26 09:47:40 theanets.trainer:168 RmsProp 826 loss=0.050477 err=0.050477
I 2015-05-26 09:47:47 theanets.trainer:168 RmsProp 827 loss=0.055530 err=0.055530
I 2015-05-26 09:47:54 theanets.trainer:168 RmsProp 828 loss=0.050327 err=0.050327
I 2015-05-26 09:48:01 theanets.trainer:168 RmsProp 829 loss=0.052601 err=0.052601
I 2015-05-26 09:48:08 theanets.trainer:168 RmsProp 830 loss=0.055676 err=0.055676
I 2015-05-26 09:48:08 theanets.trainer:168 validation 83 loss=704.197998 err=704.197998 *
I 2015-05-26 09:48:14 theanets.trainer:168 RmsProp 831 loss=0.044280 err=0.044280
I 2015-05-26 09:48:21 theanets.trainer:168 RmsProp 832 loss=0.061410 err=0.061410
I 2015-05-26 09:48:27 theanets.trainer:168 RmsProp 833 loss=0.054157 err=0.054157
I 2015-05-26 09:48:34 theanets.trainer:168 RmsProp 834 loss=0.044190 err=0.044190
I 2015-05-26 09:48:40 theanets.trainer:168 RmsProp 835 loss=0.074299 err=0.074299
I 2015-05-26 09:48:47 theanets.trainer:168 RmsProp 836 loss=0.054916 err=0.054916
I 2015-05-26 09:48:54 theanets.trainer:168 RmsProp 837 loss=0.046522 err=0.046522
I 2015-05-26 09:49:01 theanets.trainer:168 RmsProp 838 loss=0.055756 err=0.055756
I 2015-05-26 09:49:08 theanets.trainer:168 RmsProp 839 loss=0.050268 err=0.050268
I 2015-05-26 09:49:15 theanets.trainer:168 RmsProp 840 loss=0.056540 err=0.056540
I 2015-05-26 09:49:16 theanets.trainer:168 validation 84 loss=703.788025 err=703.788025 *
I 2015-05-26 09:49:22 theanets.trainer:168 RmsProp 841 loss=0.050730 err=0.050730
I 2015-05-26 09:49:29 theanets.trainer:168 RmsProp 842 loss=0.050415 err=0.050415
I 2015-05-26 09:49:35 theanets.trainer:168 RmsProp 843 loss=0.052348 err=0.052348
I 2015-05-26 09:49:41 theanets.trainer:168 RmsProp 844 loss=0.051616 err=0.051616
I 2015-05-26 09:49:48 theanets.trainer:168 RmsProp 845 loss=0.053480 err=0.053480
I 2015-05-26 09:49:54 theanets.trainer:168 RmsProp 846 loss=0.051214 err=0.051214
I 2015-05-26 09:50:01 theanets.trainer:168 RmsProp 847 loss=0.051640 err=0.051640
I 2015-05-26 09:50:07 theanets.trainer:168 RmsProp 848 loss=0.049064 err=0.049064
I 2015-05-26 09:50:14 theanets.trainer:168 RmsProp 849 loss=0.044047 err=0.044047
I 2015-05-26 09:50:20 theanets.trainer:168 RmsProp 850 loss=0.061532 err=0.061532
I 2015-05-26 09:50:21 theanets.trainer:168 validation 85 loss=703.641418 err=703.641418 *
I 2015-05-26 09:50:28 theanets.trainer:168 RmsProp 851 loss=0.054194 err=0.054194
I 2015-05-26 09:50:35 theanets.trainer:168 RmsProp 852 loss=0.047651 err=0.047651
I 2015-05-26 09:50:42 theanets.trainer:168 RmsProp 853 loss=0.056312 err=0.056312
I 2015-05-26 09:50:49 theanets.trainer:168 RmsProp 854 loss=0.045898 err=0.045898
I 2015-05-26 09:50:56 theanets.trainer:168 RmsProp 855 loss=0.054630 err=0.054630
I 2015-05-26 09:51:02 theanets.trainer:168 RmsProp 856 loss=0.048836 err=0.048836
I 2015-05-26 09:51:09 theanets.trainer:168 RmsProp 857 loss=0.055636 err=0.055636
I 2015-05-26 09:51:15 theanets.trainer:168 RmsProp 858 loss=0.057161 err=0.057161
I 2015-05-26 09:51:22 theanets.trainer:168 RmsProp 859 loss=0.050126 err=0.050126
I 2015-05-26 09:51:28 theanets.trainer:168 RmsProp 860 loss=0.057787 err=0.057787
I 2015-05-26 09:51:28 theanets.trainer:168 validation 86 loss=702.479126 err=702.479126 *
I 2015-05-26 09:51:34 theanets.trainer:168 RmsProp 861 loss=0.050894 err=0.050894
I 2015-05-26 09:51:41 theanets.trainer:168 RmsProp 862 loss=0.048237 err=0.048237
I 2015-05-26 09:51:49 theanets.trainer:168 RmsProp 863 loss=0.051649 err=0.051649
I 2015-05-26 09:51:55 theanets.trainer:168 RmsProp 864 loss=0.053930 err=0.053930
I 2015-05-26 09:52:02 theanets.trainer:168 RmsProp 865 loss=0.050274 err=0.050274
I 2015-05-26 09:52:09 theanets.trainer:168 RmsProp 866 loss=0.047576 err=0.047576
I 2015-05-26 09:52:16 theanets.trainer:168 RmsProp 867 loss=0.050351 err=0.050351
I 2015-05-26 09:52:24 theanets.trainer:168 RmsProp 868 loss=0.058617 err=0.058617
I 2015-05-26 09:52:30 theanets.trainer:168 RmsProp 869 loss=0.055744 err=0.055744
I 2015-05-26 09:52:37 theanets.trainer:168 RmsProp 870 loss=0.047117 err=0.047117
I 2015-05-26 09:52:38 theanets.trainer:168 validation 87 loss=702.273254 err=702.273254 *
I 2015-05-26 09:52:44 theanets.trainer:168 RmsProp 871 loss=0.058512 err=0.058512
I 2015-05-26 09:52:51 theanets.trainer:168 RmsProp 872 loss=0.051398 err=0.051398
I 2015-05-26 09:52:58 theanets.trainer:168 RmsProp 873 loss=0.047470 err=0.047470
I 2015-05-26 09:53:05 theanets.trainer:168 RmsProp 874 loss=0.059354 err=0.059354
I 2015-05-26 09:53:12 theanets.trainer:168 RmsProp 875 loss=0.046566 err=0.046566
I 2015-05-26 09:53:19 theanets.trainer:168 RmsProp 876 loss=0.047035 err=0.047035
I 2015-05-26 09:53:26 theanets.trainer:168 RmsProp 877 loss=0.050689 err=0.050689
I 2015-05-26 09:53:32 theanets.trainer:168 RmsProp 878 loss=0.050376 err=0.050376
I 2015-05-26 09:53:40 theanets.trainer:168 RmsProp 879 loss=0.054066 err=0.054066
I 2015-05-26 09:53:47 theanets.trainer:168 RmsProp 880 loss=0.050250 err=0.050250
I 2015-05-26 09:53:47 theanets.trainer:168 validation 88 loss=702.445129 err=702.445129
I 2015-05-26 09:53:54 theanets.trainer:168 RmsProp 881 loss=0.042091 err=0.042091
I 2015-05-26 09:54:01 theanets.trainer:168 RmsProp 882 loss=0.063062 err=0.063062
I 2015-05-26 09:54:08 theanets.trainer:168 RmsProp 883 loss=0.054333 err=0.054333
I 2015-05-26 09:54:15 theanets.trainer:168 RmsProp 884 loss=0.045228 err=0.045228
I 2015-05-26 09:54:22 theanets.trainer:168 RmsProp 885 loss=0.050226 err=0.050226
I 2015-05-26 09:54:30 theanets.trainer:168 RmsProp 886 loss=0.054488 err=0.054488
I 2015-05-26 09:54:36 theanets.trainer:168 RmsProp 887 loss=0.053411 err=0.053411
I 2015-05-26 09:54:44 theanets.trainer:168 RmsProp 888 loss=0.045927 err=0.045927
I 2015-05-26 09:54:51 theanets.trainer:168 RmsProp 889 loss=0.051067 err=0.051067
I 2015-05-26 09:54:58 theanets.trainer:168 RmsProp 890 loss=0.049629 err=0.049629
I 2015-05-26 09:54:58 theanets.trainer:168 validation 89 loss=701.985657 err=701.985657 *
I 2015-05-26 09:55:05 theanets.trainer:168 RmsProp 891 loss=0.049832 err=0.049832
I 2015-05-26 09:55:13 theanets.trainer:168 RmsProp 892 loss=0.048135 err=0.048135
I 2015-05-26 09:55:20 theanets.trainer:168 RmsProp 893 loss=0.062895 err=0.062895
I 2015-05-26 09:55:27 theanets.trainer:168 RmsProp 894 loss=0.052660 err=0.052660
I 2015-05-26 09:55:34 theanets.trainer:168 RmsProp 895 loss=0.048315 err=0.048315
I 2015-05-26 09:55:41 theanets.trainer:168 RmsProp 896 loss=0.053085 err=0.053085
I 2015-05-26 09:55:48 theanets.trainer:168 RmsProp 897 loss=0.052485 err=0.052485
I 2015-05-26 09:55:55 theanets.trainer:168 RmsProp 898 loss=0.046985 err=0.046985
I 2015-05-26 09:56:02 theanets.trainer:168 RmsProp 899 loss=0.043306 err=0.043306
I 2015-05-26 09:56:09 theanets.trainer:168 RmsProp 900 loss=0.056701 err=0.056701
I 2015-05-26 09:56:09 theanets.trainer:168 validation 90 loss=702.153442 err=702.153442
I 2015-05-26 09:56:16 theanets.trainer:168 RmsProp 901 loss=0.052736 err=0.052736
I 2015-05-26 09:56:23 theanets.trainer:168 RmsProp 902 loss=0.046958 err=0.046958
I 2015-05-26 09:56:30 theanets.trainer:168 RmsProp 903 loss=0.045304 err=0.045304
I 2015-05-26 09:56:36 theanets.trainer:168 RmsProp 904 loss=0.053421 err=0.053421
I 2015-05-26 09:56:44 theanets.trainer:168 RmsProp 905 loss=0.055180 err=0.055180
I 2015-05-26 09:56:50 theanets.trainer:168 RmsProp 906 loss=0.045767 err=0.045767
I 2015-05-26 09:56:57 theanets.trainer:168 RmsProp 907 loss=0.050270 err=0.050270
I 2015-05-26 09:57:04 theanets.trainer:168 RmsProp 908 loss=0.052343 err=0.052343
I 2015-05-26 09:57:11 theanets.trainer:168 RmsProp 909 loss=0.049709 err=0.049709
I 2015-05-26 09:57:17 theanets.trainer:168 RmsProp 910 loss=0.044985 err=0.044985
I 2015-05-26 09:57:18 theanets.trainer:168 validation 91 loss=701.564148 err=701.564148 *
I 2015-05-26 09:57:24 theanets.trainer:168 RmsProp 911 loss=0.059171 err=0.059171
I 2015-05-26 09:57:31 theanets.trainer:168 RmsProp 912 loss=0.048691 err=0.048691
I 2015-05-26 09:57:37 theanets.trainer:168 RmsProp 913 loss=0.041278 err=0.041278
I 2015-05-26 09:57:44 theanets.trainer:168 RmsProp 914 loss=0.055959 err=0.055959
I 2015-05-26 09:57:51 theanets.trainer:168 RmsProp 915 loss=0.044594 err=0.044594
I 2015-05-26 09:57:57 theanets.trainer:168 RmsProp 916 loss=0.052158 err=0.052158
I 2015-05-26 09:58:04 theanets.trainer:168 RmsProp 917 loss=0.046971 err=0.046971
I 2015-05-26 09:58:10 theanets.trainer:168 RmsProp 918 loss=0.048341 err=0.048341
I 2015-05-26 09:58:17 theanets.trainer:168 RmsProp 919 loss=0.051796 err=0.051796
I 2015-05-26 09:58:24 theanets.trainer:168 RmsProp 920 loss=0.054063 err=0.054063
I 2015-05-26 09:58:24 theanets.trainer:168 validation 92 loss=700.604980 err=700.604980 *
I 2015-05-26 09:58:31 theanets.trainer:168 RmsProp 921 loss=0.049203 err=0.049203
I 2015-05-26 09:58:38 theanets.trainer:168 RmsProp 922 loss=0.054958 err=0.054958
I 2015-05-26 09:58:44 theanets.trainer:168 RmsProp 923 loss=0.048109 err=0.048109
I 2015-05-26 09:58:52 theanets.trainer:168 RmsProp 924 loss=0.047706 err=0.047706
I 2015-05-26 09:58:59 theanets.trainer:168 RmsProp 925 loss=0.051252 err=0.051252
I 2015-05-26 09:59:06 theanets.trainer:168 RmsProp 926 loss=0.049689 err=0.049689
I 2015-05-26 09:59:13 theanets.trainer:168 RmsProp 927 loss=0.043640 err=0.043640
I 2015-05-26 09:59:20 theanets.trainer:168 RmsProp 928 loss=0.049789 err=0.049789
I 2015-05-26 09:59:28 theanets.trainer:168 RmsProp 929 loss=0.037247 err=0.037247
I 2015-05-26 09:59:35 theanets.trainer:168 RmsProp 930 loss=0.084520 err=0.084520
I 2015-05-26 09:59:35 theanets.trainer:168 validation 93 loss=700.440308 err=700.440308 *
I 2015-05-26 09:59:42 theanets.trainer:168 RmsProp 931 loss=0.063009 err=0.063009
I 2015-05-26 09:59:48 theanets.trainer:168 RmsProp 932 loss=0.043039 err=0.043039
I 2015-05-26 09:59:54 theanets.trainer:168 RmsProp 933 loss=0.047031 err=0.047031
I 2015-05-26 10:00:01 theanets.trainer:168 RmsProp 934 loss=0.061631 err=0.061631
I 2015-05-26 10:00:07 theanets.trainer:168 RmsProp 935 loss=0.049540 err=0.049540
I 2015-05-26 10:00:14 theanets.trainer:168 RmsProp 936 loss=0.044693 err=0.044693
I 2015-05-26 10:00:21 theanets.trainer:168 RmsProp 937 loss=0.046904 err=0.046904
I 2015-05-26 10:00:28 theanets.trainer:168 RmsProp 938 loss=0.053537 err=0.053537
I 2015-05-26 10:00:34 theanets.trainer:168 RmsProp 939 loss=0.054110 err=0.054110
I 2015-05-26 10:00:41 theanets.trainer:168 RmsProp 940 loss=0.039602 err=0.039602
I 2015-05-26 10:00:41 theanets.trainer:168 validation 94 loss=700.113403 err=700.113403 *
I 2015-05-26 10:00:48 theanets.trainer:168 RmsProp 941 loss=0.052625 err=0.052625
I 2015-05-26 10:00:55 theanets.trainer:168 RmsProp 942 loss=0.044797 err=0.044797
I 2015-05-26 10:01:03 theanets.trainer:168 RmsProp 943 loss=0.044868 err=0.044868
I 2015-05-26 10:01:10 theanets.trainer:168 RmsProp 944 loss=0.065748 err=0.065748
I 2015-05-26 10:01:16 theanets.trainer:168 RmsProp 945 loss=0.047871 err=0.047871
I 2015-05-26 10:01:23 theanets.trainer:168 RmsProp 946 loss=0.043151 err=0.043151
I 2015-05-26 10:01:30 theanets.trainer:168 RmsProp 947 loss=0.053068 err=0.053068
I 2015-05-26 10:01:37 theanets.trainer:168 RmsProp 948 loss=0.068462 err=0.068462
I 2015-05-26 10:01:44 theanets.trainer:168 RmsProp 949 loss=0.041704 err=0.041704
I 2015-05-26 10:01:51 theanets.trainer:168 RmsProp 950 loss=0.048979 err=0.048979
I 2015-05-26 10:01:51 theanets.trainer:168 validation 95 loss=700.029968 err=700.029968 *
I 2015-05-26 10:01:58 theanets.trainer:168 RmsProp 951 loss=0.044473 err=0.044473
I 2015-05-26 10:02:05 theanets.trainer:168 RmsProp 952 loss=0.048079 err=0.048079
I 2015-05-26 10:02:12 theanets.trainer:168 RmsProp 953 loss=0.057995 err=0.057995
I 2015-05-26 10:02:18 theanets.trainer:168 RmsProp 954 loss=0.053751 err=0.053751
I 2015-05-26 10:02:25 theanets.trainer:168 RmsProp 955 loss=0.042926 err=0.042926
I 2015-05-26 10:02:32 theanets.trainer:168 RmsProp 956 loss=0.052069 err=0.052069
I 2015-05-26 10:02:40 theanets.trainer:168 RmsProp 957 loss=0.048198 err=0.048198
I 2015-05-26 10:02:46 theanets.trainer:168 RmsProp 958 loss=0.043839 err=0.043839
I 2015-05-26 10:02:53 theanets.trainer:168 RmsProp 959 loss=0.053315 err=0.053315
I 2015-05-26 10:03:01 theanets.trainer:168 RmsProp 960 loss=0.044448 err=0.044448
I 2015-05-26 10:03:01 theanets.trainer:168 validation 96 loss=700.135193 err=700.135193
I 2015-05-26 10:03:07 theanets.trainer:168 RmsProp 961 loss=0.051658 err=0.051658
I 2015-05-26 10:03:14 theanets.trainer:168 RmsProp 962 loss=0.050404 err=0.050404
I 2015-05-26 10:03:22 theanets.trainer:168 RmsProp 963 loss=0.047542 err=0.047542
I 2015-05-26 10:03:29 theanets.trainer:168 RmsProp 964 loss=0.053376 err=0.053376
I 2015-05-26 10:03:36 theanets.trainer:168 RmsProp 965 loss=0.050323 err=0.050323
I 2015-05-26 10:03:43 theanets.trainer:168 RmsProp 966 loss=0.051990 err=0.051990
I 2015-05-26 10:03:51 theanets.trainer:168 RmsProp 967 loss=0.040538 err=0.040538
I 2015-05-26 10:03:57 theanets.trainer:168 RmsProp 968 loss=0.051697 err=0.051697
I 2015-05-26 10:04:04 theanets.trainer:168 RmsProp 969 loss=0.045370 err=0.045370
I 2015-05-26 10:04:10 theanets.trainer:168 RmsProp 970 loss=0.044588 err=0.044588
I 2015-05-26 10:04:11 theanets.trainer:168 validation 97 loss=699.745239 err=699.745239 *
I 2015-05-26 10:04:16 theanets.trainer:168 RmsProp 971 loss=0.045766 err=0.045766
I 2015-05-26 10:04:22 theanets.trainer:168 RmsProp 972 loss=0.045553 err=0.045553
I 2015-05-26 10:04:28 theanets.trainer:168 RmsProp 973 loss=0.042774 err=0.042774
I 2015-05-26 10:04:34 theanets.trainer:168 RmsProp 974 loss=0.042167 err=0.042167
I 2015-05-26 10:04:40 theanets.trainer:168 RmsProp 975 loss=0.065030 err=0.065030
I 2015-05-26 10:04:47 theanets.trainer:168 RmsProp 976 loss=0.047541 err=0.047541
I 2015-05-26 10:04:53 theanets.trainer:168 RmsProp 977 loss=0.047348 err=0.047348
I 2015-05-26 10:04:59 theanets.trainer:168 RmsProp 978 loss=0.045482 err=0.045482
I 2015-05-26 10:05:05 theanets.trainer:168 RmsProp 979 loss=0.044355 err=0.044355
I 2015-05-26 10:05:10 theanets.trainer:168 RmsProp 980 loss=0.051216 err=0.051216
I 2015-05-26 10:05:11 theanets.trainer:168 validation 98 loss=698.632935 err=698.632935 *
I 2015-05-26 10:05:17 theanets.trainer:168 RmsProp 981 loss=0.048268 err=0.048268
I 2015-05-26 10:05:23 theanets.trainer:168 RmsProp 982 loss=0.047752 err=0.047752
I 2015-05-26 10:05:30 theanets.trainer:168 RmsProp 983 loss=0.044875 err=0.044875
I 2015-05-26 10:05:36 theanets.trainer:168 RmsProp 984 loss=0.050367 err=0.050367
I 2015-05-26 10:05:42 theanets.trainer:168 RmsProp 985 loss=0.043137 err=0.043137
I 2015-05-26 10:05:48 theanets.trainer:168 RmsProp 986 loss=0.047521 err=0.047521
I 2015-05-26 10:05:54 theanets.trainer:168 RmsProp 987 loss=0.047369 err=0.047369
I 2015-05-26 10:06:00 theanets.trainer:168 RmsProp 988 loss=0.047030 err=0.047030
I 2015-05-26 10:06:06 theanets.trainer:168 RmsProp 989 loss=0.043682 err=0.043682
I 2015-05-26 10:06:12 theanets.trainer:168 RmsProp 990 loss=0.043353 err=0.043353
I 2015-05-26 10:06:13 theanets.trainer:168 validation 99 loss=699.884399 err=699.884399
I 2015-05-26 10:06:18 theanets.trainer:168 RmsProp 991 loss=0.046412 err=0.046412
I 2015-05-26 10:06:25 theanets.trainer:168 RmsProp 992 loss=0.042400 err=0.042400
I 2015-05-26 10:06:31 theanets.trainer:168 RmsProp 993 loss=0.056203 err=0.056203
I 2015-05-26 10:06:37 theanets.trainer:168 RmsProp 994 loss=0.050742 err=0.050742
I 2015-05-26 10:06:43 theanets.trainer:168 RmsProp 995 loss=0.047969 err=0.047969
I 2015-05-26 10:06:48 theanets.trainer:168 RmsProp 996 loss=0.045594 err=0.045594
I 2015-05-26 10:06:54 theanets.trainer:168 RmsProp 997 loss=0.042883 err=0.042883
I 2015-05-26 10:07:01 theanets.trainer:168 RmsProp 998 loss=0.046991 err=0.046991
I 2015-05-26 10:07:07 theanets.trainer:168 RmsProp 999 loss=0.044209 err=0.044209
I 2015-05-26 10:07:13 theanets.trainer:168 RmsProp 1000 loss=0.051317 err=0.051317
I 2015-05-26 10:07:13 theanets.trainer:168 validation 100 loss=698.383179 err=698.383179 *
I 2015-05-26 10:07:19 theanets.trainer:168 RmsProp 1001 loss=0.041175 err=0.041175
I 2015-05-26 10:07:24 theanets.trainer:168 RmsProp 1002 loss=0.043585 err=0.043585
I 2015-05-26 10:07:29 theanets.trainer:168 RmsProp 1003 loss=0.045787 err=0.045787
I 2015-05-26 10:07:36 theanets.trainer:168 RmsProp 1004 loss=0.047244 err=0.047244
I 2015-05-26 10:07:42 theanets.trainer:168 RmsProp 1005 loss=0.054339 err=0.054339
I 2015-05-26 10:07:48 theanets.trainer:168 RmsProp 1006 loss=0.038157 err=0.038157
I 2015-05-26 10:07:54 theanets.trainer:168 RmsProp 1007 loss=0.053953 err=0.053953
I 2015-05-26 10:08:00 theanets.trainer:168 RmsProp 1008 loss=0.059120 err=0.059120
I 2015-05-26 10:08:06 theanets.trainer:168 RmsProp 1009 loss=0.048187 err=0.048187
I 2015-05-26 10:08:12 theanets.trainer:168 RmsProp 1010 loss=0.042104 err=0.042104
I 2015-05-26 10:08:13 theanets.trainer:168 validation 101 loss=697.858704 err=697.858704 *
I 2015-05-26 10:08:19 theanets.trainer:168 RmsProp 1011 loss=0.047682 err=0.047682
I 2015-05-26 10:08:24 theanets.trainer:168 RmsProp 1012 loss=0.038206 err=0.038206
I 2015-05-26 10:08:30 theanets.trainer:168 RmsProp 1013 loss=0.051372 err=0.051372
I 2015-05-26 10:08:36 theanets.trainer:168 RmsProp 1014 loss=0.047241 err=0.047241
I 2015-05-26 10:08:42 theanets.trainer:168 RmsProp 1015 loss=0.048000 err=0.048000
I 2015-05-26 10:08:48 theanets.trainer:168 RmsProp 1016 loss=0.045696 err=0.045696
I 2015-05-26 10:08:55 theanets.trainer:168 RmsProp 1017 loss=0.046510 err=0.046510
I 2015-05-26 10:09:01 theanets.trainer:168 RmsProp 1018 loss=0.048425 err=0.048425
I 2015-05-26 10:09:07 theanets.trainer:168 RmsProp 1019 loss=0.050259 err=0.050259
I 2015-05-26 10:09:13 theanets.trainer:168 RmsProp 1020 loss=0.053772 err=0.053772
I 2015-05-26 10:09:13 theanets.trainer:168 validation 102 loss=697.732605 err=697.732605 *
I 2015-05-26 10:09:19 theanets.trainer:168 RmsProp 1021 loss=0.044552 err=0.044552
I 2015-05-26 10:09:24 theanets.trainer:168 RmsProp 1022 loss=0.047692 err=0.047692
I 2015-05-26 10:09:31 theanets.trainer:168 RmsProp 1023 loss=0.041828 err=0.041828
I 2015-05-26 10:09:36 theanets.trainer:168 RmsProp 1024 loss=0.045746 err=0.045746
I 2015-05-26 10:09:42 theanets.trainer:168 RmsProp 1025 loss=0.045647 err=0.045647
I 2015-05-26 10:09:49 theanets.trainer:168 RmsProp 1026 loss=0.042680 err=0.042680
I 2015-05-26 10:09:55 theanets.trainer:168 RmsProp 1027 loss=0.041911 err=0.041911
I 2015-05-26 10:10:01 theanets.trainer:168 RmsProp 1028 loss=0.041527 err=0.041527
I 2015-05-26 10:10:07 theanets.trainer:168 RmsProp 1029 loss=0.050068 err=0.050068
I 2015-05-26 10:10:13 theanets.trainer:168 RmsProp 1030 loss=0.036633 err=0.036633
I 2015-05-26 10:10:13 theanets.trainer:168 validation 103 loss=697.603638 err=697.603638 *
I 2015-05-26 10:10:19 theanets.trainer:168 RmsProp 1031 loss=0.050584 err=0.050584
I 2015-05-26 10:10:25 theanets.trainer:168 RmsProp 1032 loss=0.036737 err=0.036737
I 2015-05-26 10:10:32 theanets.trainer:168 RmsProp 1033 loss=0.051114 err=0.051114
I 2015-05-26 10:10:38 theanets.trainer:168 RmsProp 1034 loss=0.051616 err=0.051616
I 2015-05-26 10:10:44 theanets.trainer:168 RmsProp 1035 loss=0.044285 err=0.044285
I 2015-05-26 10:10:50 theanets.trainer:168 RmsProp 1036 loss=0.043714 err=0.043714
I 2015-05-26 10:10:56 theanets.trainer:168 RmsProp 1037 loss=0.040795 err=0.040795
I 2015-05-26 10:11:02 theanets.trainer:168 RmsProp 1038 loss=0.045728 err=0.045728
I 2015-05-26 10:11:07 theanets.trainer:168 RmsProp 1039 loss=0.044363 err=0.044363
I 2015-05-26 10:11:13 theanets.trainer:168 RmsProp 1040 loss=0.045786 err=0.045786
I 2015-05-26 10:11:13 theanets.trainer:168 validation 104 loss=697.440063 err=697.440063 *
I 2015-05-26 10:11:19 theanets.trainer:168 RmsProp 1041 loss=0.050819 err=0.050819
I 2015-05-26 10:11:24 theanets.trainer:168 RmsProp 1042 loss=0.044769 err=0.044769
I 2015-05-26 10:11:29 theanets.trainer:168 RmsProp 1043 loss=0.045926 err=0.045926
I 2015-05-26 10:11:35 theanets.trainer:168 RmsProp 1044 loss=0.044126 err=0.044126
I 2015-05-26 10:11:40 theanets.trainer:168 RmsProp 1045 loss=0.037973 err=0.037973
I 2015-05-26 10:11:46 theanets.trainer:168 RmsProp 1046 loss=0.047185 err=0.047185
I 2015-05-26 10:11:51 theanets.trainer:168 RmsProp 1047 loss=0.051341 err=0.051341
I 2015-05-26 10:11:57 theanets.trainer:168 RmsProp 1048 loss=0.044277 err=0.044277
I 2015-05-26 10:12:03 theanets.trainer:168 RmsProp 1049 loss=0.040553 err=0.040553
I 2015-05-26 10:12:09 theanets.trainer:168 RmsProp 1050 loss=0.046518 err=0.046518
I 2015-05-26 10:12:09 theanets.trainer:168 validation 105 loss=697.152771 err=697.152771 *
I 2015-05-26 10:12:15 theanets.trainer:168 RmsProp 1051 loss=0.041898 err=0.041898
I 2015-05-26 10:12:21 theanets.trainer:168 RmsProp 1052 loss=0.039446 err=0.039446
I 2015-05-26 10:12:28 theanets.trainer:168 RmsProp 1053 loss=0.046420 err=0.046420
I 2015-05-26 10:12:33 theanets.trainer:168 RmsProp 1054 loss=0.049102 err=0.049102
I 2015-05-26 10:12:39 theanets.trainer:168 RmsProp 1055 loss=0.052387 err=0.052387
I 2015-05-26 10:12:46 theanets.trainer:168 RmsProp 1056 loss=0.043127 err=0.043127
I 2015-05-26 10:12:52 theanets.trainer:168 RmsProp 1057 loss=0.045929 err=0.045929
I 2015-05-26 10:12:58 theanets.trainer:168 RmsProp 1058 loss=0.041007 err=0.041007
I 2015-05-26 10:13:03 theanets.trainer:168 RmsProp 1059 loss=0.047137 err=0.047137
I 2015-05-26 10:13:09 theanets.trainer:168 RmsProp 1060 loss=0.040915 err=0.040915
I 2015-05-26 10:13:09 theanets.trainer:168 validation 106 loss=696.740356 err=696.740356 *
I 2015-05-26 10:13:15 theanets.trainer:168 RmsProp 1061 loss=0.044457 err=0.044457
I 2015-05-26 10:13:21 theanets.trainer:168 RmsProp 1062 loss=0.051339 err=0.051339
I 2015-05-26 10:13:27 theanets.trainer:168 RmsProp 1063 loss=0.046591 err=0.046591
I 2015-05-26 10:13:33 theanets.trainer:168 RmsProp 1064 loss=0.039357 err=0.039357
I 2015-05-26 10:13:39 theanets.trainer:168 RmsProp 1065 loss=0.036644 err=0.036644
I 2015-05-26 10:13:45 theanets.trainer:168 RmsProp 1066 loss=0.075715 err=0.075715
I 2015-05-26 10:13:51 theanets.trainer:168 RmsProp 1067 loss=0.055018 err=0.055018
I 2015-05-26 10:13:57 theanets.trainer:168 RmsProp 1068 loss=0.043334 err=0.043334
I 2015-05-26 10:14:03 theanets.trainer:168 RmsProp 1069 loss=0.037256 err=0.037256
I 2015-05-26 10:14:08 theanets.trainer:168 RmsProp 1070 loss=0.043273 err=0.043273
I 2015-05-26 10:14:09 theanets.trainer:168 validation 107 loss=695.536377 err=695.536377 *
I 2015-05-26 10:14:14 theanets.trainer:168 RmsProp 1071 loss=0.049063 err=0.049063
I 2015-05-26 10:14:21 theanets.trainer:168 RmsProp 1072 loss=0.042106 err=0.042106
I 2015-05-26 10:14:27 theanets.trainer:168 RmsProp 1073 loss=0.045282 err=0.045282
I 2015-05-26 10:14:32 theanets.trainer:168 RmsProp 1074 loss=0.038392 err=0.038392
I 2015-05-26 10:14:39 theanets.trainer:168 RmsProp 1075 loss=0.041175 err=0.041175
I 2015-05-26 10:14:45 theanets.trainer:168 RmsProp 1076 loss=0.053960 err=0.053960
I 2015-05-26 10:14:51 theanets.trainer:168 RmsProp 1077 loss=0.038301 err=0.038301
I 2015-05-26 10:14:57 theanets.trainer:168 RmsProp 1078 loss=0.050809 err=0.050809
I 2015-05-26 10:15:04 theanets.trainer:168 RmsProp 1079 loss=0.045013 err=0.045013
I 2015-05-26 10:15:10 theanets.trainer:168 RmsProp 1080 loss=0.034658 err=0.034658
I 2015-05-26 10:15:10 theanets.trainer:168 validation 108 loss=694.272583 err=694.272583 *
I 2015-05-26 10:15:16 theanets.trainer:168 RmsProp 1081 loss=0.052444 err=0.052444
I 2015-05-26 10:15:21 theanets.trainer:168 RmsProp 1082 loss=0.040642 err=0.040642
I 2015-05-26 10:15:27 theanets.trainer:168 RmsProp 1083 loss=0.041058 err=0.041058
I 2015-05-26 10:15:32 theanets.trainer:168 RmsProp 1084 loss=0.046933 err=0.046933
I 2015-05-26 10:15:38 theanets.trainer:168 RmsProp 1085 loss=0.043309 err=0.043309
I 2015-05-26 10:15:44 theanets.trainer:168 RmsProp 1086 loss=0.036439 err=0.036439
I 2015-05-26 10:15:50 theanets.trainer:168 RmsProp 1087 loss=0.055585 err=0.055585
I 2015-05-26 10:15:55 theanets.trainer:168 RmsProp 1088 loss=0.047934 err=0.047934
I 2015-05-26 10:16:02 theanets.trainer:168 RmsProp 1089 loss=0.040468 err=0.040468
I 2015-05-26 10:16:08 theanets.trainer:168 RmsProp 1090 loss=0.033196 err=0.033196
I 2015-05-26 10:16:08 theanets.trainer:168 validation 109 loss=694.367615 err=694.367615
I 2015-05-26 10:16:13 theanets.trainer:168 RmsProp 1091 loss=0.066345 err=0.066345
I 2015-05-26 10:16:19 theanets.trainer:168 RmsProp 1092 loss=0.046775 err=0.046775
I 2015-05-26 10:16:26 theanets.trainer:168 RmsProp 1093 loss=0.040876 err=0.040876
I 2015-05-26 10:16:32 theanets.trainer:168 RmsProp 1094 loss=0.038915 err=0.038915
I 2015-05-26 10:16:38 theanets.trainer:168 RmsProp 1095 loss=0.038699 err=0.038699
I 2015-05-26 10:16:45 theanets.trainer:168 RmsProp 1096 loss=0.048193 err=0.048193
I 2015-05-26 10:16:51 theanets.trainer:168 RmsProp 1097 loss=0.041287 err=0.041287
I 2015-05-26 10:16:57 theanets.trainer:168 RmsProp 1098 loss=0.043945 err=0.043945
I 2015-05-26 10:17:03 theanets.trainer:168 RmsProp 1099 loss=0.043075 err=0.043075
I 2015-05-26 10:17:09 theanets.trainer:168 RmsProp 1100 loss=0.048364 err=0.048364
I 2015-05-26 10:17:09 theanets.trainer:168 validation 110 loss=694.166626 err=694.166626 *
I 2015-05-26 10:17:15 theanets.trainer:168 RmsProp 1101 loss=0.042472 err=0.042472
I 2015-05-26 10:17:21 theanets.trainer:168 RmsProp 1102 loss=0.050844 err=0.050844
I 2015-05-26 10:17:27 theanets.trainer:168 RmsProp 1103 loss=0.047426 err=0.047426
I 2015-05-26 10:17:33 theanets.trainer:168 RmsProp 1104 loss=0.043745 err=0.043745
I 2015-05-26 10:17:39 theanets.trainer:168 RmsProp 1105 loss=0.043483 err=0.043483
I 2015-05-26 10:17:45 theanets.trainer:168 RmsProp 1106 loss=0.037448 err=0.037448
I 2015-05-26 10:17:52 theanets.trainer:168 RmsProp 1107 loss=0.053530 err=0.053530
I 2015-05-26 10:17:58 theanets.trainer:168 RmsProp 1108 loss=0.038349 err=0.038349
I 2015-05-26 10:18:04 theanets.trainer:168 RmsProp 1109 loss=0.033680 err=0.033680
I 2015-05-26 10:18:09 theanets.trainer:168 RmsProp 1110 loss=0.074311 err=0.074311
I 2015-05-26 10:18:10 theanets.trainer:168 validation 111 loss=694.745605 err=694.745605
I 2015-05-26 10:18:15 theanets.trainer:168 RmsProp 1111 loss=0.049542 err=0.049542
I 2015-05-26 10:18:21 theanets.trainer:168 RmsProp 1112 loss=0.043058 err=0.043058
I 2015-05-26 10:18:27 theanets.trainer:168 RmsProp 1113 loss=0.044996 err=0.044996
I 2015-05-26 10:18:33 theanets.trainer:168 RmsProp 1114 loss=0.034999 err=0.034999
I 2015-05-26 10:18:39 theanets.trainer:168 RmsProp 1115 loss=0.050214 err=0.050214
I 2015-05-26 10:18:45 theanets.trainer:168 RmsProp 1116 loss=0.041430 err=0.041430
I 2015-05-26 10:18:51 theanets.trainer:168 RmsProp 1117 loss=0.041484 err=0.041484
I 2015-05-26 10:18:58 theanets.trainer:168 RmsProp 1118 loss=0.041519 err=0.041519
I 2015-05-26 10:19:04 theanets.trainer:168 RmsProp 1119 loss=0.041022 err=0.041022
I 2015-05-26 10:19:10 theanets.trainer:168 RmsProp 1120 loss=0.044030 err=0.044030
I 2015-05-26 10:19:11 theanets.trainer:168 validation 112 loss=693.921387 err=693.921387 *
I 2015-05-26 10:19:16 theanets.trainer:168 RmsProp 1121 loss=0.041259 err=0.041259
I 2015-05-26 10:19:22 theanets.trainer:168 RmsProp 1122 loss=0.040486 err=0.040486
I 2015-05-26 10:19:29 theanets.trainer:168 RmsProp 1123 loss=0.041908 err=0.041908
I 2015-05-26 10:19:35 theanets.trainer:168 RmsProp 1124 loss=0.034892 err=0.034892
I 2015-05-26 10:19:41 theanets.trainer:168 RmsProp 1125 loss=0.053526 err=0.053526
I 2015-05-26 10:19:47 theanets.trainer:168 RmsProp 1126 loss=0.042747 err=0.042747
I 2015-05-26 10:19:53 theanets.trainer:168 RmsProp 1127 loss=0.038338 err=0.038338
I 2015-05-26 10:20:00 theanets.trainer:168 RmsProp 1128 loss=0.052722 err=0.052722
I 2015-05-26 10:20:06 theanets.trainer:168 RmsProp 1129 loss=0.042944 err=0.042944
I 2015-05-26 10:20:12 theanets.trainer:168 RmsProp 1130 loss=0.046879 err=0.046879
I 2015-05-26 10:20:12 theanets.trainer:168 validation 113 loss=693.725525 err=693.725525 *
I 2015-05-26 10:20:18 theanets.trainer:168 RmsProp 1131 loss=0.043141 err=0.043141
I 2015-05-26 10:20:24 theanets.trainer:168 RmsProp 1132 loss=0.044184 err=0.044184
I 2015-05-26 10:20:30 theanets.trainer:168 RmsProp 1133 loss=0.043060 err=0.043060
I 2015-05-26 10:20:36 theanets.trainer:168 RmsProp 1134 loss=0.039634 err=0.039634
I 2015-05-26 10:20:41 theanets.trainer:168 RmsProp 1135 loss=0.043291 err=0.043291
I 2015-05-26 10:20:47 theanets.trainer:168 RmsProp 1136 loss=0.043189 err=0.043189
I 2015-05-26 10:20:52 theanets.trainer:168 RmsProp 1137 loss=0.040302 err=0.040302
I 2015-05-26 10:20:58 theanets.trainer:168 RmsProp 1138 loss=0.036617 err=0.036617
I 2015-05-26 10:21:03 theanets.trainer:168 RmsProp 1139 loss=0.045180 err=0.045180
I 2015-05-26 10:21:09 theanets.trainer:168 RmsProp 1140 loss=0.046045 err=0.046045
I 2015-05-26 10:21:09 theanets.trainer:168 validation 114 loss=694.249268 err=694.249268
I 2015-05-26 10:21:15 theanets.trainer:168 RmsProp 1141 loss=0.041876 err=0.041876
I 2015-05-26 10:21:20 theanets.trainer:168 RmsProp 1142 loss=0.037465 err=0.037465
I 2015-05-26 10:21:27 theanets.trainer:168 RmsProp 1143 loss=0.044994 err=0.044994
I 2015-05-26 10:21:33 theanets.trainer:168 RmsProp 1144 loss=0.039020 err=0.039020
I 2015-05-26 10:21:38 theanets.trainer:168 RmsProp 1145 loss=0.047772 err=0.047772
I 2015-05-26 10:21:44 theanets.trainer:168 RmsProp 1146 loss=0.041956 err=0.041956
I 2015-05-26 10:21:50 theanets.trainer:168 RmsProp 1147 loss=0.038665 err=0.038665
I 2015-05-26 10:21:55 theanets.trainer:168 RmsProp 1148 loss=0.041365 err=0.041365
I 2015-05-26 10:22:01 theanets.trainer:168 RmsProp 1149 loss=0.041042 err=0.041042
I 2015-05-26 10:22:07 theanets.trainer:168 RmsProp 1150 loss=0.042268 err=0.042268
I 2015-05-26 10:22:07 theanets.trainer:168 validation 115 loss=693.650818 err=693.650818 *
I 2015-05-26 10:22:13 theanets.trainer:168 RmsProp 1151 loss=0.035098 err=0.035098
I 2015-05-26 10:22:19 theanets.trainer:168 RmsProp 1152 loss=0.041372 err=0.041372
I 2015-05-26 10:22:25 theanets.trainer:168 RmsProp 1153 loss=0.037212 err=0.037212
I 2015-05-26 10:22:31 theanets.trainer:168 RmsProp 1154 loss=0.044871 err=0.044871
I 2015-05-26 10:22:38 theanets.trainer:168 RmsProp 1155 loss=0.043878 err=0.043878
I 2015-05-26 10:22:44 theanets.trainer:168 RmsProp 1156 loss=0.043625 err=0.043625
I 2015-05-26 10:22:50 theanets.trainer:168 RmsProp 1157 loss=0.041962 err=0.041962
I 2015-05-26 10:22:55 theanets.trainer:168 RmsProp 1158 loss=0.039439 err=0.039439
I 2015-05-26 10:23:01 theanets.trainer:168 RmsProp 1159 loss=0.038570 err=0.038570
I 2015-05-26 10:23:08 theanets.trainer:168 RmsProp 1160 loss=0.040199 err=0.040199
I 2015-05-26 10:23:08 theanets.trainer:168 validation 116 loss=693.544067 err=693.544067 *
I 2015-05-26 10:23:13 theanets.trainer:168 RmsProp 1161 loss=0.045594 err=0.045594
I 2015-05-26 10:23:19 theanets.trainer:168 RmsProp 1162 loss=0.039777 err=0.039777
I 2015-05-26 10:23:25 theanets.trainer:168 RmsProp 1163 loss=0.036593 err=0.036593
I 2015-05-26 10:23:32 theanets.trainer:168 RmsProp 1164 loss=0.055080 err=0.055080
I 2015-05-26 10:23:38 theanets.trainer:168 RmsProp 1165 loss=0.040952 err=0.040952
I 2015-05-26 10:23:44 theanets.trainer:168 RmsProp 1166 loss=0.042922 err=0.042922
I 2015-05-26 10:23:50 theanets.trainer:168 RmsProp 1167 loss=0.034230 err=0.034230
I 2015-05-26 10:23:56 theanets.trainer:168 RmsProp 1168 loss=0.050384 err=0.050384
I 2015-05-26 10:24:02 theanets.trainer:168 RmsProp 1169 loss=0.041381 err=0.041381
I 2015-05-26 10:24:09 theanets.trainer:168 RmsProp 1170 loss=0.040626 err=0.040626
I 2015-05-26 10:24:09 theanets.trainer:168 validation 117 loss=692.654236 err=692.654236 *
I 2015-05-26 10:24:15 theanets.trainer:168 RmsProp 1171 loss=0.038143 err=0.038143
I 2015-05-26 10:24:21 theanets.trainer:168 RmsProp 1172 loss=0.042233 err=0.042233
I 2015-05-26 10:24:27 theanets.trainer:168 RmsProp 1173 loss=0.041012 err=0.041012
I 2015-05-26 10:24:33 theanets.trainer:168 RmsProp 1174 loss=0.040185 err=0.040185
I 2015-05-26 10:24:39 theanets.trainer:168 RmsProp 1175 loss=0.042013 err=0.042013
I 2015-05-26 10:24:45 theanets.trainer:168 RmsProp 1176 loss=0.035189 err=0.035189
I 2015-05-26 10:24:51 theanets.trainer:168 RmsProp 1177 loss=0.053580 err=0.053580
I 2015-05-26 10:24:57 theanets.trainer:168 RmsProp 1178 loss=0.039059 err=0.039059
I 2015-05-26 10:25:03 theanets.trainer:168 RmsProp 1179 loss=0.044706 err=0.044706
I 2015-05-26 10:25:09 theanets.trainer:168 RmsProp 1180 loss=0.039778 err=0.039778
I 2015-05-26 10:25:09 theanets.trainer:168 validation 118 loss=692.359131 err=692.359131 *
I 2015-05-26 10:25:15 theanets.trainer:168 RmsProp 1181 loss=0.039357 err=0.039357
I 2015-05-26 10:25:21 theanets.trainer:168 RmsProp 1182 loss=0.038328 err=0.038328
I 2015-05-26 10:25:27 theanets.trainer:168 RmsProp 1183 loss=0.042756 err=0.042756
I 2015-05-26 10:25:33 theanets.trainer:168 RmsProp 1184 loss=0.042866 err=0.042866
I 2015-05-26 10:25:39 theanets.trainer:168 RmsProp 1185 loss=0.041171 err=0.041171
I 2015-05-26 10:25:46 theanets.trainer:168 RmsProp 1186 loss=0.041188 err=0.041188
I 2015-05-26 10:25:52 theanets.trainer:168 RmsProp 1187 loss=0.042572 err=0.042572
I 2015-05-26 10:25:57 theanets.trainer:168 RmsProp 1188 loss=0.040487 err=0.040487
I 2015-05-26 10:26:03 theanets.trainer:168 RmsProp 1189 loss=0.035419 err=0.035419
I 2015-05-26 10:26:09 theanets.trainer:168 RmsProp 1190 loss=0.049808 err=0.049808
I 2015-05-26 10:26:10 theanets.trainer:168 validation 119 loss=692.548767 err=692.548767
I 2015-05-26 10:26:16 theanets.trainer:168 RmsProp 1191 loss=0.038060 err=0.038060
I 2015-05-26 10:26:22 theanets.trainer:168 RmsProp 1192 loss=0.041964 err=0.041964
I 2015-05-26 10:26:28 theanets.trainer:168 RmsProp 1193 loss=0.038835 err=0.038835
I 2015-05-26 10:26:34 theanets.trainer:168 RmsProp 1194 loss=0.039659 err=0.039659
I 2015-05-26 10:26:40 theanets.trainer:168 RmsProp 1195 loss=0.040340 err=0.040340
I 2015-05-26 10:26:45 theanets.trainer:168 RmsProp 1196 loss=0.043181 err=0.043181
I 2015-05-26 10:26:52 theanets.trainer:168 RmsProp 1197 loss=0.040235 err=0.040235
I 2015-05-26 10:26:58 theanets.trainer:168 RmsProp 1198 loss=0.037238 err=0.037238
I 2015-05-26 10:27:04 theanets.trainer:168 RmsProp 1199 loss=0.043971 err=0.043971
I 2015-05-26 10:27:10 theanets.trainer:168 RmsProp 1200 loss=0.038321 err=0.038321
I 2015-05-26 10:27:11 theanets.trainer:168 validation 120 loss=692.775696 err=692.775696
I 2015-05-26 10:27:16 theanets.trainer:168 RmsProp 1201 loss=0.030772 err=0.030772
I 2015-05-26 10:27:21 theanets.trainer:168 RmsProp 1202 loss=0.070027 err=0.070027
I 2015-05-26 10:27:27 theanets.trainer:168 RmsProp 1203 loss=0.046942 err=0.046942
I 2015-05-26 10:27:33 theanets.trainer:168 RmsProp 1204 loss=0.037111 err=0.037111
I 2015-05-26 10:27:39 theanets.trainer:168 RmsProp 1205 loss=0.040760 err=0.040760
I 2015-05-26 10:27:45 theanets.trainer:168 RmsProp 1206 loss=0.038218 err=0.038218
I 2015-05-26 10:27:51 theanets.trainer:168 RmsProp 1207 loss=0.039851 err=0.039851
I 2015-05-26 10:27:57 theanets.trainer:168 RmsProp 1208 loss=0.039682 err=0.039682
I 2015-05-26 10:28:03 theanets.trainer:168 RmsProp 1209 loss=0.040013 err=0.040013
I 2015-05-26 10:28:09 theanets.trainer:168 RmsProp 1210 loss=0.042317 err=0.042317
I 2015-05-26 10:28:10 theanets.trainer:168 validation 121 loss=691.720215 err=691.720215 *
I 2015-05-26 10:28:15 theanets.trainer:168 RmsProp 1211 loss=0.042346 err=0.042346
I 2015-05-26 10:28:21 theanets.trainer:168 RmsProp 1212 loss=0.034945 err=0.034945
I 2015-05-26 10:28:27 theanets.trainer:168 RmsProp 1213 loss=0.052948 err=0.052948
I 2015-05-26 10:28:33 theanets.trainer:168 RmsProp 1214 loss=0.038690 err=0.038690
I 2015-05-26 10:28:40 theanets.trainer:168 RmsProp 1215 loss=0.031608 err=0.031608
I 2015-05-26 10:28:46 theanets.trainer:168 RmsProp 1216 loss=0.066830 err=0.066830
I 2015-05-26 10:28:52 theanets.trainer:168 RmsProp 1217 loss=0.062351 err=0.062351
I 2015-05-26 10:28:58 theanets.trainer:168 RmsProp 1218 loss=0.039913 err=0.039913
I 2015-05-26 10:29:04 theanets.trainer:168 RmsProp 1219 loss=0.038850 err=0.038850
I 2015-05-26 10:29:10 theanets.trainer:168 RmsProp 1220 loss=0.037137 err=0.037137
I 2015-05-26 10:29:11 theanets.trainer:168 validation 122 loss=692.303406 err=692.303406
I 2015-05-26 10:29:16 theanets.trainer:168 RmsProp 1221 loss=0.040406 err=0.040406
I 2015-05-26 10:29:22 theanets.trainer:168 RmsProp 1222 loss=0.042841 err=0.042841
I 2015-05-26 10:29:28 theanets.trainer:168 RmsProp 1223 loss=0.039634 err=0.039634
I 2015-05-26 10:29:34 theanets.trainer:168 RmsProp 1224 loss=0.044866 err=0.044866
I 2015-05-26 10:29:40 theanets.trainer:168 RmsProp 1225 loss=0.039754 err=0.039754
I 2015-05-26 10:29:46 theanets.trainer:168 RmsProp 1226 loss=0.031803 err=0.031803
I 2015-05-26 10:29:52 theanets.trainer:168 RmsProp 1227 loss=0.057613 err=0.057613
I 2015-05-26 10:29:58 theanets.trainer:168 RmsProp 1228 loss=0.059436 err=0.059436
I 2015-05-26 10:30:04 theanets.trainer:168 RmsProp 1229 loss=0.039626 err=0.039626
I 2015-05-26 10:30:11 theanets.trainer:168 RmsProp 1230 loss=0.031021 err=0.031021
I 2015-05-26 10:30:11 theanets.trainer:168 validation 123 loss=691.439209 err=691.439209 *
I 2015-05-26 10:30:17 theanets.trainer:168 RmsProp 1231 loss=0.059025 err=0.059025
I 2015-05-26 10:30:23 theanets.trainer:168 RmsProp 1232 loss=0.041881 err=0.041881
I 2015-05-26 10:30:29 theanets.trainer:168 RmsProp 1233 loss=0.036814 err=0.036814
I 2015-05-26 10:30:35 theanets.trainer:168 RmsProp 1234 loss=0.036062 err=0.036062
I 2015-05-26 10:30:41 theanets.trainer:168 RmsProp 1235 loss=0.048543 err=0.048543
I 2015-05-26 10:30:47 theanets.trainer:168 RmsProp 1236 loss=0.044384 err=0.044384
I 2015-05-26 10:30:53 theanets.trainer:168 RmsProp 1237 loss=0.033021 err=0.033021
I 2015-05-26 10:30:59 theanets.trainer:168 RmsProp 1238 loss=0.055990 err=0.055990
I 2015-05-26 10:31:04 theanets.trainer:168 RmsProp 1239 loss=0.041801 err=0.041801
I 2015-05-26 10:31:10 theanets.trainer:168 RmsProp 1240 loss=0.033934 err=0.033934
I 2015-05-26 10:31:10 theanets.trainer:168 validation 124 loss=691.409790 err=691.409790 *
I 2015-05-26 10:31:16 theanets.trainer:168 RmsProp 1241 loss=0.038938 err=0.038938
I 2015-05-26 10:31:21 theanets.trainer:168 RmsProp 1242 loss=0.036911 err=0.036911
I 2015-05-26 10:31:26 theanets.trainer:168 RmsProp 1243 loss=0.051034 err=0.051034
I 2015-05-26 10:31:32 theanets.trainer:168 RmsProp 1244 loss=0.047791 err=0.047791
I 2015-05-26 10:31:38 theanets.trainer:168 RmsProp 1245 loss=0.035540 err=0.035540
I 2015-05-26 10:31:43 theanets.trainer:168 RmsProp 1246 loss=0.041588 err=0.041588
I 2015-05-26 10:31:50 theanets.trainer:168 RmsProp 1247 loss=0.036273 err=0.036273
I 2015-05-26 10:31:56 theanets.trainer:168 RmsProp 1248 loss=0.046850 err=0.046850
I 2015-05-26 10:32:02 theanets.trainer:168 RmsProp 1249 loss=0.054732 err=0.054732
I 2015-05-26 10:32:08 theanets.trainer:168 RmsProp 1250 loss=0.036273 err=0.036273
I 2015-05-26 10:32:08 theanets.trainer:168 validation 125 loss=690.358887 err=690.358887 *
I 2015-05-26 10:32:14 theanets.trainer:168 RmsProp 1251 loss=0.030817 err=0.030817
I 2015-05-26 10:32:19 theanets.trainer:168 RmsProp 1252 loss=0.054854 err=0.054854
I 2015-05-26 10:32:26 theanets.trainer:168 RmsProp 1253 loss=0.041173 err=0.041173
I 2015-05-26 10:32:31 theanets.trainer:168 RmsProp 1254 loss=0.038923 err=0.038923
I 2015-05-26 10:32:37 theanets.trainer:168 RmsProp 1255 loss=0.043498 err=0.043498
I 2015-05-26 10:32:43 theanets.trainer:168 RmsProp 1256 loss=0.040528 err=0.040528
I 2015-05-26 10:32:49 theanets.trainer:168 RmsProp 1257 loss=0.033947 err=0.033947
I 2015-05-26 10:32:55 theanets.trainer:168 RmsProp 1258 loss=0.043946 err=0.043946
I 2015-05-26 10:33:01 theanets.trainer:168 RmsProp 1259 loss=0.037560 err=0.037560
I 2015-05-26 10:33:07 theanets.trainer:168 RmsProp 1260 loss=0.036661 err=0.036661
I 2015-05-26 10:33:08 theanets.trainer:168 validation 126 loss=690.067993 err=690.067993 *
I 2015-05-26 10:33:13 theanets.trainer:168 RmsProp 1261 loss=0.039238 err=0.039238
I 2015-05-26 10:33:20 theanets.trainer:168 RmsProp 1262 loss=0.038015 err=0.038015
I 2015-05-26 10:33:26 theanets.trainer:168 RmsProp 1263 loss=0.039141 err=0.039141
I 2015-05-26 10:33:32 theanets.trainer:168 RmsProp 1264 loss=0.042068 err=0.042068
I 2015-05-26 10:33:38 theanets.trainer:168 RmsProp 1265 loss=0.034337 err=0.034337
I 2015-05-26 10:33:44 theanets.trainer:168 RmsProp 1266 loss=0.039070 err=0.039070
I 2015-05-26 10:33:50 theanets.trainer:168 RmsProp 1267 loss=0.040227 err=0.040227
I 2015-05-26 10:33:56 theanets.trainer:168 RmsProp 1268 loss=0.039373 err=0.039373
I 2015-05-26 10:34:02 theanets.trainer:168 RmsProp 1269 loss=0.039993 err=0.039993
I 2015-05-26 10:34:08 theanets.trainer:168 RmsProp 1270 loss=0.036702 err=0.036702
I 2015-05-26 10:34:09 theanets.trainer:168 validation 127 loss=691.026550 err=691.026550
I 2015-05-26 10:34:15 theanets.trainer:168 RmsProp 1271 loss=0.042120 err=0.042120
I 2015-05-26 10:34:21 theanets.trainer:168 RmsProp 1272 loss=0.049396 err=0.049396
I 2015-05-26 10:34:27 theanets.trainer:168 RmsProp 1273 loss=0.034880 err=0.034880
I 2015-05-26 10:34:33 theanets.trainer:168 RmsProp 1274 loss=0.041628 err=0.041628
I 2015-05-26 10:34:39 theanets.trainer:168 RmsProp 1275 loss=0.042613 err=0.042613
I 2015-05-26 10:34:45 theanets.trainer:168 RmsProp 1276 loss=0.033043 err=0.033043
I 2015-05-26 10:34:51 theanets.trainer:168 RmsProp 1277 loss=0.056946 err=0.056946
I 2015-05-26 10:34:57 theanets.trainer:168 RmsProp 1278 loss=0.041975 err=0.041975
I 2015-05-26 10:35:03 theanets.trainer:168 RmsProp 1279 loss=0.031543 err=0.031543
I 2015-05-26 10:35:09 theanets.trainer:168 RmsProp 1280 loss=0.039600 err=0.039600
I 2015-05-26 10:35:09 theanets.trainer:168 validation 128 loss=691.303650 err=691.303650
I 2015-05-26 10:35:15 theanets.trainer:168 RmsProp 1281 loss=0.037871 err=0.037871
I 2015-05-26 10:35:21 theanets.trainer:168 RmsProp 1282 loss=0.041711 err=0.041711
I 2015-05-26 10:35:27 theanets.trainer:168 RmsProp 1283 loss=0.036824 err=0.036824
I 2015-05-26 10:35:33 theanets.trainer:168 RmsProp 1284 loss=0.038169 err=0.038169
I 2015-05-26 10:35:39 theanets.trainer:168 RmsProp 1285 loss=0.036387 err=0.036387
I 2015-05-26 10:35:45 theanets.trainer:168 RmsProp 1286 loss=0.040711 err=0.040711
I 2015-05-26 10:35:51 theanets.trainer:168 RmsProp 1287 loss=0.039724 err=0.039724
I 2015-05-26 10:35:56 theanets.trainer:168 RmsProp 1288 loss=0.036726 err=0.036726
I 2015-05-26 10:36:02 theanets.trainer:168 RmsProp 1289 loss=0.039572 err=0.039572
I 2015-05-26 10:36:09 theanets.trainer:168 RmsProp 1290 loss=0.040877 err=0.040877
I 2015-05-26 10:36:09 theanets.trainer:168 validation 129 loss=690.422729 err=690.422729
I 2015-05-26 10:36:15 theanets.trainer:168 RmsProp 1291 loss=0.035621 err=0.035621
I 2015-05-26 10:36:21 theanets.trainer:168 RmsProp 1292 loss=0.038580 err=0.038580
I 2015-05-26 10:36:26 theanets.trainer:168 RmsProp 1293 loss=0.035844 err=0.035844
I 2015-05-26 10:36:32 theanets.trainer:168 RmsProp 1294 loss=0.039238 err=0.039238
I 2015-05-26 10:36:39 theanets.trainer:168 RmsProp 1295 loss=0.038115 err=0.038115
I 2015-05-26 10:36:44 theanets.trainer:168 RmsProp 1296 loss=0.036047 err=0.036047
I 2015-05-26 10:36:51 theanets.trainer:168 RmsProp 1297 loss=0.036273 err=0.036273
I 2015-05-26 10:36:56 theanets.trainer:168 RmsProp 1298 loss=0.042204 err=0.042204
I 2015-05-26 10:37:01 theanets.trainer:168 RmsProp 1299 loss=0.032803 err=0.032803
I 2015-05-26 10:37:06 theanets.trainer:168 RmsProp 1300 loss=0.048432 err=0.048432
I 2015-05-26 10:37:07 theanets.trainer:168 validation 130 loss=689.218384 err=689.218384 *
I 2015-05-26 10:37:13 theanets.trainer:168 RmsProp 1301 loss=0.031025 err=0.031025
I 2015-05-26 10:37:18 theanets.trainer:168 RmsProp 1302 loss=0.052132 err=0.052132
I 2015-05-26 10:37:24 theanets.trainer:168 RmsProp 1303 loss=0.041870 err=0.041870
I 2015-05-26 10:37:31 theanets.trainer:168 RmsProp 1304 loss=0.038342 err=0.038342
I 2015-05-26 10:37:36 theanets.trainer:168 RmsProp 1305 loss=0.038591 err=0.038591
I 2015-05-26 10:37:42 theanets.trainer:168 RmsProp 1306 loss=0.038885 err=0.038885
I 2015-05-26 10:37:48 theanets.trainer:168 RmsProp 1307 loss=0.032793 err=0.032793
I 2015-05-26 10:37:54 theanets.trainer:168 RmsProp 1308 loss=0.049590 err=0.049590
I 2015-05-26 10:38:00 theanets.trainer:168 RmsProp 1309 loss=0.044425 err=0.044425
I 2015-05-26 10:38:06 theanets.trainer:168 RmsProp 1310 loss=0.034714 err=0.034714
I 2015-05-26 10:38:06 theanets.trainer:168 validation 131 loss=688.951843 err=688.951843 *
I 2015-05-26 10:38:12 theanets.trainer:168 RmsProp 1311 loss=0.038934 err=0.038934
I 2015-05-26 10:38:18 theanets.trainer:168 RmsProp 1312 loss=0.038874 err=0.038874
I 2015-05-26 10:38:24 theanets.trainer:168 RmsProp 1313 loss=0.027576 err=0.027576
I 2015-05-26 10:38:30 theanets.trainer:168 RmsProp 1314 loss=0.073469 err=0.073469
I 2015-05-26 10:38:35 theanets.trainer:168 RmsProp 1315 loss=0.039398 err=0.039398
I 2015-05-26 10:38:41 theanets.trainer:168 RmsProp 1316 loss=0.032385 err=0.032385
I 2015-05-26 10:38:47 theanets.trainer:168 RmsProp 1317 loss=0.038614 err=0.038614
I 2015-05-26 10:38:53 theanets.trainer:168 RmsProp 1318 loss=0.040853 err=0.040853
I 2015-05-26 10:38:59 theanets.trainer:168 RmsProp 1319 loss=0.036782 err=0.036782
I 2015-05-26 10:39:04 theanets.trainer:168 RmsProp 1320 loss=0.037433 err=0.037433
I 2015-05-26 10:39:05 theanets.trainer:168 validation 132 loss=688.263489 err=688.263489 *
I 2015-05-26 10:39:11 theanets.trainer:168 RmsProp 1321 loss=0.038877 err=0.038877
I 2015-05-26 10:39:17 theanets.trainer:168 RmsProp 1322 loss=0.033588 err=0.033588
I 2015-05-26 10:39:23 theanets.trainer:168 RmsProp 1323 loss=0.044254 err=0.044254
I 2015-05-26 10:39:29 theanets.trainer:168 RmsProp 1324 loss=0.034741 err=0.034741
I 2015-05-26 10:39:35 theanets.trainer:168 RmsProp 1325 loss=0.038110 err=0.038110
I 2015-05-26 10:39:42 theanets.trainer:168 RmsProp 1326 loss=0.033708 err=0.033708
I 2015-05-26 10:39:48 theanets.trainer:168 RmsProp 1327 loss=0.041119 err=0.041119
I 2015-05-26 10:39:54 theanets.trainer:168 RmsProp 1328 loss=0.034686 err=0.034686
I 2015-05-26 10:40:00 theanets.trainer:168 RmsProp 1329 loss=0.046578 err=0.046578
I 2015-05-26 10:40:06 theanets.trainer:168 RmsProp 1330 loss=0.039632 err=0.039632
I 2015-05-26 10:40:06 theanets.trainer:168 validation 133 loss=687.846130 err=687.846130 *
I 2015-05-26 10:40:12 theanets.trainer:168 RmsProp 1331 loss=0.035101 err=0.035101
I 2015-05-26 10:40:18 theanets.trainer:168 RmsProp 1332 loss=0.033349 err=0.033349
I 2015-05-26 10:40:24 theanets.trainer:168 RmsProp 1333 loss=0.044261 err=0.044261
I 2015-05-26 10:40:30 theanets.trainer:168 RmsProp 1334 loss=0.035512 err=0.035512
I 2015-05-26 10:40:36 theanets.trainer:168 RmsProp 1335 loss=0.040301 err=0.040301
I 2015-05-26 10:40:41 theanets.trainer:168 RmsProp 1336 loss=0.039516 err=0.039516
I 2015-05-26 10:40:47 theanets.trainer:168 RmsProp 1337 loss=0.037947 err=0.037947
I 2015-05-26 10:40:53 theanets.trainer:168 RmsProp 1338 loss=0.032313 err=0.032313
I 2015-05-26 10:40:59 theanets.trainer:168 RmsProp 1339 loss=0.044941 err=0.044941
I 2015-05-26 10:41:05 theanets.trainer:168 RmsProp 1340 loss=0.036141 err=0.036141
I 2015-05-26 10:41:05 theanets.trainer:168 validation 134 loss=688.254089 err=688.254089
I 2015-05-26 10:41:11 theanets.trainer:168 RmsProp 1341 loss=0.039603 err=0.039603
I 2015-05-26 10:41:17 theanets.trainer:168 RmsProp 1342 loss=0.034415 err=0.034415
I 2015-05-26 10:41:23 theanets.trainer:168 RmsProp 1343 loss=0.036484 err=0.036484
I 2015-05-26 10:41:28 theanets.trainer:168 RmsProp 1344 loss=0.041026 err=0.041026
I 2015-05-26 10:41:34 theanets.trainer:168 RmsProp 1345 loss=0.043144 err=0.043144
I 2015-05-26 10:41:40 theanets.trainer:168 RmsProp 1346 loss=0.032875 err=0.032875
I 2015-05-26 10:41:46 theanets.trainer:168 RmsProp 1347 loss=0.029494 err=0.029494
I 2015-05-26 10:41:52 theanets.trainer:168 RmsProp 1348 loss=0.059659 err=0.059659
I 2015-05-26 10:41:58 theanets.trainer:168 RmsProp 1349 loss=0.041490 err=0.041490
I 2015-05-26 10:42:04 theanets.trainer:168 RmsProp 1350 loss=0.032621 err=0.032621
I 2015-05-26 10:42:05 theanets.trainer:168 validation 135 loss=688.136414 err=688.136414
I 2015-05-26 10:42:11 theanets.trainer:168 RmsProp 1351 loss=0.040321 err=0.040321
I 2015-05-26 10:42:16 theanets.trainer:168 RmsProp 1352 loss=0.039024 err=0.039024
I 2015-05-26 10:42:22 theanets.trainer:168 RmsProp 1353 loss=0.035271 err=0.035271
I 2015-05-26 10:42:27 theanets.trainer:168 RmsProp 1354 loss=0.035211 err=0.035211
I 2015-05-26 10:42:33 theanets.trainer:168 RmsProp 1355 loss=0.045541 err=0.045541
I 2015-05-26 10:42:39 theanets.trainer:168 RmsProp 1356 loss=0.034819 err=0.034819
I 2015-05-26 10:42:46 theanets.trainer:168 RmsProp 1357 loss=0.035936 err=0.035936
I 2015-05-26 10:42:52 theanets.trainer:168 RmsProp 1358 loss=0.038145 err=0.038145
I 2015-05-26 10:42:58 theanets.trainer:168 RmsProp 1359 loss=0.033745 err=0.033745
I 2015-05-26 10:43:04 theanets.trainer:168 RmsProp 1360 loss=0.040685 err=0.040685
I 2015-05-26 10:43:05 theanets.trainer:168 validation 136 loss=686.884399 err=686.884399 *
I 2015-05-26 10:43:10 theanets.trainer:168 RmsProp 1361 loss=0.033614 err=0.033614
I 2015-05-26 10:43:17 theanets.trainer:168 RmsProp 1362 loss=0.040039 err=0.040039
I 2015-05-26 10:43:22 theanets.trainer:168 RmsProp 1363 loss=0.039219 err=0.039219
I 2015-05-26 10:43:29 theanets.trainer:168 RmsProp 1364 loss=0.032916 err=0.032916
I 2015-05-26 10:43:34 theanets.trainer:168 RmsProp 1365 loss=0.038361 err=0.038361
I 2015-05-26 10:43:40 theanets.trainer:168 RmsProp 1366 loss=0.039715 err=0.039715
I 2015-05-26 10:43:47 theanets.trainer:168 RmsProp 1367 loss=0.034150 err=0.034150
I 2015-05-26 10:43:52 theanets.trainer:168 RmsProp 1368 loss=0.033763 err=0.033763
I 2015-05-26 10:43:57 theanets.trainer:168 RmsProp 1369 loss=0.044881 err=0.044881
I 2015-05-26 10:44:03 theanets.trainer:168 RmsProp 1370 loss=0.036734 err=0.036734
I 2015-05-26 10:44:03 theanets.trainer:168 validation 137 loss=686.113770 err=686.113770 *
I 2015-05-26 10:44:09 theanets.trainer:168 RmsProp 1371 loss=0.035100 err=0.035100
I 2015-05-26 10:44:14 theanets.trainer:168 RmsProp 1372 loss=0.039883 err=0.039883
I 2015-05-26 10:44:20 theanets.trainer:168 RmsProp 1373 loss=0.033493 err=0.033493
I 2015-05-26 10:44:27 theanets.trainer:168 RmsProp 1374 loss=0.032799 err=0.032799
I 2015-05-26 10:44:32 theanets.trainer:168 RmsProp 1375 loss=0.055948 err=0.055948
I 2015-05-26 10:44:38 theanets.trainer:168 RmsProp 1376 loss=0.032663 err=0.032663
I 2015-05-26 10:44:43 theanets.trainer:168 RmsProp 1377 loss=0.041099 err=0.041099
I 2015-05-26 10:44:49 theanets.trainer:168 RmsProp 1378 loss=0.040281 err=0.040281
I 2015-05-26 10:44:56 theanets.trainer:168 RmsProp 1379 loss=0.031296 err=0.031296
I 2015-05-26 10:45:02 theanets.trainer:168 RmsProp 1380 loss=0.039248 err=0.039248
I 2015-05-26 10:45:02 theanets.trainer:168 validation 138 loss=684.872009 err=684.872009 *
I 2015-05-26 10:45:07 theanets.trainer:168 RmsProp 1381 loss=0.035672 err=0.035672
I 2015-05-26 10:45:13 theanets.trainer:168 RmsProp 1382 loss=0.036725 err=0.036725
I 2015-05-26 10:45:19 theanets.trainer:168 RmsProp 1383 loss=0.043536 err=0.043536
I 2015-05-26 10:45:25 theanets.trainer:168 RmsProp 1384 loss=0.033716 err=0.033716
I 2015-05-26 10:45:32 theanets.trainer:168 RmsProp 1385 loss=0.033810 err=0.033810
I 2015-05-26 10:45:38 theanets.trainer:168 RmsProp 1386 loss=0.040021 err=0.040021
I 2015-05-26 10:45:44 theanets.trainer:168 RmsProp 1387 loss=0.046250 err=0.046250
I 2015-05-26 10:45:50 theanets.trainer:168 RmsProp 1388 loss=0.034757 err=0.034757
I 2015-05-26 10:45:55 theanets.trainer:168 RmsProp 1389 loss=0.033614 err=0.033614
I 2015-05-26 10:46:01 theanets.trainer:168 RmsProp 1390 loss=0.038649 err=0.038649
I 2015-05-26 10:46:02 theanets.trainer:168 validation 139 loss=685.993103 err=685.993103
I 2015-05-26 10:46:07 theanets.trainer:168 RmsProp 1391 loss=0.043665 err=0.043665
I 2015-05-26 10:46:13 theanets.trainer:168 RmsProp 1392 loss=0.031286 err=0.031286
I 2015-05-26 10:46:20 theanets.trainer:168 RmsProp 1393 loss=0.035908 err=0.035908
I 2015-05-26 10:46:25 theanets.trainer:168 RmsProp 1394 loss=0.036868 err=0.036868
I 2015-05-26 10:46:31 theanets.trainer:168 RmsProp 1395 loss=0.037496 err=0.037496
I 2015-05-26 10:46:38 theanets.trainer:168 RmsProp 1396 loss=0.030409 err=0.030409
I 2015-05-26 10:46:43 theanets.trainer:168 RmsProp 1397 loss=0.046212 err=0.046212
I 2015-05-26 10:46:49 theanets.trainer:168 RmsProp 1398 loss=0.035221 err=0.035221
I 2015-05-26 10:46:55 theanets.trainer:168 RmsProp 1399 loss=0.034272 err=0.034272
I 2015-05-26 10:47:01 theanets.trainer:168 RmsProp 1400 loss=0.032152 err=0.032152
I 2015-05-26 10:47:02 theanets.trainer:168 validation 140 loss=684.903503 err=684.903503
I 2015-05-26 10:47:07 theanets.trainer:168 RmsProp 1401 loss=0.034512 err=0.034512
I 2015-05-26 10:47:14 theanets.trainer:168 RmsProp 1402 loss=0.035991 err=0.035991
I 2015-05-26 10:47:20 theanets.trainer:168 RmsProp 1403 loss=0.032165 err=0.032165
I 2015-05-26 10:47:26 theanets.trainer:168 RmsProp 1404 loss=0.046248 err=0.046248
I 2015-05-26 10:47:32 theanets.trainer:168 RmsProp 1405 loss=0.040773 err=0.040773
I 2015-05-26 10:47:38 theanets.trainer:168 RmsProp 1406 loss=0.031620 err=0.031620
I 2015-05-26 10:47:44 theanets.trainer:168 RmsProp 1407 loss=0.039121 err=0.039121
I 2015-05-26 10:47:49 theanets.trainer:168 RmsProp 1408 loss=0.052155 err=0.052155
I 2015-05-26 10:47:56 theanets.trainer:168 RmsProp 1409 loss=0.038372 err=0.038372
I 2015-05-26 10:48:02 theanets.trainer:168 RmsProp 1410 loss=0.030079 err=0.030079
I 2015-05-26 10:48:02 theanets.trainer:168 validation 141 loss=685.178528 err=685.178528
I 2015-05-26 10:48:08 theanets.trainer:168 RmsProp 1411 loss=0.039874 err=0.039874
I 2015-05-26 10:48:14 theanets.trainer:168 RmsProp 1412 loss=0.026609 err=0.026609
I 2015-05-26 10:48:20 theanets.trainer:168 RmsProp 1413 loss=0.052290 err=0.052290
I 2015-05-26 10:48:26 theanets.trainer:168 RmsProp 1414 loss=0.033774 err=0.033774
I 2015-05-26 10:48:32 theanets.trainer:168 RmsProp 1415 loss=0.030351 err=0.030351
I 2015-05-26 10:48:38 theanets.trainer:168 RmsProp 1416 loss=0.042643 err=0.042643
I 2015-05-26 10:48:44 theanets.trainer:168 RmsProp 1417 loss=0.032854 err=0.032854
I 2015-05-26 10:48:50 theanets.trainer:168 RmsProp 1418 loss=0.037845 err=0.037845
I 2015-05-26 10:48:56 theanets.trainer:168 RmsProp 1419 loss=0.034483 err=0.034483
I 2015-05-26 10:49:02 theanets.trainer:168 RmsProp 1420 loss=0.042954 err=0.042954
I 2015-05-26 10:49:03 theanets.trainer:168 validation 142 loss=684.820679 err=684.820679 *
I 2015-05-26 10:49:08 theanets.trainer:168 RmsProp 1421 loss=0.036069 err=0.036069
I 2015-05-26 10:49:14 theanets.trainer:168 RmsProp 1422 loss=0.033547 err=0.033547
I 2015-05-26 10:49:19 theanets.trainer:168 RmsProp 1423 loss=0.037379 err=0.037379
I 2015-05-26 10:49:26 theanets.trainer:168 RmsProp 1424 loss=0.038732 err=0.038732
I 2015-05-26 10:49:32 theanets.trainer:168 RmsProp 1425 loss=0.031388 err=0.031388
I 2015-05-26 10:49:38 theanets.trainer:168 RmsProp 1426 loss=0.041898 err=0.041898
I 2015-05-26 10:49:44 theanets.trainer:168 RmsProp 1427 loss=0.037798 err=0.037798
I 2015-05-26 10:49:50 theanets.trainer:168 RmsProp 1428 loss=0.035094 err=0.035094
I 2015-05-26 10:49:56 theanets.trainer:168 RmsProp 1429 loss=0.035982 err=0.035982
I 2015-05-26 10:50:02 theanets.trainer:168 RmsProp 1430 loss=0.033065 err=0.033065
I 2015-05-26 10:50:02 theanets.trainer:168 validation 143 loss=685.092834 err=685.092834
I 2015-05-26 10:50:08 theanets.trainer:168 RmsProp 1431 loss=0.036111 err=0.036111
I 2015-05-26 10:50:14 theanets.trainer:168 RmsProp 1432 loss=0.035781 err=0.035781
I 2015-05-26 10:50:20 theanets.trainer:168 RmsProp 1433 loss=0.040660 err=0.040660
I 2015-05-26 10:50:26 theanets.trainer:168 RmsProp 1434 loss=0.033927 err=0.033927
I 2015-05-26 10:50:32 theanets.trainer:168 RmsProp 1435 loss=0.031314 err=0.031314
I 2015-05-26 10:50:38 theanets.trainer:168 RmsProp 1436 loss=0.046133 err=0.046133
I 2015-05-26 10:50:44 theanets.trainer:168 RmsProp 1437 loss=0.035275 err=0.035275
I 2015-05-26 10:50:50 theanets.trainer:168 RmsProp 1438 loss=0.031426 err=0.031426
I 2015-05-26 10:50:56 theanets.trainer:168 RmsProp 1439 loss=0.043345 err=0.043345
I 2015-05-26 10:51:03 theanets.trainer:168 RmsProp 1440 loss=0.039168 err=0.039168
I 2015-05-26 10:51:03 theanets.trainer:168 validation 144 loss=683.495056 err=683.495056 *
I 2015-05-26 10:51:09 theanets.trainer:168 RmsProp 1441 loss=0.026355 err=0.026355
I 2015-05-26 10:51:14 theanets.trainer:168 RmsProp 1442 loss=0.043928 err=0.043928
I 2015-05-26 10:51:21 theanets.trainer:168 RmsProp 1443 loss=0.032820 err=0.032820
I 2015-05-26 10:51:27 theanets.trainer:168 RmsProp 1444 loss=0.040228 err=0.040228
I 2015-05-26 10:51:33 theanets.trainer:168 RmsProp 1445 loss=0.032289 err=0.032289
I 2015-05-26 10:51:39 theanets.trainer:168 RmsProp 1446 loss=0.032076 err=0.032076
I 2015-05-26 10:51:45 theanets.trainer:168 RmsProp 1447 loss=0.041510 err=0.041510
I 2015-05-26 10:51:50 theanets.trainer:168 RmsProp 1448 loss=0.029467 err=0.029467
I 2015-05-26 10:51:56 theanets.trainer:168 RmsProp 1449 loss=0.036405 err=0.036405
I 2015-05-26 10:52:02 theanets.trainer:168 RmsProp 1450 loss=0.031041 err=0.031041
I 2015-05-26 10:52:03 theanets.trainer:168 validation 145 loss=682.964355 err=682.964355 *
I 2015-05-26 10:52:08 theanets.trainer:168 RmsProp 1451 loss=0.047762 err=0.047762
I 2015-05-26 10:52:14 theanets.trainer:168 RmsProp 1452 loss=0.035295 err=0.035295
I 2015-05-26 10:52:20 theanets.trainer:168 RmsProp 1453 loss=0.033602 err=0.033602
I 2015-05-26 10:52:25 theanets.trainer:168 RmsProp 1454 loss=0.032040 err=0.032040
I 2015-05-26 10:52:32 theanets.trainer:168 RmsProp 1455 loss=0.042771 err=0.042771
I 2015-05-26 10:52:37 theanets.trainer:168 RmsProp 1456 loss=0.035157 err=0.035157
I 2015-05-26 10:52:43 theanets.trainer:168 RmsProp 1457 loss=0.034011 err=0.034011
I 2015-05-26 10:52:49 theanets.trainer:168 RmsProp 1458 loss=0.032175 err=0.032175
I 2015-05-26 10:52:55 theanets.trainer:168 RmsProp 1459 loss=0.041326 err=0.041326
I 2015-05-26 10:53:00 theanets.trainer:168 RmsProp 1460 loss=0.036066 err=0.036066
I 2015-05-26 10:53:01 theanets.trainer:168 validation 146 loss=683.514465 err=683.514465
I 2015-05-26 10:53:06 theanets.trainer:168 RmsProp 1461 loss=0.032080 err=0.032080
I 2015-05-26 10:53:13 theanets.trainer:168 RmsProp 1462 loss=0.034014 err=0.034014
I 2015-05-26 10:53:19 theanets.trainer:168 RmsProp 1463 loss=0.041422 err=0.041422
I 2015-05-26 10:53:25 theanets.trainer:168 RmsProp 1464 loss=0.037944 err=0.037944
I 2015-05-26 10:53:31 theanets.trainer:168 RmsProp 1465 loss=0.036990 err=0.036990
I 2015-05-26 10:53:37 theanets.trainer:168 RmsProp 1466 loss=0.035949 err=0.035949
I 2015-05-26 10:53:43 theanets.trainer:168 RmsProp 1467 loss=0.030548 err=0.030548
I 2015-05-26 10:53:49 theanets.trainer:168 RmsProp 1468 loss=0.037015 err=0.037015
I 2015-05-26 10:53:54 theanets.trainer:168 RmsProp 1469 loss=0.032772 err=0.032772
I 2015-05-26 10:54:00 theanets.trainer:168 RmsProp 1470 loss=0.033215 err=0.033215
I 2015-05-26 10:54:00 theanets.trainer:168 validation 147 loss=683.020813 err=683.020813
I 2015-05-26 10:54:06 theanets.trainer:168 RmsProp 1471 loss=0.040704 err=0.040704
I 2015-05-26 10:54:12 theanets.trainer:168 RmsProp 1472 loss=0.034805 err=0.034805
I 2015-05-26 10:54:18 theanets.trainer:168 RmsProp 1473 loss=0.028615 err=0.028615
I 2015-05-26 10:54:23 theanets.trainer:168 RmsProp 1474 loss=0.046149 err=0.046149
I 2015-05-26 10:54:29 theanets.trainer:168 RmsProp 1475 loss=0.029048 err=0.029048
I 2015-05-26 10:54:35 theanets.trainer:168 RmsProp 1476 loss=0.036015 err=0.036015
I 2015-05-26 10:54:41 theanets.trainer:168 RmsProp 1477 loss=0.036852 err=0.036852
I 2015-05-26 10:54:47 theanets.trainer:168 RmsProp 1478 loss=0.038827 err=0.038827
I 2015-05-26 10:54:53 theanets.trainer:168 RmsProp 1479 loss=0.034235 err=0.034235
I 2015-05-26 10:54:59 theanets.trainer:168 RmsProp 1480 loss=0.036842 err=0.036842
I 2015-05-26 10:54:59 theanets.trainer:168 validation 148 loss=683.799744 err=683.799744
I 2015-05-26 10:55:05 theanets.trainer:168 RmsProp 1481 loss=0.030014 err=0.030014
I 2015-05-26 10:55:10 theanets.trainer:168 RmsProp 1482 loss=0.033919 err=0.033919
I 2015-05-26 10:55:16 theanets.trainer:168 RmsProp 1483 loss=0.034158 err=0.034158
I 2015-05-26 10:55:22 theanets.trainer:168 RmsProp 1484 loss=0.030919 err=0.030919
I 2015-05-26 10:55:28 theanets.trainer:168 RmsProp 1485 loss=0.040784 err=0.040784
I 2015-05-26 10:55:34 theanets.trainer:168 RmsProp 1486 loss=0.030676 err=0.030676
I 2015-05-26 10:55:40 theanets.trainer:168 RmsProp 1487 loss=0.041690 err=0.041690
I 2015-05-26 10:55:45 theanets.trainer:168 RmsProp 1488 loss=0.044410 err=0.044410
I 2015-05-26 10:55:50 theanets.trainer:168 RmsProp 1489 loss=0.033775 err=0.033775
I 2015-05-26 10:55:56 theanets.trainer:168 RmsProp 1490 loss=0.031192 err=0.031192
I 2015-05-26 10:55:56 theanets.trainer:168 validation 149 loss=682.827087 err=682.827087 *
I 2015-05-26 10:56:02 theanets.trainer:168 RmsProp 1491 loss=0.036870 err=0.036870
I 2015-05-26 10:56:08 theanets.trainer:168 RmsProp 1492 loss=0.040209 err=0.040209
I 2015-05-26 10:56:14 theanets.trainer:168 RmsProp 1493 loss=0.032067 err=0.032067
I 2015-05-26 10:56:20 theanets.trainer:168 RmsProp 1494 loss=0.032191 err=0.032191
I 2015-05-26 10:56:26 theanets.trainer:168 RmsProp 1495 loss=0.037020 err=0.037020
I 2015-05-26 10:56:32 theanets.trainer:168 RmsProp 1496 loss=0.036168 err=0.036168
I 2015-05-26 10:56:38 theanets.trainer:168 RmsProp 1497 loss=0.031300 err=0.031300
I 2015-05-26 10:56:44 theanets.trainer:168 RmsProp 1498 loss=0.033905 err=0.033905
I 2015-05-26 10:56:51 theanets.trainer:168 RmsProp 1499 loss=0.035816 err=0.035816
I 2015-05-26 10:56:57 theanets.trainer:168 RmsProp 1500 loss=0.032985 err=0.032985
I 2015-05-26 10:56:58 theanets.trainer:168 validation 150 loss=682.622864 err=682.622864 *
I 2015-05-26 10:57:03 theanets.trainer:168 RmsProp 1501 loss=0.038033 err=0.038033
I 2015-05-26 10:57:09 theanets.trainer:168 RmsProp 1502 loss=0.034608 err=0.034608
I 2015-05-26 10:57:15 theanets.trainer:168 RmsProp 1503 loss=0.024539 err=0.024539
I 2015-05-26 10:57:21 theanets.trainer:168 RmsProp 1504 loss=0.071315 err=0.071315
I 2015-05-26 10:57:27 theanets.trainer:168 RmsProp 1505 loss=0.044321 err=0.044321
I 2015-05-26 10:57:33 theanets.trainer:168 RmsProp 1506 loss=0.029730 err=0.029730
I 2015-05-26 10:57:39 theanets.trainer:168 RmsProp 1507 loss=0.028678 err=0.028678
I 2015-05-26 10:57:46 theanets.trainer:168 RmsProp 1508 loss=0.031268 err=0.031268
I 2015-05-26 10:57:52 theanets.trainer:168 RmsProp 1509 loss=0.043318 err=0.043318
I 2015-05-26 10:57:57 theanets.trainer:168 RmsProp 1510 loss=0.028808 err=0.028808
I 2015-05-26 10:57:58 theanets.trainer:168 validation 151 loss=681.673035 err=681.673035 *
I 2015-05-26 10:58:03 theanets.trainer:168 RmsProp 1511 loss=0.034806 err=0.034806
I 2015-05-26 10:58:09 theanets.trainer:168 RmsProp 1512 loss=0.039771 err=0.039771
I 2015-05-26 10:58:15 theanets.trainer:168 RmsProp 1513 loss=0.030908 err=0.030908
I 2015-05-26 10:58:21 theanets.trainer:168 RmsProp 1514 loss=0.026788 err=0.026788
I 2015-05-26 10:58:26 theanets.trainer:168 RmsProp 1515 loss=0.047419 err=0.047419
I 2015-05-26 10:58:32 theanets.trainer:168 RmsProp 1516 loss=0.032324 err=0.032324
I 2015-05-26 10:58:38 theanets.trainer:168 RmsProp 1517 loss=0.034030 err=0.034030
I 2015-05-26 10:58:44 theanets.trainer:168 RmsProp 1518 loss=0.031174 err=0.031174
I 2015-05-26 10:58:50 theanets.trainer:168 RmsProp 1519 loss=0.032504 err=0.032504
I 2015-05-26 10:58:56 theanets.trainer:168 RmsProp 1520 loss=0.033618 err=0.033618
I 2015-05-26 10:58:56 theanets.trainer:168 validation 152 loss=682.088867 err=682.088867
I 2015-05-26 10:59:02 theanets.trainer:168 RmsProp 1521 loss=0.037189 err=0.037189
I 2015-05-26 10:59:08 theanets.trainer:168 RmsProp 1522 loss=0.031796 err=0.031796
I 2015-05-26 10:59:14 theanets.trainer:168 RmsProp 1523 loss=0.031476 err=0.031476
I 2015-05-26 10:59:20 theanets.trainer:168 RmsProp 1524 loss=0.036599 err=0.036599
I 2015-05-26 10:59:26 theanets.trainer:168 RmsProp 1525 loss=0.032294 err=0.032294
I 2015-05-26 10:59:33 theanets.trainer:168 RmsProp 1526 loss=0.033239 err=0.033239
I 2015-05-26 10:59:39 theanets.trainer:168 RmsProp 1527 loss=0.033146 err=0.033146
I 2015-05-26 10:59:45 theanets.trainer:168 RmsProp 1528 loss=0.034233 err=0.034233
I 2015-05-26 10:59:51 theanets.trainer:168 RmsProp 1529 loss=0.034497 err=0.034497
I 2015-05-26 10:59:57 theanets.trainer:168 RmsProp 1530 loss=0.032545 err=0.032545
I 2015-05-26 10:59:57 theanets.trainer:168 validation 153 loss=680.399109 err=680.399109 *
I 2015-05-26 11:00:03 theanets.trainer:168 RmsProp 1531 loss=0.031259 err=0.031259
I 2015-05-26 11:00:09 theanets.trainer:168 RmsProp 1532 loss=0.045104 err=0.045104
I 2015-05-26 11:00:16 theanets.trainer:168 RmsProp 1533 loss=0.063854 err=0.063854
I 2015-05-26 11:00:21 theanets.trainer:168 RmsProp 1534 loss=0.035617 err=0.035617
I 2015-05-26 11:00:27 theanets.trainer:168 RmsProp 1535 loss=0.027336 err=0.027336
I 2015-05-26 11:00:34 theanets.trainer:168 RmsProp 1536 loss=0.032278 err=0.032278
I 2015-05-26 11:00:40 theanets.trainer:168 RmsProp 1537 loss=0.037926 err=0.037926
I 2015-05-26 11:00:46 theanets.trainer:168 RmsProp 1538 loss=0.038363 err=0.038363
I 2015-05-26 11:00:51 theanets.trainer:168 RmsProp 1539 loss=0.029602 err=0.029602
I 2015-05-26 11:00:57 theanets.trainer:168 RmsProp 1540 loss=0.037314 err=0.037314
I 2015-05-26 11:00:58 theanets.trainer:168 validation 154 loss=679.556335 err=679.556335 *
I 2015-05-26 11:01:03 theanets.trainer:168 RmsProp 1541 loss=0.032854 err=0.032854
I 2015-05-26 11:01:09 theanets.trainer:168 RmsProp 1542 loss=0.030499 err=0.030499
I 2015-05-26 11:01:15 theanets.trainer:168 RmsProp 1543 loss=0.042648 err=0.042648
I 2015-05-26 11:01:21 theanets.trainer:168 RmsProp 1544 loss=0.036755 err=0.036755
I 2015-05-26 11:01:27 theanets.trainer:168 RmsProp 1545 loss=0.027289 err=0.027289
I 2015-05-26 11:01:33 theanets.trainer:168 RmsProp 1546 loss=0.055219 err=0.055219
I 2015-05-26 11:01:39 theanets.trainer:168 RmsProp 1547 loss=0.030695 err=0.030695
I 2015-05-26 11:01:46 theanets.trainer:168 RmsProp 1548 loss=0.029695 err=0.029695
I 2015-05-26 11:01:52 theanets.trainer:168 RmsProp 1549 loss=0.045104 err=0.045104
I 2015-05-26 11:01:58 theanets.trainer:168 RmsProp 1550 loss=0.031635 err=0.031635
I 2015-05-26 11:01:58 theanets.trainer:168 validation 155 loss=679.404175 err=679.404175 *
I 2015-05-26 11:02:04 theanets.trainer:168 RmsProp 1551 loss=0.030710 err=0.030710
I 2015-05-26 11:02:09 theanets.trainer:168 RmsProp 1552 loss=0.046843 err=0.046843
I 2015-05-26 11:02:15 theanets.trainer:168 RmsProp 1553 loss=0.031825 err=0.031825
I 2015-05-26 11:02:22 theanets.trainer:168 RmsProp 1554 loss=0.029757 err=0.029757
I 2015-05-26 11:02:28 theanets.trainer:168 RmsProp 1555 loss=0.031101 err=0.031101
I 2015-05-26 11:02:33 theanets.trainer:168 RmsProp 1556 loss=0.039980 err=0.039980
I 2015-05-26 11:02:38 theanets.trainer:168 RmsProp 1557 loss=0.031940 err=0.031940
I 2015-05-26 11:02:44 theanets.trainer:168 RmsProp 1558 loss=0.030427 err=0.030427
I 2015-05-26 11:02:49 theanets.trainer:168 RmsProp 1559 loss=0.044795 err=0.044795
I 2015-05-26 11:02:54 theanets.trainer:168 RmsProp 1560 loss=0.035413 err=0.035413
I 2015-05-26 11:02:54 theanets.trainer:168 validation 156 loss=680.377380 err=680.377380
I 2015-05-26 11:02:59 theanets.trainer:168 RmsProp 1561 loss=0.029598 err=0.029598
I 2015-05-26 11:03:04 theanets.trainer:168 RmsProp 1562 loss=0.036458 err=0.036458
I 2015-05-26 11:03:09 theanets.trainer:168 RmsProp 1563 loss=0.036826 err=0.036826
I 2015-05-26 11:03:14 theanets.trainer:168 RmsProp 1564 loss=0.034730 err=0.034730
I 2015-05-26 11:03:19 theanets.trainer:168 RmsProp 1565 loss=0.035558 err=0.035558
I 2015-05-26 11:03:25 theanets.trainer:168 RmsProp 1566 loss=0.034006 err=0.034006
I 2015-05-26 11:03:30 theanets.trainer:168 RmsProp 1567 loss=0.040224 err=0.040224
I 2015-05-26 11:03:35 theanets.trainer:168 RmsProp 1568 loss=0.032329 err=0.032329
I 2015-05-26 11:03:40 theanets.trainer:168 RmsProp 1569 loss=0.033090 err=0.033090
I 2015-05-26 11:03:45 theanets.trainer:168 RmsProp 1570 loss=0.035634 err=0.035634
I 2015-05-26 11:03:46 theanets.trainer:168 validation 157 loss=679.490417 err=679.490417
I 2015-05-26 11:03:51 theanets.trainer:168 RmsProp 1571 loss=0.035419 err=0.035419
I 2015-05-26 11:03:56 theanets.trainer:168 RmsProp 1572 loss=0.025803 err=0.025803
I 2015-05-26 11:04:01 theanets.trainer:168 RmsProp 1573 loss=0.049246 err=0.049246
I 2015-05-26 11:04:06 theanets.trainer:168 RmsProp 1574 loss=0.035944 err=0.035944
I 2015-05-26 11:04:11 theanets.trainer:168 RmsProp 1575 loss=0.026555 err=0.026555
I 2015-05-26 11:04:16 theanets.trainer:168 RmsProp 1576 loss=0.039292 err=0.039292
I 2015-05-26 11:04:22 theanets.trainer:168 RmsProp 1577 loss=0.036170 err=0.036170
I 2015-05-26 11:04:27 theanets.trainer:168 RmsProp 1578 loss=0.027413 err=0.027413
I 2015-05-26 11:04:32 theanets.trainer:168 RmsProp 1579 loss=0.038761 err=0.038761
I 2015-05-26 11:04:37 theanets.trainer:168 RmsProp 1580 loss=0.036207 err=0.036207
I 2015-05-26 11:04:38 theanets.trainer:168 validation 158 loss=680.172852 err=680.172852
I 2015-05-26 11:04:42 theanets.trainer:168 RmsProp 1581 loss=0.031853 err=0.031853
I 2015-05-26 11:04:48 theanets.trainer:168 RmsProp 1582 loss=0.037639 err=0.037639
I 2015-05-26 11:04:51 theanets.trainer:168 RmsProp 1583 loss=0.034900 err=0.034900
I 2015-05-26 11:04:55 theanets.trainer:168 RmsProp 1584 loss=0.033360 err=0.033360
I 2015-05-26 11:05:00 theanets.trainer:168 RmsProp 1585 loss=0.031319 err=0.031319
I 2015-05-26 11:05:04 theanets.trainer:168 RmsProp 1586 loss=0.032826 err=0.032826
I 2015-05-26 11:05:08 theanets.trainer:168 RmsProp 1587 loss=0.032023 err=0.032023
I 2015-05-26 11:05:12 theanets.trainer:168 RmsProp 1588 loss=0.036466 err=0.036466
I 2015-05-26 11:05:16 theanets.trainer:168 RmsProp 1589 loss=0.034059 err=0.034059
I 2015-05-26 11:05:20 theanets.trainer:168 RmsProp 1590 loss=0.032035 err=0.032035
I 2015-05-26 11:05:20 theanets.trainer:168 validation 159 loss=679.932434 err=679.932434
I 2015-05-26 11:05:24 theanets.trainer:168 RmsProp 1591 loss=0.036371 err=0.036371
I 2015-05-26 11:05:28 theanets.trainer:168 RmsProp 1592 loss=0.032371 err=0.032371
I 2015-05-26 11:05:32 theanets.trainer:168 RmsProp 1593 loss=0.032080 err=0.032080
I 2015-05-26 11:05:36 theanets.trainer:168 RmsProp 1594 loss=0.035305 err=0.035305
I 2015-05-26 11:05:40 theanets.trainer:168 RmsProp 1595 loss=0.034278 err=0.034278
I 2015-05-26 11:05:44 theanets.trainer:168 RmsProp 1596 loss=0.034212 err=0.034212
I 2015-05-26 11:05:48 theanets.trainer:168 RmsProp 1597 loss=0.030753 err=0.030753
I 2015-05-26 11:05:52 theanets.trainer:168 RmsProp 1598 loss=0.034313 err=0.034313
I 2015-05-26 11:05:56 theanets.trainer:168 RmsProp 1599 loss=0.032230 err=0.032230
I 2015-05-26 11:06:00 theanets.trainer:168 RmsProp 1600 loss=0.034324 err=0.034324
I 2015-05-26 11:06:00 theanets.trainer:168 validation 160 loss=679.131287 err=679.131287 *
I 2015-05-26 11:06:03 theanets.trainer:168 RmsProp 1601 loss=0.038723 err=0.038723
I 2015-05-26 11:06:07 theanets.trainer:168 RmsProp 1602 loss=0.028300 err=0.028300
I 2015-05-26 11:06:11 theanets.trainer:168 RmsProp 1603 loss=0.040816 err=0.040816
I 2015-05-26 11:06:15 theanets.trainer:168 RmsProp 1604 loss=0.028738 err=0.028738
I 2015-05-26 11:06:19 theanets.trainer:168 RmsProp 1605 loss=0.045649 err=0.045649
I 2015-05-26 11:06:24 theanets.trainer:168 RmsProp 1606 loss=0.039560 err=0.039560
I 2015-05-26 11:06:28 theanets.trainer:168 RmsProp 1607 loss=0.034920 err=0.034920
I 2015-05-26 11:06:32 theanets.trainer:168 RmsProp 1608 loss=0.031165 err=0.031165
I 2015-05-26 11:06:36 theanets.trainer:168 RmsProp 1609 loss=0.035407 err=0.035407
I 2015-05-26 11:06:39 theanets.trainer:168 RmsProp 1610 loss=0.029505 err=0.029505
I 2015-05-26 11:06:40 theanets.trainer:168 validation 161 loss=679.781555 err=679.781555
I 2015-05-26 11:06:43 theanets.trainer:168 RmsProp 1611 loss=0.037769 err=0.037769
I 2015-05-26 11:06:47 theanets.trainer:168 RmsProp 1612 loss=0.029279 err=0.029279
I 2015-05-26 11:06:51 theanets.trainer:168 RmsProp 1613 loss=0.041847 err=0.041847
I 2015-05-26 11:06:55 theanets.trainer:168 RmsProp 1614 loss=0.037367 err=0.037367
I 2015-05-26 11:06:59 theanets.trainer:168 RmsProp 1615 loss=0.028402 err=0.028402
I 2015-05-26 11:07:03 theanets.trainer:168 RmsProp 1616 loss=0.036040 err=0.036040
I 2015-05-26 11:07:07 theanets.trainer:168 RmsProp 1617 loss=0.033339 err=0.033339
I 2015-05-26 11:07:12 theanets.trainer:168 RmsProp 1618 loss=0.033761 err=0.033761
I 2015-05-26 11:07:16 theanets.trainer:168 RmsProp 1619 loss=0.036360 err=0.036360
I 2015-05-26 11:07:19 theanets.trainer:168 RmsProp 1620 loss=0.031293 err=0.031293
I 2015-05-26 11:07:20 theanets.trainer:168 validation 162 loss=679.230652 err=679.230652
I 2015-05-26 11:07:23 theanets.trainer:168 RmsProp 1621 loss=0.031709 err=0.031709
I 2015-05-26 11:07:27 theanets.trainer:168 RmsProp 1622 loss=0.025698 err=0.025698
I 2015-05-26 11:07:31 theanets.trainer:168 RmsProp 1623 loss=0.049752 err=0.049752
I 2015-05-26 11:07:35 theanets.trainer:168 RmsProp 1624 loss=0.035726 err=0.035726
I 2015-05-26 11:07:39 theanets.trainer:168 RmsProp 1625 loss=0.027469 err=0.027469
I 2015-05-26 11:07:43 theanets.trainer:168 RmsProp 1626 loss=0.039324 err=0.039324
I 2015-05-26 11:07:48 theanets.trainer:168 RmsProp 1627 loss=0.041887 err=0.041887
I 2015-05-26 11:07:52 theanets.trainer:168 RmsProp 1628 loss=0.027945 err=0.027945
I 2015-05-26 11:07:56 theanets.trainer:168 RmsProp 1629 loss=0.028681 err=0.028681
I 2015-05-26 11:07:59 theanets.trainer:168 RmsProp 1630 loss=0.031987 err=0.031987
I 2015-05-26 11:08:00 theanets.trainer:168 validation 163 loss=678.367493 err=678.367493 *
I 2015-05-26 11:08:03 theanets.trainer:168 RmsProp 1631 loss=0.034226 err=0.034226
I 2015-05-26 11:08:07 theanets.trainer:168 RmsProp 1632 loss=0.039700 err=0.039700
I 2015-05-26 11:08:11 theanets.trainer:168 RmsProp 1633 loss=0.029496 err=0.029496
I 2015-05-26 11:08:15 theanets.trainer:168 RmsProp 1634 loss=0.036600 err=0.036600
I 2015-05-26 11:08:19 theanets.trainer:168 RmsProp 1635 loss=0.030230 err=0.030230
I 2015-05-26 11:08:24 theanets.trainer:168 RmsProp 1636 loss=0.033742 err=0.033742
I 2015-05-26 11:08:28 theanets.trainer:168 RmsProp 1637 loss=0.038765 err=0.038765
I 2015-05-26 11:08:32 theanets.trainer:168 RmsProp 1638 loss=0.030721 err=0.030721
I 2015-05-26 11:08:36 theanets.trainer:168 RmsProp 1639 loss=0.028397 err=0.028397
I 2015-05-26 11:08:40 theanets.trainer:168 RmsProp 1640 loss=0.035852 err=0.035852
I 2015-05-26 11:08:40 theanets.trainer:168 validation 164 loss=678.495117 err=678.495117
I 2015-05-26 11:08:43 theanets.trainer:168 RmsProp 1641 loss=0.029051 err=0.029051
I 2015-05-26 11:08:48 theanets.trainer:168 RmsProp 1642 loss=0.033465 err=0.033465
I 2015-05-26 11:08:51 theanets.trainer:168 RmsProp 1643 loss=0.027682 err=0.027682
I 2015-05-26 11:08:55 theanets.trainer:168 RmsProp 1644 loss=0.037067 err=0.037067
I 2015-05-26 11:09:00 theanets.trainer:168 RmsProp 1645 loss=0.029927 err=0.029927
I 2015-05-26 11:09:04 theanets.trainer:168 RmsProp 1646 loss=0.032672 err=0.032672
I 2015-05-26 11:09:08 theanets.trainer:168 RmsProp 1647 loss=0.028637 err=0.028637
I 2015-05-26 11:09:12 theanets.trainer:168 RmsProp 1648 loss=0.031774 err=0.031774
I 2015-05-26 11:09:16 theanets.trainer:168 RmsProp 1649 loss=0.037997 err=0.037997
I 2015-05-26 11:09:20 theanets.trainer:168 RmsProp 1650 loss=0.036129 err=0.036129
I 2015-05-26 11:09:20 theanets.trainer:168 validation 165 loss=677.522034 err=677.522034 *
I 2015-05-26 11:09:24 theanets.trainer:168 RmsProp 1651 loss=0.030551 err=0.030551
I 2015-05-26 11:09:28 theanets.trainer:168 RmsProp 1652 loss=0.036682 err=0.036682
I 2015-05-26 11:09:31 theanets.trainer:168 RmsProp 1653 loss=0.036009 err=0.036009
I 2015-05-26 11:09:36 theanets.trainer:168 RmsProp 1654 loss=0.028244 err=0.028244
I 2015-05-26 11:09:40 theanets.trainer:168 RmsProp 1655 loss=0.034529 err=0.034529
I 2015-05-26 11:09:44 theanets.trainer:168 RmsProp 1656 loss=0.034825 err=0.034825
I 2015-05-26 11:09:48 theanets.trainer:168 RmsProp 1657 loss=0.028598 err=0.028598
I 2015-05-26 11:09:52 theanets.trainer:168 RmsProp 1658 loss=0.038212 err=0.038212
I 2015-05-26 11:09:56 theanets.trainer:168 RmsProp 1659 loss=0.033588 err=0.033588
I 2015-05-26 11:10:00 theanets.trainer:168 RmsProp 1660 loss=0.028642 err=0.028642
I 2015-05-26 11:10:00 theanets.trainer:168 validation 166 loss=678.119263 err=678.119263
I 2015-05-26 11:10:04 theanets.trainer:168 RmsProp 1661 loss=0.035044 err=0.035044
I 2015-05-26 11:10:08 theanets.trainer:168 RmsProp 1662 loss=0.033279 err=0.033279
I 2015-05-26 11:10:12 theanets.trainer:168 RmsProp 1663 loss=0.029680 err=0.029680
I 2015-05-26 11:10:16 theanets.trainer:168 RmsProp 1664 loss=0.036278 err=0.036278
I 2015-05-26 11:10:20 theanets.trainer:168 RmsProp 1665 loss=0.025774 err=0.025774
I 2015-05-26 11:10:24 theanets.trainer:168 RmsProp 1666 loss=0.035146 err=0.035146
I 2015-05-26 11:10:28 theanets.trainer:168 RmsProp 1667 loss=0.029041 err=0.029041
I 2015-05-26 11:10:32 theanets.trainer:168 RmsProp 1668 loss=0.030058 err=0.030058
I 2015-05-26 11:10:36 theanets.trainer:168 RmsProp 1669 loss=0.036323 err=0.036323
I 2015-05-26 11:10:40 theanets.trainer:168 RmsProp 1670 loss=0.032706 err=0.032706
I 2015-05-26 11:10:40 theanets.trainer:168 validation 167 loss=676.986938 err=676.986938 *
I 2015-05-26 11:10:44 theanets.trainer:168 RmsProp 1671 loss=0.027190 err=0.027190
I 2015-05-26 11:10:48 theanets.trainer:168 RmsProp 1672 loss=0.035644 err=0.035644
I 2015-05-26 11:10:52 theanets.trainer:168 RmsProp 1673 loss=0.033821 err=0.033821
I 2015-05-26 11:10:56 theanets.trainer:168 RmsProp 1674 loss=0.024738 err=0.024738
I 2015-05-26 11:11:00 theanets.trainer:168 RmsProp 1675 loss=0.047717 err=0.047717
I 2015-05-26 11:11:04 theanets.trainer:168 RmsProp 1676 loss=0.034935 err=0.034935
I 2015-05-26 11:11:08 theanets.trainer:168 RmsProp 1677 loss=0.028804 err=0.028804
I 2015-05-26 11:11:12 theanets.trainer:168 RmsProp 1678 loss=0.029866 err=0.029866
I 2015-05-26 11:11:16 theanets.trainer:168 RmsProp 1679 loss=0.037216 err=0.037216
I 2015-05-26 11:11:20 theanets.trainer:168 RmsProp 1680 loss=0.051289 err=0.051289
I 2015-05-26 11:11:21 theanets.trainer:168 validation 168 loss=677.316284 err=677.316284
I 2015-05-26 11:11:24 theanets.trainer:168 RmsProp 1681 loss=0.034934 err=0.034934
I 2015-05-26 11:11:28 theanets.trainer:168 RmsProp 1682 loss=0.030273 err=0.030273
I 2015-05-26 11:11:32 theanets.trainer:168 RmsProp 1683 loss=0.027153 err=0.027153
I 2015-05-26 11:11:36 theanets.trainer:168 RmsProp 1684 loss=0.031743 err=0.031743
I 2015-05-26 11:11:40 theanets.trainer:168 RmsProp 1685 loss=0.037769 err=0.037769
I 2015-05-26 11:11:44 theanets.trainer:168 RmsProp 1686 loss=0.023850 err=0.023850
I 2015-05-26 11:11:48 theanets.trainer:168 RmsProp 1687 loss=0.043228 err=0.043228
I 2015-05-26 11:11:52 theanets.trainer:168 RmsProp 1688 loss=0.036434 err=0.036434
I 2015-05-26 11:11:56 theanets.trainer:168 RmsProp 1689 loss=0.030077 err=0.030077
I 2015-05-26 11:12:00 theanets.trainer:168 RmsProp 1690 loss=0.030457 err=0.030457
I 2015-05-26 11:12:00 theanets.trainer:168 validation 169 loss=675.757690 err=675.757690 *
I 2015-05-26 11:12:04 theanets.trainer:168 RmsProp 1691 loss=0.030417 err=0.030417
I 2015-05-26 11:12:08 theanets.trainer:168 RmsProp 1692 loss=0.033307 err=0.033307
I 2015-05-26 11:12:12 theanets.trainer:168 RmsProp 1693 loss=0.034950 err=0.034950
I 2015-05-26 11:12:16 theanets.trainer:168 RmsProp 1694 loss=0.033545 err=0.033545
I 2015-05-26 11:12:20 theanets.trainer:168 RmsProp 1695 loss=0.030295 err=0.030295
I 2015-05-26 11:12:24 theanets.trainer:168 RmsProp 1696 loss=0.030409 err=0.030409
I 2015-05-26 11:12:28 theanets.trainer:168 RmsProp 1697 loss=0.034600 err=0.034600
I 2015-05-26 11:12:32 theanets.trainer:168 RmsProp 1698 loss=0.023666 err=0.023666
I 2015-05-26 11:12:36 theanets.trainer:168 RmsProp 1699 loss=0.049551 err=0.049551
I 2015-05-26 11:12:40 theanets.trainer:168 RmsProp 1700 loss=0.033327 err=0.033327
I 2015-05-26 11:12:40 theanets.trainer:168 validation 170 loss=675.873718 err=675.873718
I 2015-05-26 11:12:44 theanets.trainer:168 RmsProp 1701 loss=0.022895 err=0.022895
I 2015-05-26 11:12:48 theanets.trainer:168 RmsProp 1702 loss=0.041775 err=0.041775
I 2015-05-26 11:12:52 theanets.trainer:168 RmsProp 1703 loss=0.030735 err=0.030735
I 2015-05-26 11:12:56 theanets.trainer:168 RmsProp 1704 loss=0.023957 err=0.023957
I 2015-05-26 11:13:00 theanets.trainer:168 RmsProp 1705 loss=0.050957 err=0.050957
I 2015-05-26 11:13:04 theanets.trainer:168 RmsProp 1706 loss=0.035015 err=0.035015
I 2015-05-26 11:13:08 theanets.trainer:168 RmsProp 1707 loss=0.029487 err=0.029487
I 2015-05-26 11:13:12 theanets.trainer:168 RmsProp 1708 loss=0.030892 err=0.030892
I 2015-05-26 11:13:16 theanets.trainer:168 RmsProp 1709 loss=0.028351 err=0.028351
I 2015-05-26 11:13:20 theanets.trainer:168 RmsProp 1710 loss=0.034306 err=0.034306
I 2015-05-26 11:13:20 theanets.trainer:168 validation 171 loss=676.163635 err=676.163635
I 2015-05-26 11:13:24 theanets.trainer:168 RmsProp 1711 loss=0.031352 err=0.031352
I 2015-05-26 11:13:28 theanets.trainer:168 RmsProp 1712 loss=0.031807 err=0.031807
I 2015-05-26 11:13:32 theanets.trainer:168 RmsProp 1713 loss=0.026871 err=0.026871
I 2015-05-26 11:13:36 theanets.trainer:168 RmsProp 1714 loss=0.037810 err=0.037810
I 2015-05-26 11:13:40 theanets.trainer:168 RmsProp 1715 loss=0.034607 err=0.034607
I 2015-05-26 11:13:44 theanets.trainer:168 RmsProp 1716 loss=0.029009 err=0.029009
I 2015-05-26 11:13:48 theanets.trainer:168 RmsProp 1717 loss=0.031357 err=0.031357
I 2015-05-26 11:13:52 theanets.trainer:168 RmsProp 1718 loss=0.029523 err=0.029523
I 2015-05-26 11:13:56 theanets.trainer:168 RmsProp 1719 loss=0.032898 err=0.032898
I 2015-05-26 11:14:00 theanets.trainer:168 RmsProp 1720 loss=0.033166 err=0.033166
I 2015-05-26 11:14:00 theanets.trainer:168 validation 172 loss=676.228699 err=676.228699
I 2015-05-26 11:14:04 theanets.trainer:168 RmsProp 1721 loss=0.030467 err=0.030467
I 2015-05-26 11:14:08 theanets.trainer:168 RmsProp 1722 loss=0.031923 err=0.031923
I 2015-05-26 11:14:11 theanets.trainer:168 RmsProp 1723 loss=0.033695 err=0.033695
I 2015-05-26 11:14:14 theanets.trainer:168 RmsProp 1724 loss=0.032039 err=0.032039
I 2015-05-26 11:14:17 theanets.trainer:168 RmsProp 1725 loss=0.031340 err=0.031340
I 2015-05-26 11:14:20 theanets.trainer:168 RmsProp 1726 loss=0.027889 err=0.027889
I 2015-05-26 11:14:23 theanets.trainer:168 RmsProp 1727 loss=0.039120 err=0.039120
I 2015-05-26 11:14:26 theanets.trainer:168 RmsProp 1728 loss=0.026774 err=0.026774
I 2015-05-26 11:14:29 theanets.trainer:168 RmsProp 1729 loss=0.035889 err=0.035889
I 2015-05-26 11:14:32 theanets.trainer:168 RmsProp 1730 loss=0.024304 err=0.024304
I 2015-05-26 11:14:32 theanets.trainer:168 validation 173 loss=675.436462 err=675.436462 *
I 2015-05-26 11:14:35 theanets.trainer:168 RmsProp 1731 loss=0.041246 err=0.041246
I 2015-05-26 11:14:38 theanets.trainer:168 RmsProp 1732 loss=0.035083 err=0.035083
I 2015-05-26 11:14:41 theanets.trainer:168 RmsProp 1733 loss=0.026643 err=0.026643
I 2015-05-26 11:14:43 theanets.trainer:168 RmsProp 1734 loss=0.025180 err=0.025180
I 2015-05-26 11:14:46 theanets.trainer:168 RmsProp 1735 loss=0.039545 err=0.039545
I 2015-05-26 11:14:49 theanets.trainer:168 RmsProp 1736 loss=0.029279 err=0.029279
I 2015-05-26 11:14:52 theanets.trainer:168 RmsProp 1737 loss=0.025331 err=0.025331
I 2015-05-26 11:14:55 theanets.trainer:168 RmsProp 1738 loss=0.042122 err=0.042122
I 2015-05-26 11:14:58 theanets.trainer:168 RmsProp 1739 loss=0.028824 err=0.028824
I 2015-05-26 11:15:01 theanets.trainer:168 RmsProp 1740 loss=0.031083 err=0.031083
I 2015-05-26 11:15:01 theanets.trainer:168 validation 174 loss=675.837402 err=675.837402
I 2015-05-26 11:15:03 theanets.trainer:168 RmsProp 1741 loss=0.034690 err=0.034690
I 2015-05-26 11:15:06 theanets.trainer:168 RmsProp 1742 loss=0.026804 err=0.026804
I 2015-05-26 11:15:09 theanets.trainer:168 RmsProp 1743 loss=0.040084 err=0.040084
I 2015-05-26 11:15:11 theanets.trainer:168 RmsProp 1744 loss=0.033108 err=0.033108
I 2015-05-26 11:15:14 theanets.trainer:168 RmsProp 1745 loss=0.026968 err=0.026968
I 2015-05-26 11:15:16 theanets.trainer:168 RmsProp 1746 loss=0.033501 err=0.033501
I 2015-05-26 11:15:19 theanets.trainer:168 RmsProp 1747 loss=0.030704 err=0.030704
I 2015-05-26 11:15:21 theanets.trainer:168 RmsProp 1748 loss=0.027878 err=0.027878
I 2015-05-26 11:15:24 theanets.trainer:168 RmsProp 1749 loss=0.036368 err=0.036368
I 2015-05-26 11:15:26 theanets.trainer:168 RmsProp 1750 loss=0.023943 err=0.023943
I 2015-05-26 11:15:27 theanets.trainer:168 validation 175 loss=675.369019 err=675.369019 *
I 2015-05-26 11:15:29 theanets.trainer:168 RmsProp 1751 loss=0.046337 err=0.046337
I 2015-05-26 11:15:32 theanets.trainer:168 RmsProp 1752 loss=0.041922 err=0.041922
I 2015-05-26 11:15:34 theanets.trainer:168 RmsProp 1753 loss=0.028326 err=0.028326
I 2015-05-26 11:15:37 theanets.trainer:168 RmsProp 1754 loss=0.025231 err=0.025231
I 2015-05-26 11:15:39 theanets.trainer:168 RmsProp 1755 loss=0.036762 err=0.036762
I 2015-05-26 11:15:42 theanets.trainer:168 RmsProp 1756 loss=0.031940 err=0.031940
I 2015-05-26 11:15:44 theanets.trainer:168 RmsProp 1757 loss=0.031660 err=0.031660
I 2015-05-26 11:15:47 theanets.trainer:168 RmsProp 1758 loss=0.031233 err=0.031233
I 2015-05-26 11:15:49 theanets.trainer:168 RmsProp 1759 loss=0.036499 err=0.036499
I 2015-05-26 11:15:52 theanets.trainer:168 RmsProp 1760 loss=0.028215 err=0.028215
I 2015-05-26 11:15:52 theanets.trainer:168 validation 176 loss=674.447815 err=674.447815 *
I 2015-05-26 11:15:55 theanets.trainer:168 RmsProp 1761 loss=0.029529 err=0.029529
I 2015-05-26 11:15:57 theanets.trainer:168 RmsProp 1762 loss=0.031776 err=0.031776
I 2015-05-26 11:16:00 theanets.trainer:168 RmsProp 1763 loss=0.032094 err=0.032094
I 2015-05-26 11:16:02 theanets.trainer:168 RmsProp 1764 loss=0.028647 err=0.028647
I 2015-05-26 11:16:05 theanets.trainer:168 RmsProp 1765 loss=0.026733 err=0.026733
I 2015-05-26 11:16:07 theanets.trainer:168 RmsProp 1766 loss=0.042541 err=0.042541
I 2015-05-26 11:16:10 theanets.trainer:168 RmsProp 1767 loss=0.028054 err=0.028054
I 2015-05-26 11:16:13 theanets.trainer:168 RmsProp 1768 loss=0.025592 err=0.025592
I 2015-05-26 11:16:15 theanets.trainer:168 RmsProp 1769 loss=0.035605 err=0.035605
I 2015-05-26 11:16:18 theanets.trainer:168 RmsProp 1770 loss=0.028717 err=0.028717
I 2015-05-26 11:16:18 theanets.trainer:168 validation 177 loss=674.924500 err=674.924500
I 2015-05-26 11:16:20 theanets.trainer:168 RmsProp 1771 loss=0.037729 err=0.037729
I 2015-05-26 11:16:23 theanets.trainer:168 RmsProp 1772 loss=0.028284 err=0.028284
I 2015-05-26 11:16:25 theanets.trainer:168 RmsProp 1773 loss=0.024607 err=0.024607
I 2015-05-26 11:16:28 theanets.trainer:168 RmsProp 1774 loss=0.034490 err=0.034490
I 2015-05-26 11:16:31 theanets.trainer:168 RmsProp 1775 loss=0.025085 err=0.025085
I 2015-05-26 11:16:33 theanets.trainer:168 RmsProp 1776 loss=0.042056 err=0.042056
I 2015-05-26 11:16:36 theanets.trainer:168 RmsProp 1777 loss=0.026560 err=0.026560
I 2015-05-26 11:16:38 theanets.trainer:168 RmsProp 1778 loss=0.027025 err=0.027025
I 2015-05-26 11:16:41 theanets.trainer:168 RmsProp 1779 loss=0.030818 err=0.030818
I 2015-05-26 11:16:43 theanets.trainer:168 RmsProp 1780 loss=0.036759 err=0.036759
I 2015-05-26 11:16:43 theanets.trainer:168 validation 178 loss=674.831726 err=674.831726
I 2015-05-26 11:16:46 theanets.trainer:168 RmsProp 1781 loss=0.031024 err=0.031024
I 2015-05-26 11:16:49 theanets.trainer:168 RmsProp 1782 loss=0.028775 err=0.028775
I 2015-05-26 11:16:52 theanets.trainer:168 RmsProp 1783 loss=0.032258 err=0.032258
I 2015-05-26 11:16:55 theanets.trainer:168 RmsProp 1784 loss=0.030888 err=0.030888
I 2015-05-26 11:16:58 theanets.trainer:168 RmsProp 1785 loss=0.026007 err=0.026007
I 2015-05-26 11:17:01 theanets.trainer:168 RmsProp 1786 loss=0.038042 err=0.038042
I 2015-05-26 11:17:04 theanets.trainer:168 RmsProp 1787 loss=0.028894 err=0.028894
I 2015-05-26 11:17:07 theanets.trainer:168 RmsProp 1788 loss=0.031287 err=0.031287
I 2015-05-26 11:17:10 theanets.trainer:168 RmsProp 1789 loss=0.027555 err=0.027555
I 2015-05-26 11:17:13 theanets.trainer:168 RmsProp 1790 loss=0.032197 err=0.032197
I 2015-05-26 11:17:13 theanets.trainer:168 validation 179 loss=674.081238 err=674.081238 *
I 2015-05-26 11:17:16 theanets.trainer:168 RmsProp 1791 loss=0.029560 err=0.029560
I 2015-05-26 11:17:19 theanets.trainer:168 RmsProp 1792 loss=0.025073 err=0.025073
I 2015-05-26 11:17:22 theanets.trainer:168 RmsProp 1793 loss=0.038062 err=0.038062
I 2015-05-26 11:17:25 theanets.trainer:168 RmsProp 1794 loss=0.033679 err=0.033679
I 2015-05-26 11:17:28 theanets.trainer:168 RmsProp 1795 loss=0.026019 err=0.026019
I 2015-05-26 11:17:31 theanets.trainer:168 RmsProp 1796 loss=0.024097 err=0.024097
I 2015-05-26 11:17:34 theanets.trainer:168 RmsProp 1797 loss=0.044252 err=0.044252
I 2015-05-26 11:17:37 theanets.trainer:168 RmsProp 1798 loss=0.035725 err=0.035725
I 2015-05-26 11:17:40 theanets.trainer:168 RmsProp 1799 loss=0.028973 err=0.028973
I 2015-05-26 11:17:43 theanets.trainer:168 RmsProp 1800 loss=0.023708 err=0.023708
I 2015-05-26 11:17:43 theanets.trainer:168 validation 180 loss=673.267090 err=673.267090 *
I 2015-05-26 11:17:46 theanets.trainer:168 RmsProp 1801 loss=0.042182 err=0.042182
I 2015-05-26 11:17:49 theanets.trainer:168 RmsProp 1802 loss=0.032314 err=0.032314
I 2015-05-26 11:17:52 theanets.trainer:168 RmsProp 1803 loss=0.024154 err=0.024154
I 2015-05-26 11:17:55 theanets.trainer:168 RmsProp 1804 loss=0.038291 err=0.038291
I 2015-05-26 11:17:58 theanets.trainer:168 RmsProp 1805 loss=0.032861 err=0.032861
I 2015-05-26 11:18:01 theanets.trainer:168 RmsProp 1806 loss=0.025920 err=0.025920
I 2015-05-26 11:18:03 theanets.trainer:168 RmsProp 1807 loss=0.029785 err=0.029785
I 2015-05-26 11:18:06 theanets.trainer:168 RmsProp 1808 loss=0.035632 err=0.035632
I 2015-05-26 11:18:08 theanets.trainer:168 RmsProp 1809 loss=0.031180 err=0.031180
I 2015-05-26 11:18:10 theanets.trainer:168 RmsProp 1810 loss=0.030177 err=0.030177
I 2015-05-26 11:18:11 theanets.trainer:168 validation 181 loss=673.321716 err=673.321716
I 2015-05-26 11:18:13 theanets.trainer:168 RmsProp 1811 loss=0.029915 err=0.029915
I 2015-05-26 11:18:15 theanets.trainer:168 RmsProp 1812 loss=0.029988 err=0.029988
I 2015-05-26 11:18:18 theanets.trainer:168 RmsProp 1813 loss=0.031242 err=0.031242
I 2015-05-26 11:18:20 theanets.trainer:168 RmsProp 1814 loss=0.027279 err=0.027279
I 2015-05-26 11:18:23 theanets.trainer:168 RmsProp 1815 loss=0.034916 err=0.034916
I 2015-05-26 11:18:25 theanets.trainer:168 RmsProp 1816 loss=0.031912 err=0.031912
I 2015-05-26 11:18:27 theanets.trainer:168 RmsProp 1817 loss=0.026435 err=0.026435
I 2015-05-26 11:18:30 theanets.trainer:168 RmsProp 1818 loss=0.022374 err=0.022374
I 2015-05-26 11:18:32 theanets.trainer:168 RmsProp 1819 loss=0.044912 err=0.044912
I 2015-05-26 11:18:34 theanets.trainer:168 RmsProp 1820 loss=0.027680 err=0.027680
I 2015-05-26 11:18:35 theanets.trainer:168 validation 182 loss=672.845154 err=672.845154 *
I 2015-05-26 11:18:37 theanets.trainer:168 RmsProp 1821 loss=0.026798 err=0.026798
I 2015-05-26 11:18:39 theanets.trainer:168 RmsProp 1822 loss=0.028061 err=0.028061
I 2015-05-26 11:18:42 theanets.trainer:168 RmsProp 1823 loss=0.029377 err=0.029377
I 2015-05-26 11:18:44 theanets.trainer:168 RmsProp 1824 loss=0.027593 err=0.027593
I 2015-05-26 11:18:47 theanets.trainer:168 RmsProp 1825 loss=0.035357 err=0.035357
I 2015-05-26 11:18:49 theanets.trainer:168 RmsProp 1826 loss=0.030823 err=0.030823
I 2015-05-26 11:18:51 theanets.trainer:168 RmsProp 1827 loss=0.026256 err=0.026256
I 2015-05-26 11:18:54 theanets.trainer:168 RmsProp 1828 loss=0.033215 err=0.033215
I 2015-05-26 11:18:56 theanets.trainer:168 RmsProp 1829 loss=0.028471 err=0.028471
I 2015-05-26 11:18:58 theanets.trainer:168 RmsProp 1830 loss=0.028186 err=0.028186
I 2015-05-26 11:18:59 theanets.trainer:168 validation 183 loss=672.196289 err=672.196289 *
I 2015-05-26 11:19:01 theanets.trainer:168 RmsProp 1831 loss=0.034230 err=0.034230
I 2015-05-26 11:19:03 theanets.trainer:168 RmsProp 1832 loss=0.032835 err=0.032835
I 2015-05-26 11:19:06 theanets.trainer:168 RmsProp 1833 loss=0.027190 err=0.027190
I 2015-05-26 11:19:08 theanets.trainer:168 RmsProp 1834 loss=0.025055 err=0.025055
I 2015-05-26 11:19:11 theanets.trainer:168 RmsProp 1835 loss=0.025433 err=0.025433
I 2015-05-26 11:19:13 theanets.trainer:168 RmsProp 1836 loss=0.045064 err=0.045064
I 2015-05-26 11:19:15 theanets.trainer:168 RmsProp 1837 loss=0.035717 err=0.035717
I 2015-05-26 11:19:18 theanets.trainer:168 RmsProp 1838 loss=0.024948 err=0.024948
I 2015-05-26 11:19:20 theanets.trainer:168 RmsProp 1839 loss=0.029656 err=0.029656
I 2015-05-26 11:19:22 theanets.trainer:168 RmsProp 1840 loss=0.035648 err=0.035648
I 2015-05-26 11:19:23 theanets.trainer:168 validation 184 loss=672.508606 err=672.508606
I 2015-05-26 11:19:25 theanets.trainer:168 RmsProp 1841 loss=0.030750 err=0.030750
I 2015-05-26 11:19:27 theanets.trainer:168 RmsProp 1842 loss=0.030123 err=0.030123
I 2015-05-26 11:19:30 theanets.trainer:168 RmsProp 1843 loss=0.032786 err=0.032786
I 2015-05-26 11:19:32 theanets.trainer:168 RmsProp 1844 loss=0.028620 err=0.028620
I 2015-05-26 11:19:34 theanets.trainer:168 RmsProp 1845 loss=0.030296 err=0.030296
I 2015-05-26 11:19:37 theanets.trainer:168 RmsProp 1846 loss=0.032377 err=0.032377
I 2015-05-26 11:19:39 theanets.trainer:168 RmsProp 1847 loss=0.025205 err=0.025205
I 2015-05-26 11:19:42 theanets.trainer:168 RmsProp 1848 loss=0.030796 err=0.030796
I 2015-05-26 11:19:44 theanets.trainer:168 RmsProp 1849 loss=0.030151 err=0.030151
I 2015-05-26 11:19:46 theanets.trainer:168 RmsProp 1850 loss=0.024739 err=0.024739
I 2015-05-26 11:19:47 theanets.trainer:168 validation 185 loss=672.359497 err=672.359497
I 2015-05-26 11:19:49 theanets.trainer:168 RmsProp 1851 loss=0.044792 err=0.044792
I 2015-05-26 11:19:51 theanets.trainer:168 RmsProp 1852 loss=0.044106 err=0.044106
I 2015-05-26 11:19:54 theanets.trainer:168 RmsProp 1853 loss=0.028209 err=0.028209
I 2015-05-26 11:19:56 theanets.trainer:168 RmsProp 1854 loss=0.023105 err=0.023105
I 2015-05-26 11:19:58 theanets.trainer:168 RmsProp 1855 loss=0.032591 err=0.032591
I 2015-05-26 11:20:01 theanets.trainer:168 RmsProp 1856 loss=0.030895 err=0.030895
I 2015-05-26 11:20:03 theanets.trainer:168 RmsProp 1857 loss=0.025666 err=0.025666
I 2015-05-26 11:20:06 theanets.trainer:168 RmsProp 1858 loss=0.036503 err=0.036503
I 2015-05-26 11:20:08 theanets.trainer:168 RmsProp 1859 loss=0.032957 err=0.032957
I 2015-05-26 11:20:10 theanets.trainer:168 RmsProp 1860 loss=0.027351 err=0.027351
I 2015-05-26 11:20:11 theanets.trainer:168 validation 186 loss=671.958984 err=671.958984 *
I 2015-05-26 11:20:13 theanets.trainer:168 RmsProp 1861 loss=0.030662 err=0.030662
I 2015-05-26 11:20:15 theanets.trainer:168 RmsProp 1862 loss=0.028882 err=0.028882
I 2015-05-26 11:20:18 theanets.trainer:168 RmsProp 1863 loss=0.026077 err=0.026077
I 2015-05-26 11:20:20 theanets.trainer:168 RmsProp 1864 loss=0.028455 err=0.028455
I 2015-05-26 11:20:22 theanets.trainer:168 RmsProp 1865 loss=0.032348 err=0.032348
I 2015-05-26 11:20:25 theanets.trainer:168 RmsProp 1866 loss=0.028689 err=0.028689
I 2015-05-26 11:20:27 theanets.trainer:168 RmsProp 1867 loss=0.028282 err=0.028282
I 2015-05-26 11:20:30 theanets.trainer:168 RmsProp 1868 loss=0.030904 err=0.030904
I 2015-05-26 11:20:32 theanets.trainer:168 RmsProp 1869 loss=0.034335 err=0.034335
I 2015-05-26 11:20:34 theanets.trainer:168 RmsProp 1870 loss=0.023541 err=0.023541
I 2015-05-26 11:20:35 theanets.trainer:168 validation 187 loss=671.846375 err=671.846375 *
I 2015-05-26 11:20:37 theanets.trainer:168 RmsProp 1871 loss=0.024146 err=0.024146
I 2015-05-26 11:20:39 theanets.trainer:168 RmsProp 1872 loss=0.045155 err=0.045155
I 2015-05-26 11:20:42 theanets.trainer:168 RmsProp 1873 loss=0.029516 err=0.029516
I 2015-05-26 11:20:44 theanets.trainer:168 RmsProp 1874 loss=0.028886 err=0.028886
I 2015-05-26 11:20:46 theanets.trainer:168 RmsProp 1875 loss=0.027884 err=0.027884
I 2015-05-26 11:20:49 theanets.trainer:168 RmsProp 1876 loss=0.028088 err=0.028088
I 2015-05-26 11:20:51 theanets.trainer:168 RmsProp 1877 loss=0.027286 err=0.027286
I 2015-05-26 11:20:54 theanets.trainer:168 RmsProp 1878 loss=0.032826 err=0.032826
I 2015-05-26 11:20:56 theanets.trainer:168 RmsProp 1879 loss=0.031008 err=0.031008
I 2015-05-26 11:20:58 theanets.trainer:168 RmsProp 1880 loss=0.027096 err=0.027096
I 2015-05-26 11:20:59 theanets.trainer:168 validation 188 loss=671.795593 err=671.795593 *
I 2015-05-26 11:21:01 theanets.trainer:168 RmsProp 1881 loss=0.025580 err=0.025580
I 2015-05-26 11:21:03 theanets.trainer:168 RmsProp 1882 loss=0.033018 err=0.033018
I 2015-05-26 11:21:06 theanets.trainer:168 RmsProp 1883 loss=0.025832 err=0.025832
I 2015-05-26 11:21:08 theanets.trainer:168 RmsProp 1884 loss=0.036672 err=0.036672
I 2015-05-26 11:21:10 theanets.trainer:168 RmsProp 1885 loss=0.029838 err=0.029838
I 2015-05-26 11:21:13 theanets.trainer:168 RmsProp 1886 loss=0.028113 err=0.028113
I 2015-05-26 11:21:15 theanets.trainer:168 RmsProp 1887 loss=0.030279 err=0.030279
I 2015-05-26 11:21:18 theanets.trainer:168 RmsProp 1888 loss=0.032581 err=0.032581
I 2015-05-26 11:21:20 theanets.trainer:168 RmsProp 1889 loss=0.028146 err=0.028146
I 2015-05-26 11:21:22 theanets.trainer:168 RmsProp 1890 loss=0.029865 err=0.029865
I 2015-05-26 11:21:22 theanets.trainer:168 validation 189 loss=671.560059 err=671.560059 *
I 2015-05-26 11:21:25 theanets.trainer:168 RmsProp 1891 loss=0.027818 err=0.027818
I 2015-05-26 11:21:27 theanets.trainer:168 RmsProp 1892 loss=0.030510 err=0.030510
I 2015-05-26 11:21:30 theanets.trainer:168 RmsProp 1893 loss=0.028953 err=0.028953
I 2015-05-26 11:21:32 theanets.trainer:168 RmsProp 1894 loss=0.027317 err=0.027317
I 2015-05-26 11:21:34 theanets.trainer:168 RmsProp 1895 loss=0.030350 err=0.030350
I 2015-05-26 11:21:37 theanets.trainer:168 RmsProp 1896 loss=0.030974 err=0.030974
I 2015-05-26 11:21:39 theanets.trainer:168 RmsProp 1897 loss=0.027008 err=0.027008
I 2015-05-26 11:21:42 theanets.trainer:168 RmsProp 1898 loss=0.024800 err=0.024800
I 2015-05-26 11:21:44 theanets.trainer:168 RmsProp 1899 loss=0.036643 err=0.036643
I 2015-05-26 11:21:46 theanets.trainer:168 RmsProp 1900 loss=0.028336 err=0.028336
I 2015-05-26 11:21:46 theanets.trainer:168 validation 190 loss=670.947876 err=670.947876 *
I 2015-05-26 11:21:49 theanets.trainer:168 RmsProp 1901 loss=0.029460 err=0.029460
I 2015-05-26 11:21:51 theanets.trainer:168 RmsProp 1902 loss=0.026832 err=0.026832
I 2015-05-26 11:21:54 theanets.trainer:168 RmsProp 1903 loss=0.035866 err=0.035866
I 2015-05-26 11:21:56 theanets.trainer:168 RmsProp 1904 loss=0.028330 err=0.028330
I 2015-05-26 11:21:58 theanets.trainer:168 RmsProp 1905 loss=0.027105 err=0.027105
I 2015-05-26 11:22:01 theanets.trainer:168 RmsProp 1906 loss=0.031603 err=0.031603
I 2015-05-26 11:22:03 theanets.trainer:168 RmsProp 1907 loss=0.025658 err=0.025658
I 2015-05-26 11:22:05 theanets.trainer:168 RmsProp 1908 loss=0.029789 err=0.029789
I 2015-05-26 11:22:08 theanets.trainer:168 RmsProp 1909 loss=0.028045 err=0.028045
I 2015-05-26 11:22:10 theanets.trainer:168 RmsProp 1910 loss=0.027883 err=0.027883
I 2015-05-26 11:22:10 theanets.trainer:168 validation 191 loss=671.724548 err=671.724548
I 2015-05-26 11:22:13 theanets.trainer:168 RmsProp 1911 loss=0.027694 err=0.027694
I 2015-05-26 11:22:15 theanets.trainer:168 RmsProp 1912 loss=0.024342 err=0.024342
I 2015-05-26 11:22:18 theanets.trainer:168 RmsProp 1913 loss=0.044012 err=0.044012
I 2015-05-26 11:22:20 theanets.trainer:168 RmsProp 1914 loss=0.032134 err=0.032134
I 2015-05-26 11:22:22 theanets.trainer:168 RmsProp 1915 loss=0.022859 err=0.022859
I 2015-05-26 11:22:25 theanets.trainer:168 RmsProp 1916 loss=0.030985 err=0.030985
I 2015-05-26 11:22:27 theanets.trainer:168 RmsProp 1917 loss=0.027629 err=0.027629
I 2015-05-26 11:22:29 theanets.trainer:168 RmsProp 1918 loss=0.027920 err=0.027920
I 2015-05-26 11:22:32 theanets.trainer:168 RmsProp 1919 loss=0.027312 err=0.027312
I 2015-05-26 11:22:34 theanets.trainer:168 RmsProp 1920 loss=0.034412 err=0.034412
I 2015-05-26 11:22:34 theanets.trainer:168 validation 192 loss=670.591492 err=670.591492 *
I 2015-05-26 11:22:37 theanets.trainer:168 RmsProp 1921 loss=0.026585 err=0.026585
I 2015-05-26 11:22:39 theanets.trainer:168 RmsProp 1922 loss=0.022527 err=0.022527
I 2015-05-26 11:22:42 theanets.trainer:168 RmsProp 1923 loss=0.041645 err=0.041645
I 2015-05-26 11:22:44 theanets.trainer:168 RmsProp 1924 loss=0.028736 err=0.028736
I 2015-05-26 11:22:46 theanets.trainer:168 RmsProp 1925 loss=0.030821 err=0.030821
I 2015-05-26 11:22:49 theanets.trainer:168 RmsProp 1926 loss=0.041144 err=0.041144
I 2015-05-26 11:22:51 theanets.trainer:168 RmsProp 1927 loss=0.028688 err=0.028688
I 2015-05-26 11:22:53 theanets.trainer:168 RmsProp 1928 loss=0.024354 err=0.024354
I 2015-05-26 11:22:56 theanets.trainer:168 RmsProp 1929 loss=0.033919 err=0.033919
I 2015-05-26 11:22:58 theanets.trainer:168 RmsProp 1930 loss=0.031945 err=0.031945
I 2015-05-26 11:22:58 theanets.trainer:168 validation 193 loss=670.764282 err=670.764282
I 2015-05-26 11:23:01 theanets.trainer:168 RmsProp 1931 loss=0.034236 err=0.034236
I 2015-05-26 11:23:03 theanets.trainer:168 RmsProp 1932 loss=0.030020 err=0.030020
I 2015-05-26 11:23:05 theanets.trainer:168 RmsProp 1933 loss=0.029612 err=0.029612
I 2015-05-26 11:23:08 theanets.trainer:168 RmsProp 1934 loss=0.026389 err=0.026389
I 2015-05-26 11:23:10 theanets.trainer:168 RmsProp 1935 loss=0.029204 err=0.029204
I 2015-05-26 11:23:13 theanets.trainer:168 RmsProp 1936 loss=0.032383 err=0.032383
I 2015-05-26 11:23:15 theanets.trainer:168 RmsProp 1937 loss=0.022938 err=0.022938
I 2015-05-26 11:23:17 theanets.trainer:168 RmsProp 1938 loss=0.035245 err=0.035245
I 2015-05-26 11:23:20 theanets.trainer:168 RmsProp 1939 loss=0.030868 err=0.030868
I 2015-05-26 11:23:22 theanets.trainer:168 RmsProp 1940 loss=0.026408 err=0.026408
I 2015-05-26 11:23:22 theanets.trainer:168 validation 194 loss=669.699158 err=669.699158 *
I 2015-05-26 11:23:25 theanets.trainer:168 RmsProp 1941 loss=0.031347 err=0.031347
I 2015-05-26 11:23:27 theanets.trainer:168 RmsProp 1942 loss=0.024453 err=0.024453
I 2015-05-26 11:23:29 theanets.trainer:168 RmsProp 1943 loss=0.032239 err=0.032239
I 2015-05-26 11:23:32 theanets.trainer:168 RmsProp 1944 loss=0.034627 err=0.034627
I 2015-05-26 11:23:34 theanets.trainer:168 RmsProp 1945 loss=0.027198 err=0.027198
I 2015-05-26 11:23:37 theanets.trainer:168 RmsProp 1946 loss=0.027682 err=0.027682
I 2015-05-26 11:23:39 theanets.trainer:168 RmsProp 1947 loss=0.028306 err=0.028306
I 2015-05-26 11:23:41 theanets.trainer:168 RmsProp 1948 loss=0.030712 err=0.030712
I 2015-05-26 11:23:44 theanets.trainer:168 RmsProp 1949 loss=0.028052 err=0.028052
I 2015-05-26 11:23:46 theanets.trainer:168 RmsProp 1950 loss=0.030010 err=0.030010
I 2015-05-26 11:23:46 theanets.trainer:168 validation 195 loss=669.862671 err=669.862671
I 2015-05-26 11:23:49 theanets.trainer:168 RmsProp 1951 loss=0.034524 err=0.034524
I 2015-05-26 11:23:51 theanets.trainer:168 RmsProp 1952 loss=0.025898 err=0.025898
I 2015-05-26 11:23:53 theanets.trainer:168 RmsProp 1953 loss=0.028567 err=0.028567
I 2015-05-26 11:23:56 theanets.trainer:168 RmsProp 1954 loss=0.022686 err=0.022686
I 2015-05-26 11:23:58 theanets.trainer:168 RmsProp 1955 loss=0.047094 err=0.047094
I 2015-05-26 11:24:01 theanets.trainer:168 RmsProp 1956 loss=0.046228 err=0.046228
I 2015-05-26 11:24:03 theanets.trainer:168 RmsProp 1957 loss=0.033123 err=0.033123
I 2015-05-26 11:24:05 theanets.trainer:168 RmsProp 1958 loss=0.027669 err=0.027669
I 2015-05-26 11:24:08 theanets.trainer:168 RmsProp 1959 loss=0.023126 err=0.023126
I 2015-05-26 11:24:10 theanets.trainer:168 RmsProp 1960 loss=0.030561 err=0.030561
I 2015-05-26 11:24:10 theanets.trainer:168 validation 196 loss=669.589417 err=669.589417 *
I 2015-05-26 11:24:13 theanets.trainer:168 RmsProp 1961 loss=0.025291 err=0.025291
I 2015-05-26 11:24:15 theanets.trainer:168 RmsProp 1962 loss=0.029956 err=0.029956
I 2015-05-26 11:24:17 theanets.trainer:168 RmsProp 1963 loss=0.034862 err=0.034862
I 2015-05-26 11:24:20 theanets.trainer:168 RmsProp 1964 loss=0.026168 err=0.026168
I 2015-05-26 11:24:22 theanets.trainer:168 RmsProp 1965 loss=0.025171 err=0.025171
I 2015-05-26 11:24:25 theanets.trainer:168 RmsProp 1966 loss=0.030923 err=0.030923
I 2015-05-26 11:24:27 theanets.trainer:168 RmsProp 1967 loss=0.028892 err=0.028892
I 2015-05-26 11:24:29 theanets.trainer:168 RmsProp 1968 loss=0.036484 err=0.036484
I 2015-05-26 11:24:32 theanets.trainer:168 RmsProp 1969 loss=0.024910 err=0.024910
I 2015-05-26 11:24:34 theanets.trainer:168 RmsProp 1970 loss=0.028365 err=0.028365
I 2015-05-26 11:24:34 theanets.trainer:168 validation 197 loss=669.804138 err=669.804138
I 2015-05-26 11:24:37 theanets.trainer:168 RmsProp 1971 loss=0.027959 err=0.027959
I 2015-05-26 11:24:39 theanets.trainer:168 RmsProp 1972 loss=0.031628 err=0.031628
I 2015-05-26 11:24:41 theanets.trainer:168 RmsProp 1973 loss=0.029221 err=0.029221
I 2015-05-26 11:24:44 theanets.trainer:168 RmsProp 1974 loss=0.027310 err=0.027310
I 2015-05-26 11:24:46 theanets.trainer:168 RmsProp 1975 loss=0.037696 err=0.037696
I 2015-05-26 11:24:48 theanets.trainer:168 RmsProp 1976 loss=0.028690 err=0.028690
I 2015-05-26 11:24:51 theanets.trainer:168 RmsProp 1977 loss=0.024252 err=0.024252
I 2015-05-26 11:24:53 theanets.trainer:168 RmsProp 1978 loss=0.024834 err=0.024834
I 2015-05-26 11:24:56 theanets.trainer:168 RmsProp 1979 loss=0.034233 err=0.034233
I 2015-05-26 11:24:58 theanets.trainer:168 RmsProp 1980 loss=0.029904 err=0.029904
I 2015-05-26 11:24:58 theanets.trainer:168 validation 198 loss=668.602234 err=668.602234 *
I 2015-05-26 11:25:01 theanets.trainer:168 RmsProp 1981 loss=0.026393 err=0.026393
I 2015-05-26 11:25:03 theanets.trainer:168 RmsProp 1982 loss=0.027318 err=0.027318
I 2015-05-26 11:25:05 theanets.trainer:168 RmsProp 1983 loss=0.031661 err=0.031661
I 2015-05-26 11:25:08 theanets.trainer:168 RmsProp 1984 loss=0.026388 err=0.026388
I 2015-05-26 11:25:10 theanets.trainer:168 RmsProp 1985 loss=0.024039 err=0.024039
I 2015-05-26 11:25:12 theanets.trainer:168 RmsProp 1986 loss=0.043310 err=0.043310
I 2015-05-26 11:25:15 theanets.trainer:168 RmsProp 1987 loss=0.028698 err=0.028698
I 2015-05-26 11:25:17 theanets.trainer:168 RmsProp 1988 loss=0.024622 err=0.024622
I 2015-05-26 11:25:20 theanets.trainer:168 RmsProp 1989 loss=0.027985 err=0.027985
I 2015-05-26 11:25:22 theanets.trainer:168 RmsProp 1990 loss=0.026969 err=0.026969
I 2015-05-26 11:25:22 theanets.trainer:168 validation 199 loss=669.063965 err=669.063965
I 2015-05-26 11:25:25 theanets.trainer:168 RmsProp 1991 loss=0.039811 err=0.039811
I 2015-05-26 11:25:27 theanets.trainer:168 RmsProp 1992 loss=0.029575 err=0.029575
I 2015-05-26 11:25:29 theanets.trainer:168 RmsProp 1993 loss=0.020287 err=0.020287
I 2015-05-26 11:25:32 theanets.trainer:168 RmsProp 1994 loss=0.044217 err=0.044217
I 2015-05-26 11:25:34 theanets.trainer:168 RmsProp 1995 loss=0.036716 err=0.036716
I 2015-05-26 11:25:36 theanets.trainer:168 RmsProp 1996 loss=0.026670 err=0.026670
I 2015-05-26 11:25:39 theanets.trainer:168 RmsProp 1997 loss=0.024849 err=0.024849
I 2015-05-26 11:25:41 theanets.trainer:168 RmsProp 1998 loss=0.028936 err=0.028936
I 2015-05-26 11:25:44 theanets.trainer:168 RmsProp 1999 loss=0.031289 err=0.031289
I 2015-05-26 11:25:46 theanets.trainer:168 RmsProp 2000 loss=0.037460 err=0.037460
I 2015-05-26 11:25:46 theanets.trainer:168 validation 200 loss=668.314636 err=668.314636 *
I 2015-05-26 11:25:49 theanets.trainer:168 RmsProp 2001 loss=0.027915 err=0.027915
I 2015-05-26 11:25:51 theanets.trainer:168 RmsProp 2002 loss=0.027520 err=0.027520
I 2015-05-26 11:25:53 theanets.trainer:168 RmsProp 2003 loss=0.025944 err=0.025944
I 2015-05-26 11:25:56 theanets.trainer:168 RmsProp 2004 loss=0.028721 err=0.028721
I 2015-05-26 11:25:58 theanets.trainer:168 RmsProp 2005 loss=0.029112 err=0.029112
I 2015-05-26 11:26:00 theanets.trainer:168 RmsProp 2006 loss=0.024307 err=0.024307
I 2015-05-26 11:26:03 theanets.trainer:168 RmsProp 2007 loss=0.029500 err=0.029500
I 2015-05-26 11:26:05 theanets.trainer:168 RmsProp 2008 loss=0.023926 err=0.023926
I 2015-05-26 11:26:08 theanets.trainer:168 RmsProp 2009 loss=0.032520 err=0.032520
I 2015-05-26 11:26:10 theanets.trainer:168 RmsProp 2010 loss=0.024566 err=0.024566
I 2015-05-26 11:26:10 theanets.trainer:168 validation 201 loss=668.516418 err=668.516418
I 2015-05-26 11:26:13 theanets.trainer:168 RmsProp 2011 loss=0.034994 err=0.034994
I 2015-05-26 11:26:15 theanets.trainer:168 RmsProp 2012 loss=0.028141 err=0.028141
I 2015-05-26 11:26:17 theanets.trainer:168 RmsProp 2013 loss=0.024381 err=0.024381
I 2015-05-26 11:26:20 theanets.trainer:168 RmsProp 2014 loss=0.033714 err=0.033714
I 2015-05-26 11:26:22 theanets.trainer:168 RmsProp 2015 loss=0.032135 err=0.032135
I 2015-05-26 11:26:24 theanets.trainer:168 RmsProp 2016 loss=0.023365 err=0.023365
I 2015-05-26 11:26:27 theanets.trainer:168 RmsProp 2017 loss=0.025762 err=0.025762
I 2015-05-26 11:26:29 theanets.trainer:168 RmsProp 2018 loss=0.028386 err=0.028386
I 2015-05-26 11:26:32 theanets.trainer:168 RmsProp 2019 loss=0.025765 err=0.025765
I 2015-05-26 11:26:34 theanets.trainer:168 RmsProp 2020 loss=0.030649 err=0.030649
I 2015-05-26 11:26:34 theanets.trainer:168 validation 202 loss=670.501404 err=670.501404
I 2015-05-26 11:26:37 theanets.trainer:168 RmsProp 2021 loss=0.032154 err=0.032154
I 2015-05-26 11:26:39 theanets.trainer:168 RmsProp 2022 loss=0.025849 err=0.025849
I 2015-05-26 11:26:41 theanets.trainer:168 RmsProp 2023 loss=0.031795 err=0.031795
I 2015-05-26 11:26:44 theanets.trainer:168 RmsProp 2024 loss=0.030043 err=0.030043
I 2015-05-26 11:26:46 theanets.trainer:168 RmsProp 2025 loss=0.021368 err=0.021368
I 2015-05-26 11:26:48 theanets.trainer:168 RmsProp 2026 loss=0.030799 err=0.030799
I 2015-05-26 11:26:51 theanets.trainer:168 RmsProp 2027 loss=0.025057 err=0.025057
I 2015-05-26 11:26:53 theanets.trainer:168 RmsProp 2028 loss=0.028073 err=0.028073
I 2015-05-26 11:26:56 theanets.trainer:168 RmsProp 2029 loss=0.032149 err=0.032149
I 2015-05-26 11:26:58 theanets.trainer:168 RmsProp 2030 loss=0.026943 err=0.026943
I 2015-05-26 11:26:58 theanets.trainer:168 validation 203 loss=668.234985 err=668.234985 *
I 2015-05-26 11:27:00 theanets.trainer:168 RmsProp 2031 loss=0.027973 err=0.027973
I 2015-05-26 11:27:03 theanets.trainer:168 RmsProp 2032 loss=0.028942 err=0.028942
I 2015-05-26 11:27:05 theanets.trainer:168 RmsProp 2033 loss=0.026407 err=0.026407
I 2015-05-26 11:27:08 theanets.trainer:168 RmsProp 2034 loss=0.031550 err=0.031550
I 2015-05-26 11:27:10 theanets.trainer:168 RmsProp 2035 loss=0.031603 err=0.031603
I 2015-05-26 11:27:12 theanets.trainer:168 RmsProp 2036 loss=0.024658 err=0.024658
I 2015-05-26 11:27:15 theanets.trainer:168 RmsProp 2037 loss=0.033834 err=0.033834
I 2015-05-26 11:27:17 theanets.trainer:168 RmsProp 2038 loss=0.033471 err=0.033471
I 2015-05-26 11:27:19 theanets.trainer:168 RmsProp 2039 loss=0.022695 err=0.022695
I 2015-05-26 11:27:22 theanets.trainer:168 RmsProp 2040 loss=0.034335 err=0.034335
I 2015-05-26 11:27:22 theanets.trainer:168 validation 204 loss=668.633728 err=668.633728
I 2015-05-26 11:27:24 theanets.trainer:168 RmsProp 2041 loss=0.027296 err=0.027296
I 2015-05-26 11:27:27 theanets.trainer:168 RmsProp 2042 loss=0.029424 err=0.029424
I 2015-05-26 11:27:29 theanets.trainer:168 RmsProp 2043 loss=0.031202 err=0.031202
I 2015-05-26 11:27:32 theanets.trainer:168 RmsProp 2044 loss=0.025124 err=0.025124
I 2015-05-26 11:27:34 theanets.trainer:168 RmsProp 2045 loss=0.028870 err=0.028870
I 2015-05-26 11:27:36 theanets.trainer:168 RmsProp 2046 loss=0.024648 err=0.024648
I 2015-05-26 11:27:39 theanets.trainer:168 RmsProp 2047 loss=0.028602 err=0.028602
I 2015-05-26 11:27:41 theanets.trainer:168 RmsProp 2048 loss=0.022493 err=0.022493
I 2015-05-26 11:27:43 theanets.trainer:168 RmsProp 2049 loss=0.036385 err=0.036385
I 2015-05-26 11:27:46 theanets.trainer:168 RmsProp 2050 loss=0.035192 err=0.035192
I 2015-05-26 11:27:46 theanets.trainer:168 validation 205 loss=667.994568 err=667.994568 *
I 2015-05-26 11:27:48 theanets.trainer:168 RmsProp 2051 loss=0.024128 err=0.024128
I 2015-05-26 11:27:51 theanets.trainer:168 RmsProp 2052 loss=0.029872 err=0.029872
I 2015-05-26 11:27:53 theanets.trainer:168 RmsProp 2053 loss=0.029906 err=0.029906
I 2015-05-26 11:27:56 theanets.trainer:168 RmsProp 2054 loss=0.027444 err=0.027444
I 2015-05-26 11:27:58 theanets.trainer:168 RmsProp 2055 loss=0.023020 err=0.023020
I 2015-05-26 11:28:00 theanets.trainer:168 RmsProp 2056 loss=0.029798 err=0.029798
I 2015-05-26 11:28:03 theanets.trainer:168 RmsProp 2057 loss=0.031914 err=0.031914
I 2015-05-26 11:28:05 theanets.trainer:168 RmsProp 2058 loss=0.021951 err=0.021951
I 2015-05-26 11:28:07 theanets.trainer:168 RmsProp 2059 loss=0.033173 err=0.033173
I 2015-05-26 11:28:10 theanets.trainer:168 RmsProp 2060 loss=0.027537 err=0.027537
I 2015-05-26 11:28:10 theanets.trainer:168 validation 206 loss=668.479187 err=668.479187
I 2015-05-26 11:28:12 theanets.trainer:168 RmsProp 2061 loss=0.027025 err=0.027025
I 2015-05-26 11:28:15 theanets.trainer:168 RmsProp 2062 loss=0.026357 err=0.026357
I 2015-05-26 11:28:17 theanets.trainer:168 RmsProp 2063 loss=0.027203 err=0.027203
I 2015-05-26 11:28:20 theanets.trainer:168 RmsProp 2064 loss=0.030910 err=0.030910
I 2015-05-26 11:28:22 theanets.trainer:168 RmsProp 2065 loss=0.025629 err=0.025629
I 2015-05-26 11:28:24 theanets.trainer:168 RmsProp 2066 loss=0.026276 err=0.026276
I 2015-05-26 11:28:27 theanets.trainer:168 RmsProp 2067 loss=0.023640 err=0.023640
I 2015-05-26 11:28:29 theanets.trainer:168 RmsProp 2068 loss=0.039234 err=0.039234
I 2015-05-26 11:28:31 theanets.trainer:168 RmsProp 2069 loss=0.028465 err=0.028465
I 2015-05-26 11:28:34 theanets.trainer:168 RmsProp 2070 loss=0.026829 err=0.026829
I 2015-05-26 11:28:34 theanets.trainer:168 validation 207 loss=667.894226 err=667.894226 *
I 2015-05-26 11:28:36 theanets.trainer:168 RmsProp 2071 loss=0.025178 err=0.025178
I 2015-05-26 11:28:39 theanets.trainer:168 RmsProp 2072 loss=0.027985 err=0.027985
I 2015-05-26 11:28:41 theanets.trainer:168 RmsProp 2073 loss=0.034400 err=0.034400
I 2015-05-26 11:28:44 theanets.trainer:168 RmsProp 2074 loss=0.025110 err=0.025110
I 2015-05-26 11:28:46 theanets.trainer:168 RmsProp 2075 loss=0.028794 err=0.028794
I 2015-05-26 11:28:48 theanets.trainer:168 RmsProp 2076 loss=0.027072 err=0.027072
I 2015-05-26 11:28:51 theanets.trainer:168 RmsProp 2077 loss=0.026772 err=0.026772
I 2015-05-26 11:28:53 theanets.trainer:168 RmsProp 2078 loss=0.025913 err=0.025913
I 2015-05-26 11:28:55 theanets.trainer:168 RmsProp 2079 loss=0.031468 err=0.031468
I 2015-05-26 11:28:58 theanets.trainer:168 RmsProp 2080 loss=0.026466 err=0.026466
I 2015-05-26 11:28:58 theanets.trainer:168 validation 208 loss=667.916992 err=667.916992
I 2015-05-26 11:29:00 theanets.trainer:168 RmsProp 2081 loss=0.026904 err=0.026904
I 2015-05-26 11:29:03 theanets.trainer:168 RmsProp 2082 loss=0.025486 err=0.025486
I 2015-05-26 11:29:05 theanets.trainer:168 RmsProp 2083 loss=0.026858 err=0.026858
I 2015-05-26 11:29:08 theanets.trainer:168 RmsProp 2084 loss=0.038971 err=0.038971
I 2015-05-26 11:29:10 theanets.trainer:168 RmsProp 2085 loss=0.029787 err=0.029787
I 2015-05-26 11:29:12 theanets.trainer:168 RmsProp 2086 loss=0.022466 err=0.022466
I 2015-05-26 11:29:15 theanets.trainer:168 RmsProp 2087 loss=0.029754 err=0.029754
I 2015-05-26 11:29:17 theanets.trainer:168 RmsProp 2088 loss=0.026970 err=0.026970
I 2015-05-26 11:29:19 theanets.trainer:168 RmsProp 2089 loss=0.026317 err=0.026317
I 2015-05-26 11:29:22 theanets.trainer:168 RmsProp 2090 loss=0.023697 err=0.023697
I 2015-05-26 11:29:22 theanets.trainer:168 validation 209 loss=667.854797 err=667.854797 *
I 2015-05-26 11:29:24 theanets.trainer:168 RmsProp 2091 loss=0.035505 err=0.035505
I 2015-05-26 11:29:27 theanets.trainer:168 RmsProp 2092 loss=0.026384 err=0.026384
I 2015-05-26 11:29:29 theanets.trainer:168 RmsProp 2093 loss=0.023398 err=0.023398
I 2015-05-26 11:29:32 theanets.trainer:168 RmsProp 2094 loss=0.029813 err=0.029813
I 2015-05-26 11:29:34 theanets.trainer:168 RmsProp 2095 loss=0.026683 err=0.026683
I 2015-05-26 11:29:36 theanets.trainer:168 RmsProp 2096 loss=0.026474 err=0.026474
I 2015-05-26 11:29:39 theanets.trainer:168 RmsProp 2097 loss=0.027446 err=0.027446
I 2015-05-26 11:29:41 theanets.trainer:168 RmsProp 2098 loss=0.028213 err=0.028213
I 2015-05-26 11:29:43 theanets.trainer:168 RmsProp 2099 loss=0.029011 err=0.029011
I 2015-05-26 11:29:46 theanets.trainer:168 RmsProp 2100 loss=0.022388 err=0.022388
I 2015-05-26 11:29:46 theanets.trainer:168 validation 210 loss=667.390808 err=667.390808 *
I 2015-05-26 11:29:48 theanets.trainer:168 RmsProp 2101 loss=0.042128 err=0.042128
I 2015-05-26 11:29:51 theanets.trainer:168 RmsProp 2102 loss=0.025865 err=0.025865
I 2015-05-26 11:29:53 theanets.trainer:168 RmsProp 2103 loss=0.020032 err=0.020032
I 2015-05-26 11:29:56 theanets.trainer:168 RmsProp 2104 loss=0.043923 err=0.043923
I 2015-05-26 11:29:58 theanets.trainer:168 RmsProp 2105 loss=0.029430 err=0.029430
I 2015-05-26 11:30:00 theanets.trainer:168 RmsProp 2106 loss=0.023205 err=0.023205
I 2015-05-26 11:30:03 theanets.trainer:168 RmsProp 2107 loss=0.033002 err=0.033002
I 2015-05-26 11:30:05 theanets.trainer:168 RmsProp 2108 loss=0.030155 err=0.030155
I 2015-05-26 11:30:07 theanets.trainer:168 RmsProp 2109 loss=0.025247 err=0.025247
I 2015-05-26 11:30:10 theanets.trainer:168 RmsProp 2110 loss=0.025655 err=0.025655
I 2015-05-26 11:30:10 theanets.trainer:168 validation 211 loss=667.046875 err=667.046875 *
I 2015-05-26 11:30:12 theanets.trainer:168 RmsProp 2111 loss=0.030095 err=0.030095
I 2015-05-26 11:30:15 theanets.trainer:168 RmsProp 2112 loss=0.022607 err=0.022607
I 2015-05-26 11:30:17 theanets.trainer:168 RmsProp 2113 loss=0.034435 err=0.034435
I 2015-05-26 11:30:20 theanets.trainer:168 RmsProp 2114 loss=0.028336 err=0.028336
I 2015-05-26 11:30:22 theanets.trainer:168 RmsProp 2115 loss=0.025018 err=0.025018
I 2015-05-26 11:30:24 theanets.trainer:168 RmsProp 2116 loss=0.028037 err=0.028037
I 2015-05-26 11:30:27 theanets.trainer:168 RmsProp 2117 loss=0.032233 err=0.032233
I 2015-05-26 11:30:29 theanets.trainer:168 RmsProp 2118 loss=0.025061 err=0.025061
I 2015-05-26 11:30:31 theanets.trainer:168 RmsProp 2119 loss=0.027487 err=0.027487
I 2015-05-26 11:30:34 theanets.trainer:168 RmsProp 2120 loss=0.025567 err=0.025567
I 2015-05-26 11:30:34 theanets.trainer:168 validation 212 loss=667.096008 err=667.096008
I 2015-05-26 11:30:36 theanets.trainer:168 RmsProp 2121 loss=0.030186 err=0.030186
I 2015-05-26 11:30:39 theanets.trainer:168 RmsProp 2122 loss=0.034988 err=0.034988
I 2015-05-26 11:30:41 theanets.trainer:168 RmsProp 2123 loss=0.022818 err=0.022818
I 2015-05-26 11:30:44 theanets.trainer:168 RmsProp 2124 loss=0.030121 err=0.030121
I 2015-05-26 11:30:46 theanets.trainer:168 RmsProp 2125 loss=0.033355 err=0.033355
I 2015-05-26 11:30:48 theanets.trainer:168 RmsProp 2126 loss=0.026887 err=0.026887
I 2015-05-26 11:30:51 theanets.trainer:168 RmsProp 2127 loss=0.020707 err=0.020707
I 2015-05-26 11:30:53 theanets.trainer:168 RmsProp 2128 loss=0.030094 err=0.030094
I 2015-05-26 11:30:55 theanets.trainer:168 RmsProp 2129 loss=0.026347 err=0.026347
I 2015-05-26 11:30:58 theanets.trainer:168 RmsProp 2130 loss=0.025129 err=0.025129
I 2015-05-26 11:30:58 theanets.trainer:168 validation 213 loss=666.483215 err=666.483215 *
I 2015-05-26 11:31:00 theanets.trainer:168 RmsProp 2131 loss=0.024273 err=0.024273
I 2015-05-26 11:31:03 theanets.trainer:168 RmsProp 2132 loss=0.028012 err=0.028012
I 2015-05-26 11:31:05 theanets.trainer:168 RmsProp 2133 loss=0.030047 err=0.030047
I 2015-05-26 11:31:08 theanets.trainer:168 RmsProp 2134 loss=0.028694 err=0.028694
I 2015-05-26 11:31:10 theanets.trainer:168 RmsProp 2135 loss=0.020969 err=0.020969
I 2015-05-26 11:31:12 theanets.trainer:168 RmsProp 2136 loss=0.043947 err=0.043947
I 2015-05-26 11:31:15 theanets.trainer:168 RmsProp 2137 loss=0.040466 err=0.040466
I 2015-05-26 11:31:17 theanets.trainer:168 RmsProp 2138 loss=0.023873 err=0.023873
I 2015-05-26 11:31:19 theanets.trainer:168 RmsProp 2139 loss=0.020667 err=0.020667
I 2015-05-26 11:31:22 theanets.trainer:168 RmsProp 2140 loss=0.029115 err=0.029115
I 2015-05-26 11:31:22 theanets.trainer:168 validation 214 loss=665.907898 err=665.907898 *
I 2015-05-26 11:31:24 theanets.trainer:168 RmsProp 2141 loss=0.026421 err=0.026421
I 2015-05-26 11:31:27 theanets.trainer:168 RmsProp 2142 loss=0.028500 err=0.028500
I 2015-05-26 11:31:29 theanets.trainer:168 RmsProp 2143 loss=0.025598 err=0.025598
I 2015-05-26 11:31:32 theanets.trainer:168 RmsProp 2144 loss=0.025444 err=0.025444
I 2015-05-26 11:31:34 theanets.trainer:168 RmsProp 2145 loss=0.025200 err=0.025200
I 2015-05-26 11:31:36 theanets.trainer:168 RmsProp 2146 loss=0.037958 err=0.037958
I 2015-05-26 11:31:39 theanets.trainer:168 RmsProp 2147 loss=0.023946 err=0.023946
I 2015-05-26 11:31:41 theanets.trainer:168 RmsProp 2148 loss=0.025205 err=0.025205
I 2015-05-26 11:31:43 theanets.trainer:168 RmsProp 2149 loss=0.027446 err=0.027446
I 2015-05-26 11:31:46 theanets.trainer:168 RmsProp 2150 loss=0.028253 err=0.028253
I 2015-05-26 11:31:46 theanets.trainer:168 validation 215 loss=665.755249 err=665.755249 *
I 2015-05-26 11:31:48 theanets.trainer:168 RmsProp 2151 loss=0.030312 err=0.030312
I 2015-05-26 11:31:51 theanets.trainer:168 RmsProp 2152 loss=0.024226 err=0.024226
I 2015-05-26 11:31:53 theanets.trainer:168 RmsProp 2153 loss=0.028333 err=0.028333
I 2015-05-26 11:31:56 theanets.trainer:168 RmsProp 2154 loss=0.026837 err=0.026837
I 2015-05-26 11:31:58 theanets.trainer:168 RmsProp 2155 loss=0.029885 err=0.029885
I 2015-05-26 11:32:00 theanets.trainer:168 RmsProp 2156 loss=0.025540 err=0.025540
I 2015-05-26 11:32:03 theanets.trainer:168 RmsProp 2157 loss=0.022938 err=0.022938
I 2015-05-26 11:32:05 theanets.trainer:168 RmsProp 2158 loss=0.027691 err=0.027691
I 2015-05-26 11:32:07 theanets.trainer:168 RmsProp 2159 loss=0.024257 err=0.024257
I 2015-05-26 11:32:10 theanets.trainer:168 RmsProp 2160 loss=0.032389 err=0.032389
I 2015-05-26 11:32:10 theanets.trainer:168 validation 216 loss=665.309570 err=665.309570 *
I 2015-05-26 11:32:12 theanets.trainer:168 RmsProp 2161 loss=0.027639 err=0.027639
I 2015-05-26 11:32:15 theanets.trainer:168 RmsProp 2162 loss=0.030440 err=0.030440
I 2015-05-26 11:32:17 theanets.trainer:168 RmsProp 2163 loss=0.027369 err=0.027369
I 2015-05-26 11:32:20 theanets.trainer:168 RmsProp 2164 loss=0.024337 err=0.024337
I 2015-05-26 11:32:22 theanets.trainer:168 RmsProp 2165 loss=0.030053 err=0.030053
I 2015-05-26 11:32:24 theanets.trainer:168 RmsProp 2166 loss=0.022551 err=0.022551
I 2015-05-26 11:32:27 theanets.trainer:168 RmsProp 2167 loss=0.027724 err=0.027724
I 2015-05-26 11:32:29 theanets.trainer:168 RmsProp 2168 loss=0.026994 err=0.026994
I 2015-05-26 11:32:31 theanets.trainer:168 RmsProp 2169 loss=0.026586 err=0.026586
I 2015-05-26 11:32:34 theanets.trainer:168 RmsProp 2170 loss=0.026004 err=0.026004
I 2015-05-26 11:32:34 theanets.trainer:168 validation 217 loss=664.624695 err=664.624695 *
I 2015-05-26 11:32:36 theanets.trainer:168 RmsProp 2171 loss=0.025789 err=0.025789
I 2015-05-26 11:32:39 theanets.trainer:168 RmsProp 2172 loss=0.024485 err=0.024485
I 2015-05-26 11:32:41 theanets.trainer:168 RmsProp 2173 loss=0.028708 err=0.028708
I 2015-05-26 11:32:43 theanets.trainer:168 RmsProp 2174 loss=0.024870 err=0.024870
I 2015-05-26 11:32:46 theanets.trainer:168 RmsProp 2175 loss=0.023458 err=0.023458
I 2015-05-26 11:32:48 theanets.trainer:168 RmsProp 2176 loss=0.026513 err=0.026513
I 2015-05-26 11:32:51 theanets.trainer:168 RmsProp 2177 loss=0.029098 err=0.029098
I 2015-05-26 11:32:53 theanets.trainer:168 RmsProp 2178 loss=0.025068 err=0.025068
I 2015-05-26 11:32:55 theanets.trainer:168 RmsProp 2179 loss=0.030488 err=0.030488
I 2015-05-26 11:32:58 theanets.trainer:168 RmsProp 2180 loss=0.028628 err=0.028628
I 2015-05-26 11:32:58 theanets.trainer:168 validation 218 loss=664.123535 err=664.123535 *
I 2015-05-26 11:33:00 theanets.trainer:168 RmsProp 2181 loss=0.024651 err=0.024651
I 2015-05-26 11:33:03 theanets.trainer:168 RmsProp 2182 loss=0.032804 err=0.032804
I 2015-05-26 11:33:05 theanets.trainer:168 RmsProp 2183 loss=0.027967 err=0.027967
I 2015-05-26 11:33:07 theanets.trainer:168 RmsProp 2184 loss=0.023918 err=0.023918
I 2015-05-26 11:33:10 theanets.trainer:168 RmsProp 2185 loss=0.023254 err=0.023254
I 2015-05-26 11:33:12 theanets.trainer:168 RmsProp 2186 loss=0.025681 err=0.025681
I 2015-05-26 11:33:15 theanets.trainer:168 RmsProp 2187 loss=0.030340 err=0.030340
I 2015-05-26 11:33:17 theanets.trainer:168 RmsProp 2188 loss=0.024946 err=0.024946
I 2015-05-26 11:33:19 theanets.trainer:168 RmsProp 2189 loss=0.024685 err=0.024685
I 2015-05-26 11:33:22 theanets.trainer:168 RmsProp 2190 loss=0.031882 err=0.031882
I 2015-05-26 11:33:22 theanets.trainer:168 validation 219 loss=663.737732 err=663.737732 *
I 2015-05-26 11:33:24 theanets.trainer:168 RmsProp 2191 loss=0.025814 err=0.025814
I 2015-05-26 11:33:27 theanets.trainer:168 RmsProp 2192 loss=0.027586 err=0.027586
I 2015-05-26 11:33:29 theanets.trainer:168 RmsProp 2193 loss=0.025416 err=0.025416
I 2015-05-26 11:33:31 theanets.trainer:168 RmsProp 2194 loss=0.026450 err=0.026450
I 2015-05-26 11:33:34 theanets.trainer:168 RmsProp 2195 loss=0.028064 err=0.028064
I 2015-05-26 11:33:36 theanets.trainer:168 RmsProp 2196 loss=0.025609 err=0.025609
I 2015-05-26 11:33:39 theanets.trainer:168 RmsProp 2197 loss=0.026306 err=0.026306
I 2015-05-26 11:33:41 theanets.trainer:168 RmsProp 2198 loss=0.024851 err=0.024851
I 2015-05-26 11:33:43 theanets.trainer:168 RmsProp 2199 loss=0.028192 err=0.028192
I 2015-05-26 11:33:46 theanets.trainer:168 RmsProp 2200 loss=0.023608 err=0.023608
I 2015-05-26 11:33:46 theanets.trainer:168 validation 220 loss=664.259033 err=664.259033
I 2015-05-26 11:33:48 theanets.trainer:168 RmsProp 2201 loss=0.025548 err=0.025548
I 2015-05-26 11:33:51 theanets.trainer:168 RmsProp 2202 loss=0.021857 err=0.021857
I 2015-05-26 11:33:53 theanets.trainer:168 RmsProp 2203 loss=0.039917 err=0.039917
I 2015-05-26 11:33:55 theanets.trainer:168 RmsProp 2204 loss=0.039046 err=0.039046
I 2015-05-26 11:33:58 theanets.trainer:168 RmsProp 2205 loss=0.026813 err=0.026813
I 2015-05-26 11:34:00 theanets.trainer:168 RmsProp 2206 loss=0.022723 err=0.022723
I 2015-05-26 11:34:03 theanets.trainer:168 RmsProp 2207 loss=0.026305 err=0.026305
I 2015-05-26 11:34:05 theanets.trainer:168 RmsProp 2208 loss=0.026990 err=0.026990
I 2015-05-26 11:34:07 theanets.trainer:168 RmsProp 2209 loss=0.022860 err=0.022860
I 2015-05-26 11:34:10 theanets.trainer:168 RmsProp 2210 loss=0.032180 err=0.032180
I 2015-05-26 11:34:10 theanets.trainer:168 validation 221 loss=663.991394 err=663.991394
I 2015-05-26 11:34:12 theanets.trainer:168 RmsProp 2211 loss=0.026578 err=0.026578
I 2015-05-26 11:34:15 theanets.trainer:168 RmsProp 2212 loss=0.024450 err=0.024450
I 2015-05-26 11:34:17 theanets.trainer:168 RmsProp 2213 loss=0.025774 err=0.025774
I 2015-05-26 11:34:19 theanets.trainer:168 RmsProp 2214 loss=0.030479 err=0.030479
I 2015-05-26 11:34:22 theanets.trainer:168 RmsProp 2215 loss=0.023297 err=0.023297
I 2015-05-26 11:34:24 theanets.trainer:168 RmsProp 2216 loss=0.026291 err=0.026291
I 2015-05-26 11:34:26 theanets.trainer:168 RmsProp 2217 loss=0.029798 err=0.029798
I 2015-05-26 11:34:29 theanets.trainer:168 RmsProp 2218 loss=0.023114 err=0.023114
I 2015-05-26 11:34:31 theanets.trainer:168 RmsProp 2219 loss=0.023252 err=0.023252
I 2015-05-26 11:34:34 theanets.trainer:168 RmsProp 2220 loss=0.024716 err=0.024716
I 2015-05-26 11:34:34 theanets.trainer:168 validation 222 loss=663.637695 err=663.637695 *
I 2015-05-26 11:34:36 theanets.trainer:168 RmsProp 2221 loss=0.028929 err=0.028929
I 2015-05-26 11:34:39 theanets.trainer:168 RmsProp 2222 loss=0.033349 err=0.033349
I 2015-05-26 11:34:41 theanets.trainer:168 RmsProp 2223 loss=0.024865 err=0.024865
I 2015-05-26 11:34:43 theanets.trainer:168 RmsProp 2224 loss=0.024051 err=0.024051
I 2015-05-26 11:34:46 theanets.trainer:168 RmsProp 2225 loss=0.024684 err=0.024684
I 2015-05-26 11:34:48 theanets.trainer:168 RmsProp 2226 loss=0.030665 err=0.030665
I 2015-05-26 11:34:50 theanets.trainer:168 RmsProp 2227 loss=0.024554 err=0.024554
I 2015-05-26 11:34:53 theanets.trainer:168 RmsProp 2228 loss=0.024359 err=0.024359
I 2015-05-26 11:34:55 theanets.trainer:168 RmsProp 2229 loss=0.025454 err=0.025454
I 2015-05-26 11:34:58 theanets.trainer:168 RmsProp 2230 loss=0.027707 err=0.027707
I 2015-05-26 11:34:58 theanets.trainer:168 validation 223 loss=664.062927 err=664.062927
I 2015-05-26 11:35:00 theanets.trainer:168 RmsProp 2231 loss=0.027214 err=0.027214
I 2015-05-26 11:35:03 theanets.trainer:168 RmsProp 2232 loss=0.027863 err=0.027863
I 2015-05-26 11:35:05 theanets.trainer:168 RmsProp 2233 loss=0.023785 err=0.023785
I 2015-05-26 11:35:07 theanets.trainer:168 RmsProp 2234 loss=0.026475 err=0.026475
I 2015-05-26 11:35:10 theanets.trainer:168 RmsProp 2235 loss=0.024803 err=0.024803
I 2015-05-26 11:35:12 theanets.trainer:168 RmsProp 2236 loss=0.025565 err=0.025565
I 2015-05-26 11:35:14 theanets.trainer:168 RmsProp 2237 loss=0.027104 err=0.027104
I 2015-05-26 11:35:17 theanets.trainer:168 RmsProp 2238 loss=0.025519 err=0.025519
I 2015-05-26 11:35:19 theanets.trainer:168 RmsProp 2239 loss=0.033280 err=0.033280
I 2015-05-26 11:35:22 theanets.trainer:168 RmsProp 2240 loss=0.027295 err=0.027295
I 2015-05-26 11:35:22 theanets.trainer:168 validation 224 loss=663.056152 err=663.056152 *
I 2015-05-26 11:35:24 theanets.trainer:168 RmsProp 2241 loss=0.024596 err=0.024596
I 2015-05-26 11:35:27 theanets.trainer:168 RmsProp 2242 loss=0.026954 err=0.026954
I 2015-05-26 11:35:29 theanets.trainer:168 RmsProp 2243 loss=0.020819 err=0.020819
I 2015-05-26 11:35:31 theanets.trainer:168 RmsProp 2244 loss=0.033735 err=0.033735
I 2015-05-26 11:35:34 theanets.trainer:168 RmsProp 2245 loss=0.026010 err=0.026010
I 2015-05-26 11:35:36 theanets.trainer:168 RmsProp 2246 loss=0.023822 err=0.023822
I 2015-05-26 11:35:38 theanets.trainer:168 RmsProp 2247 loss=0.023280 err=0.023280
I 2015-05-26 11:35:41 theanets.trainer:168 RmsProp 2248 loss=0.026203 err=0.026203
I 2015-05-26 11:35:43 theanets.trainer:168 RmsProp 2249 loss=0.027756 err=0.027756
I 2015-05-26 11:35:46 theanets.trainer:168 RmsProp 2250 loss=0.023932 err=0.023932
I 2015-05-26 11:35:46 theanets.trainer:168 validation 225 loss=662.732727 err=662.732727 *
I 2015-05-26 11:35:48 theanets.trainer:168 RmsProp 2251 loss=0.029741 err=0.029741
I 2015-05-26 11:35:51 theanets.trainer:168 RmsProp 2252 loss=0.021085 err=0.021085
I 2015-05-26 11:35:53 theanets.trainer:168 RmsProp 2253 loss=0.030094 err=0.030094
I 2015-05-26 11:35:55 theanets.trainer:168 RmsProp 2254 loss=0.023849 err=0.023849
I 2015-05-26 11:35:58 theanets.trainer:168 RmsProp 2255 loss=0.025541 err=0.025541
I 2015-05-26 11:36:00 theanets.trainer:168 RmsProp 2256 loss=0.024524 err=0.024524
I 2015-05-26 11:36:02 theanets.trainer:168 RmsProp 2257 loss=0.025480 err=0.025480
I 2015-05-26 11:36:05 theanets.trainer:168 RmsProp 2258 loss=0.030311 err=0.030311
I 2015-05-26 11:36:07 theanets.trainer:168 RmsProp 2259 loss=0.024372 err=0.024372
I 2015-05-26 11:36:10 theanets.trainer:168 RmsProp 2260 loss=0.021337 err=0.021337
I 2015-05-26 11:36:10 theanets.trainer:168 validation 226 loss=662.298523 err=662.298523 *
I 2015-05-26 11:36:12 theanets.trainer:168 RmsProp 2261 loss=0.030874 err=0.030874
I 2015-05-26 11:36:14 theanets.trainer:168 RmsProp 2262 loss=0.023819 err=0.023819
I 2015-05-26 11:36:17 theanets.trainer:168 RmsProp 2263 loss=0.024547 err=0.024547
I 2015-05-26 11:36:19 theanets.trainer:168 RmsProp 2264 loss=0.027070 err=0.027070
I 2015-05-26 11:36:22 theanets.trainer:168 RmsProp 2265 loss=0.023701 err=0.023701
I 2015-05-26 11:36:24 theanets.trainer:168 RmsProp 2266 loss=0.029353 err=0.029353
I 2015-05-26 11:36:26 theanets.trainer:168 RmsProp 2267 loss=0.029991 err=0.029991
I 2015-05-26 11:36:29 theanets.trainer:168 RmsProp 2268 loss=0.020082 err=0.020082
I 2015-05-26 11:36:31 theanets.trainer:168 RmsProp 2269 loss=0.034599 err=0.034599
I 2015-05-26 11:36:34 theanets.trainer:168 RmsProp 2270 loss=0.023444 err=0.023444
I 2015-05-26 11:36:34 theanets.trainer:168 validation 227 loss=662.073059 err=662.073059 *
I 2015-05-26 11:36:36 theanets.trainer:168 RmsProp 2271 loss=0.019636 err=0.019636
I 2015-05-26 11:36:38 theanets.trainer:168 RmsProp 2272 loss=0.046864 err=0.046864
I 2015-05-26 11:36:41 theanets.trainer:168 RmsProp 2273 loss=0.030289 err=0.030289
I 2015-05-26 11:36:43 theanets.trainer:168 RmsProp 2274 loss=0.022841 err=0.022841
I 2015-05-26 11:36:46 theanets.trainer:168 RmsProp 2275 loss=0.025096 err=0.025096
I 2015-05-26 11:36:48 theanets.trainer:168 RmsProp 2276 loss=0.023973 err=0.023973
I 2015-05-26 11:36:50 theanets.trainer:168 RmsProp 2277 loss=0.025170 err=0.025170
I 2015-05-26 11:36:53 theanets.trainer:168 RmsProp 2278 loss=0.022936 err=0.022936
I 2015-05-26 11:36:55 theanets.trainer:168 RmsProp 2279 loss=0.025602 err=0.025602
I 2015-05-26 11:36:57 theanets.trainer:168 RmsProp 2280 loss=0.026534 err=0.026534
I 2015-05-26 11:36:58 theanets.trainer:168 validation 228 loss=662.571106 err=662.571106
I 2015-05-26 11:37:00 theanets.trainer:168 RmsProp 2281 loss=0.027995 err=0.027995
I 2015-05-26 11:37:02 theanets.trainer:168 RmsProp 2282 loss=0.022032 err=0.022032
I 2015-05-26 11:37:05 theanets.trainer:168 RmsProp 2283 loss=0.026709 err=0.026709
I 2015-05-26 11:37:07 theanets.trainer:168 RmsProp 2284 loss=0.026151 err=0.026151
I 2015-05-26 11:37:10 theanets.trainer:168 RmsProp 2285 loss=0.025175 err=0.025175
I 2015-05-26 11:37:12 theanets.trainer:168 RmsProp 2286 loss=0.024803 err=0.024803
I 2015-05-26 11:37:14 theanets.trainer:168 RmsProp 2287 loss=0.024663 err=0.024663
I 2015-05-26 11:37:17 theanets.trainer:168 RmsProp 2288 loss=0.027310 err=0.027310
I 2015-05-26 11:37:19 theanets.trainer:168 RmsProp 2289 loss=0.026232 err=0.026232
I 2015-05-26 11:37:21 theanets.trainer:168 RmsProp 2290 loss=0.022424 err=0.022424
I 2015-05-26 11:37:22 theanets.trainer:168 validation 229 loss=662.238586 err=662.238586
I 2015-05-26 11:37:24 theanets.trainer:168 RmsProp 2291 loss=0.031026 err=0.031026
I 2015-05-26 11:37:26 theanets.trainer:168 RmsProp 2292 loss=0.030807 err=0.030807
I 2015-05-26 11:37:29 theanets.trainer:168 RmsProp 2293 loss=0.024767 err=0.024767
I 2015-05-26 11:37:31 theanets.trainer:168 RmsProp 2294 loss=0.024873 err=0.024873
I 2015-05-26 11:37:34 theanets.trainer:168 RmsProp 2295 loss=0.032803 err=0.032803
I 2015-05-26 11:37:36 theanets.trainer:168 RmsProp 2296 loss=0.023031 err=0.023031
I 2015-05-26 11:37:38 theanets.trainer:168 RmsProp 2297 loss=0.025112 err=0.025112
I 2015-05-26 11:37:41 theanets.trainer:168 RmsProp 2298 loss=0.027657 err=0.027657
I 2015-05-26 11:37:43 theanets.trainer:168 RmsProp 2299 loss=0.022660 err=0.022660
I 2015-05-26 11:37:45 theanets.trainer:168 RmsProp 2300 loss=0.028564 err=0.028564
I 2015-05-26 11:37:46 theanets.trainer:168 validation 230 loss=663.333923 err=663.333923
I 2015-05-26 11:37:48 theanets.trainer:168 RmsProp 2301 loss=0.032530 err=0.032530
I 2015-05-26 11:37:50 theanets.trainer:168 RmsProp 2302 loss=0.020433 err=0.020433
I 2015-05-26 11:37:53 theanets.trainer:168 RmsProp 2303 loss=0.023408 err=0.023408
I 2015-05-26 11:37:55 theanets.trainer:168 RmsProp 2304 loss=0.021728 err=0.021728
I 2015-05-26 11:37:58 theanets.trainer:168 RmsProp 2305 loss=0.028207 err=0.028207
I 2015-05-26 11:38:00 theanets.trainer:168 RmsProp 2306 loss=0.022137 err=0.022137
I 2015-05-26 11:38:02 theanets.trainer:168 RmsProp 2307 loss=0.025313 err=0.025313
I 2015-05-26 11:38:05 theanets.trainer:168 RmsProp 2308 loss=0.026051 err=0.026051
I 2015-05-26 11:38:07 theanets.trainer:168 RmsProp 2309 loss=0.025807 err=0.025807
I 2015-05-26 11:38:09 theanets.trainer:168 RmsProp 2310 loss=0.027348 err=0.027348
I 2015-05-26 11:38:10 theanets.trainer:168 validation 231 loss=662.817993 err=662.817993
I 2015-05-26 11:38:12 theanets.trainer:168 RmsProp 2311 loss=0.022669 err=0.022669
I 2015-05-26 11:38:14 theanets.trainer:168 RmsProp 2312 loss=0.034071 err=0.034071
I 2015-05-26 11:38:17 theanets.trainer:168 RmsProp 2313 loss=0.027358 err=0.027358
I 2015-05-26 11:38:19 theanets.trainer:168 RmsProp 2314 loss=0.024019 err=0.024019
I 2015-05-26 11:38:22 theanets.trainer:168 RmsProp 2315 loss=0.031767 err=0.031767
I 2015-05-26 11:38:24 theanets.trainer:168 RmsProp 2316 loss=0.026637 err=0.026637
I 2015-05-26 11:38:26 theanets.trainer:168 RmsProp 2317 loss=0.025200 err=0.025200
I 2015-05-26 11:38:29 theanets.trainer:168 RmsProp 2318 loss=0.021345 err=0.021345
I 2015-05-26 11:38:31 theanets.trainer:168 RmsProp 2319 loss=0.024498 err=0.024498
I 2015-05-26 11:38:33 theanets.trainer:168 RmsProp 2320 loss=0.027148 err=0.027148
I 2015-05-26 11:38:34 theanets.trainer:168 validation 232 loss=662.385864 err=662.385864
I 2015-05-26 11:38:34 theanets.trainer:252 patience elapsed!
I 2015-05-26 11:38:34 theanets.main:237 models_deep_post_code_sep/95116-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saving model
I 2015-05-26 11:38:34 theanets.graph:477 models_deep_post_code_sep/95116-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saved model parameters
