I 2015-05-26 22:05:11 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:11 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95111-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:11 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:11 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:11 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:11 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:11 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:11 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:11 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:11 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:11 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:11 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:11 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:11 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:24 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:05 theanets.trainer:168 validation 0 loss=14400.327148 err=14158.081055 *
I 2015-05-26 22:08:15 theanets.trainer:168 RmsProp 1 loss=13293.765625 err=13200.875000
I 2015-05-26 22:08:48 theanets.trainer:168 RmsProp 2 loss=13125.365234 err=13095.763672
I 2015-05-26 22:09:26 theanets.trainer:168 RmsProp 3 loss=12512.388672 err=12461.762695
I 2015-05-26 22:10:04 theanets.trainer:168 RmsProp 4 loss=10993.251953 err=10908.139648
I 2015-05-26 22:10:41 theanets.trainer:168 RmsProp 5 loss=10153.854492 err=10046.500977
I 2015-05-26 22:11:20 theanets.trainer:168 RmsProp 6 loss=9419.768555 err=9293.879883
I 2015-05-26 22:11:58 theanets.trainer:168 RmsProp 7 loss=8749.364258 err=8605.320312
I 2015-05-26 22:12:36 theanets.trainer:168 RmsProp 8 loss=8287.377930 err=8122.609375
I 2015-05-26 22:13:14 theanets.trainer:168 RmsProp 9 loss=7977.725586 err=7794.925293
I 2015-05-26 22:13:52 theanets.trainer:168 RmsProp 10 loss=7673.986816 err=7473.825195
I 2015-05-26 22:13:53 theanets.trainer:168 validation 1 loss=7131.972168 err=6921.063965 *
I 2015-05-26 22:14:32 theanets.trainer:168 RmsProp 11 loss=7517.550293 err=7297.202637
I 2015-05-26 22:15:10 theanets.trainer:168 RmsProp 12 loss=7270.722168 err=7030.603027
I 2015-05-26 22:15:49 theanets.trainer:168 RmsProp 13 loss=7035.653809 err=6787.950684
I 2015-05-26 22:16:28 theanets.trainer:168 RmsProp 14 loss=6764.343262 err=6506.270020
I 2015-05-26 22:17:06 theanets.trainer:168 RmsProp 15 loss=6560.414062 err=6291.070801
I 2015-05-26 22:17:45 theanets.trainer:168 RmsProp 16 loss=6497.212402 err=6212.729492
I 2015-05-26 22:18:24 theanets.trainer:168 RmsProp 17 loss=6292.445312 err=5986.357910
I 2015-05-26 22:19:02 theanets.trainer:168 RmsProp 18 loss=6322.351074 err=5997.181152
I 2015-05-26 22:19:40 theanets.trainer:168 RmsProp 19 loss=6019.340332 err=5682.365234
I 2015-05-26 22:20:18 theanets.trainer:168 RmsProp 20 loss=5833.575684 err=5484.936523
I 2015-05-26 22:20:19 theanets.trainer:168 validation 2 loss=5688.437988 err=5332.563477 *
I 2015-05-26 22:20:57 theanets.trainer:168 RmsProp 21 loss=5808.293457 err=5448.402832
I 2015-05-26 22:21:35 theanets.trainer:168 RmsProp 22 loss=5799.028320 err=5423.356934
I 2015-05-26 22:22:14 theanets.trainer:168 RmsProp 23 loss=5866.834473 err=5468.251465
I 2015-05-26 22:22:53 theanets.trainer:168 RmsProp 24 loss=5415.617188 err=5002.737305
I 2015-05-26 22:23:31 theanets.trainer:168 RmsProp 25 loss=5131.393555 err=4720.437988
I 2015-05-26 22:24:09 theanets.trainer:168 RmsProp 26 loss=4923.328613 err=4513.406738
I 2015-05-26 22:24:48 theanets.trainer:168 RmsProp 27 loss=4961.168457 err=4546.002441
I 2015-05-26 22:25:26 theanets.trainer:168 RmsProp 28 loss=4822.110352 err=4397.085449
I 2015-05-26 22:26:04 theanets.trainer:168 RmsProp 29 loss=4581.475098 err=4152.895508
I 2015-05-26 22:26:43 theanets.trainer:168 RmsProp 30 loss=4522.339355 err=4087.891602
I 2015-05-26 22:26:44 theanets.trainer:168 validation 3 loss=4611.261230 err=4168.948730 *
I 2015-05-26 22:27:22 theanets.trainer:168 RmsProp 31 loss=4441.907715 err=3992.938477
I 2015-05-26 22:28:00 theanets.trainer:168 RmsProp 32 loss=4314.720215 err=3859.087402
I 2015-05-26 22:28:40 theanets.trainer:168 RmsProp 33 loss=4154.430176 err=3694.956299
I 2015-05-26 22:29:18 theanets.trainer:168 RmsProp 34 loss=4080.975586 err=3613.043945
I 2015-05-26 22:29:57 theanets.trainer:168 RmsProp 35 loss=3969.234375 err=3492.847412
I 2015-05-26 22:30:35 theanets.trainer:168 RmsProp 36 loss=3908.436768 err=3422.208740
I 2015-05-26 22:31:14 theanets.trainer:168 RmsProp 37 loss=3784.264404 err=3291.480225
I 2015-05-26 22:31:53 theanets.trainer:168 RmsProp 38 loss=3745.175781 err=3243.150879
I 2015-05-26 22:32:32 theanets.trainer:168 RmsProp 39 loss=3633.739014 err=3121.576416
I 2015-05-26 22:33:10 theanets.trainer:168 RmsProp 40 loss=3554.007812 err=3035.006836
I 2015-05-26 22:33:10 theanets.trainer:168 validation 4 loss=4156.097656 err=3633.107178 *
I 2015-05-26 22:33:49 theanets.trainer:168 RmsProp 41 loss=3490.957520 err=2964.288818
I 2015-05-26 22:34:26 theanets.trainer:168 RmsProp 42 loss=3556.265869 err=3016.577881
I 2015-05-26 22:35:06 theanets.trainer:168 RmsProp 43 loss=3493.529785 err=2934.139404
I 2015-05-26 22:35:44 theanets.trainer:168 RmsProp 44 loss=3316.956055 err=2751.644043
I 2015-05-26 22:36:22 theanets.trainer:168 RmsProp 45 loss=3190.972412 err=2622.338623
I 2015-05-26 22:37:00 theanets.trainer:168 RmsProp 46 loss=3048.941162 err=2480.156250
I 2015-05-26 22:37:38 theanets.trainer:168 RmsProp 47 loss=2991.871826 err=2422.025879
I 2015-05-26 22:38:15 theanets.trainer:168 RmsProp 48 loss=2882.687256 err=2309.761230
I 2015-05-26 22:38:53 theanets.trainer:168 RmsProp 49 loss=2832.360352 err=2254.319336
I 2015-05-26 22:39:32 theanets.trainer:168 RmsProp 50 loss=2707.192627 err=2125.580566
I 2015-05-26 22:39:32 theanets.trainer:168 validation 5 loss=3697.077393 err=3113.857178 *
I 2015-05-26 22:40:10 theanets.trainer:168 RmsProp 51 loss=2660.112061 err=2076.268555
I 2015-05-26 22:40:47 theanets.trainer:168 RmsProp 52 loss=2594.492920 err=2007.488892
I 2015-05-26 22:41:25 theanets.trainer:168 RmsProp 53 loss=2502.974365 err=1913.562744
I 2015-05-26 22:42:04 theanets.trainer:168 RmsProp 54 loss=2482.432861 err=1889.499878
I 2015-05-26 22:42:42 theanets.trainer:168 RmsProp 55 loss=2443.272705 err=1845.519165
I 2015-05-26 22:43:20 theanets.trainer:168 RmsProp 56 loss=2373.819336 err=1772.199585
I 2015-05-26 22:43:59 theanets.trainer:168 RmsProp 57 loss=2341.724121 err=1735.853760
I 2015-05-26 22:44:38 theanets.trainer:168 RmsProp 58 loss=2301.667236 err=1691.474731
I 2015-05-26 22:45:18 theanets.trainer:168 RmsProp 59 loss=2283.644775 err=1669.555054
I 2015-05-26 22:45:56 theanets.trainer:168 RmsProp 60 loss=2215.811279 err=1597.821533
I 2015-05-26 22:45:57 theanets.trainer:168 validation 6 loss=3456.578125 err=2837.478271 *
I 2015-05-26 22:46:34 theanets.trainer:168 RmsProp 61 loss=2211.489258 err=1590.780640
I 2015-05-26 22:47:12 theanets.trainer:168 RmsProp 62 loss=2141.862549 err=1517.965210
I 2015-05-26 22:47:50 theanets.trainer:168 RmsProp 63 loss=2066.929932 err=1442.723022
I 2015-05-26 22:48:28 theanets.trainer:168 RmsProp 64 loss=2105.233398 err=1478.812744
I 2015-05-26 22:49:05 theanets.trainer:168 RmsProp 65 loss=2078.547119 err=1446.824097
I 2015-05-26 22:49:43 theanets.trainer:168 RmsProp 66 loss=1977.969971 err=1345.770752
I 2015-05-26 22:50:21 theanets.trainer:168 RmsProp 67 loss=1933.884644 err=1302.640015
I 2015-05-26 22:51:00 theanets.trainer:168 RmsProp 68 loss=1892.700928 err=1261.614990
I 2015-05-26 22:51:39 theanets.trainer:168 RmsProp 69 loss=1892.946777 err=1259.870972
I 2015-05-26 22:52:17 theanets.trainer:168 RmsProp 70 loss=1857.800171 err=1223.090210
I 2015-05-26 22:52:18 theanets.trainer:168 validation 7 loss=3235.877197 err=2600.706787 *
I 2015-05-26 22:52:55 theanets.trainer:168 RmsProp 71 loss=1823.393066 err=1187.837158
I 2015-05-26 22:53:34 theanets.trainer:168 RmsProp 72 loss=1778.771362 err=1142.453247
I 2015-05-26 22:54:14 theanets.trainer:168 RmsProp 73 loss=1755.587524 err=1119.669922
I 2015-05-26 22:54:53 theanets.trainer:168 RmsProp 74 loss=1737.916016 err=1102.752808
I 2015-05-26 22:55:31 theanets.trainer:168 RmsProp 75 loss=1705.574219 err=1071.068848
I 2015-05-26 22:56:10 theanets.trainer:168 RmsProp 76 loss=1693.984131 err=1059.028076
I 2015-05-26 22:56:49 theanets.trainer:168 RmsProp 77 loss=1670.777466 err=1035.669922
I 2015-05-26 22:57:28 theanets.trainer:168 RmsProp 78 loss=1653.139771 err=1018.782043
I 2015-05-26 22:58:08 theanets.trainer:168 RmsProp 79 loss=1651.187988 err=1016.012146
I 2015-05-26 22:58:47 theanets.trainer:168 RmsProp 80 loss=1631.993896 err=995.968018
I 2015-05-26 22:58:48 theanets.trainer:168 validation 8 loss=3145.228516 err=2508.226074 *
I 2015-05-26 22:59:27 theanets.trainer:168 RmsProp 81 loss=1637.177368 err=1000.278320
I 2015-05-26 23:00:04 theanets.trainer:168 RmsProp 82 loss=1629.526245 err=991.786987
I 2015-05-26 23:00:41 theanets.trainer:168 RmsProp 83 loss=1609.305054 err=971.177368
I 2015-05-26 23:01:20 theanets.trainer:168 RmsProp 84 loss=1595.934326 err=956.826904
I 2015-05-26 23:01:58 theanets.trainer:168 RmsProp 85 loss=1558.328125 err=920.811829
I 2015-05-26 23:02:37 theanets.trainer:168 RmsProp 86 loss=1573.581177 err=936.127747
I 2015-05-26 23:03:16 theanets.trainer:168 RmsProp 87 loss=1540.546143 err=902.114624
I 2015-05-26 23:03:54 theanets.trainer:168 RmsProp 88 loss=1515.587769 err=878.100952
I 2015-05-26 23:04:33 theanets.trainer:168 RmsProp 89 loss=1503.464233 err=867.182007
I 2015-05-26 23:05:11 theanets.trainer:168 RmsProp 90 loss=1500.915405 err=864.701599
I 2015-05-26 23:05:11 theanets.trainer:168 validation 9 loss=2874.816650 err=2239.055664 *
I 2015-05-26 23:05:49 theanets.trainer:168 RmsProp 91 loss=1464.409912 err=829.375366
I 2015-05-26 23:06:25 theanets.trainer:168 RmsProp 92 loss=1457.467285 err=824.474365
I 2015-05-26 23:07:03 theanets.trainer:168 RmsProp 93 loss=1451.412964 err=819.012451
I 2015-05-26 23:07:42 theanets.trainer:168 RmsProp 94 loss=1466.726440 err=834.477905
I 2015-05-26 23:08:21 theanets.trainer:168 RmsProp 95 loss=1436.462646 err=804.161560
I 2015-05-26 23:09:01 theanets.trainer:168 RmsProp 96 loss=1414.556152 err=783.881958
I 2015-05-26 23:09:39 theanets.trainer:168 RmsProp 97 loss=1412.039917 err=782.000305
I 2015-05-26 23:10:18 theanets.trainer:168 RmsProp 98 loss=1398.996216 err=769.499634
I 2015-05-26 23:10:55 theanets.trainer:168 RmsProp 99 loss=1389.046143 err=760.543945
I 2015-05-26 23:11:33 theanets.trainer:168 RmsProp 100 loss=1391.592163 err=762.375122
I 2015-05-26 23:11:34 theanets.trainer:168 validation 10 loss=2852.876953 err=2223.428467 *
I 2015-05-26 23:12:12 theanets.trainer:168 RmsProp 101 loss=1371.040283 err=742.583862
I 2015-05-26 23:12:50 theanets.trainer:168 RmsProp 102 loss=1378.090454 err=750.850952
I 2015-05-26 23:13:28 theanets.trainer:168 RmsProp 103 loss=1343.745972 err=717.569458
I 2015-05-26 23:14:07 theanets.trainer:168 RmsProp 104 loss=1333.187134 err=709.651062
I 2015-05-26 23:14:46 theanets.trainer:168 RmsProp 105 loss=1345.210938 err=722.047729
I 2015-05-26 23:15:24 theanets.trainer:168 RmsProp 106 loss=1340.586060 err=716.837891
I 2015-05-26 23:16:03 theanets.trainer:168 RmsProp 107 loss=1325.362793 err=703.078125
I 2015-05-26 23:16:42 theanets.trainer:168 RmsProp 108 loss=1322.700439 err=700.477356
I 2015-05-26 23:17:20 theanets.trainer:168 RmsProp 109 loss=1311.499146 err=689.481689
I 2015-05-26 23:17:57 theanets.trainer:168 RmsProp 110 loss=1303.991943 err=682.781616
I 2015-05-26 23:17:58 theanets.trainer:168 validation 11 loss=2624.081299 err=2003.669800 *
I 2015-05-26 23:18:36 theanets.trainer:168 RmsProp 111 loss=1289.787476 err=669.912537
I 2015-05-26 23:19:13 theanets.trainer:168 RmsProp 112 loss=1274.808350 err=655.882141
I 2015-05-26 23:19:50 theanets.trainer:168 RmsProp 113 loss=1278.348022 err=659.745422
I 2015-05-26 23:20:27 theanets.trainer:168 RmsProp 114 loss=1283.772339 err=664.978699
I 2015-05-26 23:21:05 theanets.trainer:168 RmsProp 115 loss=1248.038940 err=631.190674
I 2015-05-26 23:21:43 theanets.trainer:168 RmsProp 116 loss=1254.616455 err=639.557373
I 2015-05-26 23:22:21 theanets.trainer:168 RmsProp 117 loss=1250.293213 err=636.064209
I 2015-05-26 23:22:59 theanets.trainer:168 RmsProp 118 loss=1253.719849 err=639.280823
I 2015-05-26 23:23:37 theanets.trainer:168 RmsProp 119 loss=1239.034424 err=626.330994
I 2015-05-26 23:24:15 theanets.trainer:168 RmsProp 120 loss=1251.818481 err=638.543579
I 2015-05-26 23:24:16 theanets.trainer:168 validation 12 loss=2598.022705 err=1984.978882 *
I 2015-05-26 23:24:54 theanets.trainer:168 RmsProp 121 loss=1222.252563 err=610.337646
I 2015-05-26 23:25:31 theanets.trainer:168 RmsProp 122 loss=1205.357666 err=594.578674
I 2015-05-26 23:26:08 theanets.trainer:168 RmsProp 123 loss=1228.009888 err=617.309692
I 2015-05-26 23:26:46 theanets.trainer:168 RmsProp 124 loss=1209.982788 err=598.593506
I 2015-05-26 23:27:24 theanets.trainer:168 RmsProp 125 loss=1201.393433 err=591.878296
I 2015-05-26 23:28:02 theanets.trainer:168 RmsProp 126 loss=1197.071045 err=588.422302
I 2015-05-26 23:28:40 theanets.trainer:168 RmsProp 127 loss=1248.192261 err=638.315796
I 2015-05-26 23:29:18 theanets.trainer:168 RmsProp 128 loss=1220.081787 err=608.605896
I 2015-05-26 23:29:57 theanets.trainer:168 RmsProp 129 loss=1181.490234 err=572.591125
I 2015-05-26 23:30:35 theanets.trainer:168 RmsProp 130 loss=1188.154419 err=580.365295
I 2015-05-26 23:30:36 theanets.trainer:168 validation 13 loss=2594.121826 err=1984.488281 *
I 2015-05-26 23:31:13 theanets.trainer:168 RmsProp 131 loss=1191.047119 err=581.527954
I 2015-05-26 23:31:50 theanets.trainer:168 RmsProp 132 loss=1185.282715 err=576.323792
I 2015-05-26 23:32:27 theanets.trainer:168 RmsProp 133 loss=1177.903931 err=569.186340
I 2015-05-26 23:33:03 theanets.trainer:168 RmsProp 134 loss=1159.848999 err=552.796265
I 2015-05-26 23:33:40 theanets.trainer:168 RmsProp 135 loss=1155.438232 err=549.631836
I 2015-05-26 23:34:18 theanets.trainer:168 RmsProp 136 loss=1137.974365 err=533.877319
I 2015-05-26 23:34:56 theanets.trainer:168 RmsProp 137 loss=1134.035400 err=531.939575
I 2015-05-26 23:35:34 theanets.trainer:168 RmsProp 138 loss=1138.404785 err=536.143616
I 2015-05-26 23:36:11 theanets.trainer:168 RmsProp 139 loss=1110.077026 err=509.814758
I 2015-05-26 23:36:48 theanets.trainer:168 RmsProp 140 loss=1118.165405 err=519.254272
I 2015-05-26 23:36:49 theanets.trainer:168 validation 14 loss=2364.113525 err=1765.158569 *
I 2015-05-26 23:37:27 theanets.trainer:168 RmsProp 141 loss=1123.208618 err=524.220032
I 2015-05-26 23:38:05 theanets.trainer:168 RmsProp 142 loss=1128.209473 err=529.594299
I 2015-05-26 23:38:44 theanets.trainer:168 RmsProp 143 loss=1110.802246 err=511.995056
I 2015-05-26 23:39:21 theanets.trainer:168 RmsProp 144 loss=1105.333862 err=508.085999
I 2015-05-26 23:39:59 theanets.trainer:168 RmsProp 145 loss=1112.646362 err=515.971863
I 2015-05-26 23:40:37 theanets.trainer:168 RmsProp 146 loss=1117.601807 err=521.404968
I 2015-05-26 23:41:16 theanets.trainer:168 RmsProp 147 loss=1111.762573 err=514.803406
I 2015-05-26 23:41:55 theanets.trainer:168 RmsProp 148 loss=1125.158691 err=527.923767
I 2015-05-26 23:42:34 theanets.trainer:168 RmsProp 149 loss=1132.864136 err=532.620667
I 2015-05-26 23:43:13 theanets.trainer:168 RmsProp 150 loss=1115.596924 err=515.952087
I 2015-05-26 23:43:14 theanets.trainer:168 validation 15 loss=2317.328369 err=1718.400391 *
I 2015-05-26 23:43:52 theanets.trainer:168 RmsProp 151 loss=1087.740723 err=490.341003
I 2015-05-26 23:44:29 theanets.trainer:168 RmsProp 152 loss=1073.570312 err=478.953705
I 2015-05-26 23:45:07 theanets.trainer:168 RmsProp 153 loss=1096.402100 err=501.247131
I 2015-05-26 23:45:45 theanets.trainer:168 RmsProp 154 loss=1100.567139 err=505.226471
I 2015-05-26 23:46:23 theanets.trainer:168 RmsProp 155 loss=1085.936646 err=490.956177
I 2015-05-26 23:47:00 theanets.trainer:168 RmsProp 156 loss=1077.447021 err=484.331940
I 2015-05-26 23:47:37 theanets.trainer:168 RmsProp 157 loss=1067.843262 err=475.237732
I 2015-05-26 23:48:13 theanets.trainer:168 RmsProp 158 loss=1056.258545 err=466.002533
I 2015-05-26 23:48:50 theanets.trainer:168 RmsProp 159 loss=1068.813110 err=478.332214
I 2015-05-26 23:49:28 theanets.trainer:168 RmsProp 160 loss=1079.250244 err=488.584045
I 2015-05-26 23:49:29 theanets.trainer:168 validation 16 loss=2234.488770 err=1642.687134 *
I 2015-05-26 23:50:06 theanets.trainer:168 RmsProp 161 loss=1085.223755 err=492.777039
I 2015-05-26 23:50:42 theanets.trainer:168 RmsProp 162 loss=1064.546509 err=472.794708
I 2015-05-26 23:51:17 theanets.trainer:168 RmsProp 163 loss=1060.532837 err=469.464844
I 2015-05-26 23:51:51 theanets.trainer:168 RmsProp 164 loss=1056.567261 err=465.745636
I 2015-05-26 23:52:26 theanets.trainer:168 RmsProp 165 loss=1092.688110 err=498.324402
I 2015-05-26 23:53:03 theanets.trainer:168 RmsProp 166 loss=1053.157715 err=460.079620
I 2015-05-26 23:53:40 theanets.trainer:168 RmsProp 167 loss=1044.890015 err=454.043060
I 2015-05-26 23:54:17 theanets.trainer:168 RmsProp 168 loss=1038.940430 err=448.535645
I 2015-05-26 23:54:55 theanets.trainer:168 RmsProp 169 loss=1027.638672 err=439.237946
I 2015-05-26 23:55:33 theanets.trainer:168 RmsProp 170 loss=1026.113403 err=438.729492
I 2015-05-26 23:55:34 theanets.trainer:168 validation 17 loss=2289.329834 err=1702.335815
I 2015-05-26 23:56:11 theanets.trainer:168 RmsProp 171 loss=1018.935608 err=432.717285
I 2015-05-26 23:56:48 theanets.trainer:168 RmsProp 172 loss=1020.611877 err=435.087524
I 2015-05-26 23:57:24 theanets.trainer:168 RmsProp 173 loss=1018.098694 err=433.116852
I 2015-05-26 23:57:59 theanets.trainer:168 RmsProp 174 loss=1011.339294 err=426.489136
I 2015-05-26 23:58:35 theanets.trainer:168 RmsProp 175 loss=1002.582825 err=419.348236
I 2015-05-26 23:59:12 theanets.trainer:168 RmsProp 176 loss=1016.417297 err=432.181274
I 2015-05-26 23:59:50 theanets.trainer:168 RmsProp 177 loss=1003.608276 err=419.442078
I 2015-05-27 00:00:28 theanets.trainer:168 RmsProp 178 loss=996.417542 err=413.705688
I 2015-05-27 00:01:05 theanets.trainer:168 RmsProp 179 loss=999.524658 err=417.440491
I 2015-05-27 00:01:43 theanets.trainer:168 RmsProp 180 loss=986.455627 err=405.520050
I 2015-05-27 00:01:44 theanets.trainer:168 validation 18 loss=2107.483643 err=1527.294922 *
I 2015-05-27 00:02:21 theanets.trainer:168 RmsProp 181 loss=998.040100 err=417.943848
I 2015-05-27 00:02:58 theanets.trainer:168 RmsProp 182 loss=990.478149 err=410.750488
I 2015-05-27 00:03:35 theanets.trainer:168 RmsProp 183 loss=981.777161 err=403.363220
I 2015-05-27 00:04:12 theanets.trainer:168 RmsProp 184 loss=974.571167 err=397.094757
I 2015-05-27 00:04:49 theanets.trainer:168 RmsProp 185 loss=977.299561 err=400.929108
I 2015-05-27 00:05:26 theanets.trainer:168 RmsProp 186 loss=979.394653 err=402.802856
I 2015-05-27 00:06:03 theanets.trainer:168 RmsProp 187 loss=959.196106 err=384.747467
I 2015-05-27 00:06:40 theanets.trainer:168 RmsProp 188 loss=968.849854 err=394.522583
I 2015-05-27 00:07:17 theanets.trainer:168 RmsProp 189 loss=956.740051 err=383.674835
I 2015-05-27 00:07:54 theanets.trainer:168 RmsProp 190 loss=945.044312 err=374.324982
I 2015-05-27 00:07:55 theanets.trainer:168 validation 19 loss=2066.213379 err=1496.620117 *
I 2015-05-27 00:08:31 theanets.trainer:168 RmsProp 191 loss=942.414246 err=373.933197
I 2015-05-27 00:09:08 theanets.trainer:168 RmsProp 192 loss=933.808533 err=366.425232
I 2015-05-27 00:09:44 theanets.trainer:168 RmsProp 193 loss=935.951782 err=369.576935
I 2015-05-27 00:10:20 theanets.trainer:168 RmsProp 194 loss=949.834534 err=382.934845
I 2015-05-27 00:10:57 theanets.trainer:168 RmsProp 195 loss=944.861267 err=378.178711
I 2015-05-27 00:11:34 theanets.trainer:168 RmsProp 196 loss=944.261658 err=378.106720
I 2015-05-27 00:12:08 theanets.trainer:168 RmsProp 197 loss=932.041138 err=366.943970
I 2015-05-27 00:12:42 theanets.trainer:168 RmsProp 198 loss=943.652588 err=379.466797
I 2015-05-27 00:13:16 theanets.trainer:168 RmsProp 199 loss=939.528870 err=375.353821
I 2015-05-27 00:13:50 theanets.trainer:168 RmsProp 200 loss=932.695374 err=368.986359
I 2015-05-27 00:13:51 theanets.trainer:168 validation 20 loss=2042.672241 err=1479.593140 *
I 2015-05-27 00:14:24 theanets.trainer:168 RmsProp 201 loss=929.806091 err=367.367676
I 2015-05-27 00:14:56 theanets.trainer:168 RmsProp 202 loss=911.079773 err=350.433075
I 2015-05-27 00:15:28 theanets.trainer:168 RmsProp 203 loss=914.926819 err=356.060394
I 2015-05-27 00:16:00 theanets.trainer:168 RmsProp 204 loss=908.091736 err=350.140778
I 2015-05-27 00:16:33 theanets.trainer:168 RmsProp 205 loss=912.052307 err=355.045319
I 2015-05-27 00:17:06 theanets.trainer:168 RmsProp 206 loss=898.467407 err=342.563324
I 2015-05-27 00:17:40 theanets.trainer:168 RmsProp 207 loss=904.288391 err=349.946350
I 2015-05-27 00:18:13 theanets.trainer:168 RmsProp 208 loss=897.068481 err=343.063751
I 2015-05-27 00:18:46 theanets.trainer:168 RmsProp 209 loss=897.817810 err=344.592224
I 2015-05-27 00:19:20 theanets.trainer:168 RmsProp 210 loss=892.113647 err=339.367493
I 2015-05-27 00:19:20 theanets.trainer:168 validation 21 loss=1986.314331 err=1434.468384 *
I 2015-05-27 00:19:54 theanets.trainer:168 RmsProp 211 loss=882.551575 err=331.975677
I 2015-05-27 00:20:27 theanets.trainer:168 RmsProp 212 loss=889.831604 err=340.699585
I 2015-05-27 00:21:01 theanets.trainer:168 RmsProp 213 loss=891.802063 err=341.912415
I 2015-05-27 00:21:34 theanets.trainer:168 RmsProp 214 loss=881.033875 err=332.657501
I 2015-05-27 00:22:08 theanets.trainer:168 RmsProp 215 loss=875.496765 err=328.362000
I 2015-05-27 00:22:42 theanets.trainer:168 RmsProp 216 loss=872.818542 err=327.119843
I 2015-05-27 00:23:15 theanets.trainer:168 RmsProp 217 loss=885.400757 err=339.597992
I 2015-05-27 00:23:49 theanets.trainer:168 RmsProp 218 loss=886.115601 err=340.491241
I 2015-05-27 00:24:22 theanets.trainer:168 RmsProp 219 loss=882.235352 err=336.258423
I 2015-05-27 00:24:56 theanets.trainer:168 RmsProp 220 loss=876.495972 err=331.449768
I 2015-05-27 00:24:56 theanets.trainer:168 validation 22 loss=1995.145508 err=1450.807617
I 2015-05-27 00:25:29 theanets.trainer:168 RmsProp 221 loss=870.069031 err=326.170441
I 2015-05-27 00:26:03 theanets.trainer:168 RmsProp 222 loss=865.212280 err=322.191986
I 2015-05-27 00:26:36 theanets.trainer:168 RmsProp 223 loss=863.839539 err=321.641663
I 2015-05-27 00:27:08 theanets.trainer:168 RmsProp 224 loss=877.714844 err=335.278687
I 2015-05-27 00:27:41 theanets.trainer:168 RmsProp 225 loss=881.091431 err=338.023895
I 2015-05-27 00:28:14 theanets.trainer:168 RmsProp 226 loss=872.822571 err=330.678925
I 2015-05-27 00:28:47 theanets.trainer:168 RmsProp 227 loss=852.520691 err=312.031708
I 2015-05-27 00:29:20 theanets.trainer:168 RmsProp 228 loss=852.787476 err=314.321838
I 2015-05-27 00:29:53 theanets.trainer:168 RmsProp 229 loss=850.359192 err=313.095764
I 2015-05-27 00:30:26 theanets.trainer:168 RmsProp 230 loss=861.348877 err=323.406067
I 2015-05-27 00:30:27 theanets.trainer:168 validation 23 loss=1979.357422 err=1441.815063 *
I 2015-05-27 00:30:59 theanets.trainer:168 RmsProp 231 loss=853.166016 err=316.034058
I 2015-05-27 00:31:32 theanets.trainer:168 RmsProp 232 loss=846.205261 err=309.734711
I 2015-05-27 00:32:05 theanets.trainer:168 RmsProp 233 loss=846.100952 err=309.930603
I 2015-05-27 00:32:38 theanets.trainer:168 RmsProp 234 loss=844.703918 err=309.778259
I 2015-05-27 00:33:12 theanets.trainer:168 RmsProp 235 loss=853.938293 err=318.928497
I 2015-05-27 00:33:45 theanets.trainer:168 RmsProp 236 loss=852.783997 err=317.968658
I 2015-05-27 00:34:19 theanets.trainer:168 RmsProp 237 loss=839.596924 err=305.849426
I 2015-05-27 00:34:52 theanets.trainer:168 RmsProp 238 loss=847.153625 err=313.445587
I 2015-05-27 00:35:26 theanets.trainer:168 RmsProp 239 loss=838.570435 err=305.693756
I 2015-05-27 00:36:00 theanets.trainer:168 RmsProp 240 loss=832.895630 err=301.311829
I 2015-05-27 00:36:01 theanets.trainer:168 validation 24 loss=1943.333130 err=1411.751587 *
I 2015-05-27 00:36:34 theanets.trainer:168 RmsProp 241 loss=832.958740 err=301.690948
I 2015-05-27 00:37:07 theanets.trainer:168 RmsProp 242 loss=818.610352 err=289.520355
I 2015-05-27 00:37:41 theanets.trainer:168 RmsProp 243 loss=827.156067 err=298.295288
I 2015-05-27 00:38:14 theanets.trainer:168 RmsProp 244 loss=815.527344 err=287.729309
I 2015-05-27 00:38:47 theanets.trainer:168 RmsProp 245 loss=810.721008 err=284.786713
I 2015-05-27 00:39:20 theanets.trainer:168 RmsProp 246 loss=813.423767 err=287.819916
I 2015-05-27 00:39:54 theanets.trainer:168 RmsProp 247 loss=805.693787 err=281.717987
I 2015-05-27 00:40:27 theanets.trainer:168 RmsProp 248 loss=806.168518 err=283.015747
I 2015-05-27 00:41:00 theanets.trainer:168 RmsProp 249 loss=802.366211 err=280.954865
I 2015-05-27 00:41:33 theanets.trainer:168 RmsProp 250 loss=799.571411 err=279.192047
I 2015-05-27 00:41:34 theanets.trainer:168 validation 25 loss=1959.814087 err=1439.938354
I 2015-05-27 00:42:07 theanets.trainer:168 RmsProp 251 loss=793.157288 err=274.213684
I 2015-05-27 00:42:40 theanets.trainer:168 RmsProp 252 loss=789.145508 err=271.611725
I 2015-05-27 00:43:14 theanets.trainer:168 RmsProp 253 loss=793.163513 err=276.595764
I 2015-05-27 00:43:47 theanets.trainer:168 RmsProp 254 loss=786.845764 err=271.116150
I 2015-05-27 00:44:20 theanets.trainer:168 RmsProp 255 loss=789.743958 err=274.936523
I 2015-05-27 00:44:54 theanets.trainer:168 RmsProp 256 loss=796.949646 err=281.525360
I 2015-05-27 00:45:27 theanets.trainer:168 RmsProp 257 loss=792.595337 err=277.683441
I 2015-05-27 00:46:00 theanets.trainer:168 RmsProp 258 loss=791.403442 err=277.308868
I 2015-05-27 00:46:34 theanets.trainer:168 RmsProp 259 loss=786.696106 err=273.885071
I 2015-05-27 00:47:07 theanets.trainer:168 RmsProp 260 loss=776.862244 err=265.301239
I 2015-05-27 00:47:08 theanets.trainer:168 validation 26 loss=1953.445435 err=1443.050781
I 2015-05-27 00:47:41 theanets.trainer:168 RmsProp 261 loss=777.800781 err=267.762024
I 2015-05-27 00:48:16 theanets.trainer:168 RmsProp 262 loss=768.156372 err=259.419861
I 2015-05-27 00:48:49 theanets.trainer:168 RmsProp 263 loss=770.535034 err=263.684113
I 2015-05-27 00:49:23 theanets.trainer:168 RmsProp 264 loss=771.383606 err=264.956665
I 2015-05-27 00:49:57 theanets.trainer:168 RmsProp 265 loss=778.199097 err=271.840485
I 2015-05-27 00:50:31 theanets.trainer:168 RmsProp 266 loss=777.318726 err=270.724548
I 2015-05-27 00:51:05 theanets.trainer:168 RmsProp 267 loss=763.816040 err=258.720184
I 2015-05-27 00:51:39 theanets.trainer:168 RmsProp 268 loss=774.048462 err=268.849426
I 2015-05-27 00:52:13 theanets.trainer:168 RmsProp 269 loss=760.486328 err=256.561127
I 2015-05-27 00:52:47 theanets.trainer:168 RmsProp 270 loss=774.889038 err=270.991302
I 2015-05-27 00:52:47 theanets.trainer:168 validation 27 loss=1929.286743 err=1424.868530 *
I 2015-05-27 00:53:21 theanets.trainer:168 RmsProp 271 loss=764.406616 err=260.521393
I 2015-05-27 00:53:54 theanets.trainer:168 RmsProp 272 loss=768.900269 err=265.550140
I 2015-05-27 00:54:27 theanets.trainer:168 RmsProp 273 loss=761.219482 err=258.799347
I 2015-05-27 00:55:01 theanets.trainer:168 RmsProp 274 loss=757.787109 err=256.549164
I 2015-05-27 00:55:35 theanets.trainer:168 RmsProp 275 loss=763.792053 err=262.664673
I 2015-05-27 00:56:09 theanets.trainer:168 RmsProp 276 loss=763.700623 err=263.160950
I 2015-05-27 00:56:42 theanets.trainer:168 RmsProp 277 loss=774.816040 err=272.605347
I 2015-05-27 00:57:15 theanets.trainer:168 RmsProp 278 loss=757.782654 err=256.283020
I 2015-05-27 00:57:49 theanets.trainer:168 RmsProp 279 loss=760.037415 err=259.611206
I 2015-05-27 00:58:22 theanets.trainer:168 RmsProp 280 loss=757.580933 err=256.757874
I 2015-05-27 00:58:23 theanets.trainer:168 validation 28 loss=1896.490601 err=1396.230591 *
I 2015-05-27 00:58:56 theanets.trainer:168 RmsProp 281 loss=754.500305 err=254.858643
I 2015-05-27 00:59:28 theanets.trainer:168 RmsProp 282 loss=753.586304 err=255.205673
I 2015-05-27 01:00:02 theanets.trainer:168 RmsProp 283 loss=752.867981 err=255.257141
I 2015-05-27 01:00:35 theanets.trainer:168 RmsProp 284 loss=746.279175 err=248.702728
I 2015-05-27 01:01:07 theanets.trainer:168 RmsProp 285 loss=747.970032 err=251.113693
I 2015-05-27 01:01:40 theanets.trainer:168 RmsProp 286 loss=764.445190 err=266.702240
I 2015-05-27 01:02:13 theanets.trainer:168 RmsProp 287 loss=744.893921 err=247.784821
I 2015-05-27 01:02:47 theanets.trainer:168 RmsProp 288 loss=737.796021 err=242.971359
I 2015-05-27 01:03:20 theanets.trainer:168 RmsProp 289 loss=735.957153 err=242.978241
I 2015-05-27 01:03:54 theanets.trainer:168 RmsProp 290 loss=738.726807 err=245.753860
I 2015-05-27 01:03:54 theanets.trainer:168 validation 29 loss=1913.588257 err=1420.892944
I 2015-05-27 01:04:28 theanets.trainer:168 RmsProp 291 loss=758.774841 err=265.419678
I 2015-05-27 01:05:02 theanets.trainer:168 RmsProp 292 loss=765.594604 err=270.066986
I 2015-05-27 01:05:35 theanets.trainer:168 RmsProp 293 loss=744.905090 err=250.437943
I 2015-05-27 01:06:09 theanets.trainer:168 RmsProp 294 loss=738.118591 err=246.103714
I 2015-05-27 01:06:42 theanets.trainer:168 RmsProp 295 loss=743.351013 err=251.773239
I 2015-05-27 01:07:16 theanets.trainer:168 RmsProp 296 loss=734.124817 err=242.841583
I 2015-05-27 01:07:50 theanets.trainer:168 RmsProp 297 loss=731.782349 err=242.301132
I 2015-05-27 01:08:23 theanets.trainer:168 RmsProp 298 loss=730.300171 err=242.053146
I 2015-05-27 01:08:57 theanets.trainer:168 RmsProp 299 loss=741.535095 err=252.382462
I 2015-05-27 01:09:31 theanets.trainer:168 RmsProp 300 loss=725.957458 err=238.332565
I 2015-05-27 01:09:32 theanets.trainer:168 validation 30 loss=1903.523560 err=1417.022461
I 2015-05-27 01:10:06 theanets.trainer:168 RmsProp 301 loss=720.564270 err=234.780411
I 2015-05-27 01:10:40 theanets.trainer:168 RmsProp 302 loss=736.803589 err=250.845963
I 2015-05-27 01:11:15 theanets.trainer:168 RmsProp 303 loss=750.431274 err=262.061401
I 2015-05-27 01:11:49 theanets.trainer:168 RmsProp 304 loss=742.693420 err=254.371185
I 2015-05-27 01:12:24 theanets.trainer:168 RmsProp 305 loss=743.591736 err=255.390488
I 2015-05-27 01:12:58 theanets.trainer:168 RmsProp 306 loss=736.517334 err=248.367340
I 2015-05-27 01:13:32 theanets.trainer:168 RmsProp 307 loss=722.540894 err=236.268066
I 2015-05-27 01:14:05 theanets.trainer:168 RmsProp 308 loss=712.669006 err=228.711105
I 2015-05-27 01:14:38 theanets.trainer:168 RmsProp 309 loss=707.916199 err=225.836426
I 2015-05-27 01:15:11 theanets.trainer:168 RmsProp 310 loss=700.687439 err=219.710724
I 2015-05-27 01:15:12 theanets.trainer:168 validation 31 loss=1953.770996 err=1473.495483
I 2015-05-27 01:15:45 theanets.trainer:168 RmsProp 311 loss=709.012817 err=229.362717
I 2015-05-27 01:16:19 theanets.trainer:168 RmsProp 312 loss=718.613220 err=237.719025
I 2015-05-27 01:16:53 theanets.trainer:168 RmsProp 313 loss=706.448792 err=226.676956
I 2015-05-27 01:17:26 theanets.trainer:168 RmsProp 314 loss=705.624756 err=226.360779
I 2015-05-27 01:18:00 theanets.trainer:168 RmsProp 315 loss=700.494812 err=222.851501
I 2015-05-27 01:18:34 theanets.trainer:168 RmsProp 316 loss=693.296265 err=217.450546
I 2015-05-27 01:19:08 theanets.trainer:168 RmsProp 317 loss=695.018127 err=220.039124
I 2015-05-27 01:19:42 theanets.trainer:168 RmsProp 318 loss=703.556274 err=228.611984
I 2015-05-27 01:20:16 theanets.trainer:168 RmsProp 319 loss=697.239258 err=222.108505
I 2015-05-27 01:20:51 theanets.trainer:168 RmsProp 320 loss=692.847778 err=218.972565
I 2015-05-27 01:20:52 theanets.trainer:168 validation 32 loss=2001.510620 err=1528.174438
I 2015-05-27 01:21:25 theanets.trainer:168 RmsProp 321 loss=691.715759 err=218.550629
I 2015-05-27 01:21:59 theanets.trainer:168 RmsProp 322 loss=692.395142 err=219.872009
I 2015-05-27 01:22:33 theanets.trainer:168 RmsProp 323 loss=688.148071 err=216.298370
I 2015-05-27 01:23:07 theanets.trainer:168 RmsProp 324 loss=687.846680 err=216.702469
I 2015-05-27 01:23:41 theanets.trainer:168 RmsProp 325 loss=679.646240 err=210.001144
I 2015-05-27 01:24:15 theanets.trainer:168 RmsProp 326 loss=685.039368 err=216.526230
I 2015-05-27 01:24:50 theanets.trainer:168 RmsProp 327 loss=703.974548 err=233.312073
I 2015-05-27 01:25:24 theanets.trainer:168 RmsProp 328 loss=685.792603 err=216.575790
I 2015-05-27 01:25:59 theanets.trainer:168 RmsProp 329 loss=677.188843 err=210.044006
I 2015-05-27 01:26:33 theanets.trainer:168 RmsProp 330 loss=676.662048 err=210.739365
I 2015-05-27 01:26:34 theanets.trainer:168 validation 33 loss=1964.498657 err=1499.000854
I 2015-05-27 01:26:34 theanets.trainer:252 patience elapsed!
I 2015-05-27 01:26:34 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 01:26:34 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 01:26:34 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 01:26:34 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 01:26:34 theanets.main:89 --batch_size = 1024
I 2015-05-27 01:26:34 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 01:26:34 theanets.main:89 --hidden_l1 = None
I 2015-05-27 01:26:34 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 01:26:34 theanets.main:89 --train_batches = 10
I 2015-05-27 01:26:34 theanets.main:89 --valid_batches = 2
I 2015-05-27 01:26:34 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 01:26:34 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 01:26:34 theanets.trainer:134 compiling evaluation function
I 2015-05-27 01:26:43 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 01:28:25 theanets.trainer:168 validation 0 loss=3081.895508 err=2581.635498 *
I 2015-05-27 01:28:35 theanets.trainer:168 RmsProp 1 loss=699.966919 err=203.143051
I 2015-05-27 01:28:46 theanets.trainer:168 RmsProp 2 loss=626.171204 err=132.264862
I 2015-05-27 01:28:56 theanets.trainer:168 RmsProp 3 loss=585.185120 err=93.328377
I 2015-05-27 01:29:07 theanets.trainer:168 RmsProp 4 loss=564.911194 err=74.845284
I 2015-05-27 01:29:18 theanets.trainer:168 RmsProp 5 loss=549.514526 err=61.221386
I 2015-05-27 01:29:28 theanets.trainer:168 RmsProp 6 loss=537.576294 err=51.169128
I 2015-05-27 01:29:39 theanets.trainer:168 RmsProp 7 loss=526.767090 err=42.514881
I 2015-05-27 01:29:49 theanets.trainer:168 RmsProp 8 loss=517.511902 err=35.762691
I 2015-05-27 01:30:00 theanets.trainer:168 RmsProp 9 loss=509.169830 err=30.175985
I 2015-05-27 01:30:11 theanets.trainer:168 RmsProp 10 loss=502.454285 err=26.439112
I 2015-05-27 01:30:11 theanets.trainer:168 validation 1 loss=2531.268555 err=2056.943115 *
I 2015-05-27 01:30:21 theanets.trainer:168 RmsProp 11 loss=496.540283 err=23.545706
I 2015-05-27 01:30:32 theanets.trainer:168 RmsProp 12 loss=490.669922 err=20.592669
I 2015-05-27 01:30:42 theanets.trainer:168 RmsProp 13 loss=486.352356 err=19.257357
I 2015-05-27 01:30:53 theanets.trainer:168 RmsProp 14 loss=482.005615 err=17.981865
I 2015-05-27 01:31:03 theanets.trainer:168 RmsProp 15 loss=477.552795 err=16.623177
I 2015-05-27 01:31:14 theanets.trainer:168 RmsProp 16 loss=473.376373 err=15.456203
I 2015-05-27 01:31:25 theanets.trainer:168 RmsProp 17 loss=469.269196 err=14.247164
I 2015-05-27 01:31:35 theanets.trainer:168 RmsProp 18 loss=465.392761 err=13.288414
I 2015-05-27 01:31:46 theanets.trainer:168 RmsProp 19 loss=462.415039 err=13.283277
I 2015-05-27 01:31:56 theanets.trainer:168 RmsProp 20 loss=458.408752 err=12.157076
I 2015-05-27 01:31:57 theanets.trainer:168 validation 2 loss=2376.206299 err=1931.471313 *
I 2015-05-27 01:32:07 theanets.trainer:168 RmsProp 21 loss=454.968994 err=11.469651
I 2015-05-27 01:32:18 theanets.trainer:168 RmsProp 22 loss=451.583099 err=10.889931
I 2015-05-27 01:32:28 theanets.trainer:168 RmsProp 23 loss=448.575439 err=10.800737
I 2015-05-27 01:32:39 theanets.trainer:168 RmsProp 24 loss=445.167389 err=10.214402
I 2015-05-27 01:32:49 theanets.trainer:168 RmsProp 25 loss=441.945557 err=9.671438
I 2015-05-27 01:33:00 theanets.trainer:168 RmsProp 26 loss=439.052338 err=9.420197
I 2015-05-27 01:33:10 theanets.trainer:168 RmsProp 27 loss=435.842285 err=8.892572
I 2015-05-27 01:33:21 theanets.trainer:168 RmsProp 28 loss=433.496643 err=9.208439
I 2015-05-27 01:33:31 theanets.trainer:168 RmsProp 29 loss=430.284515 err=8.521757
I 2015-05-27 01:33:42 theanets.trainer:168 RmsProp 30 loss=427.723450 err=8.472380
I 2015-05-27 01:33:43 theanets.trainer:168 validation 3 loss=2292.716064 err=1874.822266 *
I 2015-05-27 01:33:54 theanets.trainer:168 RmsProp 31 loss=425.141174 err=8.328536
I 2015-05-27 01:34:04 theanets.trainer:168 RmsProp 32 loss=422.376282 err=7.893689
I 2015-05-27 01:34:15 theanets.trainer:168 RmsProp 33 loss=419.835114 err=7.695829
I 2015-05-27 01:34:26 theanets.trainer:168 RmsProp 34 loss=417.218842 err=7.527859
I 2015-05-27 01:34:36 theanets.trainer:168 RmsProp 35 loss=414.699463 err=7.446396
I 2015-05-27 01:34:46 theanets.trainer:168 RmsProp 36 loss=412.011719 err=7.095885
I 2015-05-27 01:34:57 theanets.trainer:168 RmsProp 37 loss=409.200989 err=6.605564
I 2015-05-27 01:35:07 theanets.trainer:168 RmsProp 38 loss=407.607117 err=7.377498
I 2015-05-27 01:35:18 theanets.trainer:168 RmsProp 39 loss=404.681885 err=6.734385
I 2015-05-27 01:35:28 theanets.trainer:168 RmsProp 40 loss=402.039246 err=6.302892
I 2015-05-27 01:35:29 theanets.trainer:168 validation 4 loss=2232.737061 err=1838.248047 *
I 2015-05-27 01:35:39 theanets.trainer:168 RmsProp 41 loss=399.882874 err=6.459784
I 2015-05-27 01:35:50 theanets.trainer:168 RmsProp 42 loss=397.390015 err=6.269032
I 2015-05-27 01:36:00 theanets.trainer:168 RmsProp 43 loss=394.956146 err=6.105439
I 2015-05-27 01:36:10 theanets.trainer:168 RmsProp 44 loss=392.582611 err=5.978496
I 2015-05-27 01:36:21 theanets.trainer:168 RmsProp 45 loss=390.552307 err=6.168482
I 2015-05-27 01:36:31 theanets.trainer:168 RmsProp 46 loss=388.071808 err=5.818730
I 2015-05-27 01:36:42 theanets.trainer:168 RmsProp 47 loss=385.743469 err=5.563338
I 2015-05-27 01:36:53 theanets.trainer:168 RmsProp 48 loss=383.696777 err=5.637293
I 2015-05-27 01:37:04 theanets.trainer:168 RmsProp 49 loss=381.423920 err=5.473083
I 2015-05-27 01:37:15 theanets.trainer:168 RmsProp 50 loss=379.327026 err=5.460308
I 2015-05-27 01:37:15 theanets.trainer:168 validation 5 loss=2165.444824 err=1792.721069 *
I 2015-05-27 01:37:26 theanets.trainer:168 RmsProp 51 loss=377.499969 err=5.677616
I 2015-05-27 01:37:37 theanets.trainer:168 RmsProp 52 loss=375.023743 err=5.126470
I 2015-05-27 01:37:47 theanets.trainer:168 RmsProp 53 loss=373.237000 err=5.275407
I 2015-05-27 01:37:58 theanets.trainer:168 RmsProp 54 loss=371.211761 err=5.174426
I 2015-05-27 01:38:09 theanets.trainer:168 RmsProp 55 loss=368.946472 err=4.828965
I 2015-05-27 01:38:20 theanets.trainer:168 RmsProp 56 loss=367.358276 err=5.202363
I 2015-05-27 01:38:30 theanets.trainer:168 RmsProp 57 loss=365.398315 err=5.140169
I 2015-05-27 01:38:41 theanets.trainer:168 RmsProp 58 loss=363.199890 err=4.749887
I 2015-05-27 01:38:51 theanets.trainer:168 RmsProp 59 loss=361.422028 err=4.788846
I 2015-05-27 01:39:02 theanets.trainer:168 RmsProp 60 loss=359.576385 err=4.798145
I 2015-05-27 01:39:03 theanets.trainer:168 validation 6 loss=2107.408203 err=1753.641968 *
I 2015-05-27 01:39:13 theanets.trainer:168 RmsProp 61 loss=357.691467 err=4.755414
I 2015-05-27 01:39:24 theanets.trainer:168 RmsProp 62 loss=355.856415 err=4.712090
I 2015-05-27 01:39:34 theanets.trainer:168 RmsProp 63 loss=353.878540 err=4.479642
I 2015-05-27 01:39:45 theanets.trainer:168 RmsProp 64 loss=352.276428 err=4.606768
I 2015-05-27 01:39:55 theanets.trainer:168 RmsProp 65 loss=350.361023 err=4.434534
I 2015-05-27 01:40:06 theanets.trainer:168 RmsProp 66 loss=348.467041 err=4.271273
I 2015-05-27 01:40:17 theanets.trainer:168 RmsProp 67 loss=346.869202 err=4.406652
I 2015-05-27 01:40:28 theanets.trainer:168 RmsProp 68 loss=345.090088 err=4.340267
I 2015-05-27 01:40:38 theanets.trainer:168 RmsProp 69 loss=343.467804 err=4.410369
I 2015-05-27 01:40:49 theanets.trainer:168 RmsProp 70 loss=341.794006 err=4.393909
I 2015-05-27 01:40:50 theanets.trainer:168 validation 7 loss=2064.736328 err=1728.217163 *
I 2015-05-27 01:41:00 theanets.trainer:168 RmsProp 71 loss=339.874237 err=4.080422
I 2015-05-27 01:41:10 theanets.trainer:168 RmsProp 72 loss=338.381592 err=4.205786
I 2015-05-27 01:41:20 theanets.trainer:168 RmsProp 73 loss=336.642151 err=4.082500
I 2015-05-27 01:41:30 theanets.trainer:168 RmsProp 74 loss=335.102722 err=4.151605
I 2015-05-27 01:41:39 theanets.trainer:168 RmsProp 75 loss=333.399353 err=4.047373
I 2015-05-27 01:41:49 theanets.trainer:168 RmsProp 76 loss=331.964905 err=4.179782
I 2015-05-27 01:41:58 theanets.trainer:168 RmsProp 77 loss=330.081879 err=3.818360
I 2015-05-27 01:42:08 theanets.trainer:168 RmsProp 78 loss=328.645142 err=3.882568
I 2015-05-27 01:42:17 theanets.trainer:168 RmsProp 79 loss=327.372833 err=4.142840
I 2015-05-27 01:42:27 theanets.trainer:168 RmsProp 80 loss=325.674896 err=3.950646
I 2015-05-27 01:42:27 theanets.trainer:168 validation 8 loss=2033.498901 err=1712.568726 *
I 2015-05-27 01:42:36 theanets.trainer:168 RmsProp 81 loss=324.217590 err=3.927896
I 2015-05-27 01:42:46 theanets.trainer:168 RmsProp 82 loss=322.706329 err=3.842717
I 2015-05-27 01:42:55 theanets.trainer:168 RmsProp 83 loss=321.251587 err=3.808057
I 2015-05-27 01:43:04 theanets.trainer:168 RmsProp 84 loss=319.866516 err=3.847783
I 2015-05-27 01:43:14 theanets.trainer:168 RmsProp 85 loss=318.224670 err=3.625989
I 2015-05-27 01:43:23 theanets.trainer:168 RmsProp 86 loss=316.993439 err=3.837590
I 2015-05-27 01:43:33 theanets.trainer:168 RmsProp 87 loss=315.819641 err=4.081065
I 2015-05-27 01:43:42 theanets.trainer:168 RmsProp 88 loss=314.075684 err=3.654750
I 2015-05-27 01:43:51 theanets.trainer:168 RmsProp 89 loss=312.617035 err=3.507517
I 2015-05-27 01:44:01 theanets.trainer:168 RmsProp 90 loss=311.436188 err=3.686534
I 2015-05-27 01:44:01 theanets.trainer:168 validation 9 loss=1997.811035 err=1690.804565 *
I 2015-05-27 01:44:10 theanets.trainer:168 RmsProp 91 loss=309.965759 err=3.568114
I 2015-05-27 01:44:20 theanets.trainer:168 RmsProp 92 loss=308.558014 err=3.499588
I 2015-05-27 01:44:29 theanets.trainer:168 RmsProp 93 loss=307.205322 err=3.478003
I 2015-05-27 01:44:39 theanets.trainer:168 RmsProp 94 loss=306.222961 err=3.821691
I 2015-05-27 01:44:48 theanets.trainer:168 RmsProp 95 loss=304.494690 err=3.376038
I 2015-05-27 01:44:58 theanets.trainer:168 RmsProp 96 loss=303.455933 err=3.584183
I 2015-05-27 01:45:07 theanets.trainer:168 RmsProp 97 loss=302.200226 err=3.567897
I 2015-05-27 01:45:17 theanets.trainer:168 RmsProp 98 loss=300.824615 err=3.410210
I 2015-05-27 01:45:26 theanets.trainer:168 RmsProp 99 loss=299.838074 err=3.654891
I 2015-05-27 01:45:36 theanets.trainer:168 RmsProp 100 loss=298.488129 err=3.503700
I 2015-05-27 01:45:37 theanets.trainer:168 validation 10 loss=1955.798340 err=1661.450195 *
I 2015-05-27 01:45:46 theanets.trainer:168 RmsProp 101 loss=297.093567 err=3.283487
I 2015-05-27 01:45:56 theanets.trainer:168 RmsProp 102 loss=296.094177 err=3.490709
I 2015-05-27 01:46:05 theanets.trainer:168 RmsProp 103 loss=295.049988 err=3.648635
I 2015-05-27 01:46:15 theanets.trainer:168 RmsProp 104 loss=293.428772 err=3.180439
I 2015-05-27 01:46:24 theanets.trainer:168 RmsProp 105 loss=292.573669 err=3.470677
I 2015-05-27 01:46:34 theanets.trainer:168 RmsProp 106 loss=291.344604 err=3.415275
I 2015-05-27 01:46:43 theanets.trainer:168 RmsProp 107 loss=289.882629 err=3.092613
I 2015-05-27 01:46:53 theanets.trainer:168 RmsProp 108 loss=288.989716 err=3.337702
I 2015-05-27 01:47:02 theanets.trainer:168 RmsProp 109 loss=287.941711 err=3.432941
I 2015-05-27 01:47:11 theanets.trainer:168 RmsProp 110 loss=286.509918 err=3.113747
I 2015-05-27 01:47:12 theanets.trainer:168 validation 11 loss=1930.122070 err=1647.343750 *
I 2015-05-27 01:47:22 theanets.trainer:168 RmsProp 111 loss=285.467834 err=3.201019
I 2015-05-27 01:47:31 theanets.trainer:168 RmsProp 112 loss=284.442596 err=3.289643
I 2015-05-27 01:47:41 theanets.trainer:168 RmsProp 113 loss=283.301270 err=3.248652
I 2015-05-27 01:47:50 theanets.trainer:168 RmsProp 114 loss=282.051636 err=3.081829
I 2015-05-27 01:47:59 theanets.trainer:168 RmsProp 115 loss=281.029510 err=3.144442
I 2015-05-27 01:48:09 theanets.trainer:168 RmsProp 116 loss=280.289246 err=3.497193
I 2015-05-27 01:48:18 theanets.trainer:168 RmsProp 117 loss=279.077576 err=3.314654
I 2015-05-27 01:48:28 theanets.trainer:168 RmsProp 118 loss=277.894897 err=3.134072
I 2015-05-27 01:48:38 theanets.trainer:168 RmsProp 119 loss=276.762756 err=2.996564
I 2015-05-27 01:48:47 theanets.trainer:168 RmsProp 120 loss=275.843384 err=3.095045
I 2015-05-27 01:48:48 theanets.trainer:168 validation 12 loss=1908.226196 err=1636.043823 *
I 2015-05-27 01:48:57 theanets.trainer:168 RmsProp 121 loss=274.840332 err=3.121230
I 2015-05-27 01:49:07 theanets.trainer:168 RmsProp 122 loss=273.754211 err=3.057631
I 2015-05-27 01:49:16 theanets.trainer:168 RmsProp 123 loss=272.801697 err=3.131108
I 2015-05-27 01:49:24 theanets.trainer:168 RmsProp 124 loss=271.798676 err=3.110906
I 2015-05-27 01:49:33 theanets.trainer:168 RmsProp 125 loss=270.563873 err=2.855632
I 2015-05-27 01:49:42 theanets.trainer:168 RmsProp 126 loss=269.976135 err=3.240649
I 2015-05-27 01:49:51 theanets.trainer:168 RmsProp 127 loss=268.741821 err=2.970425
I 2015-05-27 01:50:00 theanets.trainer:168 RmsProp 128 loss=267.851257 err=3.046834
I 2015-05-27 01:50:09 theanets.trainer:168 RmsProp 129 loss=266.824768 err=2.973687
I 2015-05-27 01:50:18 theanets.trainer:168 RmsProp 130 loss=265.750305 err=2.864484
I 2015-05-27 01:50:18 theanets.trainer:168 validation 13 loss=1879.226318 err=1616.869995 *
I 2015-05-27 01:50:27 theanets.trainer:168 RmsProp 131 loss=264.838287 err=2.919306
I 2015-05-27 01:50:36 theanets.trainer:168 RmsProp 132 loss=263.930786 err=2.979258
I 2015-05-27 01:50:44 theanets.trainer:168 RmsProp 133 loss=262.970642 err=2.964589
I 2015-05-27 01:50:53 theanets.trainer:168 RmsProp 134 loss=262.153503 err=3.070019
I 2015-05-27 01:51:01 theanets.trainer:168 RmsProp 135 loss=261.033417 err=2.852405
I 2015-05-27 01:51:11 theanets.trainer:168 RmsProp 136 loss=260.189056 err=2.889967
I 2015-05-27 01:51:21 theanets.trainer:168 RmsProp 137 loss=259.204834 err=2.806167
I 2015-05-27 01:51:31 theanets.trainer:168 RmsProp 138 loss=258.582031 err=3.089861
I 2015-05-27 01:51:40 theanets.trainer:168 RmsProp 139 loss=257.582520 err=2.977334
I 2015-05-27 01:51:50 theanets.trainer:168 RmsProp 140 loss=256.265381 err=2.523327
I 2015-05-27 01:51:51 theanets.trainer:168 validation 14 loss=1851.688477 err=1598.421875 *
I 2015-05-27 01:52:01 theanets.trainer:168 RmsProp 141 loss=256.314514 err=3.438588
I 2015-05-27 01:52:10 theanets.trainer:168 RmsProp 142 loss=254.992218 err=2.958308
I 2015-05-27 01:52:20 theanets.trainer:168 RmsProp 143 loss=253.976852 err=2.732823
I 2015-05-27 01:52:30 theanets.trainer:168 RmsProp 144 loss=253.374054 err=2.943356
I 2015-05-27 01:52:40 theanets.trainer:168 RmsProp 145 loss=252.686111 err=3.067183
I 2015-05-27 01:52:49 theanets.trainer:168 RmsProp 146 loss=251.547211 err=2.707912
I 2015-05-27 01:52:58 theanets.trainer:168 RmsProp 147 loss=250.780121 err=2.731527
I 2015-05-27 01:53:08 theanets.trainer:168 RmsProp 148 loss=250.112427 err=2.864793
I 2015-05-27 01:53:17 theanets.trainer:168 RmsProp 149 loss=249.046799 err=2.608424
I 2015-05-27 01:53:27 theanets.trainer:168 RmsProp 150 loss=248.526337 err=2.896532
I 2015-05-27 01:53:27 theanets.trainer:168 validation 15 loss=1832.734375 err=1587.545776 *
I 2015-05-27 01:53:37 theanets.trainer:168 RmsProp 151 loss=247.507248 err=2.684478
I 2015-05-27 01:53:46 theanets.trainer:168 RmsProp 152 loss=246.595612 err=2.574605
I 2015-05-27 01:53:56 theanets.trainer:168 RmsProp 153 loss=246.246262 err=3.024691
I 2015-05-27 01:54:06 theanets.trainer:168 RmsProp 154 loss=245.015823 err=2.579485
I 2015-05-27 01:54:15 theanets.trainer:168 RmsProp 155 loss=244.566971 err=2.898618
I 2015-05-27 01:54:25 theanets.trainer:168 RmsProp 156 loss=243.734161 err=2.823140
I 2015-05-27 01:54:35 theanets.trainer:168 RmsProp 157 loss=242.894089 err=2.728791
I 2015-05-27 01:54:44 theanets.trainer:168 RmsProp 158 loss=242.270416 err=2.848640
I 2015-05-27 01:54:54 theanets.trainer:168 RmsProp 159 loss=241.372116 err=2.683999
I 2015-05-27 01:55:03 theanets.trainer:168 RmsProp 160 loss=240.619339 err=2.659485
I 2015-05-27 01:55:04 theanets.trainer:168 validation 16 loss=1818.686646 err=1581.127808 *
I 2015-05-27 01:55:13 theanets.trainer:168 RmsProp 161 loss=239.903244 err=2.679282
I 2015-05-27 01:55:23 theanets.trainer:168 RmsProp 162 loss=239.239532 err=2.744235
I 2015-05-27 01:55:33 theanets.trainer:168 RmsProp 163 loss=238.285278 err=2.515019
I 2015-05-27 01:55:42 theanets.trainer:168 RmsProp 164 loss=237.908722 err=2.870908
I 2015-05-27 01:55:52 theanets.trainer:168 RmsProp 165 loss=237.039459 err=2.715291
I 2015-05-27 01:56:01 theanets.trainer:168 RmsProp 166 loss=236.117111 err=2.495110
I 2015-05-27 01:56:11 theanets.trainer:168 RmsProp 167 loss=235.704758 err=2.782283
I 2015-05-27 01:56:20 theanets.trainer:168 RmsProp 168 loss=234.884155 err=2.654457
I 2015-05-27 01:56:30 theanets.trainer:168 RmsProp 169 loss=234.108032 err=2.567953
I 2015-05-27 01:56:40 theanets.trainer:168 RmsProp 170 loss=233.418182 err=2.568669
I 2015-05-27 01:56:40 theanets.trainer:168 validation 17 loss=1792.272705 err=1561.803711 *
I 2015-05-27 01:56:50 theanets.trainer:168 RmsProp 171 loss=232.845413 err=2.697605
I 2015-05-27 01:56:59 theanets.trainer:168 RmsProp 172 loss=232.298538 err=2.831291
I 2015-05-27 01:57:09 theanets.trainer:168 RmsProp 173 loss=231.233734 err=2.428881
I 2015-05-27 01:57:19 theanets.trainer:168 RmsProp 174 loss=230.714401 err=2.571225
I 2015-05-27 01:57:29 theanets.trainer:168 RmsProp 175 loss=229.775269 err=2.304515
I 2015-05-27 01:57:38 theanets.trainer:168 RmsProp 176 loss=230.055588 err=3.272725
I 2015-05-27 01:57:48 theanets.trainer:168 RmsProp 177 loss=228.759552 err=2.618218
I 2015-05-27 01:57:58 theanets.trainer:168 RmsProp 178 loss=228.068436 err=2.534131
I 2015-05-27 01:58:08 theanets.trainer:168 RmsProp 179 loss=227.400833 err=2.479095
I 2015-05-27 01:58:17 theanets.trainer:168 RmsProp 180 loss=226.868805 err=2.572687
I 2015-05-27 01:58:18 theanets.trainer:168 validation 18 loss=1766.259644 err=1542.301392 *
I 2015-05-27 01:58:27 theanets.trainer:168 RmsProp 181 loss=226.154877 err=2.491187
I 2015-05-27 01:58:37 theanets.trainer:168 RmsProp 182 loss=225.680298 err=2.647165
I 2015-05-27 01:58:47 theanets.trainer:168 RmsProp 183 loss=225.021286 err=2.623490
I 2015-05-27 01:58:57 theanets.trainer:168 RmsProp 184 loss=224.319672 err=2.527540
I 2015-05-27 01:59:07 theanets.trainer:168 RmsProp 185 loss=223.442535 err=2.264197
I 2015-05-27 01:59:16 theanets.trainer:168 RmsProp 186 loss=223.420654 err=2.868245
I 2015-05-27 01:59:26 theanets.trainer:168 RmsProp 187 loss=222.391434 err=2.445910
I 2015-05-27 01:59:35 theanets.trainer:168 RmsProp 188 loss=221.899628 err=2.548700
I 2015-05-27 01:59:45 theanets.trainer:168 RmsProp 189 loss=221.331329 err=2.570365
I 2015-05-27 01:59:55 theanets.trainer:168 RmsProp 190 loss=220.550262 err=2.386779
I 2015-05-27 01:59:55 theanets.trainer:168 validation 19 loss=1751.500122 err=1533.677002 *
I 2015-05-27 02:00:05 theanets.trainer:168 RmsProp 191 loss=220.057816 err=2.493837
I 2015-05-27 02:00:14 theanets.trainer:168 RmsProp 192 loss=219.419388 err=2.449268
I 2015-05-27 02:00:24 theanets.trainer:168 RmsProp 193 loss=218.916672 err=2.538370
I 2015-05-27 02:00:34 theanets.trainer:168 RmsProp 194 loss=218.214890 err=2.410565
I 2015-05-27 02:00:44 theanets.trainer:168 RmsProp 195 loss=217.780487 err=2.556076
I 2015-05-27 02:00:54 theanets.trainer:168 RmsProp 196 loss=217.166260 err=2.513529
I 2015-05-27 02:01:04 theanets.trainer:168 RmsProp 197 loss=216.423126 err=2.338224
I 2015-05-27 02:01:14 theanets.trainer:168 RmsProp 198 loss=215.971268 err=2.459678
I 2015-05-27 02:01:23 theanets.trainer:168 RmsProp 199 loss=215.322174 err=2.382898
I 2015-05-27 02:01:33 theanets.trainer:168 RmsProp 200 loss=214.760452 err=2.401207
I 2015-05-27 02:01:34 theanets.trainer:168 validation 20 loss=1726.067505 err=1514.023315 *
I 2015-05-27 02:01:43 theanets.trainer:168 RmsProp 201 loss=214.159866 err=2.378271
I 2015-05-27 02:01:53 theanets.trainer:168 RmsProp 202 loss=213.480789 err=2.274717
I 2015-05-27 02:02:02 theanets.trainer:168 RmsProp 203 loss=213.170441 err=2.533846
I 2015-05-27 02:02:12 theanets.trainer:168 RmsProp 204 loss=212.493988 err=2.417311
I 2015-05-27 02:02:22 theanets.trainer:168 RmsProp 205 loss=211.842255 err=2.319816
I 2015-05-27 02:02:32 theanets.trainer:168 RmsProp 206 loss=211.435715 err=2.457587
I 2015-05-27 02:02:42 theanets.trainer:168 RmsProp 207 loss=210.810013 err=2.384862
I 2015-05-27 02:02:52 theanets.trainer:168 RmsProp 208 loss=210.213089 err=2.322326
I 2015-05-27 02:03:01 theanets.trainer:168 RmsProp 209 loss=209.906815 err=2.552365
I 2015-05-27 02:03:11 theanets.trainer:168 RmsProp 210 loss=209.156036 err=2.328075
I 2015-05-27 02:03:11 theanets.trainer:168 validation 21 loss=1709.239136 err=1502.686523 *
I 2015-05-27 02:03:21 theanets.trainer:168 RmsProp 211 loss=208.717285 err=2.412629
I 2015-05-27 02:03:30 theanets.trainer:168 RmsProp 212 loss=208.141891 err=2.367951
I 2015-05-27 02:03:40 theanets.trainer:168 RmsProp 213 loss=207.568192 err=2.313215
I 2015-05-27 02:03:50 theanets.trainer:168 RmsProp 214 loss=207.144684 err=2.412810
I 2015-05-27 02:04:00 theanets.trainer:168 RmsProp 215 loss=206.624420 err=2.393154
I 2015-05-27 02:04:09 theanets.trainer:168 RmsProp 216 loss=206.079468 err=2.353330
I 2015-05-27 02:04:19 theanets.trainer:168 RmsProp 217 loss=205.558441 err=2.330678
I 2015-05-27 02:04:29 theanets.trainer:168 RmsProp 218 loss=205.097946 err=2.364044
I 2015-05-27 02:04:39 theanets.trainer:168 RmsProp 219 loss=204.536072 err=2.296380
I 2015-05-27 02:04:49 theanets.trainer:168 RmsProp 220 loss=204.275818 err=2.530380
I 2015-05-27 02:04:49 theanets.trainer:168 validation 22 loss=1681.120483 err=1479.645996 *
I 2015-05-27 02:04:59 theanets.trainer:168 RmsProp 221 loss=203.622437 err=2.369017
I 2015-05-27 02:05:09 theanets.trainer:168 RmsProp 222 loss=203.138824 err=2.358357
I 2015-05-27 02:05:19 theanets.trainer:168 RmsProp 223 loss=202.596771 err=2.292702
I 2015-05-27 02:05:28 theanets.trainer:168 RmsProp 224 loss=202.096207 err=2.266119
I 2015-05-27 02:05:38 theanets.trainer:168 RmsProp 225 loss=201.791306 err=2.436335
I 2015-05-27 02:05:48 theanets.trainer:168 RmsProp 226 loss=201.133026 err=2.252069
I 2015-05-27 02:05:58 theanets.trainer:168 RmsProp 227 loss=200.804657 err=2.396580
I 2015-05-27 02:06:07 theanets.trainer:168 RmsProp 228 loss=200.280029 err=2.342665
I 2015-05-27 02:06:17 theanets.trainer:168 RmsProp 229 loss=199.834274 err=2.354326
I 2015-05-27 02:06:27 theanets.trainer:168 RmsProp 230 loss=199.302490 err=2.278957
I 2015-05-27 02:06:27 theanets.trainer:168 validation 23 loss=1661.211670 err=1464.444580 *
I 2015-05-27 02:06:37 theanets.trainer:168 RmsProp 231 loss=198.943756 err=2.376097
I 2015-05-27 02:06:47 theanets.trainer:168 RmsProp 232 loss=198.373337 err=2.257731
I 2015-05-27 02:06:57 theanets.trainer:168 RmsProp 233 loss=197.927170 err=2.261029
I 2015-05-27 02:07:07 theanets.trainer:168 RmsProp 234 loss=197.575241 err=2.358035
I 2015-05-27 02:07:17 theanets.trainer:168 RmsProp 235 loss=197.120331 err=2.349384
I 2015-05-27 02:07:27 theanets.trainer:168 RmsProp 236 loss=196.669159 err=2.334498
I 2015-05-27 02:07:36 theanets.trainer:168 RmsProp 237 loss=196.200592 err=2.302965
I 2015-05-27 02:07:46 theanets.trainer:168 RmsProp 238 loss=195.728897 err=2.264447
I 2015-05-27 02:07:56 theanets.trainer:168 RmsProp 239 loss=195.282928 err=2.250682
I 2015-05-27 02:08:06 theanets.trainer:168 RmsProp 240 loss=194.906662 err=2.308355
I 2015-05-27 02:08:06 theanets.trainer:168 validation 24 loss=1638.235474 err=1445.865234 *
I 2015-05-27 02:08:16 theanets.trainer:168 RmsProp 241 loss=194.292816 err=2.131421
I 2015-05-27 02:08:25 theanets.trainer:168 RmsProp 242 loss=194.132034 err=2.408797
I 2015-05-27 02:08:35 theanets.trainer:168 RmsProp 243 loss=193.452118 err=2.158049
I 2015-05-27 02:08:45 theanets.trainer:168 RmsProp 244 loss=193.066467 err=2.198354
I 2015-05-27 02:08:55 theanets.trainer:168 RmsProp 245 loss=192.723557 err=2.284678
I 2015-05-27 02:09:05 theanets.trainer:168 RmsProp 246 loss=192.449432 err=2.437109
I 2015-05-27 02:09:15 theanets.trainer:168 RmsProp 247 loss=192.008575 err=2.410850
I 2015-05-27 02:09:25 theanets.trainer:168 RmsProp 248 loss=191.359573 err=2.162145
I 2015-05-27 02:09:34 theanets.trainer:168 RmsProp 249 loss=191.138885 err=2.350256
I 2015-05-27 02:09:44 theanets.trainer:168 RmsProp 250 loss=190.889938 err=2.498504
I 2015-05-27 02:09:44 theanets.trainer:168 validation 25 loss=1620.126709 err=1431.953491 *
I 2015-05-27 02:09:54 theanets.trainer:168 RmsProp 251 loss=190.099197 err=2.101750
I 2015-05-27 02:10:03 theanets.trainer:168 RmsProp 252 loss=189.775970 err=2.175639
I 2015-05-27 02:10:13 theanets.trainer:168 RmsProp 253 loss=189.316010 err=2.121560
I 2015-05-27 02:10:23 theanets.trainer:168 RmsProp 254 loss=189.307343 err=2.528081
I 2015-05-27 02:10:33 theanets.trainer:168 RmsProp 255 loss=188.740234 err=2.360799
I 2015-05-27 02:10:42 theanets.trainer:168 RmsProp 256 loss=188.033829 err=2.045753
I 2015-05-27 02:10:52 theanets.trainer:168 RmsProp 257 loss=187.766083 err=2.161961
I 2015-05-27 02:11:02 theanets.trainer:168 RmsProp 258 loss=187.501328 err=2.297975
I 2015-05-27 02:11:11 theanets.trainer:168 RmsProp 259 loss=187.015656 err=2.203166
I 2015-05-27 02:11:21 theanets.trainer:168 RmsProp 260 loss=186.728531 err=2.308029
I 2015-05-27 02:11:21 theanets.trainer:168 validation 26 loss=1589.674927 err=1405.475586 *
I 2015-05-27 02:11:31 theanets.trainer:168 RmsProp 261 loss=186.189423 err=2.160659
I 2015-05-27 02:11:41 theanets.trainer:168 RmsProp 262 loss=186.029388 err=2.381049
I 2015-05-27 02:11:51 theanets.trainer:168 RmsProp 263 loss=185.552109 err=2.274954
I 2015-05-27 02:12:00 theanets.trainer:168 RmsProp 264 loss=184.870712 err=1.961231
I 2015-05-27 02:12:10 theanets.trainer:168 RmsProp 265 loss=184.982788 err=2.447329
I 2015-05-27 02:12:20 theanets.trainer:168 RmsProp 266 loss=184.298340 err=2.141088
I 2015-05-27 02:12:29 theanets.trainer:168 RmsProp 267 loss=183.934326 err=2.150185
I 2015-05-27 02:12:39 theanets.trainer:168 RmsProp 268 loss=183.248413 err=1.850844
I 2015-05-27 02:12:49 theanets.trainer:168 RmsProp 269 loss=184.153168 err=3.125307
I 2015-05-27 02:12:59 theanets.trainer:168 RmsProp 270 loss=182.771729 err=2.109307
I 2015-05-27 02:13:00 theanets.trainer:168 validation 27 loss=1570.991699 err=1390.511108 *
I 2015-05-27 02:13:09 theanets.trainer:168 RmsProp 271 loss=182.389755 err=2.075082
I 2015-05-27 02:13:19 theanets.trainer:168 RmsProp 272 loss=182.145203 err=2.189353
I 2015-05-27 02:13:29 theanets.trainer:168 RmsProp 273 loss=181.639069 err=2.048172
I 2015-05-27 02:13:39 theanets.trainer:168 RmsProp 274 loss=181.585190 err=2.363721
I 2015-05-27 02:13:48 theanets.trainer:168 RmsProp 275 loss=180.994232 err=2.136603
I 2015-05-27 02:13:58 theanets.trainer:168 RmsProp 276 loss=180.521973 err=2.022997
I 2015-05-27 02:14:08 theanets.trainer:168 RmsProp 277 loss=180.369553 err=2.233078
I 2015-05-27 02:14:17 theanets.trainer:168 RmsProp 278 loss=179.844025 err=2.063786
I 2015-05-27 02:14:26 theanets.trainer:168 RmsProp 279 loss=179.568512 err=2.144632
I 2015-05-27 02:14:36 theanets.trainer:168 RmsProp 280 loss=179.339645 err=2.269043
I 2015-05-27 02:14:36 theanets.trainer:168 validation 28 loss=1548.615601 err=1371.730347 *
I 2015-05-27 02:14:46 theanets.trainer:168 RmsProp 281 loss=178.971848 err=2.247613
I 2015-05-27 02:14:55 theanets.trainer:168 RmsProp 282 loss=178.557419 err=2.176375
I 2015-05-27 02:15:04 theanets.trainer:168 RmsProp 283 loss=178.169037 err=2.122745
I 2015-05-27 02:15:14 theanets.trainer:168 RmsProp 284 loss=177.719818 err=2.015463
I 2015-05-27 02:15:23 theanets.trainer:168 RmsProp 285 loss=177.461304 err=2.096944
I 2015-05-27 02:15:32 theanets.trainer:168 RmsProp 286 loss=177.155746 err=2.139046
I 2015-05-27 02:15:42 theanets.trainer:168 RmsProp 287 loss=176.921143 err=2.246298
I 2015-05-27 02:15:51 theanets.trainer:168 RmsProp 288 loss=176.541885 err=2.203068
I 2015-05-27 02:15:59 theanets.trainer:168 RmsProp 289 loss=176.166977 err=2.158319
I 2015-05-27 02:16:08 theanets.trainer:168 RmsProp 290 loss=175.575394 err=1.897135
I 2015-05-27 02:16:09 theanets.trainer:168 validation 29 loss=1526.051514 err=1352.559570 *
I 2015-05-27 02:16:18 theanets.trainer:168 RmsProp 291 loss=175.868561 err=2.521461
I 2015-05-27 02:16:26 theanets.trainer:168 RmsProp 292 loss=174.921249 err=1.903398
I 2015-05-27 02:16:34 theanets.trainer:168 RmsProp 293 loss=174.784103 err=2.093550
I 2015-05-27 02:16:42 theanets.trainer:168 RmsProp 294 loss=174.360413 err=1.999791
I 2015-05-27 02:16:51 theanets.trainer:168 RmsProp 295 loss=174.213593 err=2.179986
I 2015-05-27 02:16:59 theanets.trainer:168 RmsProp 296 loss=173.645905 err=1.945089
I 2015-05-27 02:17:08 theanets.trainer:168 RmsProp 297 loss=173.610947 err=2.237322
I 2015-05-27 02:17:16 theanets.trainer:168 RmsProp 298 loss=173.023895 err=1.980998
I 2015-05-27 02:17:25 theanets.trainer:168 RmsProp 299 loss=172.710114 err=1.989852
I 2015-05-27 02:17:33 theanets.trainer:168 RmsProp 300 loss=172.525818 err=2.137386
I 2015-05-27 02:17:34 theanets.trainer:168 validation 30 loss=1499.083252 err=1328.869385 *
I 2015-05-27 02:17:42 theanets.trainer:168 RmsProp 301 loss=172.135712 err=2.070812
I 2015-05-27 02:17:50 theanets.trainer:168 RmsProp 302 loss=171.725311 err=1.989089
I 2015-05-27 02:17:58 theanets.trainer:168 RmsProp 303 loss=171.631805 err=2.219043
I 2015-05-27 02:18:06 theanets.trainer:168 RmsProp 304 loss=171.172668 err=2.074789
I 2015-05-27 02:18:13 theanets.trainer:168 RmsProp 305 loss=170.898361 err=2.110070
I 2015-05-27 02:18:21 theanets.trainer:168 RmsProp 306 loss=170.555023 err=2.077284
I 2015-05-27 02:18:29 theanets.trainer:168 RmsProp 307 loss=170.261841 err=2.085420
I 2015-05-27 02:18:37 theanets.trainer:168 RmsProp 308 loss=169.918991 err=2.043772
I 2015-05-27 02:18:45 theanets.trainer:168 RmsProp 309 loss=169.685822 err=2.109027
I 2015-05-27 02:18:53 theanets.trainer:168 RmsProp 310 loss=169.234558 err=1.959011
I 2015-05-27 02:18:53 theanets.trainer:168 validation 31 loss=1490.933960 err=1323.821167 *
I 2015-05-27 02:19:01 theanets.trainer:168 RmsProp 311 loss=169.198975 err=2.219743
I 2015-05-27 02:19:09 theanets.trainer:168 RmsProp 312 loss=168.575272 err=1.894511
I 2015-05-27 02:19:18 theanets.trainer:168 RmsProp 313 loss=168.391434 err=2.004179
I 2015-05-27 02:19:24 theanets.trainer:168 RmsProp 314 loss=168.309052 err=2.224725
I 2015-05-27 02:19:33 theanets.trainer:168 RmsProp 315 loss=167.797546 err=2.010368
I 2015-05-27 02:19:41 theanets.trainer:168 RmsProp 316 loss=167.524231 err=2.030586
I 2015-05-27 02:19:49 theanets.trainer:168 RmsProp 317 loss=167.307419 err=2.112358
I 2015-05-27 02:19:57 theanets.trainer:168 RmsProp 318 loss=166.858276 err=1.955180
I 2015-05-27 02:20:05 theanets.trainer:168 RmsProp 319 loss=166.584030 err=1.975756
I 2015-05-27 02:20:13 theanets.trainer:168 RmsProp 320 loss=166.451889 err=2.133187
I 2015-05-27 02:20:14 theanets.trainer:168 validation 32 loss=1453.881226 err=1289.715210 *
I 2015-05-27 02:20:21 theanets.trainer:168 RmsProp 321 loss=166.122314 err=2.092932
I 2015-05-27 02:20:29 theanets.trainer:168 RmsProp 322 loss=165.716217 err=1.972989
I 2015-05-27 02:20:37 theanets.trainer:168 RmsProp 323 loss=165.379425 err=1.925335
I 2015-05-27 02:20:44 theanets.trainer:168 RmsProp 324 loss=165.187637 err=2.032333
I 2015-05-27 02:20:53 theanets.trainer:168 RmsProp 325 loss=164.888382 err=2.020144
I 2015-05-27 02:21:00 theanets.trainer:168 RmsProp 326 loss=164.590790 err=2.014728
I 2015-05-27 02:21:08 theanets.trainer:168 RmsProp 327 loss=164.104858 err=1.818299
I 2015-05-27 02:21:15 theanets.trainer:168 RmsProp 328 loss=164.131989 err=2.133357
I 2015-05-27 02:21:24 theanets.trainer:168 RmsProp 329 loss=163.598053 err=1.886910
I 2015-05-27 02:21:31 theanets.trainer:168 RmsProp 330 loss=163.656525 err=2.226472
I 2015-05-27 02:21:32 theanets.trainer:168 validation 33 loss=1455.744751 err=1294.472046
I 2015-05-27 02:21:40 theanets.trainer:168 RmsProp 331 loss=163.100281 err=1.950997
I 2015-05-27 02:21:48 theanets.trainer:168 RmsProp 332 loss=162.824402 err=1.948087
I 2015-05-27 02:21:56 theanets.trainer:168 RmsProp 333 loss=162.557007 err=1.961203
I 2015-05-27 02:22:04 theanets.trainer:168 RmsProp 334 loss=162.398071 err=2.077793
I 2015-05-27 02:22:13 theanets.trainer:168 RmsProp 335 loss=161.941574 err=1.901044
I 2015-05-27 02:22:21 theanets.trainer:168 RmsProp 336 loss=161.827118 err=2.063118
I 2015-05-27 02:22:29 theanets.trainer:168 RmsProp 337 loss=161.387924 err=1.894102
I 2015-05-27 02:22:37 theanets.trainer:168 RmsProp 338 loss=161.147095 err=1.926753
I 2015-05-27 02:22:45 theanets.trainer:168 RmsProp 339 loss=160.947144 err=1.997143
I 2015-05-27 02:22:52 theanets.trainer:168 RmsProp 340 loss=160.662323 err=1.985898
I 2015-05-27 02:22:52 theanets.trainer:168 validation 34 loss=1445.539917 err=1287.013672 *
I 2015-05-27 02:23:00 theanets.trainer:168 RmsProp 341 loss=160.327682 err=1.920590
I 2015-05-27 02:23:08 theanets.trainer:168 RmsProp 342 loss=160.085709 err=1.953164
I 2015-05-27 02:23:16 theanets.trainer:168 RmsProp 343 loss=159.908554 err=2.039401
I 2015-05-27 02:23:24 theanets.trainer:168 RmsProp 344 loss=159.528717 err=1.925219
I 2015-05-27 02:23:32 theanets.trainer:168 RmsProp 345 loss=159.324371 err=1.983632
I 2015-05-27 02:23:40 theanets.trainer:168 RmsProp 346 loss=159.029556 err=1.946600
I 2015-05-27 02:23:47 theanets.trainer:168 RmsProp 347 loss=158.804672 err=1.985863
I 2015-05-27 02:23:55 theanets.trainer:168 RmsProp 348 loss=158.624710 err=2.060741
I 2015-05-27 02:24:02 theanets.trainer:168 RmsProp 349 loss=157.973419 err=1.668556
I 2015-05-27 02:24:09 theanets.trainer:168 RmsProp 350 loss=158.675598 err=2.618090
I 2015-05-27 02:24:10 theanets.trainer:168 validation 35 loss=1435.201782 err=1279.280151 *
I 2015-05-27 02:24:17 theanets.trainer:168 RmsProp 351 loss=157.766510 err=1.955968
I 2015-05-27 02:24:26 theanets.trainer:168 RmsProp 352 loss=157.422882 err=1.854986
I 2015-05-27 02:24:35 theanets.trainer:168 RmsProp 353 loss=157.285828 err=1.959878
I 2015-05-27 02:24:42 theanets.trainer:168 RmsProp 354 loss=157.014816 err=1.938487
I 2015-05-27 02:24:50 theanets.trainer:168 RmsProp 355 loss=156.787170 err=1.954033
I 2015-05-27 02:24:57 theanets.trainer:168 RmsProp 356 loss=156.397598 err=1.818651
I 2015-05-27 02:25:04 theanets.trainer:168 RmsProp 357 loss=156.471680 err=2.142119
I 2015-05-27 02:25:11 theanets.trainer:168 RmsProp 358 loss=156.063004 err=1.982955
I 2015-05-27 02:25:17 theanets.trainer:168 RmsProp 359 loss=155.680466 err=1.843879
I 2015-05-27 02:25:24 theanets.trainer:168 RmsProp 360 loss=155.559921 err=1.970896
I 2015-05-27 02:25:25 theanets.trainer:168 validation 36 loss=1438.748169 err=1285.283081
I 2015-05-27 02:25:31 theanets.trainer:168 RmsProp 361 loss=155.317505 err=1.972692
I 2015-05-27 02:25:38 theanets.trainer:168 RmsProp 362 loss=155.017029 err=1.915426
I 2015-05-27 02:25:45 theanets.trainer:168 RmsProp 363 loss=154.788712 err=1.925828
I 2015-05-27 02:25:52 theanets.trainer:168 RmsProp 364 loss=154.477341 err=1.851527
I 2015-05-27 02:25:58 theanets.trainer:168 RmsProp 365 loss=154.366531 err=1.983439
I 2015-05-27 02:26:04 theanets.trainer:168 RmsProp 366 loss=154.066223 err=1.924891
I 2015-05-27 02:26:11 theanets.trainer:168 RmsProp 367 loss=153.881165 err=1.978272
I 2015-05-27 02:26:17 theanets.trainer:168 RmsProp 368 loss=153.560104 err=1.892910
I 2015-05-27 02:26:23 theanets.trainer:168 RmsProp 369 loss=153.369461 err=1.939876
I 2015-05-27 02:26:29 theanets.trainer:168 RmsProp 370 loss=153.165115 err=1.973808
I 2015-05-27 02:26:30 theanets.trainer:168 validation 37 loss=1424.489868 err=1273.433228 *
I 2015-05-27 02:26:35 theanets.trainer:168 RmsProp 371 loss=152.793106 err=1.840108
I 2015-05-27 02:26:41 theanets.trainer:168 RmsProp 372 loss=152.658325 err=1.939978
I 2015-05-27 02:26:48 theanets.trainer:168 RmsProp 373 loss=152.327728 err=1.847668
I 2015-05-27 02:26:54 theanets.trainer:168 RmsProp 374 loss=152.256973 err=2.003393
I 2015-05-27 02:27:00 theanets.trainer:168 RmsProp 375 loss=151.884521 err=1.865892
I 2015-05-27 02:27:06 theanets.trainer:168 RmsProp 376 loss=151.685272 err=1.895708
I 2015-05-27 02:27:13 theanets.trainer:168 RmsProp 377 loss=151.520370 err=1.963777
I 2015-05-27 02:27:19 theanets.trainer:168 RmsProp 378 loss=151.159134 err=1.835682
I 2015-05-27 02:27:26 theanets.trainer:168 RmsProp 379 loss=151.092072 err=1.995784
I 2015-05-27 02:27:32 theanets.trainer:168 RmsProp 380 loss=150.943268 err=2.069430
I 2015-05-27 02:27:32 theanets.trainer:168 validation 38 loss=1415.683228 err=1266.930420 *
I 2015-05-27 02:27:38 theanets.trainer:168 RmsProp 381 loss=150.373077 err=1.722822
I 2015-05-27 02:27:45 theanets.trainer:168 RmsProp 382 loss=150.204132 err=1.781068
I 2015-05-27 02:27:51 theanets.trainer:168 RmsProp 383 loss=150.233673 err=2.033716
I 2015-05-27 02:27:58 theanets.trainer:168 RmsProp 384 loss=149.938461 err=1.962927
I 2015-05-27 02:28:04 theanets.trainer:168 RmsProp 385 loss=149.549301 err=1.793136
I 2015-05-27 02:28:10 theanets.trainer:168 RmsProp 386 loss=149.583710 err=2.045168
I 2015-05-27 02:28:16 theanets.trainer:168 RmsProp 387 loss=149.139954 err=1.824664
I 2015-05-27 02:28:22 theanets.trainer:168 RmsProp 388 loss=148.932404 err=1.835096
I 2015-05-27 02:28:29 theanets.trainer:168 RmsProp 389 loss=148.765228 err=1.889536
I 2015-05-27 02:28:36 theanets.trainer:168 RmsProp 390 loss=148.588226 err=1.927863
I 2015-05-27 02:28:36 theanets.trainer:168 validation 39 loss=1393.404785 err=1246.847046 *
I 2015-05-27 02:28:42 theanets.trainer:168 RmsProp 391 loss=148.406570 err=1.960495
I 2015-05-27 02:28:48 theanets.trainer:168 RmsProp 392 loss=148.172623 err=1.941136
I 2015-05-27 02:28:55 theanets.trainer:168 RmsProp 393 loss=147.860916 err=1.848248
I 2015-05-27 02:29:01 theanets.trainer:168 RmsProp 394 loss=147.609650 err=1.812714
I 2015-05-27 02:29:07 theanets.trainer:168 RmsProp 395 loss=147.404175 err=1.819382
I 2015-05-27 02:29:14 theanets.trainer:168 RmsProp 396 loss=147.262817 err=1.898265
I 2015-05-27 02:29:20 theanets.trainer:168 RmsProp 397 loss=147.042725 err=1.888638
I 2015-05-27 02:29:26 theanets.trainer:168 RmsProp 398 loss=146.828033 err=1.887561
I 2015-05-27 02:29:32 theanets.trainer:168 RmsProp 399 loss=146.520935 err=1.793150
I 2015-05-27 02:29:38 theanets.trainer:168 RmsProp 400 loss=146.353561 err=1.833240
I 2015-05-27 02:29:38 theanets.trainer:168 validation 40 loss=1413.859985 err=1269.464844
I 2015-05-27 02:29:45 theanets.trainer:168 RmsProp 401 loss=146.240021 err=1.932731
I 2015-05-27 02:29:51 theanets.trainer:168 RmsProp 402 loss=145.991806 err=1.894553
I 2015-05-27 02:29:57 theanets.trainer:168 RmsProp 403 loss=145.701324 err=1.811370
I 2015-05-27 02:30:03 theanets.trainer:168 RmsProp 404 loss=145.589279 err=1.906814
I 2015-05-27 02:30:10 theanets.trainer:168 RmsProp 405 loss=145.380539 err=1.902887
I 2015-05-27 02:30:16 theanets.trainer:168 RmsProp 406 loss=144.981644 err=1.714268
I 2015-05-27 02:30:22 theanets.trainer:168 RmsProp 407 loss=145.208771 err=2.138102
I 2015-05-27 02:30:28 theanets.trainer:168 RmsProp 408 loss=144.786346 err=1.915344
I 2015-05-27 02:30:34 theanets.trainer:168 RmsProp 409 loss=144.504486 err=1.828795
I 2015-05-27 02:30:41 theanets.trainer:168 RmsProp 410 loss=144.283890 err=1.807394
I 2015-05-27 02:30:41 theanets.trainer:168 validation 41 loss=1397.086792 err=1254.721680
I 2015-05-27 02:30:47 theanets.trainer:168 RmsProp 411 loss=144.260696 err=1.980672
I 2015-05-27 02:30:53 theanets.trainer:168 RmsProp 412 loss=144.060104 err=1.975284
I 2015-05-27 02:30:59 theanets.trainer:168 RmsProp 413 loss=143.640488 err=1.750209
I 2015-05-27 02:31:05 theanets.trainer:168 RmsProp 414 loss=143.582428 err=1.889227
I 2015-05-27 02:31:12 theanets.trainer:168 RmsProp 415 loss=143.341202 err=1.847922
I 2015-05-27 02:31:18 theanets.trainer:168 RmsProp 416 loss=143.169525 err=1.868271
I 2015-05-27 02:31:24 theanets.trainer:168 RmsProp 417 loss=143.057709 err=1.948982
I 2015-05-27 02:31:30 theanets.trainer:168 RmsProp 418 loss=142.799316 err=1.876438
I 2015-05-27 02:31:37 theanets.trainer:168 RmsProp 419 loss=142.676056 err=1.944324
I 2015-05-27 02:31:42 theanets.trainer:168 RmsProp 420 loss=142.209091 err=1.669261
I 2015-05-27 02:31:43 theanets.trainer:168 validation 42 loss=1392.512695 err=1252.067261 *
I 2015-05-27 02:31:49 theanets.trainer:168 RmsProp 421 loss=142.376968 err=2.030663
I 2015-05-27 02:31:55 theanets.trainer:168 RmsProp 422 loss=142.527313 err=2.364986
I 2015-05-27 02:32:01 theanets.trainer:168 RmsProp 423 loss=141.603500 err=1.632646
I 2015-05-27 02:32:07 theanets.trainer:168 RmsProp 424 loss=141.548889 err=1.760027
I 2015-05-27 02:32:13 theanets.trainer:168 RmsProp 425 loss=141.597000 err=1.986825
I 2015-05-27 02:32:20 theanets.trainer:168 RmsProp 426 loss=141.239349 err=1.817532
I 2015-05-27 02:32:26 theanets.trainer:168 RmsProp 427 loss=140.910477 err=1.676187
I 2015-05-27 02:32:32 theanets.trainer:168 RmsProp 428 loss=140.982681 err=1.936627
I 2015-05-27 02:32:39 theanets.trainer:168 RmsProp 429 loss=140.628632 err=1.775749
I 2015-05-27 02:32:45 theanets.trainer:168 RmsProp 430 loss=140.580460 err=1.913194
I 2015-05-27 02:32:46 theanets.trainer:168 validation 43 loss=1377.861084 err=1239.300659 *
I 2015-05-27 02:32:51 theanets.trainer:168 RmsProp 431 loss=140.401306 err=1.924241
I 2015-05-27 02:32:57 theanets.trainer:168 RmsProp 432 loss=140.052963 err=1.756404
I 2015-05-27 02:33:04 theanets.trainer:168 RmsProp 433 loss=140.001740 err=1.890316
I 2015-05-27 02:33:10 theanets.trainer:168 RmsProp 434 loss=139.841248 err=1.909436
I 2015-05-27 02:33:16 theanets.trainer:168 RmsProp 435 loss=139.392624 err=1.649064
I 2015-05-27 02:33:22 theanets.trainer:168 RmsProp 436 loss=139.439056 err=1.875501
I 2015-05-27 02:33:28 theanets.trainer:168 RmsProp 437 loss=139.260178 err=1.878630
I 2015-05-27 02:33:35 theanets.trainer:168 RmsProp 438 loss=139.050171 err=1.852527
I 2015-05-27 02:33:41 theanets.trainer:168 RmsProp 439 loss=138.761749 err=1.741043
I 2015-05-27 02:33:47 theanets.trainer:168 RmsProp 440 loss=138.504013 err=1.661323
I 2015-05-27 02:33:47 theanets.trainer:168 validation 44 loss=1390.954712 err=1254.206909
I 2015-05-27 02:33:54 theanets.trainer:168 RmsProp 441 loss=138.480011 err=1.818565
I 2015-05-27 02:34:00 theanets.trainer:168 RmsProp 442 loss=138.555878 err=2.070733
I 2015-05-27 02:34:07 theanets.trainer:168 RmsProp 443 loss=138.124924 err=1.815849
I 2015-05-27 02:34:13 theanets.trainer:168 RmsProp 444 loss=137.845840 err=1.712566
I 2015-05-27 02:34:19 theanets.trainer:168 RmsProp 445 loss=137.826263 err=1.868668
I 2015-05-27 02:34:25 theanets.trainer:168 RmsProp 446 loss=137.495193 err=1.711648
I 2015-05-27 02:34:31 theanets.trainer:168 RmsProp 447 loss=137.574661 err=1.970500
I 2015-05-27 02:34:37 theanets.trainer:168 RmsProp 448 loss=137.153442 err=1.720350
I 2015-05-27 02:34:44 theanets.trainer:168 RmsProp 449 loss=137.036804 err=1.774569
I 2015-05-27 02:34:50 theanets.trainer:168 RmsProp 450 loss=137.034103 err=1.944650
I 2015-05-27 02:34:50 theanets.trainer:168 validation 45 loss=1357.753418 err=1222.742188 *
I 2015-05-27 02:34:56 theanets.trainer:168 RmsProp 451 loss=136.825073 err=1.905480
I 2015-05-27 02:35:03 theanets.trainer:168 RmsProp 452 loss=136.446381 err=1.697052
I 2015-05-27 02:35:10 theanets.trainer:168 RmsProp 453 loss=136.422211 err=1.841580
I 2015-05-27 02:35:16 theanets.trainer:168 RmsProp 454 loss=136.195953 err=1.786422
I 2015-05-27 02:35:22 theanets.trainer:168 RmsProp 455 loss=136.039169 err=1.800774
I 2015-05-27 02:35:28 theanets.trainer:168 RmsProp 456 loss=135.832214 err=1.767372
I 2015-05-27 02:35:34 theanets.trainer:168 RmsProp 457 loss=135.679611 err=1.783130
I 2015-05-27 02:35:41 theanets.trainer:168 RmsProp 458 loss=135.484665 err=1.754127
I 2015-05-27 02:35:47 theanets.trainer:168 RmsProp 459 loss=135.292633 err=1.734565
I 2015-05-27 02:35:53 theanets.trainer:168 RmsProp 460 loss=135.260834 err=1.869525
I 2015-05-27 02:35:53 theanets.trainer:168 validation 46 loss=1371.534668 err=1238.227905
I 2015-05-27 02:36:00 theanets.trainer:168 RmsProp 461 loss=135.096695 err=1.872650
I 2015-05-27 02:36:06 theanets.trainer:168 RmsProp 462 loss=134.829620 err=1.770937
I 2015-05-27 02:36:12 theanets.trainer:168 RmsProp 463 loss=134.597931 err=1.706409
I 2015-05-27 02:36:18 theanets.trainer:168 RmsProp 464 loss=134.607498 err=1.884035
I 2015-05-27 02:36:25 theanets.trainer:168 RmsProp 465 loss=134.323212 err=1.762372
I 2015-05-27 02:36:30 theanets.trainer:168 RmsProp 466 loss=134.057892 err=1.666046
I 2015-05-27 02:36:36 theanets.trainer:168 RmsProp 467 loss=134.083405 err=1.856549
I 2015-05-27 02:36:42 theanets.trainer:168 RmsProp 468 loss=133.805832 err=1.746232
I 2015-05-27 02:36:48 theanets.trainer:168 RmsProp 469 loss=133.614731 err=1.713502
I 2015-05-27 02:36:54 theanets.trainer:168 RmsProp 470 loss=133.523270 err=1.785755
I 2015-05-27 02:36:54 theanets.trainer:168 validation 47 loss=1357.143921 err=1225.502563 *
I 2015-05-27 02:37:00 theanets.trainer:168 RmsProp 471 loss=133.300858 err=1.727789
I 2015-05-27 02:37:06 theanets.trainer:168 RmsProp 472 loss=133.256012 err=1.841920
I 2015-05-27 02:37:12 theanets.trainer:168 RmsProp 473 loss=133.297333 err=2.040354
I 2015-05-27 02:37:18 theanets.trainer:168 RmsProp 474 loss=132.657303 err=1.557061
I 2015-05-27 02:37:24 theanets.trainer:168 RmsProp 475 loss=132.956818 err=2.011644
I 2015-05-27 02:37:30 theanets.trainer:168 RmsProp 476 loss=132.401459 err=1.612686
I 2015-05-27 02:37:36 theanets.trainer:168 RmsProp 477 loss=132.498352 err=1.871241
I 2015-05-27 02:37:43 theanets.trainer:168 RmsProp 478 loss=132.364716 err=1.890404
I 2015-05-27 02:37:49 theanets.trainer:168 RmsProp 479 loss=132.017242 err=1.699690
I 2015-05-27 02:37:55 theanets.trainer:168 RmsProp 480 loss=131.887283 err=1.723708
I 2015-05-27 02:37:55 theanets.trainer:168 validation 48 loss=1358.930786 err=1228.844360
I 2015-05-27 02:38:01 theanets.trainer:168 RmsProp 481 loss=131.823868 err=1.816927
I 2015-05-27 02:38:07 theanets.trainer:168 RmsProp 482 loss=131.595947 err=1.745848
I 2015-05-27 02:38:14 theanets.trainer:168 RmsProp 483 loss=131.562576 err=1.864244
I 2015-05-27 02:38:21 theanets.trainer:168 RmsProp 484 loss=131.226105 err=1.682107
I 2015-05-27 02:38:26 theanets.trainer:168 RmsProp 485 loss=131.041534 err=1.656144
I 2015-05-27 02:38:32 theanets.trainer:168 RmsProp 486 loss=130.933624 err=1.701918
I 2015-05-27 02:38:38 theanets.trainer:168 RmsProp 487 loss=130.790237 err=1.714758
I 2015-05-27 02:38:45 theanets.trainer:168 RmsProp 488 loss=130.832230 err=1.911395
I 2015-05-27 02:38:50 theanets.trainer:168 RmsProp 489 loss=130.410095 err=1.643576
I 2015-05-27 02:38:56 theanets.trainer:168 RmsProp 490 loss=130.495529 err=1.883103
I 2015-05-27 02:38:57 theanets.trainer:168 validation 49 loss=1362.735229 err=1234.197144
I 2015-05-27 02:39:03 theanets.trainer:168 RmsProp 491 loss=130.394379 err=1.927682
I 2015-05-27 02:39:09 theanets.trainer:168 RmsProp 492 loss=130.017120 err=1.703680
I 2015-05-27 02:39:16 theanets.trainer:168 RmsProp 493 loss=129.879837 err=1.713421
I 2015-05-27 02:39:22 theanets.trainer:168 RmsProp 494 loss=129.889572 err=1.870608
I 2015-05-27 02:39:28 theanets.trainer:168 RmsProp 495 loss=129.499222 err=1.628826
I 2015-05-27 02:39:35 theanets.trainer:168 RmsProp 496 loss=129.669266 err=1.946309
I 2015-05-27 02:39:41 theanets.trainer:168 RmsProp 497 loss=129.100433 err=1.528899
I 2015-05-27 02:39:47 theanets.trainer:168 RmsProp 498 loss=129.418030 err=1.990589
I 2015-05-27 02:39:53 theanets.trainer:168 RmsProp 499 loss=128.928299 err=1.651042
I 2015-05-27 02:39:59 theanets.trainer:168 RmsProp 500 loss=128.875031 err=1.742963
I 2015-05-27 02:39:59 theanets.trainer:168 validation 50 loss=1342.938721 err=1215.888550 *
I 2015-05-27 02:40:05 theanets.trainer:168 RmsProp 501 loss=128.716782 err=1.736315
I 2015-05-27 02:40:11 theanets.trainer:168 RmsProp 502 loss=128.771210 err=1.931739
I 2015-05-27 02:40:18 theanets.trainer:168 RmsProp 503 loss=128.305557 err=1.614340
I 2015-05-27 02:40:25 theanets.trainer:168 RmsProp 504 loss=128.351837 err=1.809400
I 2015-05-27 02:40:31 theanets.trainer:168 RmsProp 505 loss=128.025131 err=1.625509
I 2015-05-27 02:40:37 theanets.trainer:168 RmsProp 506 loss=128.036713 err=1.786358
I 2015-05-27 02:40:43 theanets.trainer:168 RmsProp 507 loss=127.853638 err=1.749382
I 2015-05-27 02:40:49 theanets.trainer:168 RmsProp 508 loss=127.743973 err=1.786432
I 2015-05-27 02:40:56 theanets.trainer:168 RmsProp 509 loss=127.582558 err=1.763013
I 2015-05-27 02:41:02 theanets.trainer:168 RmsProp 510 loss=127.428574 err=1.758041
I 2015-05-27 02:41:02 theanets.trainer:168 validation 51 loss=1346.300049 err=1220.701416
I 2015-05-27 02:41:08 theanets.trainer:168 RmsProp 511 loss=127.193932 err=1.662380
I 2015-05-27 02:41:14 theanets.trainer:168 RmsProp 512 loss=127.023476 err=1.634309
I 2015-05-27 02:41:20 theanets.trainer:168 RmsProp 513 loss=127.135208 err=1.889167
I 2015-05-27 02:41:27 theanets.trainer:168 RmsProp 514 loss=127.020973 err=1.911741
I 2015-05-27 02:41:33 theanets.trainer:168 RmsProp 515 loss=126.406616 err=1.444404
I 2015-05-27 02:41:39 theanets.trainer:168 RmsProp 516 loss=126.738831 err=1.910399
I 2015-05-27 02:41:45 theanets.trainer:168 RmsProp 517 loss=126.345932 err=1.661707
I 2015-05-27 02:41:51 theanets.trainer:168 RmsProp 518 loss=126.321854 err=1.779558
I 2015-05-27 02:41:57 theanets.trainer:168 RmsProp 519 loss=126.251053 err=1.847508
I 2015-05-27 02:42:03 theanets.trainer:168 RmsProp 520 loss=125.889992 err=1.625974
I 2015-05-27 02:42:04 theanets.trainer:168 validation 52 loss=1344.536133 err=1220.349731
I 2015-05-27 02:42:10 theanets.trainer:168 RmsProp 521 loss=125.816849 err=1.691474
I 2015-05-27 02:42:16 theanets.trainer:168 RmsProp 522 loss=125.752151 err=1.764021
I 2015-05-27 02:42:22 theanets.trainer:168 RmsProp 523 loss=125.575562 err=1.724824
I 2015-05-27 02:42:28 theanets.trainer:168 RmsProp 524 loss=125.247459 err=1.538580
I 2015-05-27 02:42:34 theanets.trainer:168 RmsProp 525 loss=125.429543 err=1.859511
I 2015-05-27 02:42:41 theanets.trainer:168 RmsProp 526 loss=125.208435 err=1.774748
I 2015-05-27 02:42:47 theanets.trainer:168 RmsProp 527 loss=125.117676 err=1.821646
I 2015-05-27 02:42:54 theanets.trainer:168 RmsProp 528 loss=124.988487 err=1.823819
I 2015-05-27 02:42:59 theanets.trainer:168 RmsProp 529 loss=124.698441 err=1.669488
I 2015-05-27 02:43:05 theanets.trainer:168 RmsProp 530 loss=124.562393 err=1.670478
I 2015-05-27 02:43:06 theanets.trainer:168 validation 53 loss=1347.834839 err=1225.010132
I 2015-05-27 02:43:12 theanets.trainer:168 RmsProp 531 loss=124.573631 err=1.818479
I 2015-05-27 02:43:18 theanets.trainer:168 RmsProp 532 loss=124.248924 err=1.625697
I 2015-05-27 02:43:24 theanets.trainer:168 RmsProp 533 loss=124.124252 err=1.636920
I 2015-05-27 02:43:31 theanets.trainer:168 RmsProp 534 loss=124.115341 err=1.764641
I 2015-05-27 02:43:37 theanets.trainer:168 RmsProp 535 loss=123.997047 err=1.779138
I 2015-05-27 02:43:43 theanets.trainer:168 RmsProp 536 loss=123.646423 err=1.568910
I 2015-05-27 02:43:49 theanets.trainer:168 RmsProp 537 loss=123.824059 err=1.881985
I 2015-05-27 02:43:56 theanets.trainer:168 RmsProp 538 loss=123.388161 err=1.582308
I 2015-05-27 02:44:02 theanets.trainer:168 RmsProp 539 loss=123.360352 err=1.691969
I 2015-05-27 02:44:08 theanets.trainer:168 RmsProp 540 loss=123.432510 err=1.892165
I 2015-05-27 02:44:08 theanets.trainer:168 validation 54 loss=1325.433594 err=1203.962524 *
I 2015-05-27 02:44:14 theanets.trainer:168 RmsProp 541 loss=122.985825 err=1.578716
I 2015-05-27 02:44:21 theanets.trainer:168 RmsProp 542 loss=123.083176 err=1.803036
I 2015-05-27 02:44:27 theanets.trainer:168 RmsProp 543 loss=122.840347 err=1.691365
I 2015-05-27 02:44:33 theanets.trainer:168 RmsProp 544 loss=122.747620 err=1.729869
I 2015-05-27 02:44:39 theanets.trainer:168 RmsProp 545 loss=122.789040 err=1.900394
I 2015-05-27 02:44:46 theanets.trainer:168 RmsProp 546 loss=122.419357 err=1.657441
I 2015-05-27 02:44:52 theanets.trainer:168 RmsProp 547 loss=122.187965 err=1.554958
I 2015-05-27 02:44:58 theanets.trainer:168 RmsProp 548 loss=122.228531 err=1.725620
I 2015-05-27 02:45:05 theanets.trainer:168 RmsProp 549 loss=122.143883 err=1.770422
I 2015-05-27 02:45:11 theanets.trainer:168 RmsProp 550 loss=121.748154 err=1.509278
I 2015-05-27 02:45:12 theanets.trainer:168 validation 55 loss=1338.689087 err=1218.524658
I 2015-05-27 02:45:18 theanets.trainer:168 RmsProp 551 loss=122.033897 err=1.920634
I 2015-05-27 02:45:23 theanets.trainer:168 RmsProp 552 loss=121.782799 err=1.801493
I 2015-05-27 02:45:30 theanets.trainer:168 RmsProp 553 loss=121.409691 err=1.556428
I 2015-05-27 02:45:37 theanets.trainer:168 RmsProp 554 loss=121.536339 err=1.810744
I 2015-05-27 02:45:44 theanets.trainer:168 RmsProp 555 loss=121.115860 err=1.524132
I 2015-05-27 02:45:50 theanets.trainer:168 RmsProp 556 loss=121.355370 err=1.891495
I 2015-05-27 02:45:56 theanets.trainer:168 RmsProp 557 loss=120.980972 err=1.644786
I 2015-05-27 02:46:03 theanets.trainer:168 RmsProp 558 loss=120.883995 err=1.671228
I 2015-05-27 02:46:09 theanets.trainer:168 RmsProp 559 loss=120.770287 err=1.680537
I 2015-05-27 02:46:15 theanets.trainer:168 RmsProp 560 loss=120.692078 err=1.729637
I 2015-05-27 02:46:15 theanets.trainer:168 validation 56 loss=1322.914551 err=1204.018433 *
I 2015-05-27 02:46:21 theanets.trainer:168 RmsProp 561 loss=120.559547 err=1.725029
I 2015-05-27 02:46:28 theanets.trainer:168 RmsProp 562 loss=120.385338 err=1.679219
I 2015-05-27 02:46:34 theanets.trainer:168 RmsProp 563 loss=120.181519 err=1.599547
I 2015-05-27 02:46:41 theanets.trainer:168 RmsProp 564 loss=120.120773 err=1.666060
I 2015-05-27 02:46:47 theanets.trainer:168 RmsProp 565 loss=119.933578 err=1.601791
I 2015-05-27 02:46:54 theanets.trainer:168 RmsProp 566 loss=119.939621 err=1.735906
I 2015-05-27 02:47:00 theanets.trainer:168 RmsProp 567 loss=119.753456 err=1.673601
I 2015-05-27 02:47:06 theanets.trainer:168 RmsProp 568 loss=119.590843 err=1.633725
I 2015-05-27 02:47:12 theanets.trainer:168 RmsProp 569 loss=119.517899 err=1.686004
I 2015-05-27 02:47:18 theanets.trainer:168 RmsProp 570 loss=119.446640 err=1.738319
I 2015-05-27 02:47:19 theanets.trainer:168 validation 57 loss=1329.985474 err=1212.344604
I 2015-05-27 02:47:25 theanets.trainer:168 RmsProp 571 loss=119.266319 err=1.681005
I 2015-05-27 02:47:31 theanets.trainer:168 RmsProp 572 loss=119.066322 err=1.602605
I 2015-05-27 02:47:37 theanets.trainer:168 RmsProp 573 loss=119.089195 err=1.749242
I 2015-05-27 02:47:44 theanets.trainer:168 RmsProp 574 loss=118.910851 err=1.691532
I 2015-05-27 02:47:50 theanets.trainer:168 RmsProp 575 loss=118.651878 err=1.556156
I 2015-05-27 02:47:56 theanets.trainer:168 RmsProp 576 loss=118.712463 err=1.740285
I 2015-05-27 02:48:02 theanets.trainer:168 RmsProp 577 loss=118.520691 err=1.665935
I 2015-05-27 02:48:08 theanets.trainer:168 RmsProp 578 loss=118.495239 err=1.763035
I 2015-05-27 02:48:14 theanets.trainer:168 RmsProp 579 loss=118.147949 err=1.538284
I 2015-05-27 02:48:21 theanets.trainer:168 RmsProp 580 loss=118.584129 err=2.092535
I 2015-05-27 02:48:21 theanets.trainer:168 validation 58 loss=1309.155518 err=1192.726440 *
I 2015-05-27 02:48:27 theanets.trainer:168 RmsProp 581 loss=118.108932 err=1.729585
I 2015-05-27 02:48:33 theanets.trainer:168 RmsProp 582 loss=117.758972 err=1.502353
I 2015-05-27 02:48:40 theanets.trainer:168 RmsProp 583 loss=117.929749 err=1.789029
I 2015-05-27 02:48:46 theanets.trainer:168 RmsProp 584 loss=117.608498 err=1.582055
I 2015-05-27 02:48:52 theanets.trainer:168 RmsProp 585 loss=117.587936 err=1.683244
I 2015-05-27 02:48:59 theanets.trainer:168 RmsProp 586 loss=117.425461 err=1.636473
I 2015-05-27 02:49:05 theanets.trainer:168 RmsProp 587 loss=117.239845 err=1.574727
I 2015-05-27 02:49:12 theanets.trainer:168 RmsProp 588 loss=117.257034 err=1.707788
I 2015-05-27 02:49:18 theanets.trainer:168 RmsProp 589 loss=116.757301 err=1.333236
I 2015-05-27 02:49:24 theanets.trainer:168 RmsProp 590 loss=117.263771 err=1.953307
I 2015-05-27 02:49:24 theanets.trainer:168 validation 59 loss=1324.614868 err=1209.356323
I 2015-05-27 02:49:30 theanets.trainer:168 RmsProp 591 loss=116.909813 err=1.715100
I 2015-05-27 02:49:36 theanets.trainer:168 RmsProp 592 loss=116.551682 err=1.477280
I 2015-05-27 02:49:42 theanets.trainer:168 RmsProp 593 loss=116.711624 err=1.752910
I 2015-05-27 02:49:48 theanets.trainer:168 RmsProp 594 loss=116.645752 err=1.804372
I 2015-05-27 02:49:54 theanets.trainer:168 RmsProp 595 loss=116.007156 err=1.283449
I 2015-05-27 02:50:00 theanets.trainer:168 RmsProp 596 loss=116.921852 err=2.303442
I 2015-05-27 02:50:07 theanets.trainer:168 RmsProp 597 loss=116.156998 err=1.656313
I 2015-05-27 02:50:13 theanets.trainer:168 RmsProp 598 loss=115.953407 err=1.561189
I 2015-05-27 02:50:20 theanets.trainer:168 RmsProp 599 loss=115.933128 err=1.651559
I 2015-05-27 02:50:26 theanets.trainer:168 RmsProp 600 loss=115.739380 err=1.570611
I 2015-05-27 02:50:26 theanets.trainer:168 validation 60 loss=1303.183472 err=1189.067993 *
I 2015-05-27 02:50:33 theanets.trainer:168 RmsProp 601 loss=115.702965 err=1.649595
I 2015-05-27 02:50:39 theanets.trainer:168 RmsProp 602 loss=115.592972 err=1.654983
I 2015-05-27 02:50:45 theanets.trainer:168 RmsProp 603 loss=115.538353 err=1.713089
I 2015-05-27 02:50:51 theanets.trainer:168 RmsProp 604 loss=115.238571 err=1.526585
I 2015-05-27 02:50:57 theanets.trainer:168 RmsProp 605 loss=115.336327 err=1.732885
I 2015-05-27 02:51:03 theanets.trainer:168 RmsProp 606 loss=115.208046 err=1.717212
I 2015-05-27 02:51:09 theanets.trainer:168 RmsProp 607 loss=115.113808 err=1.732865
I 2015-05-27 02:51:16 theanets.trainer:168 RmsProp 608 loss=114.819420 err=1.550162
I 2015-05-27 02:51:22 theanets.trainer:168 RmsProp 609 loss=114.826271 err=1.665572
I 2015-05-27 02:51:28 theanets.trainer:168 RmsProp 610 loss=114.781235 err=1.728473
I 2015-05-27 02:51:28 theanets.trainer:168 validation 61 loss=1300.003052 err=1187.024414 *
I 2015-05-27 02:51:34 theanets.trainer:168 RmsProp 611 loss=114.527794 err=1.589054
I 2015-05-27 02:51:40 theanets.trainer:168 RmsProp 612 loss=114.563843 err=1.733163
I 2015-05-27 02:51:46 theanets.trainer:168 RmsProp 613 loss=114.271286 err=1.550925
I 2015-05-27 02:51:52 theanets.trainer:168 RmsProp 614 loss=114.317284 err=1.706413
I 2015-05-27 02:51:58 theanets.trainer:168 RmsProp 615 loss=114.357033 err=1.851997
I 2015-05-27 02:52:05 theanets.trainer:168 RmsProp 616 loss=113.985878 err=1.588109
I 2015-05-27 02:52:11 theanets.trainer:168 RmsProp 617 loss=113.999489 err=1.704372
I 2015-05-27 02:52:17 theanets.trainer:168 RmsProp 618 loss=113.745644 err=1.558726
I 2015-05-27 02:52:24 theanets.trainer:168 RmsProp 619 loss=113.827515 err=1.743992
I 2015-05-27 02:52:30 theanets.trainer:168 RmsProp 620 loss=113.546242 err=1.573413
I 2015-05-27 02:52:31 theanets.trainer:168 validation 62 loss=1293.868774 err=1181.953369 *
I 2015-05-27 02:52:37 theanets.trainer:168 RmsProp 621 loss=113.535011 err=1.668685
I 2015-05-27 02:52:43 theanets.trainer:168 RmsProp 622 loss=113.478989 err=1.713518
I 2015-05-27 02:52:49 theanets.trainer:168 RmsProp 623 loss=113.273277 err=1.613319
I 2015-05-27 02:52:55 theanets.trainer:168 RmsProp 624 loss=113.119728 err=1.566981
I 2015-05-27 02:53:02 theanets.trainer:168 RmsProp 625 loss=113.174889 err=1.726744
I 2015-05-27 02:53:08 theanets.trainer:168 RmsProp 626 loss=112.857483 err=1.512560
I 2015-05-27 02:53:14 theanets.trainer:168 RmsProp 627 loss=112.984573 err=1.745238
I 2015-05-27 02:53:21 theanets.trainer:168 RmsProp 628 loss=112.739563 err=1.601546
I 2015-05-27 02:53:27 theanets.trainer:168 RmsProp 629 loss=112.581100 err=1.550232
I 2015-05-27 02:53:33 theanets.trainer:168 RmsProp 630 loss=112.716331 err=1.788801
I 2015-05-27 02:53:33 theanets.trainer:168 validation 63 loss=1288.369873 err=1177.486450 *
I 2015-05-27 02:53:39 theanets.trainer:168 RmsProp 631 loss=112.320740 err=1.495793
I 2015-05-27 02:53:46 theanets.trainer:168 RmsProp 632 loss=112.556175 err=1.830715
I 2015-05-27 02:53:51 theanets.trainer:168 RmsProp 633 loss=112.365067 err=1.742014
I 2015-05-27 02:53:58 theanets.trainer:168 RmsProp 634 loss=112.006393 err=1.491800
I 2015-05-27 02:54:04 theanets.trainer:168 RmsProp 635 loss=112.224144 err=1.811123
I 2015-05-27 02:54:10 theanets.trainer:168 RmsProp 636 loss=112.012711 err=1.698284
I 2015-05-27 02:54:17 theanets.trainer:168 RmsProp 637 loss=111.837990 err=1.621323
I 2015-05-27 02:54:23 theanets.trainer:168 RmsProp 638 loss=111.896645 err=1.778269
I 2015-05-27 02:54:29 theanets.trainer:168 RmsProp 639 loss=111.520714 err=1.508366
I 2015-05-27 02:54:35 theanets.trainer:168 RmsProp 640 loss=111.539810 err=1.627271
I 2015-05-27 02:54:36 theanets.trainer:168 validation 64 loss=1296.961426 err=1187.107056
I 2015-05-27 02:54:42 theanets.trainer:168 RmsProp 641 loss=111.244919 err=1.437399
I 2015-05-27 02:54:48 theanets.trainer:168 RmsProp 642 loss=111.471817 err=1.761017
I 2015-05-27 02:54:54 theanets.trainer:168 RmsProp 643 loss=111.405869 err=1.798695
I 2015-05-27 02:55:01 theanets.trainer:168 RmsProp 644 loss=111.102013 err=1.591673
I 2015-05-27 02:55:08 theanets.trainer:168 RmsProp 645 loss=111.004662 err=1.593817
I 2015-05-27 02:55:14 theanets.trainer:168 RmsProp 646 loss=110.962997 err=1.648754
I 2015-05-27 02:55:20 theanets.trainer:168 RmsProp 647 loss=110.853043 err=1.638404
I 2015-05-27 02:55:26 theanets.trainer:168 RmsProp 648 loss=110.764854 err=1.650483
I 2015-05-27 02:55:32 theanets.trainer:168 RmsProp 649 loss=110.602859 err=1.583167
I 2015-05-27 02:55:38 theanets.trainer:168 RmsProp 650 loss=110.580444 err=1.661152
I 2015-05-27 02:55:39 theanets.trainer:168 validation 65 loss=1284.071289 err=1175.203369 *
I 2015-05-27 02:55:45 theanets.trainer:168 RmsProp 651 loss=110.496506 err=1.674201
I 2015-05-27 02:55:51 theanets.trainer:168 RmsProp 652 loss=110.274818 err=1.552563
I 2015-05-27 02:55:57 theanets.trainer:168 RmsProp 653 loss=110.577805 err=1.949403
I 2015-05-27 02:56:04 theanets.trainer:168 RmsProp 654 loss=110.127602 err=1.597360
I 2015-05-27 02:56:11 theanets.trainer:168 RmsProp 655 loss=110.000587 err=1.563824
I 2015-05-27 02:56:17 theanets.trainer:168 RmsProp 656 loss=109.936096 err=1.592690
I 2015-05-27 02:56:24 theanets.trainer:168 RmsProp 657 loss=109.970139 err=1.725186
I 2015-05-27 02:56:30 theanets.trainer:168 RmsProp 658 loss=109.614784 err=1.467276
I 2015-05-27 02:56:36 theanets.trainer:168 RmsProp 659 loss=109.931107 err=1.880171
I 2015-05-27 02:56:42 theanets.trainer:168 RmsProp 660 loss=109.482346 err=1.531687
I 2015-05-27 02:56:43 theanets.trainer:168 validation 66 loss=1292.334473 err=1184.423218
I 2015-05-27 02:56:49 theanets.trainer:168 RmsProp 661 loss=109.206467 err=1.355241
I 2015-05-27 02:56:55 theanets.trainer:168 RmsProp 662 loss=109.621033 err=1.864473
I 2015-05-27 02:57:02 theanets.trainer:168 RmsProp 663 loss=109.084702 err=1.426311
I 2015-05-27 02:57:09 theanets.trainer:168 RmsProp 664 loss=109.255173 err=1.694282
I 2015-05-27 02:57:15 theanets.trainer:168 RmsProp 665 loss=109.024918 err=1.562469
I 2015-05-27 02:57:21 theanets.trainer:168 RmsProp 666 loss=108.991882 err=1.626729
I 2015-05-27 02:57:28 theanets.trainer:168 RmsProp 667 loss=108.841537 err=1.570915
I 2015-05-27 02:57:33 theanets.trainer:168 RmsProp 668 loss=108.950783 err=1.771046
I 2015-05-27 02:57:40 theanets.trainer:168 RmsProp 669 loss=108.851524 err=1.765073
I 2015-05-27 02:57:47 theanets.trainer:168 RmsProp 670 loss=108.579819 err=1.583201
I 2015-05-27 02:57:47 theanets.trainer:168 validation 67 loss=1292.165405 err=1185.214966
I 2015-05-27 02:57:53 theanets.trainer:168 RmsProp 671 loss=108.508347 err=1.603982
I 2015-05-27 02:57:59 theanets.trainer:168 RmsProp 672 loss=108.414673 err=1.602874
I 2015-05-27 02:58:05 theanets.trainer:168 RmsProp 673 loss=108.494431 err=1.770732
I 2015-05-27 02:58:11 theanets.trainer:168 RmsProp 674 loss=108.096962 err=1.470124
I 2015-05-27 02:58:17 theanets.trainer:168 RmsProp 675 loss=108.162621 err=1.627771
I 2015-05-27 02:58:23 theanets.trainer:168 RmsProp 676 loss=107.949463 err=1.507485
I 2015-05-27 02:58:30 theanets.trainer:168 RmsProp 677 loss=108.061256 err=1.709786
I 2015-05-27 02:58:36 theanets.trainer:168 RmsProp 678 loss=107.894455 err=1.638943
I 2015-05-27 02:58:43 theanets.trainer:168 RmsProp 679 loss=107.526962 err=1.365353
I 2015-05-27 02:58:49 theanets.trainer:168 RmsProp 680 loss=107.914062 err=1.842119
I 2015-05-27 02:58:49 theanets.trainer:168 validation 68 loss=1294.570190 err=1188.547119
I 2015-05-27 02:58:55 theanets.trainer:168 RmsProp 681 loss=107.672340 err=1.688436
I 2015-05-27 02:59:01 theanets.trainer:168 RmsProp 682 loss=107.436844 err=1.544752
I 2015-05-27 02:59:07 theanets.trainer:168 RmsProp 683 loss=107.318993 err=1.519502
I 2015-05-27 02:59:14 theanets.trainer:168 RmsProp 684 loss=107.209946 err=1.502821
I 2015-05-27 02:59:19 theanets.trainer:168 RmsProp 685 loss=107.318710 err=1.699244
I 2015-05-27 02:59:26 theanets.trainer:168 RmsProp 686 loss=107.042702 err=1.515093
I 2015-05-27 02:59:32 theanets.trainer:168 RmsProp 687 loss=107.151634 err=1.714716
I 2015-05-27 02:59:39 theanets.trainer:168 RmsProp 688 loss=106.885155 err=1.540844
I 2015-05-27 02:59:45 theanets.trainer:168 RmsProp 689 loss=106.908730 err=1.651409
I 2015-05-27 02:59:51 theanets.trainer:168 RmsProp 690 loss=106.673927 err=1.507671
I 2015-05-27 02:59:52 theanets.trainer:168 validation 69 loss=1286.499146 err=1181.378052
I 2015-05-27 02:59:58 theanets.trainer:168 RmsProp 691 loss=106.899979 err=1.819243
I 2015-05-27 03:00:04 theanets.trainer:168 RmsProp 692 loss=106.573181 err=1.584562
I 2015-05-27 03:00:10 theanets.trainer:168 RmsProp 693 loss=106.415794 err=1.516328
I 2015-05-27 03:00:16 theanets.trainer:168 RmsProp 694 loss=106.527283 err=1.712861
I 2015-05-27 03:00:22 theanets.trainer:168 RmsProp 695 loss=106.249161 err=1.526440
I 2015-05-27 03:00:29 theanets.trainer:168 RmsProp 696 loss=106.415504 err=1.776772
I 2015-05-27 03:00:34 theanets.trainer:168 RmsProp 697 loss=105.852646 err=1.309009
I 2015-05-27 03:00:39 theanets.trainer:168 RmsProp 698 loss=106.278214 err=1.817521
I 2015-05-27 03:00:44 theanets.trainer:168 RmsProp 699 loss=105.967056 err=1.598474
I 2015-05-27 03:00:50 theanets.trainer:168 RmsProp 700 loss=105.713112 err=1.431721
I 2015-05-27 03:00:50 theanets.trainer:168 validation 70 loss=1290.020020 err=1185.779907
I 2015-05-27 03:00:50 theanets.trainer:252 patience elapsed!
I 2015-05-27 03:00:50 theanets.main:237 models_deep_post_code_sep/95111-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 03:00:50 theanets.graph:477 models_deep_post_code_sep/95111-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
