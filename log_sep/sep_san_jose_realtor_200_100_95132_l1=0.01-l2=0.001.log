I 2015-05-26 22:05:12 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:12 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95132-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:12 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:12 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:12 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:12 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:12 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:12 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:12 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:12 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:12 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:12 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:12 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:29 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:03 theano.gof.compilelock:266 Waiting for existing lock by process '29907' (I am process '29998')
I 2015-05-26 22:08:03 theano.gof.compilelock:268 To manually release the lock, delete /localdisk/qyou/.theano/compiledir_Linux-3.19-fc20.x86_64-x86_64-with-fedora-20-Heisenbug-x86_64-2.7.5-64/lock_dir
I 2015-05-26 22:08:17 theanets.trainer:168 validation 0 loss=14400.434570 err=14158.374023 *
I 2015-05-26 22:08:50 theanets.trainer:168 RmsProp 1 loss=13305.211914 err=13212.380859
I 2015-05-26 22:09:26 theanets.trainer:168 RmsProp 2 loss=13238.853516 err=13215.684570
I 2015-05-26 22:10:03 theanets.trainer:168 RmsProp 3 loss=12681.963867 err=12637.895508
I 2015-05-26 22:10:39 theanets.trainer:168 RmsProp 4 loss=11290.823242 err=11214.192383
I 2015-05-26 22:11:16 theanets.trainer:168 RmsProp 5 loss=10206.607422 err=10100.231445
I 2015-05-26 22:11:53 theanets.trainer:168 RmsProp 6 loss=9609.702148 err=9479.884766
I 2015-05-26 22:12:30 theanets.trainer:168 RmsProp 7 loss=9150.911133 err=8993.666016
I 2015-05-26 22:13:06 theanets.trainer:168 RmsProp 8 loss=8677.541016 err=8512.080078
I 2015-05-26 22:13:43 theanets.trainer:168 RmsProp 9 loss=8514.044922 err=8312.646484
I 2015-05-26 22:14:21 theanets.trainer:168 RmsProp 10 loss=7970.717285 err=7756.247070
I 2015-05-26 22:14:22 theanets.trainer:168 validation 1 loss=8108.579590 err=7891.542480 *
I 2015-05-26 22:14:59 theanets.trainer:168 RmsProp 11 loss=7664.106445 err=7440.828613
I 2015-05-26 22:15:37 theanets.trainer:168 RmsProp 12 loss=7345.092773 err=7108.920898
I 2015-05-26 22:16:15 theanets.trainer:168 RmsProp 13 loss=6970.313965 err=6720.298828
I 2015-05-26 22:16:52 theanets.trainer:168 RmsProp 14 loss=6863.572754 err=6596.326660
I 2015-05-26 22:17:30 theanets.trainer:168 RmsProp 15 loss=6617.172363 err=6333.302246
I 2015-05-26 22:18:07 theanets.trainer:168 RmsProp 16 loss=6371.368164 err=6071.270996
I 2015-05-26 22:18:43 theanets.trainer:168 RmsProp 17 loss=6090.099121 err=5774.084961
I 2015-05-26 22:19:20 theanets.trainer:168 RmsProp 18 loss=5813.334473 err=5479.909180
I 2015-05-26 22:19:57 theanets.trainer:168 RmsProp 19 loss=5517.014160 err=5166.948730
I 2015-05-26 22:20:34 theanets.trainer:168 RmsProp 20 loss=5230.150391 err=4863.898438
I 2015-05-26 22:20:35 theanets.trainer:168 validation 2 loss=5660.575684 err=5286.545898 *
I 2015-05-26 22:21:12 theanets.trainer:168 RmsProp 21 loss=5015.749023 err=4635.393555
I 2015-05-26 22:21:49 theanets.trainer:168 RmsProp 22 loss=4837.013184 err=4442.502441
I 2015-05-26 22:22:26 theanets.trainer:168 RmsProp 23 loss=4621.018066 err=4213.405273
I 2015-05-26 22:23:03 theanets.trainer:168 RmsProp 24 loss=4494.528320 err=4072.773926
I 2015-05-26 22:23:39 theanets.trainer:168 RmsProp 25 loss=4343.457031 err=3909.664795
I 2015-05-26 22:24:16 theanets.trainer:168 RmsProp 26 loss=4208.549316 err=3763.243408
I 2015-05-26 22:24:53 theanets.trainer:168 RmsProp 27 loss=4120.516113 err=3662.854004
I 2015-05-26 22:25:30 theanets.trainer:168 RmsProp 28 loss=4005.834717 err=3537.403809
I 2015-05-26 22:26:07 theanets.trainer:168 RmsProp 29 loss=3857.767334 err=3383.067139
I 2015-05-26 22:26:44 theanets.trainer:168 RmsProp 30 loss=3735.651123 err=3253.403320
I 2015-05-26 22:26:45 theanets.trainer:168 validation 3 loss=4239.839844 err=3754.257080 *
I 2015-05-26 22:27:22 theanets.trainer:168 RmsProp 31 loss=3615.286621 err=3126.330322
I 2015-05-26 22:27:59 theanets.trainer:168 RmsProp 32 loss=3546.485840 err=3049.795166
I 2015-05-26 22:28:37 theanets.trainer:168 RmsProp 33 loss=3507.937256 err=3001.813477
I 2015-05-26 22:29:15 theanets.trainer:168 RmsProp 34 loss=3375.557129 err=2861.692383
I 2015-05-26 22:29:53 theanets.trainer:168 RmsProp 35 loss=3332.642334 err=2812.007080
I 2015-05-26 22:30:31 theanets.trainer:168 RmsProp 36 loss=3214.442139 err=2687.506104
I 2015-05-26 22:31:08 theanets.trainer:168 RmsProp 37 loss=3197.903809 err=2663.253906
I 2015-05-26 22:31:46 theanets.trainer:168 RmsProp 38 loss=3138.384033 err=2597.340820
I 2015-05-26 22:32:23 theanets.trainer:168 RmsProp 39 loss=3106.716309 err=2560.275879
I 2015-05-26 22:33:01 theanets.trainer:168 RmsProp 40 loss=3034.353027 err=2483.450684
I 2015-05-26 22:33:02 theanets.trainer:168 validation 4 loss=3681.932861 err=3128.705811 *
I 2015-05-26 22:33:39 theanets.trainer:168 RmsProp 41 loss=2992.761963 err=2437.120850
I 2015-05-26 22:34:15 theanets.trainer:168 RmsProp 42 loss=3036.745361 err=2473.912598
I 2015-05-26 22:34:52 theanets.trainer:168 RmsProp 43 loss=2973.513916 err=2403.766357
I 2015-05-26 22:35:30 theanets.trainer:168 RmsProp 44 loss=2875.119629 err=2302.211426
I 2015-05-26 22:36:06 theanets.trainer:168 RmsProp 45 loss=2846.345459 err=2267.768311
I 2015-05-26 22:36:42 theanets.trainer:168 RmsProp 46 loss=2829.304443 err=2245.162354
I 2015-05-26 22:37:19 theanets.trainer:168 RmsProp 47 loss=2823.429443 err=2232.681885
I 2015-05-26 22:37:56 theanets.trainer:168 RmsProp 48 loss=2742.195312 err=2148.121338
I 2015-05-26 22:38:32 theanets.trainer:168 RmsProp 49 loss=2686.504395 err=2088.945557
I 2015-05-26 22:39:09 theanets.trainer:168 RmsProp 50 loss=2686.812988 err=2083.657471
I 2015-05-26 22:39:09 theanets.trainer:168 validation 5 loss=3596.971436 err=2991.276367 *
I 2015-05-26 22:39:46 theanets.trainer:168 RmsProp 51 loss=2666.629883 err=2059.253418
I 2015-05-26 22:40:22 theanets.trainer:168 RmsProp 52 loss=2596.793701 err=1985.143799
I 2015-05-26 22:40:59 theanets.trainer:168 RmsProp 53 loss=2646.235352 err=2029.165283
I 2015-05-26 22:41:35 theanets.trainer:168 RmsProp 54 loss=2568.114746 err=1946.147705
I 2015-05-26 22:42:12 theanets.trainer:168 RmsProp 55 loss=2535.432617 err=1910.698486
I 2015-05-26 22:42:49 theanets.trainer:168 RmsProp 56 loss=2512.592529 err=1885.716919
I 2015-05-26 22:43:26 theanets.trainer:168 RmsProp 57 loss=2531.265137 err=1900.061157
I 2015-05-26 22:44:02 theanets.trainer:168 RmsProp 58 loss=2561.667236 err=1924.072510
I 2015-05-26 22:44:40 theanets.trainer:168 RmsProp 59 loss=2486.597900 err=1845.458862
I 2015-05-26 22:45:18 theanets.trainer:168 RmsProp 60 loss=2516.609131 err=1871.905151
I 2015-05-26 22:45:19 theanets.trainer:168 validation 6 loss=3504.735596 err=2858.098389 *
I 2015-05-26 22:45:56 theanets.trainer:168 RmsProp 61 loss=2507.139160 err=1859.093140
I 2015-05-26 22:46:32 theanets.trainer:168 RmsProp 62 loss=2542.649902 err=1890.142456
I 2015-05-26 22:47:08 theanets.trainer:168 RmsProp 63 loss=2505.977295 err=1849.198730
I 2015-05-26 22:47:45 theanets.trainer:168 RmsProp 64 loss=2469.967041 err=1810.133667
I 2015-05-26 22:48:21 theanets.trainer:168 RmsProp 65 loss=2422.277588 err=1757.742188
I 2015-05-26 22:48:57 theanets.trainer:168 RmsProp 66 loss=2492.683594 err=1823.885620
I 2015-05-26 22:49:33 theanets.trainer:168 RmsProp 67 loss=2458.422852 err=1785.638916
I 2015-05-26 22:50:10 theanets.trainer:168 RmsProp 68 loss=2423.824707 err=1745.589111
I 2015-05-26 22:50:47 theanets.trainer:168 RmsProp 69 loss=2412.618164 err=1732.914673
I 2015-05-26 22:51:24 theanets.trainer:168 RmsProp 70 loss=2503.385742 err=1816.720337
I 2015-05-26 22:51:25 theanets.trainer:168 validation 7 loss=3468.397217 err=2779.530518 *
I 2015-05-26 22:52:02 theanets.trainer:168 RmsProp 71 loss=2488.165527 err=1796.060181
I 2015-05-26 22:52:38 theanets.trainer:168 RmsProp 72 loss=2400.250244 err=1707.402588
I 2015-05-26 22:53:15 theanets.trainer:168 RmsProp 73 loss=2353.524414 err=1660.724854
I 2015-05-26 22:53:54 theanets.trainer:168 RmsProp 74 loss=2347.820557 err=1652.786255
I 2015-05-26 22:54:33 theanets.trainer:168 RmsProp 75 loss=2327.017090 err=1630.798584
I 2015-05-26 22:55:10 theanets.trainer:168 RmsProp 76 loss=2327.156982 err=1628.809937
I 2015-05-26 22:55:47 theanets.trainer:168 RmsProp 77 loss=2326.920898 err=1625.639893
I 2015-05-26 22:56:24 theanets.trainer:168 RmsProp 78 loss=2308.464844 err=1604.994507
I 2015-05-26 22:57:01 theanets.trainer:168 RmsProp 79 loss=2315.104004 err=1609.944214
I 2015-05-26 22:57:39 theanets.trainer:168 RmsProp 80 loss=2276.928711 err=1569.785278
I 2015-05-26 22:57:40 theanets.trainer:168 validation 8 loss=3380.416016 err=2673.065186 *
I 2015-05-26 22:58:18 theanets.trainer:168 RmsProp 81 loss=2221.490479 err=1513.386719
I 2015-05-26 22:58:55 theanets.trainer:168 RmsProp 82 loss=2369.665283 err=1655.015503
I 2015-05-26 22:59:32 theanets.trainer:168 RmsProp 83 loss=2306.479736 err=1584.764404
I 2015-05-26 23:00:07 theanets.trainer:168 RmsProp 84 loss=2278.016357 err=1555.947998
I 2015-05-26 23:00:43 theanets.trainer:168 RmsProp 85 loss=2247.222656 err=1523.683960
I 2015-05-26 23:01:20 theanets.trainer:168 RmsProp 86 loss=2407.404541 err=1678.243896
I 2015-05-26 23:01:57 theanets.trainer:168 RmsProp 87 loss=2458.994385 err=1717.154907
I 2015-05-26 23:02:34 theanets.trainer:168 RmsProp 88 loss=2326.201416 err=1583.284058
I 2015-05-26 23:03:12 theanets.trainer:168 RmsProp 89 loss=2334.118408 err=1591.191528
I 2015-05-26 23:03:50 theanets.trainer:168 RmsProp 90 loss=2286.636475 err=1543.291748
I 2015-05-26 23:03:51 theanets.trainer:168 validation 9 loss=2885.096436 err=2142.177246 *
I 2015-05-26 23:04:27 theanets.trainer:168 RmsProp 91 loss=2264.611572 err=1520.395386
I 2015-05-26 23:05:04 theanets.trainer:168 RmsProp 92 loss=2255.383545 err=1509.039551
I 2015-05-26 23:05:41 theanets.trainer:168 RmsProp 93 loss=2202.261475 err=1457.079834
I 2015-05-26 23:06:16 theanets.trainer:168 RmsProp 94 loss=2223.527344 err=1477.268677
I 2015-05-26 23:06:53 theanets.trainer:168 RmsProp 95 loss=2229.666748 err=1480.994995
I 2015-05-26 23:07:31 theanets.trainer:168 RmsProp 96 loss=2165.702148 err=1417.288452
I 2015-05-26 23:08:08 theanets.trainer:168 RmsProp 97 loss=2307.750732 err=1554.380737
I 2015-05-26 23:08:46 theanets.trainer:168 RmsProp 98 loss=2205.513184 err=1448.150024
I 2015-05-26 23:09:23 theanets.trainer:168 RmsProp 99 loss=1922.089355 err=1165.894409
I 2015-05-26 23:10:00 theanets.trainer:168 RmsProp 100 loss=1933.869751 err=1173.710083
I 2015-05-26 23:10:01 theanets.trainer:168 validation 10 loss=2390.611328 err=1630.594604 *
I 2015-05-26 23:10:37 theanets.trainer:168 RmsProp 101 loss=1901.585083 err=1142.729858
I 2015-05-26 23:11:13 theanets.trainer:168 RmsProp 102 loss=1830.199341 err=1073.952881
I 2015-05-26 23:11:49 theanets.trainer:168 RmsProp 103 loss=1687.559326 err=942.794983
I 2015-05-26 23:12:25 theanets.trainer:168 RmsProp 104 loss=1632.666260 err=898.626831
I 2015-05-26 23:13:02 theanets.trainer:168 RmsProp 105 loss=1575.274536 err=850.375244
I 2015-05-26 23:13:38 theanets.trainer:168 RmsProp 106 loss=1549.362915 err=832.484009
I 2015-05-26 23:14:15 theanets.trainer:168 RmsProp 107 loss=1529.731079 err=818.943481
I 2015-05-26 23:14:53 theanets.trainer:168 RmsProp 108 loss=1516.047363 err=810.486633
I 2015-05-26 23:15:30 theanets.trainer:168 RmsProp 109 loss=1495.413330 err=794.598022
I 2015-05-26 23:16:07 theanets.trainer:168 RmsProp 110 loss=1478.060669 err=781.406006
I 2015-05-26 23:16:08 theanets.trainer:168 validation 11 loss=2343.328125 err=1648.556030 *
I 2015-05-26 23:16:45 theanets.trainer:168 RmsProp 111 loss=1471.729736 err=778.613953
I 2015-05-26 23:17:21 theanets.trainer:168 RmsProp 112 loss=1451.386597 err=762.086304
I 2015-05-26 23:17:57 theanets.trainer:168 RmsProp 113 loss=1441.067505 err=755.184998
I 2015-05-26 23:18:33 theanets.trainer:168 RmsProp 114 loss=1420.965942 err=738.713745
I 2015-05-26 23:19:08 theanets.trainer:168 RmsProp 115 loss=1415.503174 err=736.763550
I 2015-05-26 23:19:44 theanets.trainer:168 RmsProp 116 loss=1406.613770 err=730.781433
I 2015-05-26 23:20:19 theanets.trainer:168 RmsProp 117 loss=1401.656006 err=728.209961
I 2015-05-26 23:20:55 theanets.trainer:168 RmsProp 118 loss=1382.235229 err=711.572571
I 2015-05-26 23:21:31 theanets.trainer:168 RmsProp 119 loss=1372.595703 err=704.763916
I 2015-05-26 23:22:07 theanets.trainer:168 RmsProp 120 loss=1360.847290 err=695.682373
I 2015-05-26 23:22:08 theanets.trainer:168 validation 12 loss=2302.978760 err=1638.908569 *
I 2015-05-26 23:22:44 theanets.trainer:168 RmsProp 121 loss=1369.342285 err=706.066956
I 2015-05-26 23:23:22 theanets.trainer:168 RmsProp 122 loss=1343.025146 err=681.861572
I 2015-05-26 23:23:59 theanets.trainer:168 RmsProp 123 loss=1340.334717 err=681.552490
I 2015-05-26 23:24:36 theanets.trainer:168 RmsProp 124 loss=1349.278931 err=691.668030
I 2015-05-26 23:25:12 theanets.trainer:168 RmsProp 125 loss=1332.709473 err=677.003601
I 2015-05-26 23:25:49 theanets.trainer:168 RmsProp 126 loss=1324.691406 err=670.720459
I 2015-05-26 23:26:25 theanets.trainer:168 RmsProp 127 loss=1314.488159 err=662.532166
I 2015-05-26 23:27:02 theanets.trainer:168 RmsProp 128 loss=1302.632690 err=652.497986
I 2015-05-26 23:27:38 theanets.trainer:168 RmsProp 129 loss=1302.360107 err=654.012451
I 2015-05-26 23:28:15 theanets.trainer:168 RmsProp 130 loss=1287.720337 err=640.683289
I 2015-05-26 23:28:16 theanets.trainer:168 validation 13 loss=2285.183350 err=1639.314453 *
I 2015-05-26 23:28:53 theanets.trainer:168 RmsProp 131 loss=1286.614380 err=641.519653
I 2015-05-26 23:29:29 theanets.trainer:168 RmsProp 132 loss=1292.917847 err=648.949951
I 2015-05-26 23:30:06 theanets.trainer:168 RmsProp 133 loss=1288.119507 err=644.950745
I 2015-05-26 23:30:43 theanets.trainer:168 RmsProp 134 loss=1283.651123 err=641.166138
I 2015-05-26 23:31:20 theanets.trainer:168 RmsProp 135 loss=1278.312378 err=636.245667
I 2015-05-26 23:31:57 theanets.trainer:168 RmsProp 136 loss=1279.145630 err=638.166382
I 2015-05-26 23:32:33 theanets.trainer:168 RmsProp 137 loss=1268.339233 err=628.078674
I 2015-05-26 23:33:09 theanets.trainer:168 RmsProp 138 loss=1264.674072 err=625.283386
I 2015-05-26 23:33:46 theanets.trainer:168 RmsProp 139 loss=1269.809204 err=631.313782
I 2015-05-26 23:34:22 theanets.trainer:168 RmsProp 140 loss=1266.682861 err=628.293762
I 2015-05-26 23:34:23 theanets.trainer:168 validation 14 loss=2275.783203 err=1637.133423 *
I 2015-05-26 23:35:00 theanets.trainer:168 RmsProp 141 loss=1268.204956 err=629.219666
I 2015-05-26 23:35:36 theanets.trainer:168 RmsProp 142 loss=1280.098755 err=640.841980
I 2015-05-26 23:36:12 theanets.trainer:168 RmsProp 143 loss=1288.316406 err=648.021057
I 2015-05-26 23:36:48 theanets.trainer:168 RmsProp 144 loss=1282.176636 err=642.539917
I 2015-05-26 23:37:25 theanets.trainer:168 RmsProp 145 loss=1259.653442 err=620.622742
I 2015-05-26 23:38:02 theanets.trainer:168 RmsProp 146 loss=1247.424438 err=610.774414
I 2015-05-26 23:38:40 theanets.trainer:168 RmsProp 147 loss=1247.975342 err=611.913757
I 2015-05-26 23:39:16 theanets.trainer:168 RmsProp 148 loss=1262.300049 err=626.497681
I 2015-05-26 23:39:52 theanets.trainer:168 RmsProp 149 loss=1254.544189 err=619.271667
I 2015-05-26 23:40:28 theanets.trainer:168 RmsProp 150 loss=1263.859497 err=628.263062
I 2015-05-26 23:40:29 theanets.trainer:168 validation 15 loss=2243.414307 err=1606.668823 *
I 2015-05-26 23:41:06 theanets.trainer:168 RmsProp 151 loss=1303.253540 err=664.368164
I 2015-05-26 23:41:43 theanets.trainer:168 RmsProp 152 loss=1281.545532 err=641.406433
I 2015-05-26 23:42:21 theanets.trainer:168 RmsProp 153 loss=1287.295532 err=647.727844
I 2015-05-26 23:42:58 theanets.trainer:168 RmsProp 154 loss=1300.844360 err=660.320923
I 2015-05-26 23:43:35 theanets.trainer:168 RmsProp 155 loss=1278.214844 err=637.129028
I 2015-05-26 23:44:12 theanets.trainer:168 RmsProp 156 loss=1287.615967 err=645.618591
I 2015-05-26 23:44:48 theanets.trainer:168 RmsProp 157 loss=1294.768677 err=650.884399
I 2015-05-26 23:45:25 theanets.trainer:168 RmsProp 158 loss=1279.172363 err=636.114868
I 2015-05-26 23:46:02 theanets.trainer:168 RmsProp 159 loss=1256.247559 err=614.043823
I 2015-05-26 23:46:38 theanets.trainer:168 RmsProp 160 loss=1248.580444 err=608.348450
I 2015-05-26 23:46:38 theanets.trainer:168 validation 16 loss=2232.000732 err=1592.459595 *
I 2015-05-26 23:47:13 theanets.trainer:168 RmsProp 161 loss=1251.446167 err=611.751831
I 2015-05-26 23:47:48 theanets.trainer:168 RmsProp 162 loss=1244.728638 err=605.391602
I 2015-05-26 23:48:22 theanets.trainer:168 RmsProp 163 loss=1234.033813 err=594.956238
I 2015-05-26 23:48:57 theanets.trainer:168 RmsProp 164 loss=1232.705688 err=595.166260
I 2015-05-26 23:49:33 theanets.trainer:168 RmsProp 165 loss=1229.462524 err=592.586914
I 2015-05-26 23:50:09 theanets.trainer:168 RmsProp 166 loss=1225.307739 err=589.538208
I 2015-05-26 23:50:45 theanets.trainer:168 RmsProp 167 loss=1235.097412 err=599.476440
I 2015-05-26 23:51:20 theanets.trainer:168 RmsProp 168 loss=1234.753174 err=598.610901
I 2015-05-26 23:51:55 theanets.trainer:168 RmsProp 169 loss=1221.226929 err=585.910034
I 2015-05-26 23:52:29 theanets.trainer:168 RmsProp 170 loss=1231.513306 err=596.974304
I 2015-05-26 23:52:30 theanets.trainer:168 validation 17 loss=2255.354248 err=1621.062866
I 2015-05-26 23:53:05 theanets.trainer:168 RmsProp 171 loss=1213.372681 err=579.245789
I 2015-05-26 23:53:40 theanets.trainer:168 RmsProp 172 loss=1219.593506 err=586.009338
I 2015-05-26 23:54:15 theanets.trainer:168 RmsProp 173 loss=1219.847046 err=585.289734
I 2015-05-26 23:54:51 theanets.trainer:168 RmsProp 174 loss=1223.761963 err=589.018799
I 2015-05-26 23:55:27 theanets.trainer:168 RmsProp 175 loss=1223.093506 err=587.755005
I 2015-05-26 23:56:03 theanets.trainer:168 RmsProp 176 loss=1205.851685 err=571.086182
I 2015-05-26 23:56:38 theanets.trainer:168 RmsProp 177 loss=1211.357910 err=576.674377
I 2015-05-26 23:57:14 theanets.trainer:168 RmsProp 178 loss=1196.890747 err=563.675110
I 2015-05-26 23:57:49 theanets.trainer:168 RmsProp 179 loss=1191.504639 err=559.602783
I 2015-05-26 23:58:24 theanets.trainer:168 RmsProp 180 loss=1219.396118 err=586.231262
I 2015-05-26 23:58:25 theanets.trainer:168 validation 18 loss=2193.317627 err=1559.053101 *
I 2015-05-26 23:59:00 theanets.trainer:168 RmsProp 181 loss=1236.666382 err=602.131592
I 2015-05-26 23:59:36 theanets.trainer:168 RmsProp 182 loss=1245.431763 err=609.303589
I 2015-05-27 00:00:13 theanets.trainer:168 RmsProp 183 loss=1226.375732 err=589.835571
I 2015-05-27 00:00:49 theanets.trainer:168 RmsProp 184 loss=1217.586426 err=581.966614
I 2015-05-27 00:01:25 theanets.trainer:168 RmsProp 185 loss=1209.076050 err=574.450073
I 2015-05-27 00:02:01 theanets.trainer:168 RmsProp 186 loss=1209.069946 err=574.175781
I 2015-05-27 00:02:36 theanets.trainer:168 RmsProp 187 loss=1217.235840 err=582.326355
I 2015-05-27 00:03:11 theanets.trainer:168 RmsProp 188 loss=1219.751343 err=583.809814
I 2015-05-27 00:03:47 theanets.trainer:168 RmsProp 189 loss=1211.258545 err=575.523621
I 2015-05-27 00:04:23 theanets.trainer:168 RmsProp 190 loss=1207.648438 err=572.300476
I 2015-05-27 00:04:24 theanets.trainer:168 validation 19 loss=2236.067383 err=1601.131470
I 2015-05-27 00:04:58 theanets.trainer:168 RmsProp 191 loss=1198.066040 err=563.445923
I 2015-05-27 00:05:33 theanets.trainer:168 RmsProp 192 loss=1196.062134 err=561.811279
I 2015-05-27 00:06:08 theanets.trainer:168 RmsProp 193 loss=1198.781250 err=564.445862
I 2015-05-27 00:06:44 theanets.trainer:168 RmsProp 194 loss=1193.481934 err=559.444031
I 2015-05-27 00:07:20 theanets.trainer:168 RmsProp 195 loss=1181.984009 err=548.807678
I 2015-05-27 00:07:56 theanets.trainer:168 RmsProp 196 loss=1210.516846 err=576.522095
I 2015-05-27 00:08:31 theanets.trainer:168 RmsProp 197 loss=1233.446411 err=596.696472
I 2015-05-27 00:09:07 theanets.trainer:168 RmsProp 198 loss=1247.775024 err=608.276306
I 2015-05-27 00:09:42 theanets.trainer:168 RmsProp 199 loss=1236.141357 err=595.865540
I 2015-05-27 00:10:18 theanets.trainer:168 RmsProp 200 loss=1222.401855 err=583.276428
I 2015-05-27 00:10:18 theanets.trainer:168 validation 20 loss=2219.057373 err=1579.963257
I 2015-05-27 00:10:53 theanets.trainer:168 RmsProp 201 loss=1235.788574 err=595.536560
I 2015-05-27 00:11:27 theanets.trainer:168 RmsProp 202 loss=1205.432373 err=565.200989
I 2015-05-27 00:12:00 theanets.trainer:168 RmsProp 203 loss=1183.819092 err=546.517456
I 2015-05-27 00:12:33 theanets.trainer:168 RmsProp 204 loss=1180.580933 err=544.580811
I 2015-05-27 00:13:07 theanets.trainer:168 RmsProp 205 loss=1220.290283 err=583.360352
I 2015-05-27 00:13:41 theanets.trainer:168 RmsProp 206 loss=1248.467896 err=607.358826
I 2015-05-27 00:14:14 theanets.trainer:168 RmsProp 207 loss=1266.301147 err=622.754028
I 2015-05-27 00:14:47 theanets.trainer:168 RmsProp 208 loss=1259.066406 err=611.221558
I 2015-05-27 00:15:20 theanets.trainer:168 RmsProp 209 loss=1218.705444 err=571.672180
I 2015-05-27 00:15:53 theanets.trainer:168 RmsProp 210 loss=1211.292114 err=566.602478
I 2015-05-27 00:15:54 theanets.trainer:168 validation 21 loss=2226.372559 err=1582.220703
I 2015-05-27 00:16:26 theanets.trainer:168 RmsProp 211 loss=1204.663696 err=561.235535
I 2015-05-27 00:16:59 theanets.trainer:168 RmsProp 212 loss=1182.197754 err=540.694275
I 2015-05-27 00:17:33 theanets.trainer:168 RmsProp 213 loss=1203.404297 err=562.551636
I 2015-05-27 00:18:06 theanets.trainer:168 RmsProp 214 loss=1205.514526 err=563.328247
I 2015-05-27 00:18:39 theanets.trainer:168 RmsProp 215 loss=1249.819092 err=605.354492
I 2015-05-27 00:19:12 theanets.trainer:168 RmsProp 216 loss=1252.265747 err=603.646545
I 2015-05-27 00:19:46 theanets.trainer:168 RmsProp 217 loss=1218.408936 err=570.592224
I 2015-05-27 00:20:19 theanets.trainer:168 RmsProp 218 loss=1225.394043 err=578.121338
I 2015-05-27 00:20:52 theanets.trainer:168 RmsProp 219 loss=1226.393188 err=578.063660
I 2015-05-27 00:21:26 theanets.trainer:168 RmsProp 220 loss=1201.424561 err=554.120117
I 2015-05-27 00:21:27 theanets.trainer:168 validation 22 loss=2211.230713 err=1565.103149
I 2015-05-27 00:22:00 theanets.trainer:168 RmsProp 221 loss=1201.623901 err=556.007629
I 2015-05-27 00:22:33 theanets.trainer:168 RmsProp 222 loss=1219.053223 err=572.228210
I 2015-05-27 00:23:07 theanets.trainer:168 RmsProp 223 loss=1187.119995 err=541.393738
I 2015-05-27 00:23:40 theanets.trainer:168 RmsProp 224 loss=1176.229980 err=532.900452
I 2015-05-27 00:24:14 theanets.trainer:168 RmsProp 225 loss=1187.788818 err=544.836548
I 2015-05-27 00:24:47 theanets.trainer:168 RmsProp 226 loss=1172.923218 err=530.521240
I 2015-05-27 00:25:20 theanets.trainer:168 RmsProp 227 loss=1168.872803 err=527.051208
I 2015-05-27 00:25:53 theanets.trainer:168 RmsProp 228 loss=1165.847900 err=524.940735
I 2015-05-27 00:26:27 theanets.trainer:168 RmsProp 229 loss=1162.101562 err=521.393738
I 2015-05-27 00:26:59 theanets.trainer:168 RmsProp 230 loss=1161.959839 err=522.092407
I 2015-05-27 00:27:00 theanets.trainer:168 validation 23 loss=2182.868408 err=1543.257690 *
I 2015-05-27 00:27:31 theanets.trainer:168 RmsProp 231 loss=1163.503662 err=523.806641
I 2015-05-27 00:28:03 theanets.trainer:168 RmsProp 232 loss=1198.038208 err=556.751038
I 2015-05-27 00:28:34 theanets.trainer:168 RmsProp 233 loss=1201.000488 err=555.712524
I 2015-05-27 00:29:07 theanets.trainer:168 RmsProp 234 loss=1197.009644 err=551.408142
I 2015-05-27 00:29:40 theanets.trainer:168 RmsProp 235 loss=1191.838623 err=546.258179
I 2015-05-27 00:30:13 theanets.trainer:168 RmsProp 236 loss=1193.664795 err=547.936401
I 2015-05-27 00:30:45 theanets.trainer:168 RmsProp 237 loss=1185.868896 err=539.590515
I 2015-05-27 00:31:18 theanets.trainer:168 RmsProp 238 loss=1167.918457 err=522.037903
I 2015-05-27 00:31:51 theanets.trainer:168 RmsProp 239 loss=1153.835693 err=509.788696
I 2015-05-27 00:32:24 theanets.trainer:168 RmsProp 240 loss=1162.262207 err=518.428528
I 2015-05-27 00:32:24 theanets.trainer:168 validation 24 loss=2174.479980 err=1530.623657 *
I 2015-05-27 00:32:58 theanets.trainer:168 RmsProp 241 loss=1161.864868 err=518.104980
I 2015-05-27 00:33:31 theanets.trainer:168 RmsProp 242 loss=1170.026855 err=525.612854
I 2015-05-27 00:34:04 theanets.trainer:168 RmsProp 243 loss=1166.976562 err=521.764771
I 2015-05-27 00:34:38 theanets.trainer:168 RmsProp 244 loss=1149.234253 err=505.706360
I 2015-05-27 00:35:11 theanets.trainer:168 RmsProp 245 loss=1152.868286 err=509.892700
I 2015-05-27 00:35:45 theanets.trainer:168 RmsProp 246 loss=1166.484619 err=523.175781
I 2015-05-27 00:36:18 theanets.trainer:168 RmsProp 247 loss=1170.691895 err=526.234741
I 2015-05-27 00:36:50 theanets.trainer:168 RmsProp 248 loss=1150.280640 err=506.837402
I 2015-05-27 00:37:23 theanets.trainer:168 RmsProp 249 loss=1143.825317 err=501.227203
I 2015-05-27 00:37:57 theanets.trainer:168 RmsProp 250 loss=1153.822266 err=510.586853
I 2015-05-27 00:37:58 theanets.trainer:168 validation 25 loss=2197.400391 err=1553.465210
I 2015-05-27 00:38:31 theanets.trainer:168 RmsProp 251 loss=1142.263184 err=498.714386
I 2015-05-27 00:39:04 theanets.trainer:168 RmsProp 252 loss=1142.027832 err=499.013641
I 2015-05-27 00:39:36 theanets.trainer:168 RmsProp 253 loss=1151.650146 err=507.561676
I 2015-05-27 00:40:09 theanets.trainer:168 RmsProp 254 loss=1127.801025 err=484.412079
I 2015-05-27 00:40:42 theanets.trainer:168 RmsProp 255 loss=1139.053955 err=496.285370
I 2015-05-27 00:41:15 theanets.trainer:168 RmsProp 256 loss=1137.500366 err=494.894012
I 2015-05-27 00:41:48 theanets.trainer:168 RmsProp 257 loss=1129.513062 err=487.332886
I 2015-05-27 00:42:21 theanets.trainer:168 RmsProp 258 loss=1120.154663 err=479.139343
I 2015-05-27 00:42:54 theanets.trainer:168 RmsProp 259 loss=1110.162109 err=470.794617
I 2015-05-27 00:43:27 theanets.trainer:168 RmsProp 260 loss=1117.633545 err=478.616852
I 2015-05-27 00:43:28 theanets.trainer:168 validation 26 loss=2232.006592 err=1592.728882
I 2015-05-27 00:44:00 theanets.trainer:168 RmsProp 261 loss=1121.827026 err=482.105347
I 2015-05-27 00:44:32 theanets.trainer:168 RmsProp 262 loss=1103.042725 err=464.832581
I 2015-05-27 00:45:04 theanets.trainer:168 RmsProp 263 loss=1118.026978 err=479.983185
I 2015-05-27 00:45:37 theanets.trainer:168 RmsProp 264 loss=1107.256958 err=469.514587
I 2015-05-27 00:46:10 theanets.trainer:168 RmsProp 265 loss=1095.705933 err=459.160431
I 2015-05-27 00:46:43 theanets.trainer:168 RmsProp 266 loss=1095.967041 err=460.750000
I 2015-05-27 00:47:17 theanets.trainer:168 RmsProp 267 loss=1109.737671 err=474.406036
I 2015-05-27 00:47:51 theanets.trainer:168 RmsProp 268 loss=1110.581299 err=474.869049
I 2015-05-27 00:48:25 theanets.trainer:168 RmsProp 269 loss=1096.552124 err=460.832611
I 2015-05-27 00:48:58 theanets.trainer:168 RmsProp 270 loss=1120.764893 err=484.126892
I 2015-05-27 00:48:59 theanets.trainer:168 validation 27 loss=2216.554932 err=1578.459473
I 2015-05-27 00:49:33 theanets.trainer:168 RmsProp 271 loss=1114.973145 err=476.787079
I 2015-05-27 00:50:06 theanets.trainer:168 RmsProp 272 loss=1119.235229 err=481.274902
I 2015-05-27 00:50:40 theanets.trainer:168 RmsProp 273 loss=1103.316284 err=465.875824
I 2015-05-27 00:51:13 theanets.trainer:168 RmsProp 274 loss=1109.988770 err=473.969238
I 2015-05-27 00:51:47 theanets.trainer:168 RmsProp 275 loss=1175.793457 err=532.664490
I 2015-05-27 00:52:20 theanets.trainer:168 RmsProp 276 loss=1135.279175 err=492.545227
I 2015-05-27 00:52:54 theanets.trainer:168 RmsProp 277 loss=1113.662720 err=473.857239
I 2015-05-27 00:53:27 theanets.trainer:168 RmsProp 278 loss=1100.131958 err=461.890442
I 2015-05-27 00:54:00 theanets.trainer:168 RmsProp 279 loss=1101.994385 err=464.652496
I 2015-05-27 00:54:33 theanets.trainer:168 RmsProp 280 loss=1084.285889 err=448.960571
I 2015-05-27 00:54:33 theanets.trainer:168 validation 28 loss=2192.617920 err=1558.235718
I 2015-05-27 00:55:06 theanets.trainer:168 RmsProp 281 loss=1076.758911 err=443.351685
I 2015-05-27 00:55:39 theanets.trainer:168 RmsProp 282 loss=1078.393188 err=446.606964
I 2015-05-27 00:56:12 theanets.trainer:168 RmsProp 283 loss=1079.028076 err=447.925415
I 2015-05-27 00:56:46 theanets.trainer:168 RmsProp 284 loss=1069.845215 err=440.252350
I 2015-05-27 00:57:19 theanets.trainer:168 RmsProp 285 loss=1072.615356 err=443.269806
I 2015-05-27 00:57:52 theanets.trainer:168 RmsProp 286 loss=1079.984985 err=450.874176
I 2015-05-27 00:58:25 theanets.trainer:168 RmsProp 287 loss=1079.948120 err=450.212219
I 2015-05-27 00:58:57 theanets.trainer:168 RmsProp 288 loss=1069.610352 err=441.023224
I 2015-05-27 00:59:30 theanets.trainer:168 RmsProp 289 loss=1083.613647 err=454.540680
I 2015-05-27 01:00:03 theanets.trainer:168 RmsProp 290 loss=1065.987671 err=437.935883
I 2015-05-27 01:00:03 theanets.trainer:168 validation 29 loss=2186.685547 err=1559.910034
I 2015-05-27 01:00:03 theanets.trainer:252 patience elapsed!
I 2015-05-27 01:00:03 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 01:00:03 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 01:00:03 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 01:00:03 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 01:00:03 theanets.main:89 --batch_size = 1024
I 2015-05-27 01:00:03 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 01:00:03 theanets.main:89 --hidden_l1 = None
I 2015-05-27 01:00:03 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 01:00:03 theanets.main:89 --train_batches = 10
I 2015-05-27 01:00:03 theanets.main:89 --valid_batches = 2
I 2015-05-27 01:00:03 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 01:00:03 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 01:00:03 theanets.trainer:134 compiling evaluation function
I 2015-05-27 01:00:12 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 01:01:50 theanets.trainer:168 validation 0 loss=2220.551514 err=1576.695312 *
I 2015-05-27 01:02:00 theanets.trainer:168 RmsProp 1 loss=982.402222 err=341.655334
I 2015-05-27 01:02:10 theanets.trainer:168 RmsProp 2 loss=846.253235 err=208.003372
I 2015-05-27 01:02:21 theanets.trainer:168 RmsProp 3 loss=778.066345 err=141.582306
I 2015-05-27 01:02:31 theanets.trainer:168 RmsProp 4 loss=744.173584 err=109.319656
I 2015-05-27 01:02:42 theanets.trainer:168 RmsProp 5 loss=721.747620 err=88.690125
I 2015-05-27 01:02:52 theanets.trainer:168 RmsProp 6 loss=703.468933 err=72.483047
I 2015-05-27 01:03:03 theanets.trainer:168 RmsProp 7 loss=690.044006 err=61.524017
I 2015-05-27 01:03:13 theanets.trainer:168 RmsProp 8 loss=676.768127 err=51.137810
I 2015-05-27 01:03:23 theanets.trainer:168 RmsProp 9 loss=666.183594 err=43.835346
I 2015-05-27 01:03:34 theanets.trainer:168 RmsProp 10 loss=657.139099 err=38.194603
I 2015-05-27 01:03:34 theanets.trainer:168 validation 1 loss=1585.046509 err=968.018250 *
I 2015-05-27 01:03:45 theanets.trainer:168 RmsProp 11 loss=648.970093 err=33.559921
I 2015-05-27 01:03:55 theanets.trainer:168 RmsProp 12 loss=642.429382 err=30.729008
I 2015-05-27 01:04:06 theanets.trainer:168 RmsProp 13 loss=636.526978 err=28.567038
I 2015-05-27 01:04:16 theanets.trainer:168 RmsProp 14 loss=630.446777 err=26.081884
I 2015-05-27 01:04:27 theanets.trainer:168 RmsProp 15 loss=624.948059 err=24.117338
I 2015-05-27 01:04:38 theanets.trainer:168 RmsProp 16 loss=620.246216 err=23.038141
I 2015-05-27 01:04:49 theanets.trainer:168 RmsProp 17 loss=615.137573 err=21.596777
I 2015-05-27 01:05:00 theanets.trainer:168 RmsProp 18 loss=610.463074 err=20.559191
I 2015-05-27 01:05:11 theanets.trainer:168 RmsProp 19 loss=605.709839 err=19.309748
I 2015-05-27 01:05:22 theanets.trainer:168 RmsProp 20 loss=601.383728 err=18.430008
I 2015-05-27 01:05:22 theanets.trainer:168 validation 2 loss=1491.331177 err=910.262512 *
I 2015-05-27 01:05:33 theanets.trainer:168 RmsProp 21 loss=597.108032 err=17.554972
I 2015-05-27 01:05:43 theanets.trainer:168 RmsProp 22 loss=592.919312 err=16.729342
I 2015-05-27 01:05:54 theanets.trainer:168 RmsProp 23 loss=589.026672 err=16.219229
I 2015-05-27 01:06:04 theanets.trainer:168 RmsProp 24 loss=585.247986 err=15.818285
I 2015-05-27 01:06:14 theanets.trainer:168 RmsProp 25 loss=581.355652 err=15.231810
I 2015-05-27 01:06:25 theanets.trainer:168 RmsProp 26 loss=577.263245 err=14.360573
I 2015-05-27 01:06:35 theanets.trainer:168 RmsProp 27 loss=573.599121 err=13.964350
I 2015-05-27 01:06:46 theanets.trainer:168 RmsProp 28 loss=570.010620 err=13.623759
I 2015-05-27 01:06:56 theanets.trainer:168 RmsProp 29 loss=566.548279 err=13.357755
I 2015-05-27 01:07:07 theanets.trainer:168 RmsProp 30 loss=562.626526 err=12.563941
I 2015-05-27 01:07:08 theanets.trainer:168 validation 3 loss=1436.495117 err=888.132446 *
I 2015-05-27 01:07:18 theanets.trainer:168 RmsProp 31 loss=559.962463 err=12.984815
I 2015-05-27 01:07:29 theanets.trainer:168 RmsProp 32 loss=555.939453 err=11.959784
I 2015-05-27 01:07:39 theanets.trainer:168 RmsProp 33 loss=552.700928 err=11.707184
I 2015-05-27 01:07:50 theanets.trainer:168 RmsProp 34 loss=549.541260 err=11.584621
I 2015-05-27 01:08:01 theanets.trainer:168 RmsProp 35 loss=546.209595 err=11.269871
I 2015-05-27 01:08:12 theanets.trainer:168 RmsProp 36 loss=542.878479 err=10.884104
I 2015-05-27 01:08:22 theanets.trainer:168 RmsProp 37 loss=539.605713 err=10.518988
I 2015-05-27 01:08:33 theanets.trainer:168 RmsProp 38 loss=537.408813 err=11.219033
I 2015-05-27 01:08:44 theanets.trainer:168 RmsProp 39 loss=533.666382 err=10.237698
I 2015-05-27 01:08:55 theanets.trainer:168 RmsProp 40 loss=530.451782 err=9.653457
I 2015-05-27 01:08:55 theanets.trainer:168 validation 4 loss=1397.492554 err=878.174438 *
I 2015-05-27 01:09:06 theanets.trainer:168 RmsProp 41 loss=528.218384 err=10.161677
I 2015-05-27 01:09:17 theanets.trainer:168 RmsProp 42 loss=525.226379 err=9.907728
I 2015-05-27 01:09:28 theanets.trainer:168 RmsProp 43 loss=521.899658 err=9.221155
I 2015-05-27 01:09:39 theanets.trainer:168 RmsProp 44 loss=519.524658 err=9.486734
I 2015-05-27 01:09:49 theanets.trainer:168 RmsProp 45 loss=516.733643 err=9.288295
I 2015-05-27 01:10:00 theanets.trainer:168 RmsProp 46 loss=513.685364 err=8.818804
I 2015-05-27 01:10:11 theanets.trainer:168 RmsProp 47 loss=511.113464 err=8.843622
I 2015-05-27 01:10:21 theanets.trainer:168 RmsProp 48 loss=508.178864 err=8.509982
I 2015-05-27 01:10:32 theanets.trainer:168 RmsProp 49 loss=505.753113 err=8.695979
I 2015-05-27 01:10:43 theanets.trainer:168 RmsProp 50 loss=503.370117 err=8.859941
I 2015-05-27 01:10:44 theanets.trainer:168 validation 5 loss=1363.883423 err=870.739868 *
I 2015-05-27 01:10:55 theanets.trainer:168 RmsProp 51 loss=500.228210 err=8.161957
I 2015-05-27 01:11:05 theanets.trainer:168 RmsProp 52 loss=497.674957 err=8.006392
I 2015-05-27 01:11:16 theanets.trainer:168 RmsProp 53 loss=495.474701 err=8.245594
I 2015-05-27 01:11:27 theanets.trainer:168 RmsProp 54 loss=492.966370 err=8.131251
I 2015-05-27 01:11:38 theanets.trainer:168 RmsProp 55 loss=490.272400 err=7.781706
I 2015-05-27 01:11:49 theanets.trainer:168 RmsProp 56 loss=487.849304 err=7.680559
I 2015-05-27 01:12:00 theanets.trainer:168 RmsProp 57 loss=485.569000 err=7.747564
I 2015-05-27 01:12:11 theanets.trainer:168 RmsProp 58 loss=482.988922 err=7.518494
I 2015-05-27 01:12:22 theanets.trainer:168 RmsProp 59 loss=480.749939 err=7.602194
I 2015-05-27 01:12:33 theanets.trainer:168 RmsProp 60 loss=478.084076 err=7.189389
I 2015-05-27 01:12:33 theanets.trainer:168 validation 6 loss=1334.368652 err=864.692200 *
I 2015-05-27 01:12:44 theanets.trainer:168 RmsProp 61 loss=476.041565 err=7.393683
I 2015-05-27 01:12:54 theanets.trainer:168 RmsProp 62 loss=473.515961 err=7.112900
I 2015-05-27 01:13:05 theanets.trainer:168 RmsProp 63 loss=471.344421 err=7.134073
I 2015-05-27 01:13:16 theanets.trainer:168 RmsProp 64 loss=469.302826 err=7.239278
I 2015-05-27 01:13:26 theanets.trainer:168 RmsProp 65 loss=466.674957 err=6.705750
I 2015-05-27 01:13:37 theanets.trainer:168 RmsProp 66 loss=464.755127 err=6.889270
I 2015-05-27 01:13:47 theanets.trainer:168 RmsProp 67 loss=462.306244 err=6.552863
I 2015-05-27 01:13:58 theanets.trainer:168 RmsProp 68 loss=460.658295 err=7.001791
I 2015-05-27 01:14:08 theanets.trainer:168 RmsProp 69 loss=458.385986 err=6.764331
I 2015-05-27 01:14:19 theanets.trainer:168 RmsProp 70 loss=456.167969 err=6.531335
I 2015-05-27 01:14:19 theanets.trainer:168 validation 7 loss=1306.527832 err=857.972473 *
I 2015-05-27 01:14:30 theanets.trainer:168 RmsProp 71 loss=454.056458 err=6.389475
I 2015-05-27 01:14:40 theanets.trainer:168 RmsProp 72 loss=452.516357 err=6.854072
I 2015-05-27 01:14:50 theanets.trainer:168 RmsProp 73 loss=450.317322 err=6.624097
I 2015-05-27 01:15:01 theanets.trainer:168 RmsProp 74 loss=447.907074 err=6.102765
I 2015-05-27 01:15:11 theanets.trainer:168 RmsProp 75 loss=446.061523 err=6.148572
I 2015-05-27 01:15:21 theanets.trainer:168 RmsProp 76 loss=444.157135 err=6.146141
I 2015-05-27 01:15:32 theanets.trainer:168 RmsProp 77 loss=442.315857 err=6.219850
I 2015-05-27 01:15:42 theanets.trainer:168 RmsProp 78 loss=440.139587 err=5.964681
I 2015-05-27 01:15:52 theanets.trainer:168 RmsProp 79 loss=438.347015 err=6.083377
I 2015-05-27 01:16:03 theanets.trainer:168 RmsProp 80 loss=436.332520 err=5.946671
I 2015-05-27 01:16:03 theanets.trainer:168 validation 8 loss=1284.043823 err=854.672485 *
I 2015-05-27 01:16:14 theanets.trainer:168 RmsProp 81 loss=434.592773 err=6.053108
I 2015-05-27 01:16:25 theanets.trainer:168 RmsProp 82 loss=432.570007 err=5.854084
I 2015-05-27 01:16:35 theanets.trainer:168 RmsProp 83 loss=430.657898 err=5.733793
I 2015-05-27 01:16:46 theanets.trainer:168 RmsProp 84 loss=429.141510 err=6.026677
I 2015-05-27 01:16:57 theanets.trainer:168 RmsProp 85 loss=427.124023 err=5.784375
I 2015-05-27 01:17:07 theanets.trainer:168 RmsProp 86 loss=425.169525 err=5.568348
I 2015-05-27 01:17:17 theanets.trainer:168 RmsProp 87 loss=423.613831 err=5.752953
I 2015-05-27 01:17:28 theanets.trainer:168 RmsProp 88 loss=421.692810 err=5.565755
I 2015-05-27 01:17:38 theanets.trainer:168 RmsProp 89 loss=420.462830 err=6.043431
I 2015-05-27 01:17:49 theanets.trainer:168 RmsProp 90 loss=418.157532 err=5.377782
I 2015-05-27 01:17:50 theanets.trainer:168 validation 9 loss=1262.478394 err=850.574219 *
I 2015-05-27 01:18:01 theanets.trainer:168 RmsProp 91 loss=416.902252 err=5.727025
I 2015-05-27 01:18:12 theanets.trainer:168 RmsProp 92 loss=414.785339 err=5.228525
I 2015-05-27 01:18:23 theanets.trainer:168 RmsProp 93 loss=413.399658 err=5.467767
I 2015-05-27 01:18:33 theanets.trainer:168 RmsProp 94 loss=412.022552 err=5.713965
I 2015-05-27 01:18:44 theanets.trainer:168 RmsProp 95 loss=410.080139 err=5.335930
I 2015-05-27 01:18:55 theanets.trainer:168 RmsProp 96 loss=408.681091 err=5.483083
I 2015-05-27 01:19:06 theanets.trainer:168 RmsProp 97 loss=407.117126 err=5.486465
I 2015-05-27 01:19:17 theanets.trainer:168 RmsProp 98 loss=405.195374 err=5.103372
I 2015-05-27 01:19:28 theanets.trainer:168 RmsProp 99 loss=403.608887 err=5.079320
I 2015-05-27 01:19:38 theanets.trainer:168 RmsProp 100 loss=402.326263 err=5.371129
I 2015-05-27 01:19:39 theanets.trainer:168 validation 10 loss=1241.603638 err=845.500671 *
I 2015-05-27 01:19:50 theanets.trainer:168 RmsProp 101 loss=400.441101 err=5.045114
I 2015-05-27 01:20:01 theanets.trainer:168 RmsProp 102 loss=399.070160 err=5.229823
I 2015-05-27 01:20:12 theanets.trainer:168 RmsProp 103 loss=397.616394 err=5.283350
I 2015-05-27 01:20:23 theanets.trainer:168 RmsProp 104 loss=395.915955 err=5.069561
I 2015-05-27 01:20:34 theanets.trainer:168 RmsProp 105 loss=394.484375 err=5.088742
I 2015-05-27 01:20:45 theanets.trainer:168 RmsProp 106 loss=393.001953 err=5.069850
I 2015-05-27 01:20:55 theanets.trainer:168 RmsProp 107 loss=391.424683 err=4.966514
I 2015-05-27 01:21:06 theanets.trainer:168 RmsProp 108 loss=389.971863 err=4.971215
I 2015-05-27 01:21:16 theanets.trainer:168 RmsProp 109 loss=388.434143 err=4.866607
I 2015-05-27 01:21:27 theanets.trainer:168 RmsProp 110 loss=387.029266 err=4.890712
I 2015-05-27 01:21:27 theanets.trainer:168 validation 11 loss=1225.445312 err=844.093201 *
I 2015-05-27 01:21:38 theanets.trainer:168 RmsProp 111 loss=385.829987 err=5.117347
I 2015-05-27 01:21:48 theanets.trainer:168 RmsProp 112 loss=384.008789 err=4.691967
I 2015-05-27 01:21:59 theanets.trainer:168 RmsProp 113 loss=382.911560 err=4.998090
I 2015-05-27 01:22:10 theanets.trainer:168 RmsProp 114 loss=381.178009 err=4.656698
I 2015-05-27 01:22:21 theanets.trainer:168 RmsProp 115 loss=379.842346 err=4.701165
I 2015-05-27 01:22:32 theanets.trainer:168 RmsProp 116 loss=378.226379 err=4.486767
I 2015-05-27 01:22:43 theanets.trainer:168 RmsProp 117 loss=377.417725 err=5.062730
I 2015-05-27 01:22:53 theanets.trainer:168 RmsProp 118 loss=375.577209 err=4.580401
I 2015-05-27 01:23:04 theanets.trainer:168 RmsProp 119 loss=374.534729 err=4.865665
I 2015-05-27 01:23:15 theanets.trainer:168 RmsProp 120 loss=373.034363 err=4.661354
I 2015-05-27 01:23:15 theanets.trainer:168 validation 12 loss=1207.091431 err=839.420349 *
I 2015-05-27 01:23:26 theanets.trainer:168 RmsProp 121 loss=371.643677 err=4.556109
I 2015-05-27 01:23:37 theanets.trainer:168 RmsProp 122 loss=370.391479 err=4.604972
I 2015-05-27 01:23:48 theanets.trainer:168 RmsProp 123 loss=368.926575 err=4.444080
I 2015-05-27 01:23:59 theanets.trainer:168 RmsProp 124 loss=367.749695 err=4.568146
I 2015-05-27 01:24:09 theanets.trainer:168 RmsProp 125 loss=366.464417 err=4.576642
I 2015-05-27 01:24:20 theanets.trainer:168 RmsProp 126 loss=364.770447 err=4.154208
I 2015-05-27 01:24:31 theanets.trainer:168 RmsProp 127 loss=364.450806 err=5.115380
I 2015-05-27 01:24:42 theanets.trainer:168 RmsProp 128 loss=362.824554 err=4.715490
I 2015-05-27 01:24:53 theanets.trainer:168 RmsProp 129 loss=361.130615 err=4.191026
I 2015-05-27 01:25:04 theanets.trainer:168 RmsProp 130 loss=360.372009 err=4.634629
I 2015-05-27 01:25:04 theanets.trainer:168 validation 13 loss=1193.036865 err=837.967407 *
I 2015-05-27 01:25:15 theanets.trainer:168 RmsProp 131 loss=358.815399 err=4.284824
I 2015-05-27 01:25:26 theanets.trainer:168 RmsProp 132 loss=357.394867 err=4.070649
I 2015-05-27 01:25:36 theanets.trainer:168 RmsProp 133 loss=356.994141 err=4.876894
I 2015-05-27 01:25:47 theanets.trainer:168 RmsProp 134 loss=355.426361 err=4.481707
I 2015-05-27 01:25:57 theanets.trainer:168 RmsProp 135 loss=354.116028 err=4.328196
I 2015-05-27 01:26:08 theanets.trainer:168 RmsProp 136 loss=353.174530 err=4.524670
I 2015-05-27 01:26:18 theanets.trainer:168 RmsProp 137 loss=351.872253 err=4.361197
I 2015-05-27 01:26:29 theanets.trainer:168 RmsProp 138 loss=350.704315 err=4.323175
I 2015-05-27 01:26:39 theanets.trainer:168 RmsProp 139 loss=349.598816 err=4.346086
I 2015-05-27 01:26:50 theanets.trainer:168 RmsProp 140 loss=348.308533 err=4.186820
I 2015-05-27 01:26:50 theanets.trainer:168 validation 14 loss=1178.464233 err=834.961914 *
I 2015-05-27 01:27:01 theanets.trainer:168 RmsProp 141 loss=347.243835 err=4.256310
I 2015-05-27 01:27:11 theanets.trainer:168 RmsProp 142 loss=345.952423 err=4.115177
I 2015-05-27 01:27:21 theanets.trainer:168 RmsProp 143 loss=344.966675 err=4.264478
I 2015-05-27 01:27:32 theanets.trainer:168 RmsProp 144 loss=343.448975 err=3.880454
I 2015-05-27 01:27:42 theanets.trainer:168 RmsProp 145 loss=343.186218 err=4.752514
I 2015-05-27 01:27:53 theanets.trainer:168 RmsProp 146 loss=341.461365 err=4.119945
I 2015-05-27 01:28:03 theanets.trainer:168 RmsProp 147 loss=340.423737 err=4.135478
I 2015-05-27 01:28:13 theanets.trainer:168 RmsProp 148 loss=339.681824 err=4.439477
I 2015-05-27 01:28:23 theanets.trainer:168 RmsProp 149 loss=338.272491 err=4.067914
I 2015-05-27 01:28:34 theanets.trainer:168 RmsProp 150 loss=337.160797 err=3.992640
I 2015-05-27 01:28:34 theanets.trainer:168 validation 15 loss=1166.087158 err=833.493835 *
I 2015-05-27 01:28:45 theanets.trainer:168 RmsProp 151 loss=336.442078 err=4.316855
I 2015-05-27 01:28:55 theanets.trainer:168 RmsProp 152 loss=334.887665 err=3.807711
I 2015-05-27 01:29:06 theanets.trainer:168 RmsProp 153 loss=334.360535 err=4.346487
I 2015-05-27 01:29:16 theanets.trainer:168 RmsProp 154 loss=332.993713 err=4.032079
I 2015-05-27 01:29:27 theanets.trainer:168 RmsProp 155 loss=331.873230 err=3.922185
I 2015-05-27 01:29:37 theanets.trainer:168 RmsProp 156 loss=330.868927 err=3.942676
I 2015-05-27 01:29:48 theanets.trainer:168 RmsProp 157 loss=330.152283 err=4.254294
I 2015-05-27 01:29:58 theanets.trainer:168 RmsProp 158 loss=328.856140 err=3.963665
I 2015-05-27 01:30:09 theanets.trainer:168 RmsProp 159 loss=327.948059 err=4.066037
I 2015-05-27 01:30:19 theanets.trainer:168 RmsProp 160 loss=326.766235 err=3.880019
I 2015-05-27 01:30:20 theanets.trainer:168 validation 16 loss=1151.274658 err=828.924255 *
I 2015-05-27 01:30:30 theanets.trainer:168 RmsProp 161 loss=325.717712 err=3.810989
I 2015-05-27 01:30:41 theanets.trainer:168 RmsProp 162 loss=325.436523 err=4.508166
I 2015-05-27 01:30:52 theanets.trainer:168 RmsProp 163 loss=323.669708 err=3.702043
I 2015-05-27 01:31:02 theanets.trainer:168 RmsProp 164 loss=322.886536 err=3.875588
I 2015-05-27 01:31:13 theanets.trainer:168 RmsProp 165 loss=322.103668 err=4.062144
I 2015-05-27 01:31:24 theanets.trainer:168 RmsProp 166 loss=321.231232 err=4.145378
I 2015-05-27 01:31:34 theanets.trainer:168 RmsProp 167 loss=320.079102 err=3.913852
I 2015-05-27 01:31:45 theanets.trainer:168 RmsProp 168 loss=318.953430 err=3.702143
I 2015-05-27 01:31:55 theanets.trainer:168 RmsProp 169 loss=318.344147 err=4.034827
I 2015-05-27 01:32:05 theanets.trainer:168 RmsProp 170 loss=317.021545 err=3.649699
I 2015-05-27 01:32:06 theanets.trainer:168 validation 17 loss=1139.190552 err=826.322937 *
I 2015-05-27 01:32:16 theanets.trainer:168 RmsProp 171 loss=316.465485 err=4.024938
I 2015-05-27 01:32:27 theanets.trainer:168 RmsProp 172 loss=315.425293 err=3.903771
I 2015-05-27 01:32:37 theanets.trainer:168 RmsProp 173 loss=314.351898 err=3.733634
I 2015-05-27 01:32:48 theanets.trainer:168 RmsProp 174 loss=313.797882 err=4.079462
I 2015-05-27 01:32:58 theanets.trainer:168 RmsProp 175 loss=312.871399 err=4.035825
I 2015-05-27 01:33:09 theanets.trainer:168 RmsProp 176 loss=311.684967 err=3.713690
I 2015-05-27 01:33:19 theanets.trainer:168 RmsProp 177 loss=310.908142 err=3.805258
I 2015-05-27 01:33:30 theanets.trainer:168 RmsProp 178 loss=309.870789 err=3.655701
I 2015-05-27 01:33:41 theanets.trainer:168 RmsProp 179 loss=309.039886 err=3.718547
I 2015-05-27 01:33:51 theanets.trainer:168 RmsProp 180 loss=308.126007 err=3.694967
I 2015-05-27 01:33:52 theanets.trainer:168 validation 18 loss=1129.830444 err=825.879089 *
I 2015-05-27 01:34:03 theanets.trainer:168 RmsProp 181 loss=307.497894 err=3.955743
I 2015-05-27 01:34:13 theanets.trainer:168 RmsProp 182 loss=306.123962 err=3.454924
I 2015-05-27 01:34:24 theanets.trainer:168 RmsProp 183 loss=305.461945 err=3.652496
I 2015-05-27 01:34:34 theanets.trainer:168 RmsProp 184 loss=304.823486 err=3.873376
I 2015-05-27 01:34:44 theanets.trainer:168 RmsProp 185 loss=303.538025 err=3.451997
I 2015-05-27 01:34:55 theanets.trainer:168 RmsProp 186 loss=303.385590 err=4.148136
I 2015-05-27 01:35:05 theanets.trainer:168 RmsProp 187 loss=302.086487 err=3.667490
I 2015-05-27 01:35:15 theanets.trainer:168 RmsProp 188 loss=301.288666 err=3.680978
I 2015-05-27 01:35:26 theanets.trainer:168 RmsProp 189 loss=300.511169 err=3.722608
I 2015-05-27 01:35:36 theanets.trainer:168 RmsProp 190 loss=299.774597 err=3.800787
I 2015-05-27 01:35:37 theanets.trainer:168 validation 19 loss=1118.425415 err=822.894348 *
I 2015-05-27 01:35:47 theanets.trainer:168 RmsProp 191 loss=298.706604 err=3.532224
I 2015-05-27 01:35:58 theanets.trainer:168 RmsProp 192 loss=298.024200 err=3.645135
I 2015-05-27 01:36:08 theanets.trainer:168 RmsProp 193 loss=297.168396 err=3.598035
I 2015-05-27 01:36:18 theanets.trainer:168 RmsProp 194 loss=296.389343 err=3.621642
I 2015-05-27 01:36:29 theanets.trainer:168 RmsProp 195 loss=295.545624 err=3.585782
I 2015-05-27 01:36:40 theanets.trainer:168 RmsProp 196 loss=295.125763 err=3.960251
I 2015-05-27 01:36:51 theanets.trainer:168 RmsProp 197 loss=293.951111 err=3.566504
I 2015-05-27 01:37:01 theanets.trainer:168 RmsProp 198 loss=293.154480 err=3.542227
I 2015-05-27 01:37:12 theanets.trainer:168 RmsProp 199 loss=292.250336 err=3.413279
I 2015-05-27 01:37:23 theanets.trainer:168 RmsProp 200 loss=292.074982 err=4.023527
I 2015-05-27 01:37:24 theanets.trainer:168 validation 20 loss=1108.237671 err=820.609070 *
I 2015-05-27 01:37:34 theanets.trainer:168 RmsProp 201 loss=290.889008 err=3.601399
I 2015-05-27 01:37:45 theanets.trainer:168 RmsProp 202 loss=290.199188 err=3.650299
I 2015-05-27 01:37:55 theanets.trainer:168 RmsProp 203 loss=289.306122 err=3.496238
I 2015-05-27 01:38:06 theanets.trainer:168 RmsProp 204 loss=288.403748 err=3.348024
I 2015-05-27 01:38:17 theanets.trainer:168 RmsProp 205 loss=287.935852 err=3.647826
I 2015-05-27 01:38:28 theanets.trainer:168 RmsProp 206 loss=287.243469 err=3.707757
I 2015-05-27 01:38:39 theanets.trainer:168 RmsProp 207 loss=286.308197 err=3.508117
I 2015-05-27 01:38:50 theanets.trainer:168 RmsProp 208 loss=285.604736 err=3.522201
I 2015-05-27 01:39:00 theanets.trainer:168 RmsProp 209 loss=284.752808 err=3.395568
I 2015-05-27 01:39:11 theanets.trainer:168 RmsProp 210 loss=284.220184 err=3.588980
I 2015-05-27 01:39:11 theanets.trainer:168 validation 21 loss=1097.034912 err=816.794373 *
I 2015-05-27 01:39:22 theanets.trainer:168 RmsProp 211 loss=283.300201 err=3.394381
I 2015-05-27 01:39:33 theanets.trainer:168 RmsProp 212 loss=282.532532 err=3.354203
I 2015-05-27 01:39:43 theanets.trainer:168 RmsProp 213 loss=282.129883 err=3.681194
I 2015-05-27 01:39:54 theanets.trainer:168 RmsProp 214 loss=281.400635 err=3.669567
I 2015-05-27 01:40:05 theanets.trainer:168 RmsProp 215 loss=280.369934 err=3.329376
I 2015-05-27 01:40:16 theanets.trainer:168 RmsProp 216 loss=279.822083 err=3.473433
I 2015-05-27 01:40:27 theanets.trainer:168 RmsProp 217 loss=279.341034 err=3.679240
I 2015-05-27 01:40:37 theanets.trainer:168 RmsProp 218 loss=278.591827 err=3.608276
I 2015-05-27 01:40:48 theanets.trainer:168 RmsProp 219 loss=277.603149 err=3.288348
I 2015-05-27 01:40:59 theanets.trainer:168 RmsProp 220 loss=277.134460 err=3.483992
I 2015-05-27 01:41:00 theanets.trainer:168 validation 22 loss=1091.263916 err=817.986450 *
I 2015-05-27 01:41:10 theanets.trainer:168 RmsProp 221 loss=276.268951 err=3.299594
I 2015-05-27 01:41:20 theanets.trainer:168 RmsProp 222 loss=275.734558 err=3.451778
I 2015-05-27 01:41:31 theanets.trainer:168 RmsProp 223 loss=275.118042 err=3.521558
I 2015-05-27 01:41:41 theanets.trainer:168 RmsProp 224 loss=274.314117 err=3.397647
I 2015-05-27 01:41:52 theanets.trainer:168 RmsProp 225 loss=273.909332 err=3.659958
I 2015-05-27 01:42:02 theanets.trainer:168 RmsProp 226 loss=272.635803 err=3.049531
I 2015-05-27 01:42:12 theanets.trainer:168 RmsProp 227 loss=272.281830 err=3.348973
I 2015-05-27 01:42:22 theanets.trainer:168 RmsProp 228 loss=271.720947 err=3.455497
I 2015-05-27 01:42:32 theanets.trainer:168 RmsProp 229 loss=271.042816 err=3.436961
I 2015-05-27 01:42:42 theanets.trainer:168 RmsProp 230 loss=270.262146 err=3.311971
I 2015-05-27 01:42:43 theanets.trainer:168 validation 23 loss=1080.062012 err=813.465149 *
I 2015-05-27 01:42:53 theanets.trainer:168 RmsProp 231 loss=269.901001 err=3.599326
I 2015-05-27 01:43:03 theanets.trainer:168 RmsProp 232 loss=269.169861 err=3.499606
I 2015-05-27 01:43:13 theanets.trainer:168 RmsProp 233 loss=268.594940 err=3.532489
I 2015-05-27 01:43:23 theanets.trainer:168 RmsProp 234 loss=267.581451 err=3.129408
I 2015-05-27 01:43:34 theanets.trainer:168 RmsProp 235 loss=267.288635 err=3.458787
I 2015-05-27 01:43:44 theanets.trainer:168 RmsProp 236 loss=266.356049 err=3.153565
I 2015-05-27 01:43:54 theanets.trainer:168 RmsProp 237 loss=265.876770 err=3.308373
I 2015-05-27 01:44:04 theanets.trainer:168 RmsProp 238 loss=265.130554 err=3.202260
I 2015-05-27 01:44:13 theanets.trainer:168 RmsProp 239 loss=264.718811 err=3.428288
I 2015-05-27 01:44:23 theanets.trainer:168 RmsProp 240 loss=263.781311 err=3.129992
I 2015-05-27 01:44:24 theanets.trainer:168 validation 24 loss=1072.865601 err=812.549988 *
I 2015-05-27 01:44:34 theanets.trainer:168 RmsProp 241 loss=263.307220 err=3.286553
I 2015-05-27 01:44:44 theanets.trainer:168 RmsProp 242 loss=262.926697 err=3.525487
I 2015-05-27 01:44:55 theanets.trainer:168 RmsProp 243 loss=261.908966 err=3.108226
I 2015-05-27 01:45:05 theanets.trainer:168 RmsProp 244 loss=261.676239 err=3.479829
I 2015-05-27 01:45:15 theanets.trainer:168 RmsProp 245 loss=261.036377 err=3.444562
I 2015-05-27 01:45:25 theanets.trainer:168 RmsProp 246 loss=260.082703 err=3.077838
I 2015-05-27 01:45:36 theanets.trainer:168 RmsProp 247 loss=259.420410 err=3.011059
I 2015-05-27 01:45:46 theanets.trainer:168 RmsProp 248 loss=259.883270 err=4.058956
I 2015-05-27 01:45:57 theanets.trainer:168 RmsProp 249 loss=258.621277 err=3.373544
I 2015-05-27 01:46:07 theanets.trainer:168 RmsProp 250 loss=257.769867 err=3.077919
I 2015-05-27 01:46:07 theanets.trainer:168 validation 25 loss=1064.995117 err=810.617310 *
I 2015-05-27 01:46:17 theanets.trainer:168 RmsProp 251 loss=257.311798 err=3.184445
I 2015-05-27 01:46:28 theanets.trainer:168 RmsProp 252 loss=256.955383 err=3.406584
I 2015-05-27 01:46:38 theanets.trainer:168 RmsProp 253 loss=255.885422 err=2.924118
I 2015-05-27 01:46:47 theanets.trainer:168 RmsProp 254 loss=255.990021 err=3.608532
I 2015-05-27 01:46:57 theanets.trainer:168 RmsProp 255 loss=255.135773 err=3.317043
I 2015-05-27 01:47:07 theanets.trainer:168 RmsProp 256 loss=254.406586 err=3.138854
I 2015-05-27 01:47:17 theanets.trainer:168 RmsProp 257 loss=253.943237 err=3.226399
I 2015-05-27 01:47:27 theanets.trainer:168 RmsProp 258 loss=253.415497 err=3.255830
I 2015-05-27 01:47:38 theanets.trainer:168 RmsProp 259 loss=252.937912 err=3.329704
I 2015-05-27 01:47:48 theanets.trainer:168 RmsProp 260 loss=252.106903 err=3.050928
I 2015-05-27 01:47:48 theanets.trainer:168 validation 26 loss=1058.309082 err=809.557434 *
I 2015-05-27 01:47:58 theanets.trainer:168 RmsProp 261 loss=251.666138 err=3.159523
I 2015-05-27 01:48:08 theanets.trainer:168 RmsProp 262 loss=250.973434 err=3.029908
I 2015-05-27 01:48:19 theanets.trainer:168 RmsProp 263 loss=250.762131 err=3.380913
I 2015-05-27 01:48:29 theanets.trainer:168 RmsProp 264 loss=249.889603 err=3.064996
I 2015-05-27 01:48:39 theanets.trainer:168 RmsProp 265 loss=249.246063 err=2.979489
I 2015-05-27 01:48:49 theanets.trainer:168 RmsProp 266 loss=248.739182 err=3.031728
I 2015-05-27 01:48:59 theanets.trainer:168 RmsProp 267 loss=248.323730 err=3.171829
I 2015-05-27 01:49:09 theanets.trainer:168 RmsProp 268 loss=247.494019 err=2.898263
I 2015-05-27 01:49:19 theanets.trainer:168 RmsProp 269 loss=247.682693 err=3.628566
I 2015-05-27 01:49:29 theanets.trainer:168 RmsProp 270 loss=246.875931 err=3.351729
I 2015-05-27 01:49:30 theanets.trainer:168 validation 27 loss=1051.726807 err=808.479065 *
I 2015-05-27 01:49:40 theanets.trainer:168 RmsProp 271 loss=245.894455 err=2.880147
I 2015-05-27 01:49:49 theanets.trainer:168 RmsProp 272 loss=245.597900 err=3.097257
I 2015-05-27 01:49:59 theanets.trainer:168 RmsProp 273 loss=245.123138 err=3.144412
I 2015-05-27 01:50:09 theanets.trainer:168 RmsProp 274 loss=244.871307 err=3.409178
I 2015-05-27 01:50:19 theanets.trainer:168 RmsProp 275 loss=243.942825 err=2.996488
I 2015-05-27 01:50:29 theanets.trainer:168 RmsProp 276 loss=243.523636 err=3.089850
I 2015-05-27 01:50:39 theanets.trainer:168 RmsProp 277 loss=243.176483 err=3.256504
I 2015-05-27 01:50:48 theanets.trainer:168 RmsProp 278 loss=242.269287 err=2.857060
I 2015-05-27 01:50:58 theanets.trainer:168 RmsProp 279 loss=242.116943 err=3.218548
I 2015-05-27 01:51:08 theanets.trainer:168 RmsProp 280 loss=241.365448 err=2.983953
I 2015-05-27 01:51:09 theanets.trainer:168 validation 28 loss=1050.994995 err=812.891846 *
I 2015-05-27 01:51:19 theanets.trainer:168 RmsProp 281 loss=241.057785 err=3.185341
I 2015-05-27 01:51:29 theanets.trainer:168 RmsProp 282 loss=240.323807 err=2.961157
I 2015-05-27 01:51:39 theanets.trainer:168 RmsProp 283 loss=240.148285 err=3.285363
I 2015-05-27 01:51:50 theanets.trainer:168 RmsProp 284 loss=239.425613 err=3.063983
I 2015-05-27 01:52:00 theanets.trainer:168 RmsProp 285 loss=238.946442 err=3.080813
I 2015-05-27 01:52:10 theanets.trainer:168 RmsProp 286 loss=238.294479 err=2.920209
I 2015-05-27 01:52:21 theanets.trainer:168 RmsProp 287 loss=237.932953 err=3.049141
I 2015-05-27 01:52:31 theanets.trainer:168 RmsProp 288 loss=237.462570 err=3.069092
I 2015-05-27 01:52:41 theanets.trainer:168 RmsProp 289 loss=237.062592 err=3.154760
I 2015-05-27 01:52:51 theanets.trainer:168 RmsProp 290 loss=236.200714 err=2.778438
I 2015-05-27 01:52:52 theanets.trainer:168 validation 29 loss=1038.745850 err=805.592407 *
I 2015-05-27 01:53:01 theanets.trainer:168 RmsProp 291 loss=236.098511 err=3.165422
I 2015-05-27 01:53:11 theanets.trainer:168 RmsProp 292 loss=235.320724 err=2.879603
I 2015-05-27 01:53:21 theanets.trainer:168 RmsProp 293 loss=235.248260 err=3.290792
I 2015-05-27 01:53:31 theanets.trainer:168 RmsProp 294 loss=234.353790 err=2.878819
I 2015-05-27 01:53:41 theanets.trainer:168 RmsProp 295 loss=234.277130 err=3.275107
I 2015-05-27 01:53:51 theanets.trainer:168 RmsProp 296 loss=233.544769 err=3.011884
I 2015-05-27 01:54:01 theanets.trainer:168 RmsProp 297 loss=233.118210 err=3.042909
I 2015-05-27 01:54:11 theanets.trainer:168 RmsProp 298 loss=232.486542 err=2.875381
I 2015-05-27 01:54:21 theanets.trainer:168 RmsProp 299 loss=232.250488 err=3.101734
I 2015-05-27 01:54:31 theanets.trainer:168 RmsProp 300 loss=231.651413 err=2.968226
I 2015-05-27 01:54:32 theanets.trainer:168 validation 30 loss=1034.533081 err=806.103943 *
I 2015-05-27 01:54:42 theanets.trainer:168 RmsProp 301 loss=231.199173 err=2.981215
I 2015-05-27 01:54:52 theanets.trainer:168 RmsProp 302 loss=230.468307 err=2.717787
I 2015-05-27 01:55:02 theanets.trainer:168 RmsProp 303 loss=230.602448 err=3.316913
I 2015-05-27 01:55:12 theanets.trainer:168 RmsProp 304 loss=229.811310 err=2.980141
I 2015-05-27 01:55:22 theanets.trainer:168 RmsProp 305 loss=228.997528 err=2.623317
I 2015-05-27 01:55:32 theanets.trainer:168 RmsProp 306 loss=229.546783 err=3.620296
I 2015-05-27 01:55:42 theanets.trainer:168 RmsProp 307 loss=228.334320 err=2.850143
I 2015-05-27 01:55:52 theanets.trainer:168 RmsProp 308 loss=227.974609 err=2.922235
I 2015-05-27 01:56:02 theanets.trainer:168 RmsProp 309 loss=227.495316 err=2.890764
I 2015-05-27 01:56:12 theanets.trainer:168 RmsProp 310 loss=227.507126 err=3.343367
I 2015-05-27 01:56:13 theanets.trainer:168 validation 31 loss=1028.752075 err=804.831543 *
I 2015-05-27 01:56:22 theanets.trainer:168 RmsProp 311 loss=226.412308 err=2.684386
I 2015-05-27 01:56:32 theanets.trainer:168 RmsProp 312 loss=226.411377 err=3.118878
I 2015-05-27 01:56:43 theanets.trainer:168 RmsProp 313 loss=225.775909 err=2.918682
I 2015-05-27 01:56:53 theanets.trainer:168 RmsProp 314 loss=225.243988 err=2.826361
I 2015-05-27 01:57:03 theanets.trainer:168 RmsProp 315 loss=225.191818 err=3.215420
I 2015-05-27 01:57:13 theanets.trainer:168 RmsProp 316 loss=224.624359 err=3.078788
I 2015-05-27 01:57:23 theanets.trainer:168 RmsProp 317 loss=224.126877 err=3.003538
I 2015-05-27 01:57:34 theanets.trainer:168 RmsProp 318 loss=223.387787 err=2.685752
I 2015-05-27 01:57:44 theanets.trainer:168 RmsProp 319 loss=223.220215 err=2.947653
I 2015-05-27 01:57:54 theanets.trainer:168 RmsProp 320 loss=222.928223 err=3.089055
I 2015-05-27 01:57:55 theanets.trainer:168 validation 32 loss=1023.170715 err=803.567078 *
I 2015-05-27 01:58:05 theanets.trainer:168 RmsProp 321 loss=222.376190 err=2.964683
I 2015-05-27 01:58:15 theanets.trainer:168 RmsProp 322 loss=221.796341 err=2.801836
I 2015-05-27 01:58:25 theanets.trainer:168 RmsProp 323 loss=221.761841 err=3.181454
I 2015-05-27 01:58:36 theanets.trainer:168 RmsProp 324 loss=221.008148 err=2.848121
I 2015-05-27 01:58:46 theanets.trainer:168 RmsProp 325 loss=220.505081 err=2.762941
I 2015-05-27 01:58:56 theanets.trainer:168 RmsProp 326 loss=220.537445 err=3.213891
I 2015-05-27 01:59:07 theanets.trainer:168 RmsProp 327 loss=219.704834 err=2.793222
I 2015-05-27 01:59:17 theanets.trainer:168 RmsProp 328 loss=219.322556 err=2.812932
I 2015-05-27 01:59:27 theanets.trainer:168 RmsProp 329 loss=219.135223 err=3.031440
I 2015-05-27 01:59:38 theanets.trainer:168 RmsProp 330 loss=218.824493 err=3.123003
I 2015-05-27 01:59:38 theanets.trainer:168 validation 33 loss=1016.846924 err=801.367371 *
I 2015-05-27 01:59:48 theanets.trainer:168 RmsProp 331 loss=218.083832 err=2.779426
I 2015-05-27 01:59:58 theanets.trainer:168 RmsProp 332 loss=217.770508 err=2.859005
I 2015-05-27 02:00:08 theanets.trainer:168 RmsProp 333 loss=217.435547 err=2.920568
I 2015-05-27 02:00:18 theanets.trainer:168 RmsProp 334 loss=216.969238 err=2.851279
I 2015-05-27 02:00:28 theanets.trainer:168 RmsProp 335 loss=216.579346 err=2.859004
I 2015-05-27 02:00:39 theanets.trainer:168 RmsProp 336 loss=216.304443 err=2.981189
I 2015-05-27 02:00:49 theanets.trainer:168 RmsProp 337 loss=215.775070 err=2.849390
I 2015-05-27 02:01:00 theanets.trainer:168 RmsProp 338 loss=215.518951 err=2.987721
I 2015-05-27 02:01:10 theanets.trainer:168 RmsProp 339 loss=214.940872 err=2.801295
I 2015-05-27 02:01:20 theanets.trainer:168 RmsProp 340 loss=214.688873 err=2.939094
I 2015-05-27 02:01:21 theanets.trainer:168 validation 34 loss=1011.349487 err=799.814575 *
I 2015-05-27 02:01:31 theanets.trainer:168 RmsProp 341 loss=214.146881 err=2.783276
I 2015-05-27 02:01:41 theanets.trainer:168 RmsProp 342 loss=213.841110 err=2.866620
I 2015-05-27 02:01:51 theanets.trainer:168 RmsProp 343 loss=213.364212 err=2.777677
I 2015-05-27 02:02:01 theanets.trainer:168 RmsProp 344 loss=213.151733 err=2.957388
I 2015-05-27 02:02:11 theanets.trainer:168 RmsProp 345 loss=212.713898 err=2.910558
I 2015-05-27 02:02:21 theanets.trainer:168 RmsProp 346 loss=212.216644 err=2.795301
I 2015-05-27 02:02:32 theanets.trainer:168 RmsProp 347 loss=211.798553 err=2.753094
I 2015-05-27 02:02:42 theanets.trainer:168 RmsProp 348 loss=211.478668 err=2.810417
I 2015-05-27 02:02:53 theanets.trainer:168 RmsProp 349 loss=211.394257 err=3.102856
I 2015-05-27 02:03:03 theanets.trainer:168 RmsProp 350 loss=210.916916 err=2.990967
I 2015-05-27 02:03:03 theanets.trainer:168 validation 35 loss=1004.952148 err=797.229675 *
I 2015-05-27 02:03:13 theanets.trainer:168 RmsProp 351 loss=210.566376 err=3.003884
I 2015-05-27 02:03:24 theanets.trainer:168 RmsProp 352 loss=209.962799 err=2.759330
I 2015-05-27 02:03:34 theanets.trainer:168 RmsProp 353 loss=209.714874 err=2.871315
I 2015-05-27 02:03:44 theanets.trainer:168 RmsProp 354 loss=209.319626 err=2.839312
I 2015-05-27 02:03:54 theanets.trainer:168 RmsProp 355 loss=208.822052 err=2.697766
I 2015-05-27 02:04:05 theanets.trainer:168 RmsProp 356 loss=208.739166 err=2.971670
I 2015-05-27 02:04:15 theanets.trainer:168 RmsProp 357 loss=207.886444 err=2.486194
I 2015-05-27 02:04:25 theanets.trainer:168 RmsProp 358 loss=208.034378 err=2.999225
I 2015-05-27 02:04:36 theanets.trainer:168 RmsProp 359 loss=207.361603 err=2.691324
I 2015-05-27 02:04:46 theanets.trainer:168 RmsProp 360 loss=207.191650 err=2.878438
I 2015-05-27 02:04:47 theanets.trainer:168 validation 36 loss=1002.244324 err=798.124084 *
I 2015-05-27 02:04:57 theanets.trainer:168 RmsProp 361 loss=206.735382 err=2.785100
I 2015-05-27 02:05:07 theanets.trainer:168 RmsProp 362 loss=206.505524 err=2.913355
I 2015-05-27 02:05:18 theanets.trainer:168 RmsProp 363 loss=206.091919 err=2.854292
I 2015-05-27 02:05:29 theanets.trainer:168 RmsProp 364 loss=205.597534 err=2.711487
I 2015-05-27 02:05:39 theanets.trainer:168 RmsProp 365 loss=205.245850 err=2.715396
I 2015-05-27 02:05:50 theanets.trainer:168 RmsProp 366 loss=205.083084 err=2.905438
I 2015-05-27 02:06:00 theanets.trainer:168 RmsProp 367 loss=204.931351 err=3.096405
I 2015-05-27 02:06:11 theanets.trainer:168 RmsProp 368 loss=204.162201 err=2.666481
I 2015-05-27 02:06:21 theanets.trainer:168 RmsProp 369 loss=203.864990 err=2.705948
I 2015-05-27 02:06:31 theanets.trainer:168 RmsProp 370 loss=203.595551 err=2.780122
I 2015-05-27 02:06:32 theanets.trainer:168 validation 37 loss=992.465515 err=791.843140 *
I 2015-05-27 02:06:42 theanets.trainer:168 RmsProp 371 loss=203.377441 err=2.902216
I 2015-05-27 02:06:52 theanets.trainer:168 RmsProp 372 loss=202.967850 err=2.831271
I 2015-05-27 02:07:03 theanets.trainer:168 RmsProp 373 loss=202.685532 err=2.886899
I 2015-05-27 02:07:13 theanets.trainer:168 RmsProp 374 loss=202.190628 err=2.725644
I 2015-05-27 02:07:24 theanets.trainer:168 RmsProp 375 loss=201.903854 err=2.774923
I 2015-05-27 02:07:34 theanets.trainer:168 RmsProp 376 loss=201.526703 err=2.729529
I 2015-05-27 02:07:44 theanets.trainer:168 RmsProp 377 loss=201.119965 err=2.659926
I 2015-05-27 02:07:55 theanets.trainer:168 RmsProp 378 loss=200.999878 err=2.873717
I 2015-05-27 02:08:05 theanets.trainer:168 RmsProp 379 loss=200.685654 err=2.887517
I 2015-05-27 02:08:15 theanets.trainer:168 RmsProp 380 loss=200.106613 err=2.638494
I 2015-05-27 02:08:16 theanets.trainer:168 validation 38 loss=990.996338 err=793.700317 *
I 2015-05-27 02:08:26 theanets.trainer:168 RmsProp 381 loss=199.963852 err=2.823742
I 2015-05-27 02:08:36 theanets.trainer:168 RmsProp 382 loss=199.330002 err=2.525430
I 2015-05-27 02:08:47 theanets.trainer:168 RmsProp 383 loss=199.317032 err=2.840143
I 2015-05-27 02:08:57 theanets.trainer:168 RmsProp 384 loss=199.064194 err=2.915733
I 2015-05-27 02:09:07 theanets.trainer:168 RmsProp 385 loss=198.599365 err=2.769549
I 2015-05-27 02:09:18 theanets.trainer:168 RmsProp 386 loss=198.129486 err=2.619720
I 2015-05-27 02:09:28 theanets.trainer:168 RmsProp 387 loss=197.922104 err=2.736028
I 2015-05-27 02:09:39 theanets.trainer:168 RmsProp 388 loss=197.621490 err=2.754804
I 2015-05-27 02:09:48 theanets.trainer:168 RmsProp 389 loss=197.471008 err=2.920606
I 2015-05-27 02:09:58 theanets.trainer:168 RmsProp 390 loss=197.113327 err=2.877911
I 2015-05-27 02:09:59 theanets.trainer:168 validation 39 loss=980.340393 err=786.268738 *
I 2015-05-27 02:10:09 theanets.trainer:168 RmsProp 391 loss=196.608917 err=2.684567
I 2015-05-27 02:10:19 theanets.trainer:168 RmsProp 392 loss=196.303009 err=2.692085
I 2015-05-27 02:10:29 theanets.trainer:168 RmsProp 393 loss=196.015533 err=2.717836
I 2015-05-27 02:10:39 theanets.trainer:168 RmsProp 394 loss=195.598587 err=2.614911
I 2015-05-27 02:10:49 theanets.trainer:168 RmsProp 395 loss=195.516052 err=2.846557
I 2015-05-27 02:11:00 theanets.trainer:168 RmsProp 396 loss=195.062012 err=2.710058
I 2015-05-27 02:11:10 theanets.trainer:168 RmsProp 397 loss=194.655029 err=2.613897
I 2015-05-27 02:11:20 theanets.trainer:168 RmsProp 398 loss=194.417007 err=2.687368
I 2015-05-27 02:11:30 theanets.trainer:168 RmsProp 399 loss=194.175522 err=2.756245
I 2015-05-27 02:11:40 theanets.trainer:168 RmsProp 400 loss=194.001297 err=2.889115
I 2015-05-27 02:11:41 theanets.trainer:168 validation 40 loss=978.803589 err=787.862183 *
I 2015-05-27 02:11:51 theanets.trainer:168 RmsProp 401 loss=193.540375 err=2.734650
I 2015-05-27 02:12:01 theanets.trainer:168 RmsProp 402 loss=193.126801 err=2.626632
I 2015-05-27 02:12:11 theanets.trainer:168 RmsProp 403 loss=192.988617 err=2.793942
I 2015-05-27 02:12:22 theanets.trainer:168 RmsProp 404 loss=192.555710 err=2.664093
I 2015-05-27 02:12:32 theanets.trainer:168 RmsProp 405 loss=192.222519 err=2.634375
I 2015-05-27 02:12:42 theanets.trainer:168 RmsProp 406 loss=191.975220 err=2.690069
I 2015-05-27 02:12:53 theanets.trainer:168 RmsProp 407 loss=191.637863 err=2.652637
I 2015-05-27 02:13:03 theanets.trainer:168 RmsProp 408 loss=191.352295 err=2.667658
I 2015-05-27 02:13:13 theanets.trainer:168 RmsProp 409 loss=191.218719 err=2.829030
I 2015-05-27 02:13:24 theanets.trainer:168 RmsProp 410 loss=190.635727 err=2.544205
I 2015-05-27 02:13:24 theanets.trainer:168 validation 41 loss=969.570679 err=781.635864 *
I 2015-05-27 02:13:35 theanets.trainer:168 RmsProp 411 loss=190.440460 err=2.641053
I 2015-05-27 02:13:45 theanets.trainer:168 RmsProp 412 loss=190.434723 err=2.927629
I 2015-05-27 02:13:55 theanets.trainer:168 RmsProp 413 loss=189.951202 err=2.735142
I 2015-05-27 02:14:05 theanets.trainer:168 RmsProp 414 loss=189.520523 err=2.590940
I 2015-05-27 02:14:15 theanets.trainer:168 RmsProp 415 loss=189.381653 err=2.736495
I 2015-05-27 02:14:25 theanets.trainer:168 RmsProp 416 loss=189.108887 err=2.748207
I 2015-05-27 02:14:35 theanets.trainer:168 RmsProp 417 loss=188.589966 err=2.518142
I 2015-05-27 02:14:45 theanets.trainer:168 RmsProp 418 loss=188.510071 err=2.723388
I 2015-05-27 02:14:55 theanets.trainer:168 RmsProp 419 loss=187.968262 err=2.472791
I 2015-05-27 02:15:06 theanets.trainer:168 RmsProp 420 loss=187.910431 err=2.701846
I 2015-05-27 02:15:06 theanets.trainer:168 validation 42 loss=965.632019 err=780.579529 *
I 2015-05-27 02:15:16 theanets.trainer:168 RmsProp 421 loss=187.635788 err=2.718000
I 2015-05-27 02:15:26 theanets.trainer:168 RmsProp 422 loss=187.298843 err=2.668274
I 2015-05-27 02:15:36 theanets.trainer:168 RmsProp 423 loss=186.914688 err=2.570296
I 2015-05-27 02:15:46 theanets.trainer:168 RmsProp 424 loss=186.789490 err=2.734375
I 2015-05-27 02:15:56 theanets.trainer:168 RmsProp 425 loss=186.397491 err=2.627907
I 2015-05-27 02:16:04 theanets.trainer:168 RmsProp 426 loss=186.021210 err=2.534522
I 2015-05-27 02:16:13 theanets.trainer:168 RmsProp 427 loss=185.948090 err=2.732422
I 2015-05-27 02:16:21 theanets.trainer:168 RmsProp 428 loss=185.712830 err=2.771574
I 2015-05-27 02:16:29 theanets.trainer:168 RmsProp 429 loss=185.239838 err=2.577089
I 2015-05-27 02:16:37 theanets.trainer:168 RmsProp 430 loss=185.169708 err=2.779027
I 2015-05-27 02:16:37 theanets.trainer:168 validation 43 loss=959.501465 err=777.269836 *
I 2015-05-27 02:16:45 theanets.trainer:168 RmsProp 431 loss=184.624802 err=2.509419
I 2015-05-27 02:16:53 theanets.trainer:168 RmsProp 432 loss=184.384796 err=2.536891
I 2015-05-27 02:17:02 theanets.trainer:168 RmsProp 433 loss=184.546722 err=2.967901
I 2015-05-27 02:17:10 theanets.trainer:168 RmsProp 434 loss=183.972458 err=2.661689
I 2015-05-27 02:17:18 theanets.trainer:168 RmsProp 435 loss=183.619614 err=2.573150
I 2015-05-27 02:17:26 theanets.trainer:168 RmsProp 436 loss=183.335907 err=2.553191
I 2015-05-27 02:17:35 theanets.trainer:168 RmsProp 437 loss=183.393829 err=2.874885
I 2015-05-27 02:17:43 theanets.trainer:168 RmsProp 438 loss=182.924026 err=2.675490
I 2015-05-27 02:17:50 theanets.trainer:168 RmsProp 439 loss=182.479645 err=2.489740
I 2015-05-27 02:17:57 theanets.trainer:168 RmsProp 440 loss=182.356567 err=2.634266
I 2015-05-27 02:17:58 theanets.trainer:168 validation 44 loss=957.332214 err=777.750427 *
I 2015-05-27 02:18:05 theanets.trainer:168 RmsProp 441 loss=182.017883 err=2.560482
I 2015-05-27 02:18:12 theanets.trainer:168 RmsProp 442 loss=181.886902 err=2.693089
I 2015-05-27 02:18:19 theanets.trainer:168 RmsProp 443 loss=181.191223 err=2.268961
I 2015-05-27 02:18:27 theanets.trainer:168 RmsProp 444 loss=181.450470 err=2.792442
I 2015-05-27 02:18:34 theanets.trainer:168 RmsProp 445 loss=180.875549 err=2.486408
I 2015-05-27 02:18:41 theanets.trainer:168 RmsProp 446 loss=180.900024 err=2.769826
I 2015-05-27 02:18:49 theanets.trainer:168 RmsProp 447 loss=180.722549 err=2.852547
I 2015-05-27 02:18:57 theanets.trainer:168 RmsProp 448 loss=180.011322 err=2.396511
I 2015-05-27 02:19:04 theanets.trainer:168 RmsProp 449 loss=180.130402 err=2.770265
I 2015-05-27 02:19:11 theanets.trainer:168 RmsProp 450 loss=179.657623 err=2.556721
I 2015-05-27 02:19:12 theanets.trainer:168 validation 45 loss=950.604553 err=773.627014 *
I 2015-05-27 02:19:20 theanets.trainer:168 RmsProp 451 loss=179.616730 err=2.760586
I 2015-05-27 02:19:27 theanets.trainer:168 RmsProp 452 loss=179.203125 err=2.597783
I 2015-05-27 02:19:35 theanets.trainer:168 RmsProp 453 loss=178.945267 err=2.588821
I 2015-05-27 02:19:44 theanets.trainer:168 RmsProp 454 loss=178.651154 err=2.546121
I 2015-05-27 02:19:51 theanets.trainer:168 RmsProp 455 loss=178.438156 err=2.585600
I 2015-05-27 02:19:59 theanets.trainer:168 RmsProp 456 loss=178.034760 err=2.435003
I 2015-05-27 02:20:08 theanets.trainer:168 RmsProp 457 loss=178.116364 err=2.765498
I 2015-05-27 02:20:16 theanets.trainer:168 RmsProp 458 loss=177.720551 err=2.616588
I 2015-05-27 02:20:24 theanets.trainer:168 RmsProp 459 loss=177.363678 err=2.508790
I 2015-05-27 02:20:32 theanets.trainer:168 RmsProp 460 loss=177.413818 err=2.800668
I 2015-05-27 02:20:32 theanets.trainer:168 validation 46 loss=947.230530 err=772.755188 *
I 2015-05-27 02:20:40 theanets.trainer:168 RmsProp 461 loss=176.802200 err=2.438832
I 2015-05-27 02:20:47 theanets.trainer:168 RmsProp 462 loss=176.876129 err=2.752534
I 2015-05-27 02:20:54 theanets.trainer:168 RmsProp 463 loss=176.352509 err=2.476365
I 2015-05-27 02:21:02 theanets.trainer:168 RmsProp 464 loss=176.183838 err=2.554065
I 2015-05-27 02:21:09 theanets.trainer:168 RmsProp 465 loss=175.898834 err=2.513633
I 2015-05-27 02:21:17 theanets.trainer:168 RmsProp 466 loss=175.772263 err=2.633354
I 2015-05-27 02:21:25 theanets.trainer:168 RmsProp 467 loss=175.354218 err=2.458000
I 2015-05-27 02:21:33 theanets.trainer:168 RmsProp 468 loss=175.181213 err=2.527708
I 2015-05-27 02:21:41 theanets.trainer:168 RmsProp 469 loss=175.140381 err=2.724597
I 2015-05-27 02:21:49 theanets.trainer:168 RmsProp 470 loss=174.672058 err=2.498538
I 2015-05-27 02:21:49 theanets.trainer:168 validation 47 loss=941.170959 err=769.131104 *
I 2015-05-27 02:21:57 theanets.trainer:168 RmsProp 471 loss=174.707062 err=2.770945
I 2015-05-27 02:22:04 theanets.trainer:168 RmsProp 472 loss=174.149368 err=2.449691
I 2015-05-27 02:22:11 theanets.trainer:168 RmsProp 473 loss=173.912720 err=2.447895
I 2015-05-27 02:22:19 theanets.trainer:168 RmsProp 474 loss=173.916855 err=2.686292
I 2015-05-27 02:22:26 theanets.trainer:168 RmsProp 475 loss=173.434723 err=2.443686
I 2015-05-27 02:22:34 theanets.trainer:168 RmsProp 476 loss=173.304596 err=2.546566
I 2015-05-27 02:22:42 theanets.trainer:168 RmsProp 477 loss=173.166153 err=2.644035
I 2015-05-27 02:22:50 theanets.trainer:168 RmsProp 478 loss=172.792343 err=2.502985
I 2015-05-27 02:22:58 theanets.trainer:168 RmsProp 479 loss=172.694077 err=2.636783
I 2015-05-27 02:23:06 theanets.trainer:168 RmsProp 480 loss=172.417953 err=2.592891
I 2015-05-27 02:23:06 theanets.trainer:168 validation 48 loss=940.181274 err=770.472961 *
I 2015-05-27 02:23:13 theanets.trainer:168 RmsProp 481 loss=172.085739 err=2.490170
I 2015-05-27 02:23:22 theanets.trainer:168 RmsProp 482 loss=171.873398 err=2.510981
I 2015-05-27 02:23:29 theanets.trainer:168 RmsProp 483 loss=171.878143 err=2.741386
I 2015-05-27 02:23:36 theanets.trainer:168 RmsProp 484 loss=171.384491 err=2.476567
I 2015-05-27 02:23:43 theanets.trainer:168 RmsProp 485 loss=171.146698 err=2.463743
I 2015-05-27 02:23:51 theanets.trainer:168 RmsProp 486 loss=170.974777 err=2.519555
I 2015-05-27 02:23:59 theanets.trainer:168 RmsProp 487 loss=170.712509 err=2.482822
I 2015-05-27 02:24:06 theanets.trainer:168 RmsProp 488 loss=170.638824 err=2.634255
I 2015-05-27 02:24:15 theanets.trainer:168 RmsProp 489 loss=170.368393 err=2.589178
I 2015-05-27 02:24:22 theanets.trainer:168 RmsProp 490 loss=170.126663 err=2.568779
I 2015-05-27 02:24:23 theanets.trainer:168 validation 49 loss=931.300781 err=763.866821 *
I 2015-05-27 02:24:30 theanets.trainer:168 RmsProp 491 loss=169.776428 err=2.443272
I 2015-05-27 02:24:39 theanets.trainer:168 RmsProp 492 loss=169.745331 err=2.632812
I 2015-05-27 02:24:47 theanets.trainer:168 RmsProp 493 loss=169.440674 err=2.548805
I 2015-05-27 02:24:55 theanets.trainer:168 RmsProp 494 loss=169.094940 err=2.426527
I 2015-05-27 02:25:03 theanets.trainer:168 RmsProp 495 loss=169.186981 err=2.733426
I 2015-05-27 02:25:11 theanets.trainer:168 RmsProp 496 loss=168.690857 err=2.459160
I 2015-05-27 02:25:17 theanets.trainer:168 RmsProp 497 loss=168.661545 err=2.645228
I 2015-05-27 02:25:24 theanets.trainer:168 RmsProp 498 loss=168.172379 err=2.372531
I 2015-05-27 02:25:31 theanets.trainer:168 RmsProp 499 loss=168.021240 err=2.436821
I 2015-05-27 02:25:38 theanets.trainer:168 RmsProp 500 loss=167.901230 err=2.533001
I 2015-05-27 02:25:38 theanets.trainer:168 validation 50 loss=927.366211 err=762.123901 *
I 2015-05-27 02:25:46 theanets.trainer:168 RmsProp 501 loss=167.883942 err=2.733546
I 2015-05-27 02:25:53 theanets.trainer:168 RmsProp 502 loss=167.419418 err=2.484134
I 2015-05-27 02:26:00 theanets.trainer:168 RmsProp 503 loss=167.293198 err=2.572861
I 2015-05-27 02:26:07 theanets.trainer:168 RmsProp 504 loss=166.878265 err=2.374221
I 2015-05-27 02:26:14 theanets.trainer:168 RmsProp 505 loss=166.910645 err=2.617537
I 2015-05-27 02:26:22 theanets.trainer:168 RmsProp 506 loss=166.467682 err=2.393663
I 2015-05-27 02:26:29 theanets.trainer:168 RmsProp 507 loss=166.366364 err=2.504017
I 2015-05-27 02:26:36 theanets.trainer:168 RmsProp 508 loss=166.110077 err=2.462917
I 2015-05-27 02:26:42 theanets.trainer:168 RmsProp 509 loss=165.938644 err=2.502639
I 2015-05-27 02:26:48 theanets.trainer:168 RmsProp 510 loss=165.617752 err=2.402250
I 2015-05-27 02:26:48 theanets.trainer:168 validation 51 loss=922.072388 err=758.961060 *
I 2015-05-27 02:26:54 theanets.trainer:168 RmsProp 511 loss=165.298508 err=2.296585
I 2015-05-27 02:27:00 theanets.trainer:168 RmsProp 512 loss=165.434692 err=2.642182
I 2015-05-27 02:27:06 theanets.trainer:168 RmsProp 513 loss=165.120514 err=2.538574
I 2015-05-27 02:27:12 theanets.trainer:168 RmsProp 514 loss=164.946365 err=2.567925
I 2015-05-27 02:27:19 theanets.trainer:168 RmsProp 515 loss=164.535065 err=2.363458
I 2015-05-27 02:27:25 theanets.trainer:168 RmsProp 516 loss=164.387848 err=2.419907
I 2015-05-27 02:27:31 theanets.trainer:168 RmsProp 517 loss=164.296432 err=2.536236
I 2015-05-27 02:27:37 theanets.trainer:168 RmsProp 518 loss=164.087891 err=2.533459
I 2015-05-27 02:27:44 theanets.trainer:168 RmsProp 519 loss=163.717621 err=2.369394
I 2015-05-27 02:27:50 theanets.trainer:168 RmsProp 520 loss=163.560852 err=2.419426
I 2015-05-27 02:27:50 theanets.trainer:168 validation 52 loss=918.085205 err=757.061523 *
I 2015-05-27 02:27:56 theanets.trainer:168 RmsProp 521 loss=163.568085 err=2.630245
I 2015-05-27 02:28:02 theanets.trainer:168 RmsProp 522 loss=163.136063 err=2.404083
I 2015-05-27 02:28:09 theanets.trainer:168 RmsProp 523 loss=163.076904 err=2.543814
I 2015-05-27 02:28:15 theanets.trainer:168 RmsProp 524 loss=162.695297 err=2.366298
I 2015-05-27 02:28:21 theanets.trainer:168 RmsProp 525 loss=162.693573 err=2.561268
I 2015-05-27 02:28:27 theanets.trainer:168 RmsProp 526 loss=162.546341 err=2.612804
I 2015-05-27 02:28:33 theanets.trainer:168 RmsProp 527 loss=162.197067 err=2.464541
I 2015-05-27 02:28:39 theanets.trainer:168 RmsProp 528 loss=161.912201 err=2.378619
I 2015-05-27 02:28:44 theanets.trainer:168 RmsProp 529 loss=161.844910 err=2.507230
I 2015-05-27 02:28:50 theanets.trainer:168 RmsProp 530 loss=161.692078 err=2.547455
I 2015-05-27 02:28:51 theanets.trainer:168 validation 53 loss=914.297119 err=755.252075 *
I 2015-05-27 02:28:57 theanets.trainer:168 RmsProp 531 loss=161.201721 err=2.258291
I 2015-05-27 02:29:03 theanets.trainer:168 RmsProp 532 loss=161.239273 err=2.493495
I 2015-05-27 02:29:09 theanets.trainer:168 RmsProp 533 loss=161.057953 err=2.509867
I 2015-05-27 02:29:15 theanets.trainer:168 RmsProp 534 loss=160.693619 err=2.347097
I 2015-05-27 02:29:21 theanets.trainer:168 RmsProp 535 loss=160.572693 err=2.424999
I 2015-05-27 02:29:27 theanets.trainer:168 RmsProp 536 loss=160.408600 err=2.458001
I 2015-05-27 02:29:34 theanets.trainer:168 RmsProp 537 loss=160.230591 err=2.476112
I 2015-05-27 02:29:40 theanets.trainer:168 RmsProp 538 loss=160.094254 err=2.534437
I 2015-05-27 02:29:46 theanets.trainer:168 RmsProp 539 loss=159.853638 err=2.484357
I 2015-05-27 02:29:52 theanets.trainer:168 RmsProp 540 loss=159.738953 err=2.562741
I 2015-05-27 02:29:52 theanets.trainer:168 validation 54 loss=906.973877 err=749.898621 *
I 2015-05-27 02:29:58 theanets.trainer:168 RmsProp 541 loss=159.426147 err=2.439599
I 2015-05-27 02:30:05 theanets.trainer:168 RmsProp 542 loss=159.147675 err=2.351118
I 2015-05-27 02:30:11 theanets.trainer:168 RmsProp 543 loss=159.151596 err=2.544461
I 2015-05-27 02:30:17 theanets.trainer:168 RmsProp 544 loss=159.053314 err=2.634501
I 2015-05-27 02:30:23 theanets.trainer:168 RmsProp 545 loss=158.606781 err=2.380983
I 2015-05-27 02:30:29 theanets.trainer:168 RmsProp 546 loss=158.240173 err=2.202961
I 2015-05-27 02:30:36 theanets.trainer:168 RmsProp 547 loss=158.394867 err=2.544121
I 2015-05-27 02:30:42 theanets.trainer:168 RmsProp 548 loss=158.112869 err=2.456541
I 2015-05-27 02:30:49 theanets.trainer:168 RmsProp 549 loss=157.820404 err=2.356742
I 2015-05-27 02:30:54 theanets.trainer:168 RmsProp 550 loss=157.717560 err=2.446157
I 2015-05-27 02:30:55 theanets.trainer:168 validation 55 loss=903.799622 err=748.626953 *
I 2015-05-27 02:31:01 theanets.trainer:168 RmsProp 551 loss=157.489044 err=2.404093
I 2015-05-27 02:31:07 theanets.trainer:168 RmsProp 552 loss=157.395416 err=2.499516
I 2015-05-27 02:31:13 theanets.trainer:168 RmsProp 553 loss=157.079742 err=2.367807
I 2015-05-27 02:31:19 theanets.trainer:168 RmsProp 554 loss=156.851776 err=2.323994
I 2015-05-27 02:31:25 theanets.trainer:168 RmsProp 555 loss=156.950378 err=2.610405
I 2015-05-27 02:31:31 theanets.trainer:168 RmsProp 556 loss=156.507278 err=2.351705
I 2015-05-27 02:31:37 theanets.trainer:168 RmsProp 557 loss=156.227493 err=2.256976
I 2015-05-27 02:31:43 theanets.trainer:168 RmsProp 558 loss=156.298981 err=2.510181
I 2015-05-27 02:31:50 theanets.trainer:168 RmsProp 559 loss=156.034988 err=2.429195
I 2015-05-27 02:31:56 theanets.trainer:168 RmsProp 560 loss=155.964355 err=2.543688
I 2015-05-27 02:31:56 theanets.trainer:168 validation 56 loss=898.158813 err=744.830383 *
I 2015-05-27 02:32:03 theanets.trainer:168 RmsProp 561 loss=155.942245 err=2.698441
I 2015-05-27 02:32:09 theanets.trainer:168 RmsProp 562 loss=155.320206 err=2.257232
I 2015-05-27 02:32:16 theanets.trainer:168 RmsProp 563 loss=155.254791 err=2.367919
I 2015-05-27 02:32:22 theanets.trainer:168 RmsProp 564 loss=155.138428 err=2.433694
I 2015-05-27 02:32:28 theanets.trainer:168 RmsProp 565 loss=154.969879 err=2.441163
I 2015-05-27 02:32:35 theanets.trainer:168 RmsProp 566 loss=154.774429 err=2.427347
I 2015-05-27 02:32:41 theanets.trainer:168 RmsProp 567 loss=154.531860 err=2.362966
I 2015-05-27 02:32:47 theanets.trainer:168 RmsProp 568 loss=154.430389 err=2.438723
I 2015-05-27 02:32:53 theanets.trainer:168 RmsProp 569 loss=154.153351 err=2.341339
I 2015-05-27 02:32:59 theanets.trainer:168 RmsProp 570 loss=153.983887 err=2.347552
I 2015-05-27 02:33:00 theanets.trainer:168 validation 57 loss=893.318115 err=741.775818 *
I 2015-05-27 02:33:06 theanets.trainer:168 RmsProp 571 loss=153.799332 err=2.342439
I 2015-05-27 02:33:12 theanets.trainer:168 RmsProp 572 loss=153.784958 err=2.502883
I 2015-05-27 02:33:18 theanets.trainer:168 RmsProp 573 loss=153.497543 err=2.392339
I 2015-05-27 02:33:24 theanets.trainer:168 RmsProp 574 loss=153.134293 err=2.205496
I 2015-05-27 02:33:30 theanets.trainer:168 RmsProp 575 loss=153.225800 err=2.469185
I 2015-05-27 02:33:36 theanets.trainer:168 RmsProp 576 loss=153.263214 err=2.681226
I 2015-05-27 02:33:42 theanets.trainer:168 RmsProp 577 loss=152.718307 err=2.310089
I 2015-05-27 02:33:48 theanets.trainer:168 RmsProp 578 loss=152.551910 err=2.320298
I 2015-05-27 02:33:54 theanets.trainer:168 RmsProp 579 loss=152.169342 err=2.116645
I 2015-05-27 02:34:00 theanets.trainer:168 RmsProp 580 loss=152.755417 err=2.868941
I 2015-05-27 02:34:01 theanets.trainer:168 validation 58 loss=887.737122 err=737.952759 *
I 2015-05-27 02:34:07 theanets.trainer:168 RmsProp 581 loss=151.926941 err=2.216045
I 2015-05-27 02:34:13 theanets.trainer:168 RmsProp 582 loss=152.023117 err=2.479554
I 2015-05-27 02:34:19 theanets.trainer:168 RmsProp 583 loss=151.888489 err=2.513412
I 2015-05-27 02:34:25 theanets.trainer:168 RmsProp 584 loss=151.618988 err=2.410234
I 2015-05-27 02:34:31 theanets.trainer:168 RmsProp 585 loss=151.248260 err=2.214089
I 2015-05-27 02:34:37 theanets.trainer:168 RmsProp 586 loss=151.312653 err=2.445915
I 2015-05-27 02:34:44 theanets.trainer:168 RmsProp 587 loss=151.101410 err=2.408185
I 2015-05-27 02:34:50 theanets.trainer:168 RmsProp 588 loss=150.775406 err=2.251508
I 2015-05-27 02:34:57 theanets.trainer:168 RmsProp 589 loss=150.717316 err=2.361063
I 2015-05-27 02:35:03 theanets.trainer:168 RmsProp 590 loss=150.600616 err=2.414114
I 2015-05-27 02:35:03 theanets.trainer:168 validation 59 loss=883.816772 err=735.720459 *
I 2015-05-27 02:35:09 theanets.trainer:168 RmsProp 591 loss=150.632797 err=2.611801
I 2015-05-27 02:35:15 theanets.trainer:168 RmsProp 592 loss=150.159302 err=2.307922
I 2015-05-27 02:35:21 theanets.trainer:168 RmsProp 593 loss=150.021011 err=2.331290
I 2015-05-27 02:35:27 theanets.trainer:168 RmsProp 594 loss=149.888763 err=2.367897
I 2015-05-27 02:35:33 theanets.trainer:168 RmsProp 595 loss=149.739075 err=2.386294
I 2015-05-27 02:35:39 theanets.trainer:168 RmsProp 596 loss=149.604797 err=2.420076
I 2015-05-27 02:35:46 theanets.trainer:168 RmsProp 597 loss=149.224274 err=2.208695
I 2015-05-27 02:35:51 theanets.trainer:168 RmsProp 598 loss=149.281952 err=2.426569
I 2015-05-27 02:35:57 theanets.trainer:168 RmsProp 599 loss=149.120255 err=2.431739
I 2015-05-27 02:36:04 theanets.trainer:168 RmsProp 600 loss=148.829422 err=2.308654
I 2015-05-27 02:36:05 theanets.trainer:168 validation 60 loss=880.082092 err=733.633728 *
I 2015-05-27 02:36:11 theanets.trainer:168 RmsProp 601 loss=148.783371 err=2.423433
I 2015-05-27 02:36:17 theanets.trainer:168 RmsProp 602 loss=148.485016 err=2.288157
I 2015-05-27 02:36:23 theanets.trainer:168 RmsProp 603 loss=148.236908 err=2.203697
I 2015-05-27 02:36:29 theanets.trainer:168 RmsProp 604 loss=148.385284 err=2.511438
I 2015-05-27 02:36:35 theanets.trainer:168 RmsProp 605 loss=147.967010 err=2.258759
I 2015-05-27 02:36:41 theanets.trainer:168 RmsProp 606 loss=147.930267 err=2.388927
I 2015-05-27 02:36:47 theanets.trainer:168 RmsProp 607 loss=147.697296 err=2.316746
I 2015-05-27 02:36:53 theanets.trainer:168 RmsProp 608 loss=147.561401 err=2.343904
I 2015-05-27 02:36:59 theanets.trainer:168 RmsProp 609 loss=147.328171 err=2.272926
I 2015-05-27 02:37:04 theanets.trainer:168 RmsProp 610 loss=147.273682 err=2.379054
I 2015-05-27 02:37:05 theanets.trainer:168 validation 61 loss=874.725220 err=729.928650 *
I 2015-05-27 02:37:11 theanets.trainer:168 RmsProp 611 loss=147.011292 err=2.277760
I 2015-05-27 02:37:17 theanets.trainer:168 RmsProp 612 loss=146.967422 err=2.395225
I 2015-05-27 02:37:23 theanets.trainer:168 RmsProp 613 loss=146.722992 err=2.311970
I 2015-05-27 02:37:29 theanets.trainer:168 RmsProp 614 loss=146.846039 err=2.587988
I 2015-05-27 02:37:36 theanets.trainer:168 RmsProp 615 loss=146.471222 err=2.371724
I 2015-05-27 02:37:42 theanets.trainer:168 RmsProp 616 loss=146.295822 err=2.350181
I 2015-05-27 02:37:48 theanets.trainer:168 RmsProp 617 loss=146.172562 err=2.384516
I 2015-05-27 02:37:55 theanets.trainer:168 RmsProp 618 loss=145.816254 err=2.188338
I 2015-05-27 02:38:01 theanets.trainer:168 RmsProp 619 loss=145.933594 err=2.458110
I 2015-05-27 02:38:07 theanets.trainer:168 RmsProp 620 loss=145.548492 err=2.232343
I 2015-05-27 02:38:07 theanets.trainer:168 validation 62 loss=870.643188 err=727.408386 *
I 2015-05-27 02:38:13 theanets.trainer:168 RmsProp 621 loss=145.471024 err=2.307850
I 2015-05-27 02:38:19 theanets.trainer:168 RmsProp 622 loss=145.347778 err=2.340452
I 2015-05-27 02:38:25 theanets.trainer:168 RmsProp 623 loss=145.183792 err=2.334888
I 2015-05-27 02:38:32 theanets.trainer:168 RmsProp 624 loss=144.967194 err=2.275920
I 2015-05-27 02:38:38 theanets.trainer:168 RmsProp 625 loss=144.909836 err=2.373837
I 2015-05-27 02:38:45 theanets.trainer:168 RmsProp 626 loss=144.591675 err=2.209241
I 2015-05-27 02:38:52 theanets.trainer:168 RmsProp 627 loss=144.667084 err=2.441803
I 2015-05-27 02:38:58 theanets.trainer:168 RmsProp 628 loss=144.386108 err=2.310732
I 2015-05-27 02:39:04 theanets.trainer:168 RmsProp 629 loss=144.189636 err=2.266452
I 2015-05-27 02:39:10 theanets.trainer:168 RmsProp 630 loss=144.200806 err=2.432531
I 2015-05-27 02:39:11 theanets.trainer:168 validation 63 loss=866.689636 err=724.991577 *
I 2015-05-27 02:39:17 theanets.trainer:168 RmsProp 631 loss=143.890945 err=2.274774
I 2015-05-27 02:39:24 theanets.trainer:168 RmsProp 632 loss=143.770447 err=2.307368
I 2015-05-27 02:39:30 theanets.trainer:168 RmsProp 633 loss=143.695892 err=2.385781
I 2015-05-27 02:39:36 theanets.trainer:168 RmsProp 634 loss=143.460205 err=2.300513
I 2015-05-27 02:39:43 theanets.trainer:168 RmsProp 635 loss=143.534714 err=2.521909
I 2015-05-27 02:39:49 theanets.trainer:168 RmsProp 636 loss=143.027924 err=2.167428
I 2015-05-27 02:39:56 theanets.trainer:168 RmsProp 637 loss=143.005463 err=2.291317
I 2015-05-27 02:40:02 theanets.trainer:168 RmsProp 638 loss=142.758392 err=2.193180
I 2015-05-27 02:40:09 theanets.trainer:168 RmsProp 639 loss=142.881683 err=2.470625
I 2015-05-27 02:40:15 theanets.trainer:168 RmsProp 640 loss=142.582336 err=2.317779
I 2015-05-27 02:40:15 theanets.trainer:168 validation 64 loss=863.319763 err=723.139832 *
I 2015-05-27 02:40:21 theanets.trainer:168 RmsProp 641 loss=142.352600 err=2.236500
I 2015-05-27 02:40:27 theanets.trainer:168 RmsProp 642 loss=142.228973 err=2.260118
I 2015-05-27 02:40:33 theanets.trainer:168 RmsProp 643 loss=142.261322 err=2.441689
I 2015-05-27 02:40:39 theanets.trainer:168 RmsProp 644 loss=141.942444 err=2.271680
I 2015-05-27 02:40:46 theanets.trainer:168 RmsProp 645 loss=141.726593 err=2.207524
I 2015-05-27 02:40:52 theanets.trainer:168 RmsProp 646 loss=141.718323 err=2.344902
I 2015-05-27 02:40:58 theanets.trainer:168 RmsProp 647 loss=141.545395 err=2.317206
I 2015-05-27 02:41:04 theanets.trainer:168 RmsProp 648 loss=141.407135 err=2.327115
I 2015-05-27 02:41:10 theanets.trainer:168 RmsProp 649 loss=141.388504 err=2.451603
I 2015-05-27 02:41:16 theanets.trainer:168 RmsProp 650 loss=141.080185 err=2.291932
I 2015-05-27 02:41:17 theanets.trainer:168 validation 65 loss=860.463501 err=721.756287 *
I 2015-05-27 02:41:22 theanets.trainer:168 RmsProp 651 loss=140.765656 err=2.121506
I 2015-05-27 02:41:29 theanets.trainer:168 RmsProp 652 loss=140.942459 err=2.439096
I 2015-05-27 02:41:35 theanets.trainer:168 RmsProp 653 loss=140.761826 err=2.402023
I 2015-05-27 02:41:41 theanets.trainer:168 RmsProp 654 loss=140.491974 err=2.276208
I 2015-05-27 02:41:47 theanets.trainer:168 RmsProp 655 loss=140.433792 err=2.360716
I 2015-05-27 02:41:53 theanets.trainer:168 RmsProp 656 loss=140.188171 err=2.260803
I 2015-05-27 02:42:00 theanets.trainer:168 RmsProp 657 loss=140.072220 err=2.289352
I 2015-05-27 02:42:06 theanets.trainer:168 RmsProp 658 loss=139.740112 err=2.102699
I 2015-05-27 02:42:12 theanets.trainer:168 RmsProp 659 loss=139.899567 err=2.403566
I 2015-05-27 02:42:19 theanets.trainer:168 RmsProp 660 loss=139.605347 err=2.257051
I 2015-05-27 02:42:19 theanets.trainer:168 validation 66 loss=853.778687 err=716.502930 *
I 2015-05-27 02:42:25 theanets.trainer:168 RmsProp 661 loss=139.536469 err=2.328240
I 2015-05-27 02:42:31 theanets.trainer:168 RmsProp 662 loss=139.355637 err=2.288335
I 2015-05-27 02:42:37 theanets.trainer:168 RmsProp 663 loss=139.022369 err=2.097428
I 2015-05-27 02:42:44 theanets.trainer:168 RmsProp 664 loss=139.205704 err=2.421563
I 2015-05-27 02:42:51 theanets.trainer:168 RmsProp 665 loss=138.837601 err=2.194344
I 2015-05-27 02:42:56 theanets.trainer:168 RmsProp 666 loss=138.760086 err=2.257192
I 2015-05-27 02:43:03 theanets.trainer:168 RmsProp 667 loss=138.589447 err=2.225931
I 2015-05-27 02:43:09 theanets.trainer:168 RmsProp 668 loss=138.565659 err=2.343620
I 2015-05-27 02:43:15 theanets.trainer:168 RmsProp 669 loss=138.399872 err=2.323537
I 2015-05-27 02:43:21 theanets.trainer:168 RmsProp 670 loss=138.097443 err=2.160082
I 2015-05-27 02:43:21 theanets.trainer:168 validation 67 loss=852.887939 err=717.021545 *
I 2015-05-27 02:43:27 theanets.trainer:168 RmsProp 671 loss=138.070587 err=2.272615
I 2015-05-27 02:43:33 theanets.trainer:168 RmsProp 672 loss=137.785675 err=2.127298
I 2015-05-27 02:43:40 theanets.trainer:168 RmsProp 673 loss=137.823639 err=2.305225
I 2015-05-27 02:43:45 theanets.trainer:168 RmsProp 674 loss=137.733551 err=2.354163
I 2015-05-27 02:43:51 theanets.trainer:168 RmsProp 675 loss=137.667206 err=2.426579
I 2015-05-27 02:43:57 theanets.trainer:168 RmsProp 676 loss=137.462662 err=2.359485
I 2015-05-27 02:44:03 theanets.trainer:168 RmsProp 677 loss=137.117935 err=2.151184
I 2015-05-27 02:44:09 theanets.trainer:168 RmsProp 678 loss=137.037949 err=2.209646
I 2015-05-27 02:44:15 theanets.trainer:168 RmsProp 679 loss=136.973587 err=2.280821
I 2015-05-27 02:44:21 theanets.trainer:168 RmsProp 680 loss=136.803314 err=2.246831
I 2015-05-27 02:44:22 theanets.trainer:168 validation 68 loss=846.011597 err=711.534546 *
I 2015-05-27 02:44:28 theanets.trainer:168 RmsProp 681 loss=136.743744 err=2.321813
I 2015-05-27 02:44:34 theanets.trainer:168 RmsProp 682 loss=136.764313 err=2.473453
I 2015-05-27 02:44:40 theanets.trainer:168 RmsProp 683 loss=136.324203 err=2.168072
I 2015-05-27 02:44:46 theanets.trainer:168 RmsProp 684 loss=136.269379 err=2.245320
I 2015-05-27 02:44:52 theanets.trainer:168 RmsProp 685 loss=136.106125 err=2.216486
I 2015-05-27 02:44:58 theanets.trainer:168 RmsProp 686 loss=136.143326 err=2.384355
I 2015-05-27 02:45:04 theanets.trainer:168 RmsProp 687 loss=135.733932 err=2.112272
I 2015-05-27 02:45:10 theanets.trainer:168 RmsProp 688 loss=135.647354 err=2.163807
I 2015-05-27 02:45:16 theanets.trainer:168 RmsProp 689 loss=135.654800 err=2.304891
I 2015-05-27 02:45:22 theanets.trainer:168 RmsProp 690 loss=135.673935 err=2.459172
I 2015-05-27 02:45:22 theanets.trainer:168 validation 69 loss=843.807678 err=710.659790 *
I 2015-05-27 02:45:28 theanets.trainer:168 RmsProp 691 loss=135.419785 err=2.332798
I 2015-05-27 02:45:34 theanets.trainer:168 RmsProp 692 loss=135.092438 err=2.139364
I 2015-05-27 02:45:40 theanets.trainer:168 RmsProp 693 loss=135.034912 err=2.213005
I 2015-05-27 02:45:46 theanets.trainer:168 RmsProp 694 loss=135.057709 err=2.369045
I 2015-05-27 02:45:52 theanets.trainer:168 RmsProp 695 loss=134.756866 err=2.202267
I 2015-05-27 02:45:58 theanets.trainer:168 RmsProp 696 loss=134.548141 err=2.123423
I 2015-05-27 02:46:04 theanets.trainer:168 RmsProp 697 loss=134.499435 err=2.210491
I 2015-05-27 02:46:11 theanets.trainer:168 RmsProp 698 loss=134.437317 err=2.279480
I 2015-05-27 02:46:17 theanets.trainer:168 RmsProp 699 loss=134.183273 err=2.158525
I 2015-05-27 02:46:23 theanets.trainer:168 RmsProp 700 loss=134.013519 err=2.118731
I 2015-05-27 02:46:23 theanets.trainer:168 validation 70 loss=840.595886 err=708.776672 *
I 2015-05-27 02:46:29 theanets.trainer:168 RmsProp 701 loss=134.125275 err=2.359443
I 2015-05-27 02:46:35 theanets.trainer:168 RmsProp 702 loss=133.842133 err=2.209401
I 2015-05-27 02:46:42 theanets.trainer:168 RmsProp 703 loss=133.853729 err=2.350122
I 2015-05-27 02:46:48 theanets.trainer:168 RmsProp 704 loss=133.774628 err=2.400482
I 2015-05-27 02:46:53 theanets.trainer:168 RmsProp 705 loss=133.358734 err=2.112623
I 2015-05-27 02:47:00 theanets.trainer:168 RmsProp 706 loss=133.398163 err=2.284056
I 2015-05-27 02:47:06 theanets.trainer:168 RmsProp 707 loss=133.148315 err=2.159266
I 2015-05-27 02:47:12 theanets.trainer:168 RmsProp 708 loss=133.120163 err=2.259845
I 2015-05-27 02:47:19 theanets.trainer:168 RmsProp 709 loss=132.887054 err=2.155367
I 2015-05-27 02:47:25 theanets.trainer:168 RmsProp 710 loss=132.773712 err=2.166923
I 2015-05-27 02:47:25 theanets.trainer:168 validation 71 loss=839.867371 err=709.332642 *
I 2015-05-27 02:47:31 theanets.trainer:168 RmsProp 711 loss=132.788910 err=2.311968
I 2015-05-27 02:47:37 theanets.trainer:168 RmsProp 712 loss=132.528809 err=2.179347
I 2015-05-27 02:47:44 theanets.trainer:168 RmsProp 713 loss=132.390686 err=2.170264
I 2015-05-27 02:47:50 theanets.trainer:168 RmsProp 714 loss=132.327789 err=2.232838
I 2015-05-27 02:47:56 theanets.trainer:168 RmsProp 715 loss=132.208542 err=2.240900
I 2015-05-27 02:48:01 theanets.trainer:168 RmsProp 716 loss=132.116821 err=2.275824
I 2015-05-27 02:48:07 theanets.trainer:168 RmsProp 717 loss=132.131989 err=2.416261
I 2015-05-27 02:48:13 theanets.trainer:168 RmsProp 718 loss=131.790009 err=2.201443
I 2015-05-27 02:48:19 theanets.trainer:168 RmsProp 719 loss=131.694794 err=2.229660
I 2015-05-27 02:48:25 theanets.trainer:168 RmsProp 720 loss=131.572586 err=2.229682
I 2015-05-27 02:48:26 theanets.trainer:168 validation 72 loss=832.521667 err=703.244934 *
I 2015-05-27 02:48:32 theanets.trainer:168 RmsProp 721 loss=131.377502 err=2.155757
I 2015-05-27 02:48:38 theanets.trainer:168 RmsProp 722 loss=131.183502 err=2.085059
I 2015-05-27 02:48:44 theanets.trainer:168 RmsProp 723 loss=131.261475 err=2.285113
I 2015-05-27 02:48:51 theanets.trainer:168 RmsProp 724 loss=131.140610 err=2.285877
I 2015-05-27 02:48:57 theanets.trainer:168 RmsProp 725 loss=131.217194 err=2.485569
I 2015-05-27 02:49:03 theanets.trainer:168 RmsProp 726 loss=130.697311 err=2.089200
I 2015-05-27 02:49:09 theanets.trainer:168 RmsProp 727 loss=130.727951 err=2.245160
I 2015-05-27 02:49:15 theanets.trainer:168 RmsProp 728 loss=130.602386 err=2.239167
I 2015-05-27 02:49:22 theanets.trainer:168 RmsProp 729 loss=130.313446 err=2.075968
I 2015-05-27 02:49:27 theanets.trainer:168 RmsProp 730 loss=130.361908 err=2.249704
I 2015-05-27 02:49:28 theanets.trainer:168 validation 73 loss=831.863831 err=703.812683 *
I 2015-05-27 02:49:34 theanets.trainer:168 RmsProp 731 loss=130.284302 err=2.294310
I 2015-05-27 02:49:40 theanets.trainer:168 RmsProp 732 loss=129.978195 err=2.110610
I 2015-05-27 02:49:47 theanets.trainer:168 RmsProp 733 loss=130.035324 err=2.287354
I 2015-05-27 02:49:53 theanets.trainer:168 RmsProp 734 loss=129.763992 err=2.139372
I 2015-05-27 02:49:58 theanets.trainer:168 RmsProp 735 loss=129.757965 err=2.254687
I 2015-05-27 02:50:04 theanets.trainer:168 RmsProp 736 loss=129.470367 err=2.086211
I 2015-05-27 02:50:11 theanets.trainer:168 RmsProp 737 loss=129.448273 err=2.186829
I 2015-05-27 02:50:16 theanets.trainer:168 RmsProp 738 loss=129.352386 err=2.213668
I 2015-05-27 02:50:22 theanets.trainer:168 RmsProp 739 loss=129.257339 err=2.239187
I 2015-05-27 02:50:29 theanets.trainer:168 RmsProp 740 loss=129.054016 err=2.154626
I 2015-05-27 02:50:29 theanets.trainer:168 validation 74 loss=827.282837 err=700.445984 *
I 2015-05-27 02:50:35 theanets.trainer:168 RmsProp 741 loss=128.907455 err=2.130548
I 2015-05-27 02:50:41 theanets.trainer:168 RmsProp 742 loss=129.003143 err=2.345158
I 2015-05-27 02:50:47 theanets.trainer:168 RmsProp 743 loss=128.757599 err=2.217472
I 2015-05-27 02:50:53 theanets.trainer:168 RmsProp 744 loss=128.483002 err=2.062518
I 2015-05-27 02:50:59 theanets.trainer:168 RmsProp 745 loss=128.379456 err=2.075887
I 2015-05-27 02:51:05 theanets.trainer:168 RmsProp 746 loss=128.574905 err=2.386738
I 2015-05-27 02:51:10 theanets.trainer:168 RmsProp 747 loss=128.314087 err=2.242510
I 2015-05-27 02:51:16 theanets.trainer:168 RmsProp 748 loss=128.169952 err=2.216689
I 2015-05-27 02:51:22 theanets.trainer:168 RmsProp 749 loss=128.018906 err=2.180298
I 2015-05-27 02:51:28 theanets.trainer:168 RmsProp 750 loss=127.966896 err=2.248355
I 2015-05-27 02:51:29 theanets.trainer:168 validation 75 loss=825.289734 err=699.632751 *
I 2015-05-27 02:51:35 theanets.trainer:168 RmsProp 751 loss=127.843506 err=2.239704
I 2015-05-27 02:51:41 theanets.trainer:168 RmsProp 752 loss=127.700012 err=2.210293
I 2015-05-27 02:51:47 theanets.trainer:168 RmsProp 753 loss=127.472977 err=2.100414
I 2015-05-27 02:51:53 theanets.trainer:168 RmsProp 754 loss=127.206215 err=1.952106
I 2015-05-27 02:52:00 theanets.trainer:168 RmsProp 755 loss=127.523026 err=2.380280
I 2015-05-27 02:52:06 theanets.trainer:168 RmsProp 756 loss=127.274887 err=2.244453
I 2015-05-27 02:52:11 theanets.trainer:168 RmsProp 757 loss=127.109337 err=2.195740
I 2015-05-27 02:52:17 theanets.trainer:168 RmsProp 758 loss=126.987755 err=2.191298
I 2015-05-27 02:52:23 theanets.trainer:168 RmsProp 759 loss=126.770584 err=2.089864
I 2015-05-27 02:52:30 theanets.trainer:168 RmsProp 760 loss=126.736343 err=2.170180
I 2015-05-27 02:52:31 theanets.trainer:168 validation 76 loss=820.623596 err=696.124634 *
I 2015-05-27 02:52:37 theanets.trainer:168 RmsProp 761 loss=126.655739 err=2.202012
I 2015-05-27 02:52:43 theanets.trainer:168 RmsProp 762 loss=126.491898 err=2.152837
I 2015-05-27 02:52:49 theanets.trainer:168 RmsProp 763 loss=126.435669 err=2.213722
I 2015-05-27 02:52:56 theanets.trainer:168 RmsProp 764 loss=126.324524 err=2.216580
I 2015-05-27 02:53:02 theanets.trainer:168 RmsProp 765 loss=126.148758 err=2.157485
I 2015-05-27 02:53:08 theanets.trainer:168 RmsProp 766 loss=126.040428 err=2.162898
I 2015-05-27 02:53:15 theanets.trainer:168 RmsProp 767 loss=125.939491 err=2.177819
I 2015-05-27 02:53:21 theanets.trainer:168 RmsProp 768 loss=125.750877 err=2.101497
I 2015-05-27 02:53:27 theanets.trainer:168 RmsProp 769 loss=125.753357 err=2.213665
I 2015-05-27 02:53:33 theanets.trainer:168 RmsProp 770 loss=125.473984 err=2.045654
I 2015-05-27 02:53:33 theanets.trainer:168 validation 77 loss=817.697449 err=694.330994 *
I 2015-05-27 02:53:39 theanets.trainer:168 RmsProp 771 loss=125.606766 err=2.291269
I 2015-05-27 02:53:45 theanets.trainer:168 RmsProp 772 loss=125.229492 err=2.032270
I 2015-05-27 02:53:52 theanets.trainer:168 RmsProp 773 loss=125.204674 err=2.118268
I 2015-05-27 02:53:58 theanets.trainer:168 RmsProp 774 loss=125.204285 err=2.235258
I 2015-05-27 02:54:05 theanets.trainer:168 RmsProp 775 loss=125.001358 err=2.142231
I 2015-05-27 02:54:11 theanets.trainer:168 RmsProp 776 loss=124.863258 err=2.116990
I 2015-05-27 02:54:18 theanets.trainer:168 RmsProp 777 loss=124.960403 err=2.321808
I 2015-05-27 02:54:24 theanets.trainer:168 RmsProp 778 loss=124.644554 err=2.117072
I 2015-05-27 02:54:31 theanets.trainer:168 RmsProp 779 loss=124.430176 err=2.018305
I 2015-05-27 02:54:37 theanets.trainer:168 RmsProp 780 loss=124.535538 err=2.235096
I 2015-05-27 02:54:37 theanets.trainer:168 validation 78 loss=815.851318 err=693.606934 *
I 2015-05-27 02:54:44 theanets.trainer:168 RmsProp 781 loss=124.576698 err=2.383297
I 2015-05-27 02:54:50 theanets.trainer:168 RmsProp 782 loss=124.221474 err=2.139174
I 2015-05-27 02:54:56 theanets.trainer:168 RmsProp 783 loss=123.946556 err=1.980324
I 2015-05-27 02:55:02 theanets.trainer:168 RmsProp 784 loss=124.111084 err=2.251232
I 2015-05-27 02:55:08 theanets.trainer:168 RmsProp 785 loss=123.682755 err=1.939966
I 2015-05-27 02:55:15 theanets.trainer:168 RmsProp 786 loss=123.783119 err=2.152222
I 2015-05-27 02:55:22 theanets.trainer:168 RmsProp 787 loss=123.768661 err=2.245804
I 2015-05-27 02:55:27 theanets.trainer:168 RmsProp 788 loss=123.536560 err=2.127575
I 2015-05-27 02:55:34 theanets.trainer:168 RmsProp 789 loss=123.557274 err=2.255352
I 2015-05-27 02:55:40 theanets.trainer:168 RmsProp 790 loss=123.262962 err=2.073344
I 2015-05-27 02:55:40 theanets.trainer:168 validation 79 loss=813.397949 err=692.264954 *
I 2015-05-27 02:55:46 theanets.trainer:168 RmsProp 791 loss=123.144066 err=2.061147
I 2015-05-27 02:55:52 theanets.trainer:168 RmsProp 792 loss=123.076683 err=2.102915
I 2015-05-27 02:55:58 theanets.trainer:168 RmsProp 793 loss=123.053543 err=2.189778
I 2015-05-27 02:56:04 theanets.trainer:168 RmsProp 794 loss=122.952515 err=2.200297
I 2015-05-27 02:56:11 theanets.trainer:168 RmsProp 795 loss=122.787636 err=2.143125
I 2015-05-27 02:56:17 theanets.trainer:168 RmsProp 796 loss=122.614120 err=2.074793
I 2015-05-27 02:56:23 theanets.trainer:168 RmsProp 797 loss=122.605774 err=2.173562
I 2015-05-27 02:56:29 theanets.trainer:168 RmsProp 798 loss=122.523148 err=2.198631
I 2015-05-27 02:56:35 theanets.trainer:168 RmsProp 799 loss=122.387833 err=2.169642
I 2015-05-27 02:56:41 theanets.trainer:168 RmsProp 800 loss=122.283119 err=2.170409
I 2015-05-27 02:56:42 theanets.trainer:168 validation 80 loss=809.713257 err=689.651794 *
I 2015-05-27 02:56:48 theanets.trainer:168 RmsProp 801 loss=122.256226 err=2.247120
I 2015-05-27 02:56:54 theanets.trainer:168 RmsProp 802 loss=122.005226 err=2.101785
I 2015-05-27 02:57:00 theanets.trainer:168 RmsProp 803 loss=121.869118 err=2.073399
I 2015-05-27 02:57:06 theanets.trainer:168 RmsProp 804 loss=121.794884 err=2.109031
I 2015-05-27 02:57:12 theanets.trainer:168 RmsProp 805 loss=121.808556 err=2.225356
I 2015-05-27 02:57:18 theanets.trainer:168 RmsProp 806 loss=121.473412 err=2.000802
I 2015-05-27 02:57:24 theanets.trainer:168 RmsProp 807 loss=121.305923 err=1.940264
I 2015-05-27 02:57:30 theanets.trainer:168 RmsProp 808 loss=121.595337 err=2.331053
I 2015-05-27 02:57:36 theanets.trainer:168 RmsProp 809 loss=121.504051 err=2.343266
I 2015-05-27 02:57:42 theanets.trainer:168 RmsProp 810 loss=121.090927 err=2.035423
I 2015-05-27 02:57:43 theanets.trainer:168 validation 81 loss=804.488403 err=685.488464 *
I 2015-05-27 02:57:48 theanets.trainer:168 RmsProp 811 loss=121.093124 err=2.143329
I 2015-05-27 02:57:55 theanets.trainer:168 RmsProp 812 loss=121.069016 err=2.220030
I 2015-05-27 02:58:01 theanets.trainer:168 RmsProp 813 loss=120.748558 err=2.004000
I 2015-05-27 02:58:08 theanets.trainer:168 RmsProp 814 loss=120.821243 err=2.179667
I 2015-05-27 02:58:14 theanets.trainer:168 RmsProp 815 loss=120.703247 err=2.163828
I 2015-05-27 02:58:20 theanets.trainer:168 RmsProp 816 loss=120.490051 err=2.056290
I 2015-05-27 02:58:26 theanets.trainer:168 RmsProp 817 loss=120.446754 err=2.110541
I 2015-05-27 02:58:32 theanets.trainer:168 RmsProp 818 loss=120.228004 err=1.998857
I 2015-05-27 02:58:39 theanets.trainer:168 RmsProp 819 loss=120.230652 err=2.104373
I 2015-05-27 02:58:45 theanets.trainer:168 RmsProp 820 loss=120.324280 err=2.298096
I 2015-05-27 02:58:45 theanets.trainer:168 validation 82 loss=800.733826 err=682.767334 *
I 2015-05-27 02:58:51 theanets.trainer:168 RmsProp 821 loss=119.715591 err=1.795161
I 2015-05-27 02:58:58 theanets.trainer:168 RmsProp 822 loss=120.254601 err=2.429100
I 2015-05-27 02:59:04 theanets.trainer:168 RmsProp 823 loss=119.904587 err=2.182793
I 2015-05-27 02:59:10 theanets.trainer:168 RmsProp 824 loss=119.711166 err=2.088014
I 2015-05-27 02:59:16 theanets.trainer:168 RmsProp 825 loss=119.614502 err=2.091054
I 2015-05-27 02:59:22 theanets.trainer:168 RmsProp 826 loss=119.504349 err=2.078675
I 2015-05-27 02:59:28 theanets.trainer:168 RmsProp 827 loss=119.456947 err=2.128565
I 2015-05-27 02:59:35 theanets.trainer:168 RmsProp 828 loss=119.337685 err=2.110799
I 2015-05-27 02:59:41 theanets.trainer:168 RmsProp 829 loss=119.594383 err=2.461734
I 2015-05-27 02:59:47 theanets.trainer:168 RmsProp 830 loss=118.977318 err=1.946217
I 2015-05-27 02:59:48 theanets.trainer:168 validation 83 loss=796.088867 err=679.114563 *
I 2015-05-27 02:59:54 theanets.trainer:168 RmsProp 831 loss=119.085709 err=2.150782
I 2015-05-27 03:00:01 theanets.trainer:168 RmsProp 832 loss=118.949448 err=2.113111
I 2015-05-27 03:00:07 theanets.trainer:168 RmsProp 833 loss=118.817993 err=2.079310
I 2015-05-27 03:00:13 theanets.trainer:168 RmsProp 834 loss=118.784767 err=2.145416
I 2015-05-27 03:00:19 theanets.trainer:168 RmsProp 835 loss=118.555984 err=2.015304
I 2015-05-27 03:00:25 theanets.trainer:168 RmsProp 836 loss=118.369423 err=1.927451
I 2015-05-27 03:00:31 theanets.trainer:168 RmsProp 837 loss=118.413574 err=2.068948
I 2015-05-27 03:00:36 theanets.trainer:168 RmsProp 838 loss=118.325378 err=2.078694
I 2015-05-27 03:00:42 theanets.trainer:168 RmsProp 839 loss=118.242043 err=2.097059
I 2015-05-27 03:00:49 theanets.trainer:168 RmsProp 840 loss=118.216331 err=2.167772
I 2015-05-27 03:00:49 theanets.trainer:168 validation 84 loss=799.016785 err=683.007996
I 2015-05-27 03:00:55 theanets.trainer:168 RmsProp 841 loss=117.904953 err=1.951366
I 2015-05-27 03:01:01 theanets.trainer:168 RmsProp 842 loss=118.189392 err=2.333571
I 2015-05-27 03:01:07 theanets.trainer:168 RmsProp 843 loss=117.771225 err=2.011324
I 2015-05-27 03:01:13 theanets.trainer:168 RmsProp 844 loss=117.756165 err=2.092098
I 2015-05-27 03:01:19 theanets.trainer:168 RmsProp 845 loss=117.697289 err=2.126798
I 2015-05-27 03:01:24 theanets.trainer:168 RmsProp 846 loss=117.480080 err=2.007105
I 2015-05-27 03:01:30 theanets.trainer:168 RmsProp 847 loss=117.555832 err=2.176465
I 2015-05-27 03:01:36 theanets.trainer:168 RmsProp 848 loss=117.425011 err=2.140385
I 2015-05-27 03:01:42 theanets.trainer:168 RmsProp 849 loss=117.275047 err=2.086381
I 2015-05-27 03:01:47 theanets.trainer:168 RmsProp 850 loss=117.051292 err=1.961445
I 2015-05-27 03:01:48 theanets.trainer:168 validation 85 loss=795.231995 err=680.196960 *
I 2015-05-27 03:01:54 theanets.trainer:168 RmsProp 851 loss=117.100510 err=2.107782
I 2015-05-27 03:01:59 theanets.trainer:168 RmsProp 852 loss=116.969482 err=2.073723
I 2015-05-27 03:02:05 theanets.trainer:168 RmsProp 853 loss=116.934059 err=2.132225
I 2015-05-27 03:02:11 theanets.trainer:168 RmsProp 854 loss=116.924026 err=2.212633
I 2015-05-27 03:02:17 theanets.trainer:168 RmsProp 855 loss=116.895447 err=2.278049
I 2015-05-27 03:02:22 theanets.trainer:168 RmsProp 856 loss=116.625961 err=2.101705
I 2015-05-27 03:02:29 theanets.trainer:168 RmsProp 857 loss=116.440834 err=2.009375
I 2015-05-27 03:02:34 theanets.trainer:168 RmsProp 858 loss=116.381058 err=2.044005
I 2015-05-27 03:02:40 theanets.trainer:168 RmsProp 859 loss=116.319923 err=2.074251
I 2015-05-27 03:02:46 theanets.trainer:168 RmsProp 860 loss=116.263840 err=2.114690
I 2015-05-27 03:02:46 theanets.trainer:168 validation 86 loss=787.393555 err=673.302246 *
I 2015-05-27 03:02:52 theanets.trainer:168 RmsProp 861 loss=116.158005 err=2.100302
I 2015-05-27 03:02:57 theanets.trainer:168 RmsProp 862 loss=116.159401 err=2.193392
I 2015-05-27 03:03:03 theanets.trainer:168 RmsProp 863 loss=115.858253 err=1.985501
I 2015-05-27 03:03:09 theanets.trainer:168 RmsProp 864 loss=115.869041 err=2.090541
I 2015-05-27 03:03:14 theanets.trainer:168 RmsProp 865 loss=115.802322 err=2.116303
I 2015-05-27 03:03:20 theanets.trainer:168 RmsProp 866 loss=115.638672 err=2.045192
I 2015-05-27 03:03:26 theanets.trainer:168 RmsProp 867 loss=115.779236 err=2.277076
I 2015-05-27 03:03:32 theanets.trainer:168 RmsProp 868 loss=115.321716 err=1.913632
I 2015-05-27 03:03:38 theanets.trainer:168 RmsProp 869 loss=115.483444 err=2.166937
I 2015-05-27 03:03:44 theanets.trainer:168 RmsProp 870 loss=115.251175 err=2.029169
I 2015-05-27 03:03:44 theanets.trainer:168 validation 87 loss=787.650635 err=674.464905
I 2015-05-27 03:03:50 theanets.trainer:168 RmsProp 871 loss=115.430908 err=2.297088
I 2015-05-27 03:03:55 theanets.trainer:168 RmsProp 872 loss=115.134354 err=2.092745
I 2015-05-27 03:04:01 theanets.trainer:168 RmsProp 873 loss=114.935669 err=1.984361
I 2015-05-27 03:04:07 theanets.trainer:168 RmsProp 874 loss=115.035538 err=2.177596
I 2015-05-27 03:04:13 theanets.trainer:168 RmsProp 875 loss=114.791672 err=2.022408
I 2015-05-27 03:04:18 theanets.trainer:168 RmsProp 876 loss=114.762329 err=2.084730
I 2015-05-27 03:04:24 theanets.trainer:168 RmsProp 877 loss=114.721420 err=2.134785
I 2015-05-27 03:04:30 theanets.trainer:168 RmsProp 878 loss=114.536133 err=2.041596
I 2015-05-27 03:04:35 theanets.trainer:168 RmsProp 879 loss=114.401001 err=1.998574
I 2015-05-27 03:04:42 theanets.trainer:168 RmsProp 880 loss=114.567307 err=2.248882
I 2015-05-27 03:04:42 theanets.trainer:168 validation 88 loss=786.861877 err=674.589905 *
I 2015-05-27 03:04:48 theanets.trainer:168 RmsProp 881 loss=114.174606 err=1.950377
I 2015-05-27 03:04:54 theanets.trainer:168 RmsProp 882 loss=114.168007 err=2.035615
I 2015-05-27 03:05:00 theanets.trainer:168 RmsProp 883 loss=114.158707 err=2.115519
I 2015-05-27 03:05:06 theanets.trainer:168 RmsProp 884 loss=114.013489 err=2.062049
I 2015-05-27 03:05:11 theanets.trainer:168 RmsProp 885 loss=114.128258 err=2.264558
I 2015-05-27 03:05:15 theanets.trainer:168 RmsProp 886 loss=113.877586 err=2.103956
I 2015-05-27 03:05:20 theanets.trainer:168 RmsProp 887 loss=113.760483 err=2.073410
I 2015-05-27 03:05:24 theanets.trainer:168 RmsProp 888 loss=113.631676 err=2.034037
I 2015-05-27 03:05:29 theanets.trainer:168 RmsProp 889 loss=113.560043 err=2.047487
I 2015-05-27 03:05:34 theanets.trainer:168 RmsProp 890 loss=113.472336 err=2.046607
I 2015-05-27 03:05:34 theanets.trainer:168 validation 89 loss=779.118591 err=667.746399 *
I 2015-05-27 03:05:39 theanets.trainer:168 RmsProp 891 loss=113.441101 err=2.108098
I 2015-05-27 03:05:44 theanets.trainer:168 RmsProp 892 loss=113.299210 err=2.052655
I 2015-05-27 03:05:48 theanets.trainer:168 RmsProp 893 loss=113.225723 err=2.070414
I 2015-05-27 03:05:54 theanets.trainer:168 RmsProp 894 loss=113.162460 err=2.092796
I 2015-05-27 03:05:59 theanets.trainer:168 RmsProp 895 loss=112.964455 err=1.982954
I 2015-05-27 03:06:03 theanets.trainer:168 RmsProp 896 loss=112.993179 err=2.097884
I 2015-05-27 03:06:08 theanets.trainer:168 RmsProp 897 loss=113.000023 err=2.192338
I 2015-05-27 03:06:12 theanets.trainer:168 RmsProp 898 loss=112.667870 err=1.949190
I 2015-05-27 03:06:17 theanets.trainer:168 RmsProp 899 loss=112.760818 err=2.126941
I 2015-05-27 03:06:23 theanets.trainer:168 RmsProp 900 loss=112.520065 err=1.976326
I 2015-05-27 03:06:23 theanets.trainer:168 validation 90 loss=773.660706 err=663.150391 *
I 2015-05-27 03:06:28 theanets.trainer:168 RmsProp 901 loss=112.530762 err=2.069566
I 2015-05-27 03:06:33 theanets.trainer:168 RmsProp 902 loss=112.260391 err=1.890708
I 2015-05-27 03:06:40 theanets.trainer:168 RmsProp 903 loss=112.460999 err=2.176297
I 2015-05-27 03:06:45 theanets.trainer:168 RmsProp 904 loss=112.175255 err=1.978384
I 2015-05-27 03:06:51 theanets.trainer:168 RmsProp 905 loss=112.298813 err=2.189492
I 2015-05-27 03:06:56 theanets.trainer:168 RmsProp 906 loss=111.969765 err=1.945777
I 2015-05-27 03:07:02 theanets.trainer:168 RmsProp 907 loss=111.920181 err=1.985064
I 2015-05-27 03:07:07 theanets.trainer:168 RmsProp 908 loss=112.074783 err=2.222064
I 2015-05-27 03:07:13 theanets.trainer:168 RmsProp 909 loss=111.856117 err=2.090960
I 2015-05-27 03:07:18 theanets.trainer:168 RmsProp 910 loss=111.655197 err=1.974428
I 2015-05-27 03:07:19 theanets.trainer:168 validation 91 loss=771.693359 err=662.062622 *
I 2015-05-27 03:07:24 theanets.trainer:168 RmsProp 911 loss=111.609276 err=2.015010
I 2015-05-27 03:07:30 theanets.trainer:168 RmsProp 912 loss=111.663391 err=2.153984
I 2015-05-27 03:07:36 theanets.trainer:168 RmsProp 913 loss=111.473251 err=2.045621
I 2015-05-27 03:07:42 theanets.trainer:168 RmsProp 914 loss=111.603004 err=2.258705
I 2015-05-27 03:07:48 theanets.trainer:168 RmsProp 915 loss=111.250832 err=1.991073
I 2015-05-27 03:07:53 theanets.trainer:168 RmsProp 916 loss=111.178139 err=2.003840
I 2015-05-27 03:07:59 theanets.trainer:168 RmsProp 917 loss=111.135254 err=2.043354
I 2015-05-27 03:08:04 theanets.trainer:168 RmsProp 918 loss=111.047035 err=2.036846
I 2015-05-27 03:08:10 theanets.trainer:168 RmsProp 919 loss=111.134628 err=2.208889
I 2015-05-27 03:08:16 theanets.trainer:168 RmsProp 920 loss=110.858688 err=2.014650
I 2015-05-27 03:08:17 theanets.trainer:168 validation 92 loss=770.447266 err=661.648621 *
I 2015-05-27 03:08:22 theanets.trainer:168 RmsProp 921 loss=110.628029 err=1.872392
I 2015-05-27 03:08:29 theanets.trainer:168 RmsProp 922 loss=110.762108 err=2.087722
I 2015-05-27 03:08:35 theanets.trainer:168 RmsProp 923 loss=110.812782 err=2.219811
I 2015-05-27 03:08:40 theanets.trainer:168 RmsProp 924 loss=110.480980 err=1.970670
I 2015-05-27 03:08:46 theanets.trainer:168 RmsProp 925 loss=110.393593 err=1.965673
I 2015-05-27 03:08:52 theanets.trainer:168 RmsProp 926 loss=110.399391 err=2.057288
I 2015-05-27 03:08:58 theanets.trainer:168 RmsProp 927 loss=110.534912 err=2.271938
I 2015-05-27 03:09:04 theanets.trainer:168 RmsProp 928 loss=110.168724 err=1.991757
I 2015-05-27 03:09:10 theanets.trainer:168 RmsProp 929 loss=110.062683 err=1.969055
I 2015-05-27 03:09:16 theanets.trainer:168 RmsProp 930 loss=110.046570 err=2.037596
I 2015-05-27 03:09:17 theanets.trainer:168 validation 93 loss=768.225281 err=660.249817 *
I 2015-05-27 03:09:22 theanets.trainer:168 RmsProp 931 loss=109.937218 err=2.007735
I 2015-05-27 03:09:28 theanets.trainer:168 RmsProp 932 loss=109.601303 err=1.757861
I 2015-05-27 03:09:34 theanets.trainer:168 RmsProp 933 loss=110.211182 err=2.444493
I 2015-05-27 03:09:39 theanets.trainer:168 RmsProp 934 loss=109.698669 err=2.013119
I 2015-05-27 03:09:45 theanets.trainer:168 RmsProp 935 loss=109.305458 err=1.707588
I 2015-05-27 03:09:51 theanets.trainer:168 RmsProp 936 loss=110.032837 err=2.507622
I 2015-05-27 03:09:57 theanets.trainer:168 RmsProp 937 loss=109.316368 err=1.876147
I 2015-05-27 03:10:02 theanets.trainer:168 RmsProp 938 loss=109.393005 err=2.031332
I 2015-05-27 03:10:08 theanets.trainer:168 RmsProp 939 loss=109.295578 err=2.013737
I 2015-05-27 03:10:14 theanets.trainer:168 RmsProp 940 loss=109.357338 err=2.155784
I 2015-05-27 03:10:14 theanets.trainer:168 validation 94 loss=763.658386 err=656.491394 *
I 2015-05-27 03:10:20 theanets.trainer:168 RmsProp 941 loss=109.263626 err=2.140868
I 2015-05-27 03:10:25 theanets.trainer:168 RmsProp 942 loss=108.800560 err=1.763527
I 2015-05-27 03:10:31 theanets.trainer:168 RmsProp 943 loss=109.131714 err=2.170105
I 2015-05-27 03:10:37 theanets.trainer:168 RmsProp 944 loss=109.226402 err=2.343031
I 2015-05-27 03:10:42 theanets.trainer:168 RmsProp 945 loss=108.747330 err=1.945634
I 2015-05-27 03:10:48 theanets.trainer:168 RmsProp 946 loss=108.673073 err=1.950583
I 2015-05-27 03:10:54 theanets.trainer:168 RmsProp 947 loss=108.960411 err=2.312547
I 2015-05-27 03:11:00 theanets.trainer:168 RmsProp 948 loss=108.597534 err=2.028067
I 2015-05-27 03:11:06 theanets.trainer:168 RmsProp 949 loss=108.376808 err=1.888197
I 2015-05-27 03:11:13 theanets.trainer:168 RmsProp 950 loss=108.507080 err=2.092125
I 2015-05-27 03:11:13 theanets.trainer:168 validation 95 loss=761.034302 err=654.660461 *
I 2015-05-27 03:11:19 theanets.trainer:168 RmsProp 951 loss=108.317726 err=1.982975
I 2015-05-27 03:11:25 theanets.trainer:168 RmsProp 952 loss=108.310074 err=2.051529
I 2015-05-27 03:11:31 theanets.trainer:168 RmsProp 953 loss=108.210976 err=2.032946
I 2015-05-27 03:11:37 theanets.trainer:168 RmsProp 954 loss=108.149979 err=2.050691
I 2015-05-27 03:11:42 theanets.trainer:168 RmsProp 955 loss=108.220131 err=2.197126
I 2015-05-27 03:11:48 theanets.trainer:168 RmsProp 956 loss=107.946938 err=2.003523
I 2015-05-27 03:11:54 theanets.trainer:168 RmsProp 957 loss=107.871323 err=2.004751
I 2015-05-27 03:12:00 theanets.trainer:168 RmsProp 958 loss=107.908852 err=2.120553
I 2015-05-27 03:12:05 theanets.trainer:168 RmsProp 959 loss=107.751083 err=2.040819
I 2015-05-27 03:12:11 theanets.trainer:168 RmsProp 960 loss=107.584862 err=1.953861
I 2015-05-27 03:12:11 theanets.trainer:168 validation 96 loss=757.393555 err=651.810059 *
I 2015-05-27 03:12:17 theanets.trainer:168 RmsProp 961 loss=107.570152 err=2.017052
I 2015-05-27 03:12:22 theanets.trainer:168 RmsProp 962 loss=107.421555 err=1.945176
I 2015-05-27 03:12:28 theanets.trainer:168 RmsProp 963 loss=107.557114 err=2.155615
I 2015-05-27 03:12:33 theanets.trainer:168 RmsProp 964 loss=107.576965 err=2.244748
I 2015-05-27 03:12:39 theanets.trainer:168 RmsProp 965 loss=107.243858 err=1.992996
I 2015-05-27 03:12:46 theanets.trainer:168 RmsProp 966 loss=107.060791 err=1.889900
I 2015-05-27 03:12:52 theanets.trainer:168 RmsProp 967 loss=107.311630 err=2.216184
I 2015-05-27 03:12:58 theanets.trainer:168 RmsProp 968 loss=106.920959 err=1.904305
I 2015-05-27 03:13:04 theanets.trainer:168 RmsProp 969 loss=107.065018 err=2.121208
I 2015-05-27 03:13:11 theanets.trainer:168 RmsProp 970 loss=106.667282 err=1.803902
I 2015-05-27 03:13:11 theanets.trainer:168 validation 97 loss=754.505676 err=649.687622 *
I 2015-05-27 03:13:16 theanets.trainer:168 RmsProp 971 loss=106.966843 err=2.178174
I 2015-05-27 03:13:22 theanets.trainer:168 RmsProp 972 loss=106.700539 err=1.986326
I 2015-05-27 03:13:28 theanets.trainer:168 RmsProp 973 loss=106.497635 err=1.860355
I 2015-05-27 03:13:33 theanets.trainer:168 RmsProp 974 loss=106.592491 err=2.031314
I 2015-05-27 03:13:40 theanets.trainer:168 RmsProp 975 loss=106.573837 err=2.089681
I 2015-05-27 03:13:45 theanets.trainer:168 RmsProp 976 loss=106.579788 err=2.170490
I 2015-05-27 03:13:51 theanets.trainer:168 RmsProp 977 loss=106.352516 err=2.019939
I 2015-05-27 03:13:56 theanets.trainer:168 RmsProp 978 loss=106.213722 err=1.957142
I 2015-05-27 03:14:02 theanets.trainer:168 RmsProp 979 loss=106.130409 err=1.949124
I 2015-05-27 03:14:07 theanets.trainer:168 RmsProp 980 loss=106.094559 err=1.987939
I 2015-05-27 03:14:08 theanets.trainer:168 validation 98 loss=753.129456 err=649.064758 *
I 2015-05-27 03:14:13 theanets.trainer:168 RmsProp 981 loss=105.999207 err=1.968694
I 2015-05-27 03:14:19 theanets.trainer:168 RmsProp 982 loss=105.974464 err=2.021445
I 2015-05-27 03:14:24 theanets.trainer:168 RmsProp 983 loss=106.022865 err=2.140758
I 2015-05-27 03:14:31 theanets.trainer:168 RmsProp 984 loss=105.692184 err=1.886725
I 2015-05-27 03:14:37 theanets.trainer:168 RmsProp 985 loss=105.784142 err=2.048543
I 2015-05-27 03:14:43 theanets.trainer:168 RmsProp 986 loss=105.560181 err=1.903986
I 2015-05-27 03:14:49 theanets.trainer:168 RmsProp 987 loss=105.675110 err=2.089674
I 2015-05-27 03:14:55 theanets.trainer:168 RmsProp 988 loss=105.663109 err=2.150225
I 2015-05-27 03:15:02 theanets.trainer:168 RmsProp 989 loss=105.379562 err=1.942813
I 2015-05-27 03:15:08 theanets.trainer:168 RmsProp 990 loss=105.378868 err=2.016840
I 2015-05-27 03:15:08 theanets.trainer:168 validation 99 loss=754.085693 err=650.754578
I 2015-05-27 03:15:14 theanets.trainer:168 RmsProp 991 loss=105.350586 err=2.060248
I 2015-05-27 03:15:19 theanets.trainer:168 RmsProp 992 loss=105.225815 err=2.007134
I 2015-05-27 03:15:26 theanets.trainer:168 RmsProp 993 loss=105.133224 err=1.989293
I 2015-05-27 03:15:32 theanets.trainer:168 RmsProp 994 loss=104.958191 err=1.887619
I 2015-05-27 03:15:38 theanets.trainer:168 RmsProp 995 loss=105.089676 err=2.093818
I 2015-05-27 03:15:44 theanets.trainer:168 RmsProp 996 loss=104.914757 err=1.995323
I 2015-05-27 03:15:50 theanets.trainer:168 RmsProp 997 loss=104.742172 err=1.894452
I 2015-05-27 03:15:57 theanets.trainer:168 RmsProp 998 loss=104.835632 err=2.060732
I 2015-05-27 03:16:02 theanets.trainer:168 RmsProp 999 loss=104.724586 err=2.021901
I 2015-05-27 03:16:08 theanets.trainer:168 RmsProp 1000 loss=104.636574 err=2.007642
I 2015-05-27 03:16:08 theanets.trainer:168 validation 100 loss=743.590088 err=640.999512 *
I 2015-05-27 03:16:14 theanets.trainer:168 RmsProp 1001 loss=104.825157 err=2.267984
I 2015-05-27 03:16:20 theanets.trainer:168 RmsProp 1002 loss=104.437416 err=1.952602
I 2015-05-27 03:16:26 theanets.trainer:168 RmsProp 1003 loss=104.296494 err=1.883503
I 2015-05-27 03:16:33 theanets.trainer:168 RmsProp 1004 loss=104.326759 err=1.984136
I 2015-05-27 03:16:39 theanets.trainer:168 RmsProp 1005 loss=104.191124 err=1.921685
I 2015-05-27 03:16:45 theanets.trainer:168 RmsProp 1006 loss=104.185501 err=1.987058
I 2015-05-27 03:16:51 theanets.trainer:168 RmsProp 1007 loss=104.210739 err=2.084592
I 2015-05-27 03:16:57 theanets.trainer:168 RmsProp 1008 loss=103.947853 err=1.894346
I 2015-05-27 03:17:03 theanets.trainer:168 RmsProp 1009 loss=103.994095 err=2.011523
I 2015-05-27 03:17:10 theanets.trainer:168 RmsProp 1010 loss=104.037659 err=2.127517
I 2015-05-27 03:17:10 theanets.trainer:168 validation 101 loss=748.086670 err=646.213013
I 2015-05-27 03:17:16 theanets.trainer:168 RmsProp 1011 loss=103.535233 err=1.701674
I 2015-05-27 03:17:22 theanets.trainer:168 RmsProp 1012 loss=104.135155 err=2.365463
I 2015-05-27 03:17:27 theanets.trainer:168 RmsProp 1013 loss=103.626183 err=1.929268
I 2015-05-27 03:17:33 theanets.trainer:168 RmsProp 1014 loss=103.620361 err=1.995452
I 2015-05-27 03:17:38 theanets.trainer:168 RmsProp 1015 loss=103.569496 err=2.016206
I 2015-05-27 03:17:44 theanets.trainer:168 RmsProp 1016 loss=103.380386 err=1.897811
I 2015-05-27 03:17:50 theanets.trainer:168 RmsProp 1017 loss=103.305443 err=1.897499
I 2015-05-27 03:17:55 theanets.trainer:168 RmsProp 1018 loss=103.530258 err=2.187908
I 2015-05-27 03:18:02 theanets.trainer:168 RmsProp 1019 loss=103.131241 err=1.863365
I 2015-05-27 03:18:08 theanets.trainer:168 RmsProp 1020 loss=102.991348 err=1.798527
I 2015-05-27 03:18:09 theanets.trainer:168 validation 102 loss=746.708252 err=645.537781
I 2015-05-27 03:18:14 theanets.trainer:168 RmsProp 1021 loss=103.224731 err=2.099308
I 2015-05-27 03:18:21 theanets.trainer:168 RmsProp 1022 loss=103.235596 err=2.177668
I 2015-05-27 03:18:27 theanets.trainer:168 RmsProp 1023 loss=102.860718 err=1.875641
I 2015-05-27 03:18:33 theanets.trainer:168 RmsProp 1024 loss=102.945900 err=2.030162
I 2015-05-27 03:18:39 theanets.trainer:168 RmsProp 1025 loss=102.783363 err=1.937166
I 2015-05-27 03:18:46 theanets.trainer:168 RmsProp 1026 loss=102.694992 err=1.920881
I 2015-05-27 03:18:52 theanets.trainer:168 RmsProp 1027 loss=102.464088 err=1.761266
I 2015-05-27 03:18:58 theanets.trainer:168 RmsProp 1028 loss=102.563698 err=1.929333
I 2015-05-27 03:19:04 theanets.trainer:168 RmsProp 1029 loss=102.602097 err=2.035986
I 2015-05-27 03:19:11 theanets.trainer:168 RmsProp 1030 loss=102.468185 err=1.974857
I 2015-05-27 03:19:11 theanets.trainer:168 validation 103 loss=742.250366 err=641.793152 *
I 2015-05-27 03:19:17 theanets.trainer:168 RmsProp 1031 loss=102.620201 err=2.193996
I 2015-05-27 03:19:23 theanets.trainer:168 RmsProp 1032 loss=102.343155 err=1.987395
I 2015-05-27 03:19:29 theanets.trainer:168 RmsProp 1033 loss=102.265053 err=1.979012
I 2015-05-27 03:19:35 theanets.trainer:168 RmsProp 1034 loss=102.130501 err=1.914136
I 2015-05-27 03:19:40 theanets.trainer:168 RmsProp 1035 loss=102.016548 err=1.873960
I 2015-05-27 03:19:46 theanets.trainer:168 RmsProp 1036 loss=102.086868 err=2.010915
I 2015-05-27 03:19:52 theanets.trainer:168 RmsProp 1037 loss=102.097488 err=2.088451
I 2015-05-27 03:19:58 theanets.trainer:168 RmsProp 1038 loss=101.704025 err=1.764456
I 2015-05-27 03:20:03 theanets.trainer:168 RmsProp 1039 loss=101.895714 err=2.023579
I 2015-05-27 03:20:09 theanets.trainer:168 RmsProp 1040 loss=101.796875 err=1.992886
I 2015-05-27 03:20:09 theanets.trainer:168 validation 104 loss=732.463501 err=632.688416 *
I 2015-05-27 03:20:15 theanets.trainer:168 RmsProp 1041 loss=101.587585 err=1.853561
I 2015-05-27 03:20:20 theanets.trainer:168 RmsProp 1042 loss=101.802750 err=2.136955
I 2015-05-27 03:20:26 theanets.trainer:168 RmsProp 1043 loss=101.790764 err=2.188997
I 2015-05-27 03:20:32 theanets.trainer:168 RmsProp 1044 loss=101.455185 err=1.921676
I 2015-05-27 03:20:37 theanets.trainer:168 RmsProp 1045 loss=101.361916 err=1.897112
I 2015-05-27 03:20:43 theanets.trainer:168 RmsProp 1046 loss=101.416016 err=2.017179
I 2015-05-27 03:20:49 theanets.trainer:168 RmsProp 1047 loss=101.282120 err=1.952059
I 2015-05-27 03:20:56 theanets.trainer:168 RmsProp 1048 loss=101.260086 err=1.992826
I 2015-05-27 03:21:02 theanets.trainer:168 RmsProp 1049 loss=101.019852 err=1.824790
I 2015-05-27 03:21:07 theanets.trainer:168 RmsProp 1050 loss=101.199371 err=2.070749
I 2015-05-27 03:21:08 theanets.trainer:168 validation 105 loss=733.812866 err=634.714050
I 2015-05-27 03:21:13 theanets.trainer:168 RmsProp 1051 loss=100.879097 err=1.819579
I 2015-05-27 03:21:19 theanets.trainer:168 RmsProp 1052 loss=100.991714 err=2.000085
I 2015-05-27 03:21:24 theanets.trainer:168 RmsProp 1053 loss=100.863602 err=1.937437
I 2015-05-27 03:21:30 theanets.trainer:168 RmsProp 1054 loss=100.872475 err=2.013728
I 2015-05-27 03:21:35 theanets.trainer:168 RmsProp 1055 loss=100.806213 err=2.013760
I 2015-05-27 03:21:40 theanets.trainer:168 RmsProp 1056 loss=100.713669 err=1.989230
I 2015-05-27 03:21:45 theanets.trainer:168 RmsProp 1057 loss=100.311737 err=1.655816
I 2015-05-27 03:21:50 theanets.trainer:168 RmsProp 1058 loss=100.732025 err=2.142184
I 2015-05-27 03:21:55 theanets.trainer:168 RmsProp 1059 loss=100.378777 err=1.858686
I 2015-05-27 03:22:00 theanets.trainer:168 RmsProp 1060 loss=100.405037 err=1.949721
I 2015-05-27 03:22:01 theanets.trainer:168 validation 106 loss=731.047363 err=632.627869 *
I 2015-05-27 03:22:06 theanets.trainer:168 RmsProp 1061 loss=100.290146 err=1.903220
I 2015-05-27 03:22:10 theanets.trainer:168 RmsProp 1062 loss=100.306122 err=1.981150
I 2015-05-27 03:22:15 theanets.trainer:168 RmsProp 1063 loss=100.092575 err=1.837468
I 2015-05-27 03:22:20 theanets.trainer:168 RmsProp 1064 loss=100.282852 err=2.093700
I 2015-05-27 03:22:25 theanets.trainer:168 RmsProp 1065 loss=100.095360 err=1.974632
I 2015-05-27 03:22:30 theanets.trainer:168 RmsProp 1066 loss=99.859581 err=1.805070
I 2015-05-27 03:22:35 theanets.trainer:168 RmsProp 1067 loss=100.140121 err=2.147571
I 2015-05-27 03:22:40 theanets.trainer:168 RmsProp 1068 loss=99.881363 err=1.954665
I 2015-05-27 03:22:45 theanets.trainer:168 RmsProp 1069 loss=99.772209 err=1.910720
I 2015-05-27 03:22:50 theanets.trainer:168 RmsProp 1070 loss=99.908295 err=2.113300
I 2015-05-27 03:22:51 theanets.trainer:168 validation 107 loss=726.125183 err=628.368286 *
I 2015-05-27 03:22:55 theanets.trainer:168 RmsProp 1071 loss=99.583092 err=1.853113
I 2015-05-27 03:23:01 theanets.trainer:168 RmsProp 1072 loss=99.595871 err=1.932052
I 2015-05-27 03:23:06 theanets.trainer:168 RmsProp 1073 loss=99.515121 err=1.917356
I 2015-05-27 03:23:11 theanets.trainer:168 RmsProp 1074 loss=99.672394 err=2.135690
I 2015-05-27 03:23:16 theanets.trainer:168 RmsProp 1075 loss=99.362984 err=1.894941
I 2015-05-27 03:23:21 theanets.trainer:168 RmsProp 1076 loss=99.285172 err=1.881068
I 2015-05-27 03:23:27 theanets.trainer:168 RmsProp 1077 loss=99.182938 err=1.843583
I 2015-05-27 03:23:32 theanets.trainer:168 RmsProp 1078 loss=99.103905 err=1.828658
I 2015-05-27 03:23:37 theanets.trainer:168 RmsProp 1079 loss=99.199989 err=1.990255
I 2015-05-27 03:23:42 theanets.trainer:168 RmsProp 1080 loss=99.116776 err=1.971759
I 2015-05-27 03:23:42 theanets.trainer:168 validation 108 loss=722.267700 err=625.148438 *
I 2015-05-27 03:23:47 theanets.trainer:168 RmsProp 1081 loss=98.966301 err=1.885461
I 2015-05-27 03:23:52 theanets.trainer:168 RmsProp 1082 loss=98.983292 err=1.966821
I 2015-05-27 03:23:57 theanets.trainer:168 RmsProp 1083 loss=99.091751 err=2.137897
I 2015-05-27 03:24:02 theanets.trainer:168 RmsProp 1084 loss=98.731361 err=1.843472
I 2015-05-27 03:24:08 theanets.trainer:168 RmsProp 1085 loss=98.913200 err=2.083089
I 2015-05-27 03:24:13 theanets.trainer:168 RmsProp 1086 loss=98.572243 err=1.805233
I 2015-05-27 03:24:18 theanets.trainer:168 RmsProp 1087 loss=98.611465 err=1.910346
I 2015-05-27 03:24:23 theanets.trainer:168 RmsProp 1088 loss=98.617783 err=1.977768
I 2015-05-27 03:24:28 theanets.trainer:168 RmsProp 1089 loss=98.401962 err=1.830855
I 2015-05-27 03:24:33 theanets.trainer:168 RmsProp 1090 loss=98.459694 err=1.949357
I 2015-05-27 03:24:34 theanets.trainer:168 validation 109 loss=724.763489 err=628.286682
I 2015-05-27 03:24:38 theanets.trainer:168 RmsProp 1091 loss=98.387161 err=1.937768
I 2015-05-27 03:24:43 theanets.trainer:168 RmsProp 1092 loss=98.304443 err=1.918064
I 2015-05-27 03:24:48 theanets.trainer:168 RmsProp 1093 loss=98.306625 err=1.982683
I 2015-05-27 03:24:54 theanets.trainer:168 RmsProp 1094 loss=98.207642 err=1.945978
I 2015-05-27 03:24:59 theanets.trainer:168 RmsProp 1095 loss=98.370010 err=2.170664
I 2015-05-27 03:25:04 theanets.trainer:168 RmsProp 1096 loss=98.083412 err=1.949482
I 2015-05-27 03:25:09 theanets.trainer:168 RmsProp 1097 loss=97.787209 err=1.717785
I 2015-05-27 03:25:14 theanets.trainer:168 RmsProp 1098 loss=98.027390 err=2.018000
I 2015-05-27 03:25:19 theanets.trainer:168 RmsProp 1099 loss=97.860870 err=1.913990
I 2015-05-27 03:25:25 theanets.trainer:168 RmsProp 1100 loss=97.890640 err=2.004897
I 2015-05-27 03:25:25 theanets.trainer:168 validation 110 loss=721.479614 err=625.633545 *
I 2015-05-27 03:25:30 theanets.trainer:168 RmsProp 1101 loss=97.774918 err=1.954079
I 2015-05-27 03:25:35 theanets.trainer:168 RmsProp 1102 loss=97.715782 err=1.955236
I 2015-05-27 03:25:40 theanets.trainer:168 RmsProp 1103 loss=97.586166 err=1.889087
I 2015-05-27 03:25:45 theanets.trainer:168 RmsProp 1104 loss=97.544052 err=1.910352
I 2015-05-27 03:25:50 theanets.trainer:168 RmsProp 1105 loss=97.556206 err=1.983525
I 2015-05-27 03:25:55 theanets.trainer:168 RmsProp 1106 loss=97.408142 err=1.898930
I 2015-05-27 03:26:01 theanets.trainer:168 RmsProp 1107 loss=97.214615 err=1.766037
I 2015-05-27 03:26:06 theanets.trainer:168 RmsProp 1108 loss=97.343895 err=1.954016
I 2015-05-27 03:26:11 theanets.trainer:168 RmsProp 1109 loss=97.230408 err=1.903209
I 2015-05-27 03:26:16 theanets.trainer:168 RmsProp 1110 loss=97.214668 err=1.954582
I 2015-05-27 03:26:17 theanets.trainer:168 validation 111 loss=713.295166 err=618.067688 *
I 2015-05-27 03:26:21 theanets.trainer:168 RmsProp 1111 loss=97.106827 err=1.908123
I 2015-05-27 03:26:26 theanets.trainer:168 RmsProp 1112 loss=97.029289 err=1.892358
I 2015-05-27 03:26:31 theanets.trainer:168 RmsProp 1113 loss=96.952568 err=1.875010
I 2015-05-27 03:26:37 theanets.trainer:168 RmsProp 1114 loss=96.872116 err=1.855604
I 2015-05-27 03:26:42 theanets.trainer:168 RmsProp 1115 loss=96.926025 err=1.972116
I 2015-05-27 03:26:47 theanets.trainer:168 RmsProp 1116 loss=97.121208 err=2.224990
I 2015-05-27 03:26:52 theanets.trainer:168 RmsProp 1117 loss=96.792183 err=1.959999
I 2015-05-27 03:26:57 theanets.trainer:168 RmsProp 1118 loss=96.571121 err=1.801714
I 2015-05-27 03:27:02 theanets.trainer:168 RmsProp 1119 loss=96.712143 err=2.003442
I 2015-05-27 03:27:08 theanets.trainer:168 RmsProp 1120 loss=96.443420 err=1.793920
I 2015-05-27 03:27:08 theanets.trainer:168 validation 112 loss=713.896667 err=619.283020
I 2015-05-27 03:27:13 theanets.trainer:168 RmsProp 1121 loss=96.588913 err=1.996871
I 2015-05-27 03:27:18 theanets.trainer:168 RmsProp 1122 loss=96.409492 err=1.878468
I 2015-05-27 03:27:23 theanets.trainer:168 RmsProp 1123 loss=96.355476 err=1.885251
I 2015-05-27 03:27:28 theanets.trainer:168 RmsProp 1124 loss=96.501724 err=2.093707
I 2015-05-27 03:27:34 theanets.trainer:168 RmsProp 1125 loss=96.432022 err=2.080715
I 2015-05-27 03:27:39 theanets.trainer:168 RmsProp 1126 loss=96.143852 err=1.854177
I 2015-05-27 03:27:44 theanets.trainer:168 RmsProp 1127 loss=96.022285 err=1.794358
I 2015-05-27 03:27:49 theanets.trainer:168 RmsProp 1128 loss=96.160110 err=1.992730
I 2015-05-27 03:27:54 theanets.trainer:168 RmsProp 1129 loss=96.022758 err=1.917463
I 2015-05-27 03:27:59 theanets.trainer:168 RmsProp 1130 loss=96.030434 err=1.984362
I 2015-05-27 03:28:00 theanets.trainer:168 validation 113 loss=711.283325 err=617.266235 *
I 2015-05-27 03:28:04 theanets.trainer:168 RmsProp 1131 loss=95.949303 err=1.964191
I 2015-05-27 03:28:09 theanets.trainer:168 RmsProp 1132 loss=95.832283 err=1.906520
I 2015-05-27 03:28:14 theanets.trainer:168 RmsProp 1133 loss=95.772964 err=1.908604
I 2015-05-27 03:28:20 theanets.trainer:168 RmsProp 1134 loss=95.700684 err=1.893358
I 2015-05-27 03:28:25 theanets.trainer:168 RmsProp 1135 loss=95.608780 err=1.859918
I 2015-05-27 03:28:30 theanets.trainer:168 RmsProp 1136 loss=95.529396 err=1.843837
I 2015-05-27 03:28:35 theanets.trainer:168 RmsProp 1137 loss=95.621933 err=1.996034
I 2015-05-27 03:28:40 theanets.trainer:168 RmsProp 1138 loss=95.445198 err=1.879833
I 2015-05-27 03:28:45 theanets.trainer:168 RmsProp 1139 loss=95.402481 err=1.895629
I 2015-05-27 03:28:51 theanets.trainer:168 RmsProp 1140 loss=95.350784 err=1.906598
I 2015-05-27 03:28:51 theanets.trainer:168 validation 114 loss=709.298340 err=615.879028 *
I 2015-05-27 03:28:56 theanets.trainer:168 RmsProp 1141 loss=95.279282 err=1.890636
I 2015-05-27 03:29:00 theanets.trainer:168 RmsProp 1142 loss=95.208214 err=1.879283
I 2015-05-27 03:29:06 theanets.trainer:168 RmsProp 1143 loss=95.174088 err=1.906655
I 2015-05-27 03:29:11 theanets.trainer:168 RmsProp 1144 loss=95.067024 err=1.857810
I 2015-05-27 03:29:16 theanets.trainer:168 RmsProp 1145 loss=95.055527 err=1.906520
I 2015-05-27 03:29:21 theanets.trainer:168 RmsProp 1146 loss=95.001183 err=1.910964
I 2015-05-27 03:29:26 theanets.trainer:168 RmsProp 1147 loss=94.774399 err=1.744532
I 2015-05-27 03:29:31 theanets.trainer:168 RmsProp 1148 loss=94.929428 err=1.956666
I 2015-05-27 03:29:36 theanets.trainer:168 RmsProp 1149 loss=94.759171 err=1.846229
I 2015-05-27 03:29:41 theanets.trainer:168 RmsProp 1150 loss=94.684647 err=1.829990
I 2015-05-27 03:29:41 theanets.trainer:168 validation 115 loss=709.056763 err=616.236633 *
I 2015-05-27 03:29:46 theanets.trainer:168 RmsProp 1151 loss=94.820694 err=2.024531
I 2015-05-27 03:29:50 theanets.trainer:168 RmsProp 1152 loss=94.665009 err=1.930014
I 2015-05-27 03:29:55 theanets.trainer:168 RmsProp 1153 loss=94.497513 err=1.821961
I 2015-05-27 03:29:59 theanets.trainer:168 RmsProp 1154 loss=94.601402 err=1.982361
I 2015-05-27 03:30:04 theanets.trainer:168 RmsProp 1155 loss=94.375183 err=1.816690
I 2015-05-27 03:30:09 theanets.trainer:168 RmsProp 1156 loss=94.414314 err=1.913432
I 2015-05-27 03:30:14 theanets.trainer:168 RmsProp 1157 loss=94.420151 err=1.978916
I 2015-05-27 03:30:19 theanets.trainer:168 RmsProp 1158 loss=94.102570 err=1.723025
I 2015-05-27 03:30:24 theanets.trainer:168 RmsProp 1159 loss=94.326218 err=2.003016
I 2015-05-27 03:30:29 theanets.trainer:168 RmsProp 1160 loss=94.370377 err=2.102302
I 2015-05-27 03:30:30 theanets.trainer:168 validation 116 loss=706.137085 err=613.905090 *
I 2015-05-27 03:30:34 theanets.trainer:168 RmsProp 1161 loss=93.932762 err=1.725816
I 2015-05-27 03:30:39 theanets.trainer:168 RmsProp 1162 loss=94.143784 err=1.995258
I 2015-05-27 03:30:45 theanets.trainer:168 RmsProp 1163 loss=93.862282 err=1.771961
I 2015-05-27 03:30:50 theanets.trainer:168 RmsProp 1164 loss=94.047783 err=2.015373
I 2015-05-27 03:30:55 theanets.trainer:168 RmsProp 1165 loss=93.912971 err=1.937928
I 2015-05-27 03:31:00 theanets.trainer:168 RmsProp 1166 loss=93.811577 err=1.894412
I 2015-05-27 03:31:05 theanets.trainer:168 RmsProp 1167 loss=93.639641 err=1.778028
I 2015-05-27 03:31:10 theanets.trainer:168 RmsProp 1168 loss=93.622467 err=1.819495
I 2015-05-27 03:31:16 theanets.trainer:168 RmsProp 1169 loss=93.667984 err=1.921341
I 2015-05-27 03:31:21 theanets.trainer:168 RmsProp 1170 loss=93.759293 err=2.070717
I 2015-05-27 03:31:21 theanets.trainer:168 validation 117 loss=703.466919 err=611.812927 *
I 2015-05-27 03:31:26 theanets.trainer:168 RmsProp 1171 loss=93.379539 err=1.752849
I 2015-05-27 03:31:31 theanets.trainer:168 RmsProp 1172 loss=93.501076 err=1.928643
I 2015-05-27 03:31:36 theanets.trainer:168 RmsProp 1173 loss=93.441635 err=1.927259
I 2015-05-27 03:31:42 theanets.trainer:168 RmsProp 1174 loss=93.352173 err=1.892807
I 2015-05-27 03:31:47 theanets.trainer:168 RmsProp 1175 loss=93.288773 err=1.889044
I 2015-05-27 03:31:52 theanets.trainer:168 RmsProp 1176 loss=93.160263 err=1.817256
I 2015-05-27 03:31:57 theanets.trainer:168 RmsProp 1177 loss=93.159531 err=1.874620
I 2015-05-27 03:32:02 theanets.trainer:168 RmsProp 1178 loss=93.084457 err=1.857591
I 2015-05-27 03:32:07 theanets.trainer:168 RmsProp 1179 loss=93.172798 err=1.999707
I 2015-05-27 03:32:12 theanets.trainer:168 RmsProp 1180 loss=92.833649 err=1.719208
I 2015-05-27 03:32:13 theanets.trainer:168 validation 118 loss=703.038574 err=611.956848 *
I 2015-05-27 03:32:17 theanets.trainer:168 RmsProp 1181 loss=92.920303 err=1.862888
I 2015-05-27 03:32:23 theanets.trainer:168 RmsProp 1182 loss=92.854568 err=1.855977
I 2015-05-27 03:32:28 theanets.trainer:168 RmsProp 1183 loss=92.755722 err=1.811555
I 2015-05-27 03:32:33 theanets.trainer:168 RmsProp 1184 loss=92.873306 err=1.983100
I 2015-05-27 03:32:38 theanets.trainer:168 RmsProp 1185 loss=92.621445 err=1.788176
I 2015-05-27 03:32:43 theanets.trainer:168 RmsProp 1186 loss=92.595406 err=1.818353
I 2015-05-27 03:32:48 theanets.trainer:168 RmsProp 1187 loss=92.734077 err=2.013850
I 2015-05-27 03:32:53 theanets.trainer:168 RmsProp 1188 loss=92.624130 err=1.955541
I 2015-05-27 03:32:58 theanets.trainer:168 RmsProp 1189 loss=92.241623 err=1.635341
I 2015-05-27 03:33:03 theanets.trainer:168 RmsProp 1190 loss=92.604294 err=2.051095
I 2015-05-27 03:33:03 theanets.trainer:168 validation 119 loss=705.630798 err=615.104980
I 2015-05-27 03:33:08 theanets.trainer:168 RmsProp 1191 loss=92.535576 err=2.039742
I 2015-05-27 03:33:13 theanets.trainer:168 RmsProp 1192 loss=92.331772 err=1.891800
I 2015-05-27 03:33:18 theanets.trainer:168 RmsProp 1193 loss=92.214279 err=1.829358
I 2015-05-27 03:33:24 theanets.trainer:168 RmsProp 1194 loss=92.150864 err=1.823251
I 2015-05-27 03:33:29 theanets.trainer:168 RmsProp 1195 loss=92.149689 err=1.876170
I 2015-05-27 03:33:34 theanets.trainer:168 RmsProp 1196 loss=92.251801 err=2.031592
I 2015-05-27 03:33:39 theanets.trainer:168 RmsProp 1197 loss=91.929886 err=1.767027
I 2015-05-27 03:33:44 theanets.trainer:168 RmsProp 1198 loss=91.799210 err=1.694770
I 2015-05-27 03:33:49 theanets.trainer:168 RmsProp 1199 loss=91.894035 err=1.846772
I 2015-05-27 03:33:55 theanets.trainer:168 RmsProp 1200 loss=91.877609 err=1.886407
I 2015-05-27 03:33:55 theanets.trainer:168 validation 120 loss=697.084473 err=607.125122 *
I 2015-05-27 03:34:00 theanets.trainer:168 RmsProp 1201 loss=91.868484 err=1.931221
I 2015-05-27 03:34:05 theanets.trainer:168 RmsProp 1202 loss=91.650673 err=1.768983
I 2015-05-27 03:34:10 theanets.trainer:168 RmsProp 1203 loss=91.682976 err=1.856658
I 2015-05-27 03:34:14 theanets.trainer:168 RmsProp 1204 loss=91.770569 err=1.997897
I 2015-05-27 03:34:19 theanets.trainer:168 RmsProp 1205 loss=91.456772 err=1.742299
I 2015-05-27 03:34:24 theanets.trainer:168 RmsProp 1206 loss=91.587631 err=1.928048
I 2015-05-27 03:34:28 theanets.trainer:168 RmsProp 1207 loss=91.364861 err=1.760772
I 2015-05-27 03:34:33 theanets.trainer:168 RmsProp 1208 loss=91.451141 err=1.903911
I 2015-05-27 03:34:37 theanets.trainer:168 RmsProp 1209 loss=91.341949 err=1.849920
I 2015-05-27 03:34:43 theanets.trainer:168 RmsProp 1210 loss=91.395309 err=1.955389
I 2015-05-27 03:34:43 theanets.trainer:168 validation 121 loss=694.338623 err=604.923767 *
I 2015-05-27 03:34:48 theanets.trainer:168 RmsProp 1211 loss=91.474037 err=2.082484
I 2015-05-27 03:34:53 theanets.trainer:168 RmsProp 1212 loss=91.160751 err=1.824700
I 2015-05-27 03:34:58 theanets.trainer:168 RmsProp 1213 loss=91.124069 err=1.844564
I 2015-05-27 03:35:03 theanets.trainer:168 RmsProp 1214 loss=91.141251 err=1.915598
I 2015-05-27 03:35:08 theanets.trainer:168 RmsProp 1215 loss=90.937805 err=1.766907
I 2015-05-27 03:35:12 theanets.trainer:168 RmsProp 1216 loss=90.939133 err=1.823405
I 2015-05-27 03:35:18 theanets.trainer:168 RmsProp 1217 loss=90.918869 err=1.856130
I 2015-05-27 03:35:23 theanets.trainer:168 RmsProp 1218 loss=90.933487 err=1.922084
I 2015-05-27 03:35:28 theanets.trainer:168 RmsProp 1219 loss=90.794823 err=1.838088
I 2015-05-27 03:35:33 theanets.trainer:168 RmsProp 1220 loss=90.713058 err=1.811368
I 2015-05-27 03:35:34 theanets.trainer:168 validation 122 loss=699.083008 err=610.203430
I 2015-05-27 03:35:38 theanets.trainer:168 RmsProp 1221 loss=90.675430 err=1.827489
I 2015-05-27 03:35:43 theanets.trainer:168 RmsProp 1222 loss=90.676170 err=1.886364
I 2015-05-27 03:35:49 theanets.trainer:168 RmsProp 1223 loss=90.684227 err=1.947786
I 2015-05-27 03:35:54 theanets.trainer:168 RmsProp 1224 loss=90.393669 err=1.713519
I 2015-05-27 03:35:58 theanets.trainer:168 RmsProp 1225 loss=90.518372 err=1.890562
I 2015-05-27 03:36:03 theanets.trainer:168 RmsProp 1226 loss=90.502220 err=1.929894
I 2015-05-27 03:36:09 theanets.trainer:168 RmsProp 1227 loss=90.377785 err=1.860528
I 2015-05-27 03:36:14 theanets.trainer:168 RmsProp 1228 loss=90.328079 err=1.862154
I 2015-05-27 03:36:19 theanets.trainer:168 RmsProp 1229 loss=90.322189 err=1.907119
I 2015-05-27 03:36:24 theanets.trainer:168 RmsProp 1230 loss=90.231331 err=1.869385
I 2015-05-27 03:36:25 theanets.trainer:168 validation 123 loss=698.557129 err=610.216125
I 2015-05-27 03:36:29 theanets.trainer:168 RmsProp 1231 loss=90.151550 err=1.845555
I 2015-05-27 03:36:34 theanets.trainer:168 RmsProp 1232 loss=90.198410 err=1.944482
I 2015-05-27 03:36:40 theanets.trainer:168 RmsProp 1233 loss=89.914833 err=1.716664
I 2015-05-27 03:36:45 theanets.trainer:168 RmsProp 1234 loss=90.064819 err=1.920545
I 2015-05-27 03:36:50 theanets.trainer:168 RmsProp 1235 loss=89.985878 err=1.891431
I 2015-05-27 03:36:55 theanets.trainer:168 RmsProp 1236 loss=89.838905 err=1.801013
I 2015-05-27 03:37:00 theanets.trainer:168 RmsProp 1237 loss=89.730995 err=1.745829
I 2015-05-27 03:37:05 theanets.trainer:168 RmsProp 1238 loss=89.821541 err=1.888381
I 2015-05-27 03:37:11 theanets.trainer:168 RmsProp 1239 loss=89.775467 err=1.895258
I 2015-05-27 03:37:16 theanets.trainer:168 RmsProp 1240 loss=89.656387 err=1.830108
I 2015-05-27 03:37:16 theanets.trainer:168 validation 124 loss=688.898376 err=601.100891 *
I 2015-05-27 03:37:21 theanets.trainer:168 RmsProp 1241 loss=89.629135 err=1.856922
I 2015-05-27 03:37:26 theanets.trainer:168 RmsProp 1242 loss=89.439255 err=1.721835
I 2015-05-27 03:37:31 theanets.trainer:168 RmsProp 1243 loss=89.560532 err=1.893604
I 2015-05-27 03:37:36 theanets.trainer:168 RmsProp 1244 loss=89.490219 err=1.875083
I 2015-05-27 03:37:42 theanets.trainer:168 RmsProp 1245 loss=89.384232 err=1.823779
I 2015-05-27 03:37:47 theanets.trainer:168 RmsProp 1246 loss=89.295334 err=1.787791
I 2015-05-27 03:37:52 theanets.trainer:168 RmsProp 1247 loss=89.384888 err=1.930044
I 2015-05-27 03:37:57 theanets.trainer:168 RmsProp 1248 loss=89.118835 err=1.721930
I 2015-05-27 03:38:02 theanets.trainer:168 RmsProp 1249 loss=89.281631 err=1.932984
I 2015-05-27 03:38:07 theanets.trainer:168 RmsProp 1250 loss=89.076614 err=1.782979
I 2015-05-27 03:38:08 theanets.trainer:168 validation 125 loss=686.975525 err=599.712158 *
I 2015-05-27 03:38:13 theanets.trainer:168 RmsProp 1251 loss=89.104004 err=1.862156
I 2015-05-27 03:38:17 theanets.trainer:168 RmsProp 1252 loss=89.047028 err=1.860300
I 2015-05-27 03:38:21 theanets.trainer:168 RmsProp 1253 loss=89.064468 err=1.927798
I 2015-05-27 03:38:25 theanets.trainer:168 RmsProp 1254 loss=88.978928 err=1.893523
I 2015-05-27 03:38:29 theanets.trainer:168 RmsProp 1255 loss=88.668755 err=1.637768
I 2015-05-27 03:38:33 theanets.trainer:168 RmsProp 1256 loss=89.008148 err=2.024441
I 2015-05-27 03:38:37 theanets.trainer:168 RmsProp 1257 loss=88.797157 err=1.867681
I 2015-05-27 03:38:41 theanets.trainer:168 RmsProp 1258 loss=88.690247 err=1.814062
I 2015-05-27 03:38:45 theanets.trainer:168 RmsProp 1259 loss=88.663986 err=1.839573
I 2015-05-27 03:38:49 theanets.trainer:168 RmsProp 1260 loss=88.522324 err=1.751436
I 2015-05-27 03:38:49 theanets.trainer:168 validation 126 loss=684.326721 err=597.571899 *
I 2015-05-27 03:38:54 theanets.trainer:168 RmsProp 1261 loss=88.577347 err=1.858816
I 2015-05-27 03:38:58 theanets.trainer:168 RmsProp 1262 loss=88.623520 err=1.955889
I 2015-05-27 03:39:02 theanets.trainer:168 RmsProp 1263 loss=88.539764 err=1.923308
I 2015-05-27 03:39:06 theanets.trainer:168 RmsProp 1264 loss=88.375870 err=1.808992
I 2015-05-27 03:39:10 theanets.trainer:168 RmsProp 1265 loss=88.302704 err=1.788303
I 2015-05-27 03:39:14 theanets.trainer:168 RmsProp 1266 loss=88.387215 err=1.924758
I 2015-05-27 03:39:17 theanets.trainer:168 RmsProp 1267 loss=88.182526 err=1.770307
I 2015-05-27 03:39:22 theanets.trainer:168 RmsProp 1268 loss=88.161438 err=1.802507
I 2015-05-27 03:39:26 theanets.trainer:168 RmsProp 1269 loss=88.231560 err=1.923485
I 2015-05-27 03:39:30 theanets.trainer:168 RmsProp 1270 loss=88.010689 err=1.753072
I 2015-05-27 03:39:30 theanets.trainer:168 validation 127 loss=686.581665 err=600.358337
I 2015-05-27 03:39:34 theanets.trainer:168 RmsProp 1271 loss=88.101097 err=1.896193
I 2015-05-27 03:39:38 theanets.trainer:168 RmsProp 1272 loss=87.940598 err=1.788416
I 2015-05-27 03:39:42 theanets.trainer:168 RmsProp 1273 loss=87.961563 err=1.859759
I 2015-05-27 03:39:46 theanets.trainer:168 RmsProp 1274 loss=87.803642 err=1.751864
I 2015-05-27 03:39:51 theanets.trainer:168 RmsProp 1275 loss=87.813019 err=1.810155
I 2015-05-27 03:39:54 theanets.trainer:168 RmsProp 1276 loss=87.722168 err=1.771334
I 2015-05-27 03:39:58 theanets.trainer:168 RmsProp 1277 loss=87.752213 err=1.851872
I 2015-05-27 03:40:02 theanets.trainer:168 RmsProp 1278 loss=87.686142 err=1.837964
I 2015-05-27 03:40:06 theanets.trainer:168 RmsProp 1279 loss=87.728806 err=1.927987
I 2015-05-27 03:40:10 theanets.trainer:168 RmsProp 1280 loss=87.677895 err=1.927484
I 2015-05-27 03:40:11 theanets.trainer:168 validation 128 loss=691.995728 err=606.265930
I 2015-05-27 03:40:14 theanets.trainer:168 RmsProp 1281 loss=87.599998 err=1.897787
I 2015-05-27 03:40:18 theanets.trainer:168 RmsProp 1282 loss=87.402199 err=1.751868
I 2015-05-27 03:40:22 theanets.trainer:168 RmsProp 1283 loss=87.680870 err=2.079781
I 2015-05-27 03:40:26 theanets.trainer:168 RmsProp 1284 loss=87.308632 err=1.757540
I 2015-05-27 03:40:30 theanets.trainer:168 RmsProp 1285 loss=87.186172 err=1.689405
I 2015-05-27 03:40:34 theanets.trainer:168 RmsProp 1286 loss=87.342064 err=1.893054
I 2015-05-27 03:40:38 theanets.trainer:168 RmsProp 1287 loss=87.261467 err=1.863176
I 2015-05-27 03:40:42 theanets.trainer:168 RmsProp 1288 loss=87.103500 err=1.756070
I 2015-05-27 03:40:46 theanets.trainer:168 RmsProp 1289 loss=87.078949 err=1.783516
I 2015-05-27 03:40:50 theanets.trainer:168 RmsProp 1290 loss=87.149979 err=1.904607
I 2015-05-27 03:40:51 theanets.trainer:168 validation 129 loss=686.852783 err=601.628662
I 2015-05-27 03:40:55 theanets.trainer:168 RmsProp 1291 loss=86.968399 err=1.774685
I 2015-05-27 03:40:59 theanets.trainer:168 RmsProp 1292 loss=87.110016 err=1.964631
I 2015-05-27 03:41:03 theanets.trainer:168 RmsProp 1293 loss=86.813126 err=1.716677
I 2015-05-27 03:41:07 theanets.trainer:168 RmsProp 1294 loss=86.888374 err=1.842202
I 2015-05-27 03:41:11 theanets.trainer:168 RmsProp 1295 loss=86.786491 err=1.788585
I 2015-05-27 03:41:15 theanets.trainer:168 RmsProp 1296 loss=86.769157 err=1.820034
I 2015-05-27 03:41:19 theanets.trainer:168 RmsProp 1297 loss=86.700760 err=1.802001
I 2015-05-27 03:41:23 theanets.trainer:168 RmsProp 1298 loss=86.674644 err=1.824719
I 2015-05-27 03:41:27 theanets.trainer:168 RmsProp 1299 loss=86.586243 err=1.787160
I 2015-05-27 03:41:31 theanets.trainer:168 RmsProp 1300 loss=86.677353 err=1.925656
I 2015-05-27 03:41:32 theanets.trainer:168 validation 130 loss=677.525085 err=592.798767 *
I 2015-05-27 03:41:36 theanets.trainer:168 RmsProp 1301 loss=86.457733 err=1.758114
I 2015-05-27 03:41:40 theanets.trainer:168 RmsProp 1302 loss=86.485092 err=1.837577
I 2015-05-27 03:41:44 theanets.trainer:168 RmsProp 1303 loss=86.449005 err=1.849832
I 2015-05-27 03:41:48 theanets.trainer:168 RmsProp 1304 loss=86.309464 err=1.758149
I 2015-05-27 03:41:52 theanets.trainer:168 RmsProp 1305 loss=86.536484 err=2.031049
I 2015-05-27 03:41:56 theanets.trainer:168 RmsProp 1306 loss=86.165894 err=1.712608
I 2015-05-27 03:42:00 theanets.trainer:168 RmsProp 1307 loss=86.080856 err=1.676701
I 2015-05-27 03:42:04 theanets.trainer:168 RmsProp 1308 loss=86.231888 err=1.878444
I 2015-05-27 03:42:08 theanets.trainer:168 RmsProp 1309 loss=86.290054 err=1.983325
I 2015-05-27 03:42:12 theanets.trainer:168 RmsProp 1310 loss=86.110756 err=1.854354
I 2015-05-27 03:42:12 theanets.trainer:168 validation 131 loss=677.766785 err=593.539673
I 2015-05-27 03:42:16 theanets.trainer:168 RmsProp 1311 loss=86.004044 err=1.799412
I 2015-05-27 03:42:19 theanets.trainer:168 RmsProp 1312 loss=85.799438 err=1.644291
I 2015-05-27 03:42:24 theanets.trainer:168 RmsProp 1313 loss=86.152054 err=2.044176
I 2015-05-27 03:42:28 theanets.trainer:168 RmsProp 1314 loss=85.875763 err=1.815981
I 2015-05-27 03:42:32 theanets.trainer:168 RmsProp 1315 loss=85.782639 err=1.774848
I 2015-05-27 03:42:36 theanets.trainer:168 RmsProp 1316 loss=85.763824 err=1.805086
I 2015-05-27 03:42:40 theanets.trainer:168 RmsProp 1317 loss=85.855659 err=1.941483
I 2015-05-27 03:42:44 theanets.trainer:168 RmsProp 1318 loss=85.641075 err=1.771971
I 2015-05-27 03:42:48 theanets.trainer:168 RmsProp 1319 loss=85.525673 err=1.704528
I 2015-05-27 03:42:52 theanets.trainer:168 RmsProp 1320 loss=85.624695 err=1.855543
I 2015-05-27 03:42:52 theanets.trainer:168 validation 132 loss=680.816040 err=597.072266
I 2015-05-27 03:42:56 theanets.trainer:168 RmsProp 1321 loss=85.535484 err=1.815036
I 2015-05-27 03:43:00 theanets.trainer:168 RmsProp 1322 loss=85.469917 err=1.800625
I 2015-05-27 03:43:05 theanets.trainer:168 RmsProp 1323 loss=85.435471 err=1.814411
I 2015-05-27 03:43:09 theanets.trainer:168 RmsProp 1324 loss=85.422211 err=1.848774
I 2015-05-27 03:43:13 theanets.trainer:168 RmsProp 1325 loss=85.378922 err=1.854781
I 2015-05-27 03:43:17 theanets.trainer:168 RmsProp 1326 loss=85.288048 err=1.812939
I 2015-05-27 03:43:21 theanets.trainer:168 RmsProp 1327 loss=85.184525 err=1.756431
I 2015-05-27 03:43:25 theanets.trainer:168 RmsProp 1328 loss=85.092636 err=1.711677
I 2015-05-27 03:43:29 theanets.trainer:168 RmsProp 1329 loss=85.258438 err=1.925023
I 2015-05-27 03:43:33 theanets.trainer:168 RmsProp 1330 loss=85.071274 err=1.787310
I 2015-05-27 03:43:33 theanets.trainer:168 validation 133 loss=680.441589 err=597.187073
I 2015-05-27 03:43:37 theanets.trainer:168 RmsProp 1331 loss=85.071655 err=1.835923
I 2015-05-27 03:43:42 theanets.trainer:168 RmsProp 1332 loss=84.963356 err=1.774099
I 2015-05-27 03:43:46 theanets.trainer:168 RmsProp 1333 loss=84.909477 err=1.766756
I 2015-05-27 03:43:50 theanets.trainer:168 RmsProp 1334 loss=85.002533 err=1.907411
I 2015-05-27 03:43:54 theanets.trainer:168 RmsProp 1335 loss=84.786781 err=1.738805
I 2015-05-27 03:43:58 theanets.trainer:168 RmsProp 1336 loss=84.840759 err=1.844165
I 2015-05-27 03:44:02 theanets.trainer:168 RmsProp 1337 loss=84.738472 err=1.787965
I 2015-05-27 03:44:06 theanets.trainer:168 RmsProp 1338 loss=84.743675 err=1.841651
I 2015-05-27 03:44:10 theanets.trainer:168 RmsProp 1339 loss=84.598808 err=1.745327
I 2015-05-27 03:44:14 theanets.trainer:168 RmsProp 1340 loss=84.652351 err=1.845426
I 2015-05-27 03:44:14 theanets.trainer:168 validation 134 loss=683.400635 err=600.616699
I 2015-05-27 03:44:18 theanets.trainer:168 RmsProp 1341 loss=84.525131 err=1.769591
I 2015-05-27 03:44:22 theanets.trainer:168 RmsProp 1342 loss=84.687004 err=1.977473
I 2015-05-27 03:44:26 theanets.trainer:168 RmsProp 1343 loss=84.591331 err=1.927854
I 2015-05-27 03:44:30 theanets.trainer:168 RmsProp 1344 loss=84.347313 err=1.733160
I 2015-05-27 03:44:34 theanets.trainer:168 RmsProp 1345 loss=84.319954 err=1.752829
I 2015-05-27 03:44:38 theanets.trainer:168 RmsProp 1346 loss=84.375351 err=1.853331
I 2015-05-27 03:44:42 theanets.trainer:168 RmsProp 1347 loss=84.235855 err=1.760131
I 2015-05-27 03:44:46 theanets.trainer:168 RmsProp 1348 loss=84.117699 err=1.691395
I 2015-05-27 03:44:50 theanets.trainer:168 RmsProp 1349 loss=84.238472 err=1.857671
I 2015-05-27 03:44:54 theanets.trainer:168 RmsProp 1350 loss=84.247879 err=1.914980
I 2015-05-27 03:44:55 theanets.trainer:168 validation 135 loss=683.238464 err=600.922791
I 2015-05-27 03:44:55 theanets.trainer:252 patience elapsed!
I 2015-05-27 03:44:55 theanets.main:237 models_deep_post_code_sep/95132-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 03:44:55 theanets.graph:477 models_deep_post_code_sep/95132-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
