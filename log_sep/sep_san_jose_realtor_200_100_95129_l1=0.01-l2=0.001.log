I 2015-05-26 22:05:11 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:11 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95129-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:11 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:11 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:11 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:11 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:11 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:11 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:11 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:11 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:11 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:11 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:11 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:29 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:16 theanets.trainer:168 validation 0 loss=14394.333008 err=14152.007812 *
I 2015-05-26 22:08:48 theanets.trainer:168 RmsProp 1 loss=13159.396484 err=13065.168945
I 2015-05-26 22:09:24 theanets.trainer:168 RmsProp 2 loss=13232.297852 err=13212.967773
I 2015-05-26 22:10:02 theanets.trainer:168 RmsProp 3 loss=13059.314453 err=13041.041992
I 2015-05-26 22:10:37 theanets.trainer:168 RmsProp 4 loss=12948.436523 err=12907.458984
I 2015-05-26 22:11:15 theanets.trainer:168 RmsProp 5 loss=11766.233398 err=11701.880859
I 2015-05-26 22:11:52 theanets.trainer:168 RmsProp 6 loss=10641.000000 err=10545.606445
I 2015-05-26 22:12:28 theanets.trainer:168 RmsProp 7 loss=10180.791992 err=10067.994141
I 2015-05-26 22:13:05 theanets.trainer:168 RmsProp 8 loss=9720.537109 err=9593.500000
I 2015-05-26 22:13:42 theanets.trainer:168 RmsProp 9 loss=9205.697266 err=9061.622070
I 2015-05-26 22:14:20 theanets.trainer:168 RmsProp 10 loss=8767.540039 err=8603.404297
I 2015-05-26 22:14:20 theanets.trainer:168 validation 1 loss=9192.022461 err=9018.051758 *
I 2015-05-26 22:14:57 theanets.trainer:168 RmsProp 11 loss=8714.655273 err=8526.806641
I 2015-05-26 22:15:34 theanets.trainer:168 RmsProp 12 loss=8498.577148 err=8293.305664
I 2015-05-26 22:16:12 theanets.trainer:168 RmsProp 13 loss=8300.004883 err=8080.444336
I 2015-05-26 22:16:50 theanets.trainer:168 RmsProp 14 loss=7944.076172 err=7711.524414
I 2015-05-26 22:17:27 theanets.trainer:168 RmsProp 15 loss=7739.389648 err=7492.774414
I 2015-05-26 22:18:05 theanets.trainer:168 RmsProp 16 loss=7627.034668 err=7363.284180
I 2015-05-26 22:18:40 theanets.trainer:168 RmsProp 17 loss=7394.996582 err=7116.317383
I 2015-05-26 22:19:17 theanets.trainer:168 RmsProp 18 loss=7114.803711 err=6821.150391
I 2015-05-26 22:19:54 theanets.trainer:168 RmsProp 19 loss=6676.295898 err=6371.368652
I 2015-05-26 22:20:31 theanets.trainer:168 RmsProp 20 loss=6284.398926 err=5971.929688
I 2015-05-26 22:20:32 theanets.trainer:168 validation 2 loss=5927.267090 err=5610.167480 *
I 2015-05-26 22:21:09 theanets.trainer:168 RmsProp 21 loss=5952.321289 err=5629.523926
I 2015-05-26 22:21:46 theanets.trainer:168 RmsProp 22 loss=5754.774902 err=5418.699707
I 2015-05-26 22:22:23 theanets.trainer:168 RmsProp 23 loss=5563.945801 err=5214.454590
I 2015-05-26 22:23:00 theanets.trainer:168 RmsProp 24 loss=5411.672852 err=5047.818359
I 2015-05-26 22:23:36 theanets.trainer:168 RmsProp 25 loss=5236.227539 err=4861.529785
I 2015-05-26 22:24:13 theanets.trainer:168 RmsProp 26 loss=5161.682617 err=4775.732422
I 2015-05-26 22:24:50 theanets.trainer:168 RmsProp 27 loss=5087.590820 err=4688.504395
I 2015-05-26 22:25:27 theanets.trainer:168 RmsProp 28 loss=4899.774902 err=4490.626953
I 2015-05-26 22:26:04 theanets.trainer:168 RmsProp 29 loss=4864.111816 err=4441.997070
I 2015-05-26 22:26:41 theanets.trainer:168 RmsProp 30 loss=4708.101074 err=4274.791992
I 2015-05-26 22:26:41 theanets.trainer:168 validation 3 loss=4476.873047 err=4039.141846 *
I 2015-05-26 22:27:18 theanets.trainer:168 RmsProp 31 loss=4576.333008 err=4133.986816
I 2015-05-26 22:27:55 theanets.trainer:168 RmsProp 32 loss=4569.545898 err=4114.606445
I 2015-05-26 22:28:33 theanets.trainer:168 RmsProp 33 loss=4478.849121 err=4013.138916
I 2015-05-26 22:29:11 theanets.trainer:168 RmsProp 34 loss=4483.009766 err=4004.936279
I 2015-05-26 22:29:49 theanets.trainer:168 RmsProp 35 loss=4356.084961 err=3866.177490
I 2015-05-26 22:30:27 theanets.trainer:168 RmsProp 36 loss=4290.973145 err=3793.448242
I 2015-05-26 22:31:05 theanets.trainer:168 RmsProp 37 loss=4144.122070 err=3637.691162
I 2015-05-26 22:31:42 theanets.trainer:168 RmsProp 38 loss=4020.376465 err=3507.283936
I 2015-05-26 22:32:20 theanets.trainer:168 RmsProp 39 loss=3984.632324 err=3463.377197
I 2015-05-26 22:32:57 theanets.trainer:168 RmsProp 40 loss=3957.334717 err=3426.286865
I 2015-05-26 22:32:58 theanets.trainer:168 validation 4 loss=4036.176514 err=3497.627686 *
I 2015-05-26 22:33:35 theanets.trainer:168 RmsProp 41 loss=3896.125000 err=3353.577637
I 2015-05-26 22:34:11 theanets.trainer:168 RmsProp 42 loss=3833.178955 err=3284.039307
I 2015-05-26 22:34:48 theanets.trainer:168 RmsProp 43 loss=3698.714111 err=3143.585693
I 2015-05-26 22:35:25 theanets.trainer:168 RmsProp 44 loss=3646.578857 err=3085.777832
I 2015-05-26 22:36:02 theanets.trainer:168 RmsProp 45 loss=3558.656250 err=2992.359619
I 2015-05-26 22:36:38 theanets.trainer:168 RmsProp 46 loss=3514.371094 err=2941.477051
I 2015-05-26 22:37:15 theanets.trainer:168 RmsProp 47 loss=3535.868164 err=2953.067139
I 2015-05-26 22:37:51 theanets.trainer:168 RmsProp 48 loss=3500.723389 err=2907.148193
I 2015-05-26 22:38:28 theanets.trainer:168 RmsProp 49 loss=3571.333252 err=2968.766113
I 2015-05-26 22:39:05 theanets.trainer:168 RmsProp 50 loss=3434.838379 err=2822.575684
I 2015-05-26 22:39:05 theanets.trainer:168 validation 5 loss=3783.794189 err=3169.215576 *
I 2015-05-26 22:39:42 theanets.trainer:168 RmsProp 51 loss=3337.133057 err=2720.810059
I 2015-05-26 22:40:18 theanets.trainer:168 RmsProp 52 loss=3227.619629 err=2608.621338
I 2015-05-26 22:40:55 theanets.trainer:168 RmsProp 53 loss=3236.978760 err=2613.185303
I 2015-05-26 22:41:31 theanets.trainer:168 RmsProp 54 loss=3217.493164 err=2585.456299
I 2015-05-26 22:42:07 theanets.trainer:168 RmsProp 55 loss=3181.318848 err=2545.053955
I 2015-05-26 22:42:44 theanets.trainer:168 RmsProp 56 loss=3130.231445 err=2489.681396
I 2015-05-26 22:43:21 theanets.trainer:168 RmsProp 57 loss=3178.859863 err=2531.242188
I 2015-05-26 22:43:57 theanets.trainer:168 RmsProp 58 loss=3290.584961 err=2630.612305
I 2015-05-26 22:44:35 theanets.trainer:168 RmsProp 59 loss=3215.583008 err=2545.921143
I 2015-05-26 22:45:12 theanets.trainer:168 RmsProp 60 loss=3054.834473 err=2383.988037
I 2015-05-26 22:45:13 theanets.trainer:168 validation 6 loss=3674.582764 err=3004.588623 *
I 2015-05-26 22:45:50 theanets.trainer:168 RmsProp 61 loss=2946.764404 err=2276.349854
I 2015-05-26 22:46:26 theanets.trainer:168 RmsProp 62 loss=2888.247070 err=2217.586670
I 2015-05-26 22:47:02 theanets.trainer:168 RmsProp 63 loss=2914.183350 err=2239.838623
I 2015-05-26 22:47:39 theanets.trainer:168 RmsProp 64 loss=2850.015137 err=2172.091309
I 2015-05-26 22:48:15 theanets.trainer:168 RmsProp 65 loss=2771.970459 err=2092.791748
I 2015-05-26 22:48:51 theanets.trainer:168 RmsProp 66 loss=2806.375244 err=2122.688232
I 2015-05-26 22:49:27 theanets.trainer:168 RmsProp 67 loss=2754.405029 err=2066.934082
I 2015-05-26 22:50:03 theanets.trainer:168 RmsProp 68 loss=2725.934326 err=2034.710815
I 2015-05-26 22:50:41 theanets.trainer:168 RmsProp 69 loss=2754.117432 err=2058.924316
I 2015-05-26 22:51:18 theanets.trainer:168 RmsProp 70 loss=2730.215820 err=2030.444092
I 2015-05-26 22:51:19 theanets.trainer:168 validation 7 loss=3513.735107 err=2811.779053 *
I 2015-05-26 22:51:56 theanets.trainer:168 RmsProp 71 loss=2664.524170 err=1961.760620
I 2015-05-26 22:52:32 theanets.trainer:168 RmsProp 72 loss=2715.739990 err=2009.025757
I 2015-05-26 22:53:09 theanets.trainer:168 RmsProp 73 loss=2766.433350 err=2050.739746
I 2015-05-26 22:53:48 theanets.trainer:168 RmsProp 74 loss=2675.353760 err=1957.385620
I 2015-05-26 22:54:26 theanets.trainer:168 RmsProp 75 loss=2650.031006 err=1930.324951
I 2015-05-26 22:55:04 theanets.trainer:168 RmsProp 76 loss=2616.195801 err=1892.282104
I 2015-05-26 22:55:40 theanets.trainer:168 RmsProp 77 loss=2563.158691 err=1837.523682
I 2015-05-26 22:56:17 theanets.trainer:168 RmsProp 78 loss=2483.758789 err=1756.507568
I 2015-05-26 22:56:55 theanets.trainer:168 RmsProp 79 loss=2528.292480 err=1798.984009
I 2015-05-26 22:57:33 theanets.trainer:168 RmsProp 80 loss=2548.083740 err=1810.510376
I 2015-05-26 22:57:33 theanets.trainer:168 validation 8 loss=3371.591064 err=2633.413574 *
I 2015-05-26 22:58:11 theanets.trainer:168 RmsProp 81 loss=2482.214844 err=1744.406982
I 2015-05-26 22:58:49 theanets.trainer:168 RmsProp 82 loss=2495.471680 err=1755.331421
I 2015-05-26 22:59:26 theanets.trainer:168 RmsProp 83 loss=2433.121338 err=1690.798584
I 2015-05-26 23:00:02 theanets.trainer:168 RmsProp 84 loss=2403.914795 err=1660.193115
I 2015-05-26 23:00:38 theanets.trainer:168 RmsProp 85 loss=2388.056396 err=1642.741699
I 2015-05-26 23:01:14 theanets.trainer:168 RmsProp 86 loss=2441.677246 err=1688.747559
I 2015-05-26 23:01:52 theanets.trainer:168 RmsProp 87 loss=2359.311523 err=1603.331543
I 2015-05-26 23:02:29 theanets.trainer:168 RmsProp 88 loss=2303.820312 err=1548.267822
I 2015-05-26 23:03:06 theanets.trainer:168 RmsProp 89 loss=2329.002930 err=1571.066162
I 2015-05-26 23:03:44 theanets.trainer:168 RmsProp 90 loss=2255.077148 err=1496.811401
I 2015-05-26 23:03:45 theanets.trainer:168 validation 9 loss=3130.082764 err=2371.020264 *
I 2015-05-26 23:04:22 theanets.trainer:168 RmsProp 91 loss=2273.714111 err=1513.695557
I 2015-05-26 23:04:58 theanets.trainer:168 RmsProp 92 loss=2275.569824 err=1512.842285
I 2015-05-26 23:05:35 theanets.trainer:168 RmsProp 93 loss=2221.810791 err=1459.204346
I 2015-05-26 23:06:10 theanets.trainer:168 RmsProp 94 loss=2268.644531 err=1503.847778
I 2015-05-26 23:06:47 theanets.trainer:168 RmsProp 95 loss=2382.485352 err=1611.467529
I 2015-05-26 23:07:24 theanets.trainer:168 RmsProp 96 loss=2391.856934 err=1610.611206
I 2015-05-26 23:08:01 theanets.trainer:168 RmsProp 97 loss=2263.524170 err=1483.755371
I 2015-05-26 23:08:39 theanets.trainer:168 RmsProp 98 loss=2264.695312 err=1487.355225
I 2015-05-26 23:09:17 theanets.trainer:168 RmsProp 99 loss=2247.606445 err=1468.487549
I 2015-05-26 23:09:55 theanets.trainer:168 RmsProp 100 loss=2276.758789 err=1496.324707
I 2015-05-26 23:09:55 theanets.trainer:168 validation 10 loss=3313.582275 err=2529.366943
I 2015-05-26 23:10:32 theanets.trainer:168 RmsProp 101 loss=2375.359619 err=1586.798340
I 2015-05-26 23:11:08 theanets.trainer:168 RmsProp 102 loss=2413.437012 err=1615.882080
I 2015-05-26 23:11:43 theanets.trainer:168 RmsProp 103 loss=2219.579102 err=1422.631226
I 2015-05-26 23:12:19 theanets.trainer:168 RmsProp 104 loss=2165.762939 err=1371.354370
I 2015-05-26 23:12:56 theanets.trainer:168 RmsProp 105 loss=2148.514404 err=1355.646240
I 2015-05-26 23:13:33 theanets.trainer:168 RmsProp 106 loss=2195.692139 err=1400.160889
I 2015-05-26 23:14:10 theanets.trainer:168 RmsProp 107 loss=2139.129150 err=1340.884399
I 2015-05-26 23:14:48 theanets.trainer:168 RmsProp 108 loss=2123.332764 err=1328.261719
I 2015-05-26 23:15:25 theanets.trainer:168 RmsProp 109 loss=2098.904785 err=1302.226196
I 2015-05-26 23:16:02 theanets.trainer:168 RmsProp 110 loss=2044.170410 err=1248.708740
I 2015-05-26 23:16:03 theanets.trainer:168 validation 11 loss=3043.075195 err=2249.684082 *
I 2015-05-26 23:16:40 theanets.trainer:168 RmsProp 111 loss=2014.676514 err=1222.738770
I 2015-05-26 23:17:16 theanets.trainer:168 RmsProp 112 loss=2019.831665 err=1227.638428
I 2015-05-26 23:17:52 theanets.trainer:168 RmsProp 113 loss=1988.406372 err=1197.091064
I 2015-05-26 23:18:28 theanets.trainer:168 RmsProp 114 loss=1992.679321 err=1201.832275
I 2015-05-26 23:19:03 theanets.trainer:168 RmsProp 115 loss=2041.896729 err=1248.354614
I 2015-05-26 23:19:39 theanets.trainer:168 RmsProp 116 loss=2030.988403 err=1232.980835
I 2015-05-26 23:20:14 theanets.trainer:168 RmsProp 117 loss=2017.126099 err=1218.606079
I 2015-05-26 23:20:50 theanets.trainer:168 RmsProp 118 loss=2014.251709 err=1214.655884
I 2015-05-26 23:21:26 theanets.trainer:168 RmsProp 119 loss=2030.004639 err=1227.058838
I 2015-05-26 23:22:02 theanets.trainer:168 RmsProp 120 loss=2017.160889 err=1213.528198
I 2015-05-26 23:22:02 theanets.trainer:168 validation 12 loss=2965.559326 err=2161.942139 *
I 2015-05-26 23:22:38 theanets.trainer:168 RmsProp 121 loss=1963.201050 err=1160.870850
I 2015-05-26 23:23:15 theanets.trainer:168 RmsProp 122 loss=1940.550903 err=1139.458862
I 2015-05-26 23:23:53 theanets.trainer:168 RmsProp 123 loss=1936.885010 err=1136.303589
I 2015-05-26 23:24:30 theanets.trainer:168 RmsProp 124 loss=1957.384155 err=1154.822388
I 2015-05-26 23:25:07 theanets.trainer:168 RmsProp 125 loss=1911.355469 err=1108.969482
I 2015-05-26 23:25:43 theanets.trainer:168 RmsProp 126 loss=1978.524536 err=1173.260376
I 2015-05-26 23:26:19 theanets.trainer:168 RmsProp 127 loss=1962.570557 err=1154.612183
I 2015-05-26 23:26:56 theanets.trainer:168 RmsProp 128 loss=1919.839233 err=1111.045532
I 2015-05-26 23:27:33 theanets.trainer:168 RmsProp 129 loss=1899.088013 err=1092.308105
I 2015-05-26 23:28:09 theanets.trainer:168 RmsProp 130 loss=1880.287964 err=1073.921021
I 2015-05-26 23:28:10 theanets.trainer:168 validation 13 loss=2947.508545 err=2141.753418 *
I 2015-05-26 23:28:47 theanets.trainer:168 RmsProp 131 loss=1903.443481 err=1096.755005
I 2015-05-26 23:29:24 theanets.trainer:168 RmsProp 132 loss=1887.378784 err=1079.916260
I 2015-05-26 23:30:01 theanets.trainer:168 RmsProp 133 loss=1870.600830 err=1062.595581
I 2015-05-26 23:30:37 theanets.trainer:168 RmsProp 134 loss=1855.097900 err=1048.370972
I 2015-05-26 23:31:14 theanets.trainer:168 RmsProp 135 loss=1972.681763 err=1162.446167
I 2015-05-26 23:31:51 theanets.trainer:168 RmsProp 136 loss=1971.842529 err=1157.789795
I 2015-05-26 23:32:28 theanets.trainer:168 RmsProp 137 loss=1906.077515 err=1091.591919
I 2015-05-26 23:33:04 theanets.trainer:168 RmsProp 138 loss=1883.780762 err=1069.743652
I 2015-05-26 23:33:40 theanets.trainer:168 RmsProp 139 loss=1863.965332 err=1051.184937
I 2015-05-26 23:34:16 theanets.trainer:168 RmsProp 140 loss=1892.123413 err=1078.671997
I 2015-05-26 23:34:17 theanets.trainer:168 validation 14 loss=2890.658936 err=2076.108154 *
I 2015-05-26 23:34:54 theanets.trainer:168 RmsProp 141 loss=1872.409912 err=1057.833374
I 2015-05-26 23:35:30 theanets.trainer:168 RmsProp 142 loss=1925.261597 err=1109.165527
I 2015-05-26 23:36:06 theanets.trainer:168 RmsProp 143 loss=1995.680908 err=1172.578125
I 2015-05-26 23:36:42 theanets.trainer:168 RmsProp 144 loss=1975.649292 err=1149.576538
I 2015-05-26 23:37:18 theanets.trainer:168 RmsProp 145 loss=1960.324585 err=1131.673462
I 2015-05-26 23:37:56 theanets.trainer:168 RmsProp 146 loss=1881.623657 err=1055.560669
I 2015-05-26 23:38:33 theanets.trainer:168 RmsProp 147 loss=1848.458618 err=1025.535522
I 2015-05-26 23:39:10 theanets.trainer:168 RmsProp 148 loss=1854.189941 err=1031.059082
I 2015-05-26 23:39:46 theanets.trainer:168 RmsProp 149 loss=1880.651245 err=1055.340088
I 2015-05-26 23:40:22 theanets.trainer:168 RmsProp 150 loss=1860.221191 err=1032.557739
I 2015-05-26 23:40:23 theanets.trainer:168 validation 15 loss=3085.277344 err=2258.076904
I 2015-05-26 23:41:00 theanets.trainer:168 RmsProp 151 loss=1846.616699 err=1019.567139
I 2015-05-26 23:41:37 theanets.trainer:168 RmsProp 152 loss=1833.876221 err=1007.102600
I 2015-05-26 23:42:15 theanets.trainer:168 RmsProp 153 loss=1842.696533 err=1015.457825
I 2015-05-26 23:42:52 theanets.trainer:168 RmsProp 154 loss=1843.702515 err=1014.878662
I 2015-05-26 23:43:29 theanets.trainer:168 RmsProp 155 loss=1881.476196 err=1050.242188
I 2015-05-26 23:44:06 theanets.trainer:168 RmsProp 156 loss=1891.842407 err=1058.420166
I 2015-05-26 23:44:42 theanets.trainer:168 RmsProp 157 loss=1899.497559 err=1063.384521
I 2015-05-26 23:45:19 theanets.trainer:168 RmsProp 158 loss=1880.373413 err=1043.429443
I 2015-05-26 23:45:56 theanets.trainer:168 RmsProp 159 loss=1824.338379 err=988.928162
I 2015-05-26 23:46:32 theanets.trainer:168 RmsProp 160 loss=1811.017944 err=977.667542
I 2015-05-26 23:46:33 theanets.trainer:168 validation 16 loss=2899.615967 err=2065.900391
I 2015-05-26 23:47:07 theanets.trainer:168 RmsProp 161 loss=1800.637207 err=966.836731
I 2015-05-26 23:47:42 theanets.trainer:168 RmsProp 162 loss=1764.889038 err=933.001709
I 2015-05-26 23:48:16 theanets.trainer:168 RmsProp 163 loss=1797.843872 err=965.841675
I 2015-05-26 23:48:51 theanets.trainer:168 RmsProp 164 loss=1809.864746 err=976.277039
I 2015-05-26 23:49:27 theanets.trainer:168 RmsProp 165 loss=1759.852661 err=925.960999
I 2015-05-26 23:50:03 theanets.trainer:168 RmsProp 166 loss=1719.441895 err=889.697815
I 2015-05-26 23:50:38 theanets.trainer:168 RmsProp 167 loss=1794.196533 err=963.207214
I 2015-05-26 23:51:14 theanets.trainer:168 RmsProp 168 loss=1759.225708 err=926.567810
I 2015-05-26 23:51:49 theanets.trainer:168 RmsProp 169 loss=1743.731567 err=912.666870
I 2015-05-26 23:52:23 theanets.trainer:168 RmsProp 170 loss=1756.503662 err=924.309265
I 2015-05-26 23:52:24 theanets.trainer:168 validation 17 loss=3001.764404 err=2169.277344
I 2015-05-26 23:52:59 theanets.trainer:168 RmsProp 171 loss=1735.269531 err=903.469299
I 2015-05-26 23:53:34 theanets.trainer:168 RmsProp 172 loss=1720.947876 err=890.028015
I 2015-05-26 23:54:09 theanets.trainer:168 RmsProp 173 loss=1715.451050 err=886.668823
I 2015-05-26 23:54:45 theanets.trainer:168 RmsProp 174 loss=1727.456299 err=898.277954
I 2015-05-26 23:55:21 theanets.trainer:168 RmsProp 175 loss=1733.294312 err=901.976379
I 2015-05-26 23:55:57 theanets.trainer:168 RmsProp 176 loss=1758.956665 err=927.130554
I 2015-05-26 23:56:32 theanets.trainer:168 RmsProp 177 loss=1751.293457 err=917.543762
I 2015-05-26 23:57:07 theanets.trainer:168 RmsProp 178 loss=1707.037964 err=874.576294
I 2015-05-26 23:57:43 theanets.trainer:168 RmsProp 179 loss=1702.726807 err=870.274170
I 2015-05-26 23:58:18 theanets.trainer:168 RmsProp 180 loss=1663.284912 err=833.933044
I 2015-05-26 23:58:18 theanets.trainer:168 validation 18 loss=2954.426514 err=2125.963135
I 2015-05-26 23:58:53 theanets.trainer:168 RmsProp 181 loss=1733.871460 err=903.768921
I 2015-05-26 23:59:30 theanets.trainer:168 RmsProp 182 loss=1744.447998 err=910.937622
I 2015-05-27 00:00:06 theanets.trainer:168 RmsProp 183 loss=1687.642334 err=854.396667
I 2015-05-27 00:00:42 theanets.trainer:168 RmsProp 184 loss=1690.611938 err=858.201782
I 2015-05-27 00:01:18 theanets.trainer:168 RmsProp 185 loss=1709.984619 err=876.583801
I 2015-05-27 00:01:54 theanets.trainer:168 RmsProp 186 loss=1688.546509 err=855.983032
I 2015-05-27 00:02:30 theanets.trainer:168 RmsProp 187 loss=1724.403198 err=889.167603
I 2015-05-27 00:03:05 theanets.trainer:168 RmsProp 188 loss=1738.095581 err=898.938354
I 2015-05-27 00:03:40 theanets.trainer:168 RmsProp 189 loss=1728.394409 err=888.114990
I 2015-05-27 00:04:16 theanets.trainer:168 RmsProp 190 loss=1696.669067 err=856.914429
I 2015-05-27 00:04:17 theanets.trainer:168 validation 19 loss=3021.385498 err=2181.954834
I 2015-05-27 00:04:17 theanets.trainer:252 patience elapsed!
I 2015-05-27 00:04:17 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 00:04:17 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 00:04:17 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 00:04:17 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 00:04:17 theanets.main:89 --batch_size = 1024
I 2015-05-27 00:04:17 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 00:04:17 theanets.main:89 --hidden_l1 = None
I 2015-05-27 00:04:17 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 00:04:17 theanets.main:89 --train_batches = 10
I 2015-05-27 00:04:17 theanets.main:89 --valid_batches = 2
I 2015-05-27 00:04:17 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 00:04:17 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 00:04:17 theanets.trainer:134 compiling evaluation function
I 2015-05-27 00:04:26 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 00:06:07 theanets.trainer:168 validation 0 loss=12496.447266 err=11681.897461 *
I 2015-05-27 00:06:18 theanets.trainer:168 RmsProp 1 loss=3547.703613 err=2736.009521
I 2015-05-27 00:06:29 theanets.trainer:168 RmsProp 2 loss=2912.905273 err=2102.475830
I 2015-05-27 00:06:41 theanets.trainer:168 RmsProp 3 loss=2567.128906 err=1757.020874
I 2015-05-27 00:06:52 theanets.trainer:168 RmsProp 4 loss=2264.490234 err=1454.874878
I 2015-05-27 00:07:03 theanets.trainer:168 RmsProp 5 loss=2101.504395 err=1292.616699
I 2015-05-27 00:07:14 theanets.trainer:168 RmsProp 6 loss=1895.331665 err=1087.535767
I 2015-05-27 00:07:24 theanets.trainer:168 RmsProp 7 loss=1766.728882 err=960.560364
I 2015-05-27 00:07:35 theanets.trainer:168 RmsProp 8 loss=1628.941406 err=825.078918
I 2015-05-27 00:07:46 theanets.trainer:168 RmsProp 9 loss=1557.660889 err=756.627808
I 2015-05-27 00:07:57 theanets.trainer:168 RmsProp 10 loss=1467.985352 err=670.006470
I 2015-05-27 00:07:58 theanets.trainer:168 validation 1 loss=10596.154297 err=9799.958008 *
I 2015-05-27 00:08:08 theanets.trainer:168 RmsProp 11 loss=1445.971436 err=651.294678
I 2015-05-27 00:08:19 theanets.trainer:168 RmsProp 12 loss=1379.072144 err=587.962158
I 2015-05-27 00:08:30 theanets.trainer:168 RmsProp 13 loss=1336.752686 err=549.545654
I 2015-05-27 00:08:41 theanets.trainer:168 RmsProp 14 loss=1282.140015 err=498.815521
I 2015-05-27 00:08:51 theanets.trainer:168 RmsProp 15 loss=1269.390869 err=489.995941
I 2015-05-27 00:09:02 theanets.trainer:168 RmsProp 16 loss=1240.503662 err=465.126709
I 2015-05-27 00:09:13 theanets.trainer:168 RmsProp 17 loss=1208.971436 err=437.431946
I 2015-05-27 00:09:24 theanets.trainer:168 RmsProp 18 loss=1200.307251 err=432.628265
I 2015-05-27 00:09:35 theanets.trainer:168 RmsProp 19 loss=1165.270020 err=401.530457
I 2015-05-27 00:09:46 theanets.trainer:168 RmsProp 20 loss=1137.499268 err=377.722107
I 2015-05-27 00:09:46 theanets.trainer:168 validation 2 loss=10537.208008 err=9779.622070 *
I 2015-05-27 00:09:57 theanets.trainer:168 RmsProp 21 loss=1129.697266 err=373.857117
I 2015-05-27 00:10:08 theanets.trainer:168 RmsProp 22 loss=1096.579102 err=344.576965
I 2015-05-27 00:10:18 theanets.trainer:168 RmsProp 23 loss=1071.171021 err=323.109253
I 2015-05-27 00:10:29 theanets.trainer:168 RmsProp 24 loss=1063.696289 err=319.289368
I 2015-05-27 00:10:39 theanets.trainer:168 RmsProp 25 loss=1051.336426 err=310.330536
I 2015-05-27 00:10:50 theanets.trainer:168 RmsProp 26 loss=1042.437866 err=304.885590
I 2015-05-27 00:11:00 theanets.trainer:168 RmsProp 27 loss=1016.537598 err=282.657410
I 2015-05-27 00:11:11 theanets.trainer:168 RmsProp 28 loss=1008.218140 err=277.880554
I 2015-05-27 00:11:22 theanets.trainer:168 RmsProp 29 loss=993.092468 err=266.193970
I 2015-05-27 00:11:32 theanets.trainer:168 RmsProp 30 loss=976.587524 err=253.219513
I 2015-05-27 00:11:32 theanets.trainer:168 validation 3 loss=10359.363281 err=9637.952148 *
I 2015-05-27 00:11:43 theanets.trainer:168 RmsProp 31 loss=962.762024 err=242.948074
I 2015-05-27 00:11:53 theanets.trainer:168 RmsProp 32 loss=959.488953 err=243.173553
I 2015-05-27 00:12:03 theanets.trainer:168 RmsProp 33 loss=943.796570 err=230.950775
I 2015-05-27 00:12:12 theanets.trainer:168 RmsProp 34 loss=926.120789 err=216.712158
I 2015-05-27 00:12:23 theanets.trainer:168 RmsProp 35 loss=899.515747 err=193.403351
I 2015-05-27 00:12:33 theanets.trainer:168 RmsProp 36 loss=897.104980 err=194.323929
I 2015-05-27 00:12:44 theanets.trainer:168 RmsProp 37 loss=892.684570 err=193.273590
I 2015-05-27 00:12:54 theanets.trainer:168 RmsProp 38 loss=878.655090 err=182.568863
I 2015-05-27 00:13:05 theanets.trainer:168 RmsProp 39 loss=869.829224 err=177.044296
I 2015-05-27 00:13:15 theanets.trainer:168 RmsProp 40 loss=859.191589 err=169.686798
I 2015-05-27 00:13:16 theanets.trainer:168 validation 4 loss=10119.199219 err=9431.470703 *
I 2015-05-27 00:13:26 theanets.trainer:168 RmsProp 41 loss=842.504272 err=156.186981
I 2015-05-27 00:13:36 theanets.trainer:168 RmsProp 42 loss=842.207642 err=159.010849
I 2015-05-27 00:13:47 theanets.trainer:168 RmsProp 43 loss=827.409668 err=147.336334
I 2015-05-27 00:13:57 theanets.trainer:168 RmsProp 44 loss=814.174866 err=137.177048
I 2015-05-27 00:14:07 theanets.trainer:168 RmsProp 45 loss=815.015686 err=141.063721
I 2015-05-27 00:14:18 theanets.trainer:168 RmsProp 46 loss=805.711792 err=134.774368
I 2015-05-27 00:14:28 theanets.trainer:168 RmsProp 47 loss=794.946655 err=126.975327
I 2015-05-27 00:14:39 theanets.trainer:168 RmsProp 48 loss=784.771851 err=119.732285
I 2015-05-27 00:14:49 theanets.trainer:168 RmsProp 49 loss=783.319946 err=121.203270
I 2015-05-27 00:14:59 theanets.trainer:168 RmsProp 50 loss=772.197266 err=112.981972
I 2015-05-27 00:15:00 theanets.trainer:168 validation 5 loss=10013.615234 err=9355.976562 *
I 2015-05-27 00:15:10 theanets.trainer:168 RmsProp 51 loss=762.835693 err=106.493530
I 2015-05-27 00:15:20 theanets.trainer:168 RmsProp 52 loss=759.929810 err=106.419312
I 2015-05-27 00:15:30 theanets.trainer:168 RmsProp 53 loss=754.086121 err=103.246460
I 2015-05-27 00:15:40 theanets.trainer:168 RmsProp 54 loss=748.979858 err=100.790565
I 2015-05-27 00:15:50 theanets.trainer:168 RmsProp 55 loss=739.217590 err=93.676483
I 2015-05-27 00:16:00 theanets.trainer:168 RmsProp 56 loss=736.199341 err=93.275803
I 2015-05-27 00:16:10 theanets.trainer:168 RmsProp 57 loss=726.049194 err=85.727982
I 2015-05-27 00:16:20 theanets.trainer:168 RmsProp 58 loss=722.458252 err=84.759979
I 2015-05-27 00:16:31 theanets.trainer:168 RmsProp 59 loss=719.617188 err=84.573410
I 2015-05-27 00:16:41 theanets.trainer:168 RmsProp 60 loss=712.143921 err=79.711105
I 2015-05-27 00:16:42 theanets.trainer:168 validation 6 loss=9912.166016 err=9281.126953 *
I 2015-05-27 00:16:52 theanets.trainer:168 RmsProp 61 loss=706.502258 err=76.582977
I 2015-05-27 00:17:02 theanets.trainer:168 RmsProp 62 loss=698.391846 err=70.937073
I 2015-05-27 00:17:12 theanets.trainer:168 RmsProp 63 loss=695.052856 err=70.109711
I 2015-05-27 00:17:22 theanets.trainer:168 RmsProp 64 loss=688.858704 err=66.412010
I 2015-05-27 00:17:33 theanets.trainer:168 RmsProp 65 loss=685.582886 err=65.588524
I 2015-05-27 00:17:43 theanets.trainer:168 RmsProp 66 loss=681.237549 err=63.624290
I 2015-05-27 00:17:53 theanets.trainer:168 RmsProp 67 loss=675.475708 err=60.243378
I 2015-05-27 00:18:04 theanets.trainer:168 RmsProp 68 loss=672.596375 err=59.766521
I 2015-05-27 00:18:14 theanets.trainer:168 RmsProp 69 loss=667.296997 err=56.812935
I 2015-05-27 00:18:24 theanets.trainer:168 RmsProp 70 loss=664.070618 err=55.912712
I 2015-05-27 00:18:25 theanets.trainer:168 validation 7 loss=9906.368164 err=9299.478516 *
I 2015-05-27 00:18:35 theanets.trainer:168 RmsProp 71 loss=656.950989 err=51.072121
I 2015-05-27 00:18:45 theanets.trainer:168 RmsProp 72 loss=655.980591 err=52.344097
I 2015-05-27 00:18:55 theanets.trainer:168 RmsProp 73 loss=650.695801 err=49.289349
I 2015-05-27 00:19:05 theanets.trainer:168 RmsProp 74 loss=647.875000 err=48.702122
I 2015-05-27 00:19:16 theanets.trainer:168 RmsProp 75 loss=645.379150 err=48.437187
I 2015-05-27 00:19:26 theanets.trainer:168 RmsProp 76 loss=640.362976 err=45.617485
I 2015-05-27 00:19:36 theanets.trainer:168 RmsProp 77 loss=636.067139 err=43.535374
I 2015-05-27 00:19:47 theanets.trainer:168 RmsProp 78 loss=633.554810 err=43.221085
I 2015-05-27 00:19:57 theanets.trainer:168 RmsProp 79 loss=630.561340 err=42.373672
I 2015-05-27 00:20:07 theanets.trainer:168 RmsProp 80 loss=628.179810 err=42.043297
I 2015-05-27 00:20:08 theanets.trainer:168 validation 8 loss=9796.374023 err=9211.353516 *
I 2015-05-27 00:20:18 theanets.trainer:168 RmsProp 81 loss=624.130005 err=40.036205
I 2015-05-27 00:20:28 theanets.trainer:168 RmsProp 82 loss=620.783142 err=38.742073
I 2015-05-27 00:20:39 theanets.trainer:168 RmsProp 83 loss=619.509888 err=39.524059
I 2015-05-27 00:20:49 theanets.trainer:168 RmsProp 84 loss=615.971741 err=38.051422
I 2015-05-27 00:21:00 theanets.trainer:168 RmsProp 85 loss=612.291321 err=36.383114
I 2015-05-27 00:21:10 theanets.trainer:168 RmsProp 86 loss=609.498413 err=35.602036
I 2015-05-27 00:21:20 theanets.trainer:168 RmsProp 87 loss=607.683533 err=35.786144
I 2015-05-27 00:21:30 theanets.trainer:168 RmsProp 88 loss=604.550842 err=34.648582
I 2015-05-27 00:21:41 theanets.trainer:168 RmsProp 89 loss=601.284241 err=33.380962
I 2015-05-27 00:21:51 theanets.trainer:168 RmsProp 90 loss=599.472900 err=33.565475
I 2015-05-27 00:21:52 theanets.trainer:168 validation 9 loss=9764.085938 err=9199.275391 *
I 2015-05-27 00:22:02 theanets.trainer:168 RmsProp 91 loss=595.921570 err=31.998550
I 2015-05-27 00:22:12 theanets.trainer:168 RmsProp 92 loss=593.459412 err=31.462936
I 2015-05-27 00:22:23 theanets.trainer:168 RmsProp 93 loss=592.072632 err=31.997364
I 2015-05-27 00:22:33 theanets.trainer:168 RmsProp 94 loss=587.898682 err=29.716919
I 2015-05-27 00:22:44 theanets.trainer:168 RmsProp 95 loss=586.183228 err=29.898108
I 2015-05-27 00:22:54 theanets.trainer:168 RmsProp 96 loss=584.637390 err=30.257397
I 2015-05-27 00:23:04 theanets.trainer:168 RmsProp 97 loss=581.941589 err=29.394688
I 2015-05-27 00:23:15 theanets.trainer:168 RmsProp 98 loss=578.278198 err=27.527176
I 2015-05-27 00:23:25 theanets.trainer:168 RmsProp 99 loss=577.409302 err=28.525986
I 2015-05-27 00:23:35 theanets.trainer:168 RmsProp 100 loss=576.940247 err=29.903915
I 2015-05-27 00:23:36 theanets.trainer:168 validation 10 loss=9731.610352 err=9185.528320 *
I 2015-05-27 00:23:46 theanets.trainer:168 RmsProp 101 loss=572.377686 err=27.047028
I 2015-05-27 00:23:56 theanets.trainer:168 RmsProp 102 loss=570.089722 err=26.448313
I 2015-05-27 00:24:06 theanets.trainer:168 RmsProp 103 loss=569.581848 err=27.687794
I 2015-05-27 00:24:17 theanets.trainer:168 RmsProp 104 loss=566.904236 err=26.737936
I 2015-05-27 00:24:27 theanets.trainer:168 RmsProp 105 loss=564.591187 err=26.106678
I 2015-05-27 00:24:38 theanets.trainer:168 RmsProp 106 loss=562.274536 err=25.461731
I 2015-05-27 00:24:48 theanets.trainer:168 RmsProp 107 loss=560.911316 err=25.737301
I 2015-05-27 00:24:58 theanets.trainer:168 RmsProp 108 loss=558.651672 err=25.125263
I 2015-05-27 00:25:08 theanets.trainer:168 RmsProp 109 loss=556.712402 err=24.872948
I 2015-05-27 00:25:19 theanets.trainer:168 RmsProp 110 loss=554.177002 err=24.058163
I 2015-05-27 00:25:19 theanets.trainer:168 validation 11 loss=9673.831055 err=9144.659180 *
I 2015-05-27 00:25:29 theanets.trainer:168 RmsProp 111 loss=552.832153 err=24.433867
I 2015-05-27 00:25:39 theanets.trainer:168 RmsProp 112 loss=551.864868 err=25.152637
I 2015-05-27 00:25:50 theanets.trainer:168 RmsProp 113 loss=549.196167 err=24.152086
I 2015-05-27 00:26:00 theanets.trainer:168 RmsProp 114 loss=546.606079 err=23.223162
I 2015-05-27 00:26:10 theanets.trainer:168 RmsProp 115 loss=546.105591 err=24.332775
I 2015-05-27 00:26:20 theanets.trainer:168 RmsProp 116 loss=544.053833 err=23.873266
I 2015-05-27 00:26:30 theanets.trainer:168 RmsProp 117 loss=542.529724 err=23.927711
I 2015-05-27 00:26:40 theanets.trainer:168 RmsProp 118 loss=539.605225 err=22.573818
I 2015-05-27 00:26:50 theanets.trainer:168 RmsProp 119 loss=538.467224 err=23.028107
I 2015-05-27 00:27:00 theanets.trainer:168 RmsProp 120 loss=538.287292 err=24.450401
I 2015-05-27 00:27:01 theanets.trainer:168 validation 12 loss=9790.988281 err=9278.010742
I 2015-05-27 00:27:10 theanets.trainer:168 RmsProp 121 loss=535.283691 err=22.986620
I 2015-05-27 00:27:20 theanets.trainer:168 RmsProp 122 loss=531.724792 err=20.930513
I 2015-05-27 00:27:30 theanets.trainer:168 RmsProp 123 loss=533.161133 err=23.911415
I 2015-05-27 00:27:39 theanets.trainer:168 RmsProp 124 loss=529.827026 err=22.089802
I 2015-05-27 00:27:49 theanets.trainer:168 RmsProp 125 loss=529.129395 err=22.872160
I 2015-05-27 00:27:59 theanets.trainer:168 RmsProp 126 loss=525.720642 err=20.959238
I 2015-05-27 00:28:08 theanets.trainer:168 RmsProp 127 loss=525.196960 err=21.916737
I 2015-05-27 00:28:18 theanets.trainer:168 RmsProp 128 loss=524.183716 err=22.374115
I 2015-05-27 00:28:28 theanets.trainer:168 RmsProp 129 loss=521.360046 err=20.982018
I 2015-05-27 00:28:38 theanets.trainer:168 RmsProp 130 loss=520.023560 err=21.066807
I 2015-05-27 00:28:38 theanets.trainer:168 validation 13 loss=9769.972656 err=9271.799805
I 2015-05-27 00:28:48 theanets.trainer:168 RmsProp 131 loss=519.263550 err=21.735979
I 2015-05-27 00:28:58 theanets.trainer:168 RmsProp 132 loss=516.739685 err=20.637722
I 2015-05-27 00:29:09 theanets.trainer:168 RmsProp 133 loss=515.673401 err=20.982416
I 2015-05-27 00:29:19 theanets.trainer:168 RmsProp 134 loss=514.191711 err=20.876543
I 2015-05-27 00:29:29 theanets.trainer:168 RmsProp 135 loss=512.296326 err=20.356876
I 2015-05-27 00:29:40 theanets.trainer:168 RmsProp 136 loss=510.756165 err=20.193104
I 2015-05-27 00:29:50 theanets.trainer:168 RmsProp 137 loss=509.071289 err=19.870256
I 2015-05-27 00:30:00 theanets.trainer:168 RmsProp 138 loss=507.627991 err=19.770260
I 2015-05-27 00:30:10 theanets.trainer:168 RmsProp 139 loss=506.372864 err=19.850487
I 2015-05-27 00:30:20 theanets.trainer:168 RmsProp 140 loss=502.990570 err=17.804403
I 2015-05-27 00:30:21 theanets.trainer:168 validation 14 loss=9772.425781 err=9287.978516
I 2015-05-27 00:30:31 theanets.trainer:168 RmsProp 141 loss=505.702881 err=21.856747
I 2015-05-27 00:30:41 theanets.trainer:168 RmsProp 142 loss=502.594879 err=20.038591
I 2015-05-27 00:30:51 theanets.trainer:168 RmsProp 143 loss=500.659729 err=19.349894
I 2015-05-27 00:31:01 theanets.trainer:168 RmsProp 144 loss=499.052002 err=19.013767
I 2015-05-27 00:31:12 theanets.trainer:168 RmsProp 145 loss=496.604675 err=17.844456
I 2015-05-27 00:31:22 theanets.trainer:168 RmsProp 146 loss=497.728668 err=20.256498
I 2015-05-27 00:31:32 theanets.trainer:168 RmsProp 147 loss=494.317200 err=18.116674
I 2015-05-27 00:31:42 theanets.trainer:168 RmsProp 148 loss=493.095123 err=18.163540
I 2015-05-27 00:31:52 theanets.trainer:168 RmsProp 149 loss=491.897217 err=18.246258
I 2015-05-27 00:32:02 theanets.trainer:168 RmsProp 150 loss=490.467621 err=18.081730
I 2015-05-27 00:32:03 theanets.trainer:168 validation 15 loss=9645.631836 err=9173.940430 *
I 2015-05-27 00:32:13 theanets.trainer:168 RmsProp 151 loss=489.576324 err=18.442898
I 2015-05-27 00:32:23 theanets.trainer:168 RmsProp 152 loss=488.386963 err=18.490376
I 2015-05-27 00:32:34 theanets.trainer:168 RmsProp 153 loss=487.306641 err=18.650373
I 2015-05-27 00:32:44 theanets.trainer:168 RmsProp 154 loss=485.931061 err=18.491016
I 2015-05-27 00:32:54 theanets.trainer:168 RmsProp 155 loss=483.749176 err=17.509439
I 2015-05-27 00:33:05 theanets.trainer:168 RmsProp 156 loss=482.207611 err=17.161936
I 2015-05-27 00:33:15 theanets.trainer:168 RmsProp 157 loss=483.006897 err=19.161806
I 2015-05-27 00:33:25 theanets.trainer:168 RmsProp 158 loss=480.481049 err=17.805710
I 2015-05-27 00:33:36 theanets.trainer:168 RmsProp 159 loss=477.488770 err=15.961641
I 2015-05-27 00:33:46 theanets.trainer:168 RmsProp 160 loss=478.367432 err=18.028349
I 2015-05-27 00:33:47 theanets.trainer:168 validation 16 loss=9672.909180 err=9213.233398
I 2015-05-27 00:33:57 theanets.trainer:168 RmsProp 161 loss=477.410065 err=18.258020
I 2015-05-27 00:34:07 theanets.trainer:168 RmsProp 162 loss=475.254791 err=17.229877
I 2015-05-27 00:34:18 theanets.trainer:168 RmsProp 163 loss=474.196960 err=17.287638
I 2015-05-27 00:34:28 theanets.trainer:168 RmsProp 164 loss=472.239166 err=16.454065
I 2015-05-27 00:34:39 theanets.trainer:168 RmsProp 165 loss=471.188416 err=16.526447
I 2015-05-27 00:34:49 theanets.trainer:168 RmsProp 166 loss=470.801025 err=17.284664
I 2015-05-27 00:35:00 theanets.trainer:168 RmsProp 167 loss=469.464417 err=17.084412
I 2015-05-27 00:35:10 theanets.trainer:168 RmsProp 168 loss=468.402985 err=17.131237
I 2015-05-27 00:35:21 theanets.trainer:168 RmsProp 169 loss=466.327820 err=16.168365
I 2015-05-27 00:35:31 theanets.trainer:168 RmsProp 170 loss=465.464050 err=16.405251
I 2015-05-27 00:35:32 theanets.trainer:168 validation 17 loss=9561.362305 err=9112.903320 *
I 2015-05-27 00:35:42 theanets.trainer:168 RmsProp 171 loss=464.113831 err=16.158772
I 2015-05-27 00:35:52 theanets.trainer:168 RmsProp 172 loss=463.179688 err=16.331825
I 2015-05-27 00:36:03 theanets.trainer:168 RmsProp 173 loss=462.277496 err=16.517401
I 2015-05-27 00:36:13 theanets.trainer:168 RmsProp 174 loss=460.534485 err=15.832510
I 2015-05-27 00:36:23 theanets.trainer:168 RmsProp 175 loss=460.158386 err=16.512955
I 2015-05-27 00:36:33 theanets.trainer:168 RmsProp 176 loss=458.218445 err=15.634770
I 2015-05-27 00:36:43 theanets.trainer:168 RmsProp 177 loss=457.508301 err=15.984273
I 2015-05-27 00:36:53 theanets.trainer:168 RmsProp 178 loss=456.217926 err=15.746527
I 2015-05-27 00:37:04 theanets.trainer:168 RmsProp 179 loss=455.332275 err=15.923813
I 2015-05-27 00:37:14 theanets.trainer:168 RmsProp 180 loss=453.838470 err=15.480176
I 2015-05-27 00:37:14 theanets.trainer:168 validation 18 loss=9569.251953 err=9131.464844
I 2015-05-27 00:37:25 theanets.trainer:168 RmsProp 181 loss=453.100281 err=15.778440
I 2015-05-27 00:37:35 theanets.trainer:168 RmsProp 182 loss=451.921204 err=15.616391
I 2015-05-27 00:37:45 theanets.trainer:168 RmsProp 183 loss=450.567566 err=15.276514
I 2015-05-27 00:37:56 theanets.trainer:168 RmsProp 184 loss=449.079895 err=14.808052
I 2015-05-27 00:38:06 theanets.trainer:168 RmsProp 185 loss=448.648743 err=15.399553
I 2015-05-27 00:38:16 theanets.trainer:168 RmsProp 186 loss=447.673157 err=15.450007
I 2015-05-27 00:38:26 theanets.trainer:168 RmsProp 187 loss=446.465912 err=15.242697
I 2015-05-27 00:38:36 theanets.trainer:168 RmsProp 188 loss=445.405670 err=15.179034
I 2015-05-27 00:38:47 theanets.trainer:168 RmsProp 189 loss=444.183533 err=14.953247
I 2015-05-27 00:38:57 theanets.trainer:168 RmsProp 190 loss=443.882263 err=15.630780
I 2015-05-27 00:38:57 theanets.trainer:168 validation 19 loss=9584.434570 err=9156.716797
I 2015-05-27 00:39:08 theanets.trainer:168 RmsProp 191 loss=440.883881 err=13.588165
I 2015-05-27 00:39:18 theanets.trainer:168 RmsProp 192 loss=440.241302 err=13.921211
I 2015-05-27 00:39:28 theanets.trainer:168 RmsProp 193 loss=440.904694 err=15.572447
I 2015-05-27 00:39:38 theanets.trainer:168 RmsProp 194 loss=439.353119 err=14.989197
I 2015-05-27 00:39:49 theanets.trainer:168 RmsProp 195 loss=437.969299 err=14.562609
I 2015-05-27 00:39:59 theanets.trainer:168 RmsProp 196 loss=436.843933 err=14.394018
I 2015-05-27 00:40:09 theanets.trainer:168 RmsProp 197 loss=435.898529 err=14.390132
I 2015-05-27 00:40:19 theanets.trainer:168 RmsProp 198 loss=434.526947 err=13.966191
I 2015-05-27 00:40:30 theanets.trainer:168 RmsProp 199 loss=434.033508 err=14.434584
I 2015-05-27 00:40:40 theanets.trainer:168 RmsProp 200 loss=432.639709 err=14.002154
I 2015-05-27 00:40:40 theanets.trainer:168 validation 20 loss=9646.662109 err=9228.541016
I 2015-05-27 00:40:51 theanets.trainer:168 RmsProp 201 loss=431.784485 err=14.077217
I 2015-05-27 00:41:01 theanets.trainer:168 RmsProp 202 loss=430.901855 err=14.113597
I 2015-05-27 00:41:11 theanets.trainer:168 RmsProp 203 loss=429.531433 err=13.656387
I 2015-05-27 00:41:21 theanets.trainer:168 RmsProp 204 loss=429.123474 err=14.151632
I 2015-05-27 00:41:32 theanets.trainer:168 RmsProp 205 loss=426.073975 err=12.023189
I 2015-05-27 00:41:42 theanets.trainer:168 RmsProp 206 loss=431.228333 err=18.096386
I 2015-05-27 00:41:52 theanets.trainer:168 RmsProp 207 loss=425.888824 err=13.609670
I 2015-05-27 00:42:02 theanets.trainer:168 RmsProp 208 loss=423.973694 err=12.502611
I 2015-05-27 00:42:12 theanets.trainer:168 RmsProp 209 loss=424.739838 err=14.110350
I 2015-05-27 00:42:23 theanets.trainer:168 RmsProp 210 loss=423.303375 err=13.560488
I 2015-05-27 00:42:23 theanets.trainer:168 validation 21 loss=9520.276367 err=9111.023438 *
I 2015-05-27 00:42:33 theanets.trainer:168 RmsProp 211 loss=422.505798 err=13.649490
I 2015-05-27 00:42:44 theanets.trainer:168 RmsProp 212 loss=421.170746 err=13.196505
I 2015-05-27 00:42:54 theanets.trainer:168 RmsProp 213 loss=422.554504 err=15.474710
I 2015-05-27 00:43:04 theanets.trainer:168 RmsProp 214 loss=420.995117 err=14.756170
I 2015-05-27 00:43:15 theanets.trainer:168 RmsProp 215 loss=418.310303 err=12.858394
I 2015-05-27 00:43:25 theanets.trainer:168 RmsProp 216 loss=417.707092 err=13.047559
I 2015-05-27 00:43:35 theanets.trainer:168 RmsProp 217 loss=417.797516 err=13.968684
I 2015-05-27 00:43:45 theanets.trainer:168 RmsProp 218 loss=415.900787 err=12.900520
I 2015-05-27 00:43:55 theanets.trainer:168 RmsProp 219 loss=415.749695 err=13.571083
I 2015-05-27 00:44:05 theanets.trainer:168 RmsProp 220 loss=414.658997 err=13.297177
I 2015-05-27 00:44:05 theanets.trainer:168 validation 22 loss=9549.945312 err=9149.036133
I 2015-05-27 00:44:15 theanets.trainer:168 RmsProp 221 loss=412.859314 err=12.323140
I 2015-05-27 00:44:25 theanets.trainer:168 RmsProp 222 loss=413.673767 err=13.964892
I 2015-05-27 00:44:35 theanets.trainer:168 RmsProp 223 loss=411.870544 err=12.970251
I 2015-05-27 00:44:45 theanets.trainer:168 RmsProp 224 loss=410.459564 err=12.360003
I 2015-05-27 00:44:55 theanets.trainer:168 RmsProp 225 loss=410.727386 err=13.435297
I 2015-05-27 00:45:05 theanets.trainer:168 RmsProp 226 loss=409.532104 err=13.045949
I 2015-05-27 00:45:15 theanets.trainer:168 RmsProp 227 loss=408.165222 err=12.470646
I 2015-05-27 00:45:25 theanets.trainer:168 RmsProp 228 loss=408.173218 err=13.274885
I 2015-05-27 00:45:36 theanets.trainer:168 RmsProp 229 loss=406.808075 err=12.705935
I 2015-05-27 00:45:46 theanets.trainer:168 RmsProp 230 loss=406.270325 err=12.945476
I 2015-05-27 00:45:47 theanets.trainer:168 validation 23 loss=9509.187500 err=9116.291016 *
I 2015-05-27 00:45:57 theanets.trainer:168 RmsProp 231 loss=404.607361 err=12.048635
I 2015-05-27 00:46:07 theanets.trainer:168 RmsProp 232 loss=404.360840 err=12.572156
I 2015-05-27 00:46:17 theanets.trainer:168 RmsProp 233 loss=403.096832 err=12.096417
I 2015-05-27 00:46:28 theanets.trainer:168 RmsProp 234 loss=402.912170 err=12.696852
I 2015-05-27 00:46:38 theanets.trainer:168 RmsProp 235 loss=401.518707 err=12.084188
I 2015-05-27 00:46:48 theanets.trainer:168 RmsProp 236 loss=402.146057 err=13.474527
I 2015-05-27 00:46:59 theanets.trainer:168 RmsProp 237 loss=400.254456 err=12.336765
I 2015-05-27 00:47:09 theanets.trainer:168 RmsProp 238 loss=399.503540 err=12.317168
I 2015-05-27 00:47:20 theanets.trainer:168 RmsProp 239 loss=398.700104 err=12.245417
I 2015-05-27 00:47:31 theanets.trainer:168 RmsProp 240 loss=397.235260 err=11.524491
I 2015-05-27 00:47:31 theanets.trainer:168 validation 24 loss=9434.984375 err=9049.674805 *
I 2015-05-27 00:47:42 theanets.trainer:168 RmsProp 241 loss=398.558685 err=13.580241
I 2015-05-27 00:47:52 theanets.trainer:168 RmsProp 242 loss=396.060089 err=11.795095
I 2015-05-27 00:48:03 theanets.trainer:168 RmsProp 243 loss=395.828674 err=12.273875
I 2015-05-27 00:48:13 theanets.trainer:168 RmsProp 244 loss=395.355713 err=12.516224
I 2015-05-27 00:48:24 theanets.trainer:168 RmsProp 245 loss=394.669617 err=12.548088
I 2015-05-27 00:48:35 theanets.trainer:168 RmsProp 246 loss=393.137299 err=11.738389
I 2015-05-27 00:48:46 theanets.trainer:168 RmsProp 247 loss=392.023895 err=11.357477
I 2015-05-27 00:48:56 theanets.trainer:168 RmsProp 248 loss=392.605042 err=12.672163
I 2015-05-27 00:49:07 theanets.trainer:168 RmsProp 249 loss=391.198639 err=11.986628
I 2015-05-27 00:49:18 theanets.trainer:168 RmsProp 250 loss=390.097961 err=11.581293
I 2015-05-27 00:49:18 theanets.trainer:168 validation 25 loss=9440.113281 err=9061.976562
I 2015-05-27 00:49:29 theanets.trainer:168 RmsProp 251 loss=390.410461 err=12.582918
I 2015-05-27 00:49:40 theanets.trainer:168 RmsProp 252 loss=388.033783 err=10.890978
I 2015-05-27 00:49:50 theanets.trainer:168 RmsProp 253 loss=388.995819 err=12.555053
I 2015-05-27 00:50:01 theanets.trainer:168 RmsProp 254 loss=388.271912 err=12.525839
I 2015-05-27 00:50:11 theanets.trainer:168 RmsProp 255 loss=385.770355 err=10.692815
I 2015-05-27 00:50:22 theanets.trainer:168 RmsProp 256 loss=387.341370 err=12.944643
I 2015-05-27 00:50:32 theanets.trainer:168 RmsProp 257 loss=385.656036 err=11.941790
I 2015-05-27 00:50:43 theanets.trainer:168 RmsProp 258 loss=383.615479 err=10.562731
I 2015-05-27 00:50:53 theanets.trainer:168 RmsProp 259 loss=383.777283 err=11.397241
I 2015-05-27 00:51:04 theanets.trainer:168 RmsProp 260 loss=383.651123 err=11.958939
I 2015-05-27 00:51:05 theanets.trainer:168 validation 26 loss=9429.107422 err=9057.791992 *
I 2015-05-27 00:51:15 theanets.trainer:168 RmsProp 261 loss=382.462463 err=11.453584
I 2015-05-27 00:51:25 theanets.trainer:168 RmsProp 262 loss=381.616425 err=11.288065
I 2015-05-27 00:51:36 theanets.trainer:168 RmsProp 263 loss=380.718811 err=11.073421
I 2015-05-27 00:51:46 theanets.trainer:168 RmsProp 264 loss=380.514099 err=11.545818
I 2015-05-27 00:51:56 theanets.trainer:168 RmsProp 265 loss=379.986816 err=11.687483
I 2015-05-27 00:52:07 theanets.trainer:168 RmsProp 266 loss=378.416382 err=10.769444
I 2015-05-27 00:52:17 theanets.trainer:168 RmsProp 267 loss=378.262939 err=11.268589
I 2015-05-27 00:52:28 theanets.trainer:168 RmsProp 268 loss=377.278076 err=10.948736
I 2015-05-27 00:52:38 theanets.trainer:168 RmsProp 269 loss=377.525940 err=11.848323
I 2015-05-27 00:52:49 theanets.trainer:168 RmsProp 270 loss=376.193665 err=11.153036
I 2015-05-27 00:52:49 theanets.trainer:168 validation 27 loss=9507.453125 err=9142.756836
I 2015-05-27 00:53:00 theanets.trainer:168 RmsProp 271 loss=375.400696 err=10.986655
I 2015-05-27 00:53:10 theanets.trainer:168 RmsProp 272 loss=375.125031 err=11.340400
I 2015-05-27 00:53:20 theanets.trainer:168 RmsProp 273 loss=373.687775 err=10.547735
I 2015-05-27 00:53:31 theanets.trainer:168 RmsProp 274 loss=373.728973 err=11.245491
I 2015-05-27 00:53:41 theanets.trainer:168 RmsProp 275 loss=372.829041 err=10.991060
I 2015-05-27 00:53:51 theanets.trainer:168 RmsProp 276 loss=372.345764 err=11.147690
I 2015-05-27 00:54:02 theanets.trainer:168 RmsProp 277 loss=371.662537 err=11.104255
I 2015-05-27 00:54:12 theanets.trainer:168 RmsProp 278 loss=371.163696 err=11.232064
I 2015-05-27 00:54:23 theanets.trainer:168 RmsProp 279 loss=370.079895 err=10.768026
I 2015-05-27 00:54:33 theanets.trainer:168 RmsProp 280 loss=369.263519 err=10.566711
I 2015-05-27 00:54:34 theanets.trainer:168 validation 28 loss=9417.443359 err=9059.096680 *
I 2015-05-27 00:54:44 theanets.trainer:168 RmsProp 281 loss=369.062378 err=10.996295
I 2015-05-27 00:54:54 theanets.trainer:168 RmsProp 282 loss=368.800720 err=11.370359
I 2015-05-27 00:55:05 theanets.trainer:168 RmsProp 283 loss=367.231659 err=10.419386
I 2015-05-27 00:55:15 theanets.trainer:168 RmsProp 284 loss=367.089294 err=10.894622
I 2015-05-27 00:55:26 theanets.trainer:168 RmsProp 285 loss=366.337585 err=10.759872
I 2015-05-27 00:55:36 theanets.trainer:168 RmsProp 286 loss=365.436218 err=10.459068
I 2015-05-27 00:55:47 theanets.trainer:168 RmsProp 287 loss=364.953308 err=10.580867
I 2015-05-27 00:55:57 theanets.trainer:168 RmsProp 288 loss=364.885406 err=11.111937
I 2015-05-27 00:56:07 theanets.trainer:168 RmsProp 289 loss=364.163727 err=10.978363
I 2015-05-27 00:56:18 theanets.trainer:168 RmsProp 290 loss=362.558350 err=9.953319
I 2015-05-27 00:56:18 theanets.trainer:168 validation 29 loss=9429.006836 err=9076.723633
I 2015-05-27 00:56:29 theanets.trainer:168 RmsProp 291 loss=361.940857 err=9.920595
I 2015-05-27 00:56:39 theanets.trainer:168 RmsProp 292 loss=363.458618 err=12.045925
I 2015-05-27 00:56:50 theanets.trainer:168 RmsProp 293 loss=362.445953 err=11.618803
I 2015-05-27 00:57:00 theanets.trainer:168 RmsProp 294 loss=359.839081 err=9.569660
I 2015-05-27 00:57:11 theanets.trainer:168 RmsProp 295 loss=360.264221 err=10.548701
I 2015-05-27 00:57:21 theanets.trainer:168 RmsProp 296 loss=360.040100 err=10.894726
I 2015-05-27 00:57:31 theanets.trainer:168 RmsProp 297 loss=358.783234 err=10.209604
I 2015-05-27 00:57:42 theanets.trainer:168 RmsProp 298 loss=358.312683 err=10.315102
I 2015-05-27 00:57:52 theanets.trainer:168 RmsProp 299 loss=357.687714 err=10.265654
I 2015-05-27 00:58:03 theanets.trainer:168 RmsProp 300 loss=357.105347 err=10.262711
I 2015-05-27 00:58:03 theanets.trainer:168 validation 30 loss=9433.115234 err=9086.590820
I 2015-05-27 00:58:13 theanets.trainer:168 RmsProp 301 loss=356.494446 err=10.228856
I 2015-05-27 00:58:24 theanets.trainer:168 RmsProp 302 loss=355.736938 err=10.050308
I 2015-05-27 00:58:34 theanets.trainer:168 RmsProp 303 loss=355.726990 err=10.614233
I 2015-05-27 00:58:44 theanets.trainer:168 RmsProp 304 loss=354.606995 err=10.058537
I 2015-05-27 00:58:54 theanets.trainer:168 RmsProp 305 loss=353.864563 err=9.879275
I 2015-05-27 00:59:05 theanets.trainer:168 RmsProp 306 loss=353.334747 err=9.913096
I 2015-05-27 00:59:15 theanets.trainer:168 RmsProp 307 loss=353.004456 err=10.137018
I 2015-05-27 00:59:26 theanets.trainer:168 RmsProp 308 loss=351.939148 err=9.631114
I 2015-05-27 00:59:36 theanets.trainer:168 RmsProp 309 loss=352.322418 err=10.573676
I 2015-05-27 00:59:47 theanets.trainer:168 RmsProp 310 loss=351.598999 err=10.395833
I 2015-05-27 00:59:47 theanets.trainer:168 validation 31 loss=9489.235352 err=9148.319336
I 2015-05-27 00:59:57 theanets.trainer:168 RmsProp 311 loss=350.619934 err=9.949931
I 2015-05-27 01:00:07 theanets.trainer:168 RmsProp 312 loss=349.712219 err=9.584371
I 2015-05-27 01:00:17 theanets.trainer:168 RmsProp 313 loss=350.022308 err=10.436365
I 2015-05-27 01:00:27 theanets.trainer:168 RmsProp 314 loss=349.086243 err=10.041595
I 2015-05-27 01:00:37 theanets.trainer:168 RmsProp 315 loss=348.022705 err=9.510595
I 2015-05-27 01:00:47 theanets.trainer:168 RmsProp 316 loss=347.689514 err=9.705469
I 2015-05-27 01:00:57 theanets.trainer:168 RmsProp 317 loss=347.083435 err=9.637153
I 2015-05-27 01:01:06 theanets.trainer:168 RmsProp 318 loss=347.287048 err=10.379486
I 2015-05-27 01:01:16 theanets.trainer:168 RmsProp 319 loss=346.493225 err=10.114887
I 2015-05-27 01:01:26 theanets.trainer:168 RmsProp 320 loss=346.268616 err=10.401971
I 2015-05-27 01:01:27 theanets.trainer:168 validation 32 loss=9386.576172 err=9050.993164 *
I 2015-05-27 01:01:37 theanets.trainer:168 RmsProp 321 loss=344.836243 err=9.474943
I 2015-05-27 01:01:46 theanets.trainer:168 RmsProp 322 loss=344.771790 err=9.908117
I 2015-05-27 01:01:56 theanets.trainer:168 RmsProp 323 loss=343.940552 err=9.587425
I 2015-05-27 01:02:07 theanets.trainer:168 RmsProp 324 loss=343.601440 err=9.768122
I 2015-05-27 01:02:17 theanets.trainer:168 RmsProp 325 loss=342.970032 err=9.658676
I 2015-05-27 01:02:28 theanets.trainer:168 RmsProp 326 loss=342.085785 err=9.298970
I 2015-05-27 01:02:38 theanets.trainer:168 RmsProp 327 loss=342.012817 err=9.753656
I 2015-05-27 01:02:48 theanets.trainer:168 RmsProp 328 loss=342.026672 err=10.289900
I 2015-05-27 01:02:59 theanets.trainer:168 RmsProp 329 loss=339.901581 err=8.677128
I 2015-05-27 01:03:09 theanets.trainer:168 RmsProp 330 loss=340.643494 err=9.928991
I 2015-05-27 01:03:10 theanets.trainer:168 validation 33 loss=9308.386719 err=8977.945312 *
I 2015-05-27 01:03:20 theanets.trainer:168 RmsProp 331 loss=340.330627 err=10.120440
I 2015-05-27 01:03:31 theanets.trainer:168 RmsProp 332 loss=339.181213 err=9.475761
I 2015-05-27 01:03:41 theanets.trainer:168 RmsProp 333 loss=338.124420 err=8.928892
I 2015-05-27 01:03:52 theanets.trainer:168 RmsProp 334 loss=338.482239 err=9.788912
I 2015-05-27 01:04:02 theanets.trainer:168 RmsProp 335 loss=338.041382 err=9.845661
I 2015-05-27 01:04:13 theanets.trainer:168 RmsProp 336 loss=336.750671 err=9.051260
I 2015-05-27 01:04:23 theanets.trainer:168 RmsProp 337 loss=337.263092 err=10.052252
I 2015-05-27 01:04:34 theanets.trainer:168 RmsProp 338 loss=335.968353 err=9.246057
I 2015-05-27 01:04:45 theanets.trainer:168 RmsProp 339 loss=335.116516 err=8.878401
I 2015-05-27 01:04:56 theanets.trainer:168 RmsProp 340 loss=335.493774 err=9.748445
I 2015-05-27 01:04:57 theanets.trainer:168 validation 34 loss=9392.600586 err=9067.128906
I 2015-05-27 01:05:07 theanets.trainer:168 RmsProp 341 loss=334.666748 err=9.420781
I 2015-05-27 01:05:18 theanets.trainer:168 RmsProp 342 loss=334.122711 err=9.370177
I 2015-05-27 01:05:29 theanets.trainer:168 RmsProp 343 loss=333.006470 err=8.741580
I 2015-05-27 01:05:40 theanets.trainer:168 RmsProp 344 loss=333.581696 err=9.798464
I 2015-05-27 01:05:50 theanets.trainer:168 RmsProp 345 loss=332.755219 err=9.450616
I 2015-05-27 01:06:01 theanets.trainer:168 RmsProp 346 loss=331.990265 err=9.158137
I 2015-05-27 01:06:11 theanets.trainer:168 RmsProp 347 loss=332.402802 err=10.031546
I 2015-05-27 01:06:22 theanets.trainer:168 RmsProp 348 loss=330.649353 err=8.740683
I 2015-05-27 01:06:32 theanets.trainer:168 RmsProp 349 loss=330.722900 err=9.277946
I 2015-05-27 01:06:43 theanets.trainer:168 RmsProp 350 loss=329.895813 err=8.919417
I 2015-05-27 01:06:43 theanets.trainer:168 validation 35 loss=9284.128906 err=8963.397461 *
I 2015-05-27 01:06:54 theanets.trainer:168 RmsProp 351 loss=329.892273 err=9.379004
I 2015-05-27 01:07:04 theanets.trainer:168 RmsProp 352 loss=329.047546 err=9.012239
I 2015-05-27 01:07:15 theanets.trainer:168 RmsProp 353 loss=329.167908 err=9.598147
I 2015-05-27 01:07:26 theanets.trainer:168 RmsProp 354 loss=328.010681 err=8.905634
I 2015-05-27 01:07:36 theanets.trainer:168 RmsProp 355 loss=327.258453 err=8.619328
I 2015-05-27 01:07:47 theanets.trainer:168 RmsProp 356 loss=326.836792 err=8.672294
I 2015-05-27 01:07:57 theanets.trainer:168 RmsProp 357 loss=327.192261 err=9.502310
I 2015-05-27 01:08:08 theanets.trainer:168 RmsProp 358 loss=326.202057 err=8.975039
I 2015-05-27 01:08:19 theanets.trainer:168 RmsProp 359 loss=325.868713 err=9.099682
I 2015-05-27 01:08:30 theanets.trainer:168 RmsProp 360 loss=325.482910 err=9.170770
I 2015-05-27 01:08:30 theanets.trainer:168 validation 36 loss=9287.469727 err=8971.401367
I 2015-05-27 01:08:41 theanets.trainer:168 RmsProp 361 loss=325.253723 err=9.393694
I 2015-05-27 01:08:52 theanets.trainer:168 RmsProp 362 loss=324.188416 err=8.781531
I 2015-05-27 01:09:03 theanets.trainer:168 RmsProp 363 loss=323.940918 err=8.984549
I 2015-05-27 01:09:13 theanets.trainer:168 RmsProp 364 loss=323.698517 err=9.189402
I 2015-05-27 01:09:24 theanets.trainer:168 RmsProp 365 loss=322.948669 err=8.876240
I 2015-05-27 01:09:35 theanets.trainer:168 RmsProp 366 loss=322.887024 err=9.257442
I 2015-05-27 01:09:46 theanets.trainer:168 RmsProp 367 loss=322.184723 err=8.990621
I 2015-05-27 01:09:57 theanets.trainer:168 RmsProp 368 loss=321.691132 err=8.928802
I 2015-05-27 01:10:07 theanets.trainer:168 RmsProp 369 loss=321.316956 err=8.985994
I 2015-05-27 01:10:18 theanets.trainer:168 RmsProp 370 loss=320.738464 err=8.846468
I 2015-05-27 01:10:19 theanets.trainer:168 validation 37 loss=9276.789062 err=8965.135742 *
I 2015-05-27 01:10:29 theanets.trainer:168 RmsProp 371 loss=319.762878 err=8.310758
I 2015-05-27 01:10:40 theanets.trainer:168 RmsProp 372 loss=319.877502 err=8.865225
I 2015-05-27 01:10:51 theanets.trainer:168 RmsProp 373 loss=319.230164 err=8.662485
I 2015-05-27 01:11:02 theanets.trainer:168 RmsProp 374 loss=319.094879 err=8.973406
I 2015-05-27 01:11:13 theanets.trainer:168 RmsProp 375 loss=318.557709 err=8.874216
I 2015-05-27 01:11:24 theanets.trainer:168 RmsProp 376 loss=317.675842 err=8.423306
I 2015-05-27 01:11:35 theanets.trainer:168 RmsProp 377 loss=317.470917 err=8.649736
I 2015-05-27 01:11:46 theanets.trainer:168 RmsProp 378 loss=317.325623 err=8.935606
I 2015-05-27 01:11:57 theanets.trainer:168 RmsProp 379 loss=317.202637 err=9.240429
I 2015-05-27 01:12:08 theanets.trainer:168 RmsProp 380 loss=316.041168 err=8.500238
I 2015-05-27 01:12:08 theanets.trainer:168 validation 38 loss=9372.785156 err=9065.471680
I 2015-05-27 01:12:19 theanets.trainer:168 RmsProp 381 loss=315.839966 err=8.715006
I 2015-05-27 01:12:30 theanets.trainer:168 RmsProp 382 loss=315.552185 err=8.841548
I 2015-05-27 01:12:41 theanets.trainer:168 RmsProp 383 loss=315.072998 err=8.774956
I 2015-05-27 01:12:51 theanets.trainer:168 RmsProp 384 loss=314.479553 err=8.594280
I 2015-05-27 01:13:02 theanets.trainer:168 RmsProp 385 loss=314.062714 err=8.591231
I 2015-05-27 01:13:13 theanets.trainer:168 RmsProp 386 loss=312.637573 err=7.584741
I 2015-05-27 01:13:23 theanets.trainer:168 RmsProp 387 loss=314.511627 err=9.870417
I 2015-05-27 01:13:34 theanets.trainer:168 RmsProp 388 loss=311.482483 err=7.263877
I 2015-05-27 01:13:44 theanets.trainer:168 RmsProp 389 loss=313.632477 err=9.819803
I 2015-05-27 01:13:55 theanets.trainer:168 RmsProp 390 loss=311.743317 err=8.333425
I 2015-05-27 01:13:56 theanets.trainer:168 validation 39 loss=9259.025391 err=8955.825195 *
I 2015-05-27 01:14:06 theanets.trainer:168 RmsProp 391 loss=311.391357 err=8.381208
I 2015-05-27 01:14:16 theanets.trainer:168 RmsProp 392 loss=311.534851 err=8.928686
I 2015-05-27 01:14:27 theanets.trainer:168 RmsProp 393 loss=310.743256 err=8.543806
I 2015-05-27 01:14:37 theanets.trainer:168 RmsProp 394 loss=310.464386 err=8.659916
I 2015-05-27 01:14:48 theanets.trainer:168 RmsProp 395 loss=310.010559 err=8.597180
I 2015-05-27 01:14:58 theanets.trainer:168 RmsProp 396 loss=309.590820 err=8.570902
I 2015-05-27 01:15:08 theanets.trainer:168 RmsProp 397 loss=309.106628 err=8.478561
I 2015-05-27 01:15:19 theanets.trainer:168 RmsProp 398 loss=308.232727 err=7.992193
I 2015-05-27 01:15:29 theanets.trainer:168 RmsProp 399 loss=308.549133 err=8.705437
I 2015-05-27 01:15:39 theanets.trainer:168 RmsProp 400 loss=307.435852 err=7.991953
I 2015-05-27 01:15:40 theanets.trainer:168 validation 40 loss=9241.958984 err=8942.733398 *
I 2015-05-27 01:15:50 theanets.trainer:168 RmsProp 401 loss=308.346680 err=9.294363
I 2015-05-27 01:16:00 theanets.trainer:168 RmsProp 402 loss=306.637024 err=7.980142
I 2015-05-27 01:16:11 theanets.trainer:168 RmsProp 403 loss=306.753357 err=8.488686
I 2015-05-27 01:16:22 theanets.trainer:168 RmsProp 404 loss=306.053802 err=8.185966
I 2015-05-27 01:16:32 theanets.trainer:168 RmsProp 405 loss=306.216125 err=8.740565
I 2015-05-27 01:16:43 theanets.trainer:168 RmsProp 406 loss=304.549866 err=7.465157
I 2015-05-27 01:16:54 theanets.trainer:168 RmsProp 407 loss=305.617493 err=8.917577
I 2015-05-27 01:17:04 theanets.trainer:168 RmsProp 408 loss=304.404602 err=8.091661
I 2015-05-27 01:17:14 theanets.trainer:168 RmsProp 409 loss=303.759338 err=7.822996
I 2015-05-27 01:17:25 theanets.trainer:168 RmsProp 410 loss=304.336884 err=8.788198
I 2015-05-27 01:17:25 theanets.trainer:168 validation 41 loss=9276.537109 err=8981.200195
I 2015-05-27 01:17:36 theanets.trainer:168 RmsProp 411 loss=303.176422 err=8.018367
I 2015-05-27 01:17:47 theanets.trainer:168 RmsProp 412 loss=303.091064 err=8.319759
I 2015-05-27 01:17:58 theanets.trainer:168 RmsProp 413 loss=302.759369 err=8.362096
I 2015-05-27 01:18:09 theanets.trainer:168 RmsProp 414 loss=302.831116 err=8.810347
I 2015-05-27 01:18:19 theanets.trainer:168 RmsProp 415 loss=301.858459 err=8.211560
I 2015-05-27 01:18:30 theanets.trainer:168 RmsProp 416 loss=301.023682 err=7.746161
I 2015-05-27 01:18:41 theanets.trainer:168 RmsProp 417 loss=301.219910 err=8.313526
I 2015-05-27 01:18:52 theanets.trainer:168 RmsProp 418 loss=300.830750 err=8.296228
I 2015-05-27 01:19:03 theanets.trainer:168 RmsProp 419 loss=300.228149 err=8.072738
I 2015-05-27 01:19:14 theanets.trainer:168 RmsProp 420 loss=299.775757 err=7.991748
I 2015-05-27 01:19:14 theanets.trainer:168 validation 42 loss=9244.642578 err=8953.063477
I 2015-05-27 01:19:25 theanets.trainer:168 RmsProp 421 loss=299.615692 err=8.208796
I 2015-05-27 01:19:36 theanets.trainer:168 RmsProp 422 loss=299.603180 err=8.571766
I 2015-05-27 01:19:47 theanets.trainer:168 RmsProp 423 loss=298.674805 err=8.010152
I 2015-05-27 01:19:58 theanets.trainer:168 RmsProp 424 loss=298.569153 err=8.271561
I 2015-05-27 01:20:09 theanets.trainer:168 RmsProp 425 loss=297.958344 err=8.027485
I 2015-05-27 01:20:20 theanets.trainer:168 RmsProp 426 loss=297.594025 err=8.029428
I 2015-05-27 01:20:31 theanets.trainer:168 RmsProp 427 loss=297.563995 err=8.364829
I 2015-05-27 01:20:42 theanets.trainer:168 RmsProp 428 loss=296.686371 err=7.848015
I 2015-05-27 01:20:52 theanets.trainer:168 RmsProp 429 loss=295.668671 err=7.199419
I 2015-05-27 01:21:03 theanets.trainer:168 RmsProp 430 loss=297.050171 err=8.939727
I 2015-05-27 01:21:03 theanets.trainer:168 validation 43 loss=9251.022461 err=8963.120117
I 2015-05-27 01:21:13 theanets.trainer:168 RmsProp 431 loss=295.613617 err=7.872069
I 2015-05-27 01:21:24 theanets.trainer:168 RmsProp 432 loss=295.142456 err=7.760102
I 2015-05-27 01:21:34 theanets.trainer:168 RmsProp 433 loss=294.499207 err=7.485487
I 2015-05-27 01:21:45 theanets.trainer:168 RmsProp 434 loss=294.573151 err=7.918023
I 2015-05-27 01:21:56 theanets.trainer:168 RmsProp 435 loss=295.123352 err=8.822432
I 2015-05-27 01:22:07 theanets.trainer:168 RmsProp 436 loss=293.620789 err=7.673778
I 2015-05-27 01:22:18 theanets.trainer:168 RmsProp 437 loss=293.221588 err=7.631626
I 2015-05-27 01:22:28 theanets.trainer:168 RmsProp 438 loss=293.018860 err=7.788396
I 2015-05-27 01:22:39 theanets.trainer:168 RmsProp 439 loss=292.326935 err=7.449868
I 2015-05-27 01:22:50 theanets.trainer:168 RmsProp 440 loss=292.666931 err=8.142721
I 2015-05-27 01:22:51 theanets.trainer:168 validation 44 loss=9213.324219 err=8928.993164 *
I 2015-05-27 01:23:01 theanets.trainer:168 RmsProp 441 loss=292.153778 err=7.984580
I 2015-05-27 01:23:12 theanets.trainer:168 RmsProp 442 loss=292.143860 err=8.323272
I 2015-05-27 01:23:23 theanets.trainer:168 RmsProp 443 loss=291.051086 err=7.574988
I 2015-05-27 01:23:34 theanets.trainer:168 RmsProp 444 loss=290.827789 err=7.697083
I 2015-05-27 01:23:45 theanets.trainer:168 RmsProp 445 loss=290.497253 err=7.717897
I 2015-05-27 01:23:55 theanets.trainer:168 RmsProp 446 loss=289.914001 err=7.481046
I 2015-05-27 01:24:06 theanets.trainer:168 RmsProp 447 loss=290.304749 err=8.220444
I 2015-05-27 01:24:17 theanets.trainer:168 RmsProp 448 loss=289.413879 err=7.674125
I 2015-05-27 01:24:28 theanets.trainer:168 RmsProp 449 loss=289.049225 err=7.652813
I 2015-05-27 01:24:39 theanets.trainer:168 RmsProp 450 loss=288.931427 err=7.878348
I 2015-05-27 01:24:39 theanets.trainer:168 validation 45 loss=9322.790039 err=9041.923828
I 2015-05-27 01:24:50 theanets.trainer:168 RmsProp 451 loss=288.337921 err=7.630404
I 2015-05-27 01:25:01 theanets.trainer:168 RmsProp 452 loss=288.533630 err=8.166098
I 2015-05-27 01:25:11 theanets.trainer:168 RmsProp 453 loss=287.550476 err=7.524973
I 2015-05-27 01:25:22 theanets.trainer:168 RmsProp 454 loss=287.734833 err=8.049133
I 2015-05-27 01:25:33 theanets.trainer:168 RmsProp 455 loss=287.330017 err=7.976028
I 2015-05-27 01:25:43 theanets.trainer:168 RmsProp 456 loss=286.712006 err=7.688879
I 2015-05-27 01:25:54 theanets.trainer:168 RmsProp 457 loss=286.432556 err=7.739305
I 2015-05-27 01:26:05 theanets.trainer:168 RmsProp 458 loss=285.315430 err=6.957803
I 2015-05-27 01:26:15 theanets.trainer:168 RmsProp 459 loss=286.035828 err=8.013042
I 2015-05-27 01:26:26 theanets.trainer:168 RmsProp 460 loss=286.219543 err=8.525682
I 2015-05-27 01:26:26 theanets.trainer:168 validation 46 loss=9207.369141 err=8929.858398 *
I 2015-05-27 01:26:37 theanets.trainer:168 RmsProp 461 loss=284.706390 err=7.342831
I 2015-05-27 01:26:47 theanets.trainer:168 RmsProp 462 loss=284.896576 err=7.860991
I 2015-05-27 01:26:58 theanets.trainer:168 RmsProp 463 loss=284.016144 err=7.308455
I 2015-05-27 01:27:08 theanets.trainer:168 RmsProp 464 loss=283.967010 err=7.584452
I 2015-05-27 01:27:18 theanets.trainer:168 RmsProp 465 loss=283.793640 err=7.737637
I 2015-05-27 01:27:29 theanets.trainer:168 RmsProp 466 loss=283.888306 err=8.155836
I 2015-05-27 01:27:39 theanets.trainer:168 RmsProp 467 loss=282.963745 err=7.551834
I 2015-05-27 01:27:49 theanets.trainer:168 RmsProp 468 loss=283.102356 err=8.004573
I 2015-05-27 01:28:00 theanets.trainer:168 RmsProp 469 loss=282.377380 err=7.594012
I 2015-05-27 01:28:10 theanets.trainer:168 RmsProp 470 loss=281.781921 err=7.311647
I 2015-05-27 01:28:11 theanets.trainer:168 validation 47 loss=9292.899414 err=9018.611328
I 2015-05-27 01:28:21 theanets.trainer:168 RmsProp 471 loss=282.045227 err=7.891843
I 2015-05-27 01:28:31 theanets.trainer:168 RmsProp 472 loss=280.997864 err=7.160112
I 2015-05-27 01:28:42 theanets.trainer:168 RmsProp 473 loss=280.680176 err=7.159719
I 2015-05-27 01:28:52 theanets.trainer:168 RmsProp 474 loss=280.977722 err=7.784446
I 2015-05-27 01:29:03 theanets.trainer:168 RmsProp 475 loss=280.875305 err=8.001689
I 2015-05-27 01:29:13 theanets.trainer:168 RmsProp 476 loss=279.428711 err=6.875911
I 2015-05-27 01:29:24 theanets.trainer:168 RmsProp 477 loss=280.066711 err=7.830547
I 2015-05-27 01:29:34 theanets.trainer:168 RmsProp 478 loss=279.150391 err=7.231916
I 2015-05-27 01:29:44 theanets.trainer:168 RmsProp 479 loss=279.021667 err=7.418837
I 2015-05-27 01:29:55 theanets.trainer:168 RmsProp 480 loss=279.518524 err=8.227420
I 2015-05-27 01:29:56 theanets.trainer:168 validation 48 loss=9237.738281 err=8966.619141
I 2015-05-27 01:30:06 theanets.trainer:168 RmsProp 481 loss=277.978058 err=6.998263
I 2015-05-27 01:30:17 theanets.trainer:168 RmsProp 482 loss=278.246887 err=7.577136
I 2015-05-27 01:30:27 theanets.trainer:168 RmsProp 483 loss=277.662811 err=7.308878
I 2015-05-27 01:30:37 theanets.trainer:168 RmsProp 484 loss=277.634155 err=7.599105
I 2015-05-27 01:30:48 theanets.trainer:168 RmsProp 485 loss=276.884888 err=7.163080
I 2015-05-27 01:30:58 theanets.trainer:168 RmsProp 486 loss=277.261383 err=7.849367
I 2015-05-27 01:31:09 theanets.trainer:168 RmsProp 487 loss=276.454712 err=7.351858
I 2015-05-27 01:31:19 theanets.trainer:168 RmsProp 488 loss=275.656097 err=6.857442
I 2015-05-27 01:31:30 theanets.trainer:168 RmsProp 489 loss=276.229858 err=7.738904
I 2015-05-27 01:31:41 theanets.trainer:168 RmsProp 490 loss=275.554626 err=7.370678
I 2015-05-27 01:31:41 theanets.trainer:168 validation 49 loss=9179.358398 err=8911.337891 *
I 2015-05-27 01:31:52 theanets.trainer:168 RmsProp 491 loss=275.103821 err=7.221433
I 2015-05-27 01:32:02 theanets.trainer:168 RmsProp 492 loss=275.135468 err=7.556339
I 2015-05-27 01:32:13 theanets.trainer:168 RmsProp 493 loss=274.260315 err=6.984678
I 2015-05-27 01:32:23 theanets.trainer:168 RmsProp 494 loss=275.009583 err=8.036570
I 2015-05-27 01:32:34 theanets.trainer:168 RmsProp 495 loss=273.880096 err=7.207740
I 2015-05-27 01:32:44 theanets.trainer:168 RmsProp 496 loss=273.817719 err=7.448052
I 2015-05-27 01:32:55 theanets.trainer:168 RmsProp 497 loss=273.166077 err=7.095010
I 2015-05-27 01:33:05 theanets.trainer:168 RmsProp 498 loss=273.192566 err=7.412223
I 2015-05-27 01:33:15 theanets.trainer:168 RmsProp 499 loss=272.960083 err=7.472545
I 2015-05-27 01:33:26 theanets.trainer:168 RmsProp 500 loss=271.957947 err=6.768949
I 2015-05-27 01:33:27 theanets.trainer:168 validation 50 loss=9252.244141 err=8987.232422
I 2015-05-27 01:33:37 theanets.trainer:168 RmsProp 501 loss=272.810333 err=7.923861
I 2015-05-27 01:33:48 theanets.trainer:168 RmsProp 502 loss=272.261566 err=7.667165
I 2015-05-27 01:33:59 theanets.trainer:168 RmsProp 503 loss=271.456635 err=7.155774
I 2015-05-27 01:34:09 theanets.trainer:168 RmsProp 504 loss=271.246918 err=7.234284
I 2015-05-27 01:34:20 theanets.trainer:168 RmsProp 505 loss=270.368835 err=6.653132
I 2015-05-27 01:34:31 theanets.trainer:168 RmsProp 506 loss=271.502747 err=8.077691
I 2015-05-27 01:34:41 theanets.trainer:168 RmsProp 507 loss=270.117432 err=6.984259
I 2015-05-27 01:34:51 theanets.trainer:168 RmsProp 508 loss=269.932861 err=7.086146
I 2015-05-27 01:35:02 theanets.trainer:168 RmsProp 509 loss=269.738281 err=7.176565
I 2015-05-27 01:35:12 theanets.trainer:168 RmsProp 510 loss=269.676300 err=7.403654
I 2015-05-27 01:35:12 theanets.trainer:168 validation 51 loss=9152.708984 err=8890.588867 *
I 2015-05-27 01:35:23 theanets.trainer:168 RmsProp 511 loss=269.304871 err=7.321373
I 2015-05-27 01:35:33 theanets.trainer:168 RmsProp 512 loss=268.917969 err=7.222868
I 2015-05-27 01:35:43 theanets.trainer:168 RmsProp 513 loss=268.358337 err=6.948977
I 2015-05-27 01:35:54 theanets.trainer:168 RmsProp 514 loss=268.020752 err=6.899460
I 2015-05-27 01:36:04 theanets.trainer:168 RmsProp 515 loss=267.891815 err=7.059859
I 2015-05-27 01:36:15 theanets.trainer:168 RmsProp 516 loss=267.785461 err=7.239903
I 2015-05-27 01:36:25 theanets.trainer:168 RmsProp 517 loss=267.818481 err=7.558784
I 2015-05-27 01:36:36 theanets.trainer:168 RmsProp 518 loss=266.630707 err=6.657182
I 2015-05-27 01:36:47 theanets.trainer:168 RmsProp 519 loss=266.596710 err=6.907853
I 2015-05-27 01:36:58 theanets.trainer:168 RmsProp 520 loss=266.794525 err=7.388767
I 2015-05-27 01:36:58 theanets.trainer:168 validation 52 loss=9168.186523 err=8908.932617
I 2015-05-27 01:37:09 theanets.trainer:168 RmsProp 521 loss=266.260193 err=7.138052
I 2015-05-27 01:37:20 theanets.trainer:168 RmsProp 522 loss=265.767273 err=6.926852
I 2015-05-27 01:37:30 theanets.trainer:168 RmsProp 523 loss=265.757721 err=7.200052
I 2015-05-27 01:37:41 theanets.trainer:168 RmsProp 524 loss=265.211731 err=6.931560
I 2015-05-27 01:37:52 theanets.trainer:168 RmsProp 525 loss=265.347748 err=7.339901
I 2015-05-27 01:38:03 theanets.trainer:168 RmsProp 526 loss=264.376312 err=6.647971
I 2015-05-27 01:38:14 theanets.trainer:168 RmsProp 527 loss=264.839172 err=7.389041
I 2015-05-27 01:38:25 theanets.trainer:168 RmsProp 528 loss=263.988342 err=6.811257
I 2015-05-27 01:38:35 theanets.trainer:168 RmsProp 529 loss=263.982483 err=7.081943
I 2015-05-27 01:38:46 theanets.trainer:168 RmsProp 530 loss=264.042297 err=7.413445
I 2015-05-27 01:38:46 theanets.trainer:168 validation 53 loss=9199.088867 err=8942.614258
I 2015-05-27 01:38:57 theanets.trainer:168 RmsProp 531 loss=263.087036 err=6.733623
I 2015-05-27 01:39:08 theanets.trainer:168 RmsProp 532 loss=263.083893 err=7.004970
I 2015-05-27 01:39:18 theanets.trainer:168 RmsProp 533 loss=262.847961 err=7.042531
I 2015-05-27 01:39:28 theanets.trainer:168 RmsProp 534 loss=262.057312 err=6.524970
I 2015-05-27 01:39:39 theanets.trainer:168 RmsProp 535 loss=262.163147 err=6.898943
I 2015-05-27 01:39:49 theanets.trainer:168 RmsProp 536 loss=262.118225 err=7.125711
I 2015-05-27 01:40:00 theanets.trainer:168 RmsProp 537 loss=261.557220 err=6.836815
I 2015-05-27 01:40:11 theanets.trainer:168 RmsProp 538 loss=261.494507 err=7.043361
I 2015-05-27 01:40:22 theanets.trainer:168 RmsProp 539 loss=261.898132 err=7.709302
I 2015-05-27 01:40:33 theanets.trainer:168 RmsProp 540 loss=260.504150 err=6.580083
I 2015-05-27 01:40:34 theanets.trainer:168 validation 54 loss=9247.493164 err=8993.718750
I 2015-05-27 01:40:45 theanets.trainer:168 RmsProp 541 loss=260.657867 err=6.999190
I 2015-05-27 01:40:55 theanets.trainer:168 RmsProp 542 loss=260.689636 err=7.295901
I 2015-05-27 01:41:06 theanets.trainer:168 RmsProp 543 loss=259.433624 err=6.311044
I 2015-05-27 01:41:16 theanets.trainer:168 RmsProp 544 loss=260.106934 err=7.244913
I 2015-05-27 01:41:27 theanets.trainer:168 RmsProp 545 loss=259.773499 err=7.178728
I 2015-05-27 01:41:37 theanets.trainer:168 RmsProp 546 loss=259.498016 err=7.161763
I 2015-05-27 01:41:47 theanets.trainer:168 RmsProp 547 loss=258.919373 err=6.845790
I 2015-05-27 01:41:58 theanets.trainer:168 RmsProp 548 loss=258.579742 err=6.771338
I 2015-05-27 01:42:08 theanets.trainer:168 RmsProp 549 loss=258.340302 err=6.789407
I 2015-05-27 01:42:18 theanets.trainer:168 RmsProp 550 loss=258.570221 err=7.280357
I 2015-05-27 01:42:19 theanets.trainer:168 validation 55 loss=9190.539062 err=8939.396484
I 2015-05-27 01:42:28 theanets.trainer:168 RmsProp 551 loss=257.252045 err=6.226794
I 2015-05-27 01:42:38 theanets.trainer:168 RmsProp 552 loss=258.102844 err=7.342598
I 2015-05-27 01:42:48 theanets.trainer:168 RmsProp 553 loss=257.060669 err=6.558408
I 2015-05-27 01:42:58 theanets.trainer:168 RmsProp 554 loss=257.056244 err=6.812749
I 2015-05-27 01:43:08 theanets.trainer:168 RmsProp 555 loss=256.977570 err=6.997131
I 2015-05-27 01:43:18 theanets.trainer:168 RmsProp 556 loss=256.277527 err=6.555222
I 2015-05-27 01:43:28 theanets.trainer:168 RmsProp 557 loss=256.421326 err=6.957614
I 2015-05-27 01:43:39 theanets.trainer:168 RmsProp 558 loss=255.845261 err=6.636876
I 2015-05-27 01:43:49 theanets.trainer:168 RmsProp 559 loss=255.648071 err=6.697101
I 2015-05-27 01:43:58 theanets.trainer:168 RmsProp 560 loss=255.407303 err=6.709531
I 2015-05-27 01:43:59 theanets.trainer:168 validation 56 loss=9122.376953 err=8873.817383 *
I 2015-05-27 01:44:09 theanets.trainer:168 RmsProp 561 loss=255.582275 err=7.139586
I 2015-05-27 01:44:19 theanets.trainer:168 RmsProp 562 loss=254.310791 err=6.127641
I 2015-05-27 01:44:29 theanets.trainer:168 RmsProp 563 loss=254.848389 err=6.924051
I 2015-05-27 01:44:39 theanets.trainer:168 RmsProp 564 loss=254.855667 err=7.186765
I 2015-05-27 01:44:50 theanets.trainer:168 RmsProp 565 loss=254.123611 err=6.702914
I 2015-05-27 01:45:00 theanets.trainer:168 RmsProp 566 loss=253.847702 err=6.678763
I 2015-05-27 01:45:10 theanets.trainer:168 RmsProp 567 loss=253.582520 err=6.664069
I 2015-05-27 01:45:20 theanets.trainer:168 RmsProp 568 loss=253.535446 err=6.870905
I 2015-05-27 01:45:30 theanets.trainer:168 RmsProp 569 loss=253.715256 err=7.301557
I 2015-05-27 01:45:41 theanets.trainer:168 RmsProp 570 loss=252.871384 err=6.702358
I 2015-05-27 01:45:42 theanets.trainer:168 validation 57 loss=9146.659180 err=8900.624023
I 2015-05-27 01:45:52 theanets.trainer:168 RmsProp 571 loss=252.630295 err=6.704999
I 2015-05-27 01:46:02 theanets.trainer:168 RmsProp 572 loss=252.459686 err=6.779638
I 2015-05-27 01:46:12 theanets.trainer:168 RmsProp 573 loss=252.092499 err=6.657300
I 2015-05-27 01:46:23 theanets.trainer:168 RmsProp 574 loss=251.659500 err=6.469086
I 2015-05-27 01:46:33 theanets.trainer:168 RmsProp 575 loss=251.479706 err=6.538358
I 2015-05-27 01:46:43 theanets.trainer:168 RmsProp 576 loss=251.395721 err=6.700691
I 2015-05-27 01:46:53 theanets.trainer:168 RmsProp 577 loss=251.093506 err=6.645955
I 2015-05-27 01:47:02 theanets.trainer:168 RmsProp 578 loss=251.093704 err=6.894660
I 2015-05-27 01:47:13 theanets.trainer:168 RmsProp 579 loss=250.362915 err=6.414514
I 2015-05-27 01:47:23 theanets.trainer:168 RmsProp 580 loss=250.506989 err=6.805903
I 2015-05-27 01:47:23 theanets.trainer:168 validation 58 loss=9173.453125 err=8929.888672
I 2015-05-27 01:47:34 theanets.trainer:168 RmsProp 581 loss=250.157471 err=6.697555
I 2015-05-27 01:47:44 theanets.trainer:168 RmsProp 582 loss=249.745041 err=6.526014
I 2015-05-27 01:47:54 theanets.trainer:168 RmsProp 583 loss=249.432465 err=6.453677
I 2015-05-27 01:48:04 theanets.trainer:168 RmsProp 584 loss=249.474289 err=6.735999
I 2015-05-27 01:48:14 theanets.trainer:168 RmsProp 585 loss=249.144653 err=6.649631
I 2015-05-27 01:48:24 theanets.trainer:168 RmsProp 586 loss=248.372589 err=6.119437
I 2015-05-27 01:48:35 theanets.trainer:168 RmsProp 587 loss=249.050171 err=7.038234
I 2015-05-27 01:48:45 theanets.trainer:168 RmsProp 588 loss=248.509720 err=6.733958
I 2015-05-27 01:48:55 theanets.trainer:168 RmsProp 589 loss=248.146484 err=6.606183
I 2015-05-27 01:49:05 theanets.trainer:168 RmsProp 590 loss=247.468582 err=6.165185
I 2015-05-27 01:49:06 theanets.trainer:168 validation 59 loss=9211.970703 err=8970.799805
I 2015-05-27 01:49:16 theanets.trainer:168 RmsProp 591 loss=247.969147 err=6.906942
I 2015-05-27 01:49:26 theanets.trainer:168 RmsProp 592 loss=247.296677 err=6.475057
I 2015-05-27 01:49:36 theanets.trainer:168 RmsProp 593 loss=247.053864 err=6.472791
I 2015-05-27 01:49:46 theanets.trainer:168 RmsProp 594 loss=246.913361 err=6.573757
I 2015-05-27 01:49:55 theanets.trainer:168 RmsProp 595 loss=246.613373 err=6.512288
I 2015-05-27 01:50:05 theanets.trainer:168 RmsProp 596 loss=246.506012 err=6.634609
I 2015-05-27 01:50:15 theanets.trainer:168 RmsProp 597 loss=245.861420 err=6.224569
I 2015-05-27 01:50:25 theanets.trainer:168 RmsProp 598 loss=246.198639 err=6.796627
I 2015-05-27 01:50:35 theanets.trainer:168 RmsProp 599 loss=245.645477 err=6.482345
I 2015-05-27 01:50:45 theanets.trainer:168 RmsProp 600 loss=245.304367 err=6.377832
I 2015-05-27 01:50:45 theanets.trainer:168 validation 60 loss=9206.166992 err=8967.372070
I 2015-05-27 01:50:55 theanets.trainer:168 RmsProp 601 loss=245.563599 err=6.873218
I 2015-05-27 01:51:05 theanets.trainer:168 RmsProp 602 loss=245.176102 err=6.714532
I 2015-05-27 01:51:15 theanets.trainer:168 RmsProp 603 loss=244.853958 err=6.618240
I 2015-05-27 01:51:26 theanets.trainer:168 RmsProp 604 loss=244.601486 err=6.593601
I 2015-05-27 01:51:36 theanets.trainer:168 RmsProp 605 loss=244.151825 err=6.372757
I 2015-05-27 01:51:46 theanets.trainer:168 RmsProp 606 loss=243.904510 err=6.357596
I 2015-05-27 01:51:56 theanets.trainer:168 RmsProp 607 loss=243.934296 err=6.614705
I 2015-05-27 01:52:07 theanets.trainer:168 RmsProp 608 loss=243.620316 err=6.519654
I 2015-05-27 01:52:17 theanets.trainer:168 RmsProp 609 loss=243.148117 err=6.274188
I 2015-05-27 01:52:27 theanets.trainer:168 RmsProp 610 loss=243.007034 err=6.367004
I 2015-05-27 01:52:28 theanets.trainer:168 validation 61 loss=9111.103516 err=8874.604492 *
I 2015-05-27 01:52:38 theanets.trainer:168 RmsProp 611 loss=242.932465 err=6.526029
I 2015-05-27 01:52:48 theanets.trainer:168 RmsProp 612 loss=242.560089 err=6.379434
I 2015-05-27 01:52:58 theanets.trainer:168 RmsProp 613 loss=242.252487 err=6.296982
I 2015-05-27 01:53:08 theanets.trainer:168 RmsProp 614 loss=242.580719 err=6.848190
I 2015-05-27 01:53:17 theanets.trainer:168 RmsProp 615 loss=242.415924 err=6.903586
I 2015-05-27 01:53:27 theanets.trainer:168 RmsProp 616 loss=241.347092 err=6.058115
I 2015-05-27 01:53:37 theanets.trainer:168 RmsProp 617 loss=241.659348 err=6.596682
I 2015-05-27 01:53:47 theanets.trainer:168 RmsProp 618 loss=241.150421 err=6.311498
I 2015-05-27 01:53:57 theanets.trainer:168 RmsProp 619 loss=240.823090 err=6.201937
I 2015-05-27 01:54:08 theanets.trainer:168 RmsProp 620 loss=241.204147 err=6.800710
I 2015-05-27 01:54:08 theanets.trainer:168 validation 62 loss=9130.854492 err=8896.574219
I 2015-05-27 01:54:18 theanets.trainer:168 RmsProp 621 loss=240.388702 err=6.207253
I 2015-05-27 01:54:28 theanets.trainer:168 RmsProp 622 loss=240.272659 err=6.317164
I 2015-05-27 01:54:38 theanets.trainer:168 RmsProp 623 loss=240.240387 err=6.509195
I 2015-05-27 01:54:48 theanets.trainer:168 RmsProp 624 loss=239.876190 err=6.368335
I 2015-05-27 01:54:58 theanets.trainer:168 RmsProp 625 loss=239.929733 err=6.646501
I 2015-05-27 01:55:08 theanets.trainer:168 RmsProp 626 loss=239.346359 err=6.277450
I 2015-05-27 01:55:17 theanets.trainer:168 RmsProp 627 loss=239.132858 err=6.276630
I 2015-05-27 01:55:28 theanets.trainer:168 RmsProp 628 loss=238.943817 err=6.303771
I 2015-05-27 01:55:38 theanets.trainer:168 RmsProp 629 loss=239.417114 err=6.997419
I 2015-05-27 01:55:48 theanets.trainer:168 RmsProp 630 loss=238.746262 err=6.541158
I 2015-05-27 01:55:49 theanets.trainer:168 validation 63 loss=9129.404297 err=8897.315430
I 2015-05-27 01:55:58 theanets.trainer:168 RmsProp 631 loss=238.098343 err=6.105900
I 2015-05-27 01:56:08 theanets.trainer:168 RmsProp 632 loss=238.089966 err=6.317313
I 2015-05-27 01:56:18 theanets.trainer:168 RmsProp 633 loss=237.764374 err=6.211334
I 2015-05-27 01:56:28 theanets.trainer:168 RmsProp 634 loss=237.560547 err=6.225459
I 2015-05-27 01:56:39 theanets.trainer:168 RmsProp 635 loss=237.617142 err=6.501704
I 2015-05-27 01:56:49 theanets.trainer:168 RmsProp 636 loss=237.211700 err=6.314689
I 2015-05-27 01:56:59 theanets.trainer:168 RmsProp 637 loss=236.852570 err=6.163733
I 2015-05-27 01:57:09 theanets.trainer:168 RmsProp 638 loss=237.029007 err=6.554541
I 2015-05-27 01:57:19 theanets.trainer:168 RmsProp 639 loss=237.005585 err=6.744303
I 2015-05-27 01:57:30 theanets.trainer:168 RmsProp 640 loss=236.087936 err=6.041360
I 2015-05-27 01:57:30 theanets.trainer:168 validation 64 loss=9060.794922 err=8830.854492 *
I 2015-05-27 01:57:41 theanets.trainer:168 RmsProp 641 loss=236.618973 err=6.776222
I 2015-05-27 01:57:51 theanets.trainer:168 RmsProp 642 loss=235.533035 err=5.905600
I 2015-05-27 01:58:01 theanets.trainer:168 RmsProp 643 loss=235.946381 err=6.527646
I 2015-05-27 01:58:11 theanets.trainer:168 RmsProp 644 loss=235.232742 err=6.032406
I 2015-05-27 01:58:21 theanets.trainer:168 RmsProp 645 loss=235.593475 err=6.604784
I 2015-05-27 01:58:31 theanets.trainer:168 RmsProp 646 loss=235.055008 err=6.277792
I 2015-05-27 01:58:42 theanets.trainer:168 RmsProp 647 loss=234.706345 err=6.137940
I 2015-05-27 01:58:52 theanets.trainer:168 RmsProp 648 loss=234.331100 err=5.977960
I 2015-05-27 01:59:03 theanets.trainer:168 RmsProp 649 loss=234.562653 err=6.418952
I 2015-05-27 01:59:13 theanets.trainer:168 RmsProp 650 loss=234.504272 err=6.567257
I 2015-05-27 01:59:14 theanets.trainer:168 validation 65 loss=9102.425781 err=8874.605469
I 2015-05-27 01:59:24 theanets.trainer:168 RmsProp 651 loss=233.674408 err=5.944918
I 2015-05-27 01:59:34 theanets.trainer:168 RmsProp 652 loss=234.074554 err=6.549182
I 2015-05-27 01:59:44 theanets.trainer:168 RmsProp 653 loss=233.454071 err=6.133218
I 2015-05-27 01:59:54 theanets.trainer:168 RmsProp 654 loss=234.088043 err=6.967665
I 2015-05-27 02:00:04 theanets.trainer:168 RmsProp 655 loss=232.620361 err=5.708385
I 2015-05-27 02:00:14 theanets.trainer:168 RmsProp 656 loss=233.295364 err=6.583005
I 2015-05-27 02:00:24 theanets.trainer:168 RmsProp 657 loss=232.900192 err=6.389852
I 2015-05-27 02:00:35 theanets.trainer:168 RmsProp 658 loss=232.461700 err=6.153396
I 2015-05-27 02:00:45 theanets.trainer:168 RmsProp 659 loss=232.284149 err=6.177569
I 2015-05-27 02:00:56 theanets.trainer:168 RmsProp 660 loss=232.579636 err=6.674375
I 2015-05-27 02:00:56 theanets.trainer:168 validation 66 loss=9061.364258 err=8835.563477
I 2015-05-27 02:01:06 theanets.trainer:168 RmsProp 661 loss=231.898117 err=6.197412
I 2015-05-27 02:01:17 theanets.trainer:168 RmsProp 662 loss=231.848724 err=6.346970
I 2015-05-27 02:01:27 theanets.trainer:168 RmsProp 663 loss=231.410324 err=6.105889
I 2015-05-27 02:01:37 theanets.trainer:168 RmsProp 664 loss=231.128540 err=6.026495
I 2015-05-27 02:01:47 theanets.trainer:168 RmsProp 665 loss=231.250977 err=6.349871
I 2015-05-27 02:01:57 theanets.trainer:168 RmsProp 666 loss=230.703857 err=6.005317
I 2015-05-27 02:02:06 theanets.trainer:168 RmsProp 667 loss=231.075363 err=6.575456
I 2015-05-27 02:02:17 theanets.trainer:168 RmsProp 668 loss=230.279694 err=5.977003
I 2015-05-27 02:02:27 theanets.trainer:168 RmsProp 669 loss=230.564163 err=6.462364
I 2015-05-27 02:02:37 theanets.trainer:168 RmsProp 670 loss=229.715622 err=5.814683
I 2015-05-27 02:02:38 theanets.trainer:168 validation 67 loss=9193.990234 err=8970.190430
I 2015-05-27 02:02:48 theanets.trainer:168 RmsProp 671 loss=230.251907 err=6.550784
I 2015-05-27 02:02:59 theanets.trainer:168 RmsProp 672 loss=230.093918 err=6.589385
I 2015-05-27 02:03:09 theanets.trainer:168 RmsProp 673 loss=229.353928 err=6.046568
I 2015-05-27 02:03:19 theanets.trainer:168 RmsProp 674 loss=228.878708 err=5.770908
I 2015-05-27 02:03:29 theanets.trainer:168 RmsProp 675 loss=229.378662 err=6.461466
I 2015-05-27 02:03:40 theanets.trainer:168 RmsProp 676 loss=228.711700 err=5.993556
I 2015-05-27 02:03:50 theanets.trainer:168 RmsProp 677 loss=228.516190 err=5.998931
I 2015-05-27 02:04:00 theanets.trainer:168 RmsProp 678 loss=228.562469 err=6.247490
I 2015-05-27 02:04:10 theanets.trainer:168 RmsProp 679 loss=228.183640 err=6.067172
I 2015-05-27 02:04:20 theanets.trainer:168 RmsProp 680 loss=228.154343 err=6.237489
I 2015-05-27 02:04:21 theanets.trainer:168 validation 68 loss=9059.827148 err=8838.026367 *
I 2015-05-27 02:04:31 theanets.trainer:168 RmsProp 681 loss=227.869659 err=6.147911
I 2015-05-27 02:04:41 theanets.trainer:168 RmsProp 682 loss=227.617523 err=6.089614
I 2015-05-27 02:04:52 theanets.trainer:168 RmsProp 683 loss=227.492523 err=6.163130
I 2015-05-27 02:05:02 theanets.trainer:168 RmsProp 684 loss=227.279083 err=6.143373
I 2015-05-27 02:05:13 theanets.trainer:168 RmsProp 685 loss=227.043304 err=6.103580
I 2015-05-27 02:05:23 theanets.trainer:168 RmsProp 686 loss=226.549286 err=5.804430
I 2015-05-27 02:05:34 theanets.trainer:168 RmsProp 687 loss=226.926270 err=6.376544
I 2015-05-27 02:05:44 theanets.trainer:168 RmsProp 688 loss=226.422287 err=6.065399
I 2015-05-27 02:05:55 theanets.trainer:168 RmsProp 689 loss=226.244461 err=6.083848
I 2015-05-27 02:06:05 theanets.trainer:168 RmsProp 690 loss=225.892944 err=5.926647
I 2015-05-27 02:06:06 theanets.trainer:168 validation 69 loss=9035.497070 err=8815.628906 *
I 2015-05-27 02:06:16 theanets.trainer:168 RmsProp 691 loss=225.966965 err=6.188472
I 2015-05-27 02:06:26 theanets.trainer:168 RmsProp 692 loss=226.212112 err=6.618369
I 2015-05-27 02:06:36 theanets.trainer:168 RmsProp 693 loss=225.237869 err=5.836328
I 2015-05-27 02:06:47 theanets.trainer:168 RmsProp 694 loss=225.611420 err=6.397584
I 2015-05-27 02:06:57 theanets.trainer:168 RmsProp 695 loss=224.891068 err=5.869095
I 2015-05-27 02:07:07 theanets.trainer:168 RmsProp 696 loss=224.910370 err=6.079251
I 2015-05-27 02:07:18 theanets.trainer:168 RmsProp 697 loss=224.712601 err=6.074945
I 2015-05-27 02:07:28 theanets.trainer:168 RmsProp 698 loss=224.548798 err=6.101147
I 2015-05-27 02:07:38 theanets.trainer:168 RmsProp 699 loss=224.238205 err=5.977726
I 2015-05-27 02:07:49 theanets.trainer:168 RmsProp 700 loss=223.860382 err=5.787078
I 2015-05-27 02:07:49 theanets.trainer:168 validation 70 loss=9121.559570 err=8903.598633
I 2015-05-27 02:07:59 theanets.trainer:168 RmsProp 701 loss=224.176605 err=6.295659
I 2015-05-27 02:08:10 theanets.trainer:168 RmsProp 702 loss=223.635223 err=5.940220
I 2015-05-27 02:08:20 theanets.trainer:168 RmsProp 703 loss=223.737015 err=6.225726
I 2015-05-27 02:08:30 theanets.trainer:168 RmsProp 704 loss=223.773148 err=6.448377
I 2015-05-27 02:08:40 theanets.trainer:168 RmsProp 705 loss=222.818451 err=5.681442
I 2015-05-27 02:08:51 theanets.trainer:168 RmsProp 706 loss=223.231613 err=6.278303
I 2015-05-27 02:09:01 theanets.trainer:168 RmsProp 707 loss=222.712677 err=5.944381
I 2015-05-27 02:09:12 theanets.trainer:168 RmsProp 708 loss=222.451263 err=5.874436
I 2015-05-27 02:09:22 theanets.trainer:168 RmsProp 709 loss=222.054764 err=5.666852
I 2015-05-27 02:09:32 theanets.trainer:168 RmsProp 710 loss=222.602203 err=6.398588
I 2015-05-27 02:09:33 theanets.trainer:168 validation 71 loss=9116.628906 err=8900.536133
I 2015-05-27 02:09:43 theanets.trainer:168 RmsProp 711 loss=222.030319 err=6.019364
I 2015-05-27 02:09:53 theanets.trainer:168 RmsProp 712 loss=221.953247 err=6.120552
I 2015-05-27 02:10:03 theanets.trainer:168 RmsProp 713 loss=221.773346 err=6.119021
I 2015-05-27 02:10:13 theanets.trainer:168 RmsProp 714 loss=220.921051 err=5.455013
I 2015-05-27 02:10:23 theanets.trainer:168 RmsProp 715 loss=221.295776 err=6.014620
I 2015-05-27 02:10:33 theanets.trainer:168 RmsProp 716 loss=221.290436 err=6.197265
I 2015-05-27 02:10:43 theanets.trainer:168 RmsProp 717 loss=221.027542 err=6.119458
I 2015-05-27 02:10:53 theanets.trainer:168 RmsProp 718 loss=220.565460 err=5.838063
I 2015-05-27 02:11:04 theanets.trainer:168 RmsProp 719 loss=220.716827 err=6.163335
I 2015-05-27 02:11:14 theanets.trainer:168 RmsProp 720 loss=220.216156 err=5.851867
I 2015-05-27 02:11:14 theanets.trainer:168 validation 72 loss=9023.434570 err=8809.166992 *
I 2015-05-27 02:11:25 theanets.trainer:168 RmsProp 721 loss=220.809113 err=6.622608
I 2015-05-27 02:11:35 theanets.trainer:168 RmsProp 722 loss=219.820923 err=5.815958
I 2015-05-27 02:11:45 theanets.trainer:168 RmsProp 723 loss=219.731033 err=5.905234
I 2015-05-27 02:11:55 theanets.trainer:168 RmsProp 724 loss=219.764374 err=6.117780
I 2015-05-27 02:12:06 theanets.trainer:168 RmsProp 725 loss=219.236053 err=5.765800
I 2015-05-27 02:12:16 theanets.trainer:168 RmsProp 726 loss=218.925140 err=5.629936
I 2015-05-27 02:12:26 theanets.trainer:168 RmsProp 727 loss=219.248444 err=6.131937
I 2015-05-27 02:12:36 theanets.trainer:168 RmsProp 728 loss=218.917725 err=5.975039
I 2015-05-27 02:12:47 theanets.trainer:168 RmsProp 729 loss=218.791702 err=6.029061
I 2015-05-27 02:12:57 theanets.trainer:168 RmsProp 730 loss=218.704346 err=6.118458
I 2015-05-27 02:12:58 theanets.trainer:168 validation 73 loss=9163.452148 err=8950.959961
I 2015-05-27 02:13:08 theanets.trainer:168 RmsProp 731 loss=218.695709 err=6.284133
I 2015-05-27 02:13:19 theanets.trainer:168 RmsProp 732 loss=217.948563 err=5.715607
I 2015-05-27 02:13:29 theanets.trainer:168 RmsProp 733 loss=217.806564 err=5.748176
I 2015-05-27 02:13:39 theanets.trainer:168 RmsProp 734 loss=218.466888 err=6.582841
I 2015-05-27 02:13:50 theanets.trainer:168 RmsProp 735 loss=217.241013 err=5.533959
I 2015-05-27 02:14:00 theanets.trainer:168 RmsProp 736 loss=217.339874 err=5.804436
I 2015-05-27 02:14:10 theanets.trainer:168 RmsProp 737 loss=217.374802 err=6.009707
I 2015-05-27 02:14:19 theanets.trainer:168 RmsProp 738 loss=217.064209 err=5.872603
I 2015-05-27 02:14:29 theanets.trainer:168 RmsProp 739 loss=216.811035 err=5.793490
I 2015-05-27 02:14:40 theanets.trainer:168 RmsProp 740 loss=217.023438 err=6.182260
I 2015-05-27 02:14:40 theanets.trainer:168 validation 74 loss=9005.911133 err=8795.158203 *
I 2015-05-27 02:14:50 theanets.trainer:168 RmsProp 741 loss=217.065094 err=6.395294
I 2015-05-27 02:15:01 theanets.trainer:168 RmsProp 742 loss=216.228119 err=5.732361
I 2015-05-27 02:15:11 theanets.trainer:168 RmsProp 743 loss=216.186600 err=5.860398
I 2015-05-27 02:15:21 theanets.trainer:168 RmsProp 744 loss=216.180130 err=6.025875
I 2015-05-27 02:15:31 theanets.trainer:168 RmsProp 745 loss=215.859695 err=5.871557
I 2015-05-27 02:15:41 theanets.trainer:168 RmsProp 746 loss=215.718460 err=5.898630
I 2015-05-27 02:15:51 theanets.trainer:168 RmsProp 747 loss=215.453049 err=5.804895
I 2015-05-27 02:16:00 theanets.trainer:168 RmsProp 748 loss=214.971512 err=5.498222
I 2015-05-27 02:16:08 theanets.trainer:168 RmsProp 749 loss=215.626587 err=6.318404
I 2015-05-27 02:16:17 theanets.trainer:168 RmsProp 750 loss=214.889038 err=5.753881
I 2015-05-27 02:16:17 theanets.trainer:168 validation 75 loss=9158.212891 err=8949.166992
I 2015-05-27 02:16:25 theanets.trainer:168 RmsProp 751 loss=215.262238 err=6.294456
I 2015-05-27 02:16:33 theanets.trainer:168 RmsProp 752 loss=214.768036 err=5.967330
I 2015-05-27 02:16:41 theanets.trainer:168 RmsProp 753 loss=214.259598 err=5.627768
I 2015-05-27 02:16:49 theanets.trainer:168 RmsProp 754 loss=214.426483 err=5.957984
I 2015-05-27 02:16:57 theanets.trainer:168 RmsProp 755 loss=214.022995 err=5.721471
I 2015-05-27 02:17:05 theanets.trainer:168 RmsProp 756 loss=213.887009 err=5.756730
I 2015-05-27 02:17:13 theanets.trainer:168 RmsProp 757 loss=214.078278 err=6.118344
I 2015-05-27 02:17:21 theanets.trainer:168 RmsProp 758 loss=213.415253 err=5.624378
I 2015-05-27 02:17:30 theanets.trainer:168 RmsProp 759 loss=213.547516 err=5.928859
I 2015-05-27 02:17:38 theanets.trainer:168 RmsProp 760 loss=213.462280 err=6.007417
I 2015-05-27 02:17:38 theanets.trainer:168 validation 76 loss=9051.518555 err=8844.156250
I 2015-05-27 02:17:46 theanets.trainer:168 RmsProp 761 loss=212.741776 err=5.450844
I 2015-05-27 02:17:54 theanets.trainer:168 RmsProp 762 loss=213.329514 err=6.204704
I 2015-05-27 02:18:01 theanets.trainer:168 RmsProp 763 loss=212.497849 err=5.538357
I 2015-05-27 02:18:09 theanets.trainer:168 RmsProp 764 loss=212.767548 err=5.972196
I 2015-05-27 02:18:16 theanets.trainer:168 RmsProp 765 loss=212.131866 err=5.503057
I 2015-05-27 02:18:24 theanets.trainer:168 RmsProp 766 loss=212.279831 err=5.817786
I 2015-05-27 02:18:31 theanets.trainer:168 RmsProp 767 loss=212.324982 err=6.030536
I 2015-05-27 02:18:38 theanets.trainer:168 RmsProp 768 loss=211.785522 err=5.659291
I 2015-05-27 02:18:46 theanets.trainer:168 RmsProp 769 loss=211.590164 err=5.626630
I 2015-05-27 02:18:54 theanets.trainer:168 RmsProp 770 loss=211.608307 err=5.806919
I 2015-05-27 02:18:54 theanets.trainer:168 validation 77 loss=9019.000000 err=8813.291992
I 2015-05-27 02:19:01 theanets.trainer:168 RmsProp 771 loss=211.372971 err=5.737990
I 2015-05-27 02:19:08 theanets.trainer:168 RmsProp 772 loss=211.266434 err=5.795053
I 2015-05-27 02:19:16 theanets.trainer:168 RmsProp 773 loss=210.828400 err=5.522834
I 2015-05-27 02:19:24 theanets.trainer:168 RmsProp 774 loss=211.186569 err=6.047335
I 2015-05-27 02:19:31 theanets.trainer:168 RmsProp 775 loss=210.698151 err=5.723566
I 2015-05-27 02:19:40 theanets.trainer:168 RmsProp 776 loss=210.414154 err=5.600911
I 2015-05-27 02:19:47 theanets.trainer:168 RmsProp 777 loss=210.560135 err=5.909719
I 2015-05-27 02:19:54 theanets.trainer:168 RmsProp 778 loss=210.266693 err=5.779258
I 2015-05-27 02:20:03 theanets.trainer:168 RmsProp 779 loss=210.066040 err=5.737977
I 2015-05-27 02:20:10 theanets.trainer:168 RmsProp 780 loss=209.794510 err=5.628263
I 2015-05-27 02:20:11 theanets.trainer:168 validation 78 loss=8999.538086 err=8795.452148 *
I 2015-05-27 02:20:18 theanets.trainer:168 RmsProp 781 loss=209.483643 err=5.477645
I 2015-05-27 02:20:26 theanets.trainer:168 RmsProp 782 loss=209.474243 err=5.631957
I 2015-05-27 02:20:33 theanets.trainer:168 RmsProp 783 loss=209.481110 err=5.804584
I 2015-05-27 02:20:40 theanets.trainer:168 RmsProp 784 loss=209.222977 err=5.706745
I 2015-05-27 02:20:48 theanets.trainer:168 RmsProp 785 loss=209.081467 err=5.725253
I 2015-05-27 02:20:56 theanets.trainer:168 RmsProp 786 loss=209.425323 err=6.228802
I 2015-05-27 02:21:04 theanets.trainer:168 RmsProp 787 loss=208.922073 err=5.886675
I 2015-05-27 02:21:11 theanets.trainer:168 RmsProp 788 loss=208.518951 err=5.646633
I 2015-05-27 02:21:18 theanets.trainer:168 RmsProp 789 loss=208.357224 err=5.643369
I 2015-05-27 02:21:26 theanets.trainer:168 RmsProp 790 loss=208.462479 err=5.901517
I 2015-05-27 02:21:26 theanets.trainer:168 validation 79 loss=9087.970703 err=8885.502930
I 2015-05-27 02:21:34 theanets.trainer:168 RmsProp 791 loss=207.805450 err=5.402092
I 2015-05-27 02:21:41 theanets.trainer:168 RmsProp 792 loss=207.981659 err=5.734018
I 2015-05-27 02:21:48 theanets.trainer:168 RmsProp 793 loss=207.653076 err=5.565066
I 2015-05-27 02:21:56 theanets.trainer:168 RmsProp 794 loss=207.735672 err=5.801355
I 2015-05-27 02:22:04 theanets.trainer:168 RmsProp 795 loss=207.229523 err=5.453905
I 2015-05-27 02:22:11 theanets.trainer:168 RmsProp 796 loss=207.773956 err=6.154069
I 2015-05-27 02:22:19 theanets.trainer:168 RmsProp 797 loss=207.138718 err=5.678693
I 2015-05-27 02:22:26 theanets.trainer:168 RmsProp 798 loss=207.232269 err=5.920315
I 2015-05-27 02:22:34 theanets.trainer:168 RmsProp 799 loss=206.812714 err=5.655347
I 2015-05-27 02:22:41 theanets.trainer:168 RmsProp 800 loss=207.081696 err=6.077322
I 2015-05-27 02:22:41 theanets.trainer:168 validation 80 loss=9118.671875 err=8917.749023
I 2015-05-27 02:22:48 theanets.trainer:168 RmsProp 801 loss=206.312897 err=5.462320
I 2015-05-27 02:22:56 theanets.trainer:168 RmsProp 802 loss=206.670807 err=5.969611
I 2015-05-27 02:23:04 theanets.trainer:168 RmsProp 803 loss=206.319626 err=5.768538
I 2015-05-27 02:23:12 theanets.trainer:168 RmsProp 804 loss=205.786652 err=5.391484
I 2015-05-27 02:23:19 theanets.trainer:168 RmsProp 805 loss=206.019333 err=5.776582
I 2015-05-27 02:23:27 theanets.trainer:168 RmsProp 806 loss=206.239960 err=6.148462
I 2015-05-27 02:23:34 theanets.trainer:168 RmsProp 807 loss=205.523560 err=5.588527
I 2015-05-27 02:23:42 theanets.trainer:168 RmsProp 808 loss=205.346069 err=5.565108
I 2015-05-27 02:23:50 theanets.trainer:168 RmsProp 809 loss=205.266113 err=5.640536
I 2015-05-27 02:23:58 theanets.trainer:168 RmsProp 810 loss=205.238571 err=5.762819
I 2015-05-27 02:23:58 theanets.trainer:168 validation 81 loss=9036.987305 err=8837.592773
I 2015-05-27 02:24:05 theanets.trainer:168 RmsProp 811 loss=205.036057 err=5.713404
I 2015-05-27 02:24:13 theanets.trainer:168 RmsProp 812 loss=204.668213 err=5.494098
I 2015-05-27 02:24:21 theanets.trainer:168 RmsProp 813 loss=204.759369 err=5.734134
I 2015-05-27 02:24:28 theanets.trainer:168 RmsProp 814 loss=204.298431 err=5.428065
I 2015-05-27 02:24:35 theanets.trainer:168 RmsProp 815 loss=204.345978 err=5.628667
I 2015-05-27 02:24:43 theanets.trainer:168 RmsProp 816 loss=203.950653 err=5.384404
I 2015-05-27 02:24:50 theanets.trainer:168 RmsProp 817 loss=204.273193 err=5.854737
I 2015-05-27 02:24:58 theanets.trainer:168 RmsProp 818 loss=204.003326 err=5.734216
I 2015-05-27 02:25:06 theanets.trainer:168 RmsProp 819 loss=204.095276 err=5.972506
I 2015-05-27 02:25:13 theanets.trainer:168 RmsProp 820 loss=203.599442 err=5.629704
I 2015-05-27 02:25:13 theanets.trainer:168 validation 82 loss=9127.587891 err=8929.700195
I 2015-05-27 02:25:21 theanets.trainer:168 RmsProp 821 loss=203.694183 err=5.872894
I 2015-05-27 02:25:28 theanets.trainer:168 RmsProp 822 loss=203.132919 err=5.458343
I 2015-05-27 02:25:35 theanets.trainer:168 RmsProp 823 loss=203.288757 err=5.762817
I 2015-05-27 02:25:42 theanets.trainer:168 RmsProp 824 loss=202.564209 err=5.190109
I 2015-05-27 02:25:49 theanets.trainer:168 RmsProp 825 loss=203.084885 err=5.858090
I 2015-05-27 02:25:56 theanets.trainer:168 RmsProp 826 loss=202.560242 err=5.481353
I 2015-05-27 02:26:03 theanets.trainer:168 RmsProp 827 loss=202.254517 err=5.319383
I 2015-05-27 02:26:10 theanets.trainer:168 RmsProp 828 loss=202.467041 err=5.681233
I 2015-05-27 02:26:18 theanets.trainer:168 RmsProp 829 loss=202.081589 err=5.447276
I 2015-05-27 02:26:25 theanets.trainer:168 RmsProp 830 loss=202.216156 err=5.734962
I 2015-05-27 02:26:26 theanets.trainer:168 validation 83 loss=9042.177734 err=8845.781250
I 2015-05-27 02:26:26 theanets.trainer:252 patience elapsed!
I 2015-05-27 02:26:26 theanets.main:237 models_deep_post_code_sep/95129-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 02:26:26 theanets.graph:477 models_deep_post_code_sep/95129-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
