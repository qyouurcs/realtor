I 2015-05-26 00:41:21 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 00:41:21 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 00:41:21 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 00:41:21 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 00:41:21 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 00:41:21 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 00:41:21 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 00:41:21 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 00:41:21 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95111-models-sep_san_jose_realtor_200_100.conf-1024-0.01-0.001-0.001.pkl
I 2015-05-26 00:41:21 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 00:41:21 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 00:41:21 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 00:41:21 theanets.main:89 --batch_size = 1024
I 2015-05-26 00:41:21 theanets.main:89 --gradient_clip = 1
I 2015-05-26 00:41:21 theanets.main:89 --hidden_l1 = 0.01
I 2015-05-26 00:41:21 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 00:41:21 theanets.main:89 --train_batches = 30
I 2015-05-26 00:41:21 theanets.main:89 --valid_batches = 3
I 2015-05-26 00:41:21 theanets.main:89 --weight_l1 = 0.001
I 2015-05-26 00:41:21 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 00:41:21 theanets.trainer:134 compiling evaluation function
I 2015-05-26 00:41:32 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 00:44:04 theanets.trainer:168 validation 0 loss=16113.040039 err=14158.820312 *
I 2015-05-26 00:44:37 theanets.trainer:168 RmsProp 1 loss=13736.172852 err=13182.400391
I 2015-05-26 00:45:14 theanets.trainer:168 RmsProp 2 loss=13271.731445 err=13125.810547
I 2015-05-26 00:45:51 theanets.trainer:168 RmsProp 3 loss=12686.737305 err=12479.980469
I 2015-05-26 00:46:27 theanets.trainer:168 RmsProp 4 loss=10880.716797 err=10561.618164
I 2015-05-26 00:47:03 theanets.trainer:168 RmsProp 5 loss=9265.666992 err=8944.515625
I 2015-05-26 00:47:40 theanets.trainer:168 RmsProp 6 loss=7941.961914 err=7605.141602
I 2015-05-26 00:48:16 theanets.trainer:168 RmsProp 7 loss=6775.261230 err=6425.452148
I 2015-05-26 00:48:55 theanets.trainer:168 RmsProp 8 loss=5911.193848 err=5545.761230
I 2015-05-26 00:49:33 theanets.trainer:168 RmsProp 9 loss=5214.979980 err=4836.001953
I 2015-05-26 00:50:10 theanets.trainer:168 RmsProp 10 loss=4687.659668 err=4296.311035
I 2015-05-26 00:50:11 theanets.trainer:168 validation 1 loss=4082.986328 err=3688.748779 *
I 2015-05-26 00:50:47 theanets.trainer:168 RmsProp 11 loss=4245.197754 err=3844.253906
I 2015-05-26 00:51:23 theanets.trainer:168 RmsProp 12 loss=3836.346191 err=3426.551758
I 2015-05-26 00:52:01 theanets.trainer:168 RmsProp 13 loss=3535.921631 err=3119.285400
I 2015-05-26 00:52:38 theanets.trainer:168 RmsProp 14 loss=3280.732666 err=2857.243896
I 2015-05-26 00:53:14 theanets.trainer:168 RmsProp 15 loss=3055.109619 err=2625.230469
I 2015-05-26 00:53:52 theanets.trainer:168 RmsProp 16 loss=2883.976562 err=2449.460449
I 2015-05-26 00:54:28 theanets.trainer:168 RmsProp 17 loss=2739.913574 err=2300.260010
I 2015-05-26 00:55:04 theanets.trainer:168 RmsProp 18 loss=2578.793945 err=2134.124512
I 2015-05-26 00:55:41 theanets.trainer:168 RmsProp 19 loss=2424.159424 err=1975.170166
I 2015-05-26 00:56:15 theanets.trainer:168 RmsProp 20 loss=2343.306152 err=1890.304810
I 2015-05-26 00:56:16 theanets.trainer:168 validation 2 loss=2795.872070 err=2348.569092 *
I 2015-05-26 00:56:52 theanets.trainer:168 RmsProp 21 loss=2235.499023 err=1778.988159
I 2015-05-26 00:57:30 theanets.trainer:168 RmsProp 22 loss=2111.793213 err=1651.457397
I 2015-05-26 00:58:07 theanets.trainer:168 RmsProp 23 loss=2036.293579 err=1572.985107
I 2015-05-26 00:58:44 theanets.trainer:168 RmsProp 24 loss=1974.527832 err=1507.137451
I 2015-05-26 00:59:20 theanets.trainer:168 RmsProp 25 loss=1880.297241 err=1410.404663
I 2015-05-26 00:59:56 theanets.trainer:168 RmsProp 26 loss=1825.885620 err=1353.426514
I 2015-05-26 01:00:32 theanets.trainer:168 RmsProp 27 loss=1757.696899 err=1282.128906
I 2015-05-26 01:01:08 theanets.trainer:168 RmsProp 28 loss=1713.316772 err=1235.916626
I 2015-05-26 01:01:44 theanets.trainer:168 RmsProp 29 loss=1657.931396 err=1177.467651
I 2015-05-26 01:02:19 theanets.trainer:168 RmsProp 30 loss=1581.406860 err=1099.252441
I 2015-05-26 01:02:20 theanets.trainer:168 validation 3 loss=2595.015381 err=2121.578857 *
I 2015-05-26 01:02:56 theanets.trainer:168 RmsProp 31 loss=1525.513794 err=1043.307983
I 2015-05-26 01:03:34 theanets.trainer:168 RmsProp 32 loss=1494.688354 err=1011.086243
I 2015-05-26 01:04:11 theanets.trainer:168 RmsProp 33 loss=1454.270386 err=969.008789
I 2015-05-26 01:04:48 theanets.trainer:168 RmsProp 34 loss=1420.919800 err=935.202942
I 2015-05-26 01:05:25 theanets.trainer:168 RmsProp 35 loss=1394.542725 err=908.058899
I 2015-05-26 01:06:03 theanets.trainer:168 RmsProp 36 loss=1366.023438 err=878.989990
I 2015-05-26 01:06:39 theanets.trainer:168 RmsProp 37 loss=1341.200684 err=853.340820
I 2015-05-26 01:07:15 theanets.trainer:168 RmsProp 38 loss=1292.907593 err=805.666138
I 2015-05-26 01:07:52 theanets.trainer:168 RmsProp 39 loss=1273.601807 err=786.965698
I 2015-05-26 01:08:29 theanets.trainer:168 RmsProp 40 loss=1247.467163 err=761.301514
I 2015-05-26 01:08:30 theanets.trainer:168 validation 4 loss=2543.184814 err=2067.539062 *
I 2015-05-26 01:09:07 theanets.trainer:168 RmsProp 41 loss=1229.295288 err=743.590271
I 2015-05-26 01:09:45 theanets.trainer:168 RmsProp 42 loss=1190.347046 err=705.768738
I 2015-05-26 01:10:23 theanets.trainer:168 RmsProp 43 loss=1169.635864 err=686.320984
I 2015-05-26 01:10:59 theanets.trainer:168 RmsProp 44 loss=1174.028931 err=690.621704
I 2015-05-26 01:11:35 theanets.trainer:168 RmsProp 45 loss=1187.091675 err=700.319458
I 2015-05-26 01:12:12 theanets.trainer:168 RmsProp 46 loss=1126.316650 err=642.560303
I 2015-05-26 01:12:50 theanets.trainer:168 RmsProp 47 loss=1117.811401 err=634.727783
I 2015-05-26 01:13:28 theanets.trainer:168 RmsProp 48 loss=1111.225098 err=629.257385
I 2015-05-26 01:14:03 theanets.trainer:168 RmsProp 49 loss=1091.353638 err=610.280640
I 2015-05-26 01:14:38 theanets.trainer:168 RmsProp 50 loss=1088.876221 err=608.056702
I 2015-05-26 01:14:39 theanets.trainer:168 validation 5 loss=2499.901855 err=2028.128296 *
I 2015-05-26 01:15:16 theanets.trainer:168 RmsProp 51 loss=1065.605957 err=585.602905
I 2015-05-26 01:15:53 theanets.trainer:168 RmsProp 52 loss=1063.841309 err=584.735413
I 2015-05-26 01:16:29 theanets.trainer:168 RmsProp 53 loss=1045.531494 err=566.235962
I 2015-05-26 01:17:06 theanets.trainer:168 RmsProp 54 loss=1038.300659 err=560.870056
I 2015-05-26 01:17:42 theanets.trainer:168 RmsProp 55 loss=1021.188477 err=543.877197
I 2015-05-26 01:18:17 theanets.trainer:168 RmsProp 56 loss=1006.095398 err=529.342224
I 2015-05-26 01:18:53 theanets.trainer:168 RmsProp 57 loss=990.410034 err=516.361511
I 2015-05-26 01:19:31 theanets.trainer:168 RmsProp 58 loss=990.584167 err=516.910461
I 2015-05-26 01:20:09 theanets.trainer:168 RmsProp 59 loss=989.898376 err=516.034607
I 2015-05-26 01:20:45 theanets.trainer:168 RmsProp 60 loss=992.977234 err=518.439453
I 2015-05-26 01:20:46 theanets.trainer:168 validation 6 loss=2353.553711 err=1885.960938 *
I 2015-05-26 01:21:22 theanets.trainer:168 RmsProp 61 loss=975.756042 err=500.803864
I 2015-05-26 01:21:58 theanets.trainer:168 RmsProp 62 loss=968.256287 err=494.155731
I 2015-05-26 01:22:34 theanets.trainer:168 RmsProp 63 loss=961.915344 err=488.215729
I 2015-05-26 01:23:10 theanets.trainer:168 RmsProp 64 loss=946.983704 err=474.020203
I 2015-05-26 01:23:46 theanets.trainer:168 RmsProp 65 loss=933.630920 err=461.843903
I 2015-05-26 01:24:21 theanets.trainer:168 RmsProp 66 loss=912.878052 err=443.168762
I 2015-05-26 01:24:57 theanets.trainer:168 RmsProp 67 loss=921.210388 err=451.676544
I 2015-05-26 01:25:32 theanets.trainer:168 RmsProp 68 loss=907.204529 err=438.140594
I 2015-05-26 01:26:08 theanets.trainer:168 RmsProp 69 loss=909.837769 err=440.329865
I 2015-05-26 01:26:43 theanets.trainer:168 RmsProp 70 loss=887.509094 err=419.959503
I 2015-05-26 01:26:44 theanets.trainer:168 validation 7 loss=2237.131348 err=1779.394165 *
I 2015-05-26 01:27:21 theanets.trainer:168 RmsProp 71 loss=879.519470 err=414.257385
I 2015-05-26 01:27:57 theanets.trainer:168 RmsProp 72 loss=875.757874 err=411.075287
I 2015-05-26 01:28:35 theanets.trainer:168 RmsProp 73 loss=862.148315 err=398.640106
I 2015-05-26 01:29:12 theanets.trainer:168 RmsProp 74 loss=852.708984 err=390.327820
I 2015-05-26 01:29:49 theanets.trainer:168 RmsProp 75 loss=848.734924 err=387.192200
I 2015-05-26 01:30:27 theanets.trainer:168 RmsProp 76 loss=840.485657 err=380.012634
I 2015-05-26 01:31:03 theanets.trainer:168 RmsProp 77 loss=860.670776 err=401.025269
I 2015-05-26 01:31:38 theanets.trainer:168 RmsProp 78 loss=837.411011 err=378.981293
I 2015-05-26 01:32:15 theanets.trainer:168 RmsProp 79 loss=825.126282 err=367.191803
I 2015-05-26 01:32:52 theanets.trainer:168 RmsProp 80 loss=825.114807 err=368.427094
I 2015-05-26 01:32:53 theanets.trainer:168 validation 8 loss=2197.023926 err=1748.905640 *
I 2015-05-26 01:33:30 theanets.trainer:168 RmsProp 81 loss=820.731262 err=364.535248
I 2015-05-26 01:34:07 theanets.trainer:168 RmsProp 82 loss=861.265503 err=404.570221
I 2015-05-26 01:34:44 theanets.trainer:168 RmsProp 83 loss=806.739380 err=350.671234
I 2015-05-26 01:35:21 theanets.trainer:168 RmsProp 84 loss=801.996216 err=347.411743
I 2015-05-26 01:35:58 theanets.trainer:168 RmsProp 85 loss=800.934143 err=347.589630
I 2015-05-26 01:36:35 theanets.trainer:168 RmsProp 86 loss=794.606384 err=340.747345
I 2015-05-26 01:37:12 theanets.trainer:168 RmsProp 87 loss=795.776611 err=342.259552
I 2015-05-26 01:37:48 theanets.trainer:168 RmsProp 88 loss=791.814514 err=338.923492
I 2015-05-26 01:38:26 theanets.trainer:168 RmsProp 89 loss=775.741882 err=324.094330
I 2015-05-26 01:39:02 theanets.trainer:168 RmsProp 90 loss=781.814087 err=330.057068
I 2015-05-26 01:39:03 theanets.trainer:168 validation 9 loss=2236.808350 err=1793.148804
I 2015-05-26 01:39:39 theanets.trainer:168 RmsProp 91 loss=772.957153 err=321.739960
I 2015-05-26 01:40:17 theanets.trainer:168 RmsProp 92 loss=761.841125 err=311.155670
I 2015-05-26 01:40:53 theanets.trainer:168 RmsProp 93 loss=761.029114 err=310.503723
I 2015-05-26 01:41:30 theanets.trainer:168 RmsProp 94 loss=773.286072 err=323.156952
I 2015-05-26 01:42:07 theanets.trainer:168 RmsProp 95 loss=762.527710 err=312.867676
I 2015-05-26 01:42:44 theanets.trainer:168 RmsProp 96 loss=753.854370 err=304.407745
I 2015-05-26 01:43:22 theanets.trainer:168 RmsProp 97 loss=745.834961 err=296.587402
I 2015-05-26 01:44:00 theanets.trainer:168 RmsProp 98 loss=748.785278 err=299.017609
I 2015-05-26 01:44:37 theanets.trainer:168 RmsProp 99 loss=750.793579 err=301.709778
I 2015-05-26 01:45:13 theanets.trainer:168 RmsProp 100 loss=746.657349 err=297.024933
I 2015-05-26 01:45:14 theanets.trainer:168 validation 10 loss=2178.895752 err=1732.946655 *
I 2015-05-26 01:45:51 theanets.trainer:168 RmsProp 101 loss=750.571655 err=299.134644
I 2015-05-26 01:46:28 theanets.trainer:168 RmsProp 102 loss=739.885376 err=289.884613
I 2015-05-26 01:47:06 theanets.trainer:168 RmsProp 103 loss=726.181213 err=276.515533
I 2015-05-26 01:47:43 theanets.trainer:168 RmsProp 104 loss=736.005859 err=286.499023
I 2015-05-26 01:48:20 theanets.trainer:168 RmsProp 105 loss=723.930237 err=274.662018
I 2015-05-26 01:48:57 theanets.trainer:168 RmsProp 106 loss=729.119873 err=279.975525
I 2015-05-26 01:49:34 theanets.trainer:168 RmsProp 107 loss=729.382019 err=279.853424
I 2015-05-26 01:50:10 theanets.trainer:168 RmsProp 108 loss=713.737305 err=264.577606
I 2015-05-26 01:50:46 theanets.trainer:168 RmsProp 109 loss=717.655273 err=269.757355
I 2015-05-26 01:51:21 theanets.trainer:168 RmsProp 110 loss=704.967651 err=258.022705
I 2015-05-26 01:51:22 theanets.trainer:168 validation 11 loss=2168.622314 err=1731.012695 *
I 2015-05-26 01:51:56 theanets.trainer:168 RmsProp 111 loss=698.250000 err=251.770615
I 2015-05-26 01:52:33 theanets.trainer:168 RmsProp 112 loss=699.611023 err=252.811768
I 2015-05-26 01:53:09 theanets.trainer:168 RmsProp 113 loss=695.827698 err=249.551239
I 2015-05-26 01:53:46 theanets.trainer:168 RmsProp 114 loss=703.810425 err=255.325211
I 2015-05-26 01:54:24 theanets.trainer:168 RmsProp 115 loss=700.785950 err=252.576355
I 2015-05-26 01:55:02 theanets.trainer:168 RmsProp 116 loss=719.698547 err=270.206512
I 2015-05-26 01:55:39 theanets.trainer:168 RmsProp 117 loss=690.879822 err=242.390045
I 2015-05-26 01:56:16 theanets.trainer:168 RmsProp 118 loss=679.699341 err=232.590973
I 2015-05-26 01:56:52 theanets.trainer:168 RmsProp 119 loss=685.892456 err=240.151962
I 2015-05-26 01:57:27 theanets.trainer:168 RmsProp 120 loss=693.681946 err=246.338409
I 2015-05-26 01:57:28 theanets.trainer:168 validation 12 loss=2243.132812 err=1799.289062
I 2015-05-26 01:58:03 theanets.trainer:168 RmsProp 121 loss=676.420166 err=228.844147
I 2015-05-26 01:58:39 theanets.trainer:168 RmsProp 122 loss=682.798645 err=236.366699
I 2015-05-26 01:59:15 theanets.trainer:168 RmsProp 123 loss=664.798706 err=219.339569
I 2015-05-26 01:59:51 theanets.trainer:168 RmsProp 124 loss=672.805664 err=229.649139
I 2015-05-26 02:00:27 theanets.trainer:168 RmsProp 125 loss=663.301636 err=219.493256
I 2015-05-26 02:01:03 theanets.trainer:168 RmsProp 126 loss=663.092773 err=219.299637
I 2015-05-26 02:01:40 theanets.trainer:168 RmsProp 127 loss=650.231323 err=208.937210
I 2015-05-26 02:02:17 theanets.trainer:168 RmsProp 128 loss=649.883545 err=208.437729
I 2015-05-26 02:02:54 theanets.trainer:168 RmsProp 129 loss=652.552124 err=212.682541
I 2015-05-26 02:03:30 theanets.trainer:168 RmsProp 130 loss=637.067505 err=198.482834
I 2015-05-26 02:03:31 theanets.trainer:168 validation 13 loss=2264.651855 err=1835.368774
I 2015-05-26 02:04:08 theanets.trainer:168 RmsProp 131 loss=604.489563 err=167.401520
I 2015-05-26 02:04:45 theanets.trainer:168 RmsProp 132 loss=552.534607 err=119.552902
I 2015-05-26 02:05:22 theanets.trainer:168 RmsProp 133 loss=530.652893 err=103.681763
I 2015-05-26 02:05:59 theanets.trainer:168 RmsProp 134 loss=519.980713 err=98.643936
I 2015-05-26 02:06:35 theanets.trainer:168 RmsProp 135 loss=513.120178 err=96.624481
I 2015-05-26 02:07:12 theanets.trainer:168 RmsProp 136 loss=506.895050 err=94.830780
I 2015-05-26 02:07:47 theanets.trainer:168 RmsProp 137 loss=501.055756 err=92.910652
I 2015-05-26 02:08:25 theanets.trainer:168 RmsProp 138 loss=492.984741 err=89.092171
I 2015-05-26 02:09:03 theanets.trainer:168 RmsProp 139 loss=490.537262 err=90.005875
I 2015-05-26 02:09:40 theanets.trainer:168 RmsProp 140 loss=483.225952 err=86.531960
I 2015-05-26 02:09:41 theanets.trainer:168 validation 14 loss=2133.733887 err=1745.468384 *
I 2015-05-26 02:10:17 theanets.trainer:168 RmsProp 141 loss=478.724640 err=85.779305
I 2015-05-26 02:10:55 theanets.trainer:168 RmsProp 142 loss=473.654327 err=83.920174
I 2015-05-26 02:11:33 theanets.trainer:168 RmsProp 143 loss=471.308868 err=84.521721
I 2015-05-26 02:12:10 theanets.trainer:168 RmsProp 144 loss=467.768158 err=83.937164
I 2015-05-26 02:12:46 theanets.trainer:168 RmsProp 145 loss=462.745483 err=81.507347
I 2015-05-26 02:13:21 theanets.trainer:168 RmsProp 146 loss=457.720856 err=79.512093
I 2015-05-26 02:13:58 theanets.trainer:168 RmsProp 147 loss=454.261322 err=78.665581
I 2015-05-26 02:14:35 theanets.trainer:168 RmsProp 148 loss=449.934174 err=77.196640
I 2015-05-26 02:15:12 theanets.trainer:168 RmsProp 149 loss=447.343719 err=77.401123
I 2015-05-26 02:15:48 theanets.trainer:168 RmsProp 150 loss=442.444366 err=75.244888
I 2015-05-26 02:15:49 theanets.trainer:168 validation 15 loss=2095.575928 err=1735.997437 *
I 2015-05-26 02:16:26 theanets.trainer:168 RmsProp 151 loss=440.739380 err=75.768799
I 2015-05-26 02:17:02 theanets.trainer:168 RmsProp 152 loss=438.160736 err=75.524506
I 2015-05-26 02:17:38 theanets.trainer:168 RmsProp 153 loss=435.242615 err=74.356529
I 2015-05-26 02:18:14 theanets.trainer:168 RmsProp 154 loss=433.314148 err=74.371895
I 2015-05-26 02:18:50 theanets.trainer:168 RmsProp 155 loss=431.195404 err=74.073250
I 2015-05-26 02:19:26 theanets.trainer:168 RmsProp 156 loss=427.009094 err=71.607834
I 2015-05-26 02:20:03 theanets.trainer:168 RmsProp 157 loss=424.137848 err=70.954559
I 2015-05-26 02:20:40 theanets.trainer:168 RmsProp 158 loss=422.626129 err=71.361107
I 2015-05-26 02:21:16 theanets.trainer:168 RmsProp 159 loss=421.508301 err=72.197945
I 2015-05-26 02:21:51 theanets.trainer:168 RmsProp 160 loss=418.469452 err=70.710640
I 2015-05-26 02:21:52 theanets.trainer:168 validation 16 loss=2105.927246 err=1764.760132
I 2015-05-26 02:22:27 theanets.trainer:168 RmsProp 161 loss=415.071777 err=69.549126
I 2015-05-26 02:23:02 theanets.trainer:168 RmsProp 162 loss=413.725189 err=69.457550
I 2015-05-26 02:23:37 theanets.trainer:168 RmsProp 163 loss=410.922302 err=68.697784
I 2015-05-26 02:24:13 theanets.trainer:168 RmsProp 164 loss=410.129364 err=69.250732
I 2015-05-26 02:24:51 theanets.trainer:168 RmsProp 165 loss=407.520782 err=67.944389
I 2015-05-26 02:25:28 theanets.trainer:168 RmsProp 166 loss=405.257446 err=67.496864
I 2015-05-26 02:26:06 theanets.trainer:168 RmsProp 167 loss=403.299103 err=67.045296
I 2015-05-26 02:26:43 theanets.trainer:168 RmsProp 168 loss=401.376587 err=66.514076
I 2015-05-26 02:27:19 theanets.trainer:168 RmsProp 169 loss=400.152618 err=66.438705
I 2015-05-26 02:27:55 theanets.trainer:168 RmsProp 170 loss=398.092072 err=65.977501
I 2015-05-26 02:27:56 theanets.trainer:168 validation 17 loss=2075.145508 err=1749.898315 *
I 2015-05-26 02:28:31 theanets.trainer:168 RmsProp 171 loss=395.057617 err=64.416138
I 2015-05-26 02:29:05 theanets.trainer:168 RmsProp 172 loss=393.026093 err=63.888794
I 2015-05-26 02:29:39 theanets.trainer:168 RmsProp 173 loss=390.709106 err=63.002079
I 2015-05-26 02:30:14 theanets.trainer:168 RmsProp 174 loss=389.556091 err=63.309807
I 2015-05-26 02:30:49 theanets.trainer:168 RmsProp 175 loss=387.845062 err=63.204178
I 2015-05-26 02:31:24 theanets.trainer:168 RmsProp 176 loss=385.183228 err=61.968731
I 2015-05-26 02:32:00 theanets.trainer:168 RmsProp 177 loss=383.893097 err=61.688602
I 2015-05-26 02:32:35 theanets.trainer:168 RmsProp 178 loss=384.067078 err=63.419910
I 2015-05-26 02:33:10 theanets.trainer:168 RmsProp 179 loss=381.005066 err=61.212337
I 2015-05-26 02:33:45 theanets.trainer:168 RmsProp 180 loss=379.815857 err=61.501648
I 2015-05-26 02:33:45 theanets.trainer:168 validation 18 loss=2085.505615 err=1772.576538
I 2015-05-26 02:34:20 theanets.trainer:168 RmsProp 181 loss=376.525452 err=59.633987
I 2015-05-26 02:34:55 theanets.trainer:168 RmsProp 182 loss=376.035217 err=60.325314
I 2015-05-26 02:35:30 theanets.trainer:168 RmsProp 183 loss=375.573151 err=60.962852
I 2015-05-26 02:36:06 theanets.trainer:168 RmsProp 184 loss=372.443756 err=58.919666
I 2015-05-26 02:36:42 theanets.trainer:168 RmsProp 185 loss=370.145172 err=58.167774
I 2015-05-26 02:37:17 theanets.trainer:168 RmsProp 186 loss=370.615356 err=59.516239
I 2015-05-26 02:37:52 theanets.trainer:168 RmsProp 187 loss=366.857025 err=56.820717
I 2015-05-26 02:38:27 theanets.trainer:168 RmsProp 188 loss=366.515045 err=57.678902
I 2015-05-26 02:39:02 theanets.trainer:168 RmsProp 189 loss=364.865173 err=57.610153
I 2015-05-26 02:39:37 theanets.trainer:168 RmsProp 190 loss=364.181824 err=57.618896
I 2015-05-26 02:39:38 theanets.trainer:168 validation 19 loss=2054.439209 err=1753.646851 *
I 2015-05-26 02:40:14 theanets.trainer:168 RmsProp 191 loss=362.048431 err=56.761154
I 2015-05-26 02:40:50 theanets.trainer:168 RmsProp 192 loss=359.765930 err=55.606701
I 2015-05-26 02:41:26 theanets.trainer:168 RmsProp 193 loss=359.324493 err=56.325256
I 2015-05-26 02:42:02 theanets.trainer:168 RmsProp 194 loss=358.242249 err=56.089191
I 2015-05-26 02:42:36 theanets.trainer:168 RmsProp 195 loss=355.598969 err=54.721661
I 2015-05-26 02:43:12 theanets.trainer:168 RmsProp 196 loss=354.386627 err=54.492249
I 2015-05-26 02:43:48 theanets.trainer:168 RmsProp 197 loss=353.907166 err=55.097923
I 2015-05-26 02:44:25 theanets.trainer:168 RmsProp 198 loss=350.087830 err=52.565437
I 2015-05-26 02:44:56 theanets.trainer:168 RmsProp 199 loss=349.201660 err=52.800076
I 2015-05-26 02:45:29 theanets.trainer:168 RmsProp 200 loss=348.965515 err=53.607250
I 2015-05-26 02:45:30 theanets.trainer:168 validation 20 loss=2042.056274 err=1752.636719 *
I 2015-05-26 02:46:03 theanets.trainer:168 RmsProp 201 loss=348.002136 err=53.560741
I 2015-05-26 02:46:33 theanets.trainer:168 RmsProp 202 loss=346.643524 err=53.112907
I 2015-05-26 02:47:05 theanets.trainer:168 RmsProp 203 loss=343.898743 err=51.552608
I 2015-05-26 02:47:37 theanets.trainer:168 RmsProp 204 loss=344.377563 err=52.731693
I 2015-05-26 02:48:09 theanets.trainer:168 RmsProp 205 loss=341.292023 err=50.725002
I 2015-05-26 02:48:42 theanets.trainer:168 RmsProp 206 loss=339.858459 err=50.275902
I 2015-05-26 02:49:15 theanets.trainer:168 RmsProp 207 loss=339.408569 err=50.812733
I 2015-05-26 02:49:47 theanets.trainer:168 RmsProp 208 loss=337.940125 err=50.315128
I 2015-05-26 02:50:20 theanets.trainer:168 RmsProp 209 loss=336.286499 err=49.814732
I 2015-05-26 02:50:52 theanets.trainer:168 RmsProp 210 loss=335.238892 err=49.375584
I 2015-05-26 02:50:53 theanets.trainer:168 validation 21 loss=2008.390991 err=1727.800171 *
I 2015-05-26 02:51:26 theanets.trainer:168 RmsProp 211 loss=333.229187 err=48.387840
I 2015-05-26 02:51:57 theanets.trainer:168 RmsProp 212 loss=334.552795 err=50.491013
I 2015-05-26 02:52:29 theanets.trainer:168 RmsProp 213 loss=331.869415 err=48.852165
I 2015-05-26 02:53:00 theanets.trainer:168 RmsProp 214 loss=331.637390 err=49.704720
I 2015-05-26 02:53:32 theanets.trainer:168 RmsProp 215 loss=328.945770 err=47.780010
I 2015-05-26 02:54:04 theanets.trainer:168 RmsProp 216 loss=328.651306 err=48.348000
I 2015-05-26 02:54:36 theanets.trainer:168 RmsProp 217 loss=327.556305 err=48.395576
I 2015-05-26 02:55:08 theanets.trainer:168 RmsProp 218 loss=327.044922 err=48.553509
I 2015-05-26 02:55:40 theanets.trainer:168 RmsProp 219 loss=325.905548 err=48.354118
I 2015-05-26 02:56:11 theanets.trainer:168 RmsProp 220 loss=323.439362 err=47.001423
I 2015-05-26 02:56:12 theanets.trainer:168 validation 22 loss=2022.714966 err=1750.597656
I 2015-05-26 02:56:43 theanets.trainer:168 RmsProp 221 loss=322.952240 err=46.977867
I 2015-05-26 02:57:14 theanets.trainer:168 RmsProp 222 loss=322.133606 err=47.028664
I 2015-05-26 02:57:45 theanets.trainer:168 RmsProp 223 loss=319.858398 err=45.702030
I 2015-05-26 02:58:15 theanets.trainer:168 RmsProp 224 loss=319.012085 err=45.787216
I 2015-05-26 02:58:47 theanets.trainer:168 RmsProp 225 loss=317.865723 err=45.459118
I 2015-05-26 02:59:18 theanets.trainer:168 RmsProp 226 loss=318.149902 err=46.261490
I 2015-05-26 02:59:48 theanets.trainer:168 RmsProp 227 loss=316.481628 err=45.437233
I 2015-05-26 03:00:20 theanets.trainer:168 RmsProp 228 loss=313.619720 err=43.706917
I 2015-05-26 03:00:52 theanets.trainer:168 RmsProp 229 loss=314.467072 err=45.151543
I 2015-05-26 03:01:24 theanets.trainer:168 RmsProp 230 loss=312.973328 err=44.318527
I 2015-05-26 03:01:24 theanets.trainer:168 validation 23 loss=1993.788452 err=1729.464844 *
I 2015-05-26 03:01:55 theanets.trainer:168 RmsProp 231 loss=311.264313 err=43.423347
I 2015-05-26 03:02:26 theanets.trainer:168 RmsProp 232 loss=311.519470 err=44.841713
I 2015-05-26 03:02:59 theanets.trainer:168 RmsProp 233 loss=310.335388 err=43.985683
I 2015-05-26 03:03:30 theanets.trainer:168 RmsProp 234 loss=308.777802 err=43.144577
I 2015-05-26 03:04:00 theanets.trainer:168 RmsProp 235 loss=308.676056 err=43.619736
I 2015-05-26 03:04:31 theanets.trainer:168 RmsProp 236 loss=306.220673 err=42.415058
I 2015-05-26 03:05:02 theanets.trainer:168 RmsProp 237 loss=306.291687 err=43.355789
I 2015-05-26 03:05:31 theanets.trainer:168 RmsProp 238 loss=304.913940 err=42.598934
I 2015-05-26 03:05:59 theanets.trainer:168 RmsProp 239 loss=304.051727 err=42.505192
I 2015-05-26 03:06:29 theanets.trainer:168 RmsProp 240 loss=303.488220 err=42.731491
I 2015-05-26 03:06:30 theanets.trainer:168 validation 24 loss=2000.739868 err=1744.836304
I 2015-05-26 03:06:58 theanets.trainer:168 RmsProp 241 loss=302.638947 err=42.304100
I 2015-05-26 03:07:26 theanets.trainer:168 RmsProp 242 loss=300.639191 err=41.311584
I 2015-05-26 03:07:55 theanets.trainer:168 RmsProp 243 loss=300.689728 err=41.812996
I 2015-05-26 03:08:25 theanets.trainer:168 RmsProp 244 loss=299.210419 err=41.111244
I 2015-05-26 03:08:54 theanets.trainer:168 RmsProp 245 loss=298.738953 err=41.413242
I 2015-05-26 03:09:23 theanets.trainer:168 RmsProp 246 loss=297.141632 err=40.507450
I 2015-05-26 03:09:52 theanets.trainer:168 RmsProp 247 loss=297.688965 err=41.386631
I 2015-05-26 03:10:21 theanets.trainer:168 RmsProp 248 loss=294.527405 err=39.138058
I 2015-05-26 03:10:51 theanets.trainer:168 RmsProp 249 loss=294.454193 err=39.922066
I 2015-05-26 03:11:19 theanets.trainer:168 RmsProp 250 loss=293.675720 err=39.806683
I 2015-05-26 03:11:19 theanets.trainer:168 validation 25 loss=1991.027710 err=1741.717163 *
I 2015-05-26 03:11:47 theanets.trainer:168 RmsProp 251 loss=293.450287 err=39.967869
I 2015-05-26 03:12:16 theanets.trainer:168 RmsProp 252 loss=291.853546 err=39.210388
I 2015-05-26 03:12:44 theanets.trainer:168 RmsProp 253 loss=290.299530 err=38.316097
I 2015-05-26 03:13:09 theanets.trainer:168 RmsProp 254 loss=290.321808 err=38.937447
I 2015-05-26 03:13:36 theanets.trainer:168 RmsProp 255 loss=289.184845 err=38.651646
I 2015-05-26 03:14:02 theanets.trainer:168 RmsProp 256 loss=288.135559 err=38.177872
I 2015-05-26 03:14:28 theanets.trainer:168 RmsProp 257 loss=286.520294 err=37.474613
I 2015-05-26 03:14:55 theanets.trainer:168 RmsProp 258 loss=286.982971 err=38.480164
I 2015-05-26 03:15:21 theanets.trainer:168 RmsProp 259 loss=285.641693 err=37.892635
I 2015-05-26 03:15:49 theanets.trainer:168 RmsProp 260 loss=285.407043 err=37.871540
I 2015-05-26 03:15:50 theanets.trainer:168 validation 26 loss=1979.556152 err=1736.399292 *
I 2015-05-26 03:16:16 theanets.trainer:168 RmsProp 261 loss=284.207397 err=37.511482
I 2015-05-26 03:16:43 theanets.trainer:168 RmsProp 262 loss=283.248169 err=37.134644
I 2015-05-26 03:17:10 theanets.trainer:168 RmsProp 263 loss=282.454590 err=37.042599
I 2015-05-26 03:17:37 theanets.trainer:168 RmsProp 264 loss=284.034637 err=38.909565
I 2015-05-26 03:18:04 theanets.trainer:168 RmsProp 265 loss=280.621948 err=36.062325
I 2015-05-26 03:18:31 theanets.trainer:168 RmsProp 266 loss=280.655823 err=36.960697
I 2015-05-26 03:18:59 theanets.trainer:168 RmsProp 267 loss=280.098083 err=36.976749
I 2015-05-26 03:19:27 theanets.trainer:168 RmsProp 268 loss=278.907898 err=36.429745
I 2015-05-26 03:19:54 theanets.trainer:168 RmsProp 269 loss=278.875946 err=36.807323
I 2015-05-26 03:20:22 theanets.trainer:168 RmsProp 270 loss=278.394318 err=36.688625
I 2015-05-26 03:20:23 theanets.trainer:168 validation 27 loss=2011.706665 err=1774.134399
I 2015-05-26 03:20:49 theanets.trainer:168 RmsProp 271 loss=276.240387 err=35.268692
I 2015-05-26 03:21:15 theanets.trainer:168 RmsProp 272 loss=276.562012 err=36.211109
I 2015-05-26 03:21:41 theanets.trainer:168 RmsProp 273 loss=276.558868 err=36.441395
I 2015-05-26 03:22:08 theanets.trainer:168 RmsProp 274 loss=274.801361 err=35.321632
I 2015-05-26 03:22:34 theanets.trainer:168 RmsProp 275 loss=274.517029 err=35.728844
I 2015-05-26 03:23:01 theanets.trainer:168 RmsProp 276 loss=274.085968 err=35.748058
I 2015-05-26 03:23:28 theanets.trainer:168 RmsProp 277 loss=272.971893 err=35.058891
I 2015-05-26 03:23:54 theanets.trainer:168 RmsProp 278 loss=271.952759 err=34.689247
I 2015-05-26 03:24:20 theanets.trainer:168 RmsProp 279 loss=270.713776 err=34.020447
I 2015-05-26 03:24:48 theanets.trainer:168 RmsProp 280 loss=269.926971 err=33.955013
I 2015-05-26 03:24:49 theanets.trainer:168 validation 28 loss=1978.551147 err=1746.711792 *
I 2015-05-26 03:25:16 theanets.trainer:168 RmsProp 281 loss=269.784607 err=34.047077
I 2015-05-26 03:25:44 theanets.trainer:168 RmsProp 282 loss=269.311707 err=34.418613
I 2015-05-26 03:26:10 theanets.trainer:168 RmsProp 283 loss=268.764069 err=34.188225
I 2015-05-26 03:26:37 theanets.trainer:168 RmsProp 284 loss=268.003082 err=33.778244
I 2015-05-26 03:27:05 theanets.trainer:168 RmsProp 285 loss=268.025787 err=34.301304
I 2015-05-26 03:27:33 theanets.trainer:168 RmsProp 286 loss=266.577026 err=33.357906
I 2015-05-26 03:28:00 theanets.trainer:168 RmsProp 287 loss=265.543732 err=32.963993
I 2015-05-26 03:28:27 theanets.trainer:168 RmsProp 288 loss=266.264832 err=34.103622
I 2015-05-26 03:28:54 theanets.trainer:168 RmsProp 289 loss=264.178833 err=32.754868
I 2015-05-26 03:29:22 theanets.trainer:168 RmsProp 290 loss=266.257355 err=35.370922
I 2015-05-26 03:29:23 theanets.trainer:168 validation 29 loss=1982.973999 err=1755.444214
I 2015-05-26 03:29:49 theanets.trainer:168 RmsProp 291 loss=266.028107 err=35.224308
I 2015-05-26 03:30:14 theanets.trainer:168 RmsProp 292 loss=263.846649 err=33.388851
I 2015-05-26 03:30:40 theanets.trainer:168 RmsProp 293 loss=262.530609 err=32.816090
I 2015-05-26 03:31:07 theanets.trainer:168 RmsProp 294 loss=261.506989 err=32.221104
I 2015-05-26 03:31:33 theanets.trainer:168 RmsProp 295 loss=260.932281 err=32.193108
I 2015-05-26 03:32:00 theanets.trainer:168 RmsProp 296 loss=261.741394 err=33.432148
I 2015-05-26 03:32:28 theanets.trainer:168 RmsProp 297 loss=259.566376 err=31.942202
I 2015-05-26 03:32:56 theanets.trainer:168 RmsProp 298 loss=259.055969 err=31.749142
I 2015-05-26 03:33:25 theanets.trainer:168 RmsProp 299 loss=259.194763 err=32.321568
I 2015-05-26 03:33:52 theanets.trainer:168 RmsProp 300 loss=258.036194 err=31.701067
I 2015-05-26 03:33:53 theanets.trainer:168 validation 30 loss=1986.003540 err=1763.278198
I 2015-05-26 03:34:16 theanets.trainer:168 RmsProp 301 loss=257.196320 err=31.404676
I 2015-05-26 03:34:39 theanets.trainer:168 RmsProp 302 loss=256.984283 err=31.722378
I 2015-05-26 03:35:04 theanets.trainer:168 RmsProp 303 loss=257.611023 err=32.370510
I 2015-05-26 03:35:38 theanets.trainer:168 RmsProp 304 loss=255.775116 err=31.188208
I 2015-05-26 03:36:37 theanets.trainer:168 RmsProp 305 loss=255.718735 err=31.467831
I 2015-05-26 03:37:45 theanets.trainer:168 RmsProp 306 loss=253.958740 err=30.134504
I 2015-05-26 03:38:46 theanets.trainer:168 RmsProp 307 loss=254.931107 err=31.340424
I 2015-05-26 03:39:51 theanets.trainer:168 RmsProp 308 loss=255.654617 err=32.296597
I 2015-05-26 03:41:01 theanets.trainer:168 RmsProp 309 loss=255.588211 err=32.490921
I 2015-05-26 03:42:11 theanets.trainer:168 RmsProp 310 loss=254.475021 err=31.801805
I 2015-05-26 03:42:12 theanets.trainer:168 validation 31 loss=1956.243530 err=1737.585815 *
I 2015-05-26 03:43:21 theanets.trainer:168 RmsProp 311 loss=252.602051 err=30.741835
I 2015-05-26 03:44:30 theanets.trainer:168 RmsProp 312 loss=251.698090 err=30.337847
I 2015-05-26 03:45:39 theanets.trainer:168 RmsProp 313 loss=251.002289 err=30.186152
I 2015-05-26 03:46:49 theanets.trainer:168 RmsProp 314 loss=251.993332 err=31.408195
I 2015-05-26 03:47:58 theanets.trainer:168 RmsProp 315 loss=250.852585 err=30.582151
I 2015-05-26 03:49:08 theanets.trainer:168 RmsProp 316 loss=249.574661 err=29.812548
I 2015-05-26 03:50:18 theanets.trainer:168 RmsProp 317 loss=248.817719 err=29.864128
I 2015-05-26 03:51:29 theanets.trainer:168 RmsProp 318 loss=248.620895 err=29.989708
I 2015-05-26 03:52:40 theanets.trainer:168 RmsProp 319 loss=247.567200 err=29.259256
I 2015-05-26 03:53:51 theanets.trainer:168 RmsProp 320 loss=246.762131 err=28.859985
I 2015-05-26 03:53:52 theanets.trainer:168 validation 32 loss=1983.985229 err=1769.841431
I 2015-05-26 03:55:03 theanets.trainer:168 RmsProp 321 loss=246.629486 err=29.127827
I 2015-05-26 03:56:14 theanets.trainer:168 RmsProp 322 loss=246.244186 err=29.174421
I 2015-05-26 03:57:25 theanets.trainer:168 RmsProp 323 loss=245.177139 err=28.618141
I 2015-05-26 03:58:36 theanets.trainer:168 RmsProp 324 loss=244.861374 err=28.716360
I 2015-05-26 03:59:46 theanets.trainer:168 RmsProp 325 loss=244.266953 err=28.557253
I 2015-05-26 04:00:57 theanets.trainer:168 RmsProp 326 loss=244.414261 err=28.879005
I 2015-05-26 04:02:08 theanets.trainer:168 RmsProp 327 loss=243.386734 err=28.282495
I 2015-05-26 04:03:19 theanets.trainer:168 RmsProp 328 loss=243.613174 err=28.925751
I 2015-05-26 04:04:30 theanets.trainer:168 RmsProp 329 loss=242.825302 err=28.648731
I 2015-05-26 04:05:41 theanets.trainer:168 RmsProp 330 loss=241.402481 err=27.700808
I 2015-05-26 04:05:42 theanets.trainer:168 validation 33 loss=1956.521606 err=1746.493530
I 2015-05-26 04:06:53 theanets.trainer:168 RmsProp 331 loss=241.323944 err=28.029108
I 2015-05-26 04:08:04 theanets.trainer:168 RmsProp 332 loss=240.276855 err=27.490887
I 2015-05-26 04:09:14 theanets.trainer:168 RmsProp 333 loss=241.382828 err=28.977232
I 2015-05-26 04:10:24 theanets.trainer:168 RmsProp 334 loss=239.732086 err=27.813427
I 2015-05-26 04:11:34 theanets.trainer:168 RmsProp 335 loss=239.215790 err=27.591803
I 2015-05-26 04:12:44 theanets.trainer:168 RmsProp 336 loss=238.964355 err=27.644352
I 2015-05-26 04:13:52 theanets.trainer:168 RmsProp 337 loss=237.801620 err=27.175449
I 2015-05-26 04:14:57 theanets.trainer:168 RmsProp 338 loss=237.886292 err=27.475721
I 2015-05-26 04:16:02 theanets.trainer:168 RmsProp 339 loss=238.207932 err=28.013998
I 2015-05-26 04:17:07 theanets.trainer:168 RmsProp 340 loss=237.356796 err=27.647806
I 2015-05-26 04:17:09 theanets.trainer:168 validation 34 loss=1985.371094 err=1779.368530
I 2015-05-26 04:18:13 theanets.trainer:168 RmsProp 341 loss=236.284653 err=26.952997
I 2015-05-26 04:19:18 theanets.trainer:168 RmsProp 342 loss=235.658783 err=26.928877
I 2015-05-26 04:20:24 theanets.trainer:168 RmsProp 343 loss=235.361038 err=26.852823
I 2015-05-26 04:21:30 theanets.trainer:168 RmsProp 344 loss=234.374924 err=26.395393
I 2015-05-26 04:22:34 theanets.trainer:168 RmsProp 345 loss=234.465622 err=26.872831
I 2015-05-26 04:23:35 theanets.trainer:168 RmsProp 346 loss=235.938278 err=28.472200
I 2015-05-26 04:24:37 theanets.trainer:168 RmsProp 347 loss=234.190201 err=27.207636
I 2015-05-26 04:25:38 theanets.trainer:168 RmsProp 348 loss=232.624023 err=25.961918
I 2015-05-26 04:26:40 theanets.trainer:168 RmsProp 349 loss=232.311417 err=25.984961
I 2015-05-26 04:27:42 theanets.trainer:168 RmsProp 350 loss=233.083069 err=27.178680
I 2015-05-26 04:27:43 theanets.trainer:168 validation 35 loss=1972.028198 err=1769.472290
I 2015-05-26 04:28:43 theanets.trainer:168 RmsProp 351 loss=231.092606 err=25.550114
I 2015-05-26 04:29:44 theanets.trainer:168 RmsProp 352 loss=231.606094 err=26.433067
I 2015-05-26 04:30:46 theanets.trainer:168 RmsProp 353 loss=230.492111 err=25.704350
I 2015-05-26 04:31:47 theanets.trainer:168 RmsProp 354 loss=230.608292 err=26.166264
I 2015-05-26 04:32:48 theanets.trainer:168 RmsProp 355 loss=229.935059 err=25.828913
I 2015-05-26 04:33:49 theanets.trainer:168 RmsProp 356 loss=229.145416 err=25.385876
I 2015-05-26 04:34:51 theanets.trainer:168 RmsProp 357 loss=228.973450 err=25.712627
I 2015-05-26 04:35:54 theanets.trainer:168 RmsProp 358 loss=228.545654 err=25.386929
I 2015-05-26 04:36:56 theanets.trainer:168 RmsProp 359 loss=227.953751 err=25.416756
I 2015-05-26 04:37:58 theanets.trainer:168 RmsProp 360 loss=227.410385 err=25.118265
I 2015-05-26 04:37:59 theanets.trainer:168 validation 36 loss=1955.234985 err=1756.618164 *
I 2015-05-26 04:39:02 theanets.trainer:168 RmsProp 361 loss=226.531570 err=24.726965
I 2015-05-26 04:40:06 theanets.trainer:168 RmsProp 362 loss=226.894577 err=25.339586
I 2015-05-26 04:41:09 theanets.trainer:168 RmsProp 363 loss=227.834381 err=26.420141
I 2015-05-26 04:42:11 theanets.trainer:168 RmsProp 364 loss=229.059250 err=27.612202
I 2015-05-26 04:43:14 theanets.trainer:168 RmsProp 365 loss=226.587830 err=25.542961
I 2015-05-26 04:44:17 theanets.trainer:168 RmsProp 366 loss=226.021393 err=25.304056
I 2015-05-26 04:45:20 theanets.trainer:168 RmsProp 367 loss=225.729736 err=25.260601
I 2015-05-26 04:46:22 theanets.trainer:168 RmsProp 368 loss=223.783768 err=24.069447
I 2015-05-26 04:47:24 theanets.trainer:168 RmsProp 369 loss=223.578873 err=24.187798
I 2015-05-26 04:48:27 theanets.trainer:168 RmsProp 370 loss=223.948807 err=24.849983
I 2015-05-26 04:48:28 theanets.trainer:168 validation 37 loss=1956.026733 err=1760.070679
I 2015-05-26 04:49:31 theanets.trainer:168 RmsProp 371 loss=223.473877 err=24.591639
I 2015-05-26 04:50:34 theanets.trainer:168 RmsProp 372 loss=222.789780 err=24.255522
I 2015-05-26 04:51:36 theanets.trainer:168 RmsProp 373 loss=222.414017 err=24.092112
I 2015-05-26 04:52:39 theanets.trainer:168 RmsProp 374 loss=221.717529 err=23.819275
I 2015-05-26 04:53:42 theanets.trainer:168 RmsProp 375 loss=221.834625 err=24.308804
I 2015-05-26 04:54:43 theanets.trainer:168 RmsProp 376 loss=222.346008 err=25.054197
I 2015-05-26 04:55:44 theanets.trainer:168 RmsProp 377 loss=221.607437 err=24.386784
I 2015-05-26 04:56:44 theanets.trainer:168 RmsProp 378 loss=220.584686 err=23.582043
I 2015-05-26 04:57:45 theanets.trainer:168 RmsProp 379 loss=220.031082 err=23.521955
I 2015-05-26 04:58:45 theanets.trainer:168 RmsProp 380 loss=221.320694 err=24.912670
I 2015-05-26 04:58:46 theanets.trainer:168 validation 38 loss=1957.771118 err=1764.989868
I 2015-05-26 04:59:47 theanets.trainer:168 RmsProp 381 loss=220.123703 err=24.019203
I 2015-05-26 05:00:48 theanets.trainer:168 RmsProp 382 loss=219.967880 err=24.106630
I 2015-05-26 05:01:49 theanets.trainer:168 RmsProp 383 loss=220.250336 err=24.430511
I 2015-05-26 05:02:49 theanets.trainer:168 RmsProp 384 loss=218.981750 err=23.588467
I 2015-05-26 05:03:50 theanets.trainer:168 RmsProp 385 loss=218.039444 err=22.794167
I 2015-05-26 05:04:51 theanets.trainer:168 RmsProp 386 loss=219.011780 err=24.398594
I 2015-05-26 05:05:52 theanets.trainer:168 RmsProp 387 loss=217.642471 err=23.372425
I 2015-05-26 05:06:53 theanets.trainer:168 RmsProp 388 loss=216.941422 err=23.136091
I 2015-05-26 05:07:54 theanets.trainer:168 RmsProp 389 loss=217.197891 err=23.432545
I 2015-05-26 05:08:52 theanets.trainer:168 RmsProp 390 loss=216.795364 err=23.233450
I 2015-05-26 05:08:53 theanets.trainer:168 validation 39 loss=1964.904785 err=1774.807983
I 2015-05-26 05:09:52 theanets.trainer:168 RmsProp 391 loss=215.518250 err=22.359007
I 2015-05-26 05:10:49 theanets.trainer:168 RmsProp 392 loss=215.806244 err=23.189432
I 2015-05-26 05:11:47 theanets.trainer:168 RmsProp 393 loss=217.324188 err=24.382504
I 2015-05-26 05:12:44 theanets.trainer:168 RmsProp 394 loss=215.377625 err=22.724174
I 2015-05-26 05:13:41 theanets.trainer:168 RmsProp 395 loss=215.296783 err=23.126921
I 2015-05-26 05:14:39 theanets.trainer:168 RmsProp 396 loss=214.762451 err=22.765499
I 2015-05-26 05:15:38 theanets.trainer:168 RmsProp 397 loss=215.295898 err=23.535173
I 2015-05-26 05:16:36 theanets.trainer:168 RmsProp 398 loss=214.077850 err=22.472767
I 2015-05-26 05:17:34 theanets.trainer:168 RmsProp 399 loss=213.084259 err=22.165461
I 2015-05-26 05:18:32 theanets.trainer:168 RmsProp 400 loss=213.695251 err=22.767653
I 2015-05-26 05:18:33 theanets.trainer:168 validation 40 loss=1936.779175 err=1749.324219 *
I 2015-05-26 05:19:31 theanets.trainer:168 RmsProp 401 loss=212.269043 err=21.990038
I 2015-05-26 05:20:28 theanets.trainer:168 RmsProp 402 loss=212.277191 err=22.158901
I 2015-05-26 05:21:27 theanets.trainer:168 RmsProp 403 loss=211.586227 err=21.712236
I 2015-05-26 05:22:25 theanets.trainer:168 RmsProp 404 loss=211.765244 err=22.204573
I 2015-05-26 05:23:23 theanets.trainer:168 RmsProp 405 loss=212.355240 err=22.793810
I 2015-05-26 05:24:21 theanets.trainer:168 RmsProp 406 loss=211.327744 err=22.129414
I 2015-05-26 05:25:19 theanets.trainer:168 RmsProp 407 loss=210.990707 err=22.025341
I 2015-05-26 05:26:17 theanets.trainer:168 RmsProp 408 loss=210.539932 err=21.944593
I 2015-05-26 05:27:15 theanets.trainer:168 RmsProp 409 loss=210.371658 err=21.806780
I 2015-05-26 05:28:13 theanets.trainer:168 RmsProp 410 loss=210.415482 err=22.033495
I 2015-05-26 05:28:14 theanets.trainer:168 validation 41 loss=1938.844116 err=1753.172241
I 2015-05-26 05:29:12 theanets.trainer:168 RmsProp 411 loss=217.561569 err=28.158911
I 2015-05-26 05:30:11 theanets.trainer:168 RmsProp 412 loss=213.293472 err=24.074154
I 2015-05-26 05:31:08 theanets.trainer:168 RmsProp 413 loss=210.993332 err=22.343637
I 2015-05-26 05:32:07 theanets.trainer:168 RmsProp 414 loss=212.871384 err=24.603001
I 2015-05-26 05:33:05 theanets.trainer:168 RmsProp 415 loss=209.247803 err=21.711708
I 2015-05-26 05:34:03 theanets.trainer:168 RmsProp 416 loss=209.157272 err=22.168432
I 2015-05-26 05:35:02 theanets.trainer:168 RmsProp 417 loss=208.692734 err=21.953827
I 2015-05-26 05:36:00 theanets.trainer:168 RmsProp 418 loss=207.369064 err=21.207531
I 2015-05-26 05:36:58 theanets.trainer:168 RmsProp 419 loss=207.019272 err=21.054249
I 2015-05-26 05:37:54 theanets.trainer:168 RmsProp 420 loss=206.684982 err=21.085812
I 2015-05-26 05:37:55 theanets.trainer:168 validation 42 loss=1922.373657 err=1739.766479 *
I 2015-05-26 05:38:51 theanets.trainer:168 RmsProp 421 loss=205.738281 err=20.492655
I 2015-05-26 05:39:46 theanets.trainer:168 RmsProp 422 loss=205.633072 err=20.844181
I 2015-05-26 05:40:41 theanets.trainer:168 RmsProp 423 loss=205.131912 err=20.488733
I 2015-05-26 05:41:37 theanets.trainer:168 RmsProp 424 loss=204.952164 err=20.614834
I 2015-05-26 05:42:33 theanets.trainer:168 RmsProp 425 loss=204.097336 err=20.115667
I 2015-05-26 05:43:29 theanets.trainer:168 RmsProp 426 loss=204.046814 err=20.409880
I 2015-05-26 05:44:25 theanets.trainer:168 RmsProp 427 loss=203.139450 err=19.828074
I 2015-05-26 05:45:22 theanets.trainer:168 RmsProp 428 loss=203.200684 err=20.219612
I 2015-05-26 05:46:19 theanets.trainer:168 RmsProp 429 loss=203.200439 err=20.550333
I 2015-05-26 05:47:15 theanets.trainer:168 RmsProp 430 loss=202.222946 err=19.883234
I 2015-05-26 05:47:16 theanets.trainer:168 validation 43 loss=1906.399292 err=1727.129517 *
I 2015-05-26 05:48:13 theanets.trainer:168 RmsProp 431 loss=201.786697 err=19.690466
I 2015-05-26 05:49:10 theanets.trainer:168 RmsProp 432 loss=202.527100 err=20.541697
I 2015-05-26 05:50:06 theanets.trainer:168 RmsProp 433 loss=202.323425 err=20.309967
I 2015-05-26 05:51:03 theanets.trainer:168 RmsProp 434 loss=200.998840 err=19.511602
I 2015-05-26 05:51:59 theanets.trainer:168 RmsProp 435 loss=200.330307 err=19.204988
I 2015-05-26 05:52:55 theanets.trainer:168 RmsProp 436 loss=200.436005 err=19.572321
I 2015-05-26 05:53:51 theanets.trainer:168 RmsProp 437 loss=201.628738 err=21.058659
I 2015-05-26 05:54:47 theanets.trainer:168 RmsProp 438 loss=200.109375 err=19.776924
I 2015-05-26 05:55:43 theanets.trainer:168 RmsProp 439 loss=200.731186 err=20.354235
I 2015-05-26 05:56:40 theanets.trainer:168 RmsProp 440 loss=199.079346 err=19.300650
I 2015-05-26 05:56:41 theanets.trainer:168 validation 44 loss=1941.083618 err=1764.251953
I 2015-05-26 05:57:37 theanets.trainer:168 RmsProp 441 loss=198.671524 err=19.145403
I 2015-05-26 05:58:33 theanets.trainer:168 RmsProp 442 loss=198.750244 err=19.606281
I 2015-05-26 05:59:30 theanets.trainer:168 RmsProp 443 loss=198.619766 err=19.450083
I 2015-05-26 06:00:26 theanets.trainer:168 RmsProp 444 loss=198.915588 err=19.998972
I 2015-05-26 06:01:22 theanets.trainer:168 RmsProp 445 loss=197.296768 err=18.901323
I 2015-05-26 06:02:19 theanets.trainer:168 RmsProp 446 loss=197.095398 err=18.781717
I 2015-05-26 06:03:16 theanets.trainer:168 RmsProp 447 loss=196.833572 err=19.022869
I 2015-05-26 06:04:13 theanets.trainer:168 RmsProp 448 loss=197.874344 err=20.083437
I 2015-05-26 06:05:09 theanets.trainer:168 RmsProp 449 loss=198.019073 err=20.183460
I 2015-05-26 06:06:06 theanets.trainer:168 RmsProp 450 loss=197.885162 err=20.578440
I 2015-05-26 06:06:07 theanets.trainer:168 validation 45 loss=1945.012573 err=1770.534058
I 2015-05-26 06:07:03 theanets.trainer:168 RmsProp 451 loss=199.343292 err=22.127586
I 2015-05-26 06:07:57 theanets.trainer:168 RmsProp 452 loss=196.073212 err=19.290358
I 2015-05-26 06:08:53 theanets.trainer:168 RmsProp 453 loss=195.185074 err=18.698357
I 2015-05-26 06:09:50 theanets.trainer:168 RmsProp 454 loss=195.115540 err=18.991858
I 2015-05-26 06:10:46 theanets.trainer:168 RmsProp 455 loss=194.458023 err=18.530632
I 2015-05-26 06:11:43 theanets.trainer:168 RmsProp 456 loss=193.700378 err=18.020344
I 2015-05-26 06:12:39 theanets.trainer:168 RmsProp 457 loss=193.274323 err=17.971865
I 2015-05-26 06:13:37 theanets.trainer:168 RmsProp 458 loss=192.944565 err=17.793467
I 2015-05-26 06:14:34 theanets.trainer:168 RmsProp 459 loss=192.746384 err=17.997999
I 2015-05-26 06:15:30 theanets.trainer:168 RmsProp 460 loss=192.124527 err=17.611300
I 2015-05-26 06:15:31 theanets.trainer:168 validation 46 loss=1951.747681 err=1780.210938
I 2015-05-26 06:16:29 theanets.trainer:168 RmsProp 461 loss=192.607330 err=18.273542
I 2015-05-26 06:17:27 theanets.trainer:168 RmsProp 462 loss=193.024216 err=18.855070
I 2015-05-26 06:18:24 theanets.trainer:168 RmsProp 463 loss=192.898666 err=18.944386
I 2015-05-26 06:19:20 theanets.trainer:168 RmsProp 464 loss=193.951645 err=20.155754
I 2015-05-26 06:20:15 theanets.trainer:168 RmsProp 465 loss=191.803741 err=18.189301
I 2015-05-26 06:21:10 theanets.trainer:168 RmsProp 466 loss=191.552948 err=18.371099
I 2015-05-26 06:22:07 theanets.trainer:168 RmsProp 467 loss=191.456833 err=18.556799
I 2015-05-26 06:23:03 theanets.trainer:168 RmsProp 468 loss=190.671585 err=18.182735
I 2015-05-26 06:23:59 theanets.trainer:168 RmsProp 469 loss=189.815857 err=17.503120
I 2015-05-26 06:24:55 theanets.trainer:168 RmsProp 470 loss=189.769089 err=17.761040
I 2015-05-26 06:24:56 theanets.trainer:168 validation 47 loss=1934.832886 err=1765.726562
I 2015-05-26 06:25:52 theanets.trainer:168 RmsProp 471 loss=189.646729 err=17.750488
I 2015-05-26 06:26:49 theanets.trainer:168 RmsProp 472 loss=189.193695 err=17.641214
I 2015-05-26 06:27:45 theanets.trainer:168 RmsProp 473 loss=188.876648 err=17.398960
I 2015-05-26 06:28:42 theanets.trainer:168 RmsProp 474 loss=188.764572 err=17.649069
I 2015-05-26 06:29:38 theanets.trainer:168 RmsProp 475 loss=189.153625 err=18.080631
I 2015-05-26 06:30:35 theanets.trainer:168 RmsProp 476 loss=188.353943 err=17.546139
I 2015-05-26 06:31:31 theanets.trainer:168 RmsProp 477 loss=188.632629 err=18.105457
I 2015-05-26 06:32:28 theanets.trainer:168 RmsProp 478 loss=188.547760 err=18.280678
I 2015-05-26 06:33:25 theanets.trainer:168 RmsProp 479 loss=189.171707 err=18.919607
I 2015-05-26 06:34:21 theanets.trainer:168 RmsProp 480 loss=189.703903 err=19.195654
I 2015-05-26 06:34:22 theanets.trainer:168 validation 48 loss=1958.791382 err=1791.049438
I 2015-05-26 06:34:22 theanets.trainer:252 patience elapsed!
I 2015-05-26 06:34:22 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 06:34:22 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 06:34:22 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 06:34:22 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 06:34:22 theanets.main:89 --batch_size = 1024
I 2015-05-26 06:34:22 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 06:34:22 theanets.main:89 --hidden_l1 = 0.01
I 2015-05-26 06:34:22 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 06:34:22 theanets.main:89 --train_batches = 10
I 2015-05-26 06:34:22 theanets.main:89 --valid_batches = 2
I 2015-05-26 06:34:22 theanets.main:89 --weight_l1 = 0.001
I 2015-05-26 06:34:22 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 06:34:22 theanets.trainer:134 compiling evaluation function
I 2015-05-26 06:34:33 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 06:36:24 theanets.trainer:168 validation 0 loss=1448.415161 err=1260.311646 *
I 2015-05-26 06:36:41 theanets.trainer:168 RmsProp 1 loss=200.299042 err=13.766531
I 2015-05-26 06:36:57 theanets.trainer:168 RmsProp 2 loss=194.011917 err=7.614681
I 2015-05-26 06:37:13 theanets.trainer:168 RmsProp 3 loss=191.002335 err=5.267797
I 2015-05-26 06:37:30 theanets.trainer:168 RmsProp 4 loss=189.528671 err=4.228445
I 2015-05-26 06:37:46 theanets.trainer:168 RmsProp 5 loss=188.392990 err=3.636921
I 2015-05-26 06:38:02 theanets.trainer:168 RmsProp 6 loss=187.520584 err=3.208134
I 2015-05-26 06:38:18 theanets.trainer:168 RmsProp 7 loss=186.153580 err=2.887246
I 2015-05-26 06:38:34 theanets.trainer:168 RmsProp 8 loss=184.825790 err=2.579103
I 2015-05-26 06:38:51 theanets.trainer:168 RmsProp 9 loss=183.837494 err=2.347087
I 2015-05-26 06:39:07 theanets.trainer:168 RmsProp 10 loss=182.178879 err=2.094703
I 2015-05-26 06:39:07 theanets.trainer:168 validation 1 loss=1223.593506 err=1042.363647 *
I 2015-05-26 06:39:24 theanets.trainer:168 RmsProp 11 loss=180.925171 err=1.924903
I 2015-05-26 06:39:40 theanets.trainer:168 RmsProp 12 loss=179.853683 err=1.799901
I 2015-05-26 06:39:56 theanets.trainer:168 RmsProp 13 loss=178.670227 err=1.695186
I 2015-05-26 06:40:12 theanets.trainer:168 RmsProp 14 loss=177.761597 err=1.611973
I 2015-05-26 06:40:27 theanets.trainer:168 RmsProp 15 loss=176.321075 err=1.526756
I 2015-05-26 06:40:43 theanets.trainer:168 RmsProp 16 loss=175.529251 err=1.474888
I 2015-05-26 06:40:59 theanets.trainer:168 RmsProp 17 loss=174.299622 err=1.398038
I 2015-05-26 06:41:15 theanets.trainer:168 RmsProp 18 loss=173.525314 err=1.354877
I 2015-05-26 06:41:30 theanets.trainer:168 RmsProp 19 loss=172.602448 err=1.316884
I 2015-05-26 06:41:46 theanets.trainer:168 RmsProp 20 loss=171.526993 err=1.255751
I 2015-05-26 06:41:47 theanets.trainer:168 validation 2 loss=1140.632935 err=968.915649 *
I 2015-05-26 06:42:02 theanets.trainer:168 RmsProp 21 loss=170.779358 err=1.215827
I 2015-05-26 06:42:18 theanets.trainer:168 RmsProp 22 loss=170.044266 err=1.214892
I 2015-05-26 06:42:33 theanets.trainer:168 RmsProp 23 loss=168.818817 err=1.150733
I 2015-05-26 06:42:49 theanets.trainer:168 RmsProp 24 loss=168.291168 err=1.103267
I 2015-05-26 06:43:04 theanets.trainer:168 RmsProp 25 loss=167.578598 err=1.113419
I 2015-05-26 06:43:19 theanets.trainer:168 RmsProp 26 loss=166.702850 err=1.064385
I 2015-05-26 06:43:35 theanets.trainer:168 RmsProp 27 loss=165.690643 err=1.053603
I 2015-05-26 06:43:51 theanets.trainer:168 RmsProp 28 loss=164.902649 err=1.009474
I 2015-05-26 06:44:06 theanets.trainer:168 RmsProp 29 loss=164.270782 err=0.996919
I 2015-05-26 06:44:22 theanets.trainer:168 RmsProp 30 loss=163.852158 err=0.953894
I 2015-05-26 06:44:22 theanets.trainer:168 validation 3 loss=1101.755249 err=937.511719 *
I 2015-05-26 06:44:38 theanets.trainer:168 RmsProp 31 loss=163.259109 err=0.998392
I 2015-05-26 06:44:54 theanets.trainer:168 RmsProp 32 loss=162.455521 err=0.945646
I 2015-05-26 06:45:09 theanets.trainer:168 RmsProp 33 loss=161.732941 err=0.897655
I 2015-05-26 06:45:25 theanets.trainer:168 RmsProp 34 loss=161.164734 err=0.911293
I 2015-05-26 06:45:41 theanets.trainer:168 RmsProp 35 loss=160.519867 err=0.873018
I 2015-05-26 06:45:56 theanets.trainer:168 RmsProp 36 loss=160.071243 err=0.863293
I 2015-05-26 06:46:12 theanets.trainer:168 RmsProp 37 loss=159.094864 err=0.845006
I 2015-05-26 06:46:28 theanets.trainer:168 RmsProp 38 loss=158.443756 err=0.834553
I 2015-05-26 06:46:44 theanets.trainer:168 RmsProp 39 loss=158.039230 err=0.806197
I 2015-05-26 06:46:59 theanets.trainer:168 RmsProp 40 loss=157.436676 err=0.806013
I 2015-05-26 06:47:00 theanets.trainer:168 validation 4 loss=1082.001709 err=923.703308 *
I 2015-05-26 06:47:16 theanets.trainer:168 RmsProp 41 loss=156.841568 err=0.777253
I 2015-05-26 06:47:31 theanets.trainer:168 RmsProp 42 loss=156.177643 err=0.786900
I 2015-05-26 06:47:47 theanets.trainer:168 RmsProp 43 loss=155.665680 err=0.754519
I 2015-05-26 06:48:02 theanets.trainer:168 RmsProp 44 loss=155.185303 err=0.745698
I 2015-05-26 06:48:18 theanets.trainer:168 RmsProp 45 loss=154.696426 err=0.731779
I 2015-05-26 06:48:33 theanets.trainer:168 RmsProp 46 loss=154.202484 err=0.732766
I 2015-05-26 06:48:48 theanets.trainer:168 RmsProp 47 loss=153.696930 err=0.707818
I 2015-05-26 06:49:04 theanets.trainer:168 RmsProp 48 loss=153.191086 err=0.720091
I 2015-05-26 06:49:19 theanets.trainer:168 RmsProp 49 loss=152.534943 err=0.703840
I 2015-05-26 06:49:35 theanets.trainer:168 RmsProp 50 loss=151.982529 err=0.685799
I 2015-05-26 06:49:35 theanets.trainer:168 validation 5 loss=1071.925537 err=918.783386 *
I 2015-05-26 06:49:51 theanets.trainer:168 RmsProp 51 loss=151.572388 err=0.665936
I 2015-05-26 06:50:07 theanets.trainer:168 RmsProp 52 loss=150.992279 err=0.666552
I 2015-05-26 06:50:22 theanets.trainer:168 RmsProp 53 loss=150.604507 err=0.684021
I 2015-05-26 06:50:38 theanets.trainer:168 RmsProp 54 loss=150.097488 err=0.641651
I 2015-05-26 06:50:53 theanets.trainer:168 RmsProp 55 loss=149.708603 err=0.639056
I 2015-05-26 06:51:09 theanets.trainer:168 RmsProp 56 loss=149.222412 err=0.630630
I 2015-05-26 06:51:25 theanets.trainer:168 RmsProp 57 loss=148.352570 err=0.623070
I 2015-05-26 06:51:40 theanets.trainer:168 RmsProp 58 loss=148.300125 err=0.644222
I 2015-05-26 06:51:56 theanets.trainer:168 RmsProp 59 loss=147.879120 err=0.596780
I 2015-05-26 06:52:12 theanets.trainer:168 RmsProp 60 loss=147.482605 err=0.615055
I 2015-05-26 06:52:12 theanets.trainer:168 validation 6 loss=1065.895874 err=917.280090 *
I 2015-05-26 06:52:28 theanets.trainer:168 RmsProp 61 loss=147.030869 err=0.635603
I 2015-05-26 06:52:43 theanets.trainer:168 RmsProp 62 loss=146.540451 err=0.578660
I 2015-05-26 06:52:59 theanets.trainer:168 RmsProp 63 loss=146.128174 err=0.579654
I 2015-05-26 06:53:14 theanets.trainer:168 RmsProp 64 loss=145.830719 err=0.577133
I 2015-05-26 06:53:30 theanets.trainer:168 RmsProp 65 loss=145.155685 err=0.576636
I 2015-05-26 06:53:45 theanets.trainer:168 RmsProp 66 loss=144.958725 err=0.569119
I 2015-05-26 06:54:01 theanets.trainer:168 RmsProp 67 loss=144.619034 err=0.546261
I 2015-05-26 06:54:16 theanets.trainer:168 RmsProp 68 loss=144.065384 err=0.538644
I 2015-05-26 06:54:32 theanets.trainer:168 RmsProp 69 loss=143.505035 err=0.549058
I 2015-05-26 06:54:48 theanets.trainer:168 RmsProp 70 loss=143.153229 err=0.538579
I 2015-05-26 06:54:48 theanets.trainer:168 validation 7 loss=1060.956665 err=916.371887 *
I 2015-05-26 06:55:04 theanets.trainer:168 RmsProp 71 loss=142.951385 err=0.535037
I 2015-05-26 06:55:19 theanets.trainer:168 RmsProp 72 loss=142.688812 err=0.537203
I 2015-05-26 06:55:35 theanets.trainer:168 RmsProp 73 loss=141.999557 err=0.518030
I 2015-05-26 06:55:51 theanets.trainer:168 RmsProp 74 loss=141.606598 err=0.496993
I 2015-05-26 06:56:06 theanets.trainer:168 RmsProp 75 loss=141.430695 err=0.555162
I 2015-05-26 06:56:22 theanets.trainer:168 RmsProp 76 loss=140.761627 err=0.501989
I 2015-05-26 06:56:38 theanets.trainer:168 RmsProp 77 loss=140.556564 err=0.488515
I 2015-05-26 06:56:53 theanets.trainer:168 RmsProp 78 loss=140.145493 err=0.486003
I 2015-05-26 06:57:09 theanets.trainer:168 RmsProp 79 loss=139.708923 err=0.505565
I 2015-05-26 06:57:23 theanets.trainer:168 RmsProp 80 loss=139.283859 err=0.490892
I 2015-05-26 06:57:24 theanets.trainer:168 validation 8 loss=1052.787109 err=911.912903 *
I 2015-05-26 06:57:39 theanets.trainer:168 RmsProp 81 loss=139.047043 err=0.481628
I 2015-05-26 06:57:54 theanets.trainer:168 RmsProp 82 loss=138.457458 err=0.458543
I 2015-05-26 06:58:08 theanets.trainer:168 RmsProp 83 loss=138.378098 err=0.472775
I 2015-05-26 06:58:22 theanets.trainer:168 RmsProp 84 loss=137.857651 err=0.448266
I 2015-05-26 06:58:36 theanets.trainer:168 RmsProp 85 loss=137.764206 err=0.478929
I 2015-05-26 06:58:50 theanets.trainer:168 RmsProp 86 loss=137.298798 err=0.460877
I 2015-05-26 06:59:03 theanets.trainer:168 RmsProp 87 loss=136.870209 err=0.438011
I 2015-05-26 06:59:17 theanets.trainer:168 RmsProp 88 loss=136.619949 err=0.442820
I 2015-05-26 06:59:31 theanets.trainer:168 RmsProp 89 loss=136.198959 err=0.437840
I 2015-05-26 06:59:45 theanets.trainer:168 RmsProp 90 loss=135.958557 err=0.441923
I 2015-05-26 06:59:46 theanets.trainer:168 validation 9 loss=1041.297119 err=903.850769 *
I 2015-05-26 06:59:59 theanets.trainer:168 RmsProp 91 loss=135.855621 err=0.443364
I 2015-05-26 07:00:13 theanets.trainer:168 RmsProp 92 loss=135.089203 err=0.434379
I 2015-05-26 07:00:27 theanets.trainer:168 RmsProp 93 loss=134.875031 err=0.419079
I 2015-05-26 07:00:41 theanets.trainer:168 RmsProp 94 loss=134.663147 err=0.417988
I 2015-05-26 07:00:55 theanets.trainer:168 RmsProp 95 loss=134.447601 err=0.401138
I 2015-05-26 07:01:09 theanets.trainer:168 RmsProp 96 loss=133.804718 err=0.432632
I 2015-05-26 07:01:23 theanets.trainer:168 RmsProp 97 loss=133.612198 err=0.480243
I 2015-05-26 07:01:37 theanets.trainer:168 RmsProp 98 loss=133.402374 err=0.414537
I 2015-05-26 07:01:51 theanets.trainer:168 RmsProp 99 loss=133.158356 err=0.392188
I 2015-05-26 07:02:05 theanets.trainer:168 RmsProp 100 loss=132.907379 err=0.391124
I 2015-05-26 07:02:05 theanets.trainer:168 validation 10 loss=1029.722900 err=895.414001 *
I 2015-05-26 07:02:19 theanets.trainer:168 RmsProp 101 loss=132.304733 err=0.395788
I 2015-05-26 07:02:34 theanets.trainer:168 RmsProp 102 loss=132.118301 err=0.392791
I 2015-05-26 07:02:47 theanets.trainer:168 RmsProp 103 loss=131.659470 err=0.383356
I 2015-05-26 07:03:02 theanets.trainer:168 RmsProp 104 loss=131.480637 err=0.390321
I 2015-05-26 07:03:16 theanets.trainer:168 RmsProp 105 loss=131.141327 err=0.372701
I 2015-05-26 07:03:30 theanets.trainer:168 RmsProp 106 loss=130.881683 err=0.383311
I 2015-05-26 07:03:44 theanets.trainer:168 RmsProp 107 loss=130.628265 err=0.367800
I 2015-05-26 07:03:58 theanets.trainer:168 RmsProp 108 loss=130.274063 err=0.378499
I 2015-05-26 07:04:12 theanets.trainer:168 RmsProp 109 loss=129.890869 err=0.355147
I 2015-05-26 07:04:26 theanets.trainer:168 RmsProp 110 loss=129.681564 err=0.371798
I 2015-05-26 07:04:27 theanets.trainer:168 validation 11 loss=1016.914612 err=885.692810 *
I 2015-05-26 07:04:41 theanets.trainer:168 RmsProp 111 loss=129.300430 err=0.357771
I 2015-05-26 07:04:54 theanets.trainer:168 RmsProp 112 loss=129.079880 err=0.366907
I 2015-05-26 07:05:08 theanets.trainer:168 RmsProp 113 loss=128.682617 err=0.354450
I 2015-05-26 07:05:22 theanets.trainer:168 RmsProp 114 loss=128.071228 err=0.356579
I 2015-05-26 07:05:35 theanets.trainer:168 RmsProp 115 loss=128.216034 err=0.352722
I 2015-05-26 07:05:49 theanets.trainer:168 RmsProp 116 loss=127.862564 err=0.345591
I 2015-05-26 07:06:02 theanets.trainer:168 RmsProp 117 loss=127.612465 err=0.339791
I 2015-05-26 07:06:15 theanets.trainer:168 RmsProp 118 loss=127.389420 err=0.360256
I 2015-05-26 07:06:29 theanets.trainer:168 RmsProp 119 loss=126.882790 err=0.342081
I 2015-05-26 07:06:42 theanets.trainer:168 RmsProp 120 loss=126.711166 err=0.327389
I 2015-05-26 07:06:43 theanets.trainer:168 validation 12 loss=1005.845093 err=877.499634 *
I 2015-05-26 07:06:57 theanets.trainer:168 RmsProp 121 loss=126.434387 err=0.349310
I 2015-05-26 07:07:11 theanets.trainer:168 RmsProp 122 loss=125.993958 err=0.322402
I 2015-05-26 07:07:25 theanets.trainer:168 RmsProp 123 loss=125.837646 err=0.352917
I 2015-05-26 07:07:40 theanets.trainer:168 RmsProp 124 loss=125.827332 err=0.324865
I 2015-05-26 07:07:54 theanets.trainer:168 RmsProp 125 loss=125.291725 err=0.332090
I 2015-05-26 07:08:08 theanets.trainer:168 RmsProp 126 loss=125.121277 err=0.325946
I 2015-05-26 07:08:22 theanets.trainer:168 RmsProp 127 loss=124.914780 err=0.319087
I 2015-05-26 07:08:36 theanets.trainer:168 RmsProp 128 loss=124.775597 err=0.325386
I 2015-05-26 07:08:50 theanets.trainer:168 RmsProp 129 loss=124.499840 err=0.321992
I 2015-05-26 07:09:04 theanets.trainer:168 RmsProp 130 loss=124.004349 err=0.316812
I 2015-05-26 07:09:05 theanets.trainer:168 validation 13 loss=992.342224 err=866.753723 *
I 2015-05-26 07:09:19 theanets.trainer:168 RmsProp 131 loss=123.628807 err=0.307524
I 2015-05-26 07:09:33 theanets.trainer:168 RmsProp 132 loss=123.629196 err=0.309886
I 2015-05-26 07:09:47 theanets.trainer:168 RmsProp 133 loss=123.257767 err=0.315772
I 2015-05-26 07:10:01 theanets.trainer:168 RmsProp 134 loss=123.023376 err=0.307716
I 2015-05-26 07:10:15 theanets.trainer:168 RmsProp 135 loss=122.586746 err=0.296003
I 2015-05-26 07:10:30 theanets.trainer:168 RmsProp 136 loss=122.299911 err=0.300243
I 2015-05-26 07:10:43 theanets.trainer:168 RmsProp 137 loss=122.231834 err=0.295357
I 2015-05-26 07:10:57 theanets.trainer:168 RmsProp 138 loss=121.870346 err=0.313557
I 2015-05-26 07:11:11 theanets.trainer:168 RmsProp 139 loss=121.559006 err=0.291352
I 2015-05-26 07:11:26 theanets.trainer:168 RmsProp 140 loss=121.300133 err=0.283115
I 2015-05-26 07:11:26 theanets.trainer:168 validation 14 loss=980.172729 err=857.178223 *
I 2015-05-26 07:11:40 theanets.trainer:168 RmsProp 141 loss=121.108658 err=0.294131
I 2015-05-26 07:11:54 theanets.trainer:168 RmsProp 142 loss=120.898155 err=0.296558
I 2015-05-26 07:12:07 theanets.trainer:168 RmsProp 143 loss=120.514648 err=0.284437
I 2015-05-26 07:12:21 theanets.trainer:168 RmsProp 144 loss=120.557999 err=0.286727
I 2015-05-26 07:12:34 theanets.trainer:168 RmsProp 145 loss=120.064491 err=0.288862
I 2015-05-26 07:12:48 theanets.trainer:168 RmsProp 146 loss=119.938332 err=0.282845
I 2015-05-26 07:13:01 theanets.trainer:168 RmsProp 147 loss=119.623123 err=0.271338
I 2015-05-26 07:13:15 theanets.trainer:168 RmsProp 148 loss=119.471268 err=0.268309
I 2015-05-26 07:13:28 theanets.trainer:168 RmsProp 149 loss=119.203537 err=0.300399
I 2015-05-26 07:13:42 theanets.trainer:168 RmsProp 150 loss=118.819168 err=0.271509
I 2015-05-26 07:13:42 theanets.trainer:168 validation 15 loss=967.784546 err=847.295349 *
I 2015-05-26 07:13:56 theanets.trainer:168 RmsProp 151 loss=118.605247 err=0.263940
I 2015-05-26 07:14:10 theanets.trainer:168 RmsProp 152 loss=118.292030 err=0.276750
I 2015-05-26 07:14:24 theanets.trainer:168 RmsProp 153 loss=118.376114 err=0.260930
I 2015-05-26 07:14:38 theanets.trainer:168 RmsProp 154 loss=117.818726 err=0.262942
I 2015-05-26 07:14:51 theanets.trainer:168 RmsProp 155 loss=117.654945 err=0.258846
I 2015-05-26 07:15:05 theanets.trainer:168 RmsProp 156 loss=117.634239 err=0.272563
I 2015-05-26 07:15:19 theanets.trainer:168 RmsProp 157 loss=117.265175 err=0.249072
I 2015-05-26 07:15:33 theanets.trainer:168 RmsProp 158 loss=117.381668 err=0.263359
I 2015-05-26 07:15:46 theanets.trainer:168 RmsProp 159 loss=116.953995 err=0.270177
I 2015-05-26 07:16:00 theanets.trainer:168 RmsProp 160 loss=116.416000 err=0.248063
I 2015-05-26 07:16:01 theanets.trainer:168 validation 16 loss=957.485474 err=839.342285 *
I 2015-05-26 07:16:15 theanets.trainer:168 RmsProp 161 loss=116.263260 err=0.253055
I 2015-05-26 07:16:28 theanets.trainer:168 RmsProp 162 loss=115.801514 err=0.257947
I 2015-05-26 07:16:42 theanets.trainer:168 RmsProp 163 loss=115.875290 err=0.247743
I 2015-05-26 07:16:56 theanets.trainer:168 RmsProp 164 loss=115.589561 err=0.244483
I 2015-05-26 07:17:10 theanets.trainer:168 RmsProp 165 loss=115.504066 err=0.257012
I 2015-05-26 07:17:24 theanets.trainer:168 RmsProp 166 loss=115.207840 err=0.232001
I 2015-05-26 07:17:37 theanets.trainer:168 RmsProp 167 loss=114.940758 err=0.264292
I 2015-05-26 07:17:51 theanets.trainer:168 RmsProp 168 loss=114.803574 err=0.244666
I 2015-05-26 07:18:05 theanets.trainer:168 RmsProp 169 loss=114.663406 err=0.240790
I 2015-05-26 07:18:18 theanets.trainer:168 RmsProp 170 loss=114.232590 err=0.255202
I 2015-05-26 07:18:19 theanets.trainer:168 validation 17 loss=947.553467 err=831.656067 *
I 2015-05-26 07:18:33 theanets.trainer:168 RmsProp 171 loss=114.318504 err=0.242513
I 2015-05-26 07:18:47 theanets.trainer:168 RmsProp 172 loss=113.784927 err=0.236388
I 2015-05-26 07:19:00 theanets.trainer:168 RmsProp 173 loss=113.601517 err=0.243830
I 2015-05-26 07:19:14 theanets.trainer:168 RmsProp 174 loss=113.396423 err=0.240166
I 2015-05-26 07:19:28 theanets.trainer:168 RmsProp 175 loss=113.363441 err=0.232686
I 2015-05-26 07:19:42 theanets.trainer:168 RmsProp 176 loss=113.155930 err=0.230179
I 2015-05-26 07:19:56 theanets.trainer:168 RmsProp 177 loss=112.863846 err=0.248874
I 2015-05-26 07:20:10 theanets.trainer:168 RmsProp 178 loss=112.651344 err=0.227095
I 2015-05-26 07:20:24 theanets.trainer:168 RmsProp 179 loss=112.060730 err=0.225262
I 2015-05-26 07:20:38 theanets.trainer:168 RmsProp 180 loss=112.179237 err=0.231716
I 2015-05-26 07:20:39 theanets.trainer:168 validation 18 loss=938.783203 err=825.011169 *
I 2015-05-26 07:20:52 theanets.trainer:168 RmsProp 181 loss=111.993149 err=0.222377
I 2015-05-26 07:21:06 theanets.trainer:168 RmsProp 182 loss=111.687157 err=0.233624
I 2015-05-26 07:21:20 theanets.trainer:168 RmsProp 183 loss=111.714478 err=0.225048
I 2015-05-26 07:21:34 theanets.trainer:168 RmsProp 184 loss=111.353653 err=0.226400
I 2015-05-26 07:21:47 theanets.trainer:168 RmsProp 185 loss=111.322571 err=0.221689
I 2015-05-26 07:22:01 theanets.trainer:168 RmsProp 186 loss=110.864220 err=0.217869
I 2015-05-26 07:22:15 theanets.trainer:168 RmsProp 187 loss=110.646652 err=0.205277
I 2015-05-26 07:22:29 theanets.trainer:168 RmsProp 188 loss=110.626114 err=0.235659
I 2015-05-26 07:22:43 theanets.trainer:168 RmsProp 189 loss=110.352989 err=0.219919
I 2015-05-26 07:22:57 theanets.trainer:168 RmsProp 190 loss=110.334839 err=0.204421
I 2015-05-26 07:22:58 theanets.trainer:168 validation 19 loss=931.485962 err=819.738098 *
I 2015-05-26 07:23:12 theanets.trainer:168 RmsProp 191 loss=109.745590 err=0.237166
I 2015-05-26 07:23:26 theanets.trainer:168 RmsProp 192 loss=109.791847 err=0.206146
I 2015-05-26 07:23:40 theanets.trainer:168 RmsProp 193 loss=109.531448 err=0.212658
I 2015-05-26 07:23:54 theanets.trainer:168 RmsProp 194 loss=109.252304 err=0.212001
I 2015-05-26 07:24:08 theanets.trainer:168 RmsProp 195 loss=109.397461 err=0.210592
I 2015-05-26 07:24:22 theanets.trainer:168 RmsProp 196 loss=109.000473 err=0.213933
I 2015-05-26 07:24:36 theanets.trainer:168 RmsProp 197 loss=108.629494 err=0.209573
I 2015-05-26 07:24:50 theanets.trainer:168 RmsProp 198 loss=108.655594 err=0.205962
I 2015-05-26 07:25:03 theanets.trainer:168 RmsProp 199 loss=108.421677 err=0.204891
I 2015-05-26 07:25:17 theanets.trainer:168 RmsProp 200 loss=108.163658 err=0.213169
I 2015-05-26 07:25:17 theanets.trainer:168 validation 20 loss=923.299133 err=813.540833 *
I 2015-05-26 07:25:31 theanets.trainer:168 RmsProp 201 loss=108.067184 err=0.212631
I 2015-05-26 07:25:44 theanets.trainer:168 RmsProp 202 loss=107.981789 err=0.203546
I 2015-05-26 07:25:57 theanets.trainer:168 RmsProp 203 loss=107.716469 err=0.211861
I 2015-05-26 07:26:11 theanets.trainer:168 RmsProp 204 loss=107.532631 err=0.201894
I 2015-05-26 07:26:24 theanets.trainer:168 RmsProp 205 loss=107.506691 err=0.201458
I 2015-05-26 07:26:37 theanets.trainer:168 RmsProp 206 loss=107.097900 err=0.210986
I 2015-05-26 07:26:50 theanets.trainer:168 RmsProp 207 loss=106.941605 err=0.192096
I 2015-05-26 07:27:03 theanets.trainer:168 RmsProp 208 loss=106.749619 err=0.207798
I 2015-05-26 07:27:16 theanets.trainer:168 RmsProp 209 loss=106.728378 err=0.208792
I 2015-05-26 07:27:28 theanets.trainer:168 RmsProp 210 loss=106.460777 err=0.202229
I 2015-05-26 07:27:29 theanets.trainer:168 validation 21 loss=917.436951 err=809.515076 *
I 2015-05-26 07:27:42 theanets.trainer:168 RmsProp 211 loss=106.178421 err=0.197018
I 2015-05-26 07:27:55 theanets.trainer:168 RmsProp 212 loss=105.974770 err=0.203317
I 2015-05-26 07:28:07 theanets.trainer:168 RmsProp 213 loss=105.836082 err=0.185918
I 2015-05-26 07:28:20 theanets.trainer:168 RmsProp 214 loss=105.767151 err=0.215672
I 2015-05-26 07:28:32 theanets.trainer:168 RmsProp 215 loss=105.592407 err=0.186238
I 2015-05-26 07:28:45 theanets.trainer:168 RmsProp 216 loss=105.298630 err=0.199903
I 2015-05-26 07:28:58 theanets.trainer:168 RmsProp 217 loss=105.062439 err=0.201570
I 2015-05-26 07:29:11 theanets.trainer:168 RmsProp 218 loss=104.974144 err=0.191474
I 2015-05-26 07:29:24 theanets.trainer:168 RmsProp 219 loss=104.930641 err=0.195117
I 2015-05-26 07:29:36 theanets.trainer:168 RmsProp 220 loss=104.534164 err=0.194950
I 2015-05-26 07:29:37 theanets.trainer:168 validation 22 loss=912.233459 err=806.069336 *
I 2015-05-26 07:29:50 theanets.trainer:168 RmsProp 221 loss=104.615822 err=0.181953
I 2015-05-26 07:30:03 theanets.trainer:168 RmsProp 222 loss=104.254395 err=0.200526
I 2015-05-26 07:30:16 theanets.trainer:168 RmsProp 223 loss=104.122780 err=0.192798
I 2015-05-26 07:30:29 theanets.trainer:168 RmsProp 224 loss=104.003342 err=0.175466
I 2015-05-26 07:30:42 theanets.trainer:168 RmsProp 225 loss=103.778709 err=0.222847
I 2015-05-26 07:30:54 theanets.trainer:168 RmsProp 226 loss=103.625572 err=0.211959
I 2015-05-26 07:31:07 theanets.trainer:168 RmsProp 227 loss=103.316910 err=0.180181
I 2015-05-26 07:31:20 theanets.trainer:168 RmsProp 228 loss=103.246872 err=0.183541
I 2015-05-26 07:31:33 theanets.trainer:168 RmsProp 229 loss=103.154861 err=0.200984
I 2015-05-26 07:31:45 theanets.trainer:168 RmsProp 230 loss=103.027908 err=0.176975
I 2015-05-26 07:31:46 theanets.trainer:168 validation 23 loss=906.684143 err=802.218689 *
I 2015-05-26 07:31:58 theanets.trainer:168 RmsProp 231 loss=102.819603 err=0.192594
I 2015-05-26 07:32:11 theanets.trainer:168 RmsProp 232 loss=102.426453 err=0.209150
I 2015-05-26 07:32:23 theanets.trainer:168 RmsProp 233 loss=102.524452 err=0.175084
I 2015-05-26 07:32:36 theanets.trainer:168 RmsProp 234 loss=102.125748 err=0.193144
I 2015-05-26 07:32:48 theanets.trainer:168 RmsProp 235 loss=101.981941 err=0.195916
I 2015-05-26 07:32:59 theanets.trainer:168 RmsProp 236 loss=102.041916 err=0.179809
I 2015-05-26 07:33:12 theanets.trainer:168 RmsProp 237 loss=101.991585 err=0.184083
I 2015-05-26 07:33:24 theanets.trainer:168 RmsProp 238 loss=101.563629 err=0.181352
I 2015-05-26 07:33:37 theanets.trainer:168 RmsProp 239 loss=101.359108 err=0.173229
I 2015-05-26 07:33:50 theanets.trainer:168 RmsProp 240 loss=101.337990 err=0.179959
I 2015-05-26 07:33:51 theanets.trainer:168 validation 24 loss=901.581970 err=798.758972 *
I 2015-05-26 07:34:03 theanets.trainer:168 RmsProp 241 loss=101.442551 err=0.177023
I 2015-05-26 07:34:16 theanets.trainer:168 RmsProp 242 loss=101.069107 err=0.186667
I 2015-05-26 07:34:29 theanets.trainer:168 RmsProp 243 loss=100.879265 err=0.185044
I 2015-05-26 07:34:42 theanets.trainer:168 RmsProp 244 loss=100.580276 err=0.165367
I 2015-05-26 07:34:54 theanets.trainer:168 RmsProp 245 loss=100.479744 err=0.179394
I 2015-05-26 07:35:07 theanets.trainer:168 RmsProp 246 loss=100.447807 err=0.175887
I 2015-05-26 07:35:20 theanets.trainer:168 RmsProp 247 loss=100.271896 err=0.180264
I 2015-05-26 07:35:32 theanets.trainer:168 RmsProp 248 loss=100.162758 err=0.172295
I 2015-05-26 07:35:45 theanets.trainer:168 RmsProp 249 loss=100.005051 err=0.177017
I 2015-05-26 07:35:57 theanets.trainer:168 RmsProp 250 loss=99.886154 err=0.174381
I 2015-05-26 07:35:58 theanets.trainer:168 validation 25 loss=896.628052 err=795.386475 *
I 2015-05-26 07:36:11 theanets.trainer:168 RmsProp 251 loss=99.636818 err=0.186637
I 2015-05-26 07:36:23 theanets.trainer:168 RmsProp 252 loss=99.695976 err=0.172676
I 2015-05-26 07:36:36 theanets.trainer:168 RmsProp 253 loss=99.385948 err=0.174404
I 2015-05-26 07:36:48 theanets.trainer:168 RmsProp 254 loss=99.182968 err=0.176571
I 2015-05-26 07:37:01 theanets.trainer:168 RmsProp 255 loss=98.824203 err=0.176153
I 2015-05-26 07:37:13 theanets.trainer:168 RmsProp 256 loss=98.716965 err=0.170586
I 2015-05-26 07:37:26 theanets.trainer:168 RmsProp 257 loss=98.739250 err=0.171848
I 2015-05-26 07:37:39 theanets.trainer:168 RmsProp 258 loss=98.564354 err=0.174556
I 2015-05-26 07:37:52 theanets.trainer:168 RmsProp 259 loss=98.371185 err=0.175292
I 2015-05-26 07:38:05 theanets.trainer:168 RmsProp 260 loss=98.156654 err=0.174720
I 2015-05-26 07:38:05 theanets.trainer:168 validation 26 loss=892.595276 err=792.854187 *
I 2015-05-26 07:38:18 theanets.trainer:168 RmsProp 261 loss=98.104134 err=0.168476
I 2015-05-26 07:38:31 theanets.trainer:168 RmsProp 262 loss=97.975548 err=0.166682
I 2015-05-26 07:38:43 theanets.trainer:168 RmsProp 263 loss=97.708733 err=0.165468
I 2015-05-26 07:38:56 theanets.trainer:168 RmsProp 264 loss=97.660271 err=0.162827
I 2015-05-26 07:39:09 theanets.trainer:168 RmsProp 265 loss=97.491104 err=0.174232
I 2015-05-26 07:39:22 theanets.trainer:168 RmsProp 266 loss=97.447395 err=0.164942
I 2015-05-26 07:39:35 theanets.trainer:168 RmsProp 267 loss=97.240829 err=0.171690
I 2015-05-26 07:39:47 theanets.trainer:168 RmsProp 268 loss=96.929619 err=0.160929
I 2015-05-26 07:40:01 theanets.trainer:168 RmsProp 269 loss=96.971169 err=0.180485
I 2015-05-26 07:40:14 theanets.trainer:168 RmsProp 270 loss=96.928421 err=0.168814
I 2015-05-26 07:40:14 theanets.trainer:168 validation 27 loss=888.134644 err=789.838074 *
I 2015-05-26 07:40:28 theanets.trainer:168 RmsProp 271 loss=96.774155 err=0.165451
I 2015-05-26 07:40:41 theanets.trainer:168 RmsProp 272 loss=96.359642 err=0.174689
I 2015-05-26 07:40:54 theanets.trainer:168 RmsProp 273 loss=96.347626 err=0.168563
I 2015-05-26 07:41:07 theanets.trainer:168 RmsProp 274 loss=96.243149 err=0.157949
I 2015-05-26 07:41:20 theanets.trainer:168 RmsProp 275 loss=96.252213 err=0.172883
I 2015-05-26 07:41:33 theanets.trainer:168 RmsProp 276 loss=95.992363 err=0.159952
I 2015-05-26 07:41:46 theanets.trainer:168 RmsProp 277 loss=95.993484 err=0.168863
I 2015-05-26 07:41:59 theanets.trainer:168 RmsProp 278 loss=95.798027 err=0.164141
I 2015-05-26 07:42:12 theanets.trainer:168 RmsProp 279 loss=95.604004 err=0.161246
I 2015-05-26 07:42:25 theanets.trainer:168 RmsProp 280 loss=95.399849 err=0.162465
I 2015-05-26 07:42:25 theanets.trainer:168 validation 28 loss=884.095703 err=787.202332 *
I 2015-05-26 07:42:38 theanets.trainer:168 RmsProp 281 loss=95.341629 err=0.163581
I 2015-05-26 07:42:51 theanets.trainer:168 RmsProp 282 loss=95.345833 err=0.170614
I 2015-05-26 07:43:04 theanets.trainer:168 RmsProp 283 loss=95.067635 err=0.157604
I 2015-05-26 07:43:17 theanets.trainer:168 RmsProp 284 loss=94.863541 err=0.161626
I 2015-05-26 07:43:29 theanets.trainer:168 RmsProp 285 loss=94.881172 err=0.166421
I 2015-05-26 07:43:41 theanets.trainer:168 RmsProp 286 loss=94.577415 err=0.156407
I 2015-05-26 07:43:54 theanets.trainer:168 RmsProp 287 loss=94.337341 err=0.170024
I 2015-05-26 07:44:06 theanets.trainer:168 RmsProp 288 loss=94.436264 err=0.166327
I 2015-05-26 07:44:19 theanets.trainer:168 RmsProp 289 loss=94.361221 err=0.163788
I 2015-05-26 07:44:31 theanets.trainer:168 RmsProp 290 loss=94.183136 err=0.158746
I 2015-05-26 07:44:32 theanets.trainer:168 validation 29 loss=880.297058 err=784.766113 *
I 2015-05-26 07:44:44 theanets.trainer:168 RmsProp 291 loss=93.898407 err=0.161874
I 2015-05-26 07:44:56 theanets.trainer:168 RmsProp 292 loss=93.610657 err=0.154889
I 2015-05-26 07:45:08 theanets.trainer:168 RmsProp 293 loss=93.582489 err=0.159524
I 2015-05-26 07:45:21 theanets.trainer:168 RmsProp 294 loss=93.725685 err=0.162467
I 2015-05-26 07:45:33 theanets.trainer:168 RmsProp 295 loss=93.567795 err=0.157289
I 2015-05-26 07:45:45 theanets.trainer:168 RmsProp 296 loss=93.269287 err=0.164365
I 2015-05-26 07:45:58 theanets.trainer:168 RmsProp 297 loss=93.129341 err=0.167715
I 2015-05-26 07:46:10 theanets.trainer:168 RmsProp 298 loss=93.044388 err=0.151885
I 2015-05-26 07:46:23 theanets.trainer:168 RmsProp 299 loss=92.959709 err=0.163237
I 2015-05-26 07:46:35 theanets.trainer:168 RmsProp 300 loss=93.045761 err=0.157848
I 2015-05-26 07:46:36 theanets.trainer:168 validation 30 loss=876.110107 err=781.884827 *
I 2015-05-26 07:46:48 theanets.trainer:168 RmsProp 301 loss=92.670799 err=0.161433
I 2015-05-26 07:47:00 theanets.trainer:168 RmsProp 302 loss=92.463295 err=0.151851
I 2015-05-26 07:47:13 theanets.trainer:168 RmsProp 303 loss=92.401505 err=0.164879
I 2015-05-26 07:47:25 theanets.trainer:168 RmsProp 304 loss=92.353775 err=0.157721
I 2015-05-26 07:47:38 theanets.trainer:168 RmsProp 305 loss=92.262672 err=0.158701
I 2015-05-26 07:47:50 theanets.trainer:168 RmsProp 306 loss=92.011772 err=0.144782
I 2015-05-26 07:48:03 theanets.trainer:168 RmsProp 307 loss=91.973282 err=0.167052
I 2015-05-26 07:48:15 theanets.trainer:168 RmsProp 308 loss=91.869370 err=0.150821
I 2015-05-26 07:48:27 theanets.trainer:168 RmsProp 309 loss=91.572891 err=0.158686
I 2015-05-26 07:48:39 theanets.trainer:168 RmsProp 310 loss=91.574409 err=0.154624
I 2015-05-26 07:48:40 theanets.trainer:168 validation 31 loss=873.025452 err=780.054688 *
I 2015-05-26 07:48:52 theanets.trainer:168 RmsProp 311 loss=91.274162 err=0.160110
I 2015-05-26 07:49:04 theanets.trainer:168 RmsProp 312 loss=91.343002 err=0.159607
I 2015-05-26 07:49:17 theanets.trainer:168 RmsProp 313 loss=91.016342 err=0.143614
I 2015-05-26 07:49:29 theanets.trainer:168 RmsProp 314 loss=91.075439 err=0.162562
I 2015-05-26 07:49:41 theanets.trainer:168 RmsProp 315 loss=90.987106 err=0.153679
I 2015-05-26 07:49:53 theanets.trainer:168 RmsProp 316 loss=90.892715 err=0.167875
I 2015-05-26 07:50:05 theanets.trainer:168 RmsProp 317 loss=90.718307 err=0.153397
I 2015-05-26 07:50:17 theanets.trainer:168 RmsProp 318 loss=90.461746 err=0.156787
I 2015-05-26 07:50:28 theanets.trainer:168 RmsProp 319 loss=90.447952 err=0.157617
I 2015-05-26 07:50:40 theanets.trainer:168 RmsProp 320 loss=90.473373 err=0.149564
I 2015-05-26 07:50:41 theanets.trainer:168 validation 32 loss=869.212708 err=777.480896 *
I 2015-05-26 07:50:52 theanets.trainer:168 RmsProp 321 loss=90.148911 err=0.151039
I 2015-05-26 07:51:04 theanets.trainer:168 RmsProp 322 loss=90.137688 err=0.156410
I 2015-05-26 07:51:16 theanets.trainer:168 RmsProp 323 loss=89.939621 err=0.160928
I 2015-05-26 07:51:27 theanets.trainer:168 RmsProp 324 loss=89.635811 err=0.163651
I 2015-05-26 07:51:39 theanets.trainer:168 RmsProp 325 loss=89.862587 err=0.148635
I 2015-05-26 07:51:50 theanets.trainer:168 RmsProp 326 loss=89.711838 err=0.155014
I 2015-05-26 07:52:02 theanets.trainer:168 RmsProp 327 loss=89.584160 err=0.153590
I 2015-05-26 07:52:15 theanets.trainer:168 RmsProp 328 loss=89.452843 err=0.157122
I 2015-05-26 07:52:27 theanets.trainer:168 RmsProp 329 loss=89.450378 err=0.150076
I 2015-05-26 07:52:39 theanets.trainer:168 RmsProp 330 loss=89.026459 err=0.151940
I 2015-05-26 07:52:40 theanets.trainer:168 validation 33 loss=866.272156 err=775.704590 *
I 2015-05-26 07:52:52 theanets.trainer:168 RmsProp 331 loss=88.998734 err=0.160063
I 2015-05-26 07:53:04 theanets.trainer:168 RmsProp 332 loss=89.066116 err=0.148289
I 2015-05-26 07:53:17 theanets.trainer:168 RmsProp 333 loss=88.836472 err=0.156447
I 2015-05-26 07:53:29 theanets.trainer:168 RmsProp 334 loss=88.770981 err=0.156017
I 2015-05-26 07:53:41 theanets.trainer:168 RmsProp 335 loss=88.618126 err=0.147685
I 2015-05-26 07:53:54 theanets.trainer:168 RmsProp 336 loss=88.582352 err=0.157123
I 2015-05-26 07:54:06 theanets.trainer:168 RmsProp 337 loss=88.404709 err=0.153241
I 2015-05-26 07:54:18 theanets.trainer:168 RmsProp 338 loss=88.162605 err=0.150687
I 2015-05-26 07:54:31 theanets.trainer:168 RmsProp 339 loss=88.010918 err=0.151453
I 2015-05-26 07:54:43 theanets.trainer:168 RmsProp 340 loss=87.965553 err=0.144985
I 2015-05-26 07:54:44 theanets.trainer:168 validation 34 loss=863.169067 err=773.767090 *
I 2015-05-26 07:54:56 theanets.trainer:168 RmsProp 341 loss=88.037056 err=0.152604
I 2015-05-26 07:55:09 theanets.trainer:168 RmsProp 342 loss=87.780296 err=0.159262
I 2015-05-26 07:55:21 theanets.trainer:168 RmsProp 343 loss=87.598633 err=0.142982
I 2015-05-26 07:55:33 theanets.trainer:168 RmsProp 344 loss=87.510742 err=0.157757
I 2015-05-26 07:55:46 theanets.trainer:168 RmsProp 345 loss=87.418045 err=0.151673
I 2015-05-26 07:55:58 theanets.trainer:168 RmsProp 346 loss=87.282196 err=0.154936
I 2015-05-26 07:56:10 theanets.trainer:168 RmsProp 347 loss=87.480331 err=0.153433
I 2015-05-26 07:56:23 theanets.trainer:168 RmsProp 348 loss=87.088272 err=0.151931
I 2015-05-26 07:56:35 theanets.trainer:168 RmsProp 349 loss=86.989136 err=0.143014
I 2015-05-26 07:56:47 theanets.trainer:168 RmsProp 350 loss=86.964836 err=0.161354
I 2015-05-26 07:56:48 theanets.trainer:168 validation 35 loss=860.909424 err=772.604858 *
I 2015-05-26 07:57:00 theanets.trainer:168 RmsProp 351 loss=86.827782 err=0.154341
I 2015-05-26 07:57:12 theanets.trainer:168 RmsProp 352 loss=86.808357 err=0.143271
I 2015-05-26 07:57:25 theanets.trainer:168 RmsProp 353 loss=86.605377 err=0.159344
I 2015-05-26 07:57:37 theanets.trainer:168 RmsProp 354 loss=86.618065 err=0.161360
I 2015-05-26 07:57:49 theanets.trainer:168 RmsProp 355 loss=86.379532 err=0.147079
I 2015-05-26 07:58:02 theanets.trainer:168 RmsProp 356 loss=86.192032 err=0.153960
I 2015-05-26 07:58:13 theanets.trainer:168 RmsProp 357 loss=86.051590 err=0.143610
I 2015-05-26 07:58:25 theanets.trainer:168 RmsProp 358 loss=86.262634 err=0.156231
I 2015-05-26 07:58:37 theanets.trainer:168 RmsProp 359 loss=85.995033 err=0.148270
I 2015-05-26 07:58:49 theanets.trainer:168 RmsProp 360 loss=85.983742 err=0.152717
I 2015-05-26 07:58:49 theanets.trainer:168 validation 36 loss=859.161865 err=771.895691 *
I 2015-05-26 07:59:01 theanets.trainer:168 RmsProp 361 loss=85.767418 err=0.152159
I 2015-05-26 07:59:13 theanets.trainer:168 RmsProp 362 loss=85.601082 err=0.153803
I 2015-05-26 07:59:24 theanets.trainer:168 RmsProp 363 loss=85.531677 err=0.149442
I 2015-05-26 07:59:36 theanets.trainer:168 RmsProp 364 loss=85.644150 err=0.161051
I 2015-05-26 07:59:48 theanets.trainer:168 RmsProp 365 loss=85.401016 err=0.152551
I 2015-05-26 08:00:01 theanets.trainer:168 RmsProp 366 loss=85.511658 err=0.148899
I 2015-05-26 08:00:13 theanets.trainer:168 RmsProp 367 loss=85.109550 err=0.152578
I 2015-05-26 08:00:26 theanets.trainer:168 RmsProp 368 loss=84.971970 err=0.153325
I 2015-05-26 08:00:39 theanets.trainer:168 RmsProp 369 loss=85.051346 err=0.155974
I 2015-05-26 08:00:51 theanets.trainer:168 RmsProp 370 loss=84.914871 err=0.147344
I 2015-05-26 08:00:52 theanets.trainer:168 validation 37 loss=857.076294 err=770.823669 *
I 2015-05-26 08:01:05 theanets.trainer:168 RmsProp 371 loss=84.919235 err=0.155872
I 2015-05-26 08:01:17 theanets.trainer:168 RmsProp 372 loss=84.718147 err=0.148139
I 2015-05-26 08:01:30 theanets.trainer:168 RmsProp 373 loss=84.678566 err=0.153068
I 2015-05-26 08:01:42 theanets.trainer:168 RmsProp 374 loss=84.505997 err=0.159314
I 2015-05-26 08:01:54 theanets.trainer:168 RmsProp 375 loss=84.227768 err=0.145965
I 2015-05-26 08:02:05 theanets.trainer:168 RmsProp 376 loss=84.384407 err=0.145128
I 2015-05-26 08:02:16 theanets.trainer:168 RmsProp 377 loss=84.172318 err=0.149653
I 2015-05-26 08:02:27 theanets.trainer:168 RmsProp 378 loss=84.188248 err=0.159503
I 2015-05-26 08:02:38 theanets.trainer:168 RmsProp 379 loss=84.064041 err=0.143701
I 2015-05-26 08:02:49 theanets.trainer:168 RmsProp 380 loss=84.152313 err=0.145462
I 2015-05-26 08:02:49 theanets.trainer:168 validation 38 loss=854.808777 err=769.536133 *
I 2015-05-26 08:03:00 theanets.trainer:168 RmsProp 381 loss=84.031021 err=0.154883
I 2015-05-26 08:03:11 theanets.trainer:168 RmsProp 382 loss=83.734009 err=0.145518
I 2015-05-26 08:03:22 theanets.trainer:168 RmsProp 383 loss=83.672234 err=0.146613
I 2015-05-26 08:03:33 theanets.trainer:168 RmsProp 384 loss=83.434990 err=0.151694
I 2015-05-26 08:03:44 theanets.trainer:168 RmsProp 385 loss=83.532639 err=0.148743
I 2015-05-26 08:03:55 theanets.trainer:168 RmsProp 386 loss=83.377548 err=0.148496
I 2015-05-26 08:04:07 theanets.trainer:168 RmsProp 387 loss=83.274887 err=0.150785
I 2015-05-26 08:04:18 theanets.trainer:168 RmsProp 388 loss=83.154480 err=0.154870
I 2015-05-26 08:04:29 theanets.trainer:168 RmsProp 389 loss=83.211861 err=0.146612
I 2015-05-26 08:04:40 theanets.trainer:168 RmsProp 390 loss=82.937759 err=0.146479
I 2015-05-26 08:04:41 theanets.trainer:168 validation 39 loss=853.264099 err=768.939697 *
I 2015-05-26 08:04:52 theanets.trainer:168 RmsProp 391 loss=82.835709 err=0.148459
I 2015-05-26 08:05:04 theanets.trainer:168 RmsProp 392 loss=82.844017 err=0.150501
I 2015-05-26 08:05:15 theanets.trainer:168 RmsProp 393 loss=82.708298 err=0.146003
I 2015-05-26 08:05:26 theanets.trainer:168 RmsProp 394 loss=82.485962 err=0.150669
I 2015-05-26 08:05:37 theanets.trainer:168 RmsProp 395 loss=82.601578 err=0.150054
I 2015-05-26 08:05:49 theanets.trainer:168 RmsProp 396 loss=82.303551 err=0.151817
I 2015-05-26 08:06:00 theanets.trainer:168 RmsProp 397 loss=82.409065 err=0.139724
I 2015-05-26 08:06:11 theanets.trainer:168 RmsProp 398 loss=82.065018 err=0.139466
I 2015-05-26 08:06:22 theanets.trainer:168 RmsProp 399 loss=82.295555 err=0.154416
I 2015-05-26 08:06:34 theanets.trainer:168 RmsProp 400 loss=82.116676 err=0.150491
I 2015-05-26 08:06:35 theanets.trainer:168 validation 40 loss=851.873901 err=768.443054 *
I 2015-05-26 08:06:46 theanets.trainer:168 RmsProp 401 loss=82.044441 err=0.145533
I 2015-05-26 08:06:57 theanets.trainer:168 RmsProp 402 loss=81.744553 err=0.149697
I 2015-05-26 08:07:09 theanets.trainer:168 RmsProp 403 loss=81.743370 err=0.154449
I 2015-05-26 08:07:20 theanets.trainer:168 RmsProp 404 loss=81.713608 err=0.152414
I 2015-05-26 08:07:31 theanets.trainer:168 RmsProp 405 loss=81.752487 err=0.143548
I 2015-05-26 08:07:42 theanets.trainer:168 RmsProp 406 loss=81.576874 err=0.147230
I 2015-05-26 08:07:52 theanets.trainer:168 RmsProp 407 loss=81.533554 err=0.144552
I 2015-05-26 08:08:03 theanets.trainer:168 RmsProp 408 loss=81.319153 err=0.152101
I 2015-05-26 08:08:14 theanets.trainer:168 RmsProp 409 loss=81.282761 err=0.148517
I 2015-05-26 08:08:24 theanets.trainer:168 RmsProp 410 loss=80.917816 err=0.150934
I 2015-05-26 08:08:25 theanets.trainer:168 validation 41 loss=850.562866 err=768.020020 *
I 2015-05-26 08:08:36 theanets.trainer:168 RmsProp 411 loss=81.402718 err=0.141828
I 2015-05-26 08:08:46 theanets.trainer:168 RmsProp 412 loss=80.960632 err=0.146018
I 2015-05-26 08:08:57 theanets.trainer:168 RmsProp 413 loss=80.659927 err=0.148187
I 2015-05-26 08:09:08 theanets.trainer:168 RmsProp 414 loss=80.853958 err=0.146199
I 2015-05-26 08:09:19 theanets.trainer:168 RmsProp 415 loss=80.774406 err=0.145019
I 2015-05-26 08:09:30 theanets.trainer:168 RmsProp 416 loss=80.623047 err=0.147087
I 2015-05-26 08:09:42 theanets.trainer:168 RmsProp 417 loss=80.763016 err=0.143439
I 2015-05-26 08:09:53 theanets.trainer:168 RmsProp 418 loss=80.339485 err=0.153154
I 2015-05-26 08:10:05 theanets.trainer:168 RmsProp 419 loss=80.355812 err=0.153222
I 2015-05-26 08:10:16 theanets.trainer:168 RmsProp 420 loss=80.226044 err=0.143763
I 2015-05-26 08:10:17 theanets.trainer:168 validation 42 loss=848.987854 err=767.311462 *
I 2015-05-26 08:10:28 theanets.trainer:168 RmsProp 421 loss=80.176437 err=0.152667
I 2015-05-26 08:10:39 theanets.trainer:168 RmsProp 422 loss=80.572769 err=0.145648
I 2015-05-26 08:10:51 theanets.trainer:168 RmsProp 423 loss=80.101906 err=0.137719
I 2015-05-26 08:11:02 theanets.trainer:168 RmsProp 424 loss=80.095779 err=0.159068
I 2015-05-26 08:11:13 theanets.trainer:168 RmsProp 425 loss=80.044815 err=0.142326
I 2015-05-26 08:11:25 theanets.trainer:168 RmsProp 426 loss=79.716263 err=0.130717
I 2015-05-26 08:11:36 theanets.trainer:168 RmsProp 427 loss=79.846230 err=0.167746
I 2015-05-26 08:11:47 theanets.trainer:168 RmsProp 428 loss=79.853317 err=0.143476
I 2015-05-26 08:11:58 theanets.trainer:168 RmsProp 429 loss=79.698166 err=0.141498
I 2015-05-26 08:12:10 theanets.trainer:168 RmsProp 430 loss=79.467720 err=0.146486
I 2015-05-26 08:12:10 theanets.trainer:168 validation 43 loss=848.328552 err=767.456360 *
I 2015-05-26 08:12:22 theanets.trainer:168 RmsProp 431 loss=79.423874 err=0.150315
I 2015-05-26 08:12:33 theanets.trainer:168 RmsProp 432 loss=79.347214 err=0.147280
I 2015-05-26 08:12:45 theanets.trainer:168 RmsProp 433 loss=79.372215 err=0.143136
I 2015-05-26 08:12:56 theanets.trainer:168 RmsProp 434 loss=79.140015 err=0.146446
I 2015-05-26 08:13:07 theanets.trainer:168 RmsProp 435 loss=79.027840 err=0.158019
I 2015-05-26 08:13:19 theanets.trainer:168 RmsProp 436 loss=78.974693 err=0.140278
I 2015-05-26 08:13:31 theanets.trainer:168 RmsProp 437 loss=79.003082 err=0.140556
I 2015-05-26 08:13:42 theanets.trainer:168 RmsProp 438 loss=79.036819 err=0.146592
I 2015-05-26 08:13:53 theanets.trainer:168 RmsProp 439 loss=78.863670 err=0.143106
I 2015-05-26 08:14:04 theanets.trainer:168 RmsProp 440 loss=78.800125 err=0.142745
I 2015-05-26 08:14:05 theanets.trainer:168 validation 44 loss=847.771973 err=767.695007 *
I 2015-05-26 08:14:16 theanets.trainer:168 RmsProp 441 loss=78.734940 err=0.150062
I 2015-05-26 08:14:27 theanets.trainer:168 RmsProp 442 loss=78.662292 err=0.144889
I 2015-05-26 08:14:39 theanets.trainer:168 RmsProp 443 loss=78.577629 err=0.143612
I 2015-05-26 08:14:50 theanets.trainer:168 RmsProp 444 loss=78.406548 err=0.146742
I 2015-05-26 08:15:01 theanets.trainer:168 RmsProp 445 loss=78.180771 err=0.143727
I 2015-05-26 08:15:12 theanets.trainer:168 RmsProp 446 loss=78.422600 err=0.142337
I 2015-05-26 08:15:24 theanets.trainer:168 RmsProp 447 loss=78.353195 err=0.138460
I 2015-05-26 08:15:35 theanets.trainer:168 RmsProp 448 loss=78.326660 err=0.155348
I 2015-05-26 08:15:47 theanets.trainer:168 RmsProp 449 loss=78.177299 err=0.149427
I 2015-05-26 08:15:58 theanets.trainer:168 RmsProp 450 loss=77.942238 err=0.134192
I 2015-05-26 08:15:59 theanets.trainer:168 validation 45 loss=846.786377 err=767.501160 *
I 2015-05-26 08:16:10 theanets.trainer:168 RmsProp 451 loss=77.979660 err=0.157553
I 2015-05-26 08:16:21 theanets.trainer:168 RmsProp 452 loss=77.909355 err=0.142261
I 2015-05-26 08:16:32 theanets.trainer:168 RmsProp 453 loss=77.747330 err=0.151991
I 2015-05-26 08:16:43 theanets.trainer:168 RmsProp 454 loss=77.618660 err=0.138495
I 2015-05-26 08:16:54 theanets.trainer:168 RmsProp 455 loss=77.843811 err=0.151969
I 2015-05-26 08:17:06 theanets.trainer:168 RmsProp 456 loss=77.740685 err=0.146524
I 2015-05-26 08:17:17 theanets.trainer:168 RmsProp 457 loss=77.510582 err=0.139621
I 2015-05-26 08:17:28 theanets.trainer:168 RmsProp 458 loss=77.509460 err=0.144985
I 2015-05-26 08:17:40 theanets.trainer:168 RmsProp 459 loss=77.293037 err=0.150981
I 2015-05-26 08:17:51 theanets.trainer:168 RmsProp 460 loss=77.238167 err=0.139060
I 2015-05-26 08:17:52 theanets.trainer:168 validation 46 loss=846.153381 err=767.602478 *
I 2015-05-26 08:18:03 theanets.trainer:168 RmsProp 461 loss=77.084305 err=0.144330
I 2015-05-26 08:18:14 theanets.trainer:168 RmsProp 462 loss=76.976944 err=0.134142
I 2015-05-26 08:18:26 theanets.trainer:168 RmsProp 463 loss=77.042862 err=0.145464
I 2015-05-26 08:18:37 theanets.trainer:168 RmsProp 464 loss=76.958862 err=0.143748
I 2015-05-26 08:18:48 theanets.trainer:168 RmsProp 465 loss=77.025703 err=0.157229
I 2015-05-26 08:19:00 theanets.trainer:168 RmsProp 466 loss=76.787460 err=0.136044
I 2015-05-26 08:19:11 theanets.trainer:168 RmsProp 467 loss=76.727631 err=0.138728
I 2015-05-26 08:19:23 theanets.trainer:168 RmsProp 468 loss=76.596451 err=0.152766
I 2015-05-26 08:19:34 theanets.trainer:168 RmsProp 469 loss=76.741310 err=0.141470
I 2015-05-26 08:19:46 theanets.trainer:168 RmsProp 470 loss=76.676529 err=0.136967
I 2015-05-26 08:19:47 theanets.trainer:168 validation 47 loss=845.599121 err=767.745117 *
I 2015-05-26 08:19:58 theanets.trainer:168 RmsProp 471 loss=76.571945 err=0.145147
I 2015-05-26 08:20:10 theanets.trainer:168 RmsProp 472 loss=76.331718 err=0.144112
I 2015-05-26 08:20:21 theanets.trainer:168 RmsProp 473 loss=76.403885 err=0.138685
I 2015-05-26 08:20:33 theanets.trainer:168 RmsProp 474 loss=76.268631 err=0.140981
I 2015-05-26 08:20:44 theanets.trainer:168 RmsProp 475 loss=76.367485 err=0.146195
I 2015-05-26 08:20:55 theanets.trainer:168 RmsProp 476 loss=76.167686 err=0.151828
I 2015-05-26 08:21:07 theanets.trainer:168 RmsProp 477 loss=75.921143 err=0.141330
I 2015-05-26 08:21:18 theanets.trainer:168 RmsProp 478 loss=76.118263 err=0.137058
I 2015-05-26 08:21:30 theanets.trainer:168 RmsProp 479 loss=75.893661 err=0.140776
I 2015-05-26 08:21:41 theanets.trainer:168 RmsProp 480 loss=75.609177 err=0.139272
I 2015-05-26 08:21:42 theanets.trainer:168 validation 48 loss=845.200928 err=768.049744 *
I 2015-05-26 08:21:53 theanets.trainer:168 RmsProp 481 loss=75.869995 err=0.144038
I 2015-05-26 08:22:04 theanets.trainer:168 RmsProp 482 loss=75.721519 err=0.141986
I 2015-05-26 08:22:16 theanets.trainer:168 RmsProp 483 loss=75.631760 err=0.134596
I 2015-05-26 08:22:27 theanets.trainer:168 RmsProp 484 loss=75.561600 err=0.141569
I 2015-05-26 08:22:38 theanets.trainer:168 RmsProp 485 loss=75.450989 err=0.141049
I 2015-05-26 08:22:50 theanets.trainer:168 RmsProp 486 loss=75.303658 err=0.141293
I 2015-05-26 08:23:02 theanets.trainer:168 RmsProp 487 loss=75.263481 err=0.143082
I 2015-05-26 08:23:13 theanets.trainer:168 RmsProp 488 loss=75.257812 err=0.140576
I 2015-05-26 08:23:25 theanets.trainer:168 RmsProp 489 loss=75.170364 err=0.138905
I 2015-05-26 08:23:36 theanets.trainer:168 RmsProp 490 loss=75.166870 err=0.145184
I 2015-05-26 08:23:37 theanets.trainer:168 validation 49 loss=845.205444 err=768.741638
I 2015-05-26 08:23:48 theanets.trainer:168 RmsProp 491 loss=75.060844 err=0.141101
I 2015-05-26 08:23:59 theanets.trainer:168 RmsProp 492 loss=74.909851 err=0.144233
I 2015-05-26 08:24:11 theanets.trainer:168 RmsProp 493 loss=75.103905 err=0.141638
I 2015-05-26 08:24:22 theanets.trainer:168 RmsProp 494 loss=74.914474 err=0.135064
I 2015-05-26 08:24:34 theanets.trainer:168 RmsProp 495 loss=75.023048 err=0.145003
I 2015-05-26 08:24:46 theanets.trainer:168 RmsProp 496 loss=74.929504 err=0.136111
I 2015-05-26 08:24:57 theanets.trainer:168 RmsProp 497 loss=74.870506 err=0.141640
I 2015-05-26 08:25:08 theanets.trainer:168 RmsProp 498 loss=74.684822 err=0.144052
I 2015-05-26 08:25:20 theanets.trainer:168 RmsProp 499 loss=74.633568 err=0.142078
I 2015-05-26 08:25:31 theanets.trainer:168 RmsProp 500 loss=74.641098 err=0.141491
I 2015-05-26 08:25:32 theanets.trainer:168 validation 50 loss=845.648621 err=769.800110
I 2015-05-26 08:25:44 theanets.trainer:168 RmsProp 501 loss=74.590454 err=0.137445
I 2015-05-26 08:25:55 theanets.trainer:168 RmsProp 502 loss=74.415222 err=0.134170
I 2015-05-26 08:26:07 theanets.trainer:168 RmsProp 503 loss=74.415947 err=0.139977
I 2015-05-26 08:26:18 theanets.trainer:168 RmsProp 504 loss=74.260582 err=0.141740
I 2015-05-26 08:26:30 theanets.trainer:168 RmsProp 505 loss=74.240616 err=0.139336
I 2015-05-26 08:26:42 theanets.trainer:168 RmsProp 506 loss=74.219460 err=0.137586
I 2015-05-26 08:26:53 theanets.trainer:168 RmsProp 507 loss=74.177986 err=0.139685
I 2015-05-26 08:27:05 theanets.trainer:168 RmsProp 508 loss=74.143936 err=0.139181
I 2015-05-26 08:27:16 theanets.trainer:168 RmsProp 509 loss=74.019142 err=0.136480
I 2015-05-26 08:27:28 theanets.trainer:168 RmsProp 510 loss=73.985535 err=0.142548
I 2015-05-26 08:27:29 theanets.trainer:168 validation 51 loss=846.167175 err=770.954651
I 2015-05-26 08:27:40 theanets.trainer:168 RmsProp 511 loss=73.822327 err=0.142607
I 2015-05-26 08:27:52 theanets.trainer:168 RmsProp 512 loss=73.708099 err=0.140524
I 2015-05-26 08:28:03 theanets.trainer:168 RmsProp 513 loss=73.787666 err=0.141591
I 2015-05-26 08:28:15 theanets.trainer:168 RmsProp 514 loss=73.647720 err=0.139435
I 2015-05-26 08:28:26 theanets.trainer:168 RmsProp 515 loss=73.642479 err=0.132675
I 2015-05-26 08:28:37 theanets.trainer:168 RmsProp 516 loss=73.639809 err=0.142017
I 2015-05-26 08:28:49 theanets.trainer:168 RmsProp 517 loss=73.521362 err=0.140493
I 2015-05-26 08:29:01 theanets.trainer:168 RmsProp 518 loss=73.621719 err=0.140779
I 2015-05-26 08:29:12 theanets.trainer:168 RmsProp 519 loss=73.452286 err=0.142289
I 2015-05-26 08:29:24 theanets.trainer:168 RmsProp 520 loss=73.386131 err=0.135314
I 2015-05-26 08:29:25 theanets.trainer:168 validation 52 loss=847.307739 err=772.721375
I 2015-05-26 08:29:36 theanets.trainer:168 RmsProp 521 loss=73.148613 err=0.137075
I 2015-05-26 08:29:47 theanets.trainer:168 RmsProp 522 loss=73.292274 err=0.138176
I 2015-05-26 08:29:59 theanets.trainer:168 RmsProp 523 loss=73.207306 err=0.133716
I 2015-05-26 08:30:11 theanets.trainer:168 RmsProp 524 loss=73.218521 err=0.141476
I 2015-05-26 08:30:22 theanets.trainer:168 RmsProp 525 loss=73.075783 err=0.135344
I 2015-05-26 08:30:34 theanets.trainer:168 RmsProp 526 loss=73.063919 err=0.140698
I 2015-05-26 08:30:46 theanets.trainer:168 RmsProp 527 loss=72.845665 err=0.131443
I 2015-05-26 08:30:57 theanets.trainer:168 RmsProp 528 loss=72.755234 err=0.143718
I 2015-05-26 08:31:09 theanets.trainer:168 RmsProp 529 loss=72.824539 err=0.135665
I 2015-05-26 08:31:20 theanets.trainer:168 RmsProp 530 loss=72.649460 err=0.133295
I 2015-05-26 08:31:21 theanets.trainer:168 validation 53 loss=848.966492 err=774.969910
I 2015-05-26 08:31:21 theanets.trainer:252 patience elapsed!
I 2015-05-26 08:31:21 theanets.main:237 models_deep_post_code_sep/95111-models-sep_san_jose_realtor_200_100.conf-1024-0.01-0.001-0.001.pkl: saving model
I 2015-05-26 08:31:21 theanets.graph:477 models_deep_post_code_sep/95111-models-sep_san_jose_realtor_200_100.conf-1024-0.01-0.001-0.001.pkl: saved model parameters
