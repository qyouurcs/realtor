I 2015-05-26 22:05:12 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:12 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95135-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:12 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:12 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:12 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:12 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:12 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:12 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:12 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:12 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:12 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:12 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:12 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:29 theano.gof.compilelock:266 Waiting for existing lock by process '29998' (I am process '30005')
I 2015-05-26 22:05:29 theano.gof.compilelock:268 To manually release the lock, delete /localdisk/qyou/.theano/compiledir_Linux-3.19-fc20.x86_64-x86_64-with-fedora-20-Heisenbug-x86_64-2.7.5-64/lock_dir
I 2015-05-26 22:05:35 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:05 theano.gof.compilelock:266 Waiting for existing lock by process '29907' (I am process '30005')
I 2015-05-26 22:08:05 theano.gof.compilelock:268 To manually release the lock, delete /localdisk/qyou/.theano/compiledir_Linux-3.19-fc20.x86_64-x86_64-with-fedora-20-Heisenbug-x86_64-2.7.5-64/lock_dir
I 2015-05-26 22:08:26 theanets.trainer:168 validation 0 loss=14393.983398 err=14151.741211 *
I 2015-05-26 22:09:02 theanets.trainer:168 RmsProp 1 loss=13223.808594 err=13130.565430
I 2015-05-26 22:09:41 theanets.trainer:168 RmsProp 2 loss=13155.072266 err=13134.472656
I 2015-05-26 22:10:20 theanets.trainer:168 RmsProp 3 loss=13031.489258 err=12999.326172
I 2015-05-26 22:10:57 theanets.trainer:168 RmsProp 4 loss=12302.520508 err=12248.133789
I 2015-05-26 22:11:36 theanets.trainer:168 RmsProp 5 loss=11167.208984 err=11092.412109
I 2015-05-26 22:12:14 theanets.trainer:168 RmsProp 6 loss=10196.498047 err=10104.360352
I 2015-05-26 22:12:52 theanets.trainer:168 RmsProp 7 loss=9679.256836 err=9574.211914
I 2015-05-26 22:13:30 theanets.trainer:168 RmsProp 8 loss=8815.603516 err=8691.660156
I 2015-05-26 22:14:10 theanets.trainer:168 RmsProp 9 loss=8324.528320 err=8178.446289
I 2015-05-26 22:14:48 theanets.trainer:168 RmsProp 10 loss=7832.830078 err=7664.775879
I 2015-05-26 22:14:49 theanets.trainer:168 validation 1 loss=7378.316895 err=7200.144531 *
I 2015-05-26 22:15:27 theanets.trainer:168 RmsProp 11 loss=7450.990723 err=7262.783691
I 2015-05-26 22:16:06 theanets.trainer:168 RmsProp 12 loss=7093.075195 err=6886.117188
I 2015-05-26 22:16:45 theanets.trainer:168 RmsProp 13 loss=6877.645020 err=6650.424805
I 2015-05-26 22:17:24 theanets.trainer:168 RmsProp 14 loss=6706.123047 err=6455.332520
I 2015-05-26 22:18:03 theanets.trainer:168 RmsProp 15 loss=6274.387207 err=6006.149414
I 2015-05-26 22:18:41 theanets.trainer:168 RmsProp 16 loss=6134.393066 err=5850.591797
I 2015-05-26 22:19:20 theanets.trainer:168 RmsProp 17 loss=6105.976562 err=5806.172363
I 2015-05-26 22:19:58 theanets.trainer:168 RmsProp 18 loss=6109.287109 err=5787.626465
I 2015-05-26 22:20:36 theanets.trainer:168 RmsProp 19 loss=6530.291016 err=6188.454102
I 2015-05-26 22:21:15 theanets.trainer:168 RmsProp 20 loss=6508.748047 err=6144.983887
I 2015-05-26 22:21:16 theanets.trainer:168 validation 2 loss=6373.443848 err=6000.056152 *
I 2015-05-26 22:21:54 theanets.trainer:168 RmsProp 21 loss=6314.976074 err=5933.320312
I 2015-05-26 22:22:33 theanets.trainer:168 RmsProp 22 loss=6003.547363 err=5615.669434
I 2015-05-26 22:23:11 theanets.trainer:168 RmsProp 23 loss=5570.191895 err=5187.395508
I 2015-05-26 22:23:49 theanets.trainer:168 RmsProp 24 loss=5500.421387 err=5116.138184
I 2015-05-26 22:24:27 theanets.trainer:168 RmsProp 25 loss=5607.266602 err=5211.632812
I 2015-05-26 22:25:06 theanets.trainer:168 RmsProp 26 loss=5189.559570 err=4779.946777
I 2015-05-26 22:25:44 theanets.trainer:168 RmsProp 27 loss=4782.403320 err=4370.029297
I 2015-05-26 22:26:21 theanets.trainer:168 RmsProp 28 loss=4602.132324 err=4177.583984
I 2015-05-26 22:27:01 theanets.trainer:168 RmsProp 29 loss=4337.003418 err=3909.493408
I 2015-05-26 22:27:40 theanets.trainer:168 RmsProp 30 loss=4233.491699 err=3804.307861
I 2015-05-26 22:27:41 theanets.trainer:168 validation 3 loss=3959.097412 err=3525.860107 *
I 2015-05-26 22:28:20 theanets.trainer:168 RmsProp 31 loss=4138.214844 err=3699.176025
I 2015-05-26 22:28:59 theanets.trainer:168 RmsProp 32 loss=4135.453125 err=3684.137207
I 2015-05-26 22:29:37 theanets.trainer:168 RmsProp 33 loss=3843.453613 err=3384.428711
I 2015-05-26 22:30:16 theanets.trainer:168 RmsProp 34 loss=3729.733643 err=3270.297363
I 2015-05-26 22:30:55 theanets.trainer:168 RmsProp 35 loss=3571.639648 err=3107.854248
I 2015-05-26 22:31:34 theanets.trainer:168 RmsProp 36 loss=3490.851074 err=3020.599121
I 2015-05-26 22:32:13 theanets.trainer:168 RmsProp 37 loss=3377.144287 err=2900.308105
I 2015-05-26 22:32:52 theanets.trainer:168 RmsProp 38 loss=3337.280029 err=2850.721924
I 2015-05-26 22:33:30 theanets.trainer:168 RmsProp 39 loss=3259.015625 err=2764.171631
I 2015-05-26 22:34:08 theanets.trainer:168 RmsProp 40 loss=3274.377686 err=2771.738525
I 2015-05-26 22:34:09 theanets.trainer:168 validation 4 loss=3665.044189 err=3155.297607 *
I 2015-05-26 22:34:47 theanets.trainer:168 RmsProp 41 loss=3187.812744 err=2674.476807
I 2015-05-26 22:35:26 theanets.trainer:168 RmsProp 42 loss=3086.998779 err=2571.658936
I 2015-05-26 22:36:04 theanets.trainer:168 RmsProp 43 loss=3005.423340 err=2485.038330
I 2015-05-26 22:36:42 theanets.trainer:168 RmsProp 44 loss=3014.791992 err=2488.964600
I 2015-05-26 22:37:20 theanets.trainer:168 RmsProp 45 loss=3179.590088 err=2639.238281
I 2015-05-26 22:37:58 theanets.trainer:168 RmsProp 46 loss=3178.176270 err=2625.767090
I 2015-05-26 22:38:36 theanets.trainer:168 RmsProp 47 loss=3182.634033 err=2618.077637
I 2015-05-26 22:39:14 theanets.trainer:168 RmsProp 48 loss=2960.009277 err=2394.390137
I 2015-05-26 22:39:52 theanets.trainer:168 RmsProp 49 loss=2847.622803 err=2283.973633
I 2015-05-26 22:40:29 theanets.trainer:168 RmsProp 50 loss=2747.833740 err=2185.119873
I 2015-05-26 22:40:30 theanets.trainer:168 validation 5 loss=2974.579834 err=2411.940674 *
I 2015-05-26 22:41:08 theanets.trainer:168 RmsProp 51 loss=2681.358154 err=2117.875488
I 2015-05-26 22:41:46 theanets.trainer:168 RmsProp 52 loss=2688.276123 err=2120.316162
I 2015-05-26 22:42:24 theanets.trainer:168 RmsProp 53 loss=2653.890137 err=2078.322266
I 2015-05-26 22:43:02 theanets.trainer:168 RmsProp 54 loss=2592.200928 err=2015.243286
I 2015-05-26 22:43:40 theanets.trainer:168 RmsProp 55 loss=2533.290527 err=1954.918823
I 2015-05-26 22:44:20 theanets.trainer:168 RmsProp 56 loss=2464.197021 err=1884.671265
I 2015-05-26 22:44:59 theanets.trainer:168 RmsProp 57 loss=2455.544189 err=1871.372559
I 2015-05-26 22:45:38 theanets.trainer:168 RmsProp 58 loss=2488.145508 err=1900.348999
I 2015-05-26 22:46:15 theanets.trainer:168 RmsProp 59 loss=2511.341064 err=1915.798340
I 2015-05-26 22:46:53 theanets.trainer:168 RmsProp 60 loss=2448.251709 err=1849.925293
I 2015-05-26 22:46:54 theanets.trainer:168 validation 6 loss=3141.266602 err=2542.179932
I 2015-05-26 22:47:33 theanets.trainer:168 RmsProp 61 loss=2422.818115 err=1821.533569
I 2015-05-26 22:48:10 theanets.trainer:168 RmsProp 62 loss=2444.642334 err=1838.912231
I 2015-05-26 22:48:48 theanets.trainer:168 RmsProp 63 loss=2345.706299 err=1738.388428
I 2015-05-26 22:49:25 theanets.trainer:168 RmsProp 64 loss=2361.164062 err=1750.476074
I 2015-05-26 22:50:03 theanets.trainer:168 RmsProp 65 loss=2275.401367 err=1661.945435
I 2015-05-26 22:50:42 theanets.trainer:168 RmsProp 66 loss=2246.613770 err=1632.336304
I 2015-05-26 22:51:21 theanets.trainer:168 RmsProp 67 loss=2218.745850 err=1602.370361
I 2015-05-26 22:52:00 theanets.trainer:168 RmsProp 68 loss=2218.769043 err=1600.465210
I 2015-05-26 22:52:37 theanets.trainer:168 RmsProp 69 loss=2221.103271 err=1599.052124
I 2015-05-26 22:53:15 theanets.trainer:168 RmsProp 70 loss=2159.452881 err=1534.078003
I 2015-05-26 22:53:16 theanets.trainer:168 validation 7 loss=2630.302979 err=2005.292847 *
I 2015-05-26 22:53:56 theanets.trainer:168 RmsProp 71 loss=2111.532227 err=1484.974487
I 2015-05-26 22:54:36 theanets.trainer:168 RmsProp 72 loss=2071.234131 err=1444.380737
I 2015-05-26 22:55:15 theanets.trainer:168 RmsProp 73 loss=2090.130127 err=1461.589844
I 2015-05-26 22:55:53 theanets.trainer:168 RmsProp 74 loss=2076.491699 err=1444.482666
I 2015-05-26 22:56:32 theanets.trainer:168 RmsProp 75 loss=2071.470947 err=1437.133911
I 2015-05-26 22:57:12 theanets.trainer:168 RmsProp 76 loss=2016.443359 err=1380.395996
I 2015-05-26 22:57:52 theanets.trainer:168 RmsProp 77 loss=2028.547607 err=1390.696411
I 2015-05-26 22:58:32 theanets.trainer:168 RmsProp 78 loss=1989.454956 err=1349.596924
I 2015-05-26 22:59:11 theanets.trainer:168 RmsProp 79 loss=1931.828247 err=1292.525269
I 2015-05-26 22:59:48 theanets.trainer:168 RmsProp 80 loss=1923.877075 err=1286.018188
I 2015-05-26 22:59:49 theanets.trainer:168 validation 8 loss=2645.629150 err=2008.010376
I 2015-05-26 23:00:26 theanets.trainer:168 RmsProp 81 loss=1956.061279 err=1315.176392
I 2015-05-26 23:01:04 theanets.trainer:168 RmsProp 82 loss=1956.001221 err=1310.215576
I 2015-05-26 23:01:43 theanets.trainer:168 RmsProp 83 loss=1925.645264 err=1280.536621
I 2015-05-26 23:02:22 theanets.trainer:168 RmsProp 84 loss=1906.131470 err=1260.027344
I 2015-05-26 23:03:00 theanets.trainer:168 RmsProp 85 loss=1979.314941 err=1329.998901
I 2015-05-26 23:03:39 theanets.trainer:168 RmsProp 86 loss=1981.925659 err=1329.000488
I 2015-05-26 23:04:17 theanets.trainer:168 RmsProp 87 loss=1861.739990 err=1209.364990
I 2015-05-26 23:04:55 theanets.trainer:168 RmsProp 88 loss=1800.380127 err=1149.524902
I 2015-05-26 23:05:32 theanets.trainer:168 RmsProp 89 loss=1749.675659 err=1102.072632
I 2015-05-26 23:06:09 theanets.trainer:168 RmsProp 90 loss=1777.529907 err=1131.394897
I 2015-05-26 23:06:10 theanets.trainer:168 validation 9 loss=2623.893066 err=1977.919556 *
I 2015-05-26 23:06:47 theanets.trainer:168 RmsProp 91 loss=1802.599487 err=1154.555786
I 2015-05-26 23:07:26 theanets.trainer:168 RmsProp 92 loss=1797.404785 err=1146.091553
I 2015-05-26 23:08:05 theanets.trainer:168 RmsProp 93 loss=1728.550049 err=1079.398560
I 2015-05-26 23:08:45 theanets.trainer:168 RmsProp 94 loss=1715.378784 err=1066.225830
I 2015-05-26 23:09:23 theanets.trainer:168 RmsProp 95 loss=1659.108032 err=1011.865356
I 2015-05-26 23:10:03 theanets.trainer:168 RmsProp 96 loss=1715.699707 err=1067.097046
I 2015-05-26 23:10:40 theanets.trainer:168 RmsProp 97 loss=1695.264893 err=1044.075439
I 2015-05-26 23:11:18 theanets.trainer:168 RmsProp 98 loss=1658.745728 err=1008.649658
I 2015-05-26 23:11:56 theanets.trainer:168 RmsProp 99 loss=1609.557007 err=961.229431
I 2015-05-26 23:12:34 theanets.trainer:168 RmsProp 100 loss=1625.582764 err=977.470886
I 2015-05-26 23:12:35 theanets.trainer:168 validation 10 loss=2579.243164 err=1928.960938 *
I 2015-05-26 23:13:13 theanets.trainer:168 RmsProp 101 loss=1703.896484 err=1050.084839
I 2015-05-26 23:13:52 theanets.trainer:168 RmsProp 102 loss=1645.458130 err=990.760437
I 2015-05-26 23:14:31 theanets.trainer:168 RmsProp 103 loss=1644.123779 err=989.461792
I 2015-05-26 23:15:09 theanets.trainer:168 RmsProp 104 loss=1654.067261 err=998.735962
I 2015-05-26 23:15:48 theanets.trainer:168 RmsProp 105 loss=1623.481201 err=967.284546
I 2015-05-26 23:16:26 theanets.trainer:168 RmsProp 106 loss=1612.722412 err=957.099243
I 2015-05-26 23:17:05 theanets.trainer:168 RmsProp 107 loss=1628.435181 err=972.659058
I 2015-05-26 23:17:42 theanets.trainer:168 RmsProp 108 loss=1613.278198 err=955.658752
I 2015-05-26 23:18:20 theanets.trainer:168 RmsProp 109 loss=1568.462158 err=911.723328
I 2015-05-26 23:18:57 theanets.trainer:168 RmsProp 110 loss=1547.366455 err=891.932190
I 2015-05-26 23:18:58 theanets.trainer:168 validation 11 loss=2470.806396 err=1815.520386 *
I 2015-05-26 23:19:35 theanets.trainer:168 RmsProp 111 loss=1523.852295 err=869.372864
I 2015-05-26 23:20:12 theanets.trainer:168 RmsProp 112 loss=1548.998169 err=894.121338
I 2015-05-26 23:20:50 theanets.trainer:168 RmsProp 113 loss=1534.178101 err=877.068604
I 2015-05-26 23:21:28 theanets.trainer:168 RmsProp 114 loss=1547.801025 err=892.930664
I 2015-05-26 23:22:06 theanets.trainer:168 RmsProp 115 loss=1609.733887 err=950.474854
I 2015-05-26 23:22:44 theanets.trainer:168 RmsProp 116 loss=1570.574341 err=910.974976
I 2015-05-26 23:23:22 theanets.trainer:168 RmsProp 117 loss=1527.748657 err=868.686096
I 2015-05-26 23:24:01 theanets.trainer:168 RmsProp 118 loss=1507.093018 err=850.041809
I 2015-05-26 23:24:40 theanets.trainer:168 RmsProp 119 loss=1500.698730 err=843.246033
I 2015-05-26 23:25:17 theanets.trainer:168 RmsProp 120 loss=1498.905151 err=841.602112
I 2015-05-26 23:25:18 theanets.trainer:168 validation 12 loss=2384.530762 err=1727.039062 *
I 2015-05-26 23:25:56 theanets.trainer:168 RmsProp 121 loss=1509.189819 err=851.238037
I 2015-05-26 23:26:33 theanets.trainer:168 RmsProp 122 loss=1607.640869 err=946.165771
I 2015-05-26 23:27:11 theanets.trainer:168 RmsProp 123 loss=1734.809082 err=1064.354858
I 2015-05-26 23:27:49 theanets.trainer:168 RmsProp 124 loss=1720.875122 err=1042.943359
I 2015-05-26 23:28:27 theanets.trainer:168 RmsProp 125 loss=1568.928345 err=892.355652
I 2015-05-26 23:29:06 theanets.trainer:168 RmsProp 126 loss=1530.751343 err=857.664124
I 2015-05-26 23:29:44 theanets.trainer:168 RmsProp 127 loss=1524.369507 err=852.738098
I 2015-05-26 23:30:23 theanets.trainer:168 RmsProp 128 loss=1520.768311 err=849.440369
I 2015-05-26 23:31:01 theanets.trainer:168 RmsProp 129 loss=1480.147339 err=808.992065
I 2015-05-26 23:31:38 theanets.trainer:168 RmsProp 130 loss=1438.417603 err=769.356323
I 2015-05-26 23:31:39 theanets.trainer:168 validation 13 loss=2510.042480 err=1842.472046
I 2015-05-26 23:32:16 theanets.trainer:168 RmsProp 131 loss=1459.735840 err=791.919800
I 2015-05-26 23:32:52 theanets.trainer:168 RmsProp 132 loss=1484.493896 err=815.825134
I 2015-05-26 23:33:29 theanets.trainer:168 RmsProp 133 loss=1532.559204 err=861.752747
I 2015-05-26 23:34:07 theanets.trainer:168 RmsProp 134 loss=1545.949097 err=870.380737
I 2015-05-26 23:34:45 theanets.trainer:168 RmsProp 135 loss=1528.460327 err=850.490417
I 2015-05-26 23:35:22 theanets.trainer:168 RmsProp 136 loss=1474.468872 err=799.467834
I 2015-05-26 23:36:00 theanets.trainer:168 RmsProp 137 loss=1455.794189 err=782.778259
I 2015-05-26 23:36:37 theanets.trainer:168 RmsProp 138 loss=1424.645020 err=753.351868
I 2015-05-26 23:37:15 theanets.trainer:168 RmsProp 139 loss=1399.650879 err=730.239685
I 2015-05-26 23:37:54 theanets.trainer:168 RmsProp 140 loss=1383.391846 err=715.989075
I 2015-05-26 23:37:55 theanets.trainer:168 validation 14 loss=2468.069336 err=1802.382202
I 2015-05-26 23:38:33 theanets.trainer:168 RmsProp 141 loss=1350.311401 err=686.403137
I 2015-05-26 23:39:10 theanets.trainer:168 RmsProp 142 loss=1382.608643 err=718.554749
I 2015-05-26 23:39:48 theanets.trainer:168 RmsProp 143 loss=1479.740356 err=809.350403
I 2015-05-26 23:40:26 theanets.trainer:168 RmsProp 144 loss=1438.133057 err=766.393921
I 2015-05-26 23:41:06 theanets.trainer:168 RmsProp 145 loss=1447.442505 err=777.001587
I 2015-05-26 23:41:44 theanets.trainer:168 RmsProp 146 loss=1430.675415 err=759.911743
I 2015-05-26 23:42:23 theanets.trainer:168 RmsProp 147 loss=1413.075806 err=743.190063
I 2015-05-26 23:43:02 theanets.trainer:168 RmsProp 148 loss=1423.813232 err=752.860291
I 2015-05-26 23:43:41 theanets.trainer:168 RmsProp 149 loss=1428.064819 err=755.785217
I 2015-05-26 23:44:19 theanets.trainer:168 RmsProp 150 loss=1393.944824 err=723.160889
I 2015-05-26 23:44:20 theanets.trainer:168 validation 15 loss=2426.494385 err=1757.236694
I 2015-05-26 23:44:58 theanets.trainer:168 RmsProp 151 loss=1385.874390 err=717.409851
I 2015-05-26 23:45:36 theanets.trainer:168 RmsProp 152 loss=1363.392456 err=694.900146
I 2015-05-26 23:46:14 theanets.trainer:168 RmsProp 153 loss=1347.727051 err=681.055481
I 2015-05-26 23:46:52 theanets.trainer:168 RmsProp 154 loss=1355.758545 err=690.074890
I 2015-05-26 23:47:29 theanets.trainer:168 RmsProp 155 loss=1367.998535 err=701.473450
I 2015-05-26 23:48:06 theanets.trainer:168 RmsProp 156 loss=1382.784424 err=716.429138
I 2015-05-26 23:48:42 theanets.trainer:168 RmsProp 157 loss=1351.263184 err=685.066284
I 2015-05-26 23:49:20 theanets.trainer:168 RmsProp 158 loss=1329.404175 err=665.262817
I 2015-05-26 23:49:58 theanets.trainer:168 RmsProp 159 loss=1375.793457 err=709.683167
I 2015-05-26 23:50:35 theanets.trainer:168 RmsProp 160 loss=1383.917847 err=713.575134
I 2015-05-26 23:50:36 theanets.trainer:168 validation 16 loss=2518.947021 err=1847.882202
I 2015-05-26 23:51:10 theanets.trainer:168 RmsProp 161 loss=1389.615234 err=718.946411
I 2015-05-26 23:51:45 theanets.trainer:168 RmsProp 162 loss=1388.951172 err=717.700134
I 2015-05-26 23:52:19 theanets.trainer:168 RmsProp 163 loss=1355.685913 err=684.744568
I 2015-05-26 23:52:56 theanets.trainer:168 RmsProp 164 loss=1354.564453 err=684.991943
I 2015-05-26 23:53:33 theanets.trainer:168 RmsProp 165 loss=1407.374634 err=733.810730
I 2015-05-26 23:54:10 theanets.trainer:168 RmsProp 166 loss=1569.984863 err=892.188538
I 2015-05-26 23:54:48 theanets.trainer:168 RmsProp 167 loss=1881.277100 err=1188.636230
I 2015-05-26 23:55:26 theanets.trainer:168 RmsProp 168 loss=1798.929077 err=1096.467285
I 2015-05-26 23:56:03 theanets.trainer:168 RmsProp 169 loss=1574.915405 err=873.217651
I 2015-05-26 23:56:40 theanets.trainer:168 RmsProp 170 loss=1479.734009 err=784.922058
I 2015-05-26 23:56:41 theanets.trainer:168 validation 17 loss=2547.093018 err=1854.534790
I 2015-05-26 23:56:41 theanets.trainer:252 patience elapsed!
I 2015-05-26 23:56:41 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 23:56:41 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 23:56:41 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 23:56:41 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 23:56:41 theanets.main:89 --batch_size = 1024
I 2015-05-26 23:56:41 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 23:56:41 theanets.main:89 --hidden_l1 = None
I 2015-05-26 23:56:41 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 23:56:41 theanets.main:89 --train_batches = 10
I 2015-05-26 23:56:41 theanets.main:89 --valid_batches = 2
I 2015-05-26 23:56:41 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 23:56:41 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 23:56:41 theanets.trainer:134 compiling evaluation function
I 2015-05-26 23:56:50 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 23:58:31 theanets.trainer:168 validation 0 loss=3293.549805 err=2636.057861 *
I 2015-05-26 23:58:43 theanets.trainer:168 RmsProp 1 loss=1256.756958 err=602.638550
I 2015-05-26 23:58:54 theanets.trainer:168 RmsProp 2 loss=1040.396118 err=389.047516
I 2015-05-26 23:59:06 theanets.trainer:168 RmsProp 3 loss=924.209839 err=274.775116
I 2015-05-26 23:59:18 theanets.trainer:168 RmsProp 4 loss=850.483887 err=203.073151
I 2015-05-26 23:59:30 theanets.trainer:168 RmsProp 5 loss=798.112732 err=153.042206
I 2015-05-26 23:59:41 theanets.trainer:168 RmsProp 6 loss=761.506409 err=119.200500
I 2015-05-26 23:59:53 theanets.trainer:168 RmsProp 7 loss=731.338379 err=92.251938
I 2015-05-27 00:00:05 theanets.trainer:168 RmsProp 8 loss=710.000427 err=74.523155
I 2015-05-27 00:00:17 theanets.trainer:168 RmsProp 9 loss=692.956360 err=61.379517
I 2015-05-27 00:00:28 theanets.trainer:168 RmsProp 10 loss=680.196655 err=52.657825
I 2015-05-27 00:00:29 theanets.trainer:168 validation 1 loss=2100.638428 err=1475.361206 *
I 2015-05-27 00:00:41 theanets.trainer:168 RmsProp 11 loss=669.257263 err=45.849106
I 2015-05-27 00:00:52 theanets.trainer:168 RmsProp 12 loss=660.160889 err=41.038948
I 2015-05-27 00:01:04 theanets.trainer:168 RmsProp 13 loss=651.891724 err=37.103184
I 2015-05-27 00:01:15 theanets.trainer:168 RmsProp 14 loss=643.862732 err=33.366024
I 2015-05-27 00:01:27 theanets.trainer:168 RmsProp 15 loss=636.681641 err=30.513403
I 2015-05-27 00:01:39 theanets.trainer:168 RmsProp 16 loss=630.786255 err=29.052052
I 2015-05-27 00:01:51 theanets.trainer:168 RmsProp 17 loss=623.263123 err=25.895929
I 2015-05-27 00:02:02 theanets.trainer:168 RmsProp 18 loss=617.017029 err=23.871202
I 2015-05-27 00:02:14 theanets.trainer:168 RmsProp 19 loss=611.915649 err=23.072523
I 2015-05-27 00:02:25 theanets.trainer:168 RmsProp 20 loss=605.837280 err=21.248793
I 2015-05-27 00:02:26 theanets.trainer:168 validation 2 loss=1951.042358 err=1368.794678 *
I 2015-05-27 00:02:37 theanets.trainer:168 RmsProp 21 loss=600.727539 err=20.372679
I 2015-05-27 00:02:49 theanets.trainer:168 RmsProp 22 loss=595.333679 err=19.085442
I 2015-05-27 00:03:00 theanets.trainer:168 RmsProp 23 loss=590.676208 err=18.461117
I 2015-05-27 00:03:12 theanets.trainer:168 RmsProp 24 loss=585.654358 err=17.362509
I 2015-05-27 00:03:23 theanets.trainer:168 RmsProp 25 loss=580.846069 err=16.450592
I 2015-05-27 00:03:35 theanets.trainer:168 RmsProp 26 loss=576.928345 err=16.470320
I 2015-05-27 00:03:47 theanets.trainer:168 RmsProp 27 loss=572.206970 err=15.568744
I 2015-05-27 00:03:58 theanets.trainer:168 RmsProp 28 loss=567.886353 err=14.858684
I 2015-05-27 00:04:10 theanets.trainer:168 RmsProp 29 loss=563.428284 err=13.978793
I 2015-05-27 00:04:21 theanets.trainer:168 RmsProp 30 loss=559.453064 err=13.612442
I 2015-05-27 00:04:22 theanets.trainer:168 validation 3 loss=1877.705566 err=1333.824463 *
I 2015-05-27 00:04:33 theanets.trainer:168 RmsProp 31 loss=555.224976 err=12.971727
I 2015-05-27 00:04:45 theanets.trainer:168 RmsProp 32 loss=551.745911 err=13.093153
I 2015-05-27 00:04:57 theanets.trainer:168 RmsProp 33 loss=547.825500 err=12.727737
I 2015-05-27 00:05:08 theanets.trainer:168 RmsProp 34 loss=543.650146 err=11.958537
I 2015-05-27 00:05:19 theanets.trainer:168 RmsProp 35 loss=540.130981 err=11.753459
I 2015-05-27 00:05:31 theanets.trainer:168 RmsProp 36 loss=536.463135 err=11.372128
I 2015-05-27 00:05:43 theanets.trainer:168 RmsProp 37 loss=532.980225 err=11.154502
I 2015-05-27 00:05:54 theanets.trainer:168 RmsProp 38 loss=529.652466 err=10.999720
I 2015-05-27 00:06:05 theanets.trainer:168 RmsProp 39 loss=526.742188 err=11.168743
I 2015-05-27 00:06:17 theanets.trainer:168 RmsProp 40 loss=522.675781 err=10.080044
I 2015-05-27 00:06:18 theanets.trainer:168 validation 4 loss=1820.138184 err=1309.197632 *
I 2015-05-27 00:06:29 theanets.trainer:168 RmsProp 41 loss=520.018982 err=10.471025
I 2015-05-27 00:06:41 theanets.trainer:168 RmsProp 42 loss=516.537781 err=10.027822
I 2015-05-27 00:06:52 theanets.trainer:168 RmsProp 43 loss=512.983704 err=9.429913
I 2015-05-27 00:07:04 theanets.trainer:168 RmsProp 44 loss=509.805573 err=9.246506
I 2015-05-27 00:07:15 theanets.trainer:168 RmsProp 45 loss=507.347321 err=9.796663
I 2015-05-27 00:07:27 theanets.trainer:168 RmsProp 46 loss=503.794281 err=9.159074
I 2015-05-27 00:07:39 theanets.trainer:168 RmsProp 47 loss=500.383484 err=8.608532
I 2015-05-27 00:07:50 theanets.trainer:168 RmsProp 48 loss=497.660461 err=8.799304
I 2015-05-27 00:08:02 theanets.trainer:168 RmsProp 49 loss=494.542480 err=8.615410
I 2015-05-27 00:08:13 theanets.trainer:168 RmsProp 50 loss=491.246033 err=8.217288
I 2015-05-27 00:08:14 theanets.trainer:168 validation 5 loss=1772.441772 err=1291.004517 *
I 2015-05-27 00:08:25 theanets.trainer:168 RmsProp 51 loss=488.550385 err=8.425969
I 2015-05-27 00:08:37 theanets.trainer:168 RmsProp 52 loss=485.366791 err=8.086144
I 2015-05-27 00:08:48 theanets.trainer:168 RmsProp 53 loss=482.350037 err=7.813445
I 2015-05-27 00:08:59 theanets.trainer:168 RmsProp 54 loss=479.917877 err=8.106149
I 2015-05-27 00:09:11 theanets.trainer:168 RmsProp 55 loss=476.676910 err=7.519929
I 2015-05-27 00:09:22 theanets.trainer:168 RmsProp 56 loss=473.946472 err=7.408263
I 2015-05-27 00:09:34 theanets.trainer:168 RmsProp 57 loss=471.336731 err=7.449148
I 2015-05-27 00:09:45 theanets.trainer:168 RmsProp 58 loss=468.484680 err=7.240856
I 2015-05-27 00:09:57 theanets.trainer:168 RmsProp 59 loss=465.773254 err=7.146842
I 2015-05-27 00:10:08 theanets.trainer:168 RmsProp 60 loss=462.895935 err=6.869907
I 2015-05-27 00:10:09 theanets.trainer:168 validation 6 loss=1736.613281 err=1282.011353 *
I 2015-05-27 00:10:20 theanets.trainer:168 RmsProp 61 loss=460.458984 err=7.027794
I 2015-05-27 00:10:32 theanets.trainer:168 RmsProp 62 loss=457.887360 err=7.001657
I 2015-05-27 00:10:43 theanets.trainer:168 RmsProp 63 loss=455.064301 err=6.667271
I 2015-05-27 00:10:54 theanets.trainer:168 RmsProp 64 loss=452.303619 err=6.357072
I 2015-05-27 00:11:06 theanets.trainer:168 RmsProp 65 loss=450.205658 err=6.718381
I 2015-05-27 00:11:17 theanets.trainer:168 RmsProp 66 loss=447.573883 err=6.515269
I 2015-05-27 00:11:28 theanets.trainer:168 RmsProp 67 loss=445.077393 err=6.362547
I 2015-05-27 00:11:40 theanets.trainer:168 RmsProp 68 loss=442.826019 err=6.425991
I 2015-05-27 00:11:50 theanets.trainer:168 RmsProp 69 loss=440.196960 err=6.087092
I 2015-05-27 00:12:01 theanets.trainer:168 RmsProp 70 loss=438.193359 err=6.352448
I 2015-05-27 00:12:01 theanets.trainer:168 validation 7 loss=1688.199097 err=1257.585571 *
I 2015-05-27 00:12:12 theanets.trainer:168 RmsProp 71 loss=435.904785 err=6.290813
I 2015-05-27 00:12:22 theanets.trainer:168 RmsProp 72 loss=433.316956 err=5.892903
I 2015-05-27 00:12:32 theanets.trainer:168 RmsProp 73 loss=431.442322 err=6.187095
I 2015-05-27 00:12:43 theanets.trainer:168 RmsProp 74 loss=428.951843 err=5.857221
I 2015-05-27 00:12:53 theanets.trainer:168 RmsProp 75 loss=426.411224 err=5.462984
I 2015-05-27 00:13:04 theanets.trainer:168 RmsProp 76 loss=425.299622 err=6.514917
I 2015-05-27 00:13:14 theanets.trainer:168 RmsProp 77 loss=422.277161 err=5.581187
I 2015-05-27 00:13:25 theanets.trainer:168 RmsProp 78 loss=420.208099 err=5.549268
I 2015-05-27 00:13:35 theanets.trainer:168 RmsProp 79 loss=418.418640 err=5.816621
I 2015-05-27 00:13:46 theanets.trainer:168 RmsProp 80 loss=415.899658 err=5.337272
I 2015-05-27 00:13:46 theanets.trainer:168 validation 8 loss=1655.093262 err=1245.642456 *
I 2015-05-27 00:13:57 theanets.trainer:168 RmsProp 81 loss=414.201019 err=5.661100
I 2015-05-27 00:14:07 theanets.trainer:168 RmsProp 82 loss=411.806885 err=5.282750
I 2015-05-27 00:14:18 theanets.trainer:168 RmsProp 83 loss=409.918884 err=5.378030
I 2015-05-27 00:14:28 theanets.trainer:168 RmsProp 84 loss=407.986633 err=5.427305
I 2015-05-27 00:14:38 theanets.trainer:168 RmsProp 85 loss=405.930115 err=5.324748
I 2015-05-27 00:14:48 theanets.trainer:168 RmsProp 86 loss=403.816345 err=5.140373
I 2015-05-27 00:14:58 theanets.trainer:168 RmsProp 87 loss=401.995605 err=5.240494
I 2015-05-27 00:15:08 theanets.trainer:168 RmsProp 88 loss=399.896240 err=5.047263
I 2015-05-27 00:15:17 theanets.trainer:168 RmsProp 89 loss=398.292908 err=5.336927
I 2015-05-27 00:15:27 theanets.trainer:168 RmsProp 90 loss=396.109100 err=5.034833
I 2015-05-27 00:15:28 theanets.trainer:168 validation 9 loss=1618.762329 err=1228.700928 *
I 2015-05-27 00:15:38 theanets.trainer:168 RmsProp 91 loss=394.457703 err=5.223237
I 2015-05-27 00:15:47 theanets.trainer:168 RmsProp 92 loss=392.535736 err=5.083858
I 2015-05-27 00:15:57 theanets.trainer:168 RmsProp 93 loss=390.862244 err=5.143544
I 2015-05-27 00:16:07 theanets.trainer:168 RmsProp 94 loss=388.969025 err=4.978599
I 2015-05-27 00:16:17 theanets.trainer:168 RmsProp 95 loss=387.202423 err=4.951974
I 2015-05-27 00:16:28 theanets.trainer:168 RmsProp 96 loss=385.501648 err=4.960382
I 2015-05-27 00:16:38 theanets.trainer:168 RmsProp 97 loss=383.555115 err=4.705832
I 2015-05-27 00:16:48 theanets.trainer:168 RmsProp 98 loss=382.045105 err=4.887516
I 2015-05-27 00:16:59 theanets.trainer:168 RmsProp 99 loss=380.076691 err=4.627467
I 2015-05-27 00:17:09 theanets.trainer:168 RmsProp 100 loss=378.498230 err=4.747404
I 2015-05-27 00:17:10 theanets.trainer:168 validation 10 loss=1584.708374 err=1211.890259 *
I 2015-05-27 00:17:20 theanets.trainer:168 RmsProp 101 loss=376.883728 err=4.822543
I 2015-05-27 00:17:30 theanets.trainer:168 RmsProp 102 loss=374.999542 err=4.604184
I 2015-05-27 00:17:41 theanets.trainer:168 RmsProp 103 loss=373.625061 err=4.854013
I 2015-05-27 00:17:51 theanets.trainer:168 RmsProp 104 loss=371.695068 err=4.539128
I 2015-05-27 00:18:02 theanets.trainer:168 RmsProp 105 loss=369.968689 err=4.420168
I 2015-05-27 00:18:12 theanets.trainer:168 RmsProp 106 loss=368.582916 err=4.652387
I 2015-05-27 00:18:23 theanets.trainer:168 RmsProp 107 loss=367.208221 err=4.887853
I 2015-05-27 00:18:33 theanets.trainer:168 RmsProp 108 loss=365.315338 err=4.523307
I 2015-05-27 00:18:43 theanets.trainer:168 RmsProp 109 loss=363.789337 err=4.488920
I 2015-05-27 00:18:53 theanets.trainer:168 RmsProp 110 loss=362.046997 err=4.234983
I 2015-05-27 00:18:54 theanets.trainer:168 validation 11 loss=1549.090576 err=1192.104858 *
I 2015-05-27 00:19:04 theanets.trainer:168 RmsProp 111 loss=360.963959 err=4.670946
I 2015-05-27 00:19:15 theanets.trainer:168 RmsProp 112 loss=359.119690 err=4.328590
I 2015-05-27 00:19:25 theanets.trainer:168 RmsProp 113 loss=357.646332 err=4.340809
I 2015-05-27 00:19:36 theanets.trainer:168 RmsProp 114 loss=356.321045 err=4.500699
I 2015-05-27 00:19:47 theanets.trainer:168 RmsProp 115 loss=354.552917 err=4.180572
I 2015-05-27 00:19:57 theanets.trainer:168 RmsProp 116 loss=353.434418 err=4.508836
I 2015-05-27 00:20:07 theanets.trainer:168 RmsProp 117 loss=351.824890 err=4.329504
I 2015-05-27 00:20:18 theanets.trainer:168 RmsProp 118 loss=350.240051 err=4.154979
I 2015-05-27 00:20:28 theanets.trainer:168 RmsProp 119 loss=348.977966 err=4.303830
I 2015-05-27 00:20:39 theanets.trainer:168 RmsProp 120 loss=347.280914 err=4.026296
I 2015-05-27 00:20:39 theanets.trainer:168 validation 12 loss=1529.815430 err=1187.340210 *
I 2015-05-27 00:20:50 theanets.trainer:168 RmsProp 121 loss=346.092468 err=4.250605
I 2015-05-27 00:21:01 theanets.trainer:168 RmsProp 122 loss=344.551208 err=4.113698
I 2015-05-27 00:21:11 theanets.trainer:168 RmsProp 123 loss=343.106659 err=4.053966
I 2015-05-27 00:21:22 theanets.trainer:168 RmsProp 124 loss=341.856415 err=4.170388
I 2015-05-27 00:21:32 theanets.trainer:168 RmsProp 125 loss=340.412537 err=4.089868
I 2015-05-27 00:21:43 theanets.trainer:168 RmsProp 126 loss=338.959656 err=3.983646
I 2015-05-27 00:21:54 theanets.trainer:168 RmsProp 127 loss=337.712585 err=4.086626
I 2015-05-27 00:22:04 theanets.trainer:168 RmsProp 128 loss=336.321442 err=4.032621
I 2015-05-27 00:22:15 theanets.trainer:168 RmsProp 129 loss=334.915253 err=3.939858
I 2015-05-27 00:22:25 theanets.trainer:168 RmsProp 130 loss=333.886108 err=4.226015
I 2015-05-27 00:22:26 theanets.trainer:168 validation 13 loss=1505.347900 err=1176.404785 *
I 2015-05-27 00:22:37 theanets.trainer:168 RmsProp 131 loss=332.322723 err=3.950376
I 2015-05-27 00:22:48 theanets.trainer:168 RmsProp 132 loss=330.974304 err=3.869781
I 2015-05-27 00:22:58 theanets.trainer:168 RmsProp 133 loss=329.892883 err=4.066969
I 2015-05-27 00:23:08 theanets.trainer:168 RmsProp 134 loss=328.637390 err=4.077587
I 2015-05-27 00:23:19 theanets.trainer:168 RmsProp 135 loss=327.289856 err=3.961612
I 2015-05-27 00:23:29 theanets.trainer:168 RmsProp 136 loss=325.940125 err=3.826454
I 2015-05-27 00:23:40 theanets.trainer:168 RmsProp 137 loss=324.882172 err=3.994442
I 2015-05-27 00:23:50 theanets.trainer:168 RmsProp 138 loss=323.369446 err=3.682772
I 2015-05-27 00:24:00 theanets.trainer:168 RmsProp 139 loss=322.580933 err=4.097206
I 2015-05-27 00:24:11 theanets.trainer:168 RmsProp 140 loss=321.053009 err=3.762949
I 2015-05-27 00:24:11 theanets.trainer:168 validation 14 loss=1482.510254 err=1165.872192 *
I 2015-05-27 00:24:22 theanets.trainer:168 RmsProp 141 loss=319.924988 err=3.830770
I 2015-05-27 00:24:32 theanets.trainer:168 RmsProp 142 loss=318.661987 err=3.767701
I 2015-05-27 00:24:43 theanets.trainer:168 RmsProp 143 loss=317.388214 err=3.687337
I 2015-05-27 00:24:53 theanets.trainer:168 RmsProp 144 loss=316.306824 err=3.792304
I 2015-05-27 00:25:03 theanets.trainer:168 RmsProp 145 loss=314.976868 err=3.641257
I 2015-05-27 00:25:14 theanets.trainer:168 RmsProp 146 loss=314.078522 err=3.912961
I 2015-05-27 00:25:24 theanets.trainer:168 RmsProp 147 loss=312.727173 err=3.702836
I 2015-05-27 00:25:34 theanets.trainer:168 RmsProp 148 loss=311.501404 err=3.600040
I 2015-05-27 00:25:45 theanets.trainer:168 RmsProp 149 loss=310.519287 err=3.745109
I 2015-05-27 00:25:55 theanets.trainer:168 RmsProp 150 loss=309.484131 err=3.822077
I 2015-05-27 00:25:56 theanets.trainer:168 validation 15 loss=1455.521484 err=1150.464966 *
I 2015-05-27 00:26:06 theanets.trainer:168 RmsProp 151 loss=308.068848 err=3.511366
I 2015-05-27 00:26:16 theanets.trainer:168 RmsProp 152 loss=307.366058 err=3.903101
I 2015-05-27 00:26:26 theanets.trainer:168 RmsProp 153 loss=305.729492 err=3.361064
I 2015-05-27 00:26:37 theanets.trainer:168 RmsProp 154 loss=305.192352 err=3.908437
I 2015-05-27 00:26:47 theanets.trainer:168 RmsProp 155 loss=303.900177 err=3.682024
I 2015-05-27 00:26:57 theanets.trainer:168 RmsProp 156 loss=302.655334 err=3.482002
I 2015-05-27 00:27:07 theanets.trainer:168 RmsProp 157 loss=301.671692 err=3.555578
I 2015-05-27 00:27:18 theanets.trainer:168 RmsProp 158 loss=300.685852 err=3.626327
I 2015-05-27 00:27:28 theanets.trainer:168 RmsProp 159 loss=299.381897 err=3.364131
I 2015-05-27 00:27:38 theanets.trainer:168 RmsProp 160 loss=298.505249 err=3.527445
I 2015-05-27 00:27:39 theanets.trainer:168 validation 16 loss=1439.527466 err=1145.130859 *
I 2015-05-27 00:27:49 theanets.trainer:168 RmsProp 161 loss=297.525330 err=3.591765
I 2015-05-27 00:27:59 theanets.trainer:168 RmsProp 162 loss=296.338501 err=3.434712
I 2015-05-27 00:28:10 theanets.trainer:168 RmsProp 163 loss=295.382263 err=3.501972
I 2015-05-27 00:28:20 theanets.trainer:168 RmsProp 164 loss=294.389862 err=3.530498
I 2015-05-27 00:28:30 theanets.trainer:168 RmsProp 165 loss=293.282074 err=3.441658
I 2015-05-27 00:28:40 theanets.trainer:168 RmsProp 166 loss=292.237854 err=3.403769
I 2015-05-27 00:28:51 theanets.trainer:168 RmsProp 167 loss=291.298401 err=3.465159
I 2015-05-27 00:29:01 theanets.trainer:168 RmsProp 168 loss=290.367218 err=3.530695
I 2015-05-27 00:29:12 theanets.trainer:168 RmsProp 169 loss=289.126709 err=3.269206
I 2015-05-27 00:29:22 theanets.trainer:168 RmsProp 170 loss=288.272034 err=3.376541
I 2015-05-27 00:29:23 theanets.trainer:168 validation 17 loss=1420.414673 err=1136.048218 *
I 2015-05-27 00:29:33 theanets.trainer:168 RmsProp 171 loss=287.374481 err=3.440264
I 2015-05-27 00:29:44 theanets.trainer:168 RmsProp 172 loss=286.441071 err=3.454988
I 2015-05-27 00:29:54 theanets.trainer:168 RmsProp 173 loss=285.385162 err=3.336045
I 2015-05-27 00:30:05 theanets.trainer:168 RmsProp 174 loss=284.660278 err=3.537423
I 2015-05-27 00:30:15 theanets.trainer:168 RmsProp 175 loss=283.704926 err=3.488150
I 2015-05-27 00:30:25 theanets.trainer:168 RmsProp 176 loss=282.592346 err=3.277652
I 2015-05-27 00:30:35 theanets.trainer:168 RmsProp 177 loss=281.731781 err=3.313735
I 2015-05-27 00:30:45 theanets.trainer:168 RmsProp 178 loss=280.818054 err=3.300821
I 2015-05-27 00:30:56 theanets.trainer:168 RmsProp 179 loss=280.009583 err=3.403878
I 2015-05-27 00:31:06 theanets.trainer:168 RmsProp 180 loss=278.966034 err=3.268821
I 2015-05-27 00:31:07 theanets.trainer:168 validation 18 loss=1403.569458 err=1128.360596 *
I 2015-05-27 00:31:17 theanets.trainer:168 RmsProp 181 loss=277.919830 err=3.130878
I 2015-05-27 00:31:27 theanets.trainer:168 RmsProp 182 loss=277.329315 err=3.438161
I 2015-05-27 00:31:37 theanets.trainer:168 RmsProp 183 loss=276.232056 err=3.236085
I 2015-05-27 00:31:48 theanets.trainer:168 RmsProp 184 loss=275.586823 err=3.470254
I 2015-05-27 00:31:58 theanets.trainer:168 RmsProp 185 loss=274.525269 err=3.277924
I 2015-05-27 00:32:08 theanets.trainer:168 RmsProp 186 loss=273.648651 err=3.248906
I 2015-05-27 00:32:19 theanets.trainer:168 RmsProp 187 loss=272.799194 err=3.246547
I 2015-05-27 00:32:29 theanets.trainer:168 RmsProp 188 loss=272.055084 err=3.352262
I 2015-05-27 00:32:39 theanets.trainer:168 RmsProp 189 loss=271.029144 err=3.163778
I 2015-05-27 00:32:50 theanets.trainer:168 RmsProp 190 loss=270.129333 err=3.106437
I 2015-05-27 00:32:51 theanets.trainer:168 validation 19 loss=1385.356079 err=1118.805176 *
I 2015-05-27 00:33:01 theanets.trainer:168 RmsProp 191 loss=269.351898 err=3.167693
I 2015-05-27 00:33:11 theanets.trainer:168 RmsProp 192 loss=268.790131 err=3.440887
I 2015-05-27 00:33:22 theanets.trainer:168 RmsProp 193 loss=267.607361 err=3.081789
I 2015-05-27 00:33:32 theanets.trainer:168 RmsProp 194 loss=266.874054 err=3.155457
I 2015-05-27 00:33:43 theanets.trainer:168 RmsProp 195 loss=266.045654 err=3.140948
I 2015-05-27 00:33:53 theanets.trainer:168 RmsProp 196 loss=265.570068 err=3.468321
I 2015-05-27 00:34:04 theanets.trainer:168 RmsProp 197 loss=264.430206 err=3.125896
I 2015-05-27 00:34:14 theanets.trainer:168 RmsProp 198 loss=263.411377 err=2.904173
I 2015-05-27 00:34:25 theanets.trainer:168 RmsProp 199 loss=262.996857 err=3.283815
I 2015-05-27 00:34:35 theanets.trainer:168 RmsProp 200 loss=262.070618 err=3.149086
I 2015-05-27 00:34:36 theanets.trainer:168 validation 20 loss=1370.518433 err=1112.024658 *
I 2015-05-27 00:34:46 theanets.trainer:168 RmsProp 201 loss=261.273834 err=3.135214
I 2015-05-27 00:34:57 theanets.trainer:168 RmsProp 202 loss=260.377502 err=3.016814
I 2015-05-27 00:35:07 theanets.trainer:168 RmsProp 203 loss=259.756714 err=3.169511
I 2015-05-27 00:35:18 theanets.trainer:168 RmsProp 204 loss=259.080811 err=3.255286
I 2015-05-27 00:35:28 theanets.trainer:168 RmsProp 205 loss=258.084717 err=3.004676
I 2015-05-27 00:35:39 theanets.trainer:168 RmsProp 206 loss=257.472229 err=3.137275
I 2015-05-27 00:35:49 theanets.trainer:168 RmsProp 207 loss=256.653076 err=3.075249
I 2015-05-27 00:36:00 theanets.trainer:168 RmsProp 208 loss=255.807037 err=2.970343
I 2015-05-27 00:36:10 theanets.trainer:168 RmsProp 209 loss=255.172577 err=3.079362
I 2015-05-27 00:36:20 theanets.trainer:168 RmsProp 210 loss=254.358932 err=3.005528
I 2015-05-27 00:36:21 theanets.trainer:168 validation 21 loss=1348.342041 err=1097.383179 *
I 2015-05-27 00:36:31 theanets.trainer:168 RmsProp 211 loss=253.775925 err=3.154214
I 2015-05-27 00:36:41 theanets.trainer:168 RmsProp 212 loss=252.919678 err=3.027504
I 2015-05-27 00:36:52 theanets.trainer:168 RmsProp 213 loss=252.125977 err=2.956170
I 2015-05-27 00:37:02 theanets.trainer:168 RmsProp 214 loss=251.643723 err=3.196283
I 2015-05-27 00:37:12 theanets.trainer:168 RmsProp 215 loss=250.781830 err=3.037537
I 2015-05-27 00:37:23 theanets.trainer:168 RmsProp 216 loss=250.011261 err=2.971045
I 2015-05-27 00:37:34 theanets.trainer:168 RmsProp 217 loss=249.114166 err=2.781844
I 2015-05-27 00:37:44 theanets.trainer:168 RmsProp 218 loss=249.065674 err=3.432424
I 2015-05-27 00:37:55 theanets.trainer:168 RmsProp 219 loss=248.115143 err=3.162465
I 2015-05-27 00:38:05 theanets.trainer:168 RmsProp 220 loss=247.138397 err=2.847858
I 2015-05-27 00:38:06 theanets.trainer:168 validation 22 loss=1334.206543 err=1090.284790 *
I 2015-05-27 00:38:16 theanets.trainer:168 RmsProp 221 loss=246.526657 err=2.906615
I 2015-05-27 00:38:26 theanets.trainer:168 RmsProp 222 loss=246.003815 err=3.064831
I 2015-05-27 00:38:37 theanets.trainer:168 RmsProp 223 loss=245.284500 err=3.031718
I 2015-05-27 00:38:47 theanets.trainer:168 RmsProp 224 loss=244.446991 err=2.873762
I 2015-05-27 00:38:57 theanets.trainer:168 RmsProp 225 loss=244.000092 err=3.099907
I 2015-05-27 00:39:08 theanets.trainer:168 RmsProp 226 loss=242.982498 err=2.750510
I 2015-05-27 00:39:18 theanets.trainer:168 RmsProp 227 loss=242.709991 err=3.135130
I 2015-05-27 00:39:29 theanets.trainer:168 RmsProp 228 loss=241.976227 err=3.048295
I 2015-05-27 00:39:39 theanets.trainer:168 RmsProp 229 loss=241.149200 err=2.857060
I 2015-05-27 00:39:49 theanets.trainer:168 RmsProp 230 loss=240.730499 err=3.073087
I 2015-05-27 00:39:50 theanets.trainer:168 validation 23 loss=1327.855469 err=1090.549438 *
I 2015-05-27 00:40:00 theanets.trainer:168 RmsProp 231 loss=239.939240 err=2.917280
I 2015-05-27 00:40:11 theanets.trainer:168 RmsProp 232 loss=239.001541 err=2.614298
I 2015-05-27 00:40:21 theanets.trainer:168 RmsProp 233 loss=239.086472 err=3.336027
I 2015-05-27 00:40:31 theanets.trainer:168 RmsProp 234 loss=237.886307 err=2.765382
I 2015-05-27 00:40:42 theanets.trainer:168 RmsProp 235 loss=237.477661 err=2.979572
I 2015-05-27 00:40:52 theanets.trainer:168 RmsProp 236 loss=236.730347 err=2.855378
I 2015-05-27 00:41:02 theanets.trainer:168 RmsProp 237 loss=236.219925 err=2.964328
I 2015-05-27 00:41:13 theanets.trainer:168 RmsProp 238 loss=235.626434 err=2.978956
I 2015-05-27 00:41:23 theanets.trainer:168 RmsProp 239 loss=234.898590 err=2.859636
I 2015-05-27 00:41:33 theanets.trainer:168 RmsProp 240 loss=234.231491 err=2.802471
I 2015-05-27 00:41:34 theanets.trainer:168 validation 24 loss=1313.660522 err=1082.558228 *
I 2015-05-27 00:41:44 theanets.trainer:168 RmsProp 241 loss=233.655853 err=2.836979
I 2015-05-27 00:41:55 theanets.trainer:168 RmsProp 242 loss=233.113678 err=2.910892
I 2015-05-27 00:42:05 theanets.trainer:168 RmsProp 243 loss=232.372925 err=2.781759
I 2015-05-27 00:42:15 theanets.trainer:168 RmsProp 244 loss=231.834259 err=2.844454
I 2015-05-27 00:42:26 theanets.trainer:168 RmsProp 245 loss=231.178345 err=2.781156
I 2015-05-27 00:42:36 theanets.trainer:168 RmsProp 246 loss=230.686844 err=2.880730
I 2015-05-27 00:42:46 theanets.trainer:168 RmsProp 247 loss=230.003448 err=2.787444
I 2015-05-27 00:42:57 theanets.trainer:168 RmsProp 248 loss=229.391922 err=2.764602
I 2015-05-27 00:43:07 theanets.trainer:168 RmsProp 249 loss=228.964767 err=2.925175
I 2015-05-27 00:43:18 theanets.trainer:168 RmsProp 250 loss=228.460114 err=2.991091
I 2015-05-27 00:43:19 theanets.trainer:168 validation 25 loss=1301.145508 err=1075.984985 *
I 2015-05-27 00:43:29 theanets.trainer:168 RmsProp 251 loss=227.572556 err=2.666645
I 2015-05-27 00:43:39 theanets.trainer:168 RmsProp 252 loss=227.212204 err=2.873678
I 2015-05-27 00:43:49 theanets.trainer:168 RmsProp 253 loss=226.559525 err=2.786561
I 2015-05-27 00:44:00 theanets.trainer:168 RmsProp 254 loss=226.076904 err=2.862792
I 2015-05-27 00:44:10 theanets.trainer:168 RmsProp 255 loss=225.478561 err=2.810652
I 2015-05-27 00:44:21 theanets.trainer:168 RmsProp 256 loss=224.939041 err=2.820415
I 2015-05-27 00:44:31 theanets.trainer:168 RmsProp 257 loss=224.346970 err=2.771725
I 2015-05-27 00:44:42 theanets.trainer:168 RmsProp 258 loss=223.428391 err=2.408866
I 2015-05-27 00:44:52 theanets.trainer:168 RmsProp 259 loss=223.816818 err=3.341153
I 2015-05-27 00:45:03 theanets.trainer:168 RmsProp 260 loss=222.601608 err=2.659657
I 2015-05-27 00:45:04 theanets.trainer:168 validation 26 loss=1288.254761 err=1068.606812 *
I 2015-05-27 00:45:14 theanets.trainer:168 RmsProp 261 loss=222.113312 err=2.699909
I 2015-05-27 00:45:24 theanets.trainer:168 RmsProp 262 loss=221.557098 err=2.675387
I 2015-05-27 00:45:34 theanets.trainer:168 RmsProp 263 loss=221.063156 err=2.714107
I 2015-05-27 00:45:45 theanets.trainer:168 RmsProp 264 loss=220.698883 err=2.880909
I 2015-05-27 00:45:55 theanets.trainer:168 RmsProp 265 loss=220.058746 err=2.771379
I 2015-05-27 00:46:06 theanets.trainer:168 RmsProp 266 loss=219.443924 err=2.676134
I 2015-05-27 00:46:16 theanets.trainer:168 RmsProp 267 loss=219.070023 err=2.821571
I 2015-05-27 00:46:27 theanets.trainer:168 RmsProp 268 loss=218.350861 err=2.618676
I 2015-05-27 00:46:37 theanets.trainer:168 RmsProp 269 loss=218.221405 err=2.996095
I 2015-05-27 00:46:47 theanets.trainer:168 RmsProp 270 loss=217.413864 err=2.699520
I 2015-05-27 00:46:48 theanets.trainer:168 validation 27 loss=1272.966675 err=1058.521851 *
I 2015-05-27 00:46:58 theanets.trainer:168 RmsProp 271 loss=216.879486 err=2.666162
I 2015-05-27 00:47:09 theanets.trainer:168 RmsProp 272 loss=216.445145 err=2.736879
I 2015-05-27 00:47:19 theanets.trainer:168 RmsProp 273 loss=215.902390 err=2.696805
I 2015-05-27 00:47:30 theanets.trainer:168 RmsProp 274 loss=215.509476 err=2.807489
I 2015-05-27 00:47:41 theanets.trainer:168 RmsProp 275 loss=214.764740 err=2.560232
I 2015-05-27 00:47:52 theanets.trainer:168 RmsProp 276 loss=214.413376 err=2.700746
I 2015-05-27 00:48:02 theanets.trainer:168 RmsProp 277 loss=213.888016 err=2.663105
I 2015-05-27 00:48:13 theanets.trainer:168 RmsProp 278 loss=213.584259 err=2.842360
I 2015-05-27 00:48:24 theanets.trainer:168 RmsProp 279 loss=212.669388 err=2.411967
I 2015-05-27 00:48:34 theanets.trainer:168 RmsProp 280 loss=212.746216 err=2.967444
I 2015-05-27 00:48:35 theanets.trainer:168 validation 28 loss=1264.137207 err=1054.622559 *
I 2015-05-27 00:48:46 theanets.trainer:168 RmsProp 281 loss=211.725372 err=2.430816
I 2015-05-27 00:48:56 theanets.trainer:168 RmsProp 282 loss=211.692871 err=2.880343
I 2015-05-27 00:49:07 theanets.trainer:168 RmsProp 283 loss=210.769257 err=2.436113
I 2015-05-27 00:49:18 theanets.trainer:168 RmsProp 284 loss=210.760956 err=2.902285
I 2015-05-27 00:49:29 theanets.trainer:168 RmsProp 285 loss=209.943436 err=2.557987
I 2015-05-27 00:49:39 theanets.trainer:168 RmsProp 286 loss=209.605423 err=2.689173
I 2015-05-27 00:49:50 theanets.trainer:168 RmsProp 287 loss=209.114304 err=2.661691
I 2015-05-27 00:50:00 theanets.trainer:168 RmsProp 288 loss=208.719696 err=2.729232
I 2015-05-27 00:50:11 theanets.trainer:168 RmsProp 289 loss=208.286179 err=2.756418
I 2015-05-27 00:50:22 theanets.trainer:168 RmsProp 290 loss=207.589966 err=2.517318
I 2015-05-27 00:50:22 theanets.trainer:168 validation 29 loss=1251.355225 err=1046.537964 *
I 2015-05-27 00:50:33 theanets.trainer:168 RmsProp 291 loss=207.169724 err=2.551861
I 2015-05-27 00:50:44 theanets.trainer:168 RmsProp 292 loss=206.793610 err=2.628836
I 2015-05-27 00:50:54 theanets.trainer:168 RmsProp 293 loss=206.182617 err=2.484938
I 2015-05-27 00:51:05 theanets.trainer:168 RmsProp 294 loss=205.732376 err=2.496210
I 2015-05-27 00:51:15 theanets.trainer:168 RmsProp 295 loss=205.629242 err=2.853509
I 2015-05-27 00:51:26 theanets.trainer:168 RmsProp 296 loss=204.996460 err=2.673702
I 2015-05-27 00:51:36 theanets.trainer:168 RmsProp 297 loss=204.355515 err=2.479255
I 2015-05-27 00:51:46 theanets.trainer:168 RmsProp 298 loss=204.179871 err=2.748052
I 2015-05-27 00:51:57 theanets.trainer:168 RmsProp 299 loss=203.413315 err=2.424600
I 2015-05-27 00:52:08 theanets.trainer:168 RmsProp 300 loss=203.464996 err=2.919595
I 2015-05-27 00:52:08 theanets.trainer:168 validation 30 loss=1235.794922 err=1035.489258 *
I 2015-05-27 00:52:19 theanets.trainer:168 RmsProp 301 loss=202.760162 err=2.648212
I 2015-05-27 00:52:29 theanets.trainer:168 RmsProp 302 loss=202.168060 err=2.478024
I 2015-05-27 00:52:40 theanets.trainer:168 RmsProp 303 loss=201.766281 err=2.503721
I 2015-05-27 00:52:50 theanets.trainer:168 RmsProp 304 loss=201.589447 err=2.752901
I 2015-05-27 00:53:01 theanets.trainer:168 RmsProp 305 loss=200.887054 err=2.482934
I 2015-05-27 00:53:11 theanets.trainer:168 RmsProp 306 loss=200.506699 err=2.528115
I 2015-05-27 00:53:21 theanets.trainer:168 RmsProp 307 loss=200.128281 err=2.574766
I 2015-05-27 00:53:32 theanets.trainer:168 RmsProp 308 loss=199.757355 err=2.628578
I 2015-05-27 00:53:42 theanets.trainer:168 RmsProp 309 loss=199.243530 err=2.533816
I 2015-05-27 00:53:53 theanets.trainer:168 RmsProp 310 loss=198.823166 err=2.531549
I 2015-05-27 00:53:54 theanets.trainer:168 validation 31 loss=1229.114746 err=1033.043213 *
I 2015-05-27 00:54:04 theanets.trainer:168 RmsProp 311 loss=198.520767 err=2.642981
I 2015-05-27 00:54:14 theanets.trainer:168 RmsProp 312 loss=197.899933 err=2.439737
I 2015-05-27 00:54:25 theanets.trainer:168 RmsProp 313 loss=197.601181 err=2.547540
I 2015-05-27 00:54:36 theanets.trainer:168 RmsProp 314 loss=197.156693 err=2.516941
I 2015-05-27 00:54:46 theanets.trainer:168 RmsProp 315 loss=196.837540 err=2.609046
I 2015-05-27 00:54:57 theanets.trainer:168 RmsProp 316 loss=196.397705 err=2.571409
I 2015-05-27 00:55:07 theanets.trainer:168 RmsProp 317 loss=195.902130 err=2.476943
I 2015-05-27 00:55:17 theanets.trainer:168 RmsProp 318 loss=195.633591 err=2.609158
I 2015-05-27 00:55:28 theanets.trainer:168 RmsProp 319 loss=195.114517 err=2.494122
I 2015-05-27 00:55:39 theanets.trainer:168 RmsProp 320 loss=194.770782 err=2.547605
I 2015-05-27 00:55:39 theanets.trainer:168 validation 32 loss=1216.848389 err=1024.841797 *
I 2015-05-27 00:55:50 theanets.trainer:168 RmsProp 321 loss=194.280182 err=2.456994
I 2015-05-27 00:56:00 theanets.trainer:168 RmsProp 322 loss=193.917328 err=2.492580
I 2015-05-27 00:56:10 theanets.trainer:168 RmsProp 323 loss=193.601486 err=2.572568
I 2015-05-27 00:56:21 theanets.trainer:168 RmsProp 324 loss=193.180069 err=2.542505
I 2015-05-27 00:56:31 theanets.trainer:168 RmsProp 325 loss=192.642685 err=2.387407
I 2015-05-27 00:56:42 theanets.trainer:168 RmsProp 326 loss=192.511871 err=2.644499
I 2015-05-27 00:56:52 theanets.trainer:168 RmsProp 327 loss=192.055939 err=2.568981
I 2015-05-27 00:57:03 theanets.trainer:168 RmsProp 328 loss=191.537964 err=2.430687
I 2015-05-27 00:57:13 theanets.trainer:168 RmsProp 329 loss=191.223541 err=2.492880
I 2015-05-27 00:57:24 theanets.trainer:168 RmsProp 330 loss=190.644211 err=2.295843
I 2015-05-27 00:57:24 theanets.trainer:168 validation 33 loss=1200.975586 err=1012.833191 *
I 2015-05-27 00:57:34 theanets.trainer:168 RmsProp 331 loss=190.691467 err=2.724249
I 2015-05-27 00:57:45 theanets.trainer:168 RmsProp 332 loss=190.012253 err=2.423288
I 2015-05-27 00:57:55 theanets.trainer:168 RmsProp 333 loss=189.812820 err=2.600875
I 2015-05-27 00:58:06 theanets.trainer:168 RmsProp 334 loss=189.271469 err=2.430952
I 2015-05-27 00:58:16 theanets.trainer:168 RmsProp 335 loss=188.875916 err=2.411516
I 2015-05-27 00:58:27 theanets.trainer:168 RmsProp 336 loss=188.652939 err=2.559317
I 2015-05-27 00:58:37 theanets.trainer:168 RmsProp 337 loss=188.117538 err=2.393678
I 2015-05-27 00:58:47 theanets.trainer:168 RmsProp 338 loss=187.730911 err=2.377574
I 2015-05-27 00:58:58 theanets.trainer:168 RmsProp 339 loss=187.527267 err=2.542166
I 2015-05-27 00:59:09 theanets.trainer:168 RmsProp 340 loss=187.060303 err=2.440397
I 2015-05-27 00:59:09 theanets.trainer:168 validation 34 loss=1197.684814 err=1013.265442 *
I 2015-05-27 00:59:20 theanets.trainer:168 RmsProp 341 loss=186.358185 err=2.102080
I 2015-05-27 00:59:30 theanets.trainer:168 RmsProp 342 loss=186.948700 err=3.047990
I 2015-05-27 00:59:41 theanets.trainer:168 RmsProp 343 loss=185.831238 err=2.286319
I 2015-05-27 00:59:51 theanets.trainer:168 RmsProp 344 loss=185.675247 err=2.477347
I 2015-05-27 01:00:01 theanets.trainer:168 RmsProp 345 loss=185.425766 err=2.576455
I 2015-05-27 01:00:12 theanets.trainer:168 RmsProp 346 loss=184.896622 err=2.396347
I 2015-05-27 01:00:22 theanets.trainer:168 RmsProp 347 loss=184.675858 err=2.528767
I 2015-05-27 01:00:32 theanets.trainer:168 RmsProp 348 loss=184.117386 err=2.319087
I 2015-05-27 01:00:42 theanets.trainer:168 RmsProp 349 loss=183.938873 err=2.488009
I 2015-05-27 01:00:53 theanets.trainer:168 RmsProp 350 loss=183.413589 err=2.304857
I 2015-05-27 01:00:53 theanets.trainer:168 validation 35 loss=1189.595581 err=1008.679871 *
I 2015-05-27 01:01:03 theanets.trainer:168 RmsProp 351 loss=183.311554 err=2.550865
I 2015-05-27 01:01:14 theanets.trainer:168 RmsProp 352 loss=182.826996 err=2.407120
I 2015-05-27 01:01:24 theanets.trainer:168 RmsProp 353 loss=182.483795 err=2.398142
I 2015-05-27 01:01:34 theanets.trainer:168 RmsProp 354 loss=182.005676 err=2.259930
I 2015-05-27 01:01:44 theanets.trainer:168 RmsProp 355 loss=182.047089 err=2.639365
I 2015-05-27 01:01:54 theanets.trainer:168 RmsProp 356 loss=181.308868 err=2.243232
I 2015-05-27 01:02:05 theanets.trainer:168 RmsProp 357 loss=181.434006 err=2.707124
I 2015-05-27 01:02:15 theanets.trainer:168 RmsProp 358 loss=180.797775 err=2.402216
I 2015-05-27 01:02:26 theanets.trainer:168 RmsProp 359 loss=180.388153 err=2.319218
I 2015-05-27 01:02:36 theanets.trainer:168 RmsProp 360 loss=180.247269 err=2.499617
I 2015-05-27 01:02:37 theanets.trainer:168 validation 36 loss=1179.171631 err=1001.592224 *
I 2015-05-27 01:02:47 theanets.trainer:168 RmsProp 361 loss=179.902466 err=2.481268
I 2015-05-27 01:02:58 theanets.trainer:168 RmsProp 362 loss=179.440399 err=2.344601
I 2015-05-27 01:03:08 theanets.trainer:168 RmsProp 363 loss=179.271378 err=2.498287
I 2015-05-27 01:03:18 theanets.trainer:168 RmsProp 364 loss=178.792709 err=2.337185
I 2015-05-27 01:03:29 theanets.trainer:168 RmsProp 365 loss=178.506424 err=2.369100
I 2015-05-27 01:03:39 theanets.trainer:168 RmsProp 366 loss=178.497375 err=2.673632
I 2015-05-27 01:03:50 theanets.trainer:168 RmsProp 367 loss=177.856964 err=2.345605
I 2015-05-27 01:04:00 theanets.trainer:168 RmsProp 368 loss=177.454086 err=2.253361
I 2015-05-27 01:04:11 theanets.trainer:168 RmsProp 369 loss=177.276535 err=2.386462
I 2015-05-27 01:04:21 theanets.trainer:168 RmsProp 370 loss=176.958466 err=2.383529
I 2015-05-27 01:04:22 theanets.trainer:168 validation 37 loss=1174.683716 err=1000.282227 *
I 2015-05-27 01:04:32 theanets.trainer:168 RmsProp 371 loss=176.661926 err=2.398166
I 2015-05-27 01:04:43 theanets.trainer:168 RmsProp 372 loss=176.435684 err=2.485661
I 2015-05-27 01:04:54 theanets.trainer:168 RmsProp 373 loss=175.920380 err=2.281255
I 2015-05-27 01:05:04 theanets.trainer:168 RmsProp 374 loss=175.673935 err=2.344407
I 2015-05-27 01:05:15 theanets.trainer:168 RmsProp 375 loss=175.371368 err=2.357763
I 2015-05-27 01:05:26 theanets.trainer:168 RmsProp 376 loss=175.345337 err=2.635005
I 2015-05-27 01:05:36 theanets.trainer:168 RmsProp 377 loss=174.705109 err=2.295626
I 2015-05-27 01:05:47 theanets.trainer:168 RmsProp 378 loss=174.522659 err=2.413030
I 2015-05-27 01:05:57 theanets.trainer:168 RmsProp 379 loss=174.009369 err=2.195937
I 2015-05-27 01:06:08 theanets.trainer:168 RmsProp 380 loss=173.994278 err=2.477225
I 2015-05-27 01:06:09 theanets.trainer:168 validation 38 loss=1180.163330 err=1008.804138
I 2015-05-27 01:06:19 theanets.trainer:168 RmsProp 381 loss=173.451080 err=2.231669
I 2015-05-27 01:06:30 theanets.trainer:168 RmsProp 382 loss=173.401474 err=2.480027
I 2015-05-27 01:06:40 theanets.trainer:168 RmsProp 383 loss=172.966812 err=2.340547
I 2015-05-27 01:06:51 theanets.trainer:168 RmsProp 384 loss=172.434845 err=2.109698
I 2015-05-27 01:07:02 theanets.trainer:168 RmsProp 385 loss=172.554184 err=2.523133
I 2015-05-27 01:07:12 theanets.trainer:168 RmsProp 386 loss=172.020905 err=2.284622
I 2015-05-27 01:07:22 theanets.trainer:168 RmsProp 387 loss=171.929016 err=2.485998
I 2015-05-27 01:07:33 theanets.trainer:168 RmsProp 388 loss=171.578140 err=2.421307
I 2015-05-27 01:07:43 theanets.trainer:168 RmsProp 389 loss=170.892868 err=2.025931
I 2015-05-27 01:07:54 theanets.trainer:168 RmsProp 390 loss=171.042389 err=2.461460
I 2015-05-27 01:07:55 theanets.trainer:168 validation 39 loss=1172.068726 err=1003.639954 *
I 2015-05-27 01:08:06 theanets.trainer:168 RmsProp 391 loss=170.456894 err=2.168135
I 2015-05-27 01:08:16 theanets.trainer:168 RmsProp 392 loss=170.573044 err=2.568969
I 2015-05-27 01:08:27 theanets.trainer:168 RmsProp 393 loss=170.179810 err=2.461716
I 2015-05-27 01:08:37 theanets.trainer:168 RmsProp 394 loss=169.677429 err=2.243482
I 2015-05-27 01:08:48 theanets.trainer:168 RmsProp 395 loss=169.494797 err=2.341838
I 2015-05-27 01:08:59 theanets.trainer:168 RmsProp 396 loss=169.154785 err=2.286372
I 2015-05-27 01:09:10 theanets.trainer:168 RmsProp 397 loss=168.919022 err=2.328871
I 2015-05-27 01:09:20 theanets.trainer:168 RmsProp 398 loss=168.578568 err=2.266267
I 2015-05-27 01:09:31 theanets.trainer:168 RmsProp 399 loss=168.557083 err=2.518423
I 2015-05-27 01:09:42 theanets.trainer:168 RmsProp 400 loss=168.055969 err=2.290022
I 2015-05-27 01:09:42 theanets.trainer:168 validation 40 loss=1155.807617 err=990.198059 *
I 2015-05-27 01:09:53 theanets.trainer:168 RmsProp 401 loss=167.831238 err=2.336422
I 2015-05-27 01:10:04 theanets.trainer:168 RmsProp 402 loss=167.536880 err=2.314991
I 2015-05-27 01:10:14 theanets.trainer:168 RmsProp 403 loss=167.137634 err=2.192380
I 2015-05-27 01:10:25 theanets.trainer:168 RmsProp 404 loss=167.054382 err=2.377283
I 2015-05-27 01:10:36 theanets.trainer:168 RmsProp 405 loss=166.762421 err=2.358381
I 2015-05-27 01:10:47 theanets.trainer:168 RmsProp 406 loss=166.361237 err=2.225585
I 2015-05-27 01:10:58 theanets.trainer:168 RmsProp 407 loss=166.063431 err=2.200295
I 2015-05-27 01:11:08 theanets.trainer:168 RmsProp 408 loss=165.881378 err=2.289292
I 2015-05-27 01:11:19 theanets.trainer:168 RmsProp 409 loss=165.813858 err=2.488051
I 2015-05-27 01:11:30 theanets.trainer:168 RmsProp 410 loss=165.411484 err=2.349241
I 2015-05-27 01:11:31 theanets.trainer:168 validation 41 loss=1159.736084 err=996.808044
I 2015-05-27 01:11:42 theanets.trainer:168 RmsProp 411 loss=165.025085 err=2.220894
I 2015-05-27 01:11:53 theanets.trainer:168 RmsProp 412 loss=164.878235 err=2.331393
I 2015-05-27 01:12:03 theanets.trainer:168 RmsProp 413 loss=164.572403 err=2.289476
I 2015-05-27 01:12:14 theanets.trainer:168 RmsProp 414 loss=164.416901 err=2.395617
I 2015-05-27 01:12:25 theanets.trainer:168 RmsProp 415 loss=164.030457 err=2.264959
I 2015-05-27 01:12:35 theanets.trainer:168 RmsProp 416 loss=163.633453 err=2.116255
I 2015-05-27 01:12:46 theanets.trainer:168 RmsProp 417 loss=163.589813 err=2.330217
I 2015-05-27 01:12:57 theanets.trainer:168 RmsProp 418 loss=163.375290 err=2.370087
I 2015-05-27 01:13:07 theanets.trainer:168 RmsProp 419 loss=163.038895 err=2.289472
I 2015-05-27 01:13:18 theanets.trainer:168 RmsProp 420 loss=162.598618 err=2.103842
I 2015-05-27 01:13:19 theanets.trainer:168 validation 42 loss=1144.976562 err=984.609558 *
I 2015-05-27 01:13:29 theanets.trainer:168 RmsProp 421 loss=162.578445 err=2.336622
I 2015-05-27 01:13:40 theanets.trainer:168 RmsProp 422 loss=162.468048 err=2.477104
I 2015-05-27 01:13:50 theanets.trainer:168 RmsProp 423 loss=161.925369 err=2.180028
I 2015-05-27 01:14:01 theanets.trainer:168 RmsProp 424 loss=161.809906 err=2.310173
I 2015-05-27 01:14:11 theanets.trainer:168 RmsProp 425 loss=161.563751 err=2.310405
I 2015-05-27 01:14:21 theanets.trainer:168 RmsProp 426 loss=161.179092 err=2.174979
I 2015-05-27 01:14:32 theanets.trainer:168 RmsProp 427 loss=161.096100 err=2.332165
I 2015-05-27 01:14:42 theanets.trainer:168 RmsProp 428 loss=160.609177 err=2.089681
I 2015-05-27 01:14:53 theanets.trainer:168 RmsProp 429 loss=160.654297 err=2.381725
I 2015-05-27 01:15:03 theanets.trainer:168 RmsProp 430 loss=160.346420 err=2.311728
I 2015-05-27 01:15:04 theanets.trainer:168 validation 43 loss=1149.107910 err=991.209961
I 2015-05-27 01:15:14 theanets.trainer:168 RmsProp 431 loss=159.983673 err=2.191939
I 2015-05-27 01:15:24 theanets.trainer:168 RmsProp 432 loss=159.790573 err=2.236727
I 2015-05-27 01:15:35 theanets.trainer:168 RmsProp 433 loss=159.611435 err=2.298050
I 2015-05-27 01:15:45 theanets.trainer:168 RmsProp 434 loss=159.185333 err=2.111098
I 2015-05-27 01:15:55 theanets.trainer:168 RmsProp 435 loss=159.116302 err=2.283454
I 2015-05-27 01:16:06 theanets.trainer:168 RmsProp 436 loss=158.910416 err=2.316920
I 2015-05-27 01:16:17 theanets.trainer:168 RmsProp 437 loss=158.508514 err=2.151080
I 2015-05-27 01:16:27 theanets.trainer:168 RmsProp 438 loss=158.333633 err=2.214768
I 2015-05-27 01:16:38 theanets.trainer:168 RmsProp 439 loss=158.220581 err=2.333061
I 2015-05-27 01:16:48 theanets.trainer:168 RmsProp 440 loss=157.942474 err=2.289446
I 2015-05-27 01:16:49 theanets.trainer:168 validation 44 loss=1143.271118 err=987.747253 *
I 2015-05-27 01:16:59 theanets.trainer:168 RmsProp 441 loss=157.451492 err=2.033585
I 2015-05-27 01:17:10 theanets.trainer:168 RmsProp 442 loss=157.466934 err=2.284017
I 2015-05-27 01:17:20 theanets.trainer:168 RmsProp 443 loss=157.149689 err=2.201809
I 2015-05-27 01:17:30 theanets.trainer:168 RmsProp 444 loss=157.025040 err=2.303965
I 2015-05-27 01:17:41 theanets.trainer:168 RmsProp 445 loss=156.980621 err=2.487353
I 2015-05-27 01:17:52 theanets.trainer:168 RmsProp 446 loss=156.419006 err=2.152082
I 2015-05-27 01:18:02 theanets.trainer:168 RmsProp 447 loss=156.196289 err=2.158969
I 2015-05-27 01:18:13 theanets.trainer:168 RmsProp 448 loss=155.857025 err=2.047403
I 2015-05-27 01:18:24 theanets.trainer:168 RmsProp 449 loss=155.779175 err=2.203284
I 2015-05-27 01:18:35 theanets.trainer:168 RmsProp 450 loss=155.561676 err=2.218472
I 2015-05-27 01:18:35 theanets.trainer:168 validation 45 loss=1139.177246 err=985.948364 *
I 2015-05-27 01:18:46 theanets.trainer:168 RmsProp 451 loss=155.271652 err=2.156234
I 2015-05-27 01:18:57 theanets.trainer:168 RmsProp 452 loss=155.098816 err=2.213001
I 2015-05-27 01:19:07 theanets.trainer:168 RmsProp 453 loss=154.882187 err=2.221059
I 2015-05-27 01:19:18 theanets.trainer:168 RmsProp 454 loss=154.632507 err=2.196466
I 2015-05-27 01:19:29 theanets.trainer:168 RmsProp 455 loss=154.621643 err=2.404408
I 2015-05-27 01:19:39 theanets.trainer:168 RmsProp 456 loss=154.258026 err=2.261460
I 2015-05-27 01:19:50 theanets.trainer:168 RmsProp 457 loss=153.971725 err=2.195933
I 2015-05-27 01:20:01 theanets.trainer:168 RmsProp 458 loss=153.745636 err=2.187051
I 2015-05-27 01:20:12 theanets.trainer:168 RmsProp 459 loss=153.426086 err=2.087930
I 2015-05-27 01:20:23 theanets.trainer:168 RmsProp 460 loss=153.224899 err=2.104739
I 2015-05-27 01:20:23 theanets.trainer:168 validation 46 loss=1136.478149 err=985.475586 *
I 2015-05-27 01:20:34 theanets.trainer:168 RmsProp 461 loss=153.192902 err=2.291907
I 2015-05-27 01:20:44 theanets.trainer:168 RmsProp 462 loss=153.008942 err=2.321947
I 2015-05-27 01:20:55 theanets.trainer:168 RmsProp 463 loss=152.634705 err=2.162750
I 2015-05-27 01:21:05 theanets.trainer:168 RmsProp 464 loss=152.495209 err=2.239314
I 2015-05-27 01:21:16 theanets.trainer:168 RmsProp 465 loss=152.203491 err=2.160197
I 2015-05-27 01:21:26 theanets.trainer:168 RmsProp 466 loss=151.998627 err=2.166739
I 2015-05-27 01:21:36 theanets.trainer:168 RmsProp 467 loss=151.753143 err=2.129826
I 2015-05-27 01:21:47 theanets.trainer:168 RmsProp 468 loss=151.601471 err=2.192488
I 2015-05-27 01:21:58 theanets.trainer:168 RmsProp 469 loss=151.502853 err=2.300321
I 2015-05-27 01:22:08 theanets.trainer:168 RmsProp 470 loss=151.215881 err=2.218755
I 2015-05-27 01:22:09 theanets.trainer:168 validation 47 loss=1118.018677 err=969.137146 *
I 2015-05-27 01:22:20 theanets.trainer:168 RmsProp 471 loss=151.035782 err=2.246521
I 2015-05-27 01:22:30 theanets.trainer:168 RmsProp 472 loss=150.687469 err=2.105876
I 2015-05-27 01:22:41 theanets.trainer:168 RmsProp 473 loss=150.376740 err=2.007875
I 2015-05-27 01:22:52 theanets.trainer:168 RmsProp 474 loss=150.600098 err=2.433894
I 2015-05-27 01:23:02 theanets.trainer:168 RmsProp 475 loss=150.126099 err=2.165127
I 2015-05-27 01:23:13 theanets.trainer:168 RmsProp 476 loss=149.809113 err=2.046381
I 2015-05-27 01:23:23 theanets.trainer:168 RmsProp 477 loss=149.766327 err=2.205315
I 2015-05-27 01:23:34 theanets.trainer:168 RmsProp 478 loss=149.454147 err=2.100714
I 2015-05-27 01:23:45 theanets.trainer:168 RmsProp 479 loss=149.347824 err=2.197106
I 2015-05-27 01:23:55 theanets.trainer:168 RmsProp 480 loss=149.167389 err=2.221565
I 2015-05-27 01:23:56 theanets.trainer:168 validation 48 loss=1123.947510 err=977.098755
I 2015-05-27 01:24:06 theanets.trainer:168 RmsProp 481 loss=149.104431 err=2.353898
I 2015-05-27 01:24:17 theanets.trainer:168 RmsProp 482 loss=148.750534 err=2.201757
I 2015-05-27 01:24:28 theanets.trainer:168 RmsProp 483 loss=148.502350 err=2.151306
I 2015-05-27 01:24:39 theanets.trainer:168 RmsProp 484 loss=148.273056 err=2.121119
I 2015-05-27 01:24:50 theanets.trainer:168 RmsProp 485 loss=148.013947 err=2.064525
I 2015-05-27 01:25:00 theanets.trainer:168 RmsProp 486 loss=148.106293 err=2.352888
I 2015-05-27 01:25:11 theanets.trainer:168 RmsProp 487 loss=147.536041 err=1.981159
I 2015-05-27 01:25:22 theanets.trainer:168 RmsProp 488 loss=147.760864 err=2.399679
I 2015-05-27 01:25:33 theanets.trainer:168 RmsProp 489 loss=147.276947 err=2.109617
I 2015-05-27 01:25:43 theanets.trainer:168 RmsProp 490 loss=147.148102 err=2.168590
I 2015-05-27 01:25:44 theanets.trainer:168 validation 49 loss=1108.660400 err=963.784302 *
I 2015-05-27 01:25:54 theanets.trainer:168 RmsProp 491 loss=146.897308 err=2.110491
I 2015-05-27 01:26:05 theanets.trainer:168 RmsProp 492 loss=146.951141 err=2.355783
I 2015-05-27 01:26:16 theanets.trainer:168 RmsProp 493 loss=146.507492 err=2.099127
I 2015-05-27 01:26:26 theanets.trainer:168 RmsProp 494 loss=146.249878 err=2.035951
I 2015-05-27 01:26:37 theanets.trainer:168 RmsProp 495 loss=146.260040 err=2.235896
I 2015-05-27 01:26:47 theanets.trainer:168 RmsProp 496 loss=145.981216 err=2.147907
I 2015-05-27 01:26:57 theanets.trainer:168 RmsProp 497 loss=145.844528 err=2.198726
I 2015-05-27 01:27:07 theanets.trainer:168 RmsProp 498 loss=145.520416 err=2.064270
I 2015-05-27 01:27:17 theanets.trainer:168 RmsProp 499 loss=145.482330 err=2.217748
I 2015-05-27 01:27:27 theanets.trainer:168 RmsProp 500 loss=145.172745 err=2.093541
I 2015-05-27 01:27:28 theanets.trainer:168 validation 50 loss=1107.647461 err=964.676941 *
I 2015-05-27 01:27:38 theanets.trainer:168 RmsProp 501 loss=144.989441 err=2.101211
I 2015-05-27 01:27:48 theanets.trainer:168 RmsProp 502 loss=144.816345 err=2.112542
I 2015-05-27 01:27:58 theanets.trainer:168 RmsProp 503 loss=144.599899 err=2.083766
I 2015-05-27 01:28:08 theanets.trainer:168 RmsProp 504 loss=144.519058 err=2.189760
I 2015-05-27 01:28:18 theanets.trainer:168 RmsProp 505 loss=144.330780 err=2.187968
I 2015-05-27 01:28:27 theanets.trainer:168 RmsProp 506 loss=144.101303 err=2.143055
I 2015-05-27 01:28:38 theanets.trainer:168 RmsProp 507 loss=143.864243 err=2.091420
I 2015-05-27 01:28:48 theanets.trainer:168 RmsProp 508 loss=143.688263 err=2.102652
I 2015-05-27 01:28:59 theanets.trainer:168 RmsProp 509 loss=143.581741 err=2.175352
I 2015-05-27 01:29:10 theanets.trainer:168 RmsProp 510 loss=143.285507 err=2.064214
I 2015-05-27 01:29:10 theanets.trainer:168 validation 51 loss=1105.514160 err=964.391296 *
I 2015-05-27 01:29:21 theanets.trainer:168 RmsProp 511 loss=143.003143 err=1.965421
I 2015-05-27 01:29:31 theanets.trainer:168 RmsProp 512 loss=143.126175 err=2.270092
I 2015-05-27 01:29:42 theanets.trainer:168 RmsProp 513 loss=142.709732 err=2.038238
I 2015-05-27 01:29:52 theanets.trainer:168 RmsProp 514 loss=142.772293 err=2.278726
I 2015-05-27 01:30:03 theanets.trainer:168 RmsProp 515 loss=142.365204 err=2.050879
I 2015-05-27 01:30:14 theanets.trainer:168 RmsProp 516 loss=142.228012 err=2.088441
I 2015-05-27 01:30:24 theanets.trainer:168 RmsProp 517 loss=142.191116 err=2.228494
I 2015-05-27 01:30:35 theanets.trainer:168 RmsProp 518 loss=141.879059 err=2.091089
I 2015-05-27 01:30:46 theanets.trainer:168 RmsProp 519 loss=141.756760 err=2.145491
I 2015-05-27 01:30:56 theanets.trainer:168 RmsProp 520 loss=141.540573 err=2.106008
I 2015-05-27 01:30:57 theanets.trainer:168 validation 52 loss=1104.795532 err=965.452820 *
I 2015-05-27 01:31:07 theanets.trainer:168 RmsProp 521 loss=141.315887 err=2.057472
I 2015-05-27 01:31:18 theanets.trainer:168 RmsProp 522 loss=141.288010 err=2.206273
I 2015-05-27 01:31:28 theanets.trainer:168 RmsProp 523 loss=141.058899 err=2.150843
I 2015-05-27 01:31:39 theanets.trainer:168 RmsProp 524 loss=140.839554 err=2.109383
I 2015-05-27 01:31:49 theanets.trainer:168 RmsProp 525 loss=140.729736 err=2.173529
I 2015-05-27 01:32:00 theanets.trainer:168 RmsProp 526 loss=140.457001 err=2.073834
I 2015-05-27 01:32:10 theanets.trainer:168 RmsProp 527 loss=140.283997 err=2.074760
I 2015-05-27 01:32:21 theanets.trainer:168 RmsProp 528 loss=140.131180 err=2.097420
I 2015-05-27 01:32:32 theanets.trainer:168 RmsProp 529 loss=139.926941 err=2.069256
I 2015-05-27 01:32:42 theanets.trainer:168 RmsProp 530 loss=139.763031 err=2.077376
I 2015-05-27 01:32:42 theanets.trainer:168 validation 53 loss=1092.875732 err=955.286072 *
I 2015-05-27 01:32:53 theanets.trainer:168 RmsProp 531 loss=139.616684 err=2.106462
I 2015-05-27 01:33:04 theanets.trainer:168 RmsProp 532 loss=139.369019 err=2.030141
I 2015-05-27 01:33:14 theanets.trainer:168 RmsProp 533 loss=139.013275 err=1.851003
I 2015-05-27 01:33:25 theanets.trainer:168 RmsProp 534 loss=139.267029 err=2.275005
I 2015-05-27 01:33:36 theanets.trainer:168 RmsProp 535 loss=138.922394 err=2.102657
I 2015-05-27 01:33:47 theanets.trainer:168 RmsProp 536 loss=138.675964 err=2.027811
I 2015-05-27 01:33:57 theanets.trainer:168 RmsProp 537 loss=138.583252 err=2.102093
I 2015-05-27 01:34:08 theanets.trainer:168 RmsProp 538 loss=138.401627 err=2.090584
I 2015-05-27 01:34:18 theanets.trainer:168 RmsProp 539 loss=138.335373 err=2.189842
I 2015-05-27 01:34:29 theanets.trainer:168 RmsProp 540 loss=138.064728 err=2.082778
I 2015-05-27 01:34:30 theanets.trainer:168 validation 54 loss=1087.728271 err=951.836853 *
I 2015-05-27 01:34:40 theanets.trainer:168 RmsProp 541 loss=137.888885 err=2.071490
I 2015-05-27 01:34:51 theanets.trainer:168 RmsProp 542 loss=137.734039 err=2.081395
I 2015-05-27 01:35:01 theanets.trainer:168 RmsProp 543 loss=137.519928 err=2.032199
I 2015-05-27 01:35:11 theanets.trainer:168 RmsProp 544 loss=137.450180 err=2.122159
I 2015-05-27 01:35:22 theanets.trainer:168 RmsProp 545 loss=137.111115 err=1.949937
I 2015-05-27 01:35:32 theanets.trainer:168 RmsProp 546 loss=137.161148 err=2.161948
I 2015-05-27 01:35:43 theanets.trainer:168 RmsProp 547 loss=136.932724 err=2.097358
I 2015-05-27 01:35:53 theanets.trainer:168 RmsProp 548 loss=136.946808 err=2.271956
I 2015-05-27 01:36:03 theanets.trainer:168 RmsProp 549 loss=136.558029 err=2.048724
I 2015-05-27 01:36:14 theanets.trainer:168 RmsProp 550 loss=136.281601 err=1.937953
I 2015-05-27 01:36:14 theanets.trainer:168 validation 55 loss=1081.942871 err=947.680664 *
I 2015-05-27 01:36:25 theanets.trainer:168 RmsProp 551 loss=136.346909 err=2.163292
I 2015-05-27 01:36:36 theanets.trainer:168 RmsProp 552 loss=136.097260 err=2.077536
I 2015-05-27 01:36:47 theanets.trainer:168 RmsProp 553 loss=135.621185 err=1.768229
I 2015-05-27 01:36:57 theanets.trainer:168 RmsProp 554 loss=135.857834 err=2.165965
I 2015-05-27 01:37:08 theanets.trainer:168 RmsProp 555 loss=135.745010 err=2.217611
I 2015-05-27 01:37:19 theanets.trainer:168 RmsProp 556 loss=135.387268 err=2.019224
I 2015-05-27 01:37:30 theanets.trainer:168 RmsProp 557 loss=135.085419 err=1.881246
I 2015-05-27 01:37:41 theanets.trainer:168 RmsProp 558 loss=135.254181 err=2.204961
I 2015-05-27 01:37:51 theanets.trainer:168 RmsProp 559 loss=134.918610 err=2.027543
I 2015-05-27 01:38:02 theanets.trainer:168 RmsProp 560 loss=134.747421 err=2.012421
I 2015-05-27 01:38:03 theanets.trainer:168 validation 56 loss=1078.295776 err=945.640808 *
I 2015-05-27 01:38:14 theanets.trainer:168 RmsProp 561 loss=134.652664 err=2.075239
I 2015-05-27 01:38:24 theanets.trainer:168 RmsProp 562 loss=134.547729 err=2.125238
I 2015-05-27 01:38:35 theanets.trainer:168 RmsProp 563 loss=134.252365 err=1.987603
I 2015-05-27 01:38:45 theanets.trainer:168 RmsProp 564 loss=134.153839 err=2.047912
I 2015-05-27 01:38:56 theanets.trainer:168 RmsProp 565 loss=133.972275 err=2.018645
I 2015-05-27 01:39:07 theanets.trainer:168 RmsProp 566 loss=134.010635 err=2.212988
I 2015-05-27 01:39:17 theanets.trainer:168 RmsProp 567 loss=133.697754 err=2.053627
I 2015-05-27 01:39:28 theanets.trainer:168 RmsProp 568 loss=133.564072 err=2.071373
I 2015-05-27 01:39:38 theanets.trainer:168 RmsProp 569 loss=133.272766 err=1.938541
I 2015-05-27 01:39:48 theanets.trainer:168 RmsProp 570 loss=133.230118 err=2.046945
I 2015-05-27 01:39:49 theanets.trainer:168 validation 57 loss=1074.786743 err=943.679138 *
I 2015-05-27 01:40:00 theanets.trainer:168 RmsProp 571 loss=133.065643 err=2.036033
I 2015-05-27 01:40:10 theanets.trainer:168 RmsProp 572 loss=132.957230 err=2.077085
I 2015-05-27 01:40:22 theanets.trainer:168 RmsProp 573 loss=132.546173 err=1.823574
I 2015-05-27 01:40:32 theanets.trainer:168 RmsProp 574 loss=132.812546 err=2.235633
I 2015-05-27 01:40:43 theanets.trainer:168 RmsProp 575 loss=132.445587 err=2.020655
I 2015-05-27 01:40:54 theanets.trainer:168 RmsProp 576 loss=132.145157 err=1.872887
I 2015-05-27 01:41:04 theanets.trainer:168 RmsProp 577 loss=132.492950 err=2.364440
I 2015-05-27 01:41:14 theanets.trainer:168 RmsProp 578 loss=131.924210 err=1.947380
I 2015-05-27 01:41:24 theanets.trainer:168 RmsProp 579 loss=131.895279 err=2.064360
I 2015-05-27 01:41:33 theanets.trainer:168 RmsProp 580 loss=131.763077 err=2.076032
I 2015-05-27 01:41:34 theanets.trainer:168 validation 58 loss=1078.344727 err=948.736328
I 2015-05-27 01:41:43 theanets.trainer:168 RmsProp 581 loss=131.676163 err=2.131990
I 2015-05-27 01:41:53 theanets.trainer:168 RmsProp 582 loss=131.343750 err=1.947509
I 2015-05-27 01:42:02 theanets.trainer:168 RmsProp 583 loss=131.179520 err=1.929208
I 2015-05-27 01:42:12 theanets.trainer:168 RmsProp 584 loss=131.086975 err=1.982948
I 2015-05-27 01:42:22 theanets.trainer:168 RmsProp 585 loss=131.088837 err=2.134862
I 2015-05-27 01:42:31 theanets.trainer:168 RmsProp 586 loss=130.857910 err=2.046590
I 2015-05-27 01:42:41 theanets.trainer:168 RmsProp 587 loss=130.601242 err=1.936299
I 2015-05-27 01:42:50 theanets.trainer:168 RmsProp 588 loss=130.536270 err=2.015958
I 2015-05-27 01:42:59 theanets.trainer:168 RmsProp 589 loss=130.358749 err=1.985019
I 2015-05-27 01:43:09 theanets.trainer:168 RmsProp 590 loss=130.319763 err=2.091892
I 2015-05-27 01:43:09 theanets.trainer:168 validation 59 loss=1073.085815 err=944.936951 *
I 2015-05-27 01:43:19 theanets.trainer:168 RmsProp 591 loss=130.064377 err=1.981886
I 2015-05-27 01:43:28 theanets.trainer:168 RmsProp 592 loss=130.005493 err=2.067244
I 2015-05-27 01:43:38 theanets.trainer:168 RmsProp 593 loss=129.769623 err=1.975501
I 2015-05-27 01:43:47 theanets.trainer:168 RmsProp 594 loss=129.677292 err=2.032226
I 2015-05-27 01:43:56 theanets.trainer:168 RmsProp 595 loss=129.631577 err=2.123957
I 2015-05-27 01:44:06 theanets.trainer:168 RmsProp 596 loss=129.485947 err=2.119309
I 2015-05-27 01:44:15 theanets.trainer:168 RmsProp 597 loss=129.101044 err=1.878815
I 2015-05-27 01:44:24 theanets.trainer:168 RmsProp 598 loss=129.117828 err=2.032463
I 2015-05-27 01:44:34 theanets.trainer:168 RmsProp 599 loss=128.776901 err=1.837878
I 2015-05-27 01:44:44 theanets.trainer:168 RmsProp 600 loss=128.946503 err=2.147147
I 2015-05-27 01:44:44 theanets.trainer:168 validation 60 loss=1070.954346 err=944.224731 *
I 2015-05-27 01:44:54 theanets.trainer:168 RmsProp 601 loss=128.794876 err=2.133841
I 2015-05-27 01:45:03 theanets.trainer:168 RmsProp 602 loss=128.590408 err=2.064948
I 2015-05-27 01:45:13 theanets.trainer:168 RmsProp 603 loss=128.424835 err=2.042717
I 2015-05-27 01:45:22 theanets.trainer:168 RmsProp 604 loss=128.221313 err=1.978995
I 2015-05-27 01:45:32 theanets.trainer:168 RmsProp 605 loss=128.188004 err=2.080425
I 2015-05-27 01:45:41 theanets.trainer:168 RmsProp 606 loss=127.910995 err=1.944513
I 2015-05-27 01:45:51 theanets.trainer:168 RmsProp 607 loss=127.814331 err=1.985785
I 2015-05-27 01:46:01 theanets.trainer:168 RmsProp 608 loss=127.758224 err=2.069295
I 2015-05-27 01:46:10 theanets.trainer:168 RmsProp 609 loss=127.463722 err=1.912322
I 2015-05-27 01:46:19 theanets.trainer:168 RmsProp 610 loss=127.387894 err=1.969844
I 2015-05-27 01:46:20 theanets.trainer:168 validation 61 loss=1060.830933 err=935.496887 *
I 2015-05-27 01:46:30 theanets.trainer:168 RmsProp 611 loss=127.321609 err=2.040532
I 2015-05-27 01:46:39 theanets.trainer:168 RmsProp 612 loss=127.148438 err=2.000297
I 2015-05-27 01:46:49 theanets.trainer:168 RmsProp 613 loss=127.173584 err=2.161552
I 2015-05-27 01:46:58 theanets.trainer:168 RmsProp 614 loss=126.700867 err=1.825711
I 2015-05-27 01:47:08 theanets.trainer:168 RmsProp 615 loss=126.774185 err=2.034622
I 2015-05-27 01:47:17 theanets.trainer:168 RmsProp 616 loss=126.653793 err=2.045784
I 2015-05-27 01:47:27 theanets.trainer:168 RmsProp 617 loss=126.460083 err=1.986262
I 2015-05-27 01:47:36 theanets.trainer:168 RmsProp 618 loss=126.288132 err=1.949683
I 2015-05-27 01:47:46 theanets.trainer:168 RmsProp 619 loss=126.221092 err=2.012692
I 2015-05-27 01:47:55 theanets.trainer:168 RmsProp 620 loss=126.104111 err=2.028963
I 2015-05-27 01:47:55 theanets.trainer:168 validation 62 loss=1056.952393 err=932.946411 *
I 2015-05-27 01:48:05 theanets.trainer:168 RmsProp 621 loss=125.916908 err=1.975585
I 2015-05-27 01:48:14 theanets.trainer:168 RmsProp 622 loss=125.771744 err=1.965331
I 2015-05-27 01:48:23 theanets.trainer:168 RmsProp 623 loss=125.871445 err=2.191108
I 2015-05-27 01:48:33 theanets.trainer:168 RmsProp 624 loss=125.474770 err=1.928423
I 2015-05-27 01:48:42 theanets.trainer:168 RmsProp 625 loss=125.434372 err=2.018377
I 2015-05-27 01:48:52 theanets.trainer:168 RmsProp 626 loss=125.135361 err=1.851771
I 2015-05-27 01:49:01 theanets.trainer:168 RmsProp 627 loss=125.217911 err=2.067664
I 2015-05-27 01:49:11 theanets.trainer:168 RmsProp 628 loss=125.106483 err=2.084931
I 2015-05-27 01:49:20 theanets.trainer:168 RmsProp 629 loss=124.969444 err=2.078440
I 2015-05-27 01:49:29 theanets.trainer:168 RmsProp 630 loss=124.635475 err=1.877857
I 2015-05-27 01:49:29 theanets.trainer:168 validation 63 loss=1056.133789 err=933.442505 *
I 2015-05-27 01:49:38 theanets.trainer:168 RmsProp 631 loss=124.699364 err=2.069267
I 2015-05-27 01:49:47 theanets.trainer:168 RmsProp 632 loss=124.428329 err=1.925173
I 2015-05-27 01:49:56 theanets.trainer:168 RmsProp 633 loss=124.437927 err=2.062143
I 2015-05-27 01:50:05 theanets.trainer:168 RmsProp 634 loss=124.251953 err=2.004778
I 2015-05-27 01:50:13 theanets.trainer:168 RmsProp 635 loss=124.082069 err=1.961040
I 2015-05-27 01:50:22 theanets.trainer:168 RmsProp 636 loss=123.987816 err=1.995512
I 2015-05-27 01:50:31 theanets.trainer:168 RmsProp 637 loss=123.824013 err=1.959025
I 2015-05-27 01:50:40 theanets.trainer:168 RmsProp 638 loss=123.641029 err=1.903455
I 2015-05-27 01:50:48 theanets.trainer:168 RmsProp 639 loss=123.714844 err=2.105518
I 2015-05-27 01:50:57 theanets.trainer:168 RmsProp 640 loss=123.504921 err=2.019893
I 2015-05-27 01:50:57 theanets.trainer:168 validation 64 loss=1055.226196 err=933.811951 *
I 2015-05-27 01:51:07 theanets.trainer:168 RmsProp 641 loss=123.317932 err=1.959661
I 2015-05-27 01:51:16 theanets.trainer:168 RmsProp 642 loss=123.267822 err=2.033419
I 2015-05-27 01:51:26 theanets.trainer:168 RmsProp 643 loss=123.095718 err=1.984330
I 2015-05-27 01:51:36 theanets.trainer:168 RmsProp 644 loss=122.941566 err=1.956693
I 2015-05-27 01:51:46 theanets.trainer:168 RmsProp 645 loss=122.838379 err=1.980480
I 2015-05-27 01:51:56 theanets.trainer:168 RmsProp 646 loss=122.645920 err=1.911121
I 2015-05-27 01:52:06 theanets.trainer:168 RmsProp 647 loss=122.612915 err=2.000731
I 2015-05-27 01:52:16 theanets.trainer:168 RmsProp 648 loss=122.376442 err=1.890548
I 2015-05-27 01:52:26 theanets.trainer:168 RmsProp 649 loss=122.232666 err=1.871508
I 2015-05-27 01:52:35 theanets.trainer:168 RmsProp 650 loss=122.149757 err=1.913654
I 2015-05-27 01:52:36 theanets.trainer:168 validation 65 loss=1053.189087 err=933.016296 *
I 2015-05-27 01:52:46 theanets.trainer:168 RmsProp 651 loss=122.146873 err=2.033916
I 2015-05-27 01:52:55 theanets.trainer:168 RmsProp 652 loss=122.051529 err=2.060721
I 2015-05-27 01:53:05 theanets.trainer:168 RmsProp 653 loss=121.931412 err=2.064023
I 2015-05-27 01:53:14 theanets.trainer:168 RmsProp 654 loss=121.725586 err=1.980531
I 2015-05-27 01:53:24 theanets.trainer:168 RmsProp 655 loss=121.574631 err=1.952781
I 2015-05-27 01:53:33 theanets.trainer:168 RmsProp 656 loss=121.429932 err=1.924308
I 2015-05-27 01:53:43 theanets.trainer:168 RmsProp 657 loss=121.221375 err=1.839900
I 2015-05-27 01:53:53 theanets.trainer:168 RmsProp 658 loss=121.242920 err=1.979511
I 2015-05-27 01:54:02 theanets.trainer:168 RmsProp 659 loss=121.175926 err=2.028059
I 2015-05-27 01:54:12 theanets.trainer:168 RmsProp 660 loss=120.965675 err=1.938413
I 2015-05-27 01:54:12 theanets.trainer:168 validation 66 loss=1043.375977 err=924.404480 *
I 2015-05-27 01:54:22 theanets.trainer:168 RmsProp 661 loss=120.796402 err=1.890857
I 2015-05-27 01:54:32 theanets.trainer:168 RmsProp 662 loss=120.814682 err=2.036165
I 2015-05-27 01:54:41 theanets.trainer:168 RmsProp 663 loss=120.587807 err=1.931468
I 2015-05-27 01:54:51 theanets.trainer:168 RmsProp 664 loss=120.513321 err=1.976858
I 2015-05-27 01:55:01 theanets.trainer:168 RmsProp 665 loss=120.464989 err=2.045755
I 2015-05-27 01:55:10 theanets.trainer:168 RmsProp 666 loss=120.215965 err=1.915157
I 2015-05-27 01:55:19 theanets.trainer:168 RmsProp 667 loss=120.051781 err=1.870591
I 2015-05-27 01:55:29 theanets.trainer:168 RmsProp 668 loss=120.041000 err=1.973960
I 2015-05-27 01:55:39 theanets.trainer:168 RmsProp 669 loss=119.809143 err=1.862316
I 2015-05-27 01:55:49 theanets.trainer:168 RmsProp 670 loss=119.914833 err=2.081084
I 2015-05-27 01:55:49 theanets.trainer:168 validation 67 loss=1040.569824 err=922.799255 *
I 2015-05-27 01:55:58 theanets.trainer:168 RmsProp 671 loss=119.944664 err=2.226585
I 2015-05-27 01:56:08 theanets.trainer:168 RmsProp 672 loss=119.520691 err=1.918789
I 2015-05-27 01:56:17 theanets.trainer:168 RmsProp 673 loss=119.472885 err=1.986411
I 2015-05-27 01:56:27 theanets.trainer:168 RmsProp 674 loss=119.274231 err=1.902158
I 2015-05-27 01:56:37 theanets.trainer:168 RmsProp 675 loss=119.133423 err=1.874932
I 2015-05-27 01:56:46 theanets.trainer:168 RmsProp 676 loss=119.157494 err=2.015645
I 2015-05-27 01:56:56 theanets.trainer:168 RmsProp 677 loss=118.940392 err=1.913222
I 2015-05-27 01:57:06 theanets.trainer:168 RmsProp 678 loss=118.888733 err=1.981790
I 2015-05-27 01:57:16 theanets.trainer:168 RmsProp 679 loss=118.742081 err=1.948035
I 2015-05-27 01:57:26 theanets.trainer:168 RmsProp 680 loss=118.665321 err=1.984540
I 2015-05-27 01:57:26 theanets.trainer:168 validation 68 loss=1036.946289 err=920.333496 *
I 2015-05-27 01:57:36 theanets.trainer:168 RmsProp 681 loss=118.431015 err=1.866537
I 2015-05-27 01:57:46 theanets.trainer:168 RmsProp 682 loss=118.439865 err=1.986550
I 2015-05-27 01:57:55 theanets.trainer:168 RmsProp 683 loss=118.336510 err=1.998753
I 2015-05-27 01:58:05 theanets.trainer:168 RmsProp 684 loss=118.022781 err=1.795820
I 2015-05-27 01:58:14 theanets.trainer:168 RmsProp 685 loss=118.030724 err=1.921047
I 2015-05-27 01:58:24 theanets.trainer:168 RmsProp 686 loss=118.051468 err=2.054423
I 2015-05-27 01:58:34 theanets.trainer:168 RmsProp 687 loss=117.828110 err=1.942282
I 2015-05-27 01:58:43 theanets.trainer:168 RmsProp 688 loss=117.721031 err=1.949989
I 2015-05-27 01:58:53 theanets.trainer:168 RmsProp 689 loss=117.580795 err=1.920087
I 2015-05-27 01:59:03 theanets.trainer:168 RmsProp 690 loss=117.465500 err=1.919791
I 2015-05-27 01:59:04 theanets.trainer:168 validation 69 loss=1035.221680 err=919.730896 *
I 2015-05-27 01:59:13 theanets.trainer:168 RmsProp 691 loss=117.353088 err=1.919286
I 2015-05-27 01:59:23 theanets.trainer:168 RmsProp 692 loss=117.281471 err=1.957931
I 2015-05-27 01:59:32 theanets.trainer:168 RmsProp 693 loss=117.105247 err=1.892245
I 2015-05-27 01:59:42 theanets.trainer:168 RmsProp 694 loss=117.052979 err=1.952806
I 2015-05-27 01:59:52 theanets.trainer:168 RmsProp 695 loss=116.903244 err=1.913707
I 2015-05-27 02:00:01 theanets.trainer:168 RmsProp 696 loss=116.773666 err=1.891291
I 2015-05-27 02:00:11 theanets.trainer:168 RmsProp 697 loss=116.662865 err=1.895494
I 2015-05-27 02:00:21 theanets.trainer:168 RmsProp 698 loss=116.640053 err=1.979518
I 2015-05-27 02:00:31 theanets.trainer:168 RmsProp 699 loss=116.425377 err=1.877422
I 2015-05-27 02:00:40 theanets.trainer:168 RmsProp 700 loss=116.422752 err=1.986029
I 2015-05-27 02:00:41 theanets.trainer:168 validation 70 loss=1031.631348 err=917.250427 *
I 2015-05-27 02:00:51 theanets.trainer:168 RmsProp 701 loss=116.137390 err=1.810043
I 2015-05-27 02:01:01 theanets.trainer:168 RmsProp 702 loss=116.166702 err=1.949615
I 2015-05-27 02:01:11 theanets.trainer:168 RmsProp 703 loss=116.015671 err=1.904018
I 2015-05-27 02:01:21 theanets.trainer:168 RmsProp 704 loss=115.897507 err=1.896256
I 2015-05-27 02:01:30 theanets.trainer:168 RmsProp 705 loss=115.786583 err=1.897592
I 2015-05-27 02:01:40 theanets.trainer:168 RmsProp 706 loss=115.688004 err=1.909347
I 2015-05-27 02:01:50 theanets.trainer:168 RmsProp 707 loss=115.539772 err=1.865170
I 2015-05-27 02:01:59 theanets.trainer:168 RmsProp 708 loss=115.442848 err=1.880716
I 2015-05-27 02:02:09 theanets.trainer:168 RmsProp 709 loss=115.402000 err=1.949991
I 2015-05-27 02:02:19 theanets.trainer:168 RmsProp 710 loss=115.204506 err=1.861086
I 2015-05-27 02:02:19 theanets.trainer:168 validation 71 loss=1028.994385 err=915.716003 *
I 2015-05-27 02:02:29 theanets.trainer:168 RmsProp 711 loss=115.070633 err=1.839140
I 2015-05-27 02:02:39 theanets.trainer:168 RmsProp 712 loss=114.994934 err=1.868008
I 2015-05-27 02:02:49 theanets.trainer:168 RmsProp 713 loss=115.066360 err=2.044883
I 2015-05-27 02:02:58 theanets.trainer:168 RmsProp 714 loss=114.765785 err=1.851203
I 2015-05-27 02:03:08 theanets.trainer:168 RmsProp 715 loss=114.667648 err=1.856858
I 2015-05-27 02:03:18 theanets.trainer:168 RmsProp 716 loss=114.680702 err=1.974714
I 2015-05-27 02:03:27 theanets.trainer:168 RmsProp 717 loss=114.514725 err=1.907446
I 2015-05-27 02:03:37 theanets.trainer:168 RmsProp 718 loss=114.406105 err=1.903231
I 2015-05-27 02:03:47 theanets.trainer:168 RmsProp 719 loss=114.312180 err=1.911632
I 2015-05-27 02:03:56 theanets.trainer:168 RmsProp 720 loss=114.234573 err=1.941444
I 2015-05-27 02:03:57 theanets.trainer:168 validation 72 loss=1026.901855 err=914.665466 *
I 2015-05-27 02:04:07 theanets.trainer:168 RmsProp 721 loss=114.103409 err=1.913739
I 2015-05-27 02:04:17 theanets.trainer:168 RmsProp 722 loss=114.101929 err=2.012920
I 2015-05-27 02:04:27 theanets.trainer:168 RmsProp 723 loss=114.061195 err=2.072069
I 2015-05-27 02:04:36 theanets.trainer:168 RmsProp 724 loss=113.694229 err=1.805959
I 2015-05-27 02:04:47 theanets.trainer:168 RmsProp 725 loss=113.705788 err=1.921932
I 2015-05-27 02:04:57 theanets.trainer:168 RmsProp 726 loss=113.580429 err=1.895420
I 2015-05-27 02:05:07 theanets.trainer:168 RmsProp 727 loss=113.454201 err=1.873723
I 2015-05-27 02:05:16 theanets.trainer:168 RmsProp 728 loss=113.419960 err=1.940169
I 2015-05-27 02:05:26 theanets.trainer:168 RmsProp 729 loss=113.173683 err=1.794995
I 2015-05-27 02:05:36 theanets.trainer:168 RmsProp 730 loss=113.021408 err=1.748390
I 2015-05-27 02:05:37 theanets.trainer:168 validation 73 loss=1026.381836 err=915.158813 *
I 2015-05-27 02:05:46 theanets.trainer:168 RmsProp 731 loss=113.140526 err=1.967824
I 2015-05-27 02:05:56 theanets.trainer:168 RmsProp 732 loss=112.825638 err=1.755928
I 2015-05-27 02:06:06 theanets.trainer:168 RmsProp 733 loss=112.931114 err=1.961390
I 2015-05-27 02:06:16 theanets.trainer:168 RmsProp 734 loss=112.768631 err=1.903114
I 2015-05-27 02:06:26 theanets.trainer:168 RmsProp 735 loss=112.828735 err=2.058248
I 2015-05-27 02:06:35 theanets.trainer:168 RmsProp 736 loss=112.550453 err=1.878510
I 2015-05-27 02:06:45 theanets.trainer:168 RmsProp 737 loss=112.540421 err=1.966817
I 2015-05-27 02:06:55 theanets.trainer:168 RmsProp 738 loss=112.281326 err=1.810144
I 2015-05-27 02:07:05 theanets.trainer:168 RmsProp 739 loss=112.079971 err=1.711046
I 2015-05-27 02:07:15 theanets.trainer:168 RmsProp 740 loss=112.344116 err=2.070674
I 2015-05-27 02:07:16 theanets.trainer:168 validation 74 loss=1018.923157 err=908.704285 *
I 2015-05-27 02:07:25 theanets.trainer:168 RmsProp 741 loss=112.121315 err=1.948851
I 2015-05-27 02:07:35 theanets.trainer:168 RmsProp 742 loss=111.855118 err=1.778691
I 2015-05-27 02:07:45 theanets.trainer:168 RmsProp 743 loss=111.862778 err=1.883305
I 2015-05-27 02:07:54 theanets.trainer:168 RmsProp 744 loss=111.789345 err=1.909940
I 2015-05-27 02:08:04 theanets.trainer:168 RmsProp 745 loss=111.555931 err=1.776017
I 2015-05-27 02:08:14 theanets.trainer:168 RmsProp 746 loss=111.550537 err=1.869301
I 2015-05-27 02:08:24 theanets.trainer:168 RmsProp 747 loss=111.428932 err=1.843857
I 2015-05-27 02:08:33 theanets.trainer:168 RmsProp 748 loss=111.380043 err=1.892202
I 2015-05-27 02:08:43 theanets.trainer:168 RmsProp 749 loss=111.304459 err=1.913129
I 2015-05-27 02:08:53 theanets.trainer:168 RmsProp 750 loss=111.136765 err=1.843438
I 2015-05-27 02:08:54 theanets.trainer:168 validation 75 loss=1013.933777 err=904.698181 *
I 2015-05-27 02:09:03 theanets.trainer:168 RmsProp 751 loss=111.140137 err=1.940954
I 2015-05-27 02:09:13 theanets.trainer:168 RmsProp 752 loss=110.901382 err=1.799473
I 2015-05-27 02:09:23 theanets.trainer:168 RmsProp 753 loss=110.931374 err=1.929342
I 2015-05-27 02:09:33 theanets.trainer:168 RmsProp 754 loss=110.806564 err=1.900350
I 2015-05-27 02:09:43 theanets.trainer:168 RmsProp 755 loss=110.634865 err=1.827220
I 2015-05-27 02:09:52 theanets.trainer:168 RmsProp 756 loss=110.542503 err=1.829125
I 2015-05-27 02:10:02 theanets.trainer:168 RmsProp 757 loss=110.493248 err=1.876054
I 2015-05-27 02:10:11 theanets.trainer:168 RmsProp 758 loss=110.386047 err=1.865750
I 2015-05-27 02:10:21 theanets.trainer:168 RmsProp 759 loss=110.378540 err=1.952935
I 2015-05-27 02:10:31 theanets.trainer:168 RmsProp 760 loss=110.186241 err=1.856779
I 2015-05-27 02:10:32 theanets.trainer:168 validation 76 loss=1011.098572 err=902.816895 *
I 2015-05-27 02:10:41 theanets.trainer:168 RmsProp 761 loss=109.931786 err=1.698647
I 2015-05-27 02:10:51 theanets.trainer:168 RmsProp 762 loss=110.054489 err=1.917463
I 2015-05-27 02:11:01 theanets.trainer:168 RmsProp 763 loss=109.923973 err=1.880515
I 2015-05-27 02:11:10 theanets.trainer:168 RmsProp 764 loss=109.895584 err=1.946678
I 2015-05-27 02:11:20 theanets.trainer:168 RmsProp 765 loss=109.837479 err=1.980258
I 2015-05-27 02:11:30 theanets.trainer:168 RmsProp 766 loss=109.458656 err=1.695643
I 2015-05-27 02:11:40 theanets.trainer:168 RmsProp 767 loss=109.701920 err=2.034460
I 2015-05-27 02:11:49 theanets.trainer:168 RmsProp 768 loss=109.393105 err=1.820946
I 2015-05-27 02:11:59 theanets.trainer:168 RmsProp 769 loss=109.353699 err=1.876644
I 2015-05-27 02:12:08 theanets.trainer:168 RmsProp 770 loss=109.302612 err=1.918804
I 2015-05-27 02:12:09 theanets.trainer:168 validation 77 loss=1009.463379 err=902.121094 *
I 2015-05-27 02:12:19 theanets.trainer:168 RmsProp 771 loss=109.181763 err=1.889361
I 2015-05-27 02:12:28 theanets.trainer:168 RmsProp 772 loss=109.031479 err=1.834103
I 2015-05-27 02:12:38 theanets.trainer:168 RmsProp 773 loss=108.871094 err=1.763105
I 2015-05-27 02:12:48 theanets.trainer:168 RmsProp 774 loss=108.930832 err=1.915604
I 2015-05-27 02:12:58 theanets.trainer:168 RmsProp 775 loss=108.854874 err=1.928072
I 2015-05-27 02:13:08 theanets.trainer:168 RmsProp 776 loss=108.597656 err=1.764724
I 2015-05-27 02:13:17 theanets.trainer:168 RmsProp 777 loss=108.611526 err=1.870487
I 2015-05-27 02:13:27 theanets.trainer:168 RmsProp 778 loss=108.526245 err=1.877380
I 2015-05-27 02:13:37 theanets.trainer:168 RmsProp 779 loss=108.332016 err=1.775932
I 2015-05-27 02:13:47 theanets.trainer:168 RmsProp 780 loss=108.628868 err=2.160222
I 2015-05-27 02:13:47 theanets.trainer:168 validation 78 loss=1006.639160 err=900.220825 *
I 2015-05-27 02:13:57 theanets.trainer:168 RmsProp 781 loss=108.089706 err=1.715017
I 2015-05-27 02:14:07 theanets.trainer:168 RmsProp 782 loss=108.105995 err=1.821236
I 2015-05-27 02:14:17 theanets.trainer:168 RmsProp 783 loss=108.146202 err=1.952052
I 2015-05-27 02:14:26 theanets.trainer:168 RmsProp 784 loss=107.867516 err=1.758294
I 2015-05-27 02:14:35 theanets.trainer:168 RmsProp 785 loss=107.968910 err=1.952064
I 2015-05-27 02:14:45 theanets.trainer:168 RmsProp 786 loss=107.755882 err=1.830331
I 2015-05-27 02:14:54 theanets.trainer:168 RmsProp 787 loss=107.822472 err=1.984858
I 2015-05-27 02:15:04 theanets.trainer:168 RmsProp 788 loss=107.575302 err=1.827008
I 2015-05-27 02:15:13 theanets.trainer:168 RmsProp 789 loss=107.597794 err=1.935633
I 2015-05-27 02:15:22 theanets.trainer:168 RmsProp 790 loss=107.400223 err=1.827360
I 2015-05-27 02:15:23 theanets.trainer:168 validation 79 loss=1004.330994 err=898.811340 *
I 2015-05-27 02:15:32 theanets.trainer:168 RmsProp 791 loss=107.375183 err=1.890186
I 2015-05-27 02:15:42 theanets.trainer:168 RmsProp 792 loss=107.238037 err=1.839385
I 2015-05-27 02:15:51 theanets.trainer:168 RmsProp 793 loss=107.083717 err=1.771811
I 2015-05-27 02:16:00 theanets.trainer:168 RmsProp 794 loss=107.023315 err=1.802673
I 2015-05-27 02:16:09 theanets.trainer:168 RmsProp 795 loss=107.024231 err=1.895974
I 2015-05-27 02:16:18 theanets.trainer:168 RmsProp 796 loss=106.802246 err=1.761244
I 2015-05-27 02:16:26 theanets.trainer:168 RmsProp 797 loss=106.832420 err=1.883621
I 2015-05-27 02:16:34 theanets.trainer:168 RmsProp 798 loss=106.685768 err=1.823316
I 2015-05-27 02:16:42 theanets.trainer:168 RmsProp 799 loss=106.478134 err=1.703540
I 2015-05-27 02:16:51 theanets.trainer:168 RmsProp 800 loss=106.511002 err=1.826547
I 2015-05-27 02:16:51 theanets.trainer:168 validation 80 loss=1000.445923 err=895.808228 *
I 2015-05-27 02:16:59 theanets.trainer:168 RmsProp 801 loss=106.535889 err=1.939971
I 2015-05-27 02:17:08 theanets.trainer:168 RmsProp 802 loss=106.515099 err=2.007612
I 2015-05-27 02:17:16 theanets.trainer:168 RmsProp 803 loss=106.186829 err=1.766101
I 2015-05-27 02:17:25 theanets.trainer:168 RmsProp 804 loss=106.020363 err=1.691881
I 2015-05-27 02:17:33 theanets.trainer:168 RmsProp 805 loss=105.955933 err=1.712187
I 2015-05-27 02:17:42 theanets.trainer:168 RmsProp 806 loss=106.203308 err=2.043893
I 2015-05-27 02:17:50 theanets.trainer:168 RmsProp 807 loss=105.715210 err=1.649248
I 2015-05-27 02:17:58 theanets.trainer:168 RmsProp 808 loss=105.785538 err=1.802937
I 2015-05-27 02:18:05 theanets.trainer:168 RmsProp 809 loss=105.742897 err=1.850505
I 2015-05-27 02:18:14 theanets.trainer:168 RmsProp 810 loss=105.559547 err=1.756194
I 2015-05-27 02:18:14 theanets.trainer:168 validation 81 loss=997.346191 err=893.582153 *
I 2015-05-27 02:18:22 theanets.trainer:168 RmsProp 811 loss=105.710770 err=1.991805
I 2015-05-27 02:18:30 theanets.trainer:168 RmsProp 812 loss=105.460129 err=1.826008
I 2015-05-27 02:18:38 theanets.trainer:168 RmsProp 813 loss=105.584213 err=2.034027
I 2015-05-27 02:18:45 theanets.trainer:168 RmsProp 814 loss=105.273399 err=1.808579
I 2015-05-27 02:18:53 theanets.trainer:168 RmsProp 815 loss=105.127831 err=1.746957
I 2015-05-27 02:19:02 theanets.trainer:168 RmsProp 816 loss=105.068863 err=1.773424
I 2015-05-27 02:19:10 theanets.trainer:168 RmsProp 817 loss=105.283058 err=2.065650
I 2015-05-27 02:19:18 theanets.trainer:168 RmsProp 818 loss=104.911339 err=1.781518
I 2015-05-27 02:19:26 theanets.trainer:168 RmsProp 819 loss=104.776894 err=1.732303
I 2015-05-27 02:19:34 theanets.trainer:168 RmsProp 820 loss=105.014481 err=2.053685
I 2015-05-27 02:19:34 theanets.trainer:168 validation 82 loss=995.251099 err=892.348328 *
I 2015-05-27 02:19:42 theanets.trainer:168 RmsProp 821 loss=104.592819 err=1.719022
I 2015-05-27 02:19:50 theanets.trainer:168 RmsProp 822 loss=104.640244 err=1.848185
I 2015-05-27 02:19:57 theanets.trainer:168 RmsProp 823 loss=104.359177 err=1.656280
I 2015-05-27 02:20:05 theanets.trainer:168 RmsProp 824 loss=104.424759 err=1.802816
I 2015-05-27 02:20:14 theanets.trainer:168 RmsProp 825 loss=104.313354 err=1.774761
I 2015-05-27 02:20:22 theanets.trainer:168 RmsProp 826 loss=104.141212 err=1.688553
I 2015-05-27 02:20:30 theanets.trainer:168 RmsProp 827 loss=104.114647 err=1.747651
I 2015-05-27 02:20:38 theanets.trainer:168 RmsProp 828 loss=104.269409 err=1.987687
I 2015-05-27 02:20:46 theanets.trainer:168 RmsProp 829 loss=103.963440 err=1.763437
I 2015-05-27 02:20:54 theanets.trainer:168 RmsProp 830 loss=103.993668 err=1.877104
I 2015-05-27 02:20:54 theanets.trainer:168 validation 83 loss=995.527405 err=893.448364
I 2015-05-27 02:21:01 theanets.trainer:168 RmsProp 831 loss=104.049454 err=2.010387
I 2015-05-27 02:21:09 theanets.trainer:168 RmsProp 832 loss=103.742531 err=1.786415
I 2015-05-27 02:21:16 theanets.trainer:168 RmsProp 833 loss=103.718674 err=1.845325
I 2015-05-27 02:21:24 theanets.trainer:168 RmsProp 834 loss=103.551254 err=1.757851
I 2015-05-27 02:21:32 theanets.trainer:168 RmsProp 835 loss=103.525185 err=1.816006
I 2015-05-27 02:21:40 theanets.trainer:168 RmsProp 836 loss=103.483780 err=1.853168
I 2015-05-27 02:21:47 theanets.trainer:168 RmsProp 837 loss=103.259315 err=1.714865
I 2015-05-27 02:21:55 theanets.trainer:168 RmsProp 838 loss=103.049622 err=1.589620
I 2015-05-27 02:22:03 theanets.trainer:168 RmsProp 839 loss=103.481216 err=2.097483
I 2015-05-27 02:22:10 theanets.trainer:168 RmsProp 840 loss=103.045555 err=1.742878
I 2015-05-27 02:22:11 theanets.trainer:168 validation 84 loss=990.066589 err=888.800293 *
I 2015-05-27 02:22:18 theanets.trainer:168 RmsProp 841 loss=103.048355 err=1.824131
I 2015-05-27 02:22:26 theanets.trainer:168 RmsProp 842 loss=102.959518 err=1.819850
I 2015-05-27 02:22:33 theanets.trainer:168 RmsProp 843 loss=102.842979 err=1.780985
I 2015-05-27 02:22:41 theanets.trainer:168 RmsProp 844 loss=102.816086 err=1.834772
I 2015-05-27 02:22:50 theanets.trainer:168 RmsProp 845 loss=102.745041 err=1.841244
I 2015-05-27 02:22:57 theanets.trainer:168 RmsProp 846 loss=102.548851 err=1.729150
I 2015-05-27 02:23:04 theanets.trainer:168 RmsProp 847 loss=102.576782 err=1.835222
I 2015-05-27 02:23:12 theanets.trainer:168 RmsProp 848 loss=102.300247 err=1.639880
I 2015-05-27 02:23:20 theanets.trainer:168 RmsProp 849 loss=102.412865 err=1.832378
I 2015-05-27 02:23:28 theanets.trainer:168 RmsProp 850 loss=102.274940 err=1.773383
I 2015-05-27 02:23:29 theanets.trainer:168 validation 85 loss=987.536011 err=887.076599 *
I 2015-05-27 02:23:36 theanets.trainer:168 RmsProp 851 loss=102.385330 err=1.963748
I 2015-05-27 02:23:44 theanets.trainer:168 RmsProp 852 loss=102.113876 err=1.774070
I 2015-05-27 02:23:52 theanets.trainer:168 RmsProp 853 loss=101.873459 err=1.615080
I 2015-05-27 02:23:59 theanets.trainer:168 RmsProp 854 loss=102.068916 err=1.887902
I 2015-05-27 02:24:07 theanets.trainer:168 RmsProp 855 loss=101.738480 err=1.639980
I 2015-05-27 02:24:15 theanets.trainer:168 RmsProp 856 loss=101.962189 err=1.940629
I 2015-05-27 02:24:23 theanets.trainer:168 RmsProp 857 loss=101.615921 err=1.673945
I 2015-05-27 02:24:31 theanets.trainer:168 RmsProp 858 loss=101.743614 err=1.881092
I 2015-05-27 02:24:39 theanets.trainer:168 RmsProp 859 loss=101.662857 err=1.874227
I 2015-05-27 02:24:47 theanets.trainer:168 RmsProp 860 loss=101.316727 err=1.609129
I 2015-05-27 02:24:48 theanets.trainer:168 validation 86 loss=985.259827 err=885.598145 *
I 2015-05-27 02:24:55 theanets.trainer:168 RmsProp 861 loss=101.404915 err=1.778584
I 2015-05-27 02:25:03 theanets.trainer:168 RmsProp 862 loss=101.448341 err=1.899101
I 2015-05-27 02:25:09 theanets.trainer:168 RmsProp 863 loss=101.244232 err=1.773080
I 2015-05-27 02:25:16 theanets.trainer:168 RmsProp 864 loss=101.106895 err=1.711147
I 2015-05-27 02:25:22 theanets.trainer:168 RmsProp 865 loss=101.193192 err=1.873372
I 2015-05-27 02:25:29 theanets.trainer:168 RmsProp 866 loss=100.910843 err=1.669095
I 2015-05-27 02:25:36 theanets.trainer:168 RmsProp 867 loss=100.996864 err=1.834309
I 2015-05-27 02:25:43 theanets.trainer:168 RmsProp 868 loss=100.829819 err=1.743582
I 2015-05-27 02:25:49 theanets.trainer:168 RmsProp 869 loss=100.809921 err=1.799972
I 2015-05-27 02:25:56 theanets.trainer:168 RmsProp 870 loss=100.633003 err=1.705017
I 2015-05-27 02:25:56 theanets.trainer:168 validation 87 loss=982.294495 err=883.404602 *
I 2015-05-27 02:26:03 theanets.trainer:168 RmsProp 871 loss=100.635574 err=1.784571
I 2015-05-27 02:26:09 theanets.trainer:168 RmsProp 872 loss=100.522781 err=1.748200
I 2015-05-27 02:26:15 theanets.trainer:168 RmsProp 873 loss=100.492821 err=1.796211
I 2015-05-27 02:26:22 theanets.trainer:168 RmsProp 874 loss=100.412720 err=1.794885
I 2015-05-27 02:26:29 theanets.trainer:168 RmsProp 875 loss=100.319450 err=1.780198
I 2015-05-27 02:26:35 theanets.trainer:168 RmsProp 876 loss=100.230400 err=1.765100
I 2015-05-27 02:26:41 theanets.trainer:168 RmsProp 877 loss=99.946945 err=1.562057
I 2015-05-27 02:26:47 theanets.trainer:168 RmsProp 878 loss=100.253258 err=1.938358
I 2015-05-27 02:26:54 theanets.trainer:168 RmsProp 879 loss=100.168427 err=1.930199
I 2015-05-27 02:27:00 theanets.trainer:168 RmsProp 880 loss=99.788155 err=1.625057
I 2015-05-27 02:27:00 theanets.trainer:168 validation 88 loss=979.670410 err=881.554504 *
I 2015-05-27 02:27:07 theanets.trainer:168 RmsProp 881 loss=99.921585 err=1.834106
I 2015-05-27 02:27:13 theanets.trainer:168 RmsProp 882 loss=99.827415 err=1.813212
I 2015-05-27 02:27:19 theanets.trainer:168 RmsProp 883 loss=99.635437 err=1.697367
I 2015-05-27 02:27:25 theanets.trainer:168 RmsProp 884 loss=99.766327 err=1.902904
I 2015-05-27 02:27:31 theanets.trainer:168 RmsProp 885 loss=99.556946 err=1.766754
I 2015-05-27 02:27:37 theanets.trainer:168 RmsProp 886 loss=99.331413 err=1.619546
I 2015-05-27 02:27:43 theanets.trainer:168 RmsProp 887 loss=99.512108 err=1.873792
I 2015-05-27 02:27:49 theanets.trainer:168 RmsProp 888 loss=99.320824 err=1.758197
I 2015-05-27 02:27:55 theanets.trainer:168 RmsProp 889 loss=99.314705 err=1.823400
I 2015-05-27 02:28:01 theanets.trainer:168 RmsProp 890 loss=99.103256 err=1.685359
I 2015-05-27 02:28:02 theanets.trainer:168 validation 89 loss=978.189026 err=880.820923 *
I 2015-05-27 02:28:07 theanets.trainer:168 RmsProp 891 loss=99.126076 err=1.783108
I 2015-05-27 02:28:14 theanets.trainer:168 RmsProp 892 loss=99.068558 err=1.797000
I 2015-05-27 02:28:20 theanets.trainer:168 RmsProp 893 loss=98.977524 err=1.778526
I 2015-05-27 02:28:26 theanets.trainer:168 RmsProp 894 loss=98.878159 err=1.751317
I 2015-05-27 02:28:32 theanets.trainer:168 RmsProp 895 loss=98.784103 err=1.733327
I 2015-05-27 02:28:38 theanets.trainer:168 RmsProp 896 loss=98.793808 err=1.813320
I 2015-05-27 02:28:45 theanets.trainer:168 RmsProp 897 loss=98.644341 err=1.735855
I 2015-05-27 02:28:51 theanets.trainer:168 RmsProp 898 loss=98.515297 err=1.679804
I 2015-05-27 02:28:57 theanets.trainer:168 RmsProp 899 loss=98.599632 err=1.836527
I 2015-05-27 02:29:03 theanets.trainer:168 RmsProp 900 loss=98.491165 err=1.802193
I 2015-05-27 02:29:04 theanets.trainer:168 validation 90 loss=975.007751 err=878.351868 *
I 2015-05-27 02:29:10 theanets.trainer:168 RmsProp 901 loss=98.379417 err=1.757726
I 2015-05-27 02:29:16 theanets.trainer:168 RmsProp 902 loss=98.286354 err=1.739921
I 2015-05-27 02:29:22 theanets.trainer:168 RmsProp 903 loss=98.304855 err=1.829470
I 2015-05-27 02:29:28 theanets.trainer:168 RmsProp 904 loss=98.100006 err=1.697378
I 2015-05-27 02:29:34 theanets.trainer:168 RmsProp 905 loss=98.087547 err=1.758324
I 2015-05-27 02:29:41 theanets.trainer:168 RmsProp 906 loss=97.917068 err=1.658586
I 2015-05-27 02:29:47 theanets.trainer:168 RmsProp 907 loss=97.965401 err=1.776416
I 2015-05-27 02:29:53 theanets.trainer:168 RmsProp 908 loss=97.892090 err=1.774183
I 2015-05-27 02:29:59 theanets.trainer:168 RmsProp 909 loss=97.936684 err=1.894404
I 2015-05-27 02:30:06 theanets.trainer:168 RmsProp 910 loss=97.703705 err=1.730163
I 2015-05-27 02:30:07 theanets.trainer:168 validation 91 loss=974.327576 err=878.393372 *
I 2015-05-27 02:30:13 theanets.trainer:168 RmsProp 911 loss=97.650826 err=1.747722
I 2015-05-27 02:30:19 theanets.trainer:168 RmsProp 912 loss=97.623634 err=1.794673
I 2015-05-27 02:30:25 theanets.trainer:168 RmsProp 913 loss=97.531120 err=1.772757
I 2015-05-27 02:30:32 theanets.trainer:168 RmsProp 914 loss=97.452499 err=1.763623
I 2015-05-27 02:30:38 theanets.trainer:168 RmsProp 915 loss=97.349312 err=1.728875
I 2015-05-27 02:30:45 theanets.trainer:168 RmsProp 916 loss=97.211174 err=1.663106
I 2015-05-27 02:30:51 theanets.trainer:168 RmsProp 917 loss=97.111107 err=1.632014
I 2015-05-27 02:30:57 theanets.trainer:168 RmsProp 918 loss=97.404343 err=1.992308
I 2015-05-27 02:31:02 theanets.trainer:168 RmsProp 919 loss=97.008087 err=1.666093
I 2015-05-27 02:31:09 theanets.trainer:168 RmsProp 920 loss=97.043076 err=1.768843
I 2015-05-27 02:31:10 theanets.trainer:168 validation 92 loss=973.227844 err=877.988586 *
I 2015-05-27 02:31:16 theanets.trainer:168 RmsProp 921 loss=96.888855 err=1.688614
I 2015-05-27 02:31:22 theanets.trainer:168 RmsProp 922 loss=97.048416 err=1.914818
I 2015-05-27 02:31:28 theanets.trainer:168 RmsProp 923 loss=96.797447 err=1.735892
I 2015-05-27 02:31:35 theanets.trainer:168 RmsProp 924 loss=96.621292 err=1.628272
I 2015-05-27 02:31:41 theanets.trainer:168 RmsProp 925 loss=96.737022 err=1.810877
I 2015-05-27 02:31:47 theanets.trainer:168 RmsProp 926 loss=96.717178 err=1.859425
I 2015-05-27 02:31:53 theanets.trainer:168 RmsProp 927 loss=96.516098 err=1.729697
I 2015-05-27 02:31:59 theanets.trainer:168 RmsProp 928 loss=96.405594 err=1.690468
I 2015-05-27 02:32:05 theanets.trainer:168 RmsProp 929 loss=96.491493 err=1.840847
I 2015-05-27 02:32:12 theanets.trainer:168 RmsProp 930 loss=96.343567 err=1.762331
I 2015-05-27 02:32:12 theanets.trainer:168 validation 93 loss=971.972107 err=877.428162 *
I 2015-05-27 02:32:18 theanets.trainer:168 RmsProp 931 loss=96.245361 err=1.731990
I 2015-05-27 02:32:25 theanets.trainer:168 RmsProp 932 loss=96.168510 err=1.722422
I 2015-05-27 02:32:31 theanets.trainer:168 RmsProp 933 loss=96.121750 err=1.745368
I 2015-05-27 02:32:37 theanets.trainer:168 RmsProp 934 loss=96.090752 err=1.780165
I 2015-05-27 02:32:43 theanets.trainer:168 RmsProp 935 loss=96.000839 err=1.759344
I 2015-05-27 02:32:50 theanets.trainer:168 RmsProp 936 loss=95.899666 err=1.727307
I 2015-05-27 02:32:56 theanets.trainer:168 RmsProp 937 loss=95.840820 err=1.736688
I 2015-05-27 02:33:02 theanets.trainer:168 RmsProp 938 loss=95.799377 err=1.761583
I 2015-05-27 02:33:08 theanets.trainer:168 RmsProp 939 loss=95.658524 err=1.689121
I 2015-05-27 02:33:15 theanets.trainer:168 RmsProp 940 loss=95.622139 err=1.720635
I 2015-05-27 02:33:15 theanets.trainer:168 validation 94 loss=970.139893 err=876.273071 *
I 2015-05-27 02:33:21 theanets.trainer:168 RmsProp 941 loss=95.567749 err=1.729847
I 2015-05-27 02:33:27 theanets.trainer:168 RmsProp 942 loss=95.406540 err=1.639488
I 2015-05-27 02:33:33 theanets.trainer:168 RmsProp 943 loss=95.517403 err=1.816314
I 2015-05-27 02:33:39 theanets.trainer:168 RmsProp 944 loss=95.368546 err=1.735818
I 2015-05-27 02:33:45 theanets.trainer:168 RmsProp 945 loss=95.222061 err=1.656045
I 2015-05-27 02:33:51 theanets.trainer:168 RmsProp 946 loss=95.273651 err=1.776150
I 2015-05-27 02:33:58 theanets.trainer:168 RmsProp 947 loss=95.148514 err=1.717795
I 2015-05-27 02:34:04 theanets.trainer:168 RmsProp 948 loss=95.071671 err=1.707401
I 2015-05-27 02:34:11 theanets.trainer:168 RmsProp 949 loss=95.147003 err=1.847896
I 2015-05-27 02:34:17 theanets.trainer:168 RmsProp 950 loss=95.004257 err=1.770066
I 2015-05-27 02:34:18 theanets.trainer:168 validation 95 loss=967.221619 err=874.030273 *
I 2015-05-27 02:34:23 theanets.trainer:168 RmsProp 951 loss=94.907974 err=1.743020
I 2015-05-27 02:34:30 theanets.trainer:168 RmsProp 952 loss=94.960670 err=1.856543
I 2015-05-27 02:34:36 theanets.trainer:168 RmsProp 953 loss=94.753525 err=1.715138
I 2015-05-27 02:34:42 theanets.trainer:168 RmsProp 954 loss=94.678360 err=1.708566
I 2015-05-27 02:34:48 theanets.trainer:168 RmsProp 955 loss=94.650589 err=1.745645
I 2015-05-27 02:34:55 theanets.trainer:168 RmsProp 956 loss=94.548080 err=1.710815
I 2015-05-27 02:35:01 theanets.trainer:168 RmsProp 957 loss=94.465729 err=1.691294
I 2015-05-27 02:35:08 theanets.trainer:168 RmsProp 958 loss=94.408356 err=1.702987
I 2015-05-27 02:35:14 theanets.trainer:168 RmsProp 959 loss=94.439041 err=1.795389
I 2015-05-27 02:35:20 theanets.trainer:168 RmsProp 960 loss=94.273308 err=1.697050
I 2015-05-27 02:35:21 theanets.trainer:168 validation 96 loss=967.323792 err=874.783508
I 2015-05-27 02:35:27 theanets.trainer:168 RmsProp 961 loss=94.230453 err=1.720544
I 2015-05-27 02:35:33 theanets.trainer:168 RmsProp 962 loss=94.125107 err=1.678117
I 2015-05-27 02:35:39 theanets.trainer:168 RmsProp 963 loss=94.078461 err=1.700692
I 2015-05-27 02:35:45 theanets.trainer:168 RmsProp 964 loss=94.145653 err=1.830391
I 2015-05-27 02:35:52 theanets.trainer:168 RmsProp 965 loss=93.912178 err=1.664427
I 2015-05-27 02:35:58 theanets.trainer:168 RmsProp 966 loss=93.936325 err=1.751310
I 2015-05-27 02:36:04 theanets.trainer:168 RmsProp 967 loss=93.840256 err=1.720923
I 2015-05-27 02:36:10 theanets.trainer:168 RmsProp 968 loss=93.585159 err=1.535146
I 2015-05-27 02:36:15 theanets.trainer:168 RmsProp 969 loss=93.967331 err=1.975855
I 2015-05-27 02:36:22 theanets.trainer:168 RmsProp 970 loss=93.531754 err=1.605777
I 2015-05-27 02:36:22 theanets.trainer:168 validation 97 loss=964.947388 err=873.060486 *
I 2015-05-27 02:36:28 theanets.trainer:168 RmsProp 971 loss=93.563637 err=1.703820
I 2015-05-27 02:36:35 theanets.trainer:168 RmsProp 972 loss=93.511314 err=1.720516
I 2015-05-27 02:36:41 theanets.trainer:168 RmsProp 973 loss=93.357452 err=1.631490
I 2015-05-27 02:36:47 theanets.trainer:168 RmsProp 974 loss=93.343544 err=1.681410
I 2015-05-27 02:36:54 theanets.trainer:168 RmsProp 975 loss=93.407097 err=1.809698
I 2015-05-27 02:37:00 theanets.trainer:168 RmsProp 976 loss=93.122360 err=1.586574
I 2015-05-27 02:37:06 theanets.trainer:168 RmsProp 977 loss=93.261513 err=1.791783
I 2015-05-27 02:37:12 theanets.trainer:168 RmsProp 978 loss=93.165764 err=1.759061
I 2015-05-27 02:37:19 theanets.trainer:168 RmsProp 979 loss=93.074280 err=1.732344
I 2015-05-27 02:37:25 theanets.trainer:168 RmsProp 980 loss=93.009193 err=1.731475
I 2015-05-27 02:37:26 theanets.trainer:168 validation 98 loss=965.332520 err=874.082947
I 2015-05-27 02:37:32 theanets.trainer:168 RmsProp 981 loss=92.871231 err=1.655595
I 2015-05-27 02:37:37 theanets.trainer:168 RmsProp 982 loss=92.815628 err=1.664589
I 2015-05-27 02:37:43 theanets.trainer:168 RmsProp 983 loss=92.724037 err=1.634354
I 2015-05-27 02:37:49 theanets.trainer:168 RmsProp 984 loss=92.791649 err=1.762347
I 2015-05-27 02:37:55 theanets.trainer:168 RmsProp 985 loss=92.657608 err=1.691989
I 2015-05-27 02:38:01 theanets.trainer:168 RmsProp 986 loss=92.543457 err=1.644850
I 2015-05-27 02:38:07 theanets.trainer:168 RmsProp 987 loss=92.721931 err=1.882237
I 2015-05-27 02:38:14 theanets.trainer:168 RmsProp 988 loss=92.396561 err=1.615906
I 2015-05-27 02:38:20 theanets.trainer:168 RmsProp 989 loss=92.459534 err=1.743439
I 2015-05-27 02:38:26 theanets.trainer:168 RmsProp 990 loss=92.265991 err=1.611239
I 2015-05-27 02:38:27 theanets.trainer:168 validation 99 loss=964.299255 err=873.675720 *
I 2015-05-27 02:38:33 theanets.trainer:168 RmsProp 991 loss=92.366959 err=1.773833
I 2015-05-27 02:38:39 theanets.trainer:168 RmsProp 992 loss=92.235687 err=1.703841
I 2015-05-27 02:38:45 theanets.trainer:168 RmsProp 993 loss=92.167969 err=1.699088
I 2015-05-27 02:38:51 theanets.trainer:168 RmsProp 994 loss=92.125031 err=1.716748
I 2015-05-27 02:38:57 theanets.trainer:168 RmsProp 995 loss=92.060852 err=1.716537
I 2015-05-27 02:39:03 theanets.trainer:168 RmsProp 996 loss=91.991821 err=1.707060
I 2015-05-27 02:39:10 theanets.trainer:168 RmsProp 997 loss=91.930946 err=1.706474
I 2015-05-27 02:39:16 theanets.trainer:168 RmsProp 998 loss=91.895523 err=1.732946
I 2015-05-27 02:39:22 theanets.trainer:168 RmsProp 999 loss=91.798630 err=1.696104
I 2015-05-27 02:39:28 theanets.trainer:168 RmsProp 1000 loss=91.733551 err=1.692171
I 2015-05-27 02:39:29 theanets.trainer:168 validation 100 loss=962.974304 err=872.972595 *
I 2015-05-27 02:39:35 theanets.trainer:168 RmsProp 1001 loss=91.741013 err=1.761120
I 2015-05-27 02:39:41 theanets.trainer:168 RmsProp 1002 loss=91.491745 err=1.576108
I 2015-05-27 02:39:47 theanets.trainer:168 RmsProp 1003 loss=91.609085 err=1.753027
I 2015-05-27 02:39:53 theanets.trainer:168 RmsProp 1004 loss=91.504913 err=1.703981
I 2015-05-27 02:39:59 theanets.trainer:168 RmsProp 1005 loss=91.403214 err=1.663673
I 2015-05-27 02:40:06 theanets.trainer:168 RmsProp 1006 loss=91.442924 err=1.762767
I 2015-05-27 02:40:12 theanets.trainer:168 RmsProp 1007 loss=91.215622 err=1.600428
I 2015-05-27 02:40:19 theanets.trainer:168 RmsProp 1008 loss=91.286423 err=1.731441
I 2015-05-27 02:40:25 theanets.trainer:168 RmsProp 1009 loss=91.082161 err=1.587244
I 2015-05-27 02:40:32 theanets.trainer:168 RmsProp 1010 loss=91.376595 err=1.938274
I 2015-05-27 02:40:32 theanets.trainer:168 validation 101 loss=962.637695 err=873.228455 *
I 2015-05-27 02:40:38 theanets.trainer:168 RmsProp 1011 loss=90.929237 err=1.553328
I 2015-05-27 02:40:44 theanets.trainer:168 RmsProp 1012 loss=91.040054 err=1.726022
I 2015-05-27 02:40:50 theanets.trainer:168 RmsProp 1013 loss=90.932060 err=1.675532
I 2015-05-27 02:40:56 theanets.trainer:168 RmsProp 1014 loss=90.780258 err=1.585512
I 2015-05-27 02:41:02 theanets.trainer:168 RmsProp 1015 loss=90.894302 err=1.755951
I 2015-05-27 02:41:08 theanets.trainer:168 RmsProp 1016 loss=90.744370 err=1.665111
I 2015-05-27 02:41:14 theanets.trainer:168 RmsProp 1017 loss=90.720604 err=1.704200
I 2015-05-27 02:41:20 theanets.trainer:168 RmsProp 1018 loss=90.708694 err=1.751425
I 2015-05-27 02:41:26 theanets.trainer:168 RmsProp 1019 loss=90.634071 err=1.734953
I 2015-05-27 02:41:33 theanets.trainer:168 RmsProp 1020 loss=90.446960 err=1.605159
I 2015-05-27 02:41:33 theanets.trainer:168 validation 102 loss=960.894592 err=872.085449 *
I 2015-05-27 02:41:39 theanets.trainer:168 RmsProp 1021 loss=90.493614 err=1.713091
I 2015-05-27 02:41:46 theanets.trainer:168 RmsProp 1022 loss=90.378883 err=1.652511
I 2015-05-27 02:41:52 theanets.trainer:168 RmsProp 1023 loss=90.335442 err=1.667949
I 2015-05-27 02:41:58 theanets.trainer:168 RmsProp 1024 loss=90.325958 err=1.715261
I 2015-05-27 02:42:04 theanets.trainer:168 RmsProp 1025 loss=90.166664 err=1.614884
I 2015-05-27 02:42:10 theanets.trainer:168 RmsProp 1026 loss=90.256729 err=1.763889
I 2015-05-27 02:42:16 theanets.trainer:168 RmsProp 1027 loss=90.080399 err=1.644273
I 2015-05-27 02:42:22 theanets.trainer:168 RmsProp 1028 loss=89.992805 err=1.615406
I 2015-05-27 02:42:28 theanets.trainer:168 RmsProp 1029 loss=90.077538 err=1.758592
I 2015-05-27 02:42:34 theanets.trainer:168 RmsProp 1030 loss=90.061821 err=1.797912
I 2015-05-27 02:42:35 theanets.trainer:168 validation 103 loss=960.671448 err=872.444336 *
I 2015-05-27 02:42:41 theanets.trainer:168 RmsProp 1031 loss=89.707726 err=1.501993
I 2015-05-27 02:42:47 theanets.trainer:168 RmsProp 1032 loss=89.919708 err=1.771232
I 2015-05-27 02:42:53 theanets.trainer:168 RmsProp 1033 loss=89.823669 err=1.733365
I 2015-05-27 02:43:00 theanets.trainer:168 RmsProp 1034 loss=89.670418 err=1.635416
I 2015-05-27 02:43:06 theanets.trainer:168 RmsProp 1035 loss=89.637199 err=1.664219
I 2015-05-27 02:43:12 theanets.trainer:168 RmsProp 1036 loss=89.612671 err=1.697248
I 2015-05-27 02:43:18 theanets.trainer:168 RmsProp 1037 loss=89.536652 err=1.678802
I 2015-05-27 02:43:24 theanets.trainer:168 RmsProp 1038 loss=89.524353 err=1.724055
I 2015-05-27 02:43:30 theanets.trainer:168 RmsProp 1039 loss=89.677063 err=1.929840
I 2015-05-27 02:43:36 theanets.trainer:168 RmsProp 1040 loss=89.296402 err=1.606980
I 2015-05-27 02:43:37 theanets.trainer:168 validation 104 loss=957.915527 err=870.256836 *
I 2015-05-27 02:43:43 theanets.trainer:168 RmsProp 1041 loss=89.235558 err=1.603549
I 2015-05-27 02:43:49 theanets.trainer:168 RmsProp 1042 loss=89.271255 err=1.696020
I 2015-05-27 02:43:55 theanets.trainer:168 RmsProp 1043 loss=88.964394 err=1.449930
I 2015-05-27 02:44:01 theanets.trainer:168 RmsProp 1044 loss=89.319252 err=1.859778
I 2015-05-27 02:44:07 theanets.trainer:168 RmsProp 1045 loss=88.920944 err=1.520564
I 2015-05-27 02:44:13 theanets.trainer:168 RmsProp 1046 loss=89.015953 err=1.667818
I 2015-05-27 02:44:20 theanets.trainer:168 RmsProp 1047 loss=89.169693 err=1.877800
I 2015-05-27 02:44:26 theanets.trainer:168 RmsProp 1048 loss=88.826874 err=1.589008
I 2015-05-27 02:44:32 theanets.trainer:168 RmsProp 1049 loss=89.018875 err=1.838473
I 2015-05-27 02:44:39 theanets.trainer:168 RmsProp 1050 loss=88.858009 err=1.735047
I 2015-05-27 02:44:39 theanets.trainer:168 validation 105 loss=957.809937 err=870.709961 *
I 2015-05-27 02:44:45 theanets.trainer:168 RmsProp 1051 loss=88.720169 err=1.653039
I 2015-05-27 02:44:51 theanets.trainer:168 RmsProp 1052 loss=88.646309 err=1.634299
I 2015-05-27 02:44:57 theanets.trainer:168 RmsProp 1053 loss=88.643860 err=1.686902
I 2015-05-27 02:45:03 theanets.trainer:168 RmsProp 1054 loss=88.468079 err=1.567756
I 2015-05-27 02:45:10 theanets.trainer:168 RmsProp 1055 loss=88.418419 err=1.572166
I 2015-05-27 02:45:17 theanets.trainer:168 RmsProp 1056 loss=88.468704 err=1.679739
I 2015-05-27 02:45:23 theanets.trainer:168 RmsProp 1057 loss=88.345779 err=1.610499
I 2015-05-27 02:45:30 theanets.trainer:168 RmsProp 1058 loss=88.322678 err=1.643923
I 2015-05-27 02:45:37 theanets.trainer:168 RmsProp 1059 loss=88.326187 err=1.704236
I 2015-05-27 02:45:44 theanets.trainer:168 RmsProp 1060 loss=88.246986 err=1.678947
I 2015-05-27 02:45:44 theanets.trainer:168 validation 106 loss=958.182800 err=871.651062
I 2015-05-27 02:45:50 theanets.trainer:168 RmsProp 1061 loss=88.152130 err=1.642173
I 2015-05-27 02:45:57 theanets.trainer:168 RmsProp 1062 loss=88.055435 err=1.601781
I 2015-05-27 02:46:04 theanets.trainer:168 RmsProp 1063 loss=88.134865 err=1.735681
I 2015-05-27 02:46:10 theanets.trainer:168 RmsProp 1064 loss=88.038803 err=1.694677
I 2015-05-27 02:46:16 theanets.trainer:168 RmsProp 1065 loss=87.807579 err=1.520918
I 2015-05-27 02:46:22 theanets.trainer:168 RmsProp 1066 loss=88.130737 err=1.893604
I 2015-05-27 02:46:29 theanets.trainer:168 RmsProp 1067 loss=87.799057 err=1.617620
I 2015-05-27 02:46:35 theanets.trainer:168 RmsProp 1068 loss=87.812042 err=1.688412
I 2015-05-27 02:46:42 theanets.trainer:168 RmsProp 1069 loss=87.740181 err=1.670137
I 2015-05-27 02:46:48 theanets.trainer:168 RmsProp 1070 loss=87.844147 err=1.826018
I 2015-05-27 02:46:48 theanets.trainer:168 validation 107 loss=958.148010 err=872.160339
I 2015-05-27 02:46:54 theanets.trainer:168 RmsProp 1071 loss=87.569290 err=1.604641
I 2015-05-27 02:47:00 theanets.trainer:168 RmsProp 1072 loss=87.588707 err=1.677943
I 2015-05-27 02:47:06 theanets.trainer:168 RmsProp 1073 loss=87.338966 err=1.484325
I 2015-05-27 02:47:12 theanets.trainer:168 RmsProp 1074 loss=87.606995 err=1.804849
I 2015-05-27 02:47:19 theanets.trainer:168 RmsProp 1075 loss=87.337296 err=1.593837
I 2015-05-27 02:47:25 theanets.trainer:168 RmsProp 1076 loss=87.263718 err=1.573438
I 2015-05-27 02:47:32 theanets.trainer:168 RmsProp 1077 loss=87.362152 err=1.726481
I 2015-05-27 02:47:38 theanets.trainer:168 RmsProp 1078 loss=87.215172 err=1.632867
I 2015-05-27 02:47:45 theanets.trainer:168 RmsProp 1079 loss=87.226151 err=1.698799
I 2015-05-27 02:47:51 theanets.trainer:168 RmsProp 1080 loss=87.093948 err=1.623326
I 2015-05-27 02:47:52 theanets.trainer:168 validation 108 loss=957.281250 err=871.823425 *
I 2015-05-27 02:47:58 theanets.trainer:168 RmsProp 1081 loss=87.286240 err=1.863923
I 2015-05-27 02:48:04 theanets.trainer:168 RmsProp 1082 loss=87.044327 err=1.676311
I 2015-05-27 02:48:10 theanets.trainer:168 RmsProp 1083 loss=86.940880 err=1.629495
I 2015-05-27 02:48:17 theanets.trainer:168 RmsProp 1084 loss=86.922867 err=1.664957
I 2015-05-27 02:48:24 theanets.trainer:168 RmsProp 1085 loss=86.861923 err=1.655791
I 2015-05-27 02:48:30 theanets.trainer:168 RmsProp 1086 loss=86.785904 err=1.632347
I 2015-05-27 02:48:36 theanets.trainer:168 RmsProp 1087 loss=86.743706 err=1.643595
I 2015-05-27 02:48:42 theanets.trainer:168 RmsProp 1088 loss=86.768387 err=1.721469
I 2015-05-27 02:48:48 theanets.trainer:168 RmsProp 1089 loss=86.629829 err=1.638506
I 2015-05-27 02:48:54 theanets.trainer:168 RmsProp 1090 loss=86.581589 err=1.642458
I 2015-05-27 02:48:55 theanets.trainer:168 validation 109 loss=954.176208 err=869.265564 *
I 2015-05-27 02:49:01 theanets.trainer:168 RmsProp 1091 loss=86.559082 err=1.673908
I 2015-05-27 02:49:07 theanets.trainer:168 RmsProp 1092 loss=86.450096 err=1.619832
I 2015-05-27 02:49:13 theanets.trainer:168 RmsProp 1093 loss=86.403839 err=1.627161
I 2015-05-27 02:49:20 theanets.trainer:168 RmsProp 1094 loss=86.285538 err=1.563845
I 2015-05-27 02:49:26 theanets.trainer:168 RmsProp 1095 loss=86.256363 err=1.585422
I 2015-05-27 02:49:32 theanets.trainer:168 RmsProp 1096 loss=86.227219 err=1.608606
I 2015-05-27 02:49:38 theanets.trainer:168 RmsProp 1097 loss=86.200302 err=1.633368
I 2015-05-27 02:49:44 theanets.trainer:168 RmsProp 1098 loss=86.139587 err=1.627991
I 2015-05-27 02:49:50 theanets.trainer:168 RmsProp 1099 loss=86.121391 err=1.662335
I 2015-05-27 02:49:57 theanets.trainer:168 RmsProp 1100 loss=86.313431 err=1.904524
I 2015-05-27 02:49:57 theanets.trainer:168 validation 110 loss=956.319092 err=871.943054
I 2015-05-27 02:50:03 theanets.trainer:168 RmsProp 1101 loss=85.994926 err=1.639384
I 2015-05-27 02:50:10 theanets.trainer:168 RmsProp 1102 loss=85.887627 err=1.582246
I 2015-05-27 02:50:16 theanets.trainer:168 RmsProp 1103 loss=85.817947 err=1.566725
I 2015-05-27 02:50:23 theanets.trainer:168 RmsProp 1104 loss=85.917671 err=1.716207
I 2015-05-27 02:50:29 theanets.trainer:168 RmsProp 1105 loss=85.821846 err=1.676672
I 2015-05-27 02:50:35 theanets.trainer:168 RmsProp 1106 loss=85.850922 err=1.756213
I 2015-05-27 02:50:41 theanets.trainer:168 RmsProp 1107 loss=85.647018 err=1.606449
I 2015-05-27 02:50:47 theanets.trainer:168 RmsProp 1108 loss=85.547485 err=1.559799
I 2015-05-27 02:50:53 theanets.trainer:168 RmsProp 1109 loss=85.493423 err=1.554574
I 2015-05-27 02:51:00 theanets.trainer:168 RmsProp 1110 loss=85.512627 err=1.628566
I 2015-05-27 02:51:00 theanets.trainer:168 validation 111 loss=956.188721 err=872.320496
I 2015-05-27 02:51:06 theanets.trainer:168 RmsProp 1111 loss=85.602600 err=1.767662
I 2015-05-27 02:51:12 theanets.trainer:168 RmsProp 1112 loss=85.349121 err=1.570526
I 2015-05-27 02:51:19 theanets.trainer:168 RmsProp 1113 loss=85.332153 err=1.605672
I 2015-05-27 02:51:25 theanets.trainer:168 RmsProp 1114 loss=85.306259 err=1.628917
I 2015-05-27 02:51:31 theanets.trainer:168 RmsProp 1115 loss=85.239563 err=1.614442
I 2015-05-27 02:51:37 theanets.trainer:168 RmsProp 1116 loss=85.122673 err=1.551026
I 2015-05-27 02:51:43 theanets.trainer:168 RmsProp 1117 loss=85.127792 err=1.607503
I 2015-05-27 02:51:49 theanets.trainer:168 RmsProp 1118 loss=85.171463 err=1.701253
I 2015-05-27 02:51:55 theanets.trainer:168 RmsProp 1119 loss=85.026947 err=1.608671
I 2015-05-27 02:52:02 theanets.trainer:168 RmsProp 1120 loss=85.027077 err=1.660043
I 2015-05-27 02:52:02 theanets.trainer:168 validation 112 loss=954.243713 err=870.908203
I 2015-05-27 02:52:08 theanets.trainer:168 RmsProp 1121 loss=85.026260 err=1.710076
I 2015-05-27 02:52:15 theanets.trainer:168 RmsProp 1122 loss=84.896835 err=1.630262
I 2015-05-27 02:52:21 theanets.trainer:168 RmsProp 1123 loss=84.833130 err=1.615410
I 2015-05-27 02:52:28 theanets.trainer:168 RmsProp 1124 loss=84.830811 err=1.667720
I 2015-05-27 02:52:34 theanets.trainer:168 RmsProp 1125 loss=84.765030 err=1.651157
I 2015-05-27 02:52:40 theanets.trainer:168 RmsProp 1126 loss=84.676521 err=1.612719
I 2015-05-27 02:52:46 theanets.trainer:168 RmsProp 1127 loss=84.689247 err=1.674157
I 2015-05-27 02:52:52 theanets.trainer:168 RmsProp 1128 loss=84.524338 err=1.560841
I 2015-05-27 02:52:59 theanets.trainer:168 RmsProp 1129 loss=84.554062 err=1.643335
I 2015-05-27 02:53:06 theanets.trainer:168 RmsProp 1130 loss=84.546593 err=1.682936
I 2015-05-27 02:53:06 theanets.trainer:168 validation 113 loss=952.113098 err=869.279480 *
I 2015-05-27 02:53:12 theanets.trainer:168 RmsProp 1131 loss=84.360771 err=1.548307
I 2015-05-27 02:53:19 theanets.trainer:168 RmsProp 1132 loss=84.389366 err=1.625422
I 2015-05-27 02:53:25 theanets.trainer:168 RmsProp 1133 loss=84.374756 err=1.664641
I 2015-05-27 02:53:31 theanets.trainer:168 RmsProp 1134 loss=84.333542 err=1.669644
I 2015-05-27 02:53:38 theanets.trainer:168 RmsProp 1135 loss=84.161377 err=1.546316
I 2015-05-27 02:53:44 theanets.trainer:168 RmsProp 1136 loss=84.276077 err=1.709421
I 2015-05-27 02:53:51 theanets.trainer:168 RmsProp 1137 loss=84.132797 err=1.616611
I 2015-05-27 02:53:57 theanets.trainer:168 RmsProp 1138 loss=84.120468 err=1.653625
I 2015-05-27 02:54:03 theanets.trainer:168 RmsProp 1139 loss=84.107552 err=1.688750
I 2015-05-27 02:54:09 theanets.trainer:168 RmsProp 1140 loss=84.060745 err=1.691264
I 2015-05-27 02:54:10 theanets.trainer:168 validation 114 loss=953.584656 err=871.243164
I 2015-05-27 02:54:16 theanets.trainer:168 RmsProp 1141 loss=83.990166 err=1.669763
I 2015-05-27 02:54:22 theanets.trainer:168 RmsProp 1142 loss=84.107056 err=1.835096
I 2015-05-27 02:54:28 theanets.trainer:168 RmsProp 1143 loss=83.810898 err=1.589649
I 2015-05-27 02:54:34 theanets.trainer:168 RmsProp 1144 loss=83.789085 err=1.617140
I 2015-05-27 02:54:41 theanets.trainer:168 RmsProp 1145 loss=83.731537 err=1.610997
I 2015-05-27 02:54:47 theanets.trainer:168 RmsProp 1146 loss=83.694412 err=1.621607
I 2015-05-27 02:54:53 theanets.trainer:168 RmsProp 1147 loss=83.668137 err=1.643060
I 2015-05-27 02:55:00 theanets.trainer:168 RmsProp 1148 loss=83.461319 err=1.485203
I 2015-05-27 02:55:06 theanets.trainer:168 RmsProp 1149 loss=83.833206 err=1.903267
I 2015-05-27 02:55:12 theanets.trainer:168 RmsProp 1150 loss=83.387833 err=1.508729
I 2015-05-27 02:55:12 theanets.trainer:168 validation 115 loss=952.588074 err=870.733887
I 2015-05-27 02:55:18 theanets.trainer:168 RmsProp 1151 loss=83.560661 err=1.726608
I 2015-05-27 02:55:24 theanets.trainer:168 RmsProp 1152 loss=83.338379 err=1.557592
I 2015-05-27 02:55:30 theanets.trainer:168 RmsProp 1153 loss=83.330734 err=1.596233
I 2015-05-27 02:55:36 theanets.trainer:168 RmsProp 1154 loss=83.403946 err=1.716101
I 2015-05-27 02:55:43 theanets.trainer:168 RmsProp 1155 loss=83.248611 err=1.606936
I 2015-05-27 02:55:49 theanets.trainer:168 RmsProp 1156 loss=83.118484 err=1.524769
I 2015-05-27 02:55:55 theanets.trainer:168 RmsProp 1157 loss=83.248085 err=1.701720
I 2015-05-27 02:56:02 theanets.trainer:168 RmsProp 1158 loss=83.116516 err=1.618541
I 2015-05-27 02:56:08 theanets.trainer:168 RmsProp 1159 loss=83.073593 err=1.624907
I 2015-05-27 02:56:15 theanets.trainer:168 RmsProp 1160 loss=82.936241 err=1.534103
I 2015-05-27 02:56:15 theanets.trainer:168 validation 116 loss=952.669861 err=871.293762
I 2015-05-27 02:56:21 theanets.trainer:168 RmsProp 1161 loss=82.981186 err=1.630054
I 2015-05-27 02:56:28 theanets.trainer:168 RmsProp 1162 loss=83.015709 err=1.711767
I 2015-05-27 02:56:34 theanets.trainer:168 RmsProp 1163 loss=82.749954 err=1.495903
I 2015-05-27 02:56:40 theanets.trainer:168 RmsProp 1164 loss=82.829453 err=1.621901
I 2015-05-27 02:56:47 theanets.trainer:168 RmsProp 1165 loss=82.835083 err=1.675338
I 2015-05-27 02:56:53 theanets.trainer:168 RmsProp 1166 loss=82.725098 err=1.616084
I 2015-05-27 02:56:59 theanets.trainer:168 RmsProp 1167 loss=82.706512 err=1.645316
I 2015-05-27 02:57:06 theanets.trainer:168 RmsProp 1168 loss=82.611633 err=1.598881
I 2015-05-27 02:57:12 theanets.trainer:168 RmsProp 1169 loss=82.619545 err=1.653444
I 2015-05-27 02:57:18 theanets.trainer:168 RmsProp 1170 loss=82.557175 err=1.637438
I 2015-05-27 02:57:19 theanets.trainer:168 validation 117 loss=952.401367 err=871.510376
I 2015-05-27 02:57:25 theanets.trainer:168 RmsProp 1171 loss=82.495956 err=1.624387
I 2015-05-27 02:57:31 theanets.trainer:168 RmsProp 1172 loss=82.391403 err=1.566929
I 2015-05-27 02:57:37 theanets.trainer:168 RmsProp 1173 loss=82.389046 err=1.613036
I 2015-05-27 02:57:44 theanets.trainer:168 RmsProp 1174 loss=82.375473 err=1.643064
I 2015-05-27 02:57:50 theanets.trainer:168 RmsProp 1175 loss=82.303368 err=1.615775
I 2015-05-27 02:57:57 theanets.trainer:168 RmsProp 1176 loss=82.194160 err=1.555623
I 2015-05-27 02:58:03 theanets.trainer:168 RmsProp 1177 loss=82.276100 err=1.686438
I 2015-05-27 02:58:09 theanets.trainer:168 RmsProp 1178 loss=82.133469 err=1.593773
I 2015-05-27 02:58:15 theanets.trainer:168 RmsProp 1179 loss=82.074478 err=1.580402
I 2015-05-27 02:58:21 theanets.trainer:168 RmsProp 1180 loss=82.069153 err=1.622225
I 2015-05-27 02:58:22 theanets.trainer:168 validation 118 loss=950.178162 err=869.752563 *
I 2015-05-27 02:58:28 theanets.trainer:168 RmsProp 1181 loss=82.033867 err=1.630143
I 2015-05-27 02:58:34 theanets.trainer:168 RmsProp 1182 loss=81.929886 err=1.574830
I 2015-05-27 02:58:40 theanets.trainer:168 RmsProp 1183 loss=81.805443 err=1.497800
I 2015-05-27 02:58:47 theanets.trainer:168 RmsProp 1184 loss=81.868301 err=1.609631
I 2015-05-27 02:58:53 theanets.trainer:168 RmsProp 1185 loss=81.830299 err=1.620127
I 2015-05-27 02:59:00 theanets.trainer:168 RmsProp 1186 loss=81.833359 err=1.667849
I 2015-05-27 02:59:06 theanets.trainer:168 RmsProp 1187 loss=81.680664 err=1.563830
I 2015-05-27 02:59:12 theanets.trainer:168 RmsProp 1188 loss=81.855240 err=1.778823
I 2015-05-27 02:59:18 theanets.trainer:168 RmsProp 1189 loss=81.689949 err=1.660886
I 2015-05-27 02:59:25 theanets.trainer:168 RmsProp 1190 loss=81.427528 err=1.445379
I 2015-05-27 02:59:25 theanets.trainer:168 validation 119 loss=951.812622 err=871.849060
I 2015-05-27 02:59:31 theanets.trainer:168 RmsProp 1191 loss=81.436974 err=1.501987
I 2015-05-27 02:59:36 theanets.trainer:168 RmsProp 1192 loss=81.622169 err=1.728666
I 2015-05-27 02:59:43 theanets.trainer:168 RmsProp 1193 loss=81.391724 err=1.545866
I 2015-05-27 02:59:49 theanets.trainer:168 RmsProp 1194 loss=81.446732 err=1.647631
I 2015-05-27 02:59:55 theanets.trainer:168 RmsProp 1195 loss=81.385025 err=1.628608
I 2015-05-27 03:00:01 theanets.trainer:168 RmsProp 1196 loss=81.373283 err=1.663868
I 2015-05-27 03:00:07 theanets.trainer:168 RmsProp 1197 loss=81.203751 err=1.543867
I 2015-05-27 03:00:13 theanets.trainer:168 RmsProp 1198 loss=81.320343 err=1.706260
I 2015-05-27 03:00:19 theanets.trainer:168 RmsProp 1199 loss=81.363312 err=1.793943
I 2015-05-27 03:00:25 theanets.trainer:168 RmsProp 1200 loss=81.047577 err=1.522170
I 2015-05-27 03:00:25 theanets.trainer:168 validation 120 loss=950.412354 err=870.911743
I 2015-05-27 03:00:31 theanets.trainer:168 RmsProp 1201 loss=81.054626 err=1.576205
I 2015-05-27 03:00:36 theanets.trainer:168 RmsProp 1202 loss=81.072159 err=1.638869
I 2015-05-27 03:00:42 theanets.trainer:168 RmsProp 1203 loss=80.982613 err=1.597908
I 2015-05-27 03:00:47 theanets.trainer:168 RmsProp 1204 loss=80.958145 err=1.617390
I 2015-05-27 03:00:52 theanets.trainer:168 RmsProp 1205 loss=80.890862 err=1.598582
I 2015-05-27 03:00:56 theanets.trainer:168 RmsProp 1206 loss=80.595444 err=1.350000
I 2015-05-27 03:01:00 theanets.trainer:168 RmsProp 1207 loss=80.841782 err=1.636152
I 2015-05-27 03:01:03 theanets.trainer:168 RmsProp 1208 loss=80.755219 err=1.597441
I 2015-05-27 03:01:07 theanets.trainer:168 RmsProp 1209 loss=80.796158 err=1.681366
I 2015-05-27 03:01:11 theanets.trainer:168 RmsProp 1210 loss=80.718269 err=1.650890
I 2015-05-27 03:01:11 theanets.trainer:168 validation 121 loss=951.220337 err=872.178406
I 2015-05-27 03:01:15 theanets.trainer:168 RmsProp 1211 loss=80.668472 err=1.647739
I 2015-05-27 03:01:19 theanets.trainer:168 RmsProp 1212 loss=80.707596 err=1.730835
I 2015-05-27 03:01:23 theanets.trainer:168 RmsProp 1213 loss=80.536026 err=1.601048
I 2015-05-27 03:01:27 theanets.trainer:168 RmsProp 1214 loss=80.548340 err=1.652458
I 2015-05-27 03:01:31 theanets.trainer:168 RmsProp 1215 loss=80.408043 err=1.558510
I 2015-05-27 03:01:35 theanets.trainer:168 RmsProp 1216 loss=80.392525 err=1.587932
I 2015-05-27 03:01:40 theanets.trainer:168 RmsProp 1217 loss=80.363541 err=1.605788
I 2015-05-27 03:01:44 theanets.trainer:168 RmsProp 1218 loss=80.366333 err=1.651755
I 2015-05-27 03:01:49 theanets.trainer:168 RmsProp 1219 loss=80.314804 err=1.643837
I 2015-05-27 03:01:53 theanets.trainer:168 RmsProp 1220 loss=80.191566 err=1.563917
I 2015-05-27 03:01:53 theanets.trainer:168 validation 122 loss=951.662354 err=873.057617
I 2015-05-27 03:01:57 theanets.trainer:168 RmsProp 1221 loss=80.216118 err=1.634040
I 2015-05-27 03:02:01 theanets.trainer:168 RmsProp 1222 loss=80.167244 err=1.629281
I 2015-05-27 03:02:05 theanets.trainer:168 RmsProp 1223 loss=80.114609 err=1.619785
I 2015-05-27 03:02:10 theanets.trainer:168 RmsProp 1224 loss=80.101547 err=1.653233
I 2015-05-27 03:02:14 theanets.trainer:168 RmsProp 1225 loss=79.971046 err=1.564364
I 2015-05-27 03:02:18 theanets.trainer:168 RmsProp 1226 loss=79.961014 err=1.597260
I 2015-05-27 03:02:22 theanets.trainer:168 RmsProp 1227 loss=79.917709 err=1.599515
I 2015-05-27 03:02:26 theanets.trainer:168 RmsProp 1228 loss=79.937187 err=1.660969
I 2015-05-27 03:02:30 theanets.trainer:168 RmsProp 1229 loss=79.774353 err=1.543158
I 2015-05-27 03:02:35 theanets.trainer:168 RmsProp 1230 loss=79.867348 err=1.678768
I 2015-05-27 03:02:35 theanets.trainer:168 validation 123 loss=948.668335 err=870.500000 *
I 2015-05-27 03:02:39 theanets.trainer:168 RmsProp 1231 loss=79.678787 err=1.533711
I 2015-05-27 03:02:43 theanets.trainer:168 RmsProp 1232 loss=79.763901 err=1.661544
I 2015-05-27 03:02:47 theanets.trainer:168 RmsProp 1233 loss=79.624466 err=1.566185
I 2015-05-27 03:02:51 theanets.trainer:168 RmsProp 1234 loss=79.609818 err=1.594957
I 2015-05-27 03:02:55 theanets.trainer:168 RmsProp 1235 loss=79.571762 err=1.600622
I 2015-05-27 03:02:59 theanets.trainer:168 RmsProp 1236 loss=79.547668 err=1.621827
I 2015-05-27 03:03:03 theanets.trainer:168 RmsProp 1237 loss=79.469711 err=1.583849
I 2015-05-27 03:03:07 theanets.trainer:168 RmsProp 1238 loss=79.311630 err=1.473413
I 2015-05-27 03:03:11 theanets.trainer:168 RmsProp 1239 loss=79.541092 err=1.745888
I 2015-05-27 03:03:16 theanets.trainer:168 RmsProp 1240 loss=79.397583 err=1.643465
I 2015-05-27 03:03:16 theanets.trainer:168 validation 124 loss=951.580200 err=873.850586
I 2015-05-27 03:03:20 theanets.trainer:168 RmsProp 1241 loss=79.375450 err=1.664467
I 2015-05-27 03:03:24 theanets.trainer:168 RmsProp 1242 loss=79.270912 err=1.601726
I 2015-05-27 03:03:28 theanets.trainer:168 RmsProp 1243 loss=79.328033 err=1.703734
I 2015-05-27 03:03:32 theanets.trainer:168 RmsProp 1244 loss=79.266441 err=1.681666
I 2015-05-27 03:03:36 theanets.trainer:168 RmsProp 1245 loss=79.050056 err=1.511114
I 2015-05-27 03:03:40 theanets.trainer:168 RmsProp 1246 loss=79.133987 err=1.633062
I 2015-05-27 03:03:44 theanets.trainer:168 RmsProp 1247 loss=79.010292 err=1.552991
I 2015-05-27 03:03:48 theanets.trainer:168 RmsProp 1248 loss=79.062355 err=1.648153
I 2015-05-27 03:03:52 theanets.trainer:168 RmsProp 1249 loss=78.929901 err=1.556479
I 2015-05-27 03:03:56 theanets.trainer:168 RmsProp 1250 loss=78.978363 err=1.649657
I 2015-05-27 03:03:56 theanets.trainer:168 validation 125 loss=949.826050 err=872.518005
I 2015-05-27 03:04:00 theanets.trainer:168 RmsProp 1251 loss=78.882545 err=1.594635
I 2015-05-27 03:04:04 theanets.trainer:168 RmsProp 1252 loss=78.715599 err=1.474873
I 2015-05-27 03:04:08 theanets.trainer:168 RmsProp 1253 loss=78.741547 err=1.543005
I 2015-05-27 03:04:12 theanets.trainer:168 RmsProp 1254 loss=78.786446 err=1.627330
I 2015-05-27 03:04:16 theanets.trainer:168 RmsProp 1255 loss=78.638695 err=1.521605
I 2015-05-27 03:04:20 theanets.trainer:168 RmsProp 1256 loss=78.593857 err=1.518244
I 2015-05-27 03:04:24 theanets.trainer:168 RmsProp 1257 loss=78.657684 err=1.628807
I 2015-05-27 03:04:28 theanets.trainer:168 RmsProp 1258 loss=78.568893 err=1.580385
I 2015-05-27 03:04:32 theanets.trainer:168 RmsProp 1259 loss=78.532722 err=1.586044
I 2015-05-27 03:04:36 theanets.trainer:168 RmsProp 1260 loss=78.499626 err=1.593911
I 2015-05-27 03:04:36 theanets.trainer:168 validation 126 loss=950.542358 err=873.652344
I 2015-05-27 03:04:40 theanets.trainer:168 RmsProp 1261 loss=78.441917 err=1.578108
I 2015-05-27 03:04:44 theanets.trainer:168 RmsProp 1262 loss=78.355125 err=1.534664
I 2015-05-27 03:04:48 theanets.trainer:168 RmsProp 1263 loss=78.417885 err=1.641587
I 2015-05-27 03:04:52 theanets.trainer:168 RmsProp 1264 loss=78.321701 err=1.591143
I 2015-05-27 03:04:55 theanets.trainer:168 RmsProp 1265 loss=78.226707 err=1.534951
I 2015-05-27 03:04:59 theanets.trainer:168 RmsProp 1266 loss=78.284203 err=1.632308
I 2015-05-27 03:05:03 theanets.trainer:168 RmsProp 1267 loss=78.100670 err=1.488827
I 2015-05-27 03:05:07 theanets.trainer:168 RmsProp 1268 loss=78.255081 err=1.684503
I 2015-05-27 03:05:11 theanets.trainer:168 RmsProp 1269 loss=78.154968 err=1.626254
I 2015-05-27 03:05:15 theanets.trainer:168 RmsProp 1270 loss=78.029228 err=1.539849
I 2015-05-27 03:05:16 theanets.trainer:168 validation 127 loss=952.278137 err=875.813416
I 2015-05-27 03:05:20 theanets.trainer:168 RmsProp 1271 loss=78.075424 err=1.626578
I 2015-05-27 03:05:24 theanets.trainer:168 RmsProp 1272 loss=77.997574 err=1.589964
I 2015-05-27 03:05:28 theanets.trainer:168 RmsProp 1273 loss=77.946426 err=1.583105
I 2015-05-27 03:05:32 theanets.trainer:168 RmsProp 1274 loss=78.007622 err=1.682216
I 2015-05-27 03:05:36 theanets.trainer:168 RmsProp 1275 loss=77.861687 err=1.578599
I 2015-05-27 03:05:40 theanets.trainer:168 RmsProp 1276 loss=77.740250 err=1.499370
I 2015-05-27 03:05:44 theanets.trainer:168 RmsProp 1277 loss=77.885269 err=1.679646
I 2015-05-27 03:05:48 theanets.trainer:168 RmsProp 1278 loss=77.602631 err=1.443574
I 2015-05-27 03:05:52 theanets.trainer:168 RmsProp 1279 loss=77.665146 err=1.546499
I 2015-05-27 03:05:55 theanets.trainer:168 RmsProp 1280 loss=77.633400 err=1.555105
I 2015-05-27 03:05:55 theanets.trainer:168 validation 128 loss=951.627686 err=875.574219
I 2015-05-27 03:05:55 theanets.trainer:252 patience elapsed!
I 2015-05-27 03:05:55 theanets.main:237 models_deep_post_code_sep/95135-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 03:05:55 theanets.graph:477 models_deep_post_code_sep/95135-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
