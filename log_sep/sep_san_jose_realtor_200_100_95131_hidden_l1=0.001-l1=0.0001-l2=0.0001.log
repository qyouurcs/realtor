I 2015-05-26 03:35:26 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 03:35:26 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95131-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl
I 2015-05-26 03:35:26 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 03:35:26 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 03:35:26 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 03:35:26 theanets.main:89 --batch_size = 1024
I 2015-05-26 03:35:26 theanets.main:89 --gradient_clip = 1
I 2015-05-26 03:35:26 theanets.main:89 --hidden_l1 = None
I 2015-05-26 03:35:26 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 03:35:26 theanets.main:89 --train_batches = 30
I 2015-05-26 03:35:26 theanets.main:89 --valid_batches = 3
I 2015-05-26 03:35:26 theanets.main:89 --weight_l1 = None
I 2015-05-26 03:35:26 theanets.main:89 --weight_l2 = None
I 2015-05-26 03:35:26 theanets.trainer:134 compiling evaluation function
I 2015-05-26 03:35:42 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 03:38:58 theanets.trainer:168 validation 0 loss=14150.463867 err=14150.463867 *
I 2015-05-26 03:39:56 theanets.trainer:168 RmsProp 1 loss=13149.572266 err=13149.572266
I 2015-05-26 03:40:55 theanets.trainer:168 RmsProp 2 loss=13228.949219 err=13228.949219
I 2015-05-26 03:41:55 theanets.trainer:168 RmsProp 3 loss=13117.190430 err=13117.190430
I 2015-05-26 03:42:53 theanets.trainer:168 RmsProp 4 loss=12418.131836 err=12418.131836
I 2015-05-26 03:43:52 theanets.trainer:168 RmsProp 5 loss=10908.969727 err=10908.969727
I 2015-05-26 03:44:50 theanets.trainer:168 RmsProp 6 loss=9948.762695 err=9948.762695
I 2015-05-26 03:45:49 theanets.trainer:168 RmsProp 7 loss=9382.333008 err=9382.333008
I 2015-05-26 03:46:48 theanets.trainer:168 RmsProp 8 loss=8644.985352 err=8644.985352
I 2015-05-26 03:47:46 theanets.trainer:168 RmsProp 9 loss=7678.976074 err=7678.976074
I 2015-05-26 03:48:45 theanets.trainer:168 RmsProp 10 loss=6879.510254 err=6879.510254
I 2015-05-26 03:48:46 theanets.trainer:168 validation 1 loss=6388.520996 err=6388.520996 *
I 2015-05-26 03:49:45 theanets.trainer:168 RmsProp 11 loss=6296.260742 err=6296.260742
I 2015-05-26 03:50:44 theanets.trainer:168 RmsProp 12 loss=5908.107422 err=5908.107422
I 2015-05-26 03:51:44 theanets.trainer:168 RmsProp 13 loss=5563.129395 err=5563.129395
I 2015-05-26 03:52:44 theanets.trainer:168 RmsProp 14 loss=5206.812988 err=5206.812988
I 2015-05-26 03:53:44 theanets.trainer:168 RmsProp 15 loss=4906.880371 err=4906.880371
I 2015-05-26 03:54:44 theanets.trainer:168 RmsProp 16 loss=4652.886230 err=4652.886230
I 2015-05-26 03:55:44 theanets.trainer:168 RmsProp 17 loss=4325.181152 err=4325.181152
I 2015-05-26 03:56:44 theanets.trainer:168 RmsProp 18 loss=4041.254883 err=4041.254883
I 2015-05-26 03:57:44 theanets.trainer:168 RmsProp 19 loss=3981.015137 err=3981.015137
I 2015-05-26 03:58:43 theanets.trainer:168 RmsProp 20 loss=3828.558838 err=3828.558838
I 2015-05-26 03:58:45 theanets.trainer:168 validation 2 loss=4254.931152 err=4254.931152 *
I 2015-05-26 03:59:43 theanets.trainer:168 RmsProp 21 loss=3554.377441 err=3554.377441
I 2015-05-26 04:00:43 theanets.trainer:168 RmsProp 22 loss=3365.994629 err=3365.994629
I 2015-05-26 04:01:43 theanets.trainer:168 RmsProp 23 loss=3092.617188 err=3092.617188
I 2015-05-26 04:02:43 theanets.trainer:168 RmsProp 24 loss=2868.600342 err=2868.600342
I 2015-05-26 04:03:43 theanets.trainer:168 RmsProp 25 loss=2718.307129 err=2718.307129
I 2015-05-26 04:04:42 theanets.trainer:168 RmsProp 26 loss=2570.823242 err=2570.823242
I 2015-05-26 04:05:42 theanets.trainer:168 RmsProp 27 loss=2462.625977 err=2462.625977
I 2015-05-26 04:06:41 theanets.trainer:168 RmsProp 28 loss=2369.254639 err=2369.254639
I 2015-05-26 04:07:41 theanets.trainer:168 RmsProp 29 loss=2193.325195 err=2193.325195
I 2015-05-26 04:08:40 theanets.trainer:168 RmsProp 30 loss=2071.247314 err=2071.247314
I 2015-05-26 04:08:42 theanets.trainer:168 validation 3 loss=3014.244385 err=3014.244385 *
I 2015-05-26 04:09:41 theanets.trainer:168 RmsProp 31 loss=1937.466309 err=1937.466309
I 2015-05-26 04:10:40 theanets.trainer:168 RmsProp 32 loss=1855.534546 err=1855.534546
I 2015-05-26 04:11:39 theanets.trainer:168 RmsProp 33 loss=1764.970581 err=1764.970581
I 2015-05-26 04:12:36 theanets.trainer:168 RmsProp 34 loss=1706.045532 err=1706.045532
I 2015-05-26 04:13:33 theanets.trainer:168 RmsProp 35 loss=1607.101807 err=1607.101807
I 2015-05-26 04:14:29 theanets.trainer:168 RmsProp 36 loss=1526.776245 err=1526.776245
I 2015-05-26 04:15:24 theanets.trainer:168 RmsProp 37 loss=1453.261963 err=1453.261963
I 2015-05-26 04:16:19 theanets.trainer:168 RmsProp 38 loss=1382.570679 err=1382.570679
I 2015-05-26 04:17:14 theanets.trainer:168 RmsProp 39 loss=1316.189087 err=1316.189087
I 2015-05-26 04:18:09 theanets.trainer:168 RmsProp 40 loss=1252.136230 err=1252.136230
I 2015-05-26 04:18:10 theanets.trainer:168 validation 4 loss=2519.184570 err=2519.184570 *
I 2015-05-26 04:19:06 theanets.trainer:168 RmsProp 41 loss=1202.352295 err=1202.352295
I 2015-05-26 04:20:01 theanets.trainer:168 RmsProp 42 loss=1151.705200 err=1151.705200
I 2015-05-26 04:20:58 theanets.trainer:168 RmsProp 43 loss=1135.514404 err=1135.514404
I 2015-05-26 04:21:54 theanets.trainer:168 RmsProp 44 loss=1070.113159 err=1070.113159
I 2015-05-26 04:22:48 theanets.trainer:168 RmsProp 45 loss=1015.291382 err=1015.291382
I 2015-05-26 04:23:39 theanets.trainer:168 RmsProp 46 loss=963.560181 err=963.560181
I 2015-05-26 04:24:31 theanets.trainer:168 RmsProp 47 loss=914.770508 err=914.770508
I 2015-05-26 04:25:23 theanets.trainer:168 RmsProp 48 loss=879.560242 err=879.560242
I 2015-05-26 04:26:16 theanets.trainer:168 RmsProp 49 loss=870.366821 err=870.366821
I 2015-05-26 04:27:08 theanets.trainer:168 RmsProp 50 loss=848.948975 err=848.948975
I 2015-05-26 04:27:09 theanets.trainer:168 validation 5 loss=2187.833252 err=2187.833252 *
I 2015-05-26 04:28:00 theanets.trainer:168 RmsProp 51 loss=802.721313 err=802.721313
I 2015-05-26 04:28:51 theanets.trainer:168 RmsProp 52 loss=792.496338 err=792.496338
I 2015-05-26 04:29:42 theanets.trainer:168 RmsProp 53 loss=765.230286 err=765.230286
I 2015-05-26 04:30:34 theanets.trainer:168 RmsProp 54 loss=735.094482 err=735.094482
I 2015-05-26 04:31:26 theanets.trainer:168 RmsProp 55 loss=706.996826 err=706.996826
I 2015-05-26 04:32:17 theanets.trainer:168 RmsProp 56 loss=675.635315 err=675.635315
I 2015-05-26 04:33:08 theanets.trainer:168 RmsProp 57 loss=648.801453 err=648.801453
I 2015-05-26 04:33:59 theanets.trainer:168 RmsProp 58 loss=643.444397 err=643.444397
I 2015-05-26 04:34:51 theanets.trainer:168 RmsProp 59 loss=620.972778 err=620.972778
I 2015-05-26 04:35:43 theanets.trainer:168 RmsProp 60 loss=598.172791 err=598.172791
I 2015-05-26 04:35:44 theanets.trainer:168 validation 6 loss=2187.852783 err=2187.852783
I 2015-05-26 04:36:37 theanets.trainer:168 RmsProp 61 loss=579.377991 err=579.377991
I 2015-05-26 04:37:29 theanets.trainer:168 RmsProp 62 loss=545.620361 err=545.620361
I 2015-05-26 04:38:21 theanets.trainer:168 RmsProp 63 loss=544.789673 err=544.789673
I 2015-05-26 04:39:14 theanets.trainer:168 RmsProp 64 loss=530.528809 err=530.528809
I 2015-05-26 04:40:07 theanets.trainer:168 RmsProp 65 loss=512.954834 err=512.954834
I 2015-05-26 04:41:00 theanets.trainer:168 RmsProp 66 loss=490.718933 err=490.718933
I 2015-05-26 04:41:53 theanets.trainer:168 RmsProp 67 loss=473.932678 err=473.932678
I 2015-05-26 04:42:46 theanets.trainer:168 RmsProp 68 loss=454.784485 err=454.784485
I 2015-05-26 04:43:39 theanets.trainer:168 RmsProp 69 loss=444.621307 err=444.621307
I 2015-05-26 04:44:32 theanets.trainer:168 RmsProp 70 loss=424.749481 err=424.749481
I 2015-05-26 04:44:33 theanets.trainer:168 validation 7 loss=2122.207031 err=2122.207031 *
I 2015-05-26 04:45:25 theanets.trainer:168 RmsProp 71 loss=431.245941 err=431.245941
I 2015-05-26 04:46:18 theanets.trainer:168 RmsProp 72 loss=416.228882 err=416.228882
I 2015-05-26 04:47:10 theanets.trainer:168 RmsProp 73 loss=404.706909 err=404.706909
I 2015-05-26 04:48:02 theanets.trainer:168 RmsProp 74 loss=399.636505 err=399.636505
I 2015-05-26 04:48:55 theanets.trainer:168 RmsProp 75 loss=380.848206 err=380.848206
I 2015-05-26 04:49:48 theanets.trainer:168 RmsProp 76 loss=368.653503 err=368.653503
I 2015-05-26 04:50:40 theanets.trainer:168 RmsProp 77 loss=373.899628 err=373.899628
I 2015-05-26 04:51:32 theanets.trainer:168 RmsProp 78 loss=356.568024 err=356.568024
I 2015-05-26 04:52:25 theanets.trainer:168 RmsProp 79 loss=342.998352 err=342.998352
I 2015-05-26 04:53:18 theanets.trainer:168 RmsProp 80 loss=335.458618 err=335.458618
I 2015-05-26 04:53:19 theanets.trainer:168 validation 8 loss=2062.880371 err=2062.880371 *
I 2015-05-26 04:54:11 theanets.trainer:168 RmsProp 81 loss=338.319672 err=338.319672
I 2015-05-26 04:55:03 theanets.trainer:168 RmsProp 82 loss=321.418610 err=321.418610
I 2015-05-26 04:55:53 theanets.trainer:168 RmsProp 83 loss=309.454041 err=309.454041
I 2015-05-26 04:56:44 theanets.trainer:168 RmsProp 84 loss=299.481049 err=299.481049
I 2015-05-26 04:57:34 theanets.trainer:168 RmsProp 85 loss=294.783752 err=294.783752
I 2015-05-26 04:58:25 theanets.trainer:168 RmsProp 86 loss=288.144623 err=288.144623
I 2015-05-26 04:59:16 theanets.trainer:168 RmsProp 87 loss=276.822876 err=276.822876
I 2015-05-26 05:00:07 theanets.trainer:168 RmsProp 88 loss=275.168030 err=275.168030
I 2015-05-26 05:00:58 theanets.trainer:168 RmsProp 89 loss=262.170105 err=262.170105
I 2015-05-26 05:01:49 theanets.trainer:168 RmsProp 90 loss=264.312531 err=264.312531
I 2015-05-26 05:01:50 theanets.trainer:168 validation 9 loss=1936.120483 err=1936.120483 *
I 2015-05-26 05:02:41 theanets.trainer:168 RmsProp 91 loss=262.205963 err=262.205963
I 2015-05-26 05:03:32 theanets.trainer:168 RmsProp 92 loss=249.512802 err=249.512802
I 2015-05-26 05:04:24 theanets.trainer:168 RmsProp 93 loss=242.502472 err=242.502472
I 2015-05-26 05:05:15 theanets.trainer:168 RmsProp 94 loss=234.687790 err=234.687790
I 2015-05-26 05:06:07 theanets.trainer:168 RmsProp 95 loss=230.348724 err=230.348724
I 2015-05-26 05:06:59 theanets.trainer:168 RmsProp 96 loss=224.201691 err=224.201691
I 2015-05-26 05:07:50 theanets.trainer:168 RmsProp 97 loss=219.775909 err=219.775909
I 2015-05-26 05:08:40 theanets.trainer:168 RmsProp 98 loss=215.806808 err=215.806808
I 2015-05-26 05:09:31 theanets.trainer:168 RmsProp 99 loss=211.233154 err=211.233154
I 2015-05-26 05:10:20 theanets.trainer:168 RmsProp 100 loss=211.261398 err=211.261398
I 2015-05-26 05:10:21 theanets.trainer:168 validation 10 loss=1846.894531 err=1846.894531 *
I 2015-05-26 05:11:11 theanets.trainer:168 RmsProp 101 loss=204.523865 err=204.523865
I 2015-05-26 05:11:59 theanets.trainer:168 RmsProp 102 loss=200.057770 err=200.057770
I 2015-05-26 05:12:48 theanets.trainer:168 RmsProp 103 loss=191.538239 err=191.538239
I 2015-05-26 05:13:37 theanets.trainer:168 RmsProp 104 loss=198.569992 err=198.569992
I 2015-05-26 05:14:27 theanets.trainer:168 RmsProp 105 loss=185.645950 err=185.645950
I 2015-05-26 05:15:17 theanets.trainer:168 RmsProp 106 loss=185.318024 err=185.318024
I 2015-05-26 05:16:07 theanets.trainer:168 RmsProp 107 loss=176.123444 err=176.123444
I 2015-05-26 05:16:56 theanets.trainer:168 RmsProp 108 loss=171.917511 err=171.917511
I 2015-05-26 05:17:46 theanets.trainer:168 RmsProp 109 loss=166.398865 err=166.398865
I 2015-05-26 05:18:36 theanets.trainer:168 RmsProp 110 loss=161.542908 err=161.542908
I 2015-05-26 05:18:37 theanets.trainer:168 validation 11 loss=1819.072632 err=1819.072632 *
I 2015-05-26 05:19:26 theanets.trainer:168 RmsProp 111 loss=160.256210 err=160.256210
I 2015-05-26 05:20:15 theanets.trainer:168 RmsProp 112 loss=152.226257 err=152.226257
I 2015-05-26 05:21:05 theanets.trainer:168 RmsProp 113 loss=155.498230 err=155.498230
I 2015-05-26 05:21:55 theanets.trainer:168 RmsProp 114 loss=154.359421 err=154.359421
I 2015-05-26 05:22:45 theanets.trainer:168 RmsProp 115 loss=144.727036 err=144.727036
I 2015-05-26 05:23:35 theanets.trainer:168 RmsProp 116 loss=142.764069 err=142.764069
I 2015-05-26 05:24:25 theanets.trainer:168 RmsProp 117 loss=141.371185 err=141.371185
I 2015-05-26 05:25:14 theanets.trainer:168 RmsProp 118 loss=138.820206 err=138.820206
I 2015-05-26 05:26:04 theanets.trainer:168 RmsProp 119 loss=139.002472 err=139.002472
I 2015-05-26 05:26:53 theanets.trainer:168 RmsProp 120 loss=139.288864 err=139.288864
I 2015-05-26 05:26:54 theanets.trainer:168 validation 12 loss=1756.646851 err=1756.646851 *
I 2015-05-26 05:27:44 theanets.trainer:168 RmsProp 121 loss=133.482452 err=133.482452
I 2015-05-26 05:28:35 theanets.trainer:168 RmsProp 122 loss=129.008362 err=129.008362
I 2015-05-26 05:29:25 theanets.trainer:168 RmsProp 123 loss=126.176643 err=126.176643
I 2015-05-26 05:30:15 theanets.trainer:168 RmsProp 124 loss=125.164909 err=125.164909
I 2015-05-26 05:31:05 theanets.trainer:168 RmsProp 125 loss=118.831696 err=118.831696
I 2015-05-26 05:31:55 theanets.trainer:168 RmsProp 126 loss=119.370331 err=119.370331
I 2015-05-26 05:32:45 theanets.trainer:168 RmsProp 127 loss=116.531219 err=116.531219
I 2015-05-26 05:33:35 theanets.trainer:168 RmsProp 128 loss=113.592140 err=113.592140
I 2015-05-26 05:34:25 theanets.trainer:168 RmsProp 129 loss=110.554092 err=110.554092
I 2015-05-26 05:35:15 theanets.trainer:168 RmsProp 130 loss=110.091377 err=110.091377
I 2015-05-26 05:35:16 theanets.trainer:168 validation 13 loss=1706.038696 err=1706.038696 *
I 2015-05-26 05:36:06 theanets.trainer:168 RmsProp 131 loss=106.984039 err=106.984039
I 2015-05-26 05:36:55 theanets.trainer:168 RmsProp 132 loss=105.706375 err=105.706375
I 2015-05-26 05:37:43 theanets.trainer:168 RmsProp 133 loss=105.289955 err=105.289955
I 2015-05-26 05:38:31 theanets.trainer:168 RmsProp 134 loss=103.882675 err=103.882675
I 2015-05-26 05:39:19 theanets.trainer:168 RmsProp 135 loss=100.128891 err=100.128891
I 2015-05-26 05:40:06 theanets.trainer:168 RmsProp 136 loss=98.374733 err=98.374733
I 2015-05-26 05:40:53 theanets.trainer:168 RmsProp 137 loss=97.221298 err=97.221298
I 2015-05-26 05:41:40 theanets.trainer:168 RmsProp 138 loss=98.269737 err=98.269737
I 2015-05-26 05:42:27 theanets.trainer:168 RmsProp 139 loss=92.991173 err=92.991173
I 2015-05-26 05:43:14 theanets.trainer:168 RmsProp 140 loss=92.639488 err=92.639488
I 2015-05-26 05:43:15 theanets.trainer:168 validation 14 loss=1667.595703 err=1667.595703 *
I 2015-05-26 05:44:03 theanets.trainer:168 RmsProp 141 loss=89.996834 err=89.996834
I 2015-05-26 05:44:50 theanets.trainer:168 RmsProp 142 loss=86.937363 err=86.937363
I 2015-05-26 05:45:38 theanets.trainer:168 RmsProp 143 loss=88.688881 err=88.688881
I 2015-05-26 05:46:25 theanets.trainer:168 RmsProp 144 loss=87.225586 err=87.225586
I 2015-05-26 05:47:13 theanets.trainer:168 RmsProp 145 loss=84.148285 err=84.148285
I 2015-05-26 05:48:01 theanets.trainer:168 RmsProp 146 loss=80.878227 err=80.878227
I 2015-05-26 05:48:49 theanets.trainer:168 RmsProp 147 loss=81.155205 err=81.155205
I 2015-05-26 05:49:37 theanets.trainer:168 RmsProp 148 loss=84.281776 err=84.281776
I 2015-05-26 05:50:25 theanets.trainer:168 RmsProp 149 loss=81.151123 err=81.151123
I 2015-05-26 05:51:13 theanets.trainer:168 RmsProp 150 loss=75.281387 err=75.281387
I 2015-05-26 05:51:14 theanets.trainer:168 validation 15 loss=1626.872192 err=1626.872192 *
I 2015-05-26 05:52:00 theanets.trainer:168 RmsProp 151 loss=74.394455 err=74.394455
I 2015-05-26 05:52:47 theanets.trainer:168 RmsProp 152 loss=72.276009 err=72.276009
I 2015-05-26 05:53:34 theanets.trainer:168 RmsProp 153 loss=73.288582 err=73.288582
I 2015-05-26 05:54:21 theanets.trainer:168 RmsProp 154 loss=70.020233 err=70.020233
I 2015-05-26 05:55:08 theanets.trainer:168 RmsProp 155 loss=76.862061 err=76.862061
I 2015-05-26 05:55:56 theanets.trainer:168 RmsProp 156 loss=69.946915 err=69.946915
I 2015-05-26 05:56:44 theanets.trainer:168 RmsProp 157 loss=65.872482 err=65.872482
I 2015-05-26 05:57:32 theanets.trainer:168 RmsProp 158 loss=62.873985 err=62.873985
I 2015-05-26 05:58:19 theanets.trainer:168 RmsProp 159 loss=63.983761 err=63.983761
I 2015-05-26 05:59:06 theanets.trainer:168 RmsProp 160 loss=60.385021 err=60.385021
I 2015-05-26 05:59:07 theanets.trainer:168 validation 16 loss=1611.650757 err=1611.650757 *
I 2015-05-26 05:59:54 theanets.trainer:168 RmsProp 161 loss=67.063431 err=67.063431
I 2015-05-26 06:00:42 theanets.trainer:168 RmsProp 162 loss=63.323269 err=63.323269
I 2015-05-26 06:01:29 theanets.trainer:168 RmsProp 163 loss=61.154507 err=61.154507
I 2015-05-26 06:02:17 theanets.trainer:168 RmsProp 164 loss=58.554989 err=58.554989
I 2015-05-26 06:03:05 theanets.trainer:168 RmsProp 165 loss=58.307133 err=58.307133
I 2015-05-26 06:03:52 theanets.trainer:168 RmsProp 166 loss=55.767441 err=55.767441
I 2015-05-26 06:04:40 theanets.trainer:168 RmsProp 167 loss=55.405224 err=55.405224
I 2015-05-26 06:05:27 theanets.trainer:168 RmsProp 168 loss=58.587002 err=58.587002
I 2015-05-26 06:06:14 theanets.trainer:168 RmsProp 169 loss=52.034138 err=52.034138
I 2015-05-26 06:07:00 theanets.trainer:168 RmsProp 170 loss=49.467693 err=49.467693
I 2015-05-26 06:07:01 theanets.trainer:168 validation 17 loss=1533.865112 err=1533.865112 *
I 2015-05-26 06:07:48 theanets.trainer:168 RmsProp 171 loss=51.403709 err=51.403709
I 2015-05-26 06:08:34 theanets.trainer:168 RmsProp 172 loss=55.028259 err=55.028259
I 2015-05-26 06:09:22 theanets.trainer:168 RmsProp 173 loss=50.529423 err=50.529423
I 2015-05-26 06:10:09 theanets.trainer:168 RmsProp 174 loss=49.519703 err=49.519703
I 2015-05-26 06:10:56 theanets.trainer:168 RmsProp 175 loss=46.545628 err=46.545628
I 2015-05-26 06:11:43 theanets.trainer:168 RmsProp 176 loss=46.567928 err=46.567928
I 2015-05-26 06:12:31 theanets.trainer:168 RmsProp 177 loss=45.113560 err=45.113560
I 2015-05-26 06:13:20 theanets.trainer:168 RmsProp 178 loss=44.998581 err=44.998581
I 2015-05-26 06:14:08 theanets.trainer:168 RmsProp 179 loss=44.571735 err=44.571735
I 2015-05-26 06:14:55 theanets.trainer:168 RmsProp 180 loss=43.577461 err=43.577461
I 2015-05-26 06:14:56 theanets.trainer:168 validation 18 loss=1523.367554 err=1523.367554 *
I 2015-05-26 06:15:44 theanets.trainer:168 RmsProp 181 loss=42.334141 err=42.334141
I 2015-05-26 06:16:31 theanets.trainer:168 RmsProp 182 loss=41.800892 err=41.800892
I 2015-05-26 06:17:19 theanets.trainer:168 RmsProp 183 loss=41.327873 err=41.327873
I 2015-05-26 06:18:08 theanets.trainer:168 RmsProp 184 loss=40.403580 err=40.403580
I 2015-05-26 06:18:55 theanets.trainer:168 RmsProp 185 loss=41.548840 err=41.548840
I 2015-05-26 06:19:43 theanets.trainer:168 RmsProp 186 loss=40.884521 err=40.884521
I 2015-05-26 06:20:29 theanets.trainer:168 RmsProp 187 loss=38.757851 err=38.757851
I 2015-05-26 06:21:16 theanets.trainer:168 RmsProp 188 loss=38.645855 err=38.645855
I 2015-05-26 06:22:03 theanets.trainer:168 RmsProp 189 loss=37.438927 err=37.438927
I 2015-05-26 06:22:51 theanets.trainer:168 RmsProp 190 loss=37.705547 err=37.705547
I 2015-05-26 06:22:52 theanets.trainer:168 validation 19 loss=1490.642212 err=1490.642212 *
I 2015-05-26 06:23:38 theanets.trainer:168 RmsProp 191 loss=36.902401 err=36.902401
I 2015-05-26 06:24:24 theanets.trainer:168 RmsProp 192 loss=36.866875 err=36.866875
I 2015-05-26 06:25:11 theanets.trainer:168 RmsProp 193 loss=35.862621 err=35.862621
I 2015-05-26 06:25:58 theanets.trainer:168 RmsProp 194 loss=34.741909 err=34.741909
I 2015-05-26 06:26:45 theanets.trainer:168 RmsProp 195 loss=34.358128 err=34.358128
I 2015-05-26 06:27:33 theanets.trainer:168 RmsProp 196 loss=34.034115 err=34.034115
I 2015-05-26 06:28:20 theanets.trainer:168 RmsProp 197 loss=33.181484 err=33.181484
I 2015-05-26 06:29:08 theanets.trainer:168 RmsProp 198 loss=32.532986 err=32.532986
I 2015-05-26 06:29:56 theanets.trainer:168 RmsProp 199 loss=32.101959 err=32.101959
I 2015-05-26 06:30:44 theanets.trainer:168 RmsProp 200 loss=31.846283 err=31.846283
I 2015-05-26 06:30:45 theanets.trainer:168 validation 20 loss=1495.699585 err=1495.699585
I 2015-05-26 06:31:32 theanets.trainer:168 RmsProp 201 loss=30.883015 err=30.883015
I 2015-05-26 06:32:20 theanets.trainer:168 RmsProp 202 loss=30.902285 err=30.902285
I 2015-05-26 06:33:08 theanets.trainer:168 RmsProp 203 loss=31.043146 err=31.043146
I 2015-05-26 06:33:56 theanets.trainer:168 RmsProp 204 loss=31.204313 err=31.204313
I 2015-05-26 06:34:43 theanets.trainer:168 RmsProp 205 loss=29.541019 err=29.541019
I 2015-05-26 06:35:28 theanets.trainer:168 RmsProp 206 loss=31.916586 err=31.916586
I 2015-05-26 06:36:14 theanets.trainer:168 RmsProp 207 loss=34.047672 err=34.047672
I 2015-05-26 06:36:59 theanets.trainer:168 RmsProp 208 loss=29.832027 err=29.832027
I 2015-05-26 06:37:45 theanets.trainer:168 RmsProp 209 loss=29.101616 err=29.101616
I 2015-05-26 06:38:30 theanets.trainer:168 RmsProp 210 loss=27.357716 err=27.357716
I 2015-05-26 06:38:31 theanets.trainer:168 validation 21 loss=1608.584839 err=1608.584839
I 2015-05-26 06:39:17 theanets.trainer:168 RmsProp 211 loss=28.152674 err=28.152674
I 2015-05-26 06:40:03 theanets.trainer:168 RmsProp 212 loss=27.205702 err=27.205702
I 2015-05-26 06:40:46 theanets.trainer:168 RmsProp 213 loss=26.640537 err=26.640537
I 2015-05-26 06:41:30 theanets.trainer:168 RmsProp 214 loss=26.976002 err=26.976002
I 2015-05-26 06:42:12 theanets.trainer:168 RmsProp 215 loss=26.459322 err=26.459322
I 2015-05-26 06:42:55 theanets.trainer:168 RmsProp 216 loss=26.037411 err=26.037411
I 2015-05-26 06:43:37 theanets.trainer:168 RmsProp 217 loss=24.461794 err=24.461794
I 2015-05-26 06:44:20 theanets.trainer:168 RmsProp 218 loss=25.912289 err=25.912289
I 2015-05-26 06:45:03 theanets.trainer:168 RmsProp 219 loss=25.579479 err=25.579479
I 2015-05-26 06:45:46 theanets.trainer:168 RmsProp 220 loss=25.034590 err=25.034590
I 2015-05-26 06:45:47 theanets.trainer:168 validation 22 loss=1588.638062 err=1588.638062
I 2015-05-26 06:46:29 theanets.trainer:168 RmsProp 221 loss=24.856699 err=24.856699
I 2015-05-26 06:47:12 theanets.trainer:168 RmsProp 222 loss=23.451063 err=23.451063
I 2015-05-26 06:47:54 theanets.trainer:168 RmsProp 223 loss=23.634844 err=23.634844
I 2015-05-26 06:48:36 theanets.trainer:168 RmsProp 224 loss=24.075964 err=24.075964
I 2015-05-26 06:49:19 theanets.trainer:168 RmsProp 225 loss=23.040445 err=23.040445
I 2015-05-26 06:50:02 theanets.trainer:168 RmsProp 226 loss=24.658369 err=24.658369
I 2015-05-26 06:50:44 theanets.trainer:168 RmsProp 227 loss=22.440857 err=22.440857
I 2015-05-26 06:51:27 theanets.trainer:168 RmsProp 228 loss=22.096647 err=22.096647
I 2015-05-26 06:52:11 theanets.trainer:168 RmsProp 229 loss=21.980429 err=21.980429
I 2015-05-26 06:52:53 theanets.trainer:168 RmsProp 230 loss=21.874310 err=21.874310
I 2015-05-26 06:52:54 theanets.trainer:168 validation 23 loss=1555.713501 err=1555.713501
I 2015-05-26 06:53:36 theanets.trainer:168 RmsProp 231 loss=21.882786 err=21.882786
I 2015-05-26 06:54:18 theanets.trainer:168 RmsProp 232 loss=21.550062 err=21.550062
I 2015-05-26 06:55:00 theanets.trainer:168 RmsProp 233 loss=21.075754 err=21.075754
I 2015-05-26 06:55:43 theanets.trainer:168 RmsProp 234 loss=20.731133 err=20.731133
I 2015-05-26 06:56:26 theanets.trainer:168 RmsProp 235 loss=20.944164 err=20.944164
I 2015-05-26 06:57:09 theanets.trainer:168 RmsProp 236 loss=20.131426 err=20.131426
I 2015-05-26 06:57:49 theanets.trainer:168 RmsProp 237 loss=19.369123 err=19.369123
I 2015-05-26 06:58:27 theanets.trainer:168 RmsProp 238 loss=19.940239 err=19.940239
I 2015-05-26 06:59:05 theanets.trainer:168 RmsProp 239 loss=20.025970 err=20.025970
I 2015-05-26 06:59:43 theanets.trainer:168 RmsProp 240 loss=20.068306 err=20.068306
I 2015-05-26 06:59:44 theanets.trainer:168 validation 24 loss=1544.125610 err=1544.125610
I 2015-05-26 06:59:44 theanets.trainer:252 patience elapsed!
I 2015-05-26 06:59:44 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 06:59:44 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 06:59:44 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 06:59:44 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 06:59:44 theanets.main:89 --batch_size = 1024
I 2015-05-26 06:59:44 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 06:59:44 theanets.main:89 --hidden_l1 = None
I 2015-05-26 06:59:44 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 06:59:44 theanets.main:89 --train_batches = 10
I 2015-05-26 06:59:44 theanets.main:89 --valid_batches = 2
I 2015-05-26 06:59:44 theanets.main:89 --weight_l1 = None
I 2015-05-26 06:59:44 theanets.main:89 --weight_l2 = None
I 2015-05-26 06:59:44 theanets.trainer:134 compiling evaluation function
I 2015-05-26 06:59:54 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 07:01:32 theanets.trainer:168 validation 0 loss=961.483215 err=961.483215 *
I 2015-05-26 07:01:45 theanets.trainer:168 RmsProp 1 loss=28.890055 err=28.890055
I 2015-05-26 07:01:58 theanets.trainer:168 RmsProp 2 loss=18.320873 err=18.320873
I 2015-05-26 07:02:11 theanets.trainer:168 RmsProp 3 loss=13.691846 err=13.691846
I 2015-05-26 07:02:24 theanets.trainer:168 RmsProp 4 loss=11.140364 err=11.140364
I 2015-05-26 07:02:37 theanets.trainer:168 RmsProp 5 loss=9.617181 err=9.617181
I 2015-05-26 07:02:50 theanets.trainer:168 RmsProp 6 loss=8.137281 err=8.137281
I 2015-05-26 07:03:03 theanets.trainer:168 RmsProp 7 loss=7.095376 err=7.095376
I 2015-05-26 07:03:16 theanets.trainer:168 RmsProp 8 loss=6.136742 err=6.136742
I 2015-05-26 07:03:29 theanets.trainer:168 RmsProp 9 loss=5.397372 err=5.397372
I 2015-05-26 07:03:42 theanets.trainer:168 RmsProp 10 loss=4.796237 err=4.796237
I 2015-05-26 07:03:42 theanets.trainer:168 validation 1 loss=872.965454 err=872.965454 *
I 2015-05-26 07:03:56 theanets.trainer:168 RmsProp 11 loss=4.369819 err=4.369819
I 2015-05-26 07:04:09 theanets.trainer:168 RmsProp 12 loss=3.952824 err=3.952824
I 2015-05-26 07:04:21 theanets.trainer:168 RmsProp 13 loss=3.611819 err=3.611819
I 2015-05-26 07:04:34 theanets.trainer:168 RmsProp 14 loss=3.364940 err=3.364940
I 2015-05-26 07:04:47 theanets.trainer:168 RmsProp 15 loss=3.133632 err=3.133632
I 2015-05-26 07:04:59 theanets.trainer:168 RmsProp 16 loss=2.948876 err=2.948876
I 2015-05-26 07:05:12 theanets.trainer:168 RmsProp 17 loss=2.719244 err=2.719244
I 2015-05-26 07:05:24 theanets.trainer:168 RmsProp 18 loss=2.580582 err=2.580582
I 2015-05-26 07:05:37 theanets.trainer:168 RmsProp 19 loss=2.484047 err=2.484047
I 2015-05-26 07:05:50 theanets.trainer:168 RmsProp 20 loss=2.434093 err=2.434093
I 2015-05-26 07:05:50 theanets.trainer:168 validation 2 loss=835.421326 err=835.421326 *
I 2015-05-26 07:06:03 theanets.trainer:168 RmsProp 21 loss=2.289576 err=2.289576
I 2015-05-26 07:06:15 theanets.trainer:168 RmsProp 22 loss=2.203575 err=2.203575
I 2015-05-26 07:06:28 theanets.trainer:168 RmsProp 23 loss=2.096019 err=2.096019
I 2015-05-26 07:06:41 theanets.trainer:168 RmsProp 24 loss=1.994749 err=1.994749
I 2015-05-26 07:06:54 theanets.trainer:168 RmsProp 25 loss=1.903387 err=1.903387
I 2015-05-26 07:07:07 theanets.trainer:168 RmsProp 26 loss=1.852992 err=1.852992
I 2015-05-26 07:07:20 theanets.trainer:168 RmsProp 27 loss=1.750922 err=1.750922
I 2015-05-26 07:07:33 theanets.trainer:168 RmsProp 28 loss=1.734102 err=1.734102
I 2015-05-26 07:07:46 theanets.trainer:168 RmsProp 29 loss=1.690592 err=1.690592
I 2015-05-26 07:07:59 theanets.trainer:168 RmsProp 30 loss=1.627798 err=1.627798
I 2015-05-26 07:08:00 theanets.trainer:168 validation 3 loss=818.621460 err=818.621460 *
I 2015-05-26 07:08:13 theanets.trainer:168 RmsProp 31 loss=1.580516 err=1.580516
I 2015-05-26 07:08:26 theanets.trainer:168 RmsProp 32 loss=1.543105 err=1.543105
I 2015-05-26 07:08:39 theanets.trainer:168 RmsProp 33 loss=1.451401 err=1.451401
I 2015-05-26 07:08:52 theanets.trainer:168 RmsProp 34 loss=1.493401 err=1.493401
I 2015-05-26 07:09:04 theanets.trainer:168 RmsProp 35 loss=1.431136 err=1.431136
I 2015-05-26 07:09:17 theanets.trainer:168 RmsProp 36 loss=1.354504 err=1.354504
I 2015-05-26 07:09:29 theanets.trainer:168 RmsProp 37 loss=1.332586 err=1.332586
I 2015-05-26 07:09:43 theanets.trainer:168 RmsProp 38 loss=1.311085 err=1.311085
I 2015-05-26 07:09:56 theanets.trainer:168 RmsProp 39 loss=1.328890 err=1.328890
I 2015-05-26 07:10:08 theanets.trainer:168 RmsProp 40 loss=1.274298 err=1.274298
I 2015-05-26 07:10:09 theanets.trainer:168 validation 4 loss=807.122375 err=807.122375 *
I 2015-05-26 07:10:22 theanets.trainer:168 RmsProp 41 loss=1.243822 err=1.243822
I 2015-05-26 07:10:35 theanets.trainer:168 RmsProp 42 loss=1.196094 err=1.196094
I 2015-05-26 07:10:48 theanets.trainer:168 RmsProp 43 loss=1.180794 err=1.180794
I 2015-05-26 07:11:01 theanets.trainer:168 RmsProp 44 loss=1.156920 err=1.156920
I 2015-05-26 07:11:14 theanets.trainer:168 RmsProp 45 loss=1.124725 err=1.124725
I 2015-05-26 07:11:27 theanets.trainer:168 RmsProp 46 loss=1.107114 err=1.107114
I 2015-05-26 07:11:40 theanets.trainer:168 RmsProp 47 loss=1.037097 err=1.037097
I 2015-05-26 07:11:52 theanets.trainer:168 RmsProp 48 loss=1.084491 err=1.084491
I 2015-05-26 07:12:05 theanets.trainer:168 RmsProp 49 loss=1.049590 err=1.049590
I 2015-05-26 07:12:17 theanets.trainer:168 RmsProp 50 loss=1.002080 err=1.002080
I 2015-05-26 07:12:18 theanets.trainer:168 validation 5 loss=799.651611 err=799.651611 *
I 2015-05-26 07:12:30 theanets.trainer:168 RmsProp 51 loss=1.026260 err=1.026260
I 2015-05-26 07:12:42 theanets.trainer:168 RmsProp 52 loss=0.999528 err=0.999528
I 2015-05-26 07:12:55 theanets.trainer:168 RmsProp 53 loss=0.968779 err=0.968779
I 2015-05-26 07:13:07 theanets.trainer:168 RmsProp 54 loss=0.936584 err=0.936584
I 2015-05-26 07:13:19 theanets.trainer:168 RmsProp 55 loss=0.962747 err=0.962747
I 2015-05-26 07:13:31 theanets.trainer:168 RmsProp 56 loss=0.925760 err=0.925760
I 2015-05-26 07:13:43 theanets.trainer:168 RmsProp 57 loss=0.890124 err=0.890124
I 2015-05-26 07:13:55 theanets.trainer:168 RmsProp 58 loss=0.890160 err=0.890160
I 2015-05-26 07:14:08 theanets.trainer:168 RmsProp 59 loss=0.891744 err=0.891744
I 2015-05-26 07:14:20 theanets.trainer:168 RmsProp 60 loss=0.886543 err=0.886543
I 2015-05-26 07:14:21 theanets.trainer:168 validation 6 loss=791.345337 err=791.345337 *
I 2015-05-26 07:14:33 theanets.trainer:168 RmsProp 61 loss=0.862016 err=0.862016
I 2015-05-26 07:14:46 theanets.trainer:168 RmsProp 62 loss=0.877114 err=0.877114
I 2015-05-26 07:14:59 theanets.trainer:168 RmsProp 63 loss=0.845931 err=0.845931
I 2015-05-26 07:15:12 theanets.trainer:168 RmsProp 64 loss=0.807055 err=0.807055
I 2015-05-26 07:15:25 theanets.trainer:168 RmsProp 65 loss=0.814843 err=0.814843
I 2015-05-26 07:15:37 theanets.trainer:168 RmsProp 66 loss=0.778599 err=0.778599
I 2015-05-26 07:15:50 theanets.trainer:168 RmsProp 67 loss=0.816808 err=0.816808
I 2015-05-26 07:16:02 theanets.trainer:168 RmsProp 68 loss=0.791699 err=0.791699
I 2015-05-26 07:16:15 theanets.trainer:168 RmsProp 69 loss=0.764120 err=0.764120
I 2015-05-26 07:16:28 theanets.trainer:168 RmsProp 70 loss=0.775829 err=0.775829
I 2015-05-26 07:16:29 theanets.trainer:168 validation 7 loss=787.996277 err=787.996277 *
I 2015-05-26 07:16:41 theanets.trainer:168 RmsProp 71 loss=0.760948 err=0.760948
I 2015-05-26 07:16:54 theanets.trainer:168 RmsProp 72 loss=0.730137 err=0.730137
I 2015-05-26 07:17:07 theanets.trainer:168 RmsProp 73 loss=0.737466 err=0.737466
I 2015-05-26 07:17:19 theanets.trainer:168 RmsProp 74 loss=0.755995 err=0.755995
I 2015-05-26 07:17:32 theanets.trainer:168 RmsProp 75 loss=0.714982 err=0.714982
I 2015-05-26 07:17:45 theanets.trainer:168 RmsProp 76 loss=0.705415 err=0.705415
I 2015-05-26 07:17:57 theanets.trainer:168 RmsProp 77 loss=0.674385 err=0.674385
I 2015-05-26 07:18:10 theanets.trainer:168 RmsProp 78 loss=0.704860 err=0.704860
I 2015-05-26 07:18:22 theanets.trainer:168 RmsProp 79 loss=0.697592 err=0.697592
I 2015-05-26 07:18:35 theanets.trainer:168 RmsProp 80 loss=0.663913 err=0.663913
I 2015-05-26 07:18:35 theanets.trainer:168 validation 8 loss=782.316895 err=782.316895 *
I 2015-05-26 07:18:48 theanets.trainer:168 RmsProp 81 loss=0.677203 err=0.677203
I 2015-05-26 07:19:01 theanets.trainer:168 RmsProp 82 loss=0.663332 err=0.663332
I 2015-05-26 07:19:13 theanets.trainer:168 RmsProp 83 loss=0.663698 err=0.663698
I 2015-05-26 07:19:26 theanets.trainer:168 RmsProp 84 loss=0.656095 err=0.656095
I 2015-05-26 07:19:39 theanets.trainer:168 RmsProp 85 loss=0.633506 err=0.633506
I 2015-05-26 07:19:53 theanets.trainer:168 RmsProp 86 loss=0.651303 err=0.651303
I 2015-05-26 07:20:06 theanets.trainer:168 RmsProp 87 loss=0.677846 err=0.677846
I 2015-05-26 07:20:18 theanets.trainer:168 RmsProp 88 loss=0.620726 err=0.620726
I 2015-05-26 07:20:31 theanets.trainer:168 RmsProp 89 loss=0.611846 err=0.611846
I 2015-05-26 07:20:44 theanets.trainer:168 RmsProp 90 loss=0.618882 err=0.618882
I 2015-05-26 07:20:44 theanets.trainer:168 validation 9 loss=777.725403 err=777.725403 *
I 2015-05-26 07:20:57 theanets.trainer:168 RmsProp 91 loss=0.630284 err=0.630284
I 2015-05-26 07:21:10 theanets.trainer:168 RmsProp 92 loss=0.606778 err=0.606778
I 2015-05-26 07:21:23 theanets.trainer:168 RmsProp 93 loss=0.600614 err=0.600614
I 2015-05-26 07:21:36 theanets.trainer:168 RmsProp 94 loss=0.570227 err=0.570227
I 2015-05-26 07:21:48 theanets.trainer:168 RmsProp 95 loss=0.578642 err=0.578642
I 2015-05-26 07:22:01 theanets.trainer:168 RmsProp 96 loss=0.576137 err=0.576137
I 2015-05-26 07:22:14 theanets.trainer:168 RmsProp 97 loss=0.581249 err=0.581249
I 2015-05-26 07:22:26 theanets.trainer:168 RmsProp 98 loss=0.578425 err=0.578425
I 2015-05-26 07:22:39 theanets.trainer:168 RmsProp 99 loss=0.572577 err=0.572577
I 2015-05-26 07:22:52 theanets.trainer:168 RmsProp 100 loss=0.552091 err=0.552091
I 2015-05-26 07:22:52 theanets.trainer:168 validation 10 loss=774.477722 err=774.477722 *
I 2015-05-26 07:23:05 theanets.trainer:168 RmsProp 101 loss=0.573450 err=0.573450
I 2015-05-26 07:23:18 theanets.trainer:168 RmsProp 102 loss=0.540811 err=0.540811
I 2015-05-26 07:23:31 theanets.trainer:168 RmsProp 103 loss=0.531158 err=0.531158
I 2015-05-26 07:23:44 theanets.trainer:168 RmsProp 104 loss=0.546646 err=0.546646
I 2015-05-26 07:23:57 theanets.trainer:168 RmsProp 105 loss=0.526681 err=0.526681
I 2015-05-26 07:24:10 theanets.trainer:168 RmsProp 106 loss=0.527014 err=0.527014
I 2015-05-26 07:24:24 theanets.trainer:168 RmsProp 107 loss=0.520860 err=0.520860
I 2015-05-26 07:24:36 theanets.trainer:168 RmsProp 108 loss=0.505686 err=0.505686
I 2015-05-26 07:24:49 theanets.trainer:168 RmsProp 109 loss=0.535799 err=0.535799
I 2015-05-26 07:25:01 theanets.trainer:168 RmsProp 110 loss=0.521654 err=0.521654
I 2015-05-26 07:25:02 theanets.trainer:168 validation 11 loss=771.907898 err=771.907898 *
I 2015-05-26 07:25:14 theanets.trainer:168 RmsProp 111 loss=0.506865 err=0.506865
I 2015-05-26 07:25:26 theanets.trainer:168 RmsProp 112 loss=0.491701 err=0.491701
I 2015-05-26 07:25:38 theanets.trainer:168 RmsProp 113 loss=0.487050 err=0.487050
I 2015-05-26 07:25:51 theanets.trainer:168 RmsProp 114 loss=0.520296 err=0.520296
I 2015-05-26 07:26:03 theanets.trainer:168 RmsProp 115 loss=0.479849 err=0.479849
I 2015-05-26 07:26:15 theanets.trainer:168 RmsProp 116 loss=0.491394 err=0.491394
I 2015-05-26 07:26:27 theanets.trainer:168 RmsProp 117 loss=0.494949 err=0.494949
I 2015-05-26 07:26:39 theanets.trainer:168 RmsProp 118 loss=0.490904 err=0.490904
I 2015-05-26 07:26:51 theanets.trainer:168 RmsProp 119 loss=0.468193 err=0.468193
I 2015-05-26 07:27:03 theanets.trainer:168 RmsProp 120 loss=0.500688 err=0.500688
I 2015-05-26 07:27:03 theanets.trainer:168 validation 12 loss=767.126953 err=767.126953 *
I 2015-05-26 07:27:15 theanets.trainer:168 RmsProp 121 loss=0.448956 err=0.448956
I 2015-05-26 07:27:27 theanets.trainer:168 RmsProp 122 loss=0.456688 err=0.456688
I 2015-05-26 07:27:39 theanets.trainer:168 RmsProp 123 loss=0.459139 err=0.459139
I 2015-05-26 07:27:51 theanets.trainer:168 RmsProp 124 loss=0.458575 err=0.458575
I 2015-05-26 07:28:03 theanets.trainer:168 RmsProp 125 loss=0.444268 err=0.444268
I 2015-05-26 07:28:15 theanets.trainer:168 RmsProp 126 loss=0.459181 err=0.459181
I 2015-05-26 07:28:26 theanets.trainer:168 RmsProp 127 loss=0.445356 err=0.445356
I 2015-05-26 07:28:39 theanets.trainer:168 RmsProp 128 loss=0.456089 err=0.456089
I 2015-05-26 07:28:51 theanets.trainer:168 RmsProp 129 loss=0.452972 err=0.452972
I 2015-05-26 07:29:02 theanets.trainer:168 RmsProp 130 loss=0.445424 err=0.445424
I 2015-05-26 07:29:03 theanets.trainer:168 validation 13 loss=765.833923 err=765.833923 *
I 2015-05-26 07:29:15 theanets.trainer:168 RmsProp 131 loss=0.433514 err=0.433514
I 2015-05-26 07:29:27 theanets.trainer:168 RmsProp 132 loss=0.459545 err=0.459545
I 2015-05-26 07:29:39 theanets.trainer:168 RmsProp 133 loss=0.441367 err=0.441367
I 2015-05-26 07:29:51 theanets.trainer:168 RmsProp 134 loss=0.406267 err=0.406267
I 2015-05-26 07:30:03 theanets.trainer:168 RmsProp 135 loss=0.450298 err=0.450298
I 2015-05-26 07:30:16 theanets.trainer:168 RmsProp 136 loss=0.424148 err=0.424148
I 2015-05-26 07:30:28 theanets.trainer:168 RmsProp 137 loss=0.424669 err=0.424669
I 2015-05-26 07:30:40 theanets.trainer:168 RmsProp 138 loss=0.414708 err=0.414708
I 2015-05-26 07:30:51 theanets.trainer:168 RmsProp 139 loss=0.418344 err=0.418344
I 2015-05-26 07:31:03 theanets.trainer:168 RmsProp 140 loss=0.404053 err=0.404053
I 2015-05-26 07:31:04 theanets.trainer:168 validation 14 loss=765.771606 err=765.771606 *
I 2015-05-26 07:31:16 theanets.trainer:168 RmsProp 141 loss=0.410807 err=0.410807
I 2015-05-26 07:31:27 theanets.trainer:168 RmsProp 142 loss=0.401685 err=0.401685
I 2015-05-26 07:31:39 theanets.trainer:168 RmsProp 143 loss=0.406977 err=0.406977
I 2015-05-26 07:31:51 theanets.trainer:168 RmsProp 144 loss=0.409021 err=0.409021
I 2015-05-26 07:32:02 theanets.trainer:168 RmsProp 145 loss=0.399979 err=0.399979
I 2015-05-26 07:32:14 theanets.trainer:168 RmsProp 146 loss=0.386975 err=0.386975
I 2015-05-26 07:32:25 theanets.trainer:168 RmsProp 147 loss=0.406234 err=0.406234
I 2015-05-26 07:32:37 theanets.trainer:168 RmsProp 148 loss=0.395754 err=0.395754
I 2015-05-26 07:32:48 theanets.trainer:168 RmsProp 149 loss=0.385798 err=0.385798
I 2015-05-26 07:32:59 theanets.trainer:168 RmsProp 150 loss=0.394029 err=0.394029
I 2015-05-26 07:33:00 theanets.trainer:168 validation 15 loss=761.255066 err=761.255066 *
I 2015-05-26 07:33:12 theanets.trainer:168 RmsProp 151 loss=0.392873 err=0.392873
I 2015-05-26 07:33:24 theanets.trainer:168 RmsProp 152 loss=0.375176 err=0.375176
I 2015-05-26 07:33:36 theanets.trainer:168 RmsProp 153 loss=0.390610 err=0.390610
I 2015-05-26 07:33:48 theanets.trainer:168 RmsProp 154 loss=0.368364 err=0.368364
I 2015-05-26 07:34:00 theanets.trainer:168 RmsProp 155 loss=0.376970 err=0.376970
I 2015-05-26 07:34:12 theanets.trainer:168 RmsProp 156 loss=0.379721 err=0.379721
I 2015-05-26 07:34:24 theanets.trainer:168 RmsProp 157 loss=0.374798 err=0.374798
I 2015-05-26 07:34:35 theanets.trainer:168 RmsProp 158 loss=0.364128 err=0.364128
I 2015-05-26 07:34:47 theanets.trainer:168 RmsProp 159 loss=0.362266 err=0.362266
I 2015-05-26 07:34:59 theanets.trainer:168 RmsProp 160 loss=0.383748 err=0.383748
I 2015-05-26 07:34:59 theanets.trainer:168 validation 16 loss=760.120789 err=760.120789 *
I 2015-05-26 07:35:11 theanets.trainer:168 RmsProp 161 loss=0.380220 err=0.380220
I 2015-05-26 07:35:23 theanets.trainer:168 RmsProp 162 loss=0.351269 err=0.351269
I 2015-05-26 07:35:35 theanets.trainer:168 RmsProp 163 loss=0.376907 err=0.376907
I 2015-05-26 07:35:47 theanets.trainer:168 RmsProp 164 loss=0.366084 err=0.366084
I 2015-05-26 07:35:59 theanets.trainer:168 RmsProp 165 loss=0.367912 err=0.367912
I 2015-05-26 07:36:10 theanets.trainer:168 RmsProp 166 loss=0.350095 err=0.350095
I 2015-05-26 07:36:22 theanets.trainer:168 RmsProp 167 loss=0.358748 err=0.358748
I 2015-05-26 07:36:34 theanets.trainer:168 RmsProp 168 loss=0.356654 err=0.356654
I 2015-05-26 07:36:46 theanets.trainer:168 RmsProp 169 loss=0.367869 err=0.367869
I 2015-05-26 07:36:58 theanets.trainer:168 RmsProp 170 loss=0.342875 err=0.342875
I 2015-05-26 07:36:58 theanets.trainer:168 validation 17 loss=757.514587 err=757.514587 *
I 2015-05-26 07:37:10 theanets.trainer:168 RmsProp 171 loss=0.339956 err=0.339956
I 2015-05-26 07:37:22 theanets.trainer:168 RmsProp 172 loss=0.365859 err=0.365859
I 2015-05-26 07:37:34 theanets.trainer:168 RmsProp 173 loss=0.334125 err=0.334125
I 2015-05-26 07:37:46 theanets.trainer:168 RmsProp 174 loss=0.332553 err=0.332553
I 2015-05-26 07:37:58 theanets.trainer:168 RmsProp 175 loss=0.350580 err=0.350580
I 2015-05-26 07:38:10 theanets.trainer:168 RmsProp 176 loss=0.351839 err=0.351839
I 2015-05-26 07:38:22 theanets.trainer:168 RmsProp 177 loss=0.334648 err=0.334648
I 2015-05-26 07:38:34 theanets.trainer:168 RmsProp 178 loss=0.321466 err=0.321466
I 2015-05-26 07:38:46 theanets.trainer:168 RmsProp 179 loss=0.344159 err=0.344159
I 2015-05-26 07:38:57 theanets.trainer:168 RmsProp 180 loss=0.326315 err=0.326315
I 2015-05-26 07:38:58 theanets.trainer:168 validation 18 loss=756.304504 err=756.304504 *
I 2015-05-26 07:39:10 theanets.trainer:168 RmsProp 181 loss=0.330037 err=0.330037
I 2015-05-26 07:39:22 theanets.trainer:168 RmsProp 182 loss=0.321885 err=0.321885
I 2015-05-26 07:39:34 theanets.trainer:168 RmsProp 183 loss=0.338344 err=0.338344
I 2015-05-26 07:39:46 theanets.trainer:168 RmsProp 184 loss=0.314787 err=0.314787
I 2015-05-26 07:39:59 theanets.trainer:168 RmsProp 185 loss=0.349047 err=0.349047
I 2015-05-26 07:40:11 theanets.trainer:168 RmsProp 186 loss=0.306098 err=0.306098
I 2015-05-26 07:40:24 theanets.trainer:168 RmsProp 187 loss=0.320664 err=0.320664
I 2015-05-26 07:40:36 theanets.trainer:168 RmsProp 188 loss=0.313091 err=0.313091
I 2015-05-26 07:40:48 theanets.trainer:168 RmsProp 189 loss=0.337802 err=0.337802
I 2015-05-26 07:41:01 theanets.trainer:168 RmsProp 190 loss=0.303569 err=0.303569
I 2015-05-26 07:41:01 theanets.trainer:168 validation 19 loss=755.209106 err=755.209106 *
I 2015-05-26 07:41:14 theanets.trainer:168 RmsProp 191 loss=0.325636 err=0.325636
I 2015-05-26 07:41:26 theanets.trainer:168 RmsProp 192 loss=0.308885 err=0.308885
I 2015-05-26 07:41:38 theanets.trainer:168 RmsProp 193 loss=0.326332 err=0.326332
I 2015-05-26 07:41:51 theanets.trainer:168 RmsProp 194 loss=0.319821 err=0.319821
I 2015-05-26 07:42:03 theanets.trainer:168 RmsProp 195 loss=0.309830 err=0.309830
I 2015-05-26 07:42:15 theanets.trainer:168 RmsProp 196 loss=0.311538 err=0.311538
I 2015-05-26 07:42:27 theanets.trainer:168 RmsProp 197 loss=0.308253 err=0.308253
I 2015-05-26 07:42:39 theanets.trainer:168 RmsProp 198 loss=0.294097 err=0.294097
I 2015-05-26 07:42:51 theanets.trainer:168 RmsProp 199 loss=0.289595 err=0.289595
I 2015-05-26 07:43:03 theanets.trainer:168 RmsProp 200 loss=0.338401 err=0.338401
I 2015-05-26 07:43:03 theanets.trainer:168 validation 20 loss=753.914185 err=753.914185 *
I 2015-05-26 07:43:14 theanets.trainer:168 RmsProp 201 loss=0.319493 err=0.319493
I 2015-05-26 07:43:26 theanets.trainer:168 RmsProp 202 loss=0.296335 err=0.296335
I 2015-05-26 07:43:37 theanets.trainer:168 RmsProp 203 loss=0.284073 err=0.284073
I 2015-05-26 07:43:48 theanets.trainer:168 RmsProp 204 loss=0.296594 err=0.296594
I 2015-05-26 07:44:00 theanets.trainer:168 RmsProp 205 loss=0.289434 err=0.289434
I 2015-05-26 07:44:11 theanets.trainer:168 RmsProp 206 loss=0.311563 err=0.311563
I 2015-05-26 07:44:22 theanets.trainer:168 RmsProp 207 loss=0.287541 err=0.287541
I 2015-05-26 07:44:33 theanets.trainer:168 RmsProp 208 loss=0.291750 err=0.291750
I 2015-05-26 07:44:44 theanets.trainer:168 RmsProp 209 loss=0.288023 err=0.288023
I 2015-05-26 07:44:55 theanets.trainer:168 RmsProp 210 loss=0.296252 err=0.296252
I 2015-05-26 07:44:56 theanets.trainer:168 validation 21 loss=747.263062 err=747.263062 *
I 2015-05-26 07:45:06 theanets.trainer:168 RmsProp 211 loss=0.287575 err=0.287575
I 2015-05-26 07:45:17 theanets.trainer:168 RmsProp 212 loss=0.283437 err=0.283437
I 2015-05-26 07:45:29 theanets.trainer:168 RmsProp 213 loss=0.287914 err=0.287914
I 2015-05-26 07:45:40 theanets.trainer:168 RmsProp 214 loss=0.275415 err=0.275415
I 2015-05-26 07:45:51 theanets.trainer:168 RmsProp 215 loss=0.287235 err=0.287235
I 2015-05-26 07:46:02 theanets.trainer:168 RmsProp 216 loss=0.278632 err=0.278632
I 2015-05-26 07:46:13 theanets.trainer:168 RmsProp 217 loss=0.291604 err=0.291604
I 2015-05-26 07:46:25 theanets.trainer:168 RmsProp 218 loss=0.270477 err=0.270477
I 2015-05-26 07:46:36 theanets.trainer:168 RmsProp 219 loss=0.286297 err=0.286297
I 2015-05-26 07:46:47 theanets.trainer:168 RmsProp 220 loss=0.283810 err=0.283810
I 2015-05-26 07:46:47 theanets.trainer:168 validation 22 loss=749.413208 err=749.413208
I 2015-05-26 07:46:58 theanets.trainer:168 RmsProp 221 loss=0.273503 err=0.273503
I 2015-05-26 07:47:09 theanets.trainer:168 RmsProp 222 loss=0.277570 err=0.277570
I 2015-05-26 07:47:20 theanets.trainer:168 RmsProp 223 loss=0.270269 err=0.270269
I 2015-05-26 07:47:31 theanets.trainer:168 RmsProp 224 loss=0.275029 err=0.275029
I 2015-05-26 07:47:43 theanets.trainer:168 RmsProp 225 loss=0.258049 err=0.258049
I 2015-05-26 07:47:54 theanets.trainer:168 RmsProp 226 loss=0.267107 err=0.267107
I 2015-05-26 07:48:05 theanets.trainer:168 RmsProp 227 loss=0.287447 err=0.287447
I 2015-05-26 07:48:16 theanets.trainer:168 RmsProp 228 loss=0.267790 err=0.267790
I 2015-05-26 07:48:27 theanets.trainer:168 RmsProp 229 loss=0.252840 err=0.252840
I 2015-05-26 07:48:38 theanets.trainer:168 RmsProp 230 loss=0.302005 err=0.302005
I 2015-05-26 07:48:38 theanets.trainer:168 validation 23 loss=745.840149 err=745.840149 *
I 2015-05-26 07:48:49 theanets.trainer:168 RmsProp 231 loss=0.271037 err=0.271037
I 2015-05-26 07:49:00 theanets.trainer:168 RmsProp 232 loss=0.252204 err=0.252204
I 2015-05-26 07:49:11 theanets.trainer:168 RmsProp 233 loss=0.268152 err=0.268152
I 2015-05-26 07:49:21 theanets.trainer:168 RmsProp 234 loss=0.263524 err=0.263524
I 2015-05-26 07:49:32 theanets.trainer:168 RmsProp 235 loss=0.281213 err=0.281213
I 2015-05-26 07:49:42 theanets.trainer:168 RmsProp 236 loss=0.250490 err=0.250490
I 2015-05-26 07:49:53 theanets.trainer:168 RmsProp 237 loss=0.262109 err=0.262109
I 2015-05-26 07:50:04 theanets.trainer:168 RmsProp 238 loss=0.255637 err=0.255637
I 2015-05-26 07:50:14 theanets.trainer:168 RmsProp 239 loss=0.249377 err=0.249377
I 2015-05-26 07:50:24 theanets.trainer:168 RmsProp 240 loss=0.266961 err=0.266961
I 2015-05-26 07:50:24 theanets.trainer:168 validation 24 loss=743.062439 err=743.062439 *
I 2015-05-26 07:50:35 theanets.trainer:168 RmsProp 241 loss=0.260851 err=0.260851
I 2015-05-26 07:50:46 theanets.trainer:168 RmsProp 242 loss=0.241743 err=0.241743
I 2015-05-26 07:50:56 theanets.trainer:168 RmsProp 243 loss=0.266982 err=0.266982
I 2015-05-26 07:51:07 theanets.trainer:168 RmsProp 244 loss=0.259735 err=0.259735
I 2015-05-26 07:51:18 theanets.trainer:168 RmsProp 245 loss=0.254252 err=0.254252
I 2015-05-26 07:51:28 theanets.trainer:168 RmsProp 246 loss=0.245030 err=0.245030
I 2015-05-26 07:51:39 theanets.trainer:168 RmsProp 247 loss=0.234923 err=0.234923
I 2015-05-26 07:51:49 theanets.trainer:168 RmsProp 248 loss=0.264815 err=0.264815
I 2015-05-26 07:52:00 theanets.trainer:168 RmsProp 249 loss=0.250677 err=0.250677
I 2015-05-26 07:52:11 theanets.trainer:168 RmsProp 250 loss=0.254614 err=0.254614
I 2015-05-26 07:52:11 theanets.trainer:168 validation 25 loss=743.459534 err=743.459534
I 2015-05-26 07:52:22 theanets.trainer:168 RmsProp 251 loss=0.241394 err=0.241394
I 2015-05-26 07:52:33 theanets.trainer:168 RmsProp 252 loss=0.252431 err=0.252431
I 2015-05-26 07:52:44 theanets.trainer:168 RmsProp 253 loss=0.243073 err=0.243073
I 2015-05-26 07:52:55 theanets.trainer:168 RmsProp 254 loss=0.255733 err=0.255733
I 2015-05-26 07:53:06 theanets.trainer:168 RmsProp 255 loss=0.237509 err=0.237509
I 2015-05-26 07:53:17 theanets.trainer:168 RmsProp 256 loss=0.247571 err=0.247571
I 2015-05-26 07:53:28 theanets.trainer:168 RmsProp 257 loss=0.233311 err=0.233311
I 2015-05-26 07:53:39 theanets.trainer:168 RmsProp 258 loss=0.253854 err=0.253854
I 2015-05-26 07:53:50 theanets.trainer:168 RmsProp 259 loss=0.227640 err=0.227640
I 2015-05-26 07:54:01 theanets.trainer:168 RmsProp 260 loss=0.241655 err=0.241655
I 2015-05-26 07:54:02 theanets.trainer:168 validation 26 loss=742.039368 err=742.039368 *
I 2015-05-26 07:54:13 theanets.trainer:168 RmsProp 261 loss=0.245629 err=0.245629
I 2015-05-26 07:54:24 theanets.trainer:168 RmsProp 262 loss=0.241705 err=0.241705
I 2015-05-26 07:54:34 theanets.trainer:168 RmsProp 263 loss=0.257070 err=0.257070
I 2015-05-26 07:54:45 theanets.trainer:168 RmsProp 264 loss=0.225585 err=0.225585
I 2015-05-26 07:54:56 theanets.trainer:168 RmsProp 265 loss=0.237445 err=0.237445
I 2015-05-26 07:55:07 theanets.trainer:168 RmsProp 266 loss=0.230977 err=0.230977
I 2015-05-26 07:55:18 theanets.trainer:168 RmsProp 267 loss=0.233381 err=0.233381
I 2015-05-26 07:55:29 theanets.trainer:168 RmsProp 268 loss=0.263316 err=0.263316
I 2015-05-26 07:55:39 theanets.trainer:168 RmsProp 269 loss=0.224906 err=0.224906
I 2015-05-26 07:55:50 theanets.trainer:168 RmsProp 270 loss=0.232387 err=0.232387
I 2015-05-26 07:55:51 theanets.trainer:168 validation 27 loss=737.723816 err=737.723816 *
I 2015-05-26 07:56:01 theanets.trainer:168 RmsProp 271 loss=0.238403 err=0.238403
I 2015-05-26 07:56:12 theanets.trainer:168 RmsProp 272 loss=0.213924 err=0.213924
I 2015-05-26 07:56:23 theanets.trainer:168 RmsProp 273 loss=0.236892 err=0.236892
I 2015-05-26 07:56:34 theanets.trainer:168 RmsProp 274 loss=0.226402 err=0.226402
I 2015-05-26 07:56:45 theanets.trainer:168 RmsProp 275 loss=0.234048 err=0.234048
I 2015-05-26 07:56:57 theanets.trainer:168 RmsProp 276 loss=0.221631 err=0.221631
I 2015-05-26 07:57:08 theanets.trainer:168 RmsProp 277 loss=0.233936 err=0.233936
I 2015-05-26 07:57:19 theanets.trainer:168 RmsProp 278 loss=0.220269 err=0.220269
I 2015-05-26 07:57:31 theanets.trainer:168 RmsProp 279 loss=0.222984 err=0.222984
I 2015-05-26 07:57:42 theanets.trainer:168 RmsProp 280 loss=0.229448 err=0.229448
I 2015-05-26 07:57:43 theanets.trainer:168 validation 28 loss=739.257080 err=739.257080
I 2015-05-26 07:57:54 theanets.trainer:168 RmsProp 281 loss=0.219742 err=0.219742
I 2015-05-26 07:58:05 theanets.trainer:168 RmsProp 282 loss=0.230634 err=0.230634
I 2015-05-26 07:58:16 theanets.trainer:168 RmsProp 283 loss=0.229341 err=0.229341
I 2015-05-26 07:58:27 theanets.trainer:168 RmsProp 284 loss=0.222029 err=0.222029
I 2015-05-26 07:58:38 theanets.trainer:168 RmsProp 285 loss=0.222088 err=0.222088
I 2015-05-26 07:58:49 theanets.trainer:168 RmsProp 286 loss=0.228109 err=0.228109
I 2015-05-26 07:59:00 theanets.trainer:168 RmsProp 287 loss=0.224884 err=0.224884
I 2015-05-26 07:59:11 theanets.trainer:168 RmsProp 288 loss=0.220462 err=0.220462
I 2015-05-26 07:59:21 theanets.trainer:168 RmsProp 289 loss=0.227109 err=0.227109
I 2015-05-26 07:59:32 theanets.trainer:168 RmsProp 290 loss=0.210841 err=0.210841
I 2015-05-26 07:59:32 theanets.trainer:168 validation 29 loss=737.398743 err=737.398743 *
I 2015-05-26 07:59:43 theanets.trainer:168 RmsProp 291 loss=0.210233 err=0.210233
I 2015-05-26 07:59:54 theanets.trainer:168 RmsProp 292 loss=0.209443 err=0.209443
I 2015-05-26 08:00:05 theanets.trainer:168 RmsProp 293 loss=0.215332 err=0.215332
I 2015-05-26 08:00:16 theanets.trainer:168 RmsProp 294 loss=0.226027 err=0.226027
I 2015-05-26 08:00:27 theanets.trainer:168 RmsProp 295 loss=0.206978 err=0.206978
I 2015-05-26 08:00:38 theanets.trainer:168 RmsProp 296 loss=0.218019 err=0.218019
I 2015-05-26 08:00:50 theanets.trainer:168 RmsProp 297 loss=0.204580 err=0.204580
I 2015-05-26 08:01:02 theanets.trainer:168 RmsProp 298 loss=0.224920 err=0.224920
I 2015-05-26 08:01:13 theanets.trainer:168 RmsProp 299 loss=0.243986 err=0.243986
I 2015-05-26 08:01:24 theanets.trainer:168 RmsProp 300 loss=0.200758 err=0.200758
I 2015-05-26 08:01:24 theanets.trainer:168 validation 30 loss=734.576782 err=734.576782 *
I 2015-05-26 08:01:35 theanets.trainer:168 RmsProp 301 loss=0.216426 err=0.216426
I 2015-05-26 08:01:47 theanets.trainer:168 RmsProp 302 loss=0.212847 err=0.212847
I 2015-05-26 08:01:57 theanets.trainer:168 RmsProp 303 loss=0.211992 err=0.211992
I 2015-05-26 08:02:08 theanets.trainer:168 RmsProp 304 loss=0.209718 err=0.209718
I 2015-05-26 08:02:18 theanets.trainer:168 RmsProp 305 loss=0.213357 err=0.213357
I 2015-05-26 08:02:28 theanets.trainer:168 RmsProp 306 loss=0.203075 err=0.203075
I 2015-05-26 08:02:38 theanets.trainer:168 RmsProp 307 loss=0.206640 err=0.206640
I 2015-05-26 08:02:48 theanets.trainer:168 RmsProp 308 loss=0.208289 err=0.208289
I 2015-05-26 08:02:59 theanets.trainer:168 RmsProp 309 loss=0.207092 err=0.207092
I 2015-05-26 08:03:09 theanets.trainer:168 RmsProp 310 loss=0.203056 err=0.203056
I 2015-05-26 08:03:09 theanets.trainer:168 validation 31 loss=735.630554 err=735.630554
I 2015-05-26 08:03:20 theanets.trainer:168 RmsProp 311 loss=0.201158 err=0.201158
I 2015-05-26 08:03:30 theanets.trainer:168 RmsProp 312 loss=0.210681 err=0.210681
I 2015-05-26 08:03:40 theanets.trainer:168 RmsProp 313 loss=0.203272 err=0.203272
I 2015-05-26 08:03:50 theanets.trainer:168 RmsProp 314 loss=0.206062 err=0.206062
I 2015-05-26 08:04:00 theanets.trainer:168 RmsProp 315 loss=0.187590 err=0.187590
I 2015-05-26 08:04:11 theanets.trainer:168 RmsProp 316 loss=0.220012 err=0.220012
I 2015-05-26 08:04:21 theanets.trainer:168 RmsProp 317 loss=0.198132 err=0.198132
I 2015-05-26 08:04:31 theanets.trainer:168 RmsProp 318 loss=0.207866 err=0.207866
I 2015-05-26 08:04:41 theanets.trainer:168 RmsProp 319 loss=0.206820 err=0.206820
I 2015-05-26 08:04:51 theanets.trainer:168 RmsProp 320 loss=0.198682 err=0.198682
I 2015-05-26 08:04:52 theanets.trainer:168 validation 32 loss=733.327087 err=733.327087 *
I 2015-05-26 08:05:02 theanets.trainer:168 RmsProp 321 loss=0.197334 err=0.197334
I 2015-05-26 08:05:13 theanets.trainer:168 RmsProp 322 loss=0.190098 err=0.190098
I 2015-05-26 08:05:23 theanets.trainer:168 RmsProp 323 loss=0.207005 err=0.207005
I 2015-05-26 08:05:34 theanets.trainer:168 RmsProp 324 loss=0.202215 err=0.202215
I 2015-05-26 08:05:44 theanets.trainer:168 RmsProp 325 loss=0.189786 err=0.189786
I 2015-05-26 08:05:54 theanets.trainer:168 RmsProp 326 loss=0.201905 err=0.201905
I 2015-05-26 08:06:04 theanets.trainer:168 RmsProp 327 loss=0.193172 err=0.193172
I 2015-05-26 08:06:14 theanets.trainer:168 RmsProp 328 loss=0.189187 err=0.189187
I 2015-05-26 08:06:25 theanets.trainer:168 RmsProp 329 loss=0.220701 err=0.220701
I 2015-05-26 08:06:35 theanets.trainer:168 RmsProp 330 loss=0.189643 err=0.189643
I 2015-05-26 08:06:36 theanets.trainer:168 validation 33 loss=732.545105 err=732.545105 *
I 2015-05-26 08:06:46 theanets.trainer:168 RmsProp 331 loss=0.193779 err=0.193779
I 2015-05-26 08:06:56 theanets.trainer:168 RmsProp 332 loss=0.203271 err=0.203271
I 2015-05-26 08:07:07 theanets.trainer:168 RmsProp 333 loss=0.191305 err=0.191305
I 2015-05-26 08:07:17 theanets.trainer:168 RmsProp 334 loss=0.190401 err=0.190401
I 2015-05-26 08:07:28 theanets.trainer:168 RmsProp 335 loss=0.185746 err=0.185746
I 2015-05-26 08:07:38 theanets.trainer:168 RmsProp 336 loss=0.196146 err=0.196146
I 2015-05-26 08:07:48 theanets.trainer:168 RmsProp 337 loss=0.194810 err=0.194810
I 2015-05-26 08:07:58 theanets.trainer:168 RmsProp 338 loss=0.178325 err=0.178325
I 2015-05-26 08:08:08 theanets.trainer:168 RmsProp 339 loss=0.201207 err=0.201207
I 2015-05-26 08:08:18 theanets.trainer:168 RmsProp 340 loss=0.189515 err=0.189515
I 2015-05-26 08:08:18 theanets.trainer:168 validation 34 loss=730.052673 err=730.052673 *
I 2015-05-26 08:08:28 theanets.trainer:168 RmsProp 341 loss=0.183572 err=0.183572
I 2015-05-26 08:08:38 theanets.trainer:168 RmsProp 342 loss=0.198771 err=0.198771
I 2015-05-26 08:08:49 theanets.trainer:168 RmsProp 343 loss=0.188925 err=0.188925
I 2015-05-26 08:08:59 theanets.trainer:168 RmsProp 344 loss=0.178689 err=0.178689
I 2015-05-26 08:09:09 theanets.trainer:168 RmsProp 345 loss=0.188149 err=0.188149
I 2015-05-26 08:09:20 theanets.trainer:168 RmsProp 346 loss=0.212419 err=0.212419
I 2015-05-26 08:09:30 theanets.trainer:168 RmsProp 347 loss=0.180563 err=0.180563
I 2015-05-26 08:09:41 theanets.trainer:168 RmsProp 348 loss=0.198706 err=0.198706
I 2015-05-26 08:09:51 theanets.trainer:168 RmsProp 349 loss=0.174655 err=0.174655
I 2015-05-26 08:10:02 theanets.trainer:168 RmsProp 350 loss=0.190528 err=0.190528
I 2015-05-26 08:10:02 theanets.trainer:168 validation 35 loss=730.382812 err=730.382812
I 2015-05-26 08:10:13 theanets.trainer:168 RmsProp 351 loss=0.178749 err=0.178749
I 2015-05-26 08:10:23 theanets.trainer:168 RmsProp 352 loss=0.184740 err=0.184740
I 2015-05-26 08:10:33 theanets.trainer:168 RmsProp 353 loss=0.194640 err=0.194640
I 2015-05-26 08:10:44 theanets.trainer:168 RmsProp 354 loss=0.176523 err=0.176523
I 2015-05-26 08:10:54 theanets.trainer:168 RmsProp 355 loss=0.182103 err=0.182103
I 2015-05-26 08:11:05 theanets.trainer:168 RmsProp 356 loss=0.193962 err=0.193962
I 2015-05-26 08:11:15 theanets.trainer:168 RmsProp 357 loss=0.191124 err=0.191124
I 2015-05-26 08:11:26 theanets.trainer:168 RmsProp 358 loss=0.182095 err=0.182095
I 2015-05-26 08:11:36 theanets.trainer:168 RmsProp 359 loss=0.184774 err=0.184774
I 2015-05-26 08:11:46 theanets.trainer:168 RmsProp 360 loss=0.196742 err=0.196742
I 2015-05-26 08:11:47 theanets.trainer:168 validation 36 loss=730.578552 err=730.578552
I 2015-05-26 08:11:56 theanets.trainer:168 RmsProp 361 loss=0.168056 err=0.168056
I 2015-05-26 08:12:06 theanets.trainer:168 RmsProp 362 loss=0.171428 err=0.171428
I 2015-05-26 08:12:17 theanets.trainer:168 RmsProp 363 loss=0.196020 err=0.196020
I 2015-05-26 08:12:27 theanets.trainer:168 RmsProp 364 loss=0.180625 err=0.180625
I 2015-05-26 08:12:38 theanets.trainer:168 RmsProp 365 loss=0.180223 err=0.180223
I 2015-05-26 08:12:48 theanets.trainer:168 RmsProp 366 loss=0.179742 err=0.179742
I 2015-05-26 08:12:58 theanets.trainer:168 RmsProp 367 loss=0.173556 err=0.173556
I 2015-05-26 08:13:09 theanets.trainer:168 RmsProp 368 loss=0.173146 err=0.173146
I 2015-05-26 08:13:19 theanets.trainer:168 RmsProp 369 loss=0.176208 err=0.176208
I 2015-05-26 08:13:30 theanets.trainer:168 RmsProp 370 loss=0.183583 err=0.183583
I 2015-05-26 08:13:31 theanets.trainer:168 validation 37 loss=728.017395 err=728.017395 *
I 2015-05-26 08:13:41 theanets.trainer:168 RmsProp 371 loss=0.179064 err=0.179064
I 2015-05-26 08:13:52 theanets.trainer:168 RmsProp 372 loss=0.176766 err=0.176766
I 2015-05-26 08:14:02 theanets.trainer:168 RmsProp 373 loss=0.174014 err=0.174014
I 2015-05-26 08:14:12 theanets.trainer:168 RmsProp 374 loss=0.175249 err=0.175249
I 2015-05-26 08:14:22 theanets.trainer:168 RmsProp 375 loss=0.182072 err=0.182072
I 2015-05-26 08:14:33 theanets.trainer:168 RmsProp 376 loss=0.172267 err=0.172267
I 2015-05-26 08:14:43 theanets.trainer:168 RmsProp 377 loss=0.170734 err=0.170734
I 2015-05-26 08:14:53 theanets.trainer:168 RmsProp 378 loss=0.180987 err=0.180987
I 2015-05-26 08:15:03 theanets.trainer:168 RmsProp 379 loss=0.194563 err=0.194563
I 2015-05-26 08:15:14 theanets.trainer:168 RmsProp 380 loss=0.164042 err=0.164042
I 2015-05-26 08:15:14 theanets.trainer:168 validation 38 loss=725.548828 err=725.548828 *
I 2015-05-26 08:15:25 theanets.trainer:168 RmsProp 381 loss=0.170534 err=0.170534
I 2015-05-26 08:15:35 theanets.trainer:168 RmsProp 382 loss=0.159450 err=0.159450
I 2015-05-26 08:15:45 theanets.trainer:168 RmsProp 383 loss=0.184378 err=0.184378
I 2015-05-26 08:15:56 theanets.trainer:168 RmsProp 384 loss=0.175335 err=0.175335
I 2015-05-26 08:16:06 theanets.trainer:168 RmsProp 385 loss=0.167745 err=0.167745
I 2015-05-26 08:16:16 theanets.trainer:168 RmsProp 386 loss=0.168366 err=0.168366
I 2015-05-26 08:16:27 theanets.trainer:168 RmsProp 387 loss=0.154321 err=0.154321
I 2015-05-26 08:16:37 theanets.trainer:168 RmsProp 388 loss=0.176813 err=0.176813
I 2015-05-26 08:16:47 theanets.trainer:168 RmsProp 389 loss=0.175599 err=0.175599
I 2015-05-26 08:16:57 theanets.trainer:168 RmsProp 390 loss=0.170328 err=0.170328
I 2015-05-26 08:16:58 theanets.trainer:168 validation 39 loss=726.911072 err=726.911072
I 2015-05-26 08:17:08 theanets.trainer:168 RmsProp 391 loss=0.159270 err=0.159270
I 2015-05-26 08:17:19 theanets.trainer:168 RmsProp 392 loss=0.165902 err=0.165902
I 2015-05-26 08:17:29 theanets.trainer:168 RmsProp 393 loss=0.158507 err=0.158507
I 2015-05-26 08:17:39 theanets.trainer:168 RmsProp 394 loss=0.178987 err=0.178987
I 2015-05-26 08:17:50 theanets.trainer:168 RmsProp 395 loss=0.157753 err=0.157753
I 2015-05-26 08:18:00 theanets.trainer:168 RmsProp 396 loss=0.175371 err=0.175371
I 2015-05-26 08:18:11 theanets.trainer:168 RmsProp 397 loss=0.163189 err=0.163189
I 2015-05-26 08:18:21 theanets.trainer:168 RmsProp 398 loss=0.173145 err=0.173145
I 2015-05-26 08:18:32 theanets.trainer:168 RmsProp 399 loss=0.178435 err=0.178435
I 2015-05-26 08:18:42 theanets.trainer:168 RmsProp 400 loss=0.174546 err=0.174546
I 2015-05-26 08:18:42 theanets.trainer:168 validation 40 loss=726.006775 err=726.006775
I 2015-05-26 08:18:52 theanets.trainer:168 RmsProp 401 loss=0.152378 err=0.152378
I 2015-05-26 08:19:03 theanets.trainer:168 RmsProp 402 loss=0.169546 err=0.169546
I 2015-05-26 08:19:13 theanets.trainer:168 RmsProp 403 loss=0.164137 err=0.164137
I 2015-05-26 08:19:24 theanets.trainer:168 RmsProp 404 loss=0.161843 err=0.161843
I 2015-05-26 08:19:35 theanets.trainer:168 RmsProp 405 loss=0.168813 err=0.168813
I 2015-05-26 08:19:45 theanets.trainer:168 RmsProp 406 loss=0.182678 err=0.182678
I 2015-05-26 08:19:56 theanets.trainer:168 RmsProp 407 loss=0.156970 err=0.156970
I 2015-05-26 08:20:06 theanets.trainer:168 RmsProp 408 loss=0.159604 err=0.159604
I 2015-05-26 08:20:16 theanets.trainer:168 RmsProp 409 loss=0.175154 err=0.175154
I 2015-05-26 08:20:27 theanets.trainer:168 RmsProp 410 loss=0.163053 err=0.163053
I 2015-05-26 08:20:27 theanets.trainer:168 validation 41 loss=723.407715 err=723.407715 *
I 2015-05-26 08:20:38 theanets.trainer:168 RmsProp 411 loss=0.160178 err=0.160178
I 2015-05-26 08:20:48 theanets.trainer:168 RmsProp 412 loss=0.156582 err=0.156582
I 2015-05-26 08:20:59 theanets.trainer:168 RmsProp 413 loss=0.156014 err=0.156014
I 2015-05-26 08:21:09 theanets.trainer:168 RmsProp 414 loss=0.152932 err=0.152932
I 2015-05-26 08:21:19 theanets.trainer:168 RmsProp 415 loss=0.171509 err=0.171509
I 2015-05-26 08:21:30 theanets.trainer:168 RmsProp 416 loss=0.148676 err=0.148676
I 2015-05-26 08:21:40 theanets.trainer:168 RmsProp 417 loss=0.159738 err=0.159738
I 2015-05-26 08:21:50 theanets.trainer:168 RmsProp 418 loss=0.152093 err=0.152093
I 2015-05-26 08:22:01 theanets.trainer:168 RmsProp 419 loss=0.160854 err=0.160854
I 2015-05-26 08:22:11 theanets.trainer:168 RmsProp 420 loss=0.167049 err=0.167049
I 2015-05-26 08:22:12 theanets.trainer:168 validation 42 loss=724.655090 err=724.655090
I 2015-05-26 08:22:22 theanets.trainer:168 RmsProp 421 loss=0.153002 err=0.153002
I 2015-05-26 08:22:33 theanets.trainer:168 RmsProp 422 loss=0.155220 err=0.155220
I 2015-05-26 08:22:44 theanets.trainer:168 RmsProp 423 loss=0.156480 err=0.156480
I 2015-05-26 08:22:54 theanets.trainer:168 RmsProp 424 loss=0.143940 err=0.143940
I 2015-05-26 08:23:05 theanets.trainer:168 RmsProp 425 loss=0.155191 err=0.155191
I 2015-05-26 08:23:15 theanets.trainer:168 RmsProp 426 loss=0.171899 err=0.171899
I 2015-05-26 08:23:25 theanets.trainer:168 RmsProp 427 loss=0.151536 err=0.151536
I 2015-05-26 08:23:36 theanets.trainer:168 RmsProp 428 loss=0.154260 err=0.154260
I 2015-05-26 08:23:46 theanets.trainer:168 RmsProp 429 loss=0.149294 err=0.149294
I 2015-05-26 08:23:56 theanets.trainer:168 RmsProp 430 loss=0.169946 err=0.169946
I 2015-05-26 08:23:57 theanets.trainer:168 validation 43 loss=722.769043 err=722.769043 *
I 2015-05-26 08:24:07 theanets.trainer:168 RmsProp 431 loss=0.154479 err=0.154479
I 2015-05-26 08:24:17 theanets.trainer:168 RmsProp 432 loss=0.159014 err=0.159014
I 2015-05-26 08:24:28 theanets.trainer:168 RmsProp 433 loss=0.146342 err=0.146342
I 2015-05-26 08:24:38 theanets.trainer:168 RmsProp 434 loss=0.169376 err=0.169376
I 2015-05-26 08:24:49 theanets.trainer:168 RmsProp 435 loss=0.156627 err=0.156627
I 2015-05-26 08:25:00 theanets.trainer:168 RmsProp 436 loss=0.156547 err=0.156547
I 2015-05-26 08:25:10 theanets.trainer:168 RmsProp 437 loss=0.142280 err=0.142280
I 2015-05-26 08:25:21 theanets.trainer:168 RmsProp 438 loss=0.171375 err=0.171375
I 2015-05-26 08:25:31 theanets.trainer:168 RmsProp 439 loss=0.162390 err=0.162390
I 2015-05-26 08:25:42 theanets.trainer:168 RmsProp 440 loss=0.153588 err=0.153588
I 2015-05-26 08:25:43 theanets.trainer:168 validation 44 loss=722.358582 err=722.358582 *
I 2015-05-26 08:25:53 theanets.trainer:168 RmsProp 441 loss=0.149279 err=0.149279
I 2015-05-26 08:26:03 theanets.trainer:168 RmsProp 442 loss=0.159840 err=0.159840
I 2015-05-26 08:26:14 theanets.trainer:168 RmsProp 443 loss=0.144621 err=0.144621
I 2015-05-26 08:26:24 theanets.trainer:168 RmsProp 444 loss=0.144222 err=0.144222
I 2015-05-26 08:26:35 theanets.trainer:168 RmsProp 445 loss=0.146419 err=0.146419
I 2015-05-26 08:26:45 theanets.trainer:168 RmsProp 446 loss=0.152177 err=0.152177
I 2015-05-26 08:26:56 theanets.trainer:168 RmsProp 447 loss=0.152867 err=0.152867
I 2015-05-26 08:27:07 theanets.trainer:168 RmsProp 448 loss=0.160659 err=0.160659
I 2015-05-26 08:27:18 theanets.trainer:168 RmsProp 449 loss=0.159020 err=0.159020
I 2015-05-26 08:27:29 theanets.trainer:168 RmsProp 450 loss=0.149753 err=0.149753
I 2015-05-26 08:27:29 theanets.trainer:168 validation 45 loss=720.768494 err=720.768494 *
I 2015-05-26 08:27:40 theanets.trainer:168 RmsProp 451 loss=0.154273 err=0.154273
I 2015-05-26 08:27:51 theanets.trainer:168 RmsProp 452 loss=0.143347 err=0.143347
I 2015-05-26 08:28:01 theanets.trainer:168 RmsProp 453 loss=0.148290 err=0.148290
I 2015-05-26 08:28:12 theanets.trainer:168 RmsProp 454 loss=0.148265 err=0.148265
I 2015-05-26 08:28:22 theanets.trainer:168 RmsProp 455 loss=0.139757 err=0.139757
I 2015-05-26 08:28:32 theanets.trainer:168 RmsProp 456 loss=0.149811 err=0.149811
I 2015-05-26 08:28:42 theanets.trainer:168 RmsProp 457 loss=0.166775 err=0.166775
I 2015-05-26 08:28:53 theanets.trainer:168 RmsProp 458 loss=0.144204 err=0.144204
I 2015-05-26 08:29:04 theanets.trainer:168 RmsProp 459 loss=0.141735 err=0.141735
I 2015-05-26 08:29:14 theanets.trainer:168 RmsProp 460 loss=0.149239 err=0.149239
I 2015-05-26 08:29:15 theanets.trainer:168 validation 46 loss=721.068787 err=721.068787
I 2015-05-26 08:29:25 theanets.trainer:168 RmsProp 461 loss=0.141590 err=0.141590
I 2015-05-26 08:29:36 theanets.trainer:168 RmsProp 462 loss=0.147915 err=0.147915
I 2015-05-26 08:29:46 theanets.trainer:168 RmsProp 463 loss=0.146255 err=0.146255
I 2015-05-26 08:29:56 theanets.trainer:168 RmsProp 464 loss=0.139041 err=0.139041
I 2015-05-26 08:30:07 theanets.trainer:168 RmsProp 465 loss=0.149199 err=0.149199
I 2015-05-26 08:30:17 theanets.trainer:168 RmsProp 466 loss=0.134868 err=0.134868
I 2015-05-26 08:30:28 theanets.trainer:168 RmsProp 467 loss=0.154898 err=0.154898
I 2015-05-26 08:30:39 theanets.trainer:168 RmsProp 468 loss=0.143762 err=0.143762
I 2015-05-26 08:30:50 theanets.trainer:168 RmsProp 469 loss=0.137626 err=0.137626
I 2015-05-26 08:31:01 theanets.trainer:168 RmsProp 470 loss=0.160021 err=0.160021
I 2015-05-26 08:31:01 theanets.trainer:168 validation 47 loss=718.390747 err=718.390747 *
I 2015-05-26 08:31:12 theanets.trainer:168 RmsProp 471 loss=0.138065 err=0.138065
I 2015-05-26 08:31:23 theanets.trainer:168 RmsProp 472 loss=0.138138 err=0.138138
I 2015-05-26 08:31:33 theanets.trainer:168 RmsProp 473 loss=0.142271 err=0.142271
I 2015-05-26 08:31:43 theanets.trainer:168 RmsProp 474 loss=0.148721 err=0.148721
I 2015-05-26 08:31:53 theanets.trainer:168 RmsProp 475 loss=0.159079 err=0.159079
I 2015-05-26 08:32:03 theanets.trainer:168 RmsProp 476 loss=0.143773 err=0.143773
I 2015-05-26 08:32:14 theanets.trainer:168 RmsProp 477 loss=0.138004 err=0.138004
I 2015-05-26 08:32:24 theanets.trainer:168 RmsProp 478 loss=0.138170 err=0.138170
I 2015-05-26 08:32:34 theanets.trainer:168 RmsProp 479 loss=0.138798 err=0.138798
I 2015-05-26 08:32:44 theanets.trainer:168 RmsProp 480 loss=0.168052 err=0.168052
I 2015-05-26 08:32:44 theanets.trainer:168 validation 48 loss=718.204712 err=718.204712 *
I 2015-05-26 08:32:54 theanets.trainer:168 RmsProp 481 loss=0.141463 err=0.141463
I 2015-05-26 08:33:04 theanets.trainer:168 RmsProp 482 loss=0.136564 err=0.136564
I 2015-05-26 08:33:14 theanets.trainer:168 RmsProp 483 loss=0.138698 err=0.138698
I 2015-05-26 08:33:24 theanets.trainer:168 RmsProp 484 loss=0.131384 err=0.131384
I 2015-05-26 08:33:34 theanets.trainer:168 RmsProp 485 loss=0.150445 err=0.150445
I 2015-05-26 08:33:44 theanets.trainer:168 RmsProp 486 loss=0.133385 err=0.133385
I 2015-05-26 08:33:54 theanets.trainer:168 RmsProp 487 loss=0.138596 err=0.138596
I 2015-05-26 08:34:04 theanets.trainer:168 RmsProp 488 loss=0.142274 err=0.142274
I 2015-05-26 08:34:14 theanets.trainer:168 RmsProp 489 loss=0.129726 err=0.129726
I 2015-05-26 08:34:24 theanets.trainer:168 RmsProp 490 loss=0.153897 err=0.153897
I 2015-05-26 08:34:25 theanets.trainer:168 validation 49 loss=717.704590 err=717.704590 *
I 2015-05-26 08:34:35 theanets.trainer:168 RmsProp 491 loss=0.132350 err=0.132350
I 2015-05-26 08:34:45 theanets.trainer:168 RmsProp 492 loss=0.142409 err=0.142409
I 2015-05-26 08:34:55 theanets.trainer:168 RmsProp 493 loss=0.136084 err=0.136084
I 2015-05-26 08:35:06 theanets.trainer:168 RmsProp 494 loss=0.143183 err=0.143183
I 2015-05-26 08:35:16 theanets.trainer:168 RmsProp 495 loss=0.143509 err=0.143509
I 2015-05-26 08:35:26 theanets.trainer:168 RmsProp 496 loss=0.131686 err=0.131686
I 2015-05-26 08:35:37 theanets.trainer:168 RmsProp 497 loss=0.132015 err=0.132015
I 2015-05-26 08:35:47 theanets.trainer:168 RmsProp 498 loss=0.147631 err=0.147631
I 2015-05-26 08:35:56 theanets.trainer:168 RmsProp 499 loss=0.130054 err=0.130054
I 2015-05-26 08:36:06 theanets.trainer:168 RmsProp 500 loss=0.153901 err=0.153901
I 2015-05-26 08:36:07 theanets.trainer:168 validation 50 loss=716.891602 err=716.891602 *
I 2015-05-26 08:36:17 theanets.trainer:168 RmsProp 501 loss=0.135592 err=0.135592
I 2015-05-26 08:36:27 theanets.trainer:168 RmsProp 502 loss=0.132347 err=0.132347
I 2015-05-26 08:36:37 theanets.trainer:168 RmsProp 503 loss=0.145310 err=0.145310
I 2015-05-26 08:36:47 theanets.trainer:168 RmsProp 504 loss=0.135231 err=0.135231
I 2015-05-26 08:36:57 theanets.trainer:168 RmsProp 505 loss=0.119232 err=0.119232
I 2015-05-26 08:37:07 theanets.trainer:168 RmsProp 506 loss=0.141758 err=0.141758
I 2015-05-26 08:37:17 theanets.trainer:168 RmsProp 507 loss=0.128794 err=0.128794
I 2015-05-26 08:37:26 theanets.trainer:168 RmsProp 508 loss=0.135619 err=0.135619
I 2015-05-26 08:37:36 theanets.trainer:168 RmsProp 509 loss=0.134877 err=0.134877
I 2015-05-26 08:37:46 theanets.trainer:168 RmsProp 510 loss=0.129709 err=0.129709
I 2015-05-26 08:37:47 theanets.trainer:168 validation 51 loss=715.636658 err=715.636658 *
I 2015-05-26 08:37:56 theanets.trainer:168 RmsProp 511 loss=0.134164 err=0.134164
I 2015-05-26 08:38:06 theanets.trainer:168 RmsProp 512 loss=0.140109 err=0.140109
I 2015-05-26 08:38:16 theanets.trainer:168 RmsProp 513 loss=0.130702 err=0.130702
I 2015-05-26 08:38:26 theanets.trainer:168 RmsProp 514 loss=0.135432 err=0.135432
I 2015-05-26 08:38:36 theanets.trainer:168 RmsProp 515 loss=0.144589 err=0.144589
I 2015-05-26 08:38:46 theanets.trainer:168 RmsProp 516 loss=0.120534 err=0.120534
I 2015-05-26 08:38:56 theanets.trainer:168 RmsProp 517 loss=0.139546 err=0.139546
I 2015-05-26 08:39:06 theanets.trainer:168 RmsProp 518 loss=0.126133 err=0.126133
I 2015-05-26 08:39:16 theanets.trainer:168 RmsProp 519 loss=0.135968 err=0.135968
I 2015-05-26 08:39:26 theanets.trainer:168 RmsProp 520 loss=0.133097 err=0.133097
I 2015-05-26 08:39:26 theanets.trainer:168 validation 52 loss=713.185730 err=713.185730 *
I 2015-05-26 08:39:36 theanets.trainer:168 RmsProp 521 loss=0.134362 err=0.134362
I 2015-05-26 08:39:46 theanets.trainer:168 RmsProp 522 loss=0.119733 err=0.119733
I 2015-05-26 08:39:56 theanets.trainer:168 RmsProp 523 loss=0.152735 err=0.152735
I 2015-05-26 08:40:06 theanets.trainer:168 RmsProp 524 loss=0.131509 err=0.131509
I 2015-05-26 08:40:16 theanets.trainer:168 RmsProp 525 loss=0.128136 err=0.128136
I 2015-05-26 08:40:26 theanets.trainer:168 RmsProp 526 loss=0.130738 err=0.130738
I 2015-05-26 08:40:36 theanets.trainer:168 RmsProp 527 loss=0.126776 err=0.126776
I 2015-05-26 08:40:45 theanets.trainer:168 RmsProp 528 loss=0.149005 err=0.149005
I 2015-05-26 08:40:55 theanets.trainer:168 RmsProp 529 loss=0.131151 err=0.131151
I 2015-05-26 08:41:05 theanets.trainer:168 RmsProp 530 loss=0.124722 err=0.124722
I 2015-05-26 08:41:05 theanets.trainer:168 validation 53 loss=713.242615 err=713.242615
I 2015-05-26 08:41:15 theanets.trainer:168 RmsProp 531 loss=0.127542 err=0.127542
I 2015-05-26 08:41:25 theanets.trainer:168 RmsProp 532 loss=0.137210 err=0.137210
I 2015-05-26 08:41:35 theanets.trainer:168 RmsProp 533 loss=0.126315 err=0.126315
I 2015-05-26 08:41:45 theanets.trainer:168 RmsProp 534 loss=0.129774 err=0.129774
I 2015-05-26 08:41:55 theanets.trainer:168 RmsProp 535 loss=0.136453 err=0.136453
I 2015-05-26 08:42:05 theanets.trainer:168 RmsProp 536 loss=0.124968 err=0.124968
I 2015-05-26 08:42:15 theanets.trainer:168 RmsProp 537 loss=0.116965 err=0.116965
I 2015-05-26 08:42:26 theanets.trainer:168 RmsProp 538 loss=0.145307 err=0.145307
I 2015-05-26 08:42:36 theanets.trainer:168 RmsProp 539 loss=0.124113 err=0.124113
I 2015-05-26 08:42:45 theanets.trainer:168 RmsProp 540 loss=0.129994 err=0.129994
I 2015-05-26 08:42:46 theanets.trainer:168 validation 54 loss=714.408020 err=714.408020
I 2015-05-26 08:42:56 theanets.trainer:168 RmsProp 541 loss=0.116059 err=0.116059
I 2015-05-26 08:43:06 theanets.trainer:168 RmsProp 542 loss=0.133853 err=0.133853
I 2015-05-26 08:43:16 theanets.trainer:168 RmsProp 543 loss=0.127425 err=0.127425
I 2015-05-26 08:43:26 theanets.trainer:168 RmsProp 544 loss=0.129070 err=0.129070
I 2015-05-26 08:43:36 theanets.trainer:168 RmsProp 545 loss=0.118996 err=0.118996
I 2015-05-26 08:43:46 theanets.trainer:168 RmsProp 546 loss=0.127452 err=0.127452
I 2015-05-26 08:43:55 theanets.trainer:168 RmsProp 547 loss=0.128895 err=0.128895
I 2015-05-26 08:44:05 theanets.trainer:168 RmsProp 548 loss=0.127956 err=0.127956
I 2015-05-26 08:44:15 theanets.trainer:168 RmsProp 549 loss=0.117371 err=0.117371
I 2015-05-26 08:44:24 theanets.trainer:168 RmsProp 550 loss=0.129664 err=0.129664
I 2015-05-26 08:44:25 theanets.trainer:168 validation 55 loss=712.826843 err=712.826843 *
I 2015-05-26 08:44:35 theanets.trainer:168 RmsProp 551 loss=0.128140 err=0.128140
I 2015-05-26 08:44:45 theanets.trainer:168 RmsProp 552 loss=0.122905 err=0.122905
I 2015-05-26 08:44:54 theanets.trainer:168 RmsProp 553 loss=0.122427 err=0.122427
I 2015-05-26 08:45:04 theanets.trainer:168 RmsProp 554 loss=0.123238 err=0.123238
I 2015-05-26 08:45:14 theanets.trainer:168 RmsProp 555 loss=0.125376 err=0.125376
I 2015-05-26 08:45:24 theanets.trainer:168 RmsProp 556 loss=0.127486 err=0.127486
I 2015-05-26 08:45:34 theanets.trainer:168 RmsProp 557 loss=0.119201 err=0.119201
I 2015-05-26 08:45:44 theanets.trainer:168 RmsProp 558 loss=0.121708 err=0.121708
I 2015-05-26 08:45:54 theanets.trainer:168 RmsProp 559 loss=0.132558 err=0.132558
I 2015-05-26 08:46:03 theanets.trainer:168 RmsProp 560 loss=0.126534 err=0.126534
I 2015-05-26 08:46:03 theanets.trainer:168 validation 56 loss=710.740723 err=710.740723 *
I 2015-05-26 08:46:12 theanets.trainer:168 RmsProp 561 loss=0.129365 err=0.129365
I 2015-05-26 08:46:21 theanets.trainer:168 RmsProp 562 loss=0.119699 err=0.119699
I 2015-05-26 08:46:30 theanets.trainer:168 RmsProp 563 loss=0.132474 err=0.132474
I 2015-05-26 08:46:39 theanets.trainer:168 RmsProp 564 loss=0.118216 err=0.118216
I 2015-05-26 08:46:48 theanets.trainer:168 RmsProp 565 loss=0.120415 err=0.120415
I 2015-05-26 08:46:56 theanets.trainer:168 RmsProp 566 loss=0.126112 err=0.126112
I 2015-05-26 08:47:05 theanets.trainer:168 RmsProp 567 loss=0.119709 err=0.119709
I 2015-05-26 08:47:14 theanets.trainer:168 RmsProp 568 loss=0.119511 err=0.119511
I 2015-05-26 08:47:22 theanets.trainer:168 RmsProp 569 loss=0.119829 err=0.119829
I 2015-05-26 08:47:31 theanets.trainer:168 RmsProp 570 loss=0.120291 err=0.120291
I 2015-05-26 08:47:31 theanets.trainer:168 validation 57 loss=710.741882 err=710.741882
I 2015-05-26 08:47:40 theanets.trainer:168 RmsProp 571 loss=0.113461 err=0.113461
I 2015-05-26 08:47:49 theanets.trainer:168 RmsProp 572 loss=0.131325 err=0.131325
I 2015-05-26 08:47:57 theanets.trainer:168 RmsProp 573 loss=0.117925 err=0.117925
I 2015-05-26 08:48:06 theanets.trainer:168 RmsProp 574 loss=0.122453 err=0.122453
I 2015-05-26 08:48:15 theanets.trainer:168 RmsProp 575 loss=0.123575 err=0.123575
I 2015-05-26 08:48:24 theanets.trainer:168 RmsProp 576 loss=0.111147 err=0.111147
I 2015-05-26 08:48:33 theanets.trainer:168 RmsProp 577 loss=0.136181 err=0.136181
I 2015-05-26 08:48:41 theanets.trainer:168 RmsProp 578 loss=0.114881 err=0.114881
I 2015-05-26 08:48:51 theanets.trainer:168 RmsProp 579 loss=0.117175 err=0.117175
I 2015-05-26 08:49:00 theanets.trainer:168 RmsProp 580 loss=0.126473 err=0.126473
I 2015-05-26 08:49:00 theanets.trainer:168 validation 58 loss=711.789246 err=711.789246
I 2015-05-26 08:49:09 theanets.trainer:168 RmsProp 581 loss=0.127036 err=0.127036
I 2015-05-26 08:49:17 theanets.trainer:168 RmsProp 582 loss=0.111298 err=0.111298
I 2015-05-26 08:49:26 theanets.trainer:168 RmsProp 583 loss=0.108092 err=0.108092
I 2015-05-26 08:49:35 theanets.trainer:168 RmsProp 584 loss=0.144477 err=0.144477
I 2015-05-26 08:49:43 theanets.trainer:168 RmsProp 585 loss=0.130833 err=0.130833
I 2015-05-26 08:49:53 theanets.trainer:168 RmsProp 586 loss=0.113824 err=0.113824
I 2015-05-26 08:50:01 theanets.trainer:168 RmsProp 587 loss=0.113564 err=0.113564
I 2015-05-26 08:50:10 theanets.trainer:168 RmsProp 588 loss=0.142412 err=0.142412
I 2015-05-26 08:50:18 theanets.trainer:168 RmsProp 589 loss=0.117890 err=0.117890
I 2015-05-26 08:50:27 theanets.trainer:168 RmsProp 590 loss=0.112840 err=0.112840
I 2015-05-26 08:50:27 theanets.trainer:168 validation 59 loss=708.387207 err=708.387207 *
I 2015-05-26 08:50:36 theanets.trainer:168 RmsProp 591 loss=0.140315 err=0.140315
I 2015-05-26 08:50:44 theanets.trainer:168 RmsProp 592 loss=0.120228 err=0.120228
I 2015-05-26 08:50:52 theanets.trainer:168 RmsProp 593 loss=0.110833 err=0.110833
I 2015-05-26 08:51:00 theanets.trainer:168 RmsProp 594 loss=0.133867 err=0.133867
I 2015-05-26 08:51:08 theanets.trainer:168 RmsProp 595 loss=0.121779 err=0.121779
I 2015-05-26 08:51:17 theanets.trainer:168 RmsProp 596 loss=0.102523 err=0.102523
I 2015-05-26 08:51:26 theanets.trainer:168 RmsProp 597 loss=0.139938 err=0.139938
I 2015-05-26 08:51:34 theanets.trainer:168 RmsProp 598 loss=0.111402 err=0.111402
I 2015-05-26 08:51:42 theanets.trainer:168 RmsProp 599 loss=0.105664 err=0.105664
I 2015-05-26 08:51:50 theanets.trainer:168 RmsProp 600 loss=0.135931 err=0.135931
I 2015-05-26 08:51:51 theanets.trainer:168 validation 60 loss=709.885986 err=709.885986
I 2015-05-26 08:51:58 theanets.trainer:168 RmsProp 601 loss=0.114920 err=0.114920
I 2015-05-26 08:52:07 theanets.trainer:168 RmsProp 602 loss=0.119901 err=0.119901
I 2015-05-26 08:52:15 theanets.trainer:168 RmsProp 603 loss=0.116506 err=0.116506
I 2015-05-26 08:52:22 theanets.trainer:168 RmsProp 604 loss=0.120058 err=0.120058
I 2015-05-26 08:52:30 theanets.trainer:168 RmsProp 605 loss=0.118226 err=0.118226
I 2015-05-26 08:52:38 theanets.trainer:168 RmsProp 606 loss=0.112564 err=0.112564
I 2015-05-26 08:52:46 theanets.trainer:168 RmsProp 607 loss=0.116772 err=0.116772
I 2015-05-26 08:52:54 theanets.trainer:168 RmsProp 608 loss=0.114764 err=0.114764
I 2015-05-26 08:53:02 theanets.trainer:168 RmsProp 609 loss=0.113886 err=0.113886
I 2015-05-26 08:53:10 theanets.trainer:168 RmsProp 610 loss=0.111203 err=0.111203
I 2015-05-26 08:53:11 theanets.trainer:168 validation 61 loss=710.440613 err=710.440613
I 2015-05-26 08:53:19 theanets.trainer:168 RmsProp 611 loss=0.115970 err=0.115970
I 2015-05-26 08:53:26 theanets.trainer:168 RmsProp 612 loss=0.110991 err=0.110991
I 2015-05-26 08:53:34 theanets.trainer:168 RmsProp 613 loss=0.111482 err=0.111482
I 2015-05-26 08:53:42 theanets.trainer:168 RmsProp 614 loss=0.117361 err=0.117361
I 2015-05-26 08:53:51 theanets.trainer:168 RmsProp 615 loss=0.120724 err=0.120724
I 2015-05-26 08:53:59 theanets.trainer:168 RmsProp 616 loss=0.108273 err=0.108273
I 2015-05-26 08:54:06 theanets.trainer:168 RmsProp 617 loss=0.116860 err=0.116860
I 2015-05-26 08:54:14 theanets.trainer:168 RmsProp 618 loss=0.108527 err=0.108527
I 2015-05-26 08:54:22 theanets.trainer:168 RmsProp 619 loss=0.129391 err=0.129391
I 2015-05-26 08:54:29 theanets.trainer:168 RmsProp 620 loss=0.108939 err=0.108939
I 2015-05-26 08:54:30 theanets.trainer:168 validation 62 loss=709.608582 err=709.608582
I 2015-05-26 08:54:37 theanets.trainer:168 RmsProp 621 loss=0.123211 err=0.123211
I 2015-05-26 08:54:45 theanets.trainer:168 RmsProp 622 loss=0.108394 err=0.108394
I 2015-05-26 08:54:52 theanets.trainer:168 RmsProp 623 loss=0.112265 err=0.112265
I 2015-05-26 08:55:00 theanets.trainer:168 RmsProp 624 loss=0.100188 err=0.100188
I 2015-05-26 08:55:08 theanets.trainer:168 RmsProp 625 loss=0.162558 err=0.162558
I 2015-05-26 08:55:15 theanets.trainer:168 RmsProp 626 loss=0.129622 err=0.129622
I 2015-05-26 08:55:22 theanets.trainer:168 RmsProp 627 loss=0.103822 err=0.103822
I 2015-05-26 08:55:30 theanets.trainer:168 RmsProp 628 loss=0.109553 err=0.109553
I 2015-05-26 08:55:38 theanets.trainer:168 RmsProp 629 loss=0.112346 err=0.112346
I 2015-05-26 08:55:46 theanets.trainer:168 RmsProp 630 loss=0.111380 err=0.111380
I 2015-05-26 08:55:46 theanets.trainer:168 validation 63 loss=708.977966 err=708.977966
I 2015-05-26 08:55:53 theanets.trainer:168 RmsProp 631 loss=0.113842 err=0.113842
I 2015-05-26 08:56:01 theanets.trainer:168 RmsProp 632 loss=0.121108 err=0.121108
I 2015-05-26 08:56:08 theanets.trainer:168 RmsProp 633 loss=0.105376 err=0.105376
I 2015-05-26 08:56:15 theanets.trainer:168 RmsProp 634 loss=0.116052 err=0.116052
I 2015-05-26 08:56:23 theanets.trainer:168 RmsProp 635 loss=0.105940 err=0.105940
I 2015-05-26 08:56:31 theanets.trainer:168 RmsProp 636 loss=0.109985 err=0.109985
I 2015-05-26 08:56:39 theanets.trainer:168 RmsProp 637 loss=0.109676 err=0.109676
I 2015-05-26 08:56:47 theanets.trainer:168 RmsProp 638 loss=0.110026 err=0.110026
I 2015-05-26 08:56:55 theanets.trainer:168 RmsProp 639 loss=0.113588 err=0.113588
I 2015-05-26 08:57:02 theanets.trainer:168 RmsProp 640 loss=0.101915 err=0.101915
I 2015-05-26 08:57:03 theanets.trainer:168 validation 64 loss=707.572815 err=707.572815 *
I 2015-05-26 08:57:10 theanets.trainer:168 RmsProp 641 loss=0.115571 err=0.115571
I 2015-05-26 08:57:18 theanets.trainer:168 RmsProp 642 loss=0.104172 err=0.104172
I 2015-05-26 08:57:26 theanets.trainer:168 RmsProp 643 loss=0.112529 err=0.112529
I 2015-05-26 08:57:34 theanets.trainer:168 RmsProp 644 loss=0.107725 err=0.107725
I 2015-05-26 08:57:41 theanets.trainer:168 RmsProp 645 loss=0.116673 err=0.116673
I 2015-05-26 08:57:50 theanets.trainer:168 RmsProp 646 loss=0.112336 err=0.112336
I 2015-05-26 08:57:57 theanets.trainer:168 RmsProp 647 loss=0.104665 err=0.104665
I 2015-05-26 08:58:05 theanets.trainer:168 RmsProp 648 loss=0.115525 err=0.115525
I 2015-05-26 08:58:12 theanets.trainer:168 RmsProp 649 loss=0.127007 err=0.127007
I 2015-05-26 08:58:20 theanets.trainer:168 RmsProp 650 loss=0.110085 err=0.110085
I 2015-05-26 08:58:21 theanets.trainer:168 validation 65 loss=706.535217 err=706.535217 *
I 2015-05-26 08:58:28 theanets.trainer:168 RmsProp 651 loss=0.110132 err=0.110132
I 2015-05-26 08:58:37 theanets.trainer:168 RmsProp 652 loss=0.110149 err=0.110149
I 2015-05-26 08:58:45 theanets.trainer:168 RmsProp 653 loss=0.103073 err=0.103073
I 2015-05-26 08:58:52 theanets.trainer:168 RmsProp 654 loss=0.098796 err=0.098796
I 2015-05-26 08:59:00 theanets.trainer:168 RmsProp 655 loss=0.123079 err=0.123079
I 2015-05-26 08:59:07 theanets.trainer:168 RmsProp 656 loss=0.106147 err=0.106147
I 2015-05-26 08:59:14 theanets.trainer:168 RmsProp 657 loss=0.115394 err=0.115394
I 2015-05-26 08:59:23 theanets.trainer:168 RmsProp 658 loss=0.103319 err=0.103319
I 2015-05-26 08:59:30 theanets.trainer:168 RmsProp 659 loss=0.121122 err=0.121122
I 2015-05-26 08:59:37 theanets.trainer:168 RmsProp 660 loss=0.103864 err=0.103864
I 2015-05-26 08:59:38 theanets.trainer:168 validation 66 loss=705.163269 err=705.163269 *
I 2015-05-26 08:59:45 theanets.trainer:168 RmsProp 661 loss=0.115066 err=0.115066
I 2015-05-26 08:59:53 theanets.trainer:168 RmsProp 662 loss=0.102059 err=0.102059
I 2015-05-26 09:00:00 theanets.trainer:168 RmsProp 663 loss=0.102478 err=0.102478
I 2015-05-26 09:00:08 theanets.trainer:168 RmsProp 664 loss=0.119778 err=0.119778
I 2015-05-26 09:00:17 theanets.trainer:168 RmsProp 665 loss=0.104055 err=0.104055
I 2015-05-26 09:00:24 theanets.trainer:168 RmsProp 666 loss=0.108960 err=0.108960
I 2015-05-26 09:00:32 theanets.trainer:168 RmsProp 667 loss=0.103693 err=0.103693
I 2015-05-26 09:00:40 theanets.trainer:168 RmsProp 668 loss=0.109058 err=0.109058
I 2015-05-26 09:00:48 theanets.trainer:168 RmsProp 669 loss=0.098051 err=0.098051
I 2015-05-26 09:00:56 theanets.trainer:168 RmsProp 670 loss=0.120573 err=0.120573
I 2015-05-26 09:00:56 theanets.trainer:168 validation 67 loss=704.594482 err=704.594482 *
I 2015-05-26 09:01:04 theanets.trainer:168 RmsProp 671 loss=0.120793 err=0.120793
I 2015-05-26 09:01:12 theanets.trainer:168 RmsProp 672 loss=0.105217 err=0.105217
I 2015-05-26 09:01:20 theanets.trainer:168 RmsProp 673 loss=0.105602 err=0.105602
I 2015-05-26 09:01:28 theanets.trainer:168 RmsProp 674 loss=0.108589 err=0.108589
I 2015-05-26 09:01:36 theanets.trainer:168 RmsProp 675 loss=0.098871 err=0.098871
I 2015-05-26 09:01:43 theanets.trainer:168 RmsProp 676 loss=0.116843 err=0.116843
I 2015-05-26 09:01:51 theanets.trainer:168 RmsProp 677 loss=0.101859 err=0.101859
I 2015-05-26 09:01:59 theanets.trainer:168 RmsProp 678 loss=0.099194 err=0.099194
I 2015-05-26 09:02:07 theanets.trainer:168 RmsProp 679 loss=0.117604 err=0.117604
I 2015-05-26 09:02:14 theanets.trainer:168 RmsProp 680 loss=0.098944 err=0.098944
I 2015-05-26 09:02:14 theanets.trainer:168 validation 68 loss=704.168640 err=704.168640 *
I 2015-05-26 09:02:21 theanets.trainer:168 RmsProp 681 loss=0.121421 err=0.121421
I 2015-05-26 09:02:29 theanets.trainer:168 RmsProp 682 loss=0.103087 err=0.103087
I 2015-05-26 09:02:36 theanets.trainer:168 RmsProp 683 loss=0.096556 err=0.096556
I 2015-05-26 09:02:45 theanets.trainer:168 RmsProp 684 loss=0.110162 err=0.110162
I 2015-05-26 09:02:52 theanets.trainer:168 RmsProp 685 loss=0.099218 err=0.099218
I 2015-05-26 09:02:59 theanets.trainer:168 RmsProp 686 loss=0.103204 err=0.103204
I 2015-05-26 09:03:08 theanets.trainer:168 RmsProp 687 loss=0.108905 err=0.108905
I 2015-05-26 09:03:15 theanets.trainer:168 RmsProp 688 loss=0.098121 err=0.098121
I 2015-05-26 09:03:22 theanets.trainer:168 RmsProp 689 loss=0.105573 err=0.105573
I 2015-05-26 09:03:31 theanets.trainer:168 RmsProp 690 loss=0.105120 err=0.105120
I 2015-05-26 09:03:31 theanets.trainer:168 validation 69 loss=704.749329 err=704.749329
I 2015-05-26 09:03:38 theanets.trainer:168 RmsProp 691 loss=0.103566 err=0.103566
I 2015-05-26 09:03:46 theanets.trainer:168 RmsProp 692 loss=0.099137 err=0.099137
I 2015-05-26 09:03:54 theanets.trainer:168 RmsProp 693 loss=0.103911 err=0.103911
I 2015-05-26 09:04:01 theanets.trainer:168 RmsProp 694 loss=0.103310 err=0.103310
I 2015-05-26 09:04:09 theanets.trainer:168 RmsProp 695 loss=0.102553 err=0.102553
I 2015-05-26 09:04:17 theanets.trainer:168 RmsProp 696 loss=0.104526 err=0.104526
I 2015-05-26 09:04:24 theanets.trainer:168 RmsProp 697 loss=0.102597 err=0.102597
I 2015-05-26 09:04:32 theanets.trainer:168 RmsProp 698 loss=0.107290 err=0.107290
I 2015-05-26 09:04:40 theanets.trainer:168 RmsProp 699 loss=0.112498 err=0.112498
I 2015-05-26 09:04:47 theanets.trainer:168 RmsProp 700 loss=0.113168 err=0.113168
I 2015-05-26 09:04:48 theanets.trainer:168 validation 70 loss=704.404724 err=704.404724
I 2015-05-26 09:04:55 theanets.trainer:168 RmsProp 701 loss=0.102475 err=0.102475
I 2015-05-26 09:05:03 theanets.trainer:168 RmsProp 702 loss=0.097638 err=0.097638
I 2015-05-26 09:05:11 theanets.trainer:168 RmsProp 703 loss=0.090411 err=0.090411
I 2015-05-26 09:05:18 theanets.trainer:168 RmsProp 704 loss=0.118360 err=0.118360
I 2015-05-26 09:05:26 theanets.trainer:168 RmsProp 705 loss=0.093442 err=0.093442
I 2015-05-26 09:05:34 theanets.trainer:168 RmsProp 706 loss=0.109167 err=0.109167
I 2015-05-26 09:05:41 theanets.trainer:168 RmsProp 707 loss=0.099817 err=0.099817
I 2015-05-26 09:05:49 theanets.trainer:168 RmsProp 708 loss=0.100163 err=0.100163
I 2015-05-26 09:05:58 theanets.trainer:168 RmsProp 709 loss=0.113392 err=0.113392
I 2015-05-26 09:06:06 theanets.trainer:168 RmsProp 710 loss=0.096749 err=0.096749
I 2015-05-26 09:06:06 theanets.trainer:168 validation 71 loss=702.681152 err=702.681152 *
I 2015-05-26 09:06:14 theanets.trainer:168 RmsProp 711 loss=0.110611 err=0.110611
I 2015-05-26 09:06:22 theanets.trainer:168 RmsProp 712 loss=0.111785 err=0.111785
I 2015-05-26 09:06:30 theanets.trainer:168 RmsProp 713 loss=0.092523 err=0.092523
I 2015-05-26 09:06:39 theanets.trainer:168 RmsProp 714 loss=0.109347 err=0.109347
I 2015-05-26 09:06:46 theanets.trainer:168 RmsProp 715 loss=0.116392 err=0.116392
I 2015-05-26 09:06:53 theanets.trainer:168 RmsProp 716 loss=0.100237 err=0.100237
I 2015-05-26 09:07:02 theanets.trainer:168 RmsProp 717 loss=0.093054 err=0.093054
I 2015-05-26 09:07:10 theanets.trainer:168 RmsProp 718 loss=0.096227 err=0.096227
I 2015-05-26 09:07:17 theanets.trainer:168 RmsProp 719 loss=0.119242 err=0.119242
I 2015-05-26 09:07:24 theanets.trainer:168 RmsProp 720 loss=0.098844 err=0.098844
I 2015-05-26 09:07:25 theanets.trainer:168 validation 72 loss=701.863281 err=701.863281 *
I 2015-05-26 09:07:33 theanets.trainer:168 RmsProp 721 loss=0.090887 err=0.090887
I 2015-05-26 09:07:41 theanets.trainer:168 RmsProp 722 loss=0.121387 err=0.121387
I 2015-05-26 09:07:49 theanets.trainer:168 RmsProp 723 loss=0.098083 err=0.098083
I 2015-05-26 09:07:56 theanets.trainer:168 RmsProp 724 loss=0.099269 err=0.099269
I 2015-05-26 09:08:04 theanets.trainer:168 RmsProp 725 loss=0.096892 err=0.096892
I 2015-05-26 09:08:11 theanets.trainer:168 RmsProp 726 loss=0.097889 err=0.097889
I 2015-05-26 09:08:19 theanets.trainer:168 RmsProp 727 loss=0.106355 err=0.106355
I 2015-05-26 09:08:27 theanets.trainer:168 RmsProp 728 loss=0.100020 err=0.100020
I 2015-05-26 09:08:34 theanets.trainer:168 RmsProp 729 loss=0.094241 err=0.094241
I 2015-05-26 09:08:41 theanets.trainer:168 RmsProp 730 loss=0.101917 err=0.101917
I 2015-05-26 09:08:42 theanets.trainer:168 validation 73 loss=700.765808 err=700.765808 *
I 2015-05-26 09:08:49 theanets.trainer:168 RmsProp 731 loss=0.099143 err=0.099143
I 2015-05-26 09:08:57 theanets.trainer:168 RmsProp 732 loss=0.092996 err=0.092996
I 2015-05-26 09:09:05 theanets.trainer:168 RmsProp 733 loss=0.099848 err=0.099848
I 2015-05-26 09:09:12 theanets.trainer:168 RmsProp 734 loss=0.103877 err=0.103877
I 2015-05-26 09:09:20 theanets.trainer:168 RmsProp 735 loss=0.104849 err=0.104849
I 2015-05-26 09:09:29 theanets.trainer:168 RmsProp 736 loss=0.093025 err=0.093025
I 2015-05-26 09:09:36 theanets.trainer:168 RmsProp 737 loss=0.095180 err=0.095180
I 2015-05-26 09:09:43 theanets.trainer:168 RmsProp 738 loss=0.107619 err=0.107619
I 2015-05-26 09:09:51 theanets.trainer:168 RmsProp 739 loss=0.096035 err=0.096035
I 2015-05-26 09:09:59 theanets.trainer:168 RmsProp 740 loss=0.085179 err=0.085179
I 2015-05-26 09:10:00 theanets.trainer:168 validation 74 loss=702.664062 err=702.664062
I 2015-05-26 09:10:08 theanets.trainer:168 RmsProp 741 loss=0.126355 err=0.126355
I 2015-05-26 09:10:16 theanets.trainer:168 RmsProp 742 loss=0.094699 err=0.094699
I 2015-05-26 09:10:24 theanets.trainer:168 RmsProp 743 loss=0.093205 err=0.093205
I 2015-05-26 09:10:32 theanets.trainer:168 RmsProp 744 loss=0.101994 err=0.101994
I 2015-05-26 09:10:40 theanets.trainer:168 RmsProp 745 loss=0.092704 err=0.092704
I 2015-05-26 09:10:47 theanets.trainer:168 RmsProp 746 loss=0.089931 err=0.089931
I 2015-05-26 09:10:55 theanets.trainer:168 RmsProp 747 loss=0.110094 err=0.110094
I 2015-05-26 09:11:03 theanets.trainer:168 RmsProp 748 loss=0.095784 err=0.095784
I 2015-05-26 09:11:10 theanets.trainer:168 RmsProp 749 loss=0.092799 err=0.092799
I 2015-05-26 09:11:17 theanets.trainer:168 RmsProp 750 loss=0.099073 err=0.099073
I 2015-05-26 09:11:17 theanets.trainer:168 validation 75 loss=700.607605 err=700.607605 *
I 2015-05-26 09:11:24 theanets.trainer:168 RmsProp 751 loss=0.094454 err=0.094454
I 2015-05-26 09:11:31 theanets.trainer:168 RmsProp 752 loss=0.090907 err=0.090907
I 2015-05-26 09:11:38 theanets.trainer:168 RmsProp 753 loss=0.114744 err=0.114744
I 2015-05-26 09:11:45 theanets.trainer:168 RmsProp 754 loss=0.107482 err=0.107482
I 2015-05-26 09:11:53 theanets.trainer:168 RmsProp 755 loss=0.090596 err=0.090596
I 2015-05-26 09:12:00 theanets.trainer:168 RmsProp 756 loss=0.096865 err=0.096865
I 2015-05-26 09:12:08 theanets.trainer:168 RmsProp 757 loss=0.099725 err=0.099725
I 2015-05-26 09:12:15 theanets.trainer:168 RmsProp 758 loss=0.090691 err=0.090691
I 2015-05-26 09:12:22 theanets.trainer:168 RmsProp 759 loss=0.101181 err=0.101181
I 2015-05-26 09:12:31 theanets.trainer:168 RmsProp 760 loss=0.093367 err=0.093367
I 2015-05-26 09:12:31 theanets.trainer:168 validation 76 loss=701.842896 err=701.842896
I 2015-05-26 09:12:38 theanets.trainer:168 RmsProp 761 loss=0.115056 err=0.115056
I 2015-05-26 09:12:46 theanets.trainer:168 RmsProp 762 loss=0.092142 err=0.092142
I 2015-05-26 09:12:53 theanets.trainer:168 RmsProp 763 loss=0.096983 err=0.096983
I 2015-05-26 09:13:00 theanets.trainer:168 RmsProp 764 loss=0.102104 err=0.102104
I 2015-05-26 09:13:07 theanets.trainer:168 RmsProp 765 loss=0.089711 err=0.089711
I 2015-05-26 09:13:14 theanets.trainer:168 RmsProp 766 loss=0.092988 err=0.092988
I 2015-05-26 09:13:21 theanets.trainer:168 RmsProp 767 loss=0.095424 err=0.095424
I 2015-05-26 09:13:28 theanets.trainer:168 RmsProp 768 loss=0.099433 err=0.099433
I 2015-05-26 09:13:35 theanets.trainer:168 RmsProp 769 loss=0.098453 err=0.098453
I 2015-05-26 09:13:42 theanets.trainer:168 RmsProp 770 loss=0.089617 err=0.089617
I 2015-05-26 09:13:43 theanets.trainer:168 validation 77 loss=698.950684 err=698.950684 *
I 2015-05-26 09:13:50 theanets.trainer:168 RmsProp 771 loss=0.097845 err=0.097845
I 2015-05-26 09:13:57 theanets.trainer:168 RmsProp 772 loss=0.088068 err=0.088068
I 2015-05-26 09:14:03 theanets.trainer:168 RmsProp 773 loss=0.102302 err=0.102302
I 2015-05-26 09:14:10 theanets.trainer:168 RmsProp 774 loss=0.095992 err=0.095992
I 2015-05-26 09:14:17 theanets.trainer:168 RmsProp 775 loss=0.095525 err=0.095525
I 2015-05-26 09:14:25 theanets.trainer:168 RmsProp 776 loss=0.088789 err=0.088789
I 2015-05-26 09:14:33 theanets.trainer:168 RmsProp 777 loss=0.092340 err=0.092340
I 2015-05-26 09:14:41 theanets.trainer:168 RmsProp 778 loss=0.101872 err=0.101872
I 2015-05-26 09:14:48 theanets.trainer:168 RmsProp 779 loss=0.084244 err=0.084244
I 2015-05-26 09:14:56 theanets.trainer:168 RmsProp 780 loss=0.111253 err=0.111253
I 2015-05-26 09:14:56 theanets.trainer:168 validation 78 loss=697.678650 err=697.678650 *
I 2015-05-26 09:15:04 theanets.trainer:168 RmsProp 781 loss=0.091550 err=0.091550
I 2015-05-26 09:15:12 theanets.trainer:168 RmsProp 782 loss=0.094775 err=0.094775
I 2015-05-26 09:15:19 theanets.trainer:168 RmsProp 783 loss=0.085996 err=0.085996
I 2015-05-26 09:15:27 theanets.trainer:168 RmsProp 784 loss=0.093482 err=0.093482
I 2015-05-26 09:15:34 theanets.trainer:168 RmsProp 785 loss=0.111417 err=0.111417
I 2015-05-26 09:15:41 theanets.trainer:168 RmsProp 786 loss=0.093556 err=0.093556
I 2015-05-26 09:15:48 theanets.trainer:168 RmsProp 787 loss=0.098081 err=0.098081
I 2015-05-26 09:15:55 theanets.trainer:168 RmsProp 788 loss=0.095010 err=0.095010
I 2015-05-26 09:16:02 theanets.trainer:168 RmsProp 789 loss=0.085727 err=0.085727
I 2015-05-26 09:16:09 theanets.trainer:168 RmsProp 790 loss=0.096128 err=0.096128
I 2015-05-26 09:16:09 theanets.trainer:168 validation 79 loss=696.957947 err=696.957947 *
I 2015-05-26 09:16:17 theanets.trainer:168 RmsProp 791 loss=0.092914 err=0.092914
I 2015-05-26 09:16:25 theanets.trainer:168 RmsProp 792 loss=0.091522 err=0.091522
I 2015-05-26 09:16:32 theanets.trainer:168 RmsProp 793 loss=0.089583 err=0.089583
I 2015-05-26 09:16:40 theanets.trainer:168 RmsProp 794 loss=0.091023 err=0.091023
I 2015-05-26 09:16:47 theanets.trainer:168 RmsProp 795 loss=0.093985 err=0.093985
I 2015-05-26 09:16:54 theanets.trainer:168 RmsProp 796 loss=0.085688 err=0.085688
I 2015-05-26 09:17:02 theanets.trainer:168 RmsProp 797 loss=0.090998 err=0.090998
I 2015-05-26 09:17:08 theanets.trainer:168 RmsProp 798 loss=0.094485 err=0.094485
I 2015-05-26 09:17:16 theanets.trainer:168 RmsProp 799 loss=0.082814 err=0.082814
I 2015-05-26 09:17:23 theanets.trainer:168 RmsProp 800 loss=0.119589 err=0.119589
I 2015-05-26 09:17:24 theanets.trainer:168 validation 80 loss=699.192810 err=699.192810
I 2015-05-26 09:17:31 theanets.trainer:168 RmsProp 801 loss=0.096727 err=0.096727
I 2015-05-26 09:17:38 theanets.trainer:168 RmsProp 802 loss=0.088935 err=0.088935
I 2015-05-26 09:17:45 theanets.trainer:168 RmsProp 803 loss=0.090467 err=0.090467
I 2015-05-26 09:17:52 theanets.trainer:168 RmsProp 804 loss=0.073557 err=0.073557
I 2015-05-26 09:18:00 theanets.trainer:168 RmsProp 805 loss=0.136856 err=0.136856
I 2015-05-26 09:18:07 theanets.trainer:168 RmsProp 806 loss=0.098461 err=0.098461
I 2015-05-26 09:18:15 theanets.trainer:168 RmsProp 807 loss=0.091028 err=0.091028
I 2015-05-26 09:18:21 theanets.trainer:168 RmsProp 808 loss=0.076385 err=0.076385
I 2015-05-26 09:18:29 theanets.trainer:168 RmsProp 809 loss=0.114353 err=0.114353
I 2015-05-26 09:18:36 theanets.trainer:168 RmsProp 810 loss=0.090499 err=0.090499
I 2015-05-26 09:18:36 theanets.trainer:168 validation 81 loss=697.091248 err=697.091248
I 2015-05-26 09:18:43 theanets.trainer:168 RmsProp 811 loss=0.084513 err=0.084513
I 2015-05-26 09:18:51 theanets.trainer:168 RmsProp 812 loss=0.090920 err=0.090920
I 2015-05-26 09:18:57 theanets.trainer:168 RmsProp 813 loss=0.086811 err=0.086811
I 2015-05-26 09:19:04 theanets.trainer:168 RmsProp 814 loss=0.096573 err=0.096573
I 2015-05-26 09:19:12 theanets.trainer:168 RmsProp 815 loss=0.086634 err=0.086634
I 2015-05-26 09:19:20 theanets.trainer:168 RmsProp 816 loss=0.095627 err=0.095627
I 2015-05-26 09:19:27 theanets.trainer:168 RmsProp 817 loss=0.082614 err=0.082614
I 2015-05-26 09:19:34 theanets.trainer:168 RmsProp 818 loss=0.106708 err=0.106708
I 2015-05-26 09:19:41 theanets.trainer:168 RmsProp 819 loss=0.104818 err=0.104818
I 2015-05-26 09:19:48 theanets.trainer:168 RmsProp 820 loss=0.094324 err=0.094324
I 2015-05-26 09:19:49 theanets.trainer:168 validation 82 loss=696.601440 err=696.601440 *
I 2015-05-26 09:19:56 theanets.trainer:168 RmsProp 821 loss=0.081075 err=0.081075
I 2015-05-26 09:20:03 theanets.trainer:168 RmsProp 822 loss=0.096498 err=0.096498
I 2015-05-26 09:20:11 theanets.trainer:168 RmsProp 823 loss=0.089975 err=0.089975
I 2015-05-26 09:20:19 theanets.trainer:168 RmsProp 824 loss=0.086454 err=0.086454
I 2015-05-26 09:20:27 theanets.trainer:168 RmsProp 825 loss=0.081458 err=0.081458
I 2015-05-26 09:20:35 theanets.trainer:168 RmsProp 826 loss=0.093883 err=0.093883
I 2015-05-26 09:20:43 theanets.trainer:168 RmsProp 827 loss=0.088425 err=0.088425
I 2015-05-26 09:20:50 theanets.trainer:168 RmsProp 828 loss=0.092861 err=0.092861
I 2015-05-26 09:20:57 theanets.trainer:168 RmsProp 829 loss=0.084957 err=0.084957
I 2015-05-26 09:21:05 theanets.trainer:168 RmsProp 830 loss=0.082887 err=0.082887
I 2015-05-26 09:21:05 theanets.trainer:168 validation 83 loss=696.004700 err=696.004700 *
I 2015-05-26 09:21:12 theanets.trainer:168 RmsProp 831 loss=0.100272 err=0.100272
I 2015-05-26 09:21:20 theanets.trainer:168 RmsProp 832 loss=0.083064 err=0.083064
I 2015-05-26 09:21:27 theanets.trainer:168 RmsProp 833 loss=0.101638 err=0.101638
I 2015-05-26 09:21:35 theanets.trainer:168 RmsProp 834 loss=0.082607 err=0.082607
I 2015-05-26 09:21:43 theanets.trainer:168 RmsProp 835 loss=0.089966 err=0.089966
I 2015-05-26 09:21:50 theanets.trainer:168 RmsProp 836 loss=0.083395 err=0.083395
I 2015-05-26 09:21:57 theanets.trainer:168 RmsProp 837 loss=0.088459 err=0.088459
I 2015-05-26 09:22:04 theanets.trainer:168 RmsProp 838 loss=0.087604 err=0.087604
I 2015-05-26 09:22:11 theanets.trainer:168 RmsProp 839 loss=0.093683 err=0.093683
I 2015-05-26 09:22:18 theanets.trainer:168 RmsProp 840 loss=0.081001 err=0.081001
I 2015-05-26 09:22:18 theanets.trainer:168 validation 84 loss=695.416626 err=695.416626 *
I 2015-05-26 09:22:25 theanets.trainer:168 RmsProp 841 loss=0.092522 err=0.092522
I 2015-05-26 09:22:33 theanets.trainer:168 RmsProp 842 loss=0.082637 err=0.082637
I 2015-05-26 09:22:40 theanets.trainer:168 RmsProp 843 loss=0.100448 err=0.100448
I 2015-05-26 09:22:47 theanets.trainer:168 RmsProp 844 loss=0.084498 err=0.084498
I 2015-05-26 09:22:53 theanets.trainer:168 RmsProp 845 loss=0.090693 err=0.090693
I 2015-05-26 09:23:00 theanets.trainer:168 RmsProp 846 loss=0.083985 err=0.083985
I 2015-05-26 09:23:07 theanets.trainer:168 RmsProp 847 loss=0.086555 err=0.086555
I 2015-05-26 09:23:13 theanets.trainer:168 RmsProp 848 loss=0.087608 err=0.087608
I 2015-05-26 09:23:20 theanets.trainer:168 RmsProp 849 loss=0.087147 err=0.087147
I 2015-05-26 09:23:27 theanets.trainer:168 RmsProp 850 loss=0.085902 err=0.085902
I 2015-05-26 09:23:27 theanets.trainer:168 validation 85 loss=696.241516 err=696.241516
I 2015-05-26 09:23:34 theanets.trainer:168 RmsProp 851 loss=0.088231 err=0.088231
I 2015-05-26 09:23:41 theanets.trainer:168 RmsProp 852 loss=0.084616 err=0.084616
I 2015-05-26 09:23:47 theanets.trainer:168 RmsProp 853 loss=0.087370 err=0.087370
I 2015-05-26 09:23:54 theanets.trainer:168 RmsProp 854 loss=0.077961 err=0.077961
I 2015-05-26 09:24:01 theanets.trainer:168 RmsProp 855 loss=0.112073 err=0.112073
I 2015-05-26 09:24:08 theanets.trainer:168 RmsProp 856 loss=0.093196 err=0.093196
I 2015-05-26 09:24:15 theanets.trainer:168 RmsProp 857 loss=0.084050 err=0.084050
I 2015-05-26 09:24:23 theanets.trainer:168 RmsProp 858 loss=0.088700 err=0.088700
I 2015-05-26 09:24:30 theanets.trainer:168 RmsProp 859 loss=0.084317 err=0.084317
I 2015-05-26 09:24:37 theanets.trainer:168 RmsProp 860 loss=0.081139 err=0.081139
I 2015-05-26 09:24:38 theanets.trainer:168 validation 86 loss=696.100037 err=696.100037
I 2015-05-26 09:24:44 theanets.trainer:168 RmsProp 861 loss=0.082384 err=0.082384
I 2015-05-26 09:24:51 theanets.trainer:168 RmsProp 862 loss=0.095556 err=0.095556
I 2015-05-26 09:24:58 theanets.trainer:168 RmsProp 863 loss=0.083009 err=0.083009
I 2015-05-26 09:25:05 theanets.trainer:168 RmsProp 864 loss=0.082754 err=0.082754
I 2015-05-26 09:25:12 theanets.trainer:168 RmsProp 865 loss=0.088443 err=0.088443
I 2015-05-26 09:25:19 theanets.trainer:168 RmsProp 866 loss=0.086918 err=0.086918
I 2015-05-26 09:25:26 theanets.trainer:168 RmsProp 867 loss=0.082918 err=0.082918
I 2015-05-26 09:25:33 theanets.trainer:168 RmsProp 868 loss=0.084926 err=0.084926
I 2015-05-26 09:25:39 theanets.trainer:168 RmsProp 869 loss=0.098273 err=0.098273
I 2015-05-26 09:25:46 theanets.trainer:168 RmsProp 870 loss=0.083833 err=0.083833
I 2015-05-26 09:25:46 theanets.trainer:168 validation 87 loss=695.472595 err=695.472595
I 2015-05-26 09:25:53 theanets.trainer:168 RmsProp 871 loss=0.092671 err=0.092671
I 2015-05-26 09:26:00 theanets.trainer:168 RmsProp 872 loss=0.084390 err=0.084390
I 2015-05-26 09:26:06 theanets.trainer:168 RmsProp 873 loss=0.080832 err=0.080832
I 2015-05-26 09:26:13 theanets.trainer:168 RmsProp 874 loss=0.089050 err=0.089050
I 2015-05-26 09:26:20 theanets.trainer:168 RmsProp 875 loss=0.081602 err=0.081602
I 2015-05-26 09:26:27 theanets.trainer:168 RmsProp 876 loss=0.089490 err=0.089490
I 2015-05-26 09:26:34 theanets.trainer:168 RmsProp 877 loss=0.084810 err=0.084810
I 2015-05-26 09:26:41 theanets.trainer:168 RmsProp 878 loss=0.075443 err=0.075443
I 2015-05-26 09:26:47 theanets.trainer:168 RmsProp 879 loss=0.116190 err=0.116190
I 2015-05-26 09:26:54 theanets.trainer:168 RmsProp 880 loss=0.081852 err=0.081852
I 2015-05-26 09:26:54 theanets.trainer:168 validation 88 loss=694.688965 err=694.688965 *
I 2015-05-26 09:27:01 theanets.trainer:168 RmsProp 881 loss=0.083003 err=0.083003
I 2015-05-26 09:27:08 theanets.trainer:168 RmsProp 882 loss=0.077479 err=0.077479
I 2015-05-26 09:27:15 theanets.trainer:168 RmsProp 883 loss=0.086526 err=0.086526
I 2015-05-26 09:27:22 theanets.trainer:168 RmsProp 884 loss=0.081073 err=0.081073
I 2015-05-26 09:27:29 theanets.trainer:168 RmsProp 885 loss=0.093143 err=0.093143
I 2015-05-26 09:27:36 theanets.trainer:168 RmsProp 886 loss=0.081435 err=0.081435
I 2015-05-26 09:27:42 theanets.trainer:168 RmsProp 887 loss=0.082743 err=0.082743
I 2015-05-26 09:27:49 theanets.trainer:168 RmsProp 888 loss=0.092596 err=0.092596
I 2015-05-26 09:27:56 theanets.trainer:168 RmsProp 889 loss=0.087077 err=0.087077
I 2015-05-26 09:28:02 theanets.trainer:168 RmsProp 890 loss=0.085876 err=0.085876
I 2015-05-26 09:28:03 theanets.trainer:168 validation 89 loss=691.830139 err=691.830139 *
I 2015-05-26 09:28:09 theanets.trainer:168 RmsProp 891 loss=0.087725 err=0.087725
I 2015-05-26 09:28:16 theanets.trainer:168 RmsProp 892 loss=0.076308 err=0.076308
I 2015-05-26 09:28:22 theanets.trainer:168 RmsProp 893 loss=0.097874 err=0.097874
I 2015-05-26 09:28:29 theanets.trainer:168 RmsProp 894 loss=0.077852 err=0.077852
I 2015-05-26 09:28:36 theanets.trainer:168 RmsProp 895 loss=0.087594 err=0.087594
I 2015-05-26 09:28:42 theanets.trainer:168 RmsProp 896 loss=0.077247 err=0.077247
I 2015-05-26 09:28:49 theanets.trainer:168 RmsProp 897 loss=0.086586 err=0.086586
I 2015-05-26 09:28:57 theanets.trainer:168 RmsProp 898 loss=0.083588 err=0.083588
I 2015-05-26 09:29:04 theanets.trainer:168 RmsProp 899 loss=0.090153 err=0.090153
I 2015-05-26 09:29:11 theanets.trainer:168 RmsProp 900 loss=0.097824 err=0.097824
I 2015-05-26 09:29:11 theanets.trainer:168 validation 90 loss=695.171021 err=695.171021
I 2015-05-26 09:29:18 theanets.trainer:168 RmsProp 901 loss=0.080250 err=0.080250
I 2015-05-26 09:29:25 theanets.trainer:168 RmsProp 902 loss=0.088292 err=0.088292
I 2015-05-26 09:29:32 theanets.trainer:168 RmsProp 903 loss=0.077692 err=0.077692
I 2015-05-26 09:29:39 theanets.trainer:168 RmsProp 904 loss=0.074842 err=0.074842
I 2015-05-26 09:29:46 theanets.trainer:168 RmsProp 905 loss=0.090548 err=0.090548
I 2015-05-26 09:29:52 theanets.trainer:168 RmsProp 906 loss=0.083316 err=0.083316
I 2015-05-26 09:29:59 theanets.trainer:168 RmsProp 907 loss=0.083706 err=0.083706
I 2015-05-26 09:30:05 theanets.trainer:168 RmsProp 908 loss=0.074312 err=0.074312
I 2015-05-26 09:30:12 theanets.trainer:168 RmsProp 909 loss=0.095306 err=0.095306
I 2015-05-26 09:30:19 theanets.trainer:168 RmsProp 910 loss=0.075109 err=0.075109
I 2015-05-26 09:30:19 theanets.trainer:168 validation 91 loss=692.003662 err=692.003662
I 2015-05-26 09:30:26 theanets.trainer:168 RmsProp 911 loss=0.082725 err=0.082725
I 2015-05-26 09:30:33 theanets.trainer:168 RmsProp 912 loss=0.081553 err=0.081553
I 2015-05-26 09:30:40 theanets.trainer:168 RmsProp 913 loss=0.082651 err=0.082651
I 2015-05-26 09:30:47 theanets.trainer:168 RmsProp 914 loss=0.089575 err=0.089575
I 2015-05-26 09:30:54 theanets.trainer:168 RmsProp 915 loss=0.081378 err=0.081378
I 2015-05-26 09:31:01 theanets.trainer:168 RmsProp 916 loss=0.079112 err=0.079112
I 2015-05-26 09:31:08 theanets.trainer:168 RmsProp 917 loss=0.092034 err=0.092034
I 2015-05-26 09:31:14 theanets.trainer:168 RmsProp 918 loss=0.085946 err=0.085946
I 2015-05-26 09:31:21 theanets.trainer:168 RmsProp 919 loss=0.074923 err=0.074923
I 2015-05-26 09:31:28 theanets.trainer:168 RmsProp 920 loss=0.082529 err=0.082529
I 2015-05-26 09:31:28 theanets.trainer:168 validation 92 loss=691.504089 err=691.504089 *
I 2015-05-26 09:31:35 theanets.trainer:168 RmsProp 921 loss=0.077086 err=0.077086
I 2015-05-26 09:31:42 theanets.trainer:168 RmsProp 922 loss=0.081751 err=0.081751
I 2015-05-26 09:31:49 theanets.trainer:168 RmsProp 923 loss=0.087392 err=0.087392
I 2015-05-26 09:31:56 theanets.trainer:168 RmsProp 924 loss=0.071216 err=0.071216
I 2015-05-26 09:32:02 theanets.trainer:168 RmsProp 925 loss=0.091391 err=0.091391
I 2015-05-26 09:32:09 theanets.trainer:168 RmsProp 926 loss=0.079941 err=0.079941
I 2015-05-26 09:32:16 theanets.trainer:168 RmsProp 927 loss=0.085097 err=0.085097
I 2015-05-26 09:32:23 theanets.trainer:168 RmsProp 928 loss=0.076789 err=0.076789
I 2015-05-26 09:32:30 theanets.trainer:168 RmsProp 929 loss=0.093756 err=0.093756
I 2015-05-26 09:32:37 theanets.trainer:168 RmsProp 930 loss=0.083873 err=0.083873
I 2015-05-26 09:32:38 theanets.trainer:168 validation 93 loss=691.759399 err=691.759399
I 2015-05-26 09:32:44 theanets.trainer:168 RmsProp 931 loss=0.072099 err=0.072099
I 2015-05-26 09:32:51 theanets.trainer:168 RmsProp 932 loss=0.099778 err=0.099778
I 2015-05-26 09:32:57 theanets.trainer:168 RmsProp 933 loss=0.081941 err=0.081941
I 2015-05-26 09:33:04 theanets.trainer:168 RmsProp 934 loss=0.088247 err=0.088247
I 2015-05-26 09:33:11 theanets.trainer:168 RmsProp 935 loss=0.089494 err=0.089494
I 2015-05-26 09:33:17 theanets.trainer:168 RmsProp 936 loss=0.068782 err=0.068782
I 2015-05-26 09:33:24 theanets.trainer:168 RmsProp 937 loss=0.114489 err=0.114489
I 2015-05-26 09:33:31 theanets.trainer:168 RmsProp 938 loss=0.093601 err=0.093601
I 2015-05-26 09:33:39 theanets.trainer:168 RmsProp 939 loss=0.074125 err=0.074125
I 2015-05-26 09:33:45 theanets.trainer:168 RmsProp 940 loss=0.072867 err=0.072867
I 2015-05-26 09:33:46 theanets.trainer:168 validation 94 loss=691.560181 err=691.560181
I 2015-05-26 09:33:52 theanets.trainer:168 RmsProp 941 loss=0.081945 err=0.081945
I 2015-05-26 09:33:59 theanets.trainer:168 RmsProp 942 loss=0.078974 err=0.078974
I 2015-05-26 09:34:06 theanets.trainer:168 RmsProp 943 loss=0.077238 err=0.077238
I 2015-05-26 09:34:13 theanets.trainer:168 RmsProp 944 loss=0.087624 err=0.087624
I 2015-05-26 09:34:20 theanets.trainer:168 RmsProp 945 loss=0.077415 err=0.077415
I 2015-05-26 09:34:26 theanets.trainer:168 RmsProp 946 loss=0.070838 err=0.070838
I 2015-05-26 09:34:33 theanets.trainer:168 RmsProp 947 loss=0.084618 err=0.084618
I 2015-05-26 09:34:40 theanets.trainer:168 RmsProp 948 loss=0.075951 err=0.075951
I 2015-05-26 09:34:46 theanets.trainer:168 RmsProp 949 loss=0.081336 err=0.081336
I 2015-05-26 09:34:52 theanets.trainer:168 RmsProp 950 loss=0.076470 err=0.076470
I 2015-05-26 09:34:52 theanets.trainer:168 validation 95 loss=689.119385 err=689.119385 *
I 2015-05-26 09:34:59 theanets.trainer:168 RmsProp 951 loss=0.076098 err=0.076098
I 2015-05-26 09:35:06 theanets.trainer:168 RmsProp 952 loss=0.083362 err=0.083362
I 2015-05-26 09:35:12 theanets.trainer:168 RmsProp 953 loss=0.083458 err=0.083458
I 2015-05-26 09:35:18 theanets.trainer:168 RmsProp 954 loss=0.084435 err=0.084435
I 2015-05-26 09:35:25 theanets.trainer:168 RmsProp 955 loss=0.069471 err=0.069471
I 2015-05-26 09:35:32 theanets.trainer:168 RmsProp 956 loss=0.090802 err=0.090802
I 2015-05-26 09:35:38 theanets.trainer:168 RmsProp 957 loss=0.075500 err=0.075500
I 2015-05-26 09:35:46 theanets.trainer:168 RmsProp 958 loss=0.084352 err=0.084352
I 2015-05-26 09:35:53 theanets.trainer:168 RmsProp 959 loss=0.077999 err=0.077999
I 2015-05-26 09:35:59 theanets.trainer:168 RmsProp 960 loss=0.079947 err=0.079947
I 2015-05-26 09:35:59 theanets.trainer:168 validation 96 loss=689.304138 err=689.304138
I 2015-05-26 09:36:06 theanets.trainer:168 RmsProp 961 loss=0.071891 err=0.071891
I 2015-05-26 09:36:14 theanets.trainer:168 RmsProp 962 loss=0.085870 err=0.085870
I 2015-05-26 09:36:20 theanets.trainer:168 RmsProp 963 loss=0.078982 err=0.078982
I 2015-05-26 09:36:27 theanets.trainer:168 RmsProp 964 loss=0.071200 err=0.071200
I 2015-05-26 09:36:33 theanets.trainer:168 RmsProp 965 loss=0.087028 err=0.087028
I 2015-05-26 09:36:40 theanets.trainer:168 RmsProp 966 loss=0.075638 err=0.075638
I 2015-05-26 09:36:47 theanets.trainer:168 RmsProp 967 loss=0.074379 err=0.074379
I 2015-05-26 09:36:53 theanets.trainer:168 RmsProp 968 loss=0.084094 err=0.084094
I 2015-05-26 09:37:00 theanets.trainer:168 RmsProp 969 loss=0.077058 err=0.077058
I 2015-05-26 09:37:07 theanets.trainer:168 RmsProp 970 loss=0.076535 err=0.076535
I 2015-05-26 09:37:08 theanets.trainer:168 validation 97 loss=689.132874 err=689.132874
I 2015-05-26 09:37:14 theanets.trainer:168 RmsProp 971 loss=0.078885 err=0.078885
I 2015-05-26 09:37:21 theanets.trainer:168 RmsProp 972 loss=0.076611 err=0.076611
I 2015-05-26 09:37:28 theanets.trainer:168 RmsProp 973 loss=0.087598 err=0.087598
I 2015-05-26 09:37:34 theanets.trainer:168 RmsProp 974 loss=0.072740 err=0.072740
I 2015-05-26 09:37:41 theanets.trainer:168 RmsProp 975 loss=0.086831 err=0.086831
I 2015-05-26 09:37:47 theanets.trainer:168 RmsProp 976 loss=0.073524 err=0.073524
I 2015-05-26 09:37:54 theanets.trainer:168 RmsProp 977 loss=0.072780 err=0.072780
I 2015-05-26 09:38:01 theanets.trainer:168 RmsProp 978 loss=0.087541 err=0.087541
I 2015-05-26 09:38:08 theanets.trainer:168 RmsProp 979 loss=0.082674 err=0.082674
I 2015-05-26 09:38:14 theanets.trainer:168 RmsProp 980 loss=0.076204 err=0.076204
I 2015-05-26 09:38:15 theanets.trainer:168 validation 98 loss=688.999573 err=688.999573 *
I 2015-05-26 09:38:21 theanets.trainer:168 RmsProp 981 loss=0.072447 err=0.072447
I 2015-05-26 09:38:28 theanets.trainer:168 RmsProp 982 loss=0.092282 err=0.092282
I 2015-05-26 09:38:35 theanets.trainer:168 RmsProp 983 loss=0.076157 err=0.076157
I 2015-05-26 09:38:41 theanets.trainer:168 RmsProp 984 loss=0.076002 err=0.076002
I 2015-05-26 09:38:49 theanets.trainer:168 RmsProp 985 loss=0.078188 err=0.078188
I 2015-05-26 09:38:56 theanets.trainer:168 RmsProp 986 loss=0.078719 err=0.078719
I 2015-05-26 09:39:03 theanets.trainer:168 RmsProp 987 loss=0.075003 err=0.075003
I 2015-05-26 09:39:10 theanets.trainer:168 RmsProp 988 loss=0.077765 err=0.077765
I 2015-05-26 09:39:16 theanets.trainer:168 RmsProp 989 loss=0.083499 err=0.083499
I 2015-05-26 09:39:23 theanets.trainer:168 RmsProp 990 loss=0.095216 err=0.095216
I 2015-05-26 09:39:23 theanets.trainer:168 validation 99 loss=687.629333 err=687.629333 *
I 2015-05-26 09:39:30 theanets.trainer:168 RmsProp 991 loss=0.076305 err=0.076305
I 2015-05-26 09:39:36 theanets.trainer:168 RmsProp 992 loss=0.068108 err=0.068108
I 2015-05-26 09:39:43 theanets.trainer:168 RmsProp 993 loss=0.075029 err=0.075029
I 2015-05-26 09:39:50 theanets.trainer:168 RmsProp 994 loss=0.080561 err=0.080561
I 2015-05-26 09:39:57 theanets.trainer:168 RmsProp 995 loss=0.081540 err=0.081540
I 2015-05-26 09:40:03 theanets.trainer:168 RmsProp 996 loss=0.075513 err=0.075513
I 2015-05-26 09:40:10 theanets.trainer:168 RmsProp 997 loss=0.072273 err=0.072273
I 2015-05-26 09:40:16 theanets.trainer:168 RmsProp 998 loss=0.082654 err=0.082654
I 2015-05-26 09:40:23 theanets.trainer:168 RmsProp 999 loss=0.066163 err=0.066163
I 2015-05-26 09:40:31 theanets.trainer:168 RmsProp 1000 loss=0.077652 err=0.077652
I 2015-05-26 09:40:31 theanets.trainer:168 validation 100 loss=687.453247 err=687.453247 *
I 2015-05-26 09:40:38 theanets.trainer:168 RmsProp 1001 loss=0.078174 err=0.078174
I 2015-05-26 09:40:44 theanets.trainer:168 RmsProp 1002 loss=0.079103 err=0.079103
I 2015-05-26 09:40:51 theanets.trainer:168 RmsProp 1003 loss=0.085047 err=0.085047
I 2015-05-26 09:40:57 theanets.trainer:168 RmsProp 1004 loss=0.078766 err=0.078766
I 2015-05-26 09:41:03 theanets.trainer:168 RmsProp 1005 loss=0.083456 err=0.083456
I 2015-05-26 09:41:10 theanets.trainer:168 RmsProp 1006 loss=0.067439 err=0.067439
I 2015-05-26 09:41:16 theanets.trainer:168 RmsProp 1007 loss=0.078092 err=0.078092
I 2015-05-26 09:41:23 theanets.trainer:168 RmsProp 1008 loss=0.076099 err=0.076099
I 2015-05-26 09:41:30 theanets.trainer:168 RmsProp 1009 loss=0.075311 err=0.075311
I 2015-05-26 09:41:37 theanets.trainer:168 RmsProp 1010 loss=0.076033 err=0.076033
I 2015-05-26 09:41:37 theanets.trainer:168 validation 101 loss=688.505310 err=688.505310
I 2015-05-26 09:41:44 theanets.trainer:168 RmsProp 1011 loss=0.076088 err=0.076088
I 2015-05-26 09:41:51 theanets.trainer:168 RmsProp 1012 loss=0.081441 err=0.081441
I 2015-05-26 09:41:57 theanets.trainer:168 RmsProp 1013 loss=0.068271 err=0.068271
I 2015-05-26 09:42:04 theanets.trainer:168 RmsProp 1014 loss=0.071922 err=0.071922
I 2015-05-26 09:42:10 theanets.trainer:168 RmsProp 1015 loss=0.082376 err=0.082376
I 2015-05-26 09:42:17 theanets.trainer:168 RmsProp 1016 loss=0.069180 err=0.069180
I 2015-05-26 09:42:24 theanets.trainer:168 RmsProp 1017 loss=0.084327 err=0.084327
I 2015-05-26 09:42:30 theanets.trainer:168 RmsProp 1018 loss=0.078599 err=0.078599
I 2015-05-26 09:42:37 theanets.trainer:168 RmsProp 1019 loss=0.065717 err=0.065717
I 2015-05-26 09:42:43 theanets.trainer:168 RmsProp 1020 loss=0.098209 err=0.098209
I 2015-05-26 09:42:44 theanets.trainer:168 validation 102 loss=688.282837 err=688.282837
I 2015-05-26 09:42:51 theanets.trainer:168 RmsProp 1021 loss=0.093852 err=0.093852
I 2015-05-26 09:42:58 theanets.trainer:168 RmsProp 1022 loss=0.071738 err=0.071738
I 2015-05-26 09:43:04 theanets.trainer:168 RmsProp 1023 loss=0.071451 err=0.071451
I 2015-05-26 09:43:11 theanets.trainer:168 RmsProp 1024 loss=0.070502 err=0.070502
I 2015-05-26 09:43:17 theanets.trainer:168 RmsProp 1025 loss=0.077780 err=0.077780
I 2015-05-26 09:43:24 theanets.trainer:168 RmsProp 1026 loss=0.079427 err=0.079427
I 2015-05-26 09:43:31 theanets.trainer:168 RmsProp 1027 loss=0.077402 err=0.077402
I 2015-05-26 09:43:37 theanets.trainer:168 RmsProp 1028 loss=0.076041 err=0.076041
I 2015-05-26 09:43:44 theanets.trainer:168 RmsProp 1029 loss=0.072051 err=0.072051
I 2015-05-26 09:43:50 theanets.trainer:168 RmsProp 1030 loss=0.081481 err=0.081481
I 2015-05-26 09:43:51 theanets.trainer:168 validation 103 loss=686.126892 err=686.126892 *
I 2015-05-26 09:43:57 theanets.trainer:168 RmsProp 1031 loss=0.071166 err=0.071166
I 2015-05-26 09:44:04 theanets.trainer:168 RmsProp 1032 loss=0.078454 err=0.078454
I 2015-05-26 09:44:11 theanets.trainer:168 RmsProp 1033 loss=0.070222 err=0.070222
I 2015-05-26 09:44:18 theanets.trainer:168 RmsProp 1034 loss=0.074157 err=0.074157
I 2015-05-26 09:44:26 theanets.trainer:168 RmsProp 1035 loss=0.075382 err=0.075382
I 2015-05-26 09:44:33 theanets.trainer:168 RmsProp 1036 loss=0.072441 err=0.072441
I 2015-05-26 09:44:40 theanets.trainer:168 RmsProp 1037 loss=0.096482 err=0.096482
I 2015-05-26 09:44:47 theanets.trainer:168 RmsProp 1038 loss=0.086339 err=0.086339
I 2015-05-26 09:44:53 theanets.trainer:168 RmsProp 1039 loss=0.066603 err=0.066603
I 2015-05-26 09:44:59 theanets.trainer:168 RmsProp 1040 loss=0.082807 err=0.082807
I 2015-05-26 09:45:00 theanets.trainer:168 validation 104 loss=687.713989 err=687.713989
I 2015-05-26 09:45:06 theanets.trainer:168 RmsProp 1041 loss=0.071948 err=0.071948
I 2015-05-26 09:45:13 theanets.trainer:168 RmsProp 1042 loss=0.070919 err=0.070919
I 2015-05-26 09:45:20 theanets.trainer:168 RmsProp 1043 loss=0.073681 err=0.073681
I 2015-05-26 09:45:27 theanets.trainer:168 RmsProp 1044 loss=0.073757 err=0.073757
I 2015-05-26 09:45:34 theanets.trainer:168 RmsProp 1045 loss=0.079351 err=0.079351
I 2015-05-26 09:45:40 theanets.trainer:168 RmsProp 1046 loss=0.073425 err=0.073425
I 2015-05-26 09:45:46 theanets.trainer:168 RmsProp 1047 loss=0.077256 err=0.077256
I 2015-05-26 09:45:53 theanets.trainer:168 RmsProp 1048 loss=0.077147 err=0.077147
I 2015-05-26 09:46:00 theanets.trainer:168 RmsProp 1049 loss=0.066743 err=0.066743
I 2015-05-26 09:46:07 theanets.trainer:168 RmsProp 1050 loss=0.070502 err=0.070502
I 2015-05-26 09:46:07 theanets.trainer:168 validation 105 loss=684.994690 err=684.994690 *
I 2015-05-26 09:46:14 theanets.trainer:168 RmsProp 1051 loss=0.074960 err=0.074960
I 2015-05-26 09:46:20 theanets.trainer:168 RmsProp 1052 loss=0.076664 err=0.076664
I 2015-05-26 09:46:27 theanets.trainer:168 RmsProp 1053 loss=0.072467 err=0.072467
I 2015-05-26 09:46:33 theanets.trainer:168 RmsProp 1054 loss=0.069779 err=0.069779
I 2015-05-26 09:46:40 theanets.trainer:168 RmsProp 1055 loss=0.069090 err=0.069090
I 2015-05-26 09:46:47 theanets.trainer:168 RmsProp 1056 loss=0.077675 err=0.077675
I 2015-05-26 09:46:54 theanets.trainer:168 RmsProp 1057 loss=0.069158 err=0.069158
I 2015-05-26 09:47:01 theanets.trainer:168 RmsProp 1058 loss=0.081526 err=0.081526
I 2015-05-26 09:47:08 theanets.trainer:168 RmsProp 1059 loss=0.077052 err=0.077052
I 2015-05-26 09:47:15 theanets.trainer:168 RmsProp 1060 loss=0.066533 err=0.066533
I 2015-05-26 09:47:15 theanets.trainer:168 validation 106 loss=684.567322 err=684.567322 *
I 2015-05-26 09:47:22 theanets.trainer:168 RmsProp 1061 loss=0.078705 err=0.078705
I 2015-05-26 09:47:29 theanets.trainer:168 RmsProp 1062 loss=0.071256 err=0.071256
I 2015-05-26 09:47:36 theanets.trainer:168 RmsProp 1063 loss=0.070556 err=0.070556
I 2015-05-26 09:47:42 theanets.trainer:168 RmsProp 1064 loss=0.084148 err=0.084148
I 2015-05-26 09:47:49 theanets.trainer:168 RmsProp 1065 loss=0.073333 err=0.073333
I 2015-05-26 09:47:56 theanets.trainer:168 RmsProp 1066 loss=0.074437 err=0.074437
I 2015-05-26 09:48:02 theanets.trainer:168 RmsProp 1067 loss=0.073519 err=0.073519
I 2015-05-26 09:48:09 theanets.trainer:168 RmsProp 1068 loss=0.073616 err=0.073616
I 2015-05-26 09:48:16 theanets.trainer:168 RmsProp 1069 loss=0.069145 err=0.069145
I 2015-05-26 09:48:24 theanets.trainer:168 RmsProp 1070 loss=0.089446 err=0.089446
I 2015-05-26 09:48:24 theanets.trainer:168 validation 107 loss=684.552673 err=684.552673 *
I 2015-05-26 09:48:31 theanets.trainer:168 RmsProp 1071 loss=0.088628 err=0.088628
I 2015-05-26 09:48:37 theanets.trainer:168 RmsProp 1072 loss=0.065966 err=0.065966
I 2015-05-26 09:48:44 theanets.trainer:168 RmsProp 1073 loss=0.066498 err=0.066498
I 2015-05-26 09:48:52 theanets.trainer:168 RmsProp 1074 loss=0.079031 err=0.079031
I 2015-05-26 09:48:59 theanets.trainer:168 RmsProp 1075 loss=0.073757 err=0.073757
I 2015-05-26 09:49:05 theanets.trainer:168 RmsProp 1076 loss=0.071810 err=0.071810
I 2015-05-26 09:49:11 theanets.trainer:168 RmsProp 1077 loss=0.064665 err=0.064665
I 2015-05-26 09:49:18 theanets.trainer:168 RmsProp 1078 loss=0.073052 err=0.073052
I 2015-05-26 09:49:25 theanets.trainer:168 RmsProp 1079 loss=0.068315 err=0.068315
I 2015-05-26 09:49:31 theanets.trainer:168 RmsProp 1080 loss=0.080257 err=0.080257
I 2015-05-26 09:49:32 theanets.trainer:168 validation 108 loss=686.075745 err=686.075745
I 2015-05-26 09:49:38 theanets.trainer:168 RmsProp 1081 loss=0.068757 err=0.068757
I 2015-05-26 09:49:45 theanets.trainer:168 RmsProp 1082 loss=0.073998 err=0.073998
I 2015-05-26 09:49:51 theanets.trainer:168 RmsProp 1083 loss=0.068795 err=0.068795
I 2015-05-26 09:49:58 theanets.trainer:168 RmsProp 1084 loss=0.068850 err=0.068850
I 2015-05-26 09:50:04 theanets.trainer:168 RmsProp 1085 loss=0.076879 err=0.076879
I 2015-05-26 09:50:11 theanets.trainer:168 RmsProp 1086 loss=0.069081 err=0.069081
I 2015-05-26 09:50:17 theanets.trainer:168 RmsProp 1087 loss=0.067119 err=0.067119
I 2015-05-26 09:50:24 theanets.trainer:168 RmsProp 1088 loss=0.074569 err=0.074569
I 2015-05-26 09:50:31 theanets.trainer:168 RmsProp 1089 loss=0.069150 err=0.069150
I 2015-05-26 09:50:37 theanets.trainer:168 RmsProp 1090 loss=0.061603 err=0.061603
I 2015-05-26 09:50:38 theanets.trainer:168 validation 109 loss=683.045105 err=683.045105 *
I 2015-05-26 09:50:44 theanets.trainer:168 RmsProp 1091 loss=0.096831 err=0.096831
I 2015-05-26 09:50:51 theanets.trainer:168 RmsProp 1092 loss=0.067930 err=0.067930
I 2015-05-26 09:50:57 theanets.trainer:168 RmsProp 1093 loss=0.069514 err=0.069514
I 2015-05-26 09:51:04 theanets.trainer:168 RmsProp 1094 loss=0.074067 err=0.074067
I 2015-05-26 09:51:11 theanets.trainer:168 RmsProp 1095 loss=0.068872 err=0.068872
I 2015-05-26 09:51:17 theanets.trainer:168 RmsProp 1096 loss=0.062118 err=0.062118
I 2015-05-26 09:51:24 theanets.trainer:168 RmsProp 1097 loss=0.100651 err=0.100651
I 2015-05-26 09:51:32 theanets.trainer:168 RmsProp 1098 loss=0.073166 err=0.073166
I 2015-05-26 09:51:39 theanets.trainer:168 RmsProp 1099 loss=0.074666 err=0.074666
I 2015-05-26 09:51:45 theanets.trainer:168 RmsProp 1100 loss=0.072654 err=0.072654
I 2015-05-26 09:51:46 theanets.trainer:168 validation 110 loss=682.713501 err=682.713501 *
I 2015-05-26 09:51:53 theanets.trainer:168 RmsProp 1101 loss=0.069345 err=0.069345
I 2015-05-26 09:51:59 theanets.trainer:168 RmsProp 1102 loss=0.076395 err=0.076395
I 2015-05-26 09:52:06 theanets.trainer:168 RmsProp 1103 loss=0.077873 err=0.077873
I 2015-05-26 09:52:14 theanets.trainer:168 RmsProp 1104 loss=0.065059 err=0.065059
I 2015-05-26 09:52:20 theanets.trainer:168 RmsProp 1105 loss=0.070639 err=0.070639
I 2015-05-26 09:52:27 theanets.trainer:168 RmsProp 1106 loss=0.068073 err=0.068073
I 2015-05-26 09:52:34 theanets.trainer:168 RmsProp 1107 loss=0.072734 err=0.072734
I 2015-05-26 09:52:40 theanets.trainer:168 RmsProp 1108 loss=0.071485 err=0.071485
I 2015-05-26 09:52:48 theanets.trainer:168 RmsProp 1109 loss=0.071448 err=0.071448
I 2015-05-26 09:52:55 theanets.trainer:168 RmsProp 1110 loss=0.067836 err=0.067836
I 2015-05-26 09:52:55 theanets.trainer:168 validation 111 loss=683.399841 err=683.399841
I 2015-05-26 09:53:02 theanets.trainer:168 RmsProp 1111 loss=0.071357 err=0.071357
I 2015-05-26 09:53:09 theanets.trainer:168 RmsProp 1112 loss=0.069892 err=0.069892
I 2015-05-26 09:53:17 theanets.trainer:168 RmsProp 1113 loss=0.070935 err=0.070935
I 2015-05-26 09:53:24 theanets.trainer:168 RmsProp 1114 loss=0.071713 err=0.071713
I 2015-05-26 09:53:31 theanets.trainer:168 RmsProp 1115 loss=0.066088 err=0.066088
I 2015-05-26 09:53:38 theanets.trainer:168 RmsProp 1116 loss=0.077694 err=0.077694
I 2015-05-26 09:53:45 theanets.trainer:168 RmsProp 1117 loss=0.071576 err=0.071576
I 2015-05-26 09:53:52 theanets.trainer:168 RmsProp 1118 loss=0.073945 err=0.073945
I 2015-05-26 09:53:59 theanets.trainer:168 RmsProp 1119 loss=0.065188 err=0.065188
I 2015-05-26 09:54:06 theanets.trainer:168 RmsProp 1120 loss=0.078782 err=0.078782
I 2015-05-26 09:54:06 theanets.trainer:168 validation 112 loss=684.288940 err=684.288940
I 2015-05-26 09:54:13 theanets.trainer:168 RmsProp 1121 loss=0.064587 err=0.064587
I 2015-05-26 09:54:20 theanets.trainer:168 RmsProp 1122 loss=0.073708 err=0.073708
I 2015-05-26 09:54:28 theanets.trainer:168 RmsProp 1123 loss=0.068922 err=0.068922
I 2015-05-26 09:54:35 theanets.trainer:168 RmsProp 1124 loss=0.065010 err=0.065010
I 2015-05-26 09:54:42 theanets.trainer:168 RmsProp 1125 loss=0.067056 err=0.067056
I 2015-05-26 09:54:49 theanets.trainer:168 RmsProp 1126 loss=0.072429 err=0.072429
I 2015-05-26 09:54:56 theanets.trainer:168 RmsProp 1127 loss=0.073173 err=0.073173
I 2015-05-26 09:55:03 theanets.trainer:168 RmsProp 1128 loss=0.075067 err=0.075067
I 2015-05-26 09:55:10 theanets.trainer:168 RmsProp 1129 loss=0.070309 err=0.070309
I 2015-05-26 09:55:18 theanets.trainer:168 RmsProp 1130 loss=0.069727 err=0.069727
I 2015-05-26 09:55:18 theanets.trainer:168 validation 113 loss=682.979675 err=682.979675
I 2015-05-26 09:55:25 theanets.trainer:168 RmsProp 1131 loss=0.069046 err=0.069046
I 2015-05-26 09:55:31 theanets.trainer:168 RmsProp 1132 loss=0.064004 err=0.064004
I 2015-05-26 09:55:38 theanets.trainer:168 RmsProp 1133 loss=0.079681 err=0.079681
I 2015-05-26 09:55:45 theanets.trainer:168 RmsProp 1134 loss=0.073204 err=0.073204
I 2015-05-26 09:55:52 theanets.trainer:168 RmsProp 1135 loss=0.061446 err=0.061446
I 2015-05-26 09:55:59 theanets.trainer:168 RmsProp 1136 loss=0.071462 err=0.071462
I 2015-05-26 09:56:07 theanets.trainer:168 RmsProp 1137 loss=0.063457 err=0.063457
I 2015-05-26 09:56:14 theanets.trainer:168 RmsProp 1138 loss=0.080369 err=0.080369
I 2015-05-26 09:56:20 theanets.trainer:168 RmsProp 1139 loss=0.065906 err=0.065906
I 2015-05-26 09:56:28 theanets.trainer:168 RmsProp 1140 loss=0.069012 err=0.069012
I 2015-05-26 09:56:28 theanets.trainer:168 validation 114 loss=681.464722 err=681.464722 *
I 2015-05-26 09:56:35 theanets.trainer:168 RmsProp 1141 loss=0.065844 err=0.065844
I 2015-05-26 09:56:41 theanets.trainer:168 RmsProp 1142 loss=0.084671 err=0.084671
I 2015-05-26 09:56:49 theanets.trainer:168 RmsProp 1143 loss=0.077627 err=0.077627
I 2015-05-26 09:56:56 theanets.trainer:168 RmsProp 1144 loss=0.064856 err=0.064856
I 2015-05-26 09:57:03 theanets.trainer:168 RmsProp 1145 loss=0.062433 err=0.062433
I 2015-05-26 09:57:09 theanets.trainer:168 RmsProp 1146 loss=0.079067 err=0.079067
I 2015-05-26 09:57:16 theanets.trainer:168 RmsProp 1147 loss=0.067783 err=0.067783
I 2015-05-26 09:57:23 theanets.trainer:168 RmsProp 1148 loss=0.068456 err=0.068456
I 2015-05-26 09:57:30 theanets.trainer:168 RmsProp 1149 loss=0.065210 err=0.065210
I 2015-05-26 09:57:37 theanets.trainer:168 RmsProp 1150 loss=0.071178 err=0.071178
I 2015-05-26 09:57:38 theanets.trainer:168 validation 115 loss=683.220886 err=683.220886
I 2015-05-26 09:57:44 theanets.trainer:168 RmsProp 1151 loss=0.067183 err=0.067183
I 2015-05-26 09:57:50 theanets.trainer:168 RmsProp 1152 loss=0.065804 err=0.065804
I 2015-05-26 09:57:57 theanets.trainer:168 RmsProp 1153 loss=0.063775 err=0.063775
I 2015-05-26 09:58:03 theanets.trainer:168 RmsProp 1154 loss=0.063691 err=0.063691
I 2015-05-26 09:58:10 theanets.trainer:168 RmsProp 1155 loss=0.084729 err=0.084729
I 2015-05-26 09:58:18 theanets.trainer:168 RmsProp 1156 loss=0.064608 err=0.064608
I 2015-05-26 09:58:25 theanets.trainer:168 RmsProp 1157 loss=0.066774 err=0.066774
I 2015-05-26 09:58:31 theanets.trainer:168 RmsProp 1158 loss=0.069163 err=0.069163
I 2015-05-26 09:58:39 theanets.trainer:168 RmsProp 1159 loss=0.072709 err=0.072709
I 2015-05-26 09:58:46 theanets.trainer:168 RmsProp 1160 loss=0.064107 err=0.064107
I 2015-05-26 09:58:46 theanets.trainer:168 validation 116 loss=681.560364 err=681.560364
I 2015-05-26 09:58:53 theanets.trainer:168 RmsProp 1161 loss=0.066003 err=0.066003
I 2015-05-26 09:59:00 theanets.trainer:168 RmsProp 1162 loss=0.067686 err=0.067686
I 2015-05-26 09:59:06 theanets.trainer:168 RmsProp 1163 loss=0.058969 err=0.058969
I 2015-05-26 09:59:14 theanets.trainer:168 RmsProp 1164 loss=0.080979 err=0.080979
I 2015-05-26 09:59:21 theanets.trainer:168 RmsProp 1165 loss=0.065513 err=0.065513
I 2015-05-26 09:59:28 theanets.trainer:168 RmsProp 1166 loss=0.062357 err=0.062357
I 2015-05-26 09:59:35 theanets.trainer:168 RmsProp 1167 loss=0.075457 err=0.075457
I 2015-05-26 09:59:42 theanets.trainer:168 RmsProp 1168 loss=0.088012 err=0.088012
I 2015-05-26 09:59:49 theanets.trainer:168 RmsProp 1169 loss=0.065893 err=0.065893
I 2015-05-26 09:59:56 theanets.trainer:168 RmsProp 1170 loss=0.067820 err=0.067820
I 2015-05-26 09:59:56 theanets.trainer:168 validation 117 loss=683.179932 err=683.179932
I 2015-05-26 10:00:03 theanets.trainer:168 RmsProp 1171 loss=0.068799 err=0.068799
I 2015-05-26 10:00:10 theanets.trainer:168 RmsProp 1172 loss=0.057327 err=0.057327
I 2015-05-26 10:00:17 theanets.trainer:168 RmsProp 1173 loss=0.078121 err=0.078121
I 2015-05-26 10:00:25 theanets.trainer:168 RmsProp 1174 loss=0.065277 err=0.065277
I 2015-05-26 10:00:31 theanets.trainer:168 RmsProp 1175 loss=0.064400 err=0.064400
I 2015-05-26 10:00:38 theanets.trainer:168 RmsProp 1176 loss=0.069643 err=0.069643
I 2015-05-26 10:00:45 theanets.trainer:168 RmsProp 1177 loss=0.069972 err=0.069972
I 2015-05-26 10:00:52 theanets.trainer:168 RmsProp 1178 loss=0.060316 err=0.060316
I 2015-05-26 10:00:59 theanets.trainer:168 RmsProp 1179 loss=0.079738 err=0.079738
I 2015-05-26 10:01:05 theanets.trainer:168 RmsProp 1180 loss=0.066783 err=0.066783
I 2015-05-26 10:01:06 theanets.trainer:168 validation 118 loss=679.636536 err=679.636536 *
I 2015-05-26 10:01:13 theanets.trainer:168 RmsProp 1181 loss=0.063875 err=0.063875
I 2015-05-26 10:01:20 theanets.trainer:168 RmsProp 1182 loss=0.068534 err=0.068534
I 2015-05-26 10:01:27 theanets.trainer:168 RmsProp 1183 loss=0.059590 err=0.059590
I 2015-05-26 10:01:34 theanets.trainer:168 RmsProp 1184 loss=0.070690 err=0.070690
I 2015-05-26 10:01:41 theanets.trainer:168 RmsProp 1185 loss=0.071433 err=0.071433
I 2015-05-26 10:01:48 theanets.trainer:168 RmsProp 1186 loss=0.064094 err=0.064094
I 2015-05-26 10:01:55 theanets.trainer:168 RmsProp 1187 loss=0.069015 err=0.069015
I 2015-05-26 10:02:02 theanets.trainer:168 RmsProp 1188 loss=0.062591 err=0.062591
I 2015-05-26 10:02:09 theanets.trainer:168 RmsProp 1189 loss=0.075424 err=0.075424
I 2015-05-26 10:02:15 theanets.trainer:168 RmsProp 1190 loss=0.058318 err=0.058318
I 2015-05-26 10:02:16 theanets.trainer:168 validation 119 loss=680.683105 err=680.683105
I 2015-05-26 10:02:22 theanets.trainer:168 RmsProp 1191 loss=0.070107 err=0.070107
I 2015-05-26 10:02:29 theanets.trainer:168 RmsProp 1192 loss=0.065254 err=0.065254
I 2015-05-26 10:02:37 theanets.trainer:168 RmsProp 1193 loss=0.069172 err=0.069172
I 2015-05-26 10:02:44 theanets.trainer:168 RmsProp 1194 loss=0.063589 err=0.063589
I 2015-05-26 10:02:50 theanets.trainer:168 RmsProp 1195 loss=0.069717 err=0.069717
I 2015-05-26 10:02:58 theanets.trainer:168 RmsProp 1196 loss=0.066077 err=0.066077
I 2015-05-26 10:03:05 theanets.trainer:168 RmsProp 1197 loss=0.069713 err=0.069713
I 2015-05-26 10:03:12 theanets.trainer:168 RmsProp 1198 loss=0.065489 err=0.065489
I 2015-05-26 10:03:18 theanets.trainer:168 RmsProp 1199 loss=0.068055 err=0.068055
I 2015-05-26 10:03:25 theanets.trainer:168 RmsProp 1200 loss=0.074558 err=0.074558
I 2015-05-26 10:03:25 theanets.trainer:168 validation 120 loss=679.893250 err=679.893250
I 2015-05-26 10:03:32 theanets.trainer:168 RmsProp 1201 loss=0.058016 err=0.058016
I 2015-05-26 10:03:39 theanets.trainer:168 RmsProp 1202 loss=0.072358 err=0.072358
I 2015-05-26 10:03:46 theanets.trainer:168 RmsProp 1203 loss=0.068961 err=0.068961
I 2015-05-26 10:03:52 theanets.trainer:168 RmsProp 1204 loss=0.065603 err=0.065603
I 2015-05-26 10:03:59 theanets.trainer:168 RmsProp 1205 loss=0.066293 err=0.066293
I 2015-05-26 10:04:05 theanets.trainer:168 RmsProp 1206 loss=0.064871 err=0.064871
I 2015-05-26 10:04:11 theanets.trainer:168 RmsProp 1207 loss=0.068415 err=0.068415
I 2015-05-26 10:04:17 theanets.trainer:168 RmsProp 1208 loss=0.063331 err=0.063331
I 2015-05-26 10:04:24 theanets.trainer:168 RmsProp 1209 loss=0.067052 err=0.067052
I 2015-05-26 10:04:30 theanets.trainer:168 RmsProp 1210 loss=0.061174 err=0.061174
I 2015-05-26 10:04:31 theanets.trainer:168 validation 121 loss=678.825867 err=678.825867 *
I 2015-05-26 10:04:36 theanets.trainer:168 RmsProp 1211 loss=0.069567 err=0.069567
I 2015-05-26 10:04:42 theanets.trainer:168 RmsProp 1212 loss=0.063842 err=0.063842
I 2015-05-26 10:04:49 theanets.trainer:168 RmsProp 1213 loss=0.067520 err=0.067520
I 2015-05-26 10:04:55 theanets.trainer:168 RmsProp 1214 loss=0.072821 err=0.072821
I 2015-05-26 10:05:01 theanets.trainer:168 RmsProp 1215 loss=0.080839 err=0.080839
I 2015-05-26 10:05:07 theanets.trainer:168 RmsProp 1216 loss=0.064761 err=0.064761
I 2015-05-26 10:05:13 theanets.trainer:168 RmsProp 1217 loss=0.063488 err=0.063488
I 2015-05-26 10:05:19 theanets.trainer:168 RmsProp 1218 loss=0.066743 err=0.066743
I 2015-05-26 10:05:25 theanets.trainer:168 RmsProp 1219 loss=0.060576 err=0.060576
I 2015-05-26 10:05:31 theanets.trainer:168 RmsProp 1220 loss=0.061622 err=0.061622
I 2015-05-26 10:05:32 theanets.trainer:168 validation 122 loss=679.462341 err=679.462341
I 2015-05-26 10:05:38 theanets.trainer:168 RmsProp 1221 loss=0.069189 err=0.069189
I 2015-05-26 10:05:44 theanets.trainer:168 RmsProp 1222 loss=0.060882 err=0.060882
I 2015-05-26 10:05:50 theanets.trainer:168 RmsProp 1223 loss=0.083185 err=0.083185
I 2015-05-26 10:05:56 theanets.trainer:168 RmsProp 1224 loss=0.065370 err=0.065370
I 2015-05-26 10:06:02 theanets.trainer:168 RmsProp 1225 loss=0.060246 err=0.060246
I 2015-05-26 10:06:08 theanets.trainer:168 RmsProp 1226 loss=0.073602 err=0.073602
I 2015-05-26 10:06:14 theanets.trainer:168 RmsProp 1227 loss=0.062379 err=0.062379
I 2015-05-26 10:06:20 theanets.trainer:168 RmsProp 1228 loss=0.054502 err=0.054502
I 2015-05-26 10:06:26 theanets.trainer:168 RmsProp 1229 loss=0.093359 err=0.093359
I 2015-05-26 10:06:32 theanets.trainer:168 RmsProp 1230 loss=0.068618 err=0.068618
I 2015-05-26 10:06:32 theanets.trainer:168 validation 123 loss=678.229614 err=678.229614 *
I 2015-05-26 10:06:38 theanets.trainer:168 RmsProp 1231 loss=0.056608 err=0.056608
I 2015-05-26 10:06:44 theanets.trainer:168 RmsProp 1232 loss=0.072412 err=0.072412
I 2015-05-26 10:06:51 theanets.trainer:168 RmsProp 1233 loss=0.056533 err=0.056533
I 2015-05-26 10:06:57 theanets.trainer:168 RmsProp 1234 loss=0.084048 err=0.084048
I 2015-05-26 10:07:03 theanets.trainer:168 RmsProp 1235 loss=0.078867 err=0.078867
I 2015-05-26 10:07:09 theanets.trainer:168 RmsProp 1236 loss=0.060298 err=0.060298
I 2015-05-26 10:07:15 theanets.trainer:168 RmsProp 1237 loss=0.066739 err=0.066739
I 2015-05-26 10:07:21 theanets.trainer:168 RmsProp 1238 loss=0.059215 err=0.059215
I 2015-05-26 10:07:26 theanets.trainer:168 RmsProp 1239 loss=0.066313 err=0.066313
I 2015-05-26 10:07:32 theanets.trainer:168 RmsProp 1240 loss=0.057380 err=0.057380
I 2015-05-26 10:07:32 theanets.trainer:168 validation 124 loss=677.422852 err=677.422852 *
I 2015-05-26 10:07:38 theanets.trainer:168 RmsProp 1241 loss=0.059695 err=0.059695
I 2015-05-26 10:07:44 theanets.trainer:168 RmsProp 1242 loss=0.074627 err=0.074627
I 2015-05-26 10:07:51 theanets.trainer:168 RmsProp 1243 loss=0.063655 err=0.063655
I 2015-05-26 10:07:57 theanets.trainer:168 RmsProp 1244 loss=0.060622 err=0.060622
I 2015-05-26 10:08:02 theanets.trainer:168 RmsProp 1245 loss=0.062772 err=0.062772
I 2015-05-26 10:08:09 theanets.trainer:168 RmsProp 1246 loss=0.074260 err=0.074260
I 2015-05-26 10:08:15 theanets.trainer:168 RmsProp 1247 loss=0.064575 err=0.064575
I 2015-05-26 10:08:21 theanets.trainer:168 RmsProp 1248 loss=0.061329 err=0.061329
I 2015-05-26 10:08:27 theanets.trainer:168 RmsProp 1249 loss=0.062830 err=0.062830
I 2015-05-26 10:08:34 theanets.trainer:168 RmsProp 1250 loss=0.061914 err=0.061914
I 2015-05-26 10:08:34 theanets.trainer:168 validation 125 loss=679.437683 err=679.437683
I 2015-05-26 10:08:40 theanets.trainer:168 RmsProp 1251 loss=0.072118 err=0.072118
I 2015-05-26 10:08:46 theanets.trainer:168 RmsProp 1252 loss=0.073604 err=0.073604
I 2015-05-26 10:08:52 theanets.trainer:168 RmsProp 1253 loss=0.061730 err=0.061730
I 2015-05-26 10:08:58 theanets.trainer:168 RmsProp 1254 loss=0.065193 err=0.065193
I 2015-05-26 10:09:05 theanets.trainer:168 RmsProp 1255 loss=0.060822 err=0.060822
I 2015-05-26 10:09:11 theanets.trainer:168 RmsProp 1256 loss=0.064548 err=0.064548
I 2015-05-26 10:09:16 theanets.trainer:168 RmsProp 1257 loss=0.064710 err=0.064710
I 2015-05-26 10:09:22 theanets.trainer:168 RmsProp 1258 loss=0.061840 err=0.061840
I 2015-05-26 10:09:29 theanets.trainer:168 RmsProp 1259 loss=0.057361 err=0.057361
I 2015-05-26 10:09:35 theanets.trainer:168 RmsProp 1260 loss=0.080534 err=0.080534
I 2015-05-26 10:09:35 theanets.trainer:168 validation 126 loss=677.246399 err=677.246399 *
I 2015-05-26 10:09:41 theanets.trainer:168 RmsProp 1261 loss=0.070171 err=0.070171
I 2015-05-26 10:09:47 theanets.trainer:168 RmsProp 1262 loss=0.060532 err=0.060532
I 2015-05-26 10:09:54 theanets.trainer:168 RmsProp 1263 loss=0.063884 err=0.063884
I 2015-05-26 10:10:00 theanets.trainer:168 RmsProp 1264 loss=0.062083 err=0.062083
I 2015-05-26 10:10:06 theanets.trainer:168 RmsProp 1265 loss=0.063638 err=0.063638
I 2015-05-26 10:10:12 theanets.trainer:168 RmsProp 1266 loss=0.058819 err=0.058819
I 2015-05-26 10:10:18 theanets.trainer:168 RmsProp 1267 loss=0.068751 err=0.068751
I 2015-05-26 10:10:24 theanets.trainer:168 RmsProp 1268 loss=0.061406 err=0.061406
I 2015-05-26 10:10:30 theanets.trainer:168 RmsProp 1269 loss=0.065859 err=0.065859
I 2015-05-26 10:10:37 theanets.trainer:168 RmsProp 1270 loss=0.059824 err=0.059824
I 2015-05-26 10:10:37 theanets.trainer:168 validation 127 loss=678.280945 err=678.280945
I 2015-05-26 10:10:43 theanets.trainer:168 RmsProp 1271 loss=0.069695 err=0.069695
I 2015-05-26 10:10:49 theanets.trainer:168 RmsProp 1272 loss=0.061961 err=0.061961
I 2015-05-26 10:10:55 theanets.trainer:168 RmsProp 1273 loss=0.057117 err=0.057117
I 2015-05-26 10:11:01 theanets.trainer:168 RmsProp 1274 loss=0.073066 err=0.073066
I 2015-05-26 10:11:06 theanets.trainer:168 RmsProp 1275 loss=0.055058 err=0.055058
I 2015-05-26 10:11:11 theanets.trainer:168 RmsProp 1276 loss=0.068287 err=0.068287
I 2015-05-26 10:11:17 theanets.trainer:168 RmsProp 1277 loss=0.061902 err=0.061902
I 2015-05-26 10:11:22 theanets.trainer:168 RmsProp 1278 loss=0.069012 err=0.069012
I 2015-05-26 10:11:28 theanets.trainer:168 RmsProp 1279 loss=0.063674 err=0.063674
I 2015-05-26 10:11:33 theanets.trainer:168 RmsProp 1280 loss=0.060492 err=0.060492
I 2015-05-26 10:11:33 theanets.trainer:168 validation 128 loss=676.183716 err=676.183716 *
I 2015-05-26 10:11:39 theanets.trainer:168 RmsProp 1281 loss=0.061902 err=0.061902
I 2015-05-26 10:11:44 theanets.trainer:168 RmsProp 1282 loss=0.059954 err=0.059954
I 2015-05-26 10:11:50 theanets.trainer:168 RmsProp 1283 loss=0.058660 err=0.058660
I 2015-05-26 10:11:55 theanets.trainer:168 RmsProp 1284 loss=0.059296 err=0.059296
I 2015-05-26 10:12:01 theanets.trainer:168 RmsProp 1285 loss=0.064516 err=0.064516
I 2015-05-26 10:12:07 theanets.trainer:168 RmsProp 1286 loss=0.065401 err=0.065401
I 2015-05-26 10:12:13 theanets.trainer:168 RmsProp 1287 loss=0.071184 err=0.071184
I 2015-05-26 10:12:19 theanets.trainer:168 RmsProp 1288 loss=0.063373 err=0.063373
I 2015-05-26 10:12:26 theanets.trainer:168 RmsProp 1289 loss=0.054736 err=0.054736
I 2015-05-26 10:12:32 theanets.trainer:168 RmsProp 1290 loss=0.070998 err=0.070998
I 2015-05-26 10:12:32 theanets.trainer:168 validation 129 loss=676.687073 err=676.687073
I 2015-05-26 10:12:38 theanets.trainer:168 RmsProp 1291 loss=0.059319 err=0.059319
I 2015-05-26 10:12:44 theanets.trainer:168 RmsProp 1292 loss=0.062022 err=0.062022
I 2015-05-26 10:12:51 theanets.trainer:168 RmsProp 1293 loss=0.059699 err=0.059699
I 2015-05-26 10:12:57 theanets.trainer:168 RmsProp 1294 loss=0.081281 err=0.081281
I 2015-05-26 10:13:03 theanets.trainer:168 RmsProp 1295 loss=0.057380 err=0.057380
I 2015-05-26 10:13:09 theanets.trainer:168 RmsProp 1296 loss=0.062303 err=0.062303
I 2015-05-26 10:13:15 theanets.trainer:168 RmsProp 1297 loss=0.060508 err=0.060508
I 2015-05-26 10:13:22 theanets.trainer:168 RmsProp 1298 loss=0.057235 err=0.057235
I 2015-05-26 10:13:28 theanets.trainer:168 RmsProp 1299 loss=0.059183 err=0.059183
I 2015-05-26 10:13:33 theanets.trainer:168 RmsProp 1300 loss=0.053868 err=0.053868
I 2015-05-26 10:13:34 theanets.trainer:168 validation 130 loss=674.851013 err=674.851013 *
I 2015-05-26 10:13:40 theanets.trainer:168 RmsProp 1301 loss=0.077896 err=0.077896
I 2015-05-26 10:13:46 theanets.trainer:168 RmsProp 1302 loss=0.059530 err=0.059530
I 2015-05-26 10:13:52 theanets.trainer:168 RmsProp 1303 loss=0.061078 err=0.061078
I 2015-05-26 10:13:58 theanets.trainer:168 RmsProp 1304 loss=0.062957 err=0.062957
I 2015-05-26 10:14:04 theanets.trainer:168 RmsProp 1305 loss=0.062751 err=0.062751
I 2015-05-26 10:14:11 theanets.trainer:168 RmsProp 1306 loss=0.061113 err=0.061113
I 2015-05-26 10:14:17 theanets.trainer:168 RmsProp 1307 loss=0.053732 err=0.053732
I 2015-05-26 10:14:23 theanets.trainer:168 RmsProp 1308 loss=0.073272 err=0.073272
I 2015-05-26 10:14:29 theanets.trainer:168 RmsProp 1309 loss=0.062494 err=0.062494
I 2015-05-26 10:14:36 theanets.trainer:168 RmsProp 1310 loss=0.058453 err=0.058453
I 2015-05-26 10:14:36 theanets.trainer:168 validation 131 loss=676.177734 err=676.177734
I 2015-05-26 10:14:41 theanets.trainer:168 RmsProp 1311 loss=0.061143 err=0.061143
I 2015-05-26 10:14:47 theanets.trainer:168 RmsProp 1312 loss=0.070394 err=0.070394
I 2015-05-26 10:14:54 theanets.trainer:168 RmsProp 1313 loss=0.054325 err=0.054325
I 2015-05-26 10:15:00 theanets.trainer:168 RmsProp 1314 loss=0.069412 err=0.069412
I 2015-05-26 10:15:06 theanets.trainer:168 RmsProp 1315 loss=0.061436 err=0.061436
I 2015-05-26 10:15:12 theanets.trainer:168 RmsProp 1316 loss=0.065525 err=0.065525
I 2015-05-26 10:15:18 theanets.trainer:168 RmsProp 1317 loss=0.059810 err=0.059810
I 2015-05-26 10:15:23 theanets.trainer:168 RmsProp 1318 loss=0.062923 err=0.062923
I 2015-05-26 10:15:28 theanets.trainer:168 RmsProp 1319 loss=0.058465 err=0.058465
I 2015-05-26 10:15:34 theanets.trainer:168 RmsProp 1320 loss=0.057634 err=0.057634
I 2015-05-26 10:15:34 theanets.trainer:168 validation 132 loss=674.563904 err=674.563904 *
I 2015-05-26 10:15:40 theanets.trainer:168 RmsProp 1321 loss=0.063010 err=0.063010
I 2015-05-26 10:15:47 theanets.trainer:168 RmsProp 1322 loss=0.057729 err=0.057729
I 2015-05-26 10:15:53 theanets.trainer:168 RmsProp 1323 loss=0.060108 err=0.060108
I 2015-05-26 10:15:59 theanets.trainer:168 RmsProp 1324 loss=0.061632 err=0.061632
I 2015-05-26 10:16:05 theanets.trainer:168 RmsProp 1325 loss=0.058354 err=0.058354
I 2015-05-26 10:16:11 theanets.trainer:168 RmsProp 1326 loss=0.069735 err=0.069735
I 2015-05-26 10:16:17 theanets.trainer:168 RmsProp 1327 loss=0.057223 err=0.057223
I 2015-05-26 10:16:23 theanets.trainer:168 RmsProp 1328 loss=0.060351 err=0.060351
I 2015-05-26 10:16:30 theanets.trainer:168 RmsProp 1329 loss=0.056550 err=0.056550
I 2015-05-26 10:16:35 theanets.trainer:168 RmsProp 1330 loss=0.071397 err=0.071397
I 2015-05-26 10:16:36 theanets.trainer:168 validation 133 loss=674.623230 err=674.623230
I 2015-05-26 10:16:41 theanets.trainer:168 RmsProp 1331 loss=0.071255 err=0.071255
I 2015-05-26 10:16:48 theanets.trainer:168 RmsProp 1332 loss=0.061456 err=0.061456
I 2015-05-26 10:16:54 theanets.trainer:168 RmsProp 1333 loss=0.055212 err=0.055212
I 2015-05-26 10:17:00 theanets.trainer:168 RmsProp 1334 loss=0.059732 err=0.059732
I 2015-05-26 10:17:06 theanets.trainer:168 RmsProp 1335 loss=0.060459 err=0.060459
I 2015-05-26 10:17:12 theanets.trainer:168 RmsProp 1336 loss=0.056679 err=0.056679
I 2015-05-26 10:17:18 theanets.trainer:168 RmsProp 1337 loss=0.054806 err=0.054806
I 2015-05-26 10:17:24 theanets.trainer:168 RmsProp 1338 loss=0.076249 err=0.076249
I 2015-05-26 10:17:30 theanets.trainer:168 RmsProp 1339 loss=0.068501 err=0.068501
I 2015-05-26 10:17:36 theanets.trainer:168 RmsProp 1340 loss=0.050503 err=0.050503
I 2015-05-26 10:17:36 theanets.trainer:168 validation 134 loss=675.429016 err=675.429016
I 2015-05-26 10:17:42 theanets.trainer:168 RmsProp 1341 loss=0.071136 err=0.071136
I 2015-05-26 10:17:48 theanets.trainer:168 RmsProp 1342 loss=0.054593 err=0.054593
I 2015-05-26 10:17:55 theanets.trainer:168 RmsProp 1343 loss=0.066631 err=0.066631
I 2015-05-26 10:18:01 theanets.trainer:168 RmsProp 1344 loss=0.058288 err=0.058288
I 2015-05-26 10:18:06 theanets.trainer:168 RmsProp 1345 loss=0.058818 err=0.058818
I 2015-05-26 10:18:12 theanets.trainer:168 RmsProp 1346 loss=0.061142 err=0.061142
I 2015-05-26 10:18:18 theanets.trainer:168 RmsProp 1347 loss=0.057391 err=0.057391
I 2015-05-26 10:18:24 theanets.trainer:168 RmsProp 1348 loss=0.052543 err=0.052543
I 2015-05-26 10:18:30 theanets.trainer:168 RmsProp 1349 loss=0.055217 err=0.055217
I 2015-05-26 10:18:36 theanets.trainer:168 RmsProp 1350 loss=0.059976 err=0.059976
I 2015-05-26 10:18:37 theanets.trainer:168 validation 135 loss=675.708130 err=675.708130
I 2015-05-26 10:18:42 theanets.trainer:168 RmsProp 1351 loss=0.059909 err=0.059909
I 2015-05-26 10:18:49 theanets.trainer:168 RmsProp 1352 loss=0.058991 err=0.058991
I 2015-05-26 10:18:55 theanets.trainer:168 RmsProp 1353 loss=0.062236 err=0.062236
I 2015-05-26 10:19:01 theanets.trainer:168 RmsProp 1354 loss=0.050360 err=0.050360
I 2015-05-26 10:19:07 theanets.trainer:168 RmsProp 1355 loss=0.072892 err=0.072892
I 2015-05-26 10:19:13 theanets.trainer:168 RmsProp 1356 loss=0.071952 err=0.071952
I 2015-05-26 10:19:19 theanets.trainer:168 RmsProp 1357 loss=0.059479 err=0.059479
I 2015-05-26 10:19:25 theanets.trainer:168 RmsProp 1358 loss=0.060540 err=0.060540
I 2015-05-26 10:19:31 theanets.trainer:168 RmsProp 1359 loss=0.058234 err=0.058234
I 2015-05-26 10:19:37 theanets.trainer:168 RmsProp 1360 loss=0.051883 err=0.051883
I 2015-05-26 10:19:38 theanets.trainer:168 validation 136 loss=675.848755 err=675.848755
I 2015-05-26 10:19:43 theanets.trainer:168 RmsProp 1361 loss=0.082034 err=0.082034
I 2015-05-26 10:19:50 theanets.trainer:168 RmsProp 1362 loss=0.060302 err=0.060302
I 2015-05-26 10:19:56 theanets.trainer:168 RmsProp 1363 loss=0.071574 err=0.071574
I 2015-05-26 10:20:02 theanets.trainer:168 RmsProp 1364 loss=0.059343 err=0.059343
I 2015-05-26 10:20:07 theanets.trainer:168 RmsProp 1365 loss=0.055335 err=0.055335
I 2015-05-26 10:20:13 theanets.trainer:168 RmsProp 1366 loss=0.063510 err=0.063510
I 2015-05-26 10:20:19 theanets.trainer:168 RmsProp 1367 loss=0.056604 err=0.056604
I 2015-05-26 10:20:25 theanets.trainer:168 RmsProp 1368 loss=0.054207 err=0.054207
I 2015-05-26 10:20:31 theanets.trainer:168 RmsProp 1369 loss=0.072202 err=0.072202
I 2015-05-26 10:20:37 theanets.trainer:168 RmsProp 1370 loss=0.053922 err=0.053922
I 2015-05-26 10:20:38 theanets.trainer:168 validation 137 loss=674.416626 err=674.416626 *
I 2015-05-26 10:20:43 theanets.trainer:168 RmsProp 1371 loss=0.058852 err=0.058852
I 2015-05-26 10:20:49 theanets.trainer:168 RmsProp 1372 loss=0.059338 err=0.059338
I 2015-05-26 10:20:54 theanets.trainer:168 RmsProp 1373 loss=0.055786 err=0.055786
I 2015-05-26 10:21:00 theanets.trainer:168 RmsProp 1374 loss=0.060978 err=0.060978
I 2015-05-26 10:21:05 theanets.trainer:168 RmsProp 1375 loss=0.058008 err=0.058008
I 2015-05-26 10:21:10 theanets.trainer:168 RmsProp 1376 loss=0.060924 err=0.060924
I 2015-05-26 10:21:17 theanets.trainer:168 RmsProp 1377 loss=0.067920 err=0.067920
I 2015-05-26 10:21:23 theanets.trainer:168 RmsProp 1378 loss=0.054601 err=0.054601
I 2015-05-26 10:21:29 theanets.trainer:168 RmsProp 1379 loss=0.057071 err=0.057071
I 2015-05-26 10:21:36 theanets.trainer:168 RmsProp 1380 loss=0.059858 err=0.059858
I 2015-05-26 10:21:36 theanets.trainer:168 validation 138 loss=673.821167 err=673.821167 *
I 2015-05-26 10:21:41 theanets.trainer:168 RmsProp 1381 loss=0.055014 err=0.055014
I 2015-05-26 10:21:47 theanets.trainer:168 RmsProp 1382 loss=0.060553 err=0.060553
I 2015-05-26 10:21:53 theanets.trainer:168 RmsProp 1383 loss=0.056346 err=0.056346
I 2015-05-26 10:21:59 theanets.trainer:168 RmsProp 1384 loss=0.062023 err=0.062023
I 2015-05-26 10:22:05 theanets.trainer:168 RmsProp 1385 loss=0.057969 err=0.057969
I 2015-05-26 10:22:12 theanets.trainer:168 RmsProp 1386 loss=0.067184 err=0.067184
I 2015-05-26 10:22:18 theanets.trainer:168 RmsProp 1387 loss=0.058460 err=0.058460
I 2015-05-26 10:22:24 theanets.trainer:168 RmsProp 1388 loss=0.053495 err=0.053495
I 2015-05-26 10:22:30 theanets.trainer:168 RmsProp 1389 loss=0.065959 err=0.065959
I 2015-05-26 10:22:36 theanets.trainer:168 RmsProp 1390 loss=0.056205 err=0.056205
I 2015-05-26 10:22:37 theanets.trainer:168 validation 139 loss=672.082520 err=672.082520 *
I 2015-05-26 10:22:43 theanets.trainer:168 RmsProp 1391 loss=0.056410 err=0.056410
I 2015-05-26 10:22:48 theanets.trainer:168 RmsProp 1392 loss=0.054915 err=0.054915
I 2015-05-26 10:22:55 theanets.trainer:168 RmsProp 1393 loss=0.068734 err=0.068734
I 2015-05-26 10:23:01 theanets.trainer:168 RmsProp 1394 loss=0.052678 err=0.052678
I 2015-05-26 10:23:07 theanets.trainer:168 RmsProp 1395 loss=0.062810 err=0.062810
I 2015-05-26 10:23:13 theanets.trainer:168 RmsProp 1396 loss=0.062605 err=0.062605
I 2015-05-26 10:23:19 theanets.trainer:168 RmsProp 1397 loss=0.073974 err=0.073974
I 2015-05-26 10:23:25 theanets.trainer:168 RmsProp 1398 loss=0.053144 err=0.053144
I 2015-05-26 10:23:32 theanets.trainer:168 RmsProp 1399 loss=0.053177 err=0.053177
I 2015-05-26 10:23:38 theanets.trainer:168 RmsProp 1400 loss=0.063208 err=0.063208
I 2015-05-26 10:23:38 theanets.trainer:168 validation 140 loss=672.504578 err=672.504578
I 2015-05-26 10:23:44 theanets.trainer:168 RmsProp 1401 loss=0.065547 err=0.065547
I 2015-05-26 10:23:50 theanets.trainer:168 RmsProp 1402 loss=0.055670 err=0.055670
I 2015-05-26 10:23:55 theanets.trainer:168 RmsProp 1403 loss=0.060294 err=0.060294
I 2015-05-26 10:24:02 theanets.trainer:168 RmsProp 1404 loss=0.058109 err=0.058109
I 2015-05-26 10:24:08 theanets.trainer:168 RmsProp 1405 loss=0.055449 err=0.055449
I 2015-05-26 10:24:14 theanets.trainer:168 RmsProp 1406 loss=0.056381 err=0.056381
I 2015-05-26 10:24:21 theanets.trainer:168 RmsProp 1407 loss=0.060557 err=0.060557
I 2015-05-26 10:24:27 theanets.trainer:168 RmsProp 1408 loss=0.054482 err=0.054482
I 2015-05-26 10:24:33 theanets.trainer:168 RmsProp 1409 loss=0.073984 err=0.073984
I 2015-05-26 10:24:39 theanets.trainer:168 RmsProp 1410 loss=0.055135 err=0.055135
I 2015-05-26 10:24:39 theanets.trainer:168 validation 141 loss=673.200867 err=673.200867
I 2015-05-26 10:24:45 theanets.trainer:168 RmsProp 1411 loss=0.053575 err=0.053575
I 2015-05-26 10:24:51 theanets.trainer:168 RmsProp 1412 loss=0.062010 err=0.062010
I 2015-05-26 10:24:58 theanets.trainer:168 RmsProp 1413 loss=0.055363 err=0.055363
I 2015-05-26 10:25:04 theanets.trainer:168 RmsProp 1414 loss=0.063341 err=0.063341
I 2015-05-26 10:25:10 theanets.trainer:168 RmsProp 1415 loss=0.055400 err=0.055400
I 2015-05-26 10:25:16 theanets.trainer:168 RmsProp 1416 loss=0.061932 err=0.061932
I 2015-05-26 10:25:23 theanets.trainer:168 RmsProp 1417 loss=0.060102 err=0.060102
I 2015-05-26 10:25:29 theanets.trainer:168 RmsProp 1418 loss=0.054081 err=0.054081
I 2015-05-26 10:25:35 theanets.trainer:168 RmsProp 1419 loss=0.064816 err=0.064816
I 2015-05-26 10:25:41 theanets.trainer:168 RmsProp 1420 loss=0.065480 err=0.065480
I 2015-05-26 10:25:41 theanets.trainer:168 validation 142 loss=671.599365 err=671.599365 *
I 2015-05-26 10:25:47 theanets.trainer:168 RmsProp 1421 loss=0.055773 err=0.055773
I 2015-05-26 10:25:52 theanets.trainer:168 RmsProp 1422 loss=0.055845 err=0.055845
I 2015-05-26 10:25:59 theanets.trainer:168 RmsProp 1423 loss=0.058933 err=0.058933
I 2015-05-26 10:26:05 theanets.trainer:168 RmsProp 1424 loss=0.056843 err=0.056843
I 2015-05-26 10:26:11 theanets.trainer:168 RmsProp 1425 loss=0.062605 err=0.062605
I 2015-05-26 10:26:17 theanets.trainer:168 RmsProp 1426 loss=0.070754 err=0.070754
I 2015-05-26 10:26:24 theanets.trainer:168 RmsProp 1427 loss=0.047513 err=0.047513
I 2015-05-26 10:26:30 theanets.trainer:168 RmsProp 1428 loss=0.063961 err=0.063961
I 2015-05-26 10:26:36 theanets.trainer:168 RmsProp 1429 loss=0.059705 err=0.059705
I 2015-05-26 10:26:42 theanets.trainer:168 RmsProp 1430 loss=0.049546 err=0.049546
I 2015-05-26 10:26:43 theanets.trainer:168 validation 143 loss=673.011169 err=673.011169
I 2015-05-26 10:26:49 theanets.trainer:168 RmsProp 1431 loss=0.060251 err=0.060251
I 2015-05-26 10:26:55 theanets.trainer:168 RmsProp 1432 loss=0.058567 err=0.058567
I 2015-05-26 10:27:01 theanets.trainer:168 RmsProp 1433 loss=0.050725 err=0.050725
I 2015-05-26 10:27:07 theanets.trainer:168 RmsProp 1434 loss=0.063063 err=0.063063
I 2015-05-26 10:27:13 theanets.trainer:168 RmsProp 1435 loss=0.047911 err=0.047911
I 2015-05-26 10:27:20 theanets.trainer:168 RmsProp 1436 loss=0.066606 err=0.066606
I 2015-05-26 10:27:26 theanets.trainer:168 RmsProp 1437 loss=0.053867 err=0.053867
I 2015-05-26 10:27:32 theanets.trainer:168 RmsProp 1438 loss=0.061429 err=0.061429
I 2015-05-26 10:27:38 theanets.trainer:168 RmsProp 1439 loss=0.056265 err=0.056265
I 2015-05-26 10:27:44 theanets.trainer:168 RmsProp 1440 loss=0.065242 err=0.065242
I 2015-05-26 10:27:45 theanets.trainer:168 validation 144 loss=670.782654 err=670.782654 *
I 2015-05-26 10:27:51 theanets.trainer:168 RmsProp 1441 loss=0.056208 err=0.056208
I 2015-05-26 10:27:57 theanets.trainer:168 RmsProp 1442 loss=0.056431 err=0.056431
I 2015-05-26 10:28:03 theanets.trainer:168 RmsProp 1443 loss=0.051464 err=0.051464
I 2015-05-26 10:28:09 theanets.trainer:168 RmsProp 1444 loss=0.057799 err=0.057799
I 2015-05-26 10:28:15 theanets.trainer:168 RmsProp 1445 loss=0.055810 err=0.055810
I 2015-05-26 10:28:21 theanets.trainer:168 RmsProp 1446 loss=0.052559 err=0.052559
I 2015-05-26 10:28:28 theanets.trainer:168 RmsProp 1447 loss=0.050481 err=0.050481
I 2015-05-26 10:28:34 theanets.trainer:168 RmsProp 1448 loss=0.081333 err=0.081333
I 2015-05-26 10:28:40 theanets.trainer:168 RmsProp 1449 loss=0.058436 err=0.058436
I 2015-05-26 10:28:47 theanets.trainer:168 RmsProp 1450 loss=0.058235 err=0.058235
I 2015-05-26 10:28:47 theanets.trainer:168 validation 145 loss=672.505554 err=672.505554
I 2015-05-26 10:28:53 theanets.trainer:168 RmsProp 1451 loss=0.054083 err=0.054083
I 2015-05-26 10:28:59 theanets.trainer:168 RmsProp 1452 loss=0.057137 err=0.057137
I 2015-05-26 10:29:05 theanets.trainer:168 RmsProp 1453 loss=0.054204 err=0.054204
I 2015-05-26 10:29:11 theanets.trainer:168 RmsProp 1454 loss=0.057121 err=0.057121
I 2015-05-26 10:29:17 theanets.trainer:168 RmsProp 1455 loss=0.056461 err=0.056461
I 2015-05-26 10:29:24 theanets.trainer:168 RmsProp 1456 loss=0.052944 err=0.052944
I 2015-05-26 10:29:30 theanets.trainer:168 RmsProp 1457 loss=0.065300 err=0.065300
I 2015-05-26 10:29:36 theanets.trainer:168 RmsProp 1458 loss=0.054182 err=0.054182
I 2015-05-26 10:29:42 theanets.trainer:168 RmsProp 1459 loss=0.054672 err=0.054672
I 2015-05-26 10:29:49 theanets.trainer:168 RmsProp 1460 loss=0.053415 err=0.053415
I 2015-05-26 10:29:49 theanets.trainer:168 validation 146 loss=673.201599 err=673.201599
I 2015-05-26 10:29:55 theanets.trainer:168 RmsProp 1461 loss=0.068936 err=0.068936
I 2015-05-26 10:30:01 theanets.trainer:168 RmsProp 1462 loss=0.051307 err=0.051307
I 2015-05-26 10:30:08 theanets.trainer:168 RmsProp 1463 loss=0.054996 err=0.054996
I 2015-05-26 10:30:14 theanets.trainer:168 RmsProp 1464 loss=0.062359 err=0.062359
I 2015-05-26 10:30:20 theanets.trainer:168 RmsProp 1465 loss=0.051446 err=0.051446
I 2015-05-26 10:30:26 theanets.trainer:168 RmsProp 1466 loss=0.062323 err=0.062323
I 2015-05-26 10:30:32 theanets.trainer:168 RmsProp 1467 loss=0.050012 err=0.050012
I 2015-05-26 10:30:39 theanets.trainer:168 RmsProp 1468 loss=0.066467 err=0.066467
I 2015-05-26 10:30:45 theanets.trainer:168 RmsProp 1469 loss=0.058229 err=0.058229
I 2015-05-26 10:30:51 theanets.trainer:168 RmsProp 1470 loss=0.056162 err=0.056162
I 2015-05-26 10:30:52 theanets.trainer:168 validation 147 loss=670.633789 err=670.633789 *
I 2015-05-26 10:30:57 theanets.trainer:168 RmsProp 1471 loss=0.052582 err=0.052582
I 2015-05-26 10:31:04 theanets.trainer:168 RmsProp 1472 loss=0.070941 err=0.070941
I 2015-05-26 10:31:10 theanets.trainer:168 RmsProp 1473 loss=0.049870 err=0.049870
I 2015-05-26 10:31:15 theanets.trainer:168 RmsProp 1474 loss=0.063249 err=0.063249
I 2015-05-26 10:31:21 theanets.trainer:168 RmsProp 1475 loss=0.070297 err=0.070297
I 2015-05-26 10:31:26 theanets.trainer:168 RmsProp 1476 loss=0.052023 err=0.052023
I 2015-05-26 10:31:32 theanets.trainer:168 RmsProp 1477 loss=0.052111 err=0.052111
I 2015-05-26 10:31:37 theanets.trainer:168 RmsProp 1478 loss=0.061299 err=0.061299
I 2015-05-26 10:31:43 theanets.trainer:168 RmsProp 1479 loss=0.056199 err=0.056199
I 2015-05-26 10:31:49 theanets.trainer:168 RmsProp 1480 loss=0.053434 err=0.053434
I 2015-05-26 10:31:49 theanets.trainer:168 validation 148 loss=669.517761 err=669.517761 *
I 2015-05-26 10:31:55 theanets.trainer:168 RmsProp 1481 loss=0.052238 err=0.052238
I 2015-05-26 10:32:02 theanets.trainer:168 RmsProp 1482 loss=0.055307 err=0.055307
I 2015-05-26 10:32:08 theanets.trainer:168 RmsProp 1483 loss=0.053109 err=0.053109
I 2015-05-26 10:32:14 theanets.trainer:168 RmsProp 1484 loss=0.059041 err=0.059041
I 2015-05-26 10:32:20 theanets.trainer:168 RmsProp 1485 loss=0.057411 err=0.057411
I 2015-05-26 10:32:26 theanets.trainer:168 RmsProp 1486 loss=0.053883 err=0.053883
I 2015-05-26 10:32:32 theanets.trainer:168 RmsProp 1487 loss=0.054279 err=0.054279
I 2015-05-26 10:32:39 theanets.trainer:168 RmsProp 1488 loss=0.051516 err=0.051516
I 2015-05-26 10:32:44 theanets.trainer:168 RmsProp 1489 loss=0.059827 err=0.059827
I 2015-05-26 10:32:50 theanets.trainer:168 RmsProp 1490 loss=0.057663 err=0.057663
I 2015-05-26 10:32:51 theanets.trainer:168 validation 149 loss=670.379150 err=670.379150
I 2015-05-26 10:32:57 theanets.trainer:168 RmsProp 1491 loss=0.058930 err=0.058930
I 2015-05-26 10:33:03 theanets.trainer:168 RmsProp 1492 loss=0.060286 err=0.060286
I 2015-05-26 10:33:09 theanets.trainer:168 RmsProp 1493 loss=0.047472 err=0.047472
I 2015-05-26 10:33:15 theanets.trainer:168 RmsProp 1494 loss=0.065357 err=0.065357
I 2015-05-26 10:33:22 theanets.trainer:168 RmsProp 1495 loss=0.054473 err=0.054473
I 2015-05-26 10:33:28 theanets.trainer:168 RmsProp 1496 loss=0.056898 err=0.056898
I 2015-05-26 10:33:34 theanets.trainer:168 RmsProp 1497 loss=0.058894 err=0.058894
I 2015-05-26 10:33:40 theanets.trainer:168 RmsProp 1498 loss=0.051897 err=0.051897
I 2015-05-26 10:33:46 theanets.trainer:168 RmsProp 1499 loss=0.058628 err=0.058628
I 2015-05-26 10:33:52 theanets.trainer:168 RmsProp 1500 loss=0.050303 err=0.050303
I 2015-05-26 10:33:53 theanets.trainer:168 validation 150 loss=671.474915 err=671.474915
I 2015-05-26 10:33:58 theanets.trainer:168 RmsProp 1501 loss=0.054068 err=0.054068
I 2015-05-26 10:34:05 theanets.trainer:168 RmsProp 1502 loss=0.053240 err=0.053240
I 2015-05-26 10:34:11 theanets.trainer:168 RmsProp 1503 loss=0.052221 err=0.052221
I 2015-05-26 10:34:17 theanets.trainer:168 RmsProp 1504 loss=0.063678 err=0.063678
I 2015-05-26 10:34:23 theanets.trainer:168 RmsProp 1505 loss=0.061103 err=0.061103
I 2015-05-26 10:34:30 theanets.trainer:168 RmsProp 1506 loss=0.047352 err=0.047352
I 2015-05-26 10:34:36 theanets.trainer:168 RmsProp 1507 loss=0.061882 err=0.061882
I 2015-05-26 10:34:42 theanets.trainer:168 RmsProp 1508 loss=0.050702 err=0.050702
I 2015-05-26 10:34:48 theanets.trainer:168 RmsProp 1509 loss=0.055795 err=0.055795
I 2015-05-26 10:34:55 theanets.trainer:168 RmsProp 1510 loss=0.061231 err=0.061231
I 2015-05-26 10:34:55 theanets.trainer:168 validation 151 loss=670.261841 err=670.261841
I 2015-05-26 10:35:01 theanets.trainer:168 RmsProp 1511 loss=0.053830 err=0.053830
I 2015-05-26 10:35:07 theanets.trainer:168 RmsProp 1512 loss=0.050079 err=0.050079
I 2015-05-26 10:35:13 theanets.trainer:168 RmsProp 1513 loss=0.061452 err=0.061452
I 2015-05-26 10:35:19 theanets.trainer:168 RmsProp 1514 loss=0.063338 err=0.063338
I 2015-05-26 10:35:26 theanets.trainer:168 RmsProp 1515 loss=0.050576 err=0.050576
I 2015-05-26 10:35:31 theanets.trainer:168 RmsProp 1516 loss=0.058751 err=0.058751
I 2015-05-26 10:35:37 theanets.trainer:168 RmsProp 1517 loss=0.056114 err=0.056114
I 2015-05-26 10:35:44 theanets.trainer:168 RmsProp 1518 loss=0.050260 err=0.050260
I 2015-05-26 10:35:50 theanets.trainer:168 RmsProp 1519 loss=0.064949 err=0.064949
I 2015-05-26 10:35:56 theanets.trainer:168 RmsProp 1520 loss=0.055120 err=0.055120
I 2015-05-26 10:35:56 theanets.trainer:168 validation 152 loss=668.967773 err=668.967773 *
I 2015-05-26 10:36:02 theanets.trainer:168 RmsProp 1521 loss=0.048053 err=0.048053
I 2015-05-26 10:36:09 theanets.trainer:168 RmsProp 1522 loss=0.058201 err=0.058201
I 2015-05-26 10:36:15 theanets.trainer:168 RmsProp 1523 loss=0.056043 err=0.056043
I 2015-05-26 10:36:21 theanets.trainer:168 RmsProp 1524 loss=0.053191 err=0.053191
I 2015-05-26 10:36:27 theanets.trainer:168 RmsProp 1525 loss=0.055876 err=0.055876
I 2015-05-26 10:36:34 theanets.trainer:168 RmsProp 1526 loss=0.048594 err=0.048594
I 2015-05-26 10:36:40 theanets.trainer:168 RmsProp 1527 loss=0.059747 err=0.059747
I 2015-05-26 10:36:46 theanets.trainer:168 RmsProp 1528 loss=0.051388 err=0.051388
I 2015-05-26 10:36:52 theanets.trainer:168 RmsProp 1529 loss=0.052826 err=0.052826
I 2015-05-26 10:36:58 theanets.trainer:168 RmsProp 1530 loss=0.055859 err=0.055859
I 2015-05-26 10:36:59 theanets.trainer:168 validation 153 loss=668.929504 err=668.929504 *
I 2015-05-26 10:37:04 theanets.trainer:168 RmsProp 1531 loss=0.055458 err=0.055458
I 2015-05-26 10:37:10 theanets.trainer:168 RmsProp 1532 loss=0.053646 err=0.053646
I 2015-05-26 10:37:16 theanets.trainer:168 RmsProp 1533 loss=0.053027 err=0.053027
I 2015-05-26 10:37:23 theanets.trainer:168 RmsProp 1534 loss=0.052418 err=0.052418
I 2015-05-26 10:37:29 theanets.trainer:168 RmsProp 1535 loss=0.051497 err=0.051497
I 2015-05-26 10:37:35 theanets.trainer:168 RmsProp 1536 loss=0.062671 err=0.062671
I 2015-05-26 10:37:41 theanets.trainer:168 RmsProp 1537 loss=0.049403 err=0.049403
I 2015-05-26 10:37:48 theanets.trainer:168 RmsProp 1538 loss=0.058836 err=0.058836
I 2015-05-26 10:37:54 theanets.trainer:168 RmsProp 1539 loss=0.067234 err=0.067234
I 2015-05-26 10:38:00 theanets.trainer:168 RmsProp 1540 loss=0.053211 err=0.053211
I 2015-05-26 10:38:00 theanets.trainer:168 validation 154 loss=667.916199 err=667.916199 *
I 2015-05-26 10:38:06 theanets.trainer:168 RmsProp 1541 loss=0.063823 err=0.063823
I 2015-05-26 10:38:12 theanets.trainer:168 RmsProp 1542 loss=0.048511 err=0.048511
I 2015-05-26 10:38:19 theanets.trainer:168 RmsProp 1543 loss=0.060370 err=0.060370
I 2015-05-26 10:38:25 theanets.trainer:168 RmsProp 1544 loss=0.056055 err=0.056055
I 2015-05-26 10:38:31 theanets.trainer:168 RmsProp 1545 loss=0.054096 err=0.054096
I 2015-05-26 10:38:37 theanets.trainer:168 RmsProp 1546 loss=0.056385 err=0.056385
I 2015-05-26 10:38:43 theanets.trainer:168 RmsProp 1547 loss=0.057974 err=0.057974
I 2015-05-26 10:38:50 theanets.trainer:168 RmsProp 1548 loss=0.051453 err=0.051453
I 2015-05-26 10:38:55 theanets.trainer:168 RmsProp 1549 loss=0.058996 err=0.058996
I 2015-05-26 10:39:01 theanets.trainer:168 RmsProp 1550 loss=0.061628 err=0.061628
I 2015-05-26 10:39:01 theanets.trainer:168 validation 155 loss=668.211060 err=668.211060
I 2015-05-26 10:39:06 theanets.trainer:168 RmsProp 1551 loss=0.052194 err=0.052194
I 2015-05-26 10:39:13 theanets.trainer:168 RmsProp 1552 loss=0.044836 err=0.044836
I 2015-05-26 10:39:19 theanets.trainer:168 RmsProp 1553 loss=0.064754 err=0.064754
I 2015-05-26 10:39:25 theanets.trainer:168 RmsProp 1554 loss=0.049116 err=0.049116
I 2015-05-26 10:39:31 theanets.trainer:168 RmsProp 1555 loss=0.054603 err=0.054603
I 2015-05-26 10:39:37 theanets.trainer:168 RmsProp 1556 loss=0.063108 err=0.063108
I 2015-05-26 10:39:43 theanets.trainer:168 RmsProp 1557 loss=0.053559 err=0.053559
I 2015-05-26 10:39:50 theanets.trainer:168 RmsProp 1558 loss=0.051781 err=0.051781
I 2015-05-26 10:39:56 theanets.trainer:168 RmsProp 1559 loss=0.055095 err=0.055095
I 2015-05-26 10:40:02 theanets.trainer:168 RmsProp 1560 loss=0.050540 err=0.050540
I 2015-05-26 10:40:03 theanets.trainer:168 validation 156 loss=666.752380 err=666.752380 *
I 2015-05-26 10:40:08 theanets.trainer:168 RmsProp 1561 loss=0.056217 err=0.056217
I 2015-05-26 10:40:15 theanets.trainer:168 RmsProp 1562 loss=0.052443 err=0.052443
I 2015-05-26 10:40:21 theanets.trainer:168 RmsProp 1563 loss=0.052912 err=0.052912
I 2015-05-26 10:40:27 theanets.trainer:168 RmsProp 1564 loss=0.047058 err=0.047058
I 2015-05-26 10:40:33 theanets.trainer:168 RmsProp 1565 loss=0.059806 err=0.059806
I 2015-05-26 10:40:40 theanets.trainer:168 RmsProp 1566 loss=0.047340 err=0.047340
I 2015-05-26 10:40:46 theanets.trainer:168 RmsProp 1567 loss=0.061766 err=0.061766
I 2015-05-26 10:40:51 theanets.trainer:168 RmsProp 1568 loss=0.049286 err=0.049286
I 2015-05-26 10:40:57 theanets.trainer:168 RmsProp 1569 loss=0.065530 err=0.065530
I 2015-05-26 10:41:04 theanets.trainer:168 RmsProp 1570 loss=0.060956 err=0.060956
I 2015-05-26 10:41:04 theanets.trainer:168 validation 157 loss=667.808289 err=667.808289
I 2015-05-26 10:41:10 theanets.trainer:168 RmsProp 1571 loss=0.049423 err=0.049423
I 2015-05-26 10:41:16 theanets.trainer:168 RmsProp 1572 loss=0.052517 err=0.052517
I 2015-05-26 10:41:22 theanets.trainer:168 RmsProp 1573 loss=0.047682 err=0.047682
I 2015-05-26 10:41:28 theanets.trainer:168 RmsProp 1574 loss=0.056980 err=0.056980
I 2015-05-26 10:41:34 theanets.trainer:168 RmsProp 1575 loss=0.051407 err=0.051407
I 2015-05-26 10:41:41 theanets.trainer:168 RmsProp 1576 loss=0.048159 err=0.048159
I 2015-05-26 10:41:47 theanets.trainer:168 RmsProp 1577 loss=0.064564 err=0.064564
I 2015-05-26 10:41:53 theanets.trainer:168 RmsProp 1578 loss=0.051725 err=0.051725
I 2015-05-26 10:41:59 theanets.trainer:168 RmsProp 1579 loss=0.051571 err=0.051571
I 2015-05-26 10:42:06 theanets.trainer:168 RmsProp 1580 loss=0.083451 err=0.083451
I 2015-05-26 10:42:06 theanets.trainer:168 validation 158 loss=666.162109 err=666.162109 *
I 2015-05-26 10:42:12 theanets.trainer:168 RmsProp 1581 loss=0.053371 err=0.053371
I 2015-05-26 10:42:18 theanets.trainer:168 RmsProp 1582 loss=0.047176 err=0.047176
I 2015-05-26 10:42:24 theanets.trainer:168 RmsProp 1583 loss=0.060864 err=0.060864
I 2015-05-26 10:42:31 theanets.trainer:168 RmsProp 1584 loss=0.051105 err=0.051105
I 2015-05-26 10:42:37 theanets.trainer:168 RmsProp 1585 loss=0.052508 err=0.052508
I 2015-05-26 10:42:43 theanets.trainer:168 RmsProp 1586 loss=0.053385 err=0.053385
I 2015-05-26 10:42:49 theanets.trainer:168 RmsProp 1587 loss=0.052320 err=0.052320
I 2015-05-26 10:42:56 theanets.trainer:168 RmsProp 1588 loss=0.057229 err=0.057229
I 2015-05-26 10:43:01 theanets.trainer:168 RmsProp 1589 loss=0.047094 err=0.047094
I 2015-05-26 10:43:07 theanets.trainer:168 RmsProp 1590 loss=0.055289 err=0.055289
I 2015-05-26 10:43:08 theanets.trainer:168 validation 159 loss=667.511902 err=667.511902
I 2015-05-26 10:43:14 theanets.trainer:168 RmsProp 1591 loss=0.051698 err=0.051698
I 2015-05-26 10:43:19 theanets.trainer:168 RmsProp 1592 loss=0.046292 err=0.046292
I 2015-05-26 10:43:26 theanets.trainer:168 RmsProp 1593 loss=0.062933 err=0.062933
I 2015-05-26 10:43:32 theanets.trainer:168 RmsProp 1594 loss=0.053712 err=0.053712
I 2015-05-26 10:43:37 theanets.trainer:168 RmsProp 1595 loss=0.053367 err=0.053367
I 2015-05-26 10:43:43 theanets.trainer:168 RmsProp 1596 loss=0.051927 err=0.051927
I 2015-05-26 10:43:49 theanets.trainer:168 RmsProp 1597 loss=0.053822 err=0.053822
I 2015-05-26 10:43:55 theanets.trainer:168 RmsProp 1598 loss=0.053276 err=0.053276
I 2015-05-26 10:44:00 theanets.trainer:168 RmsProp 1599 loss=0.051587 err=0.051587
I 2015-05-26 10:44:06 theanets.trainer:168 RmsProp 1600 loss=0.052127 err=0.052127
I 2015-05-26 10:44:06 theanets.trainer:168 validation 160 loss=666.207642 err=666.207642
I 2015-05-26 10:44:12 theanets.trainer:168 RmsProp 1601 loss=0.048737 err=0.048737
I 2015-05-26 10:44:18 theanets.trainer:168 RmsProp 1602 loss=0.045726 err=0.045726
I 2015-05-26 10:44:24 theanets.trainer:168 RmsProp 1603 loss=0.070808 err=0.070808
I 2015-05-26 10:44:30 theanets.trainer:168 RmsProp 1604 loss=0.050125 err=0.050125
I 2015-05-26 10:44:36 theanets.trainer:168 RmsProp 1605 loss=0.058139 err=0.058139
I 2015-05-26 10:44:43 theanets.trainer:168 RmsProp 1606 loss=0.056654 err=0.056654
I 2015-05-26 10:44:49 theanets.trainer:168 RmsProp 1607 loss=0.048626 err=0.048626
I 2015-05-26 10:44:55 theanets.trainer:168 RmsProp 1608 loss=0.055626 err=0.055626
I 2015-05-26 10:45:01 theanets.trainer:168 RmsProp 1609 loss=0.050478 err=0.050478
I 2015-05-26 10:45:07 theanets.trainer:168 RmsProp 1610 loss=0.054229 err=0.054229
I 2015-05-26 10:45:07 theanets.trainer:168 validation 161 loss=665.009705 err=665.009705 *
I 2015-05-26 10:45:13 theanets.trainer:168 RmsProp 1611 loss=0.052447 err=0.052447
I 2015-05-26 10:45:19 theanets.trainer:168 RmsProp 1612 loss=0.054501 err=0.054501
I 2015-05-26 10:45:25 theanets.trainer:168 RmsProp 1613 loss=0.052929 err=0.052929
I 2015-05-26 10:45:31 theanets.trainer:168 RmsProp 1614 loss=0.044723 err=0.044723
I 2015-05-26 10:45:37 theanets.trainer:168 RmsProp 1615 loss=0.047198 err=0.047198
I 2015-05-26 10:45:44 theanets.trainer:168 RmsProp 1616 loss=0.054096 err=0.054096
I 2015-05-26 10:45:50 theanets.trainer:168 RmsProp 1617 loss=0.050065 err=0.050065
I 2015-05-26 10:45:56 theanets.trainer:168 RmsProp 1618 loss=0.057794 err=0.057794
I 2015-05-26 10:46:02 theanets.trainer:168 RmsProp 1619 loss=0.058793 err=0.058793
I 2015-05-26 10:46:08 theanets.trainer:168 RmsProp 1620 loss=0.045454 err=0.045454
I 2015-05-26 10:46:09 theanets.trainer:168 validation 162 loss=664.826538 err=664.826538 *
I 2015-05-26 10:46:14 theanets.trainer:168 RmsProp 1621 loss=0.048486 err=0.048486
I 2015-05-26 10:46:21 theanets.trainer:168 RmsProp 1622 loss=0.053253 err=0.053253
I 2015-05-26 10:46:27 theanets.trainer:168 RmsProp 1623 loss=0.058959 err=0.058959
I 2015-05-26 10:46:33 theanets.trainer:168 RmsProp 1624 loss=0.044273 err=0.044273
I 2015-05-26 10:46:39 theanets.trainer:168 RmsProp 1625 loss=0.057060 err=0.057060
I 2015-05-26 10:46:45 theanets.trainer:168 RmsProp 1626 loss=0.053255 err=0.053255
I 2015-05-26 10:46:51 theanets.trainer:168 RmsProp 1627 loss=0.056406 err=0.056406
I 2015-05-26 10:46:57 theanets.trainer:168 RmsProp 1628 loss=0.047131 err=0.047131
I 2015-05-26 10:47:02 theanets.trainer:168 RmsProp 1629 loss=0.050944 err=0.050944
I 2015-05-26 10:47:09 theanets.trainer:168 RmsProp 1630 loss=0.046595 err=0.046595
I 2015-05-26 10:47:09 theanets.trainer:168 validation 163 loss=666.165039 err=666.165039
I 2015-05-26 10:47:15 theanets.trainer:168 RmsProp 1631 loss=0.057926 err=0.057926
I 2015-05-26 10:47:21 theanets.trainer:168 RmsProp 1632 loss=0.051179 err=0.051179
I 2015-05-26 10:47:28 theanets.trainer:168 RmsProp 1633 loss=0.053404 err=0.053404
I 2015-05-26 10:47:34 theanets.trainer:168 RmsProp 1634 loss=0.045892 err=0.045892
I 2015-05-26 10:47:40 theanets.trainer:168 RmsProp 1635 loss=0.054134 err=0.054134
I 2015-05-26 10:47:46 theanets.trainer:168 RmsProp 1636 loss=0.048185 err=0.048185
I 2015-05-26 10:47:52 theanets.trainer:168 RmsProp 1637 loss=0.053556 err=0.053556
I 2015-05-26 10:47:59 theanets.trainer:168 RmsProp 1638 loss=0.048729 err=0.048729
I 2015-05-26 10:48:05 theanets.trainer:168 RmsProp 1639 loss=0.053856 err=0.053856
I 2015-05-26 10:48:11 theanets.trainer:168 RmsProp 1640 loss=0.055053 err=0.055053
I 2015-05-26 10:48:11 theanets.trainer:168 validation 164 loss=665.130493 err=665.130493
I 2015-05-26 10:48:17 theanets.trainer:168 RmsProp 1641 loss=0.051830 err=0.051830
I 2015-05-26 10:48:24 theanets.trainer:168 RmsProp 1642 loss=0.052336 err=0.052336
I 2015-05-26 10:48:30 theanets.trainer:168 RmsProp 1643 loss=0.043710 err=0.043710
I 2015-05-26 10:48:36 theanets.trainer:168 RmsProp 1644 loss=0.064634 err=0.064634
I 2015-05-26 10:48:42 theanets.trainer:168 RmsProp 1645 loss=0.054117 err=0.054117
I 2015-05-26 10:48:48 theanets.trainer:168 RmsProp 1646 loss=0.052903 err=0.052903
I 2015-05-26 10:48:55 theanets.trainer:168 RmsProp 1647 loss=0.050147 err=0.050147
I 2015-05-26 10:49:01 theanets.trainer:168 RmsProp 1648 loss=0.048581 err=0.048581
I 2015-05-26 10:49:07 theanets.trainer:168 RmsProp 1649 loss=0.047208 err=0.047208
I 2015-05-26 10:49:13 theanets.trainer:168 RmsProp 1650 loss=0.061961 err=0.061961
I 2015-05-26 10:49:14 theanets.trainer:168 validation 165 loss=664.293396 err=664.293396 *
I 2015-05-26 10:49:19 theanets.trainer:168 RmsProp 1651 loss=0.050605 err=0.050605
I 2015-05-26 10:49:26 theanets.trainer:168 RmsProp 1652 loss=0.044252 err=0.044252
I 2015-05-26 10:49:32 theanets.trainer:168 RmsProp 1653 loss=0.054587 err=0.054587
I 2015-05-26 10:49:38 theanets.trainer:168 RmsProp 1654 loss=0.049796 err=0.049796
I 2015-05-26 10:49:44 theanets.trainer:168 RmsProp 1655 loss=0.046858 err=0.046858
I 2015-05-26 10:49:50 theanets.trainer:168 RmsProp 1656 loss=0.060675 err=0.060675
I 2015-05-26 10:49:56 theanets.trainer:168 RmsProp 1657 loss=0.053831 err=0.053831
I 2015-05-26 10:50:02 theanets.trainer:168 RmsProp 1658 loss=0.048002 err=0.048002
I 2015-05-26 10:50:09 theanets.trainer:168 RmsProp 1659 loss=0.052408 err=0.052408
I 2015-05-26 10:50:14 theanets.trainer:168 RmsProp 1660 loss=0.052307 err=0.052307
I 2015-05-26 10:50:15 theanets.trainer:168 validation 166 loss=662.995300 err=662.995300 *
I 2015-05-26 10:50:20 theanets.trainer:168 RmsProp 1661 loss=0.050572 err=0.050572
I 2015-05-26 10:50:27 theanets.trainer:168 RmsProp 1662 loss=0.056944 err=0.056944
I 2015-05-26 10:50:33 theanets.trainer:168 RmsProp 1663 loss=0.045401 err=0.045401
I 2015-05-26 10:50:39 theanets.trainer:168 RmsProp 1664 loss=0.049263 err=0.049263
I 2015-05-26 10:50:45 theanets.trainer:168 RmsProp 1665 loss=0.053235 err=0.053235
I 2015-05-26 10:50:52 theanets.trainer:168 RmsProp 1666 loss=0.048712 err=0.048712
I 2015-05-26 10:50:57 theanets.trainer:168 RmsProp 1667 loss=0.052787 err=0.052787
I 2015-05-26 10:51:04 theanets.trainer:168 RmsProp 1668 loss=0.050464 err=0.050464
I 2015-05-26 10:51:10 theanets.trainer:168 RmsProp 1669 loss=0.048452 err=0.048452
I 2015-05-26 10:51:16 theanets.trainer:168 RmsProp 1670 loss=0.058906 err=0.058906
I 2015-05-26 10:51:17 theanets.trainer:168 validation 167 loss=664.381470 err=664.381470
I 2015-05-26 10:51:23 theanets.trainer:168 RmsProp 1671 loss=0.048936 err=0.048936
I 2015-05-26 10:51:29 theanets.trainer:168 RmsProp 1672 loss=0.048205 err=0.048205
I 2015-05-26 10:51:35 theanets.trainer:168 RmsProp 1673 loss=0.054059 err=0.054059
I 2015-05-26 10:51:40 theanets.trainer:168 RmsProp 1674 loss=0.045508 err=0.045508
I 2015-05-26 10:51:46 theanets.trainer:168 RmsProp 1675 loss=0.053767 err=0.053767
I 2015-05-26 10:51:52 theanets.trainer:168 RmsProp 1676 loss=0.044124 err=0.044124
I 2015-05-26 10:51:58 theanets.trainer:168 RmsProp 1677 loss=0.059643 err=0.059643
I 2015-05-26 10:52:04 theanets.trainer:168 RmsProp 1678 loss=0.045924 err=0.045924
I 2015-05-26 10:52:10 theanets.trainer:168 RmsProp 1679 loss=0.053142 err=0.053142
I 2015-05-26 10:52:17 theanets.trainer:168 RmsProp 1680 loss=0.047472 err=0.047472
I 2015-05-26 10:52:17 theanets.trainer:168 validation 168 loss=662.882629 err=662.882629 *
I 2015-05-26 10:52:23 theanets.trainer:168 RmsProp 1681 loss=0.052275 err=0.052275
I 2015-05-26 10:52:29 theanets.trainer:168 RmsProp 1682 loss=0.047333 err=0.047333
I 2015-05-26 10:52:35 theanets.trainer:168 RmsProp 1683 loss=0.039692 err=0.039692
I 2015-05-26 10:52:41 theanets.trainer:168 RmsProp 1684 loss=0.069132 err=0.069132
I 2015-05-26 10:52:48 theanets.trainer:168 RmsProp 1685 loss=0.048575 err=0.048575
I 2015-05-26 10:52:53 theanets.trainer:168 RmsProp 1686 loss=0.046364 err=0.046364
I 2015-05-26 10:52:59 theanets.trainer:168 RmsProp 1687 loss=0.058138 err=0.058138
I 2015-05-26 10:53:05 theanets.trainer:168 RmsProp 1688 loss=0.045996 err=0.045996
I 2015-05-26 10:53:11 theanets.trainer:168 RmsProp 1689 loss=0.064599 err=0.064599
I 2015-05-26 10:53:16 theanets.trainer:168 RmsProp 1690 loss=0.058282 err=0.058282
I 2015-05-26 10:53:17 theanets.trainer:168 validation 169 loss=664.165466 err=664.165466
I 2015-05-26 10:53:23 theanets.trainer:168 RmsProp 1691 loss=0.045207 err=0.045207
I 2015-05-26 10:53:28 theanets.trainer:168 RmsProp 1692 loss=0.049814 err=0.049814
I 2015-05-26 10:53:34 theanets.trainer:168 RmsProp 1693 loss=0.050750 err=0.050750
I 2015-05-26 10:53:41 theanets.trainer:168 RmsProp 1694 loss=0.048135 err=0.048135
I 2015-05-26 10:53:47 theanets.trainer:168 RmsProp 1695 loss=0.056097 err=0.056097
I 2015-05-26 10:53:53 theanets.trainer:168 RmsProp 1696 loss=0.056353 err=0.056353
I 2015-05-26 10:53:59 theanets.trainer:168 RmsProp 1697 loss=0.043246 err=0.043246
I 2015-05-26 10:54:05 theanets.trainer:168 RmsProp 1698 loss=0.061800 err=0.061800
I 2015-05-26 10:54:11 theanets.trainer:168 RmsProp 1699 loss=0.056311 err=0.056311
I 2015-05-26 10:54:17 theanets.trainer:168 RmsProp 1700 loss=0.046098 err=0.046098
I 2015-05-26 10:54:17 theanets.trainer:168 validation 170 loss=662.590515 err=662.590515 *
I 2015-05-26 10:54:23 theanets.trainer:168 RmsProp 1701 loss=0.046173 err=0.046173
I 2015-05-26 10:54:29 theanets.trainer:168 RmsProp 1702 loss=0.052235 err=0.052235
I 2015-05-26 10:54:35 theanets.trainer:168 RmsProp 1703 loss=0.061194 err=0.061194
I 2015-05-26 10:54:41 theanets.trainer:168 RmsProp 1704 loss=0.049177 err=0.049177
I 2015-05-26 10:54:46 theanets.trainer:168 RmsProp 1705 loss=0.045187 err=0.045187
I 2015-05-26 10:54:53 theanets.trainer:168 RmsProp 1706 loss=0.052222 err=0.052222
I 2015-05-26 10:54:59 theanets.trainer:168 RmsProp 1707 loss=0.048966 err=0.048966
I 2015-05-26 10:55:05 theanets.trainer:168 RmsProp 1708 loss=0.052332 err=0.052332
I 2015-05-26 10:55:11 theanets.trainer:168 RmsProp 1709 loss=0.054543 err=0.054543
I 2015-05-26 10:55:17 theanets.trainer:168 RmsProp 1710 loss=0.042385 err=0.042385
I 2015-05-26 10:55:18 theanets.trainer:168 validation 171 loss=661.509888 err=661.509888 *
I 2015-05-26 10:55:24 theanets.trainer:168 RmsProp 1711 loss=0.063975 err=0.063975
I 2015-05-26 10:55:30 theanets.trainer:168 RmsProp 1712 loss=0.049989 err=0.049989
I 2015-05-26 10:55:36 theanets.trainer:168 RmsProp 1713 loss=0.043544 err=0.043544
I 2015-05-26 10:55:41 theanets.trainer:168 RmsProp 1714 loss=0.057574 err=0.057574
I 2015-05-26 10:55:47 theanets.trainer:168 RmsProp 1715 loss=0.047137 err=0.047137
I 2015-05-26 10:55:52 theanets.trainer:168 RmsProp 1716 loss=0.051592 err=0.051592
I 2015-05-26 10:55:58 theanets.trainer:168 RmsProp 1717 loss=0.045299 err=0.045299
I 2015-05-26 10:56:04 theanets.trainer:168 RmsProp 1718 loss=0.050683 err=0.050683
I 2015-05-26 10:56:10 theanets.trainer:168 RmsProp 1719 loss=0.058623 err=0.058623
I 2015-05-26 10:56:16 theanets.trainer:168 RmsProp 1720 loss=0.046878 err=0.046878
I 2015-05-26 10:56:16 theanets.trainer:168 validation 172 loss=661.260071 err=661.260071 *
I 2015-05-26 10:56:22 theanets.trainer:168 RmsProp 1721 loss=0.049561 err=0.049561
I 2015-05-26 10:56:28 theanets.trainer:168 RmsProp 1722 loss=0.041093 err=0.041093
I 2015-05-26 10:56:34 theanets.trainer:168 RmsProp 1723 loss=0.049004 err=0.049004
I 2015-05-26 10:56:41 theanets.trainer:168 RmsProp 1724 loss=0.052858 err=0.052858
I 2015-05-26 10:56:47 theanets.trainer:168 RmsProp 1725 loss=0.047598 err=0.047598
I 2015-05-26 10:56:53 theanets.trainer:168 RmsProp 1726 loss=0.047171 err=0.047171
I 2015-05-26 10:56:59 theanets.trainer:168 RmsProp 1727 loss=0.051565 err=0.051565
I 2015-05-26 10:57:06 theanets.trainer:168 RmsProp 1728 loss=0.054205 err=0.054205
I 2015-05-26 10:57:12 theanets.trainer:168 RmsProp 1729 loss=0.043269 err=0.043269
I 2015-05-26 10:57:18 theanets.trainer:168 RmsProp 1730 loss=0.053034 err=0.053034
I 2015-05-26 10:57:18 theanets.trainer:168 validation 173 loss=660.203857 err=660.203857 *
I 2015-05-26 10:57:24 theanets.trainer:168 RmsProp 1731 loss=0.049796 err=0.049796
I 2015-05-26 10:57:31 theanets.trainer:168 RmsProp 1732 loss=0.051218 err=0.051218
I 2015-05-26 10:57:37 theanets.trainer:168 RmsProp 1733 loss=0.046887 err=0.046887
I 2015-05-26 10:57:43 theanets.trainer:168 RmsProp 1734 loss=0.047883 err=0.047883
I 2015-05-26 10:57:49 theanets.trainer:168 RmsProp 1735 loss=0.056186 err=0.056186
I 2015-05-26 10:57:55 theanets.trainer:168 RmsProp 1736 loss=0.042195 err=0.042195
I 2015-05-26 10:58:01 theanets.trainer:168 RmsProp 1737 loss=0.058063 err=0.058063
I 2015-05-26 10:58:07 theanets.trainer:168 RmsProp 1738 loss=0.046670 err=0.046670
I 2015-05-26 10:58:13 theanets.trainer:168 RmsProp 1739 loss=0.050226 err=0.050226
I 2015-05-26 10:58:19 theanets.trainer:168 RmsProp 1740 loss=0.040746 err=0.040746
I 2015-05-26 10:58:19 theanets.trainer:168 validation 174 loss=660.581726 err=660.581726
I 2015-05-26 10:58:24 theanets.trainer:168 RmsProp 1741 loss=0.059906 err=0.059906
I 2015-05-26 10:58:30 theanets.trainer:168 RmsProp 1742 loss=0.079891 err=0.079891
I 2015-05-26 10:58:37 theanets.trainer:168 RmsProp 1743 loss=0.049947 err=0.049947
I 2015-05-26 10:58:43 theanets.trainer:168 RmsProp 1744 loss=0.045620 err=0.045620
I 2015-05-26 10:58:49 theanets.trainer:168 RmsProp 1745 loss=0.053301 err=0.053301
I 2015-05-26 10:58:55 theanets.trainer:168 RmsProp 1746 loss=0.052822 err=0.052822
I 2015-05-26 10:59:02 theanets.trainer:168 RmsProp 1747 loss=0.046437 err=0.046437
I 2015-05-26 10:59:08 theanets.trainer:168 RmsProp 1748 loss=0.045741 err=0.045741
I 2015-05-26 10:59:14 theanets.trainer:168 RmsProp 1749 loss=0.054948 err=0.054948
I 2015-05-26 10:59:20 theanets.trainer:168 RmsProp 1750 loss=0.047174 err=0.047174
I 2015-05-26 10:59:21 theanets.trainer:168 validation 175 loss=661.240051 err=661.240051
I 2015-05-26 10:59:26 theanets.trainer:168 RmsProp 1751 loss=0.045808 err=0.045808
I 2015-05-26 10:59:33 theanets.trainer:168 RmsProp 1752 loss=0.041247 err=0.041247
I 2015-05-26 10:59:39 theanets.trainer:168 RmsProp 1753 loss=0.055976 err=0.055976
I 2015-05-26 10:59:45 theanets.trainer:168 RmsProp 1754 loss=0.052594 err=0.052594
I 2015-05-26 10:59:51 theanets.trainer:168 RmsProp 1755 loss=0.047438 err=0.047438
I 2015-05-26 10:59:57 theanets.trainer:168 RmsProp 1756 loss=0.043815 err=0.043815
I 2015-05-26 11:00:04 theanets.trainer:168 RmsProp 1757 loss=0.052791 err=0.052791
I 2015-05-26 11:00:10 theanets.trainer:168 RmsProp 1758 loss=0.045262 err=0.045262
I 2015-05-26 11:00:16 theanets.trainer:168 RmsProp 1759 loss=0.056650 err=0.056650
I 2015-05-26 11:00:22 theanets.trainer:168 RmsProp 1760 loss=0.043302 err=0.043302
I 2015-05-26 11:00:23 theanets.trainer:168 validation 176 loss=660.878540 err=660.878540
I 2015-05-26 11:00:29 theanets.trainer:168 RmsProp 1761 loss=0.043375 err=0.043375
I 2015-05-26 11:00:35 theanets.trainer:168 RmsProp 1762 loss=0.057519 err=0.057519
I 2015-05-26 11:00:41 theanets.trainer:168 RmsProp 1763 loss=0.048175 err=0.048175
I 2015-05-26 11:00:47 theanets.trainer:168 RmsProp 1764 loss=0.047078 err=0.047078
I 2015-05-26 11:00:53 theanets.trainer:168 RmsProp 1765 loss=0.045417 err=0.045417
I 2015-05-26 11:00:59 theanets.trainer:168 RmsProp 1766 loss=0.055220 err=0.055220
I 2015-05-26 11:01:05 theanets.trainer:168 RmsProp 1767 loss=0.049178 err=0.049178
I 2015-05-26 11:01:11 theanets.trainer:168 RmsProp 1768 loss=0.043528 err=0.043528
I 2015-05-26 11:01:18 theanets.trainer:168 RmsProp 1769 loss=0.044724 err=0.044724
I 2015-05-26 11:01:24 theanets.trainer:168 RmsProp 1770 loss=0.065432 err=0.065432
I 2015-05-26 11:01:24 theanets.trainer:168 validation 177 loss=660.491760 err=660.491760
I 2015-05-26 11:01:30 theanets.trainer:168 RmsProp 1771 loss=0.048498 err=0.048498
I 2015-05-26 11:01:36 theanets.trainer:168 RmsProp 1772 loss=0.043964 err=0.043964
I 2015-05-26 11:01:43 theanets.trainer:168 RmsProp 1773 loss=0.049279 err=0.049279
I 2015-05-26 11:01:49 theanets.trainer:168 RmsProp 1774 loss=0.045049 err=0.045049
I 2015-05-26 11:01:55 theanets.trainer:168 RmsProp 1775 loss=0.047899 err=0.047899
I 2015-05-26 11:02:01 theanets.trainer:168 RmsProp 1776 loss=0.049367 err=0.049367
I 2015-05-26 11:02:08 theanets.trainer:168 RmsProp 1777 loss=0.041837 err=0.041837
I 2015-05-26 11:02:14 theanets.trainer:168 RmsProp 1778 loss=0.050258 err=0.050258
I 2015-05-26 11:02:20 theanets.trainer:168 RmsProp 1779 loss=0.043572 err=0.043572
I 2015-05-26 11:02:26 theanets.trainer:168 RmsProp 1780 loss=0.049567 err=0.049567
I 2015-05-26 11:02:27 theanets.trainer:168 validation 178 loss=660.859802 err=660.859802
I 2015-05-26 11:02:27 theanets.trainer:252 patience elapsed!
I 2015-05-26 11:02:27 theanets.main:237 models_deep_post_code_sep/95131-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saving model
I 2015-05-26 11:02:27 theanets.graph:477 models_deep_post_code_sep/95131-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saved model parameters
