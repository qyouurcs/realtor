I 2015-05-26 03:35:26 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 03:35:26 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 03:35:26 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95136-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl
I 2015-05-26 03:35:26 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 03:35:26 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 03:35:26 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 03:35:26 theanets.main:89 --batch_size = 1024
I 2015-05-26 03:35:26 theanets.main:89 --gradient_clip = 1
I 2015-05-26 03:35:26 theanets.main:89 --hidden_l1 = None
I 2015-05-26 03:35:26 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 03:35:26 theanets.main:89 --train_batches = 30
I 2015-05-26 03:35:26 theanets.main:89 --valid_batches = 3
I 2015-05-26 03:35:26 theanets.main:89 --weight_l1 = None
I 2015-05-26 03:35:26 theanets.main:89 --weight_l2 = None
I 2015-05-26 03:35:26 theanets.trainer:134 compiling evaluation function
I 2015-05-26 03:35:42 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 03:38:58 theanets.trainer:168 validation 0 loss=14154.059570 err=14154.059570 *
I 2015-05-26 03:39:58 theanets.trainer:168 RmsProp 1 loss=13203.058594 err=13203.058594
I 2015-05-26 03:40:58 theanets.trainer:168 RmsProp 2 loss=13087.051758 err=13087.051758
I 2015-05-26 03:41:59 theanets.trainer:168 RmsProp 3 loss=12468.568359 err=12468.568359
I 2015-05-26 03:42:59 theanets.trainer:168 RmsProp 4 loss=10966.792969 err=10966.792969
I 2015-05-26 03:43:58 theanets.trainer:168 RmsProp 5 loss=10233.759766 err=10233.759766
I 2015-05-26 03:44:57 theanets.trainer:168 RmsProp 6 loss=9589.150391 err=9589.150391
I 2015-05-26 03:45:56 theanets.trainer:168 RmsProp 7 loss=8915.180664 err=8915.180664
I 2015-05-26 03:46:57 theanets.trainer:168 RmsProp 8 loss=8284.764648 err=8284.764648
I 2015-05-26 03:47:58 theanets.trainer:168 RmsProp 9 loss=7684.929199 err=7684.929199
I 2015-05-26 03:48:58 theanets.trainer:168 RmsProp 10 loss=7129.503418 err=7129.503418
I 2015-05-26 03:48:59 theanets.trainer:168 validation 1 loss=6399.984375 err=6399.984375 *
I 2015-05-26 03:50:00 theanets.trainer:168 RmsProp 11 loss=6733.640137 err=6733.640137
I 2015-05-26 03:51:00 theanets.trainer:168 RmsProp 12 loss=5992.668457 err=5992.668457
I 2015-05-26 03:52:02 theanets.trainer:168 RmsProp 13 loss=5585.028320 err=5585.028320
I 2015-05-26 03:53:03 theanets.trainer:168 RmsProp 14 loss=5073.041016 err=5073.041016
I 2015-05-26 03:54:04 theanets.trainer:168 RmsProp 15 loss=4582.574707 err=4582.574707
I 2015-05-26 03:55:05 theanets.trainer:168 RmsProp 16 loss=4185.382812 err=4185.382812
I 2015-05-26 03:56:07 theanets.trainer:168 RmsProp 17 loss=3798.902588 err=3798.902588
I 2015-05-26 03:57:08 theanets.trainer:168 RmsProp 18 loss=3494.872070 err=3494.872070
I 2015-05-26 03:58:09 theanets.trainer:168 RmsProp 19 loss=3209.837402 err=3209.837402
I 2015-05-26 03:59:10 theanets.trainer:168 RmsProp 20 loss=3015.968018 err=3015.968018
I 2015-05-26 03:59:11 theanets.trainer:168 validation 2 loss=3179.720459 err=3179.720459 *
I 2015-05-26 04:00:12 theanets.trainer:168 RmsProp 21 loss=2806.719482 err=2806.719482
I 2015-05-26 04:01:13 theanets.trainer:168 RmsProp 22 loss=2616.655518 err=2616.655518
I 2015-05-26 04:02:14 theanets.trainer:168 RmsProp 23 loss=2465.979492 err=2465.979492
I 2015-05-26 04:03:15 theanets.trainer:168 RmsProp 24 loss=2403.448242 err=2403.448242
I 2015-05-26 04:04:16 theanets.trainer:168 RmsProp 25 loss=2301.250977 err=2301.250977
I 2015-05-26 04:05:17 theanets.trainer:168 RmsProp 26 loss=2134.910156 err=2134.910156
I 2015-05-26 04:06:18 theanets.trainer:168 RmsProp 27 loss=1992.299438 err=1992.299438
I 2015-05-26 04:07:18 theanets.trainer:168 RmsProp 28 loss=1861.117798 err=1861.117798
I 2015-05-26 04:08:19 theanets.trainer:168 RmsProp 29 loss=1803.014282 err=1803.014282
I 2015-05-26 04:09:20 theanets.trainer:168 RmsProp 30 loss=1705.371582 err=1705.371582
I 2015-05-26 04:09:21 theanets.trainer:168 validation 3 loss=2321.486816 err=2321.486816 *
I 2015-05-26 04:10:22 theanets.trainer:168 RmsProp 31 loss=1622.290649 err=1622.290649
I 2015-05-26 04:11:22 theanets.trainer:168 RmsProp 32 loss=1531.495972 err=1531.495972
I 2015-05-26 04:12:22 theanets.trainer:168 RmsProp 33 loss=1436.746826 err=1436.746826
I 2015-05-26 04:13:21 theanets.trainer:168 RmsProp 34 loss=1350.251099 err=1350.251099
I 2015-05-26 04:14:18 theanets.trainer:168 RmsProp 35 loss=1270.064819 err=1270.064819
I 2015-05-26 04:15:15 theanets.trainer:168 RmsProp 36 loss=1204.052734 err=1204.052734
I 2015-05-26 04:16:11 theanets.trainer:168 RmsProp 37 loss=1176.576660 err=1176.576660
I 2015-05-26 04:17:08 theanets.trainer:168 RmsProp 38 loss=1096.362671 err=1096.362671
I 2015-05-26 04:18:04 theanets.trainer:168 RmsProp 39 loss=1053.968872 err=1053.968872
I 2015-05-26 04:19:00 theanets.trainer:168 RmsProp 40 loss=1015.330078 err=1015.330078
I 2015-05-26 04:19:01 theanets.trainer:168 validation 4 loss=2108.654053 err=2108.654053 *
I 2015-05-26 04:19:58 theanets.trainer:168 RmsProp 41 loss=980.633972 err=980.633972
I 2015-05-26 04:20:55 theanets.trainer:168 RmsProp 42 loss=937.438049 err=937.438049
I 2015-05-26 04:21:52 theanets.trainer:168 RmsProp 43 loss=890.771667 err=890.771667
I 2015-05-26 04:22:47 theanets.trainer:168 RmsProp 44 loss=838.777771 err=838.777771
I 2015-05-26 04:23:40 theanets.trainer:168 RmsProp 45 loss=796.639282 err=796.639282
I 2015-05-26 04:24:33 theanets.trainer:168 RmsProp 46 loss=782.573547 err=782.573547
I 2015-05-26 04:25:26 theanets.trainer:168 RmsProp 47 loss=750.669373 err=750.669373
I 2015-05-26 04:26:20 theanets.trainer:168 RmsProp 48 loss=730.942444 err=730.942444
I 2015-05-26 04:27:14 theanets.trainer:168 RmsProp 49 loss=685.522522 err=685.522522
I 2015-05-26 04:28:07 theanets.trainer:168 RmsProp 50 loss=642.683716 err=642.683716
I 2015-05-26 04:28:08 theanets.trainer:168 validation 5 loss=1913.370483 err=1913.370483 *
I 2015-05-26 04:29:00 theanets.trainer:168 RmsProp 51 loss=624.653015 err=624.653015
I 2015-05-26 04:29:53 theanets.trainer:168 RmsProp 52 loss=605.495850 err=605.495850
I 2015-05-26 04:30:47 theanets.trainer:168 RmsProp 53 loss=586.443909 err=586.443909
I 2015-05-26 04:31:40 theanets.trainer:168 RmsProp 54 loss=561.851746 err=561.851746
I 2015-05-26 04:32:33 theanets.trainer:168 RmsProp 55 loss=548.549561 err=548.549561
I 2015-05-26 04:33:26 theanets.trainer:168 RmsProp 56 loss=517.168518 err=517.168518
I 2015-05-26 04:34:19 theanets.trainer:168 RmsProp 57 loss=499.442993 err=499.442993
I 2015-05-26 04:35:13 theanets.trainer:168 RmsProp 58 loss=482.967163 err=482.967163
I 2015-05-26 04:36:06 theanets.trainer:168 RmsProp 59 loss=465.515289 err=465.515289
I 2015-05-26 04:37:01 theanets.trainer:168 RmsProp 60 loss=456.890625 err=456.890625
I 2015-05-26 04:37:02 theanets.trainer:168 validation 6 loss=1836.481445 err=1836.481445 *
I 2015-05-26 04:37:56 theanets.trainer:168 RmsProp 61 loss=465.331543 err=465.331543
I 2015-05-26 04:38:50 theanets.trainer:168 RmsProp 62 loss=444.580109 err=444.580109
I 2015-05-26 04:39:44 theanets.trainer:168 RmsProp 63 loss=427.609711 err=427.609711
I 2015-05-26 04:40:39 theanets.trainer:168 RmsProp 64 loss=412.884094 err=412.884094
I 2015-05-26 04:41:33 theanets.trainer:168 RmsProp 65 loss=380.562500 err=380.562500
I 2015-05-26 04:42:27 theanets.trainer:168 RmsProp 66 loss=371.128113 err=371.128113
I 2015-05-26 04:43:22 theanets.trainer:168 RmsProp 67 loss=372.448608 err=372.448608
I 2015-05-26 04:44:16 theanets.trainer:168 RmsProp 68 loss=379.091766 err=379.091766
I 2015-05-26 04:45:10 theanets.trainer:168 RmsProp 69 loss=354.358521 err=354.358521
I 2015-05-26 04:46:04 theanets.trainer:168 RmsProp 70 loss=342.696350 err=342.696350
I 2015-05-26 04:46:05 theanets.trainer:168 validation 7 loss=1817.146851 err=1817.146851 *
I 2015-05-26 04:46:59 theanets.trainer:168 RmsProp 71 loss=348.539185 err=348.539185
I 2015-05-26 04:47:52 theanets.trainer:168 RmsProp 72 loss=329.518829 err=329.518829
I 2015-05-26 04:48:46 theanets.trainer:168 RmsProp 73 loss=306.707703 err=306.707703
I 2015-05-26 04:49:40 theanets.trainer:168 RmsProp 74 loss=297.861481 err=297.861481
I 2015-05-26 04:50:35 theanets.trainer:168 RmsProp 75 loss=285.712463 err=285.712463
I 2015-05-26 04:51:28 theanets.trainer:168 RmsProp 76 loss=278.549408 err=278.549408
I 2015-05-26 04:52:23 theanets.trainer:168 RmsProp 77 loss=271.079468 err=271.079468
I 2015-05-26 04:53:17 theanets.trainer:168 RmsProp 78 loss=270.596832 err=270.596832
I 2015-05-26 04:54:11 theanets.trainer:168 RmsProp 79 loss=268.136810 err=268.136810
I 2015-05-26 04:55:04 theanets.trainer:168 RmsProp 80 loss=254.686356 err=254.686356
I 2015-05-26 04:55:05 theanets.trainer:168 validation 8 loss=1827.296509 err=1827.296509
I 2015-05-26 04:55:57 theanets.trainer:168 RmsProp 81 loss=244.472565 err=244.472565
I 2015-05-26 04:56:50 theanets.trainer:168 RmsProp 82 loss=236.038025 err=236.038025
I 2015-05-26 04:57:43 theanets.trainer:168 RmsProp 83 loss=227.355637 err=227.355637
I 2015-05-26 04:58:35 theanets.trainer:168 RmsProp 84 loss=222.073273 err=222.073273
I 2015-05-26 04:59:28 theanets.trainer:168 RmsProp 85 loss=219.282288 err=219.282288
I 2015-05-26 05:00:21 theanets.trainer:168 RmsProp 86 loss=211.390961 err=211.390961
I 2015-05-26 05:01:13 theanets.trainer:168 RmsProp 87 loss=208.774017 err=208.774017
I 2015-05-26 05:02:06 theanets.trainer:168 RmsProp 88 loss=200.024658 err=200.024658
I 2015-05-26 05:02:59 theanets.trainer:168 RmsProp 89 loss=198.961014 err=198.961014
I 2015-05-26 05:03:52 theanets.trainer:168 RmsProp 90 loss=191.734329 err=191.734329
I 2015-05-26 05:03:53 theanets.trainer:168 validation 9 loss=1754.757446 err=1754.757446 *
I 2015-05-26 05:04:46 theanets.trainer:168 RmsProp 91 loss=187.785324 err=187.785324
I 2015-05-26 05:05:39 theanets.trainer:168 RmsProp 92 loss=181.568039 err=181.568039
I 2015-05-26 05:06:33 theanets.trainer:168 RmsProp 93 loss=179.174149 err=179.174149
I 2015-05-26 05:07:26 theanets.trainer:168 RmsProp 94 loss=176.510468 err=176.510468
I 2015-05-26 05:08:17 theanets.trainer:168 RmsProp 95 loss=177.027252 err=177.027252
I 2015-05-26 05:09:08 theanets.trainer:168 RmsProp 96 loss=173.654144 err=173.654144
I 2015-05-26 05:09:59 theanets.trainer:168 RmsProp 97 loss=164.375732 err=164.375732
I 2015-05-26 05:10:49 theanets.trainer:168 RmsProp 98 loss=162.713120 err=162.713120
I 2015-05-26 05:11:39 theanets.trainer:168 RmsProp 99 loss=160.772354 err=160.772354
I 2015-05-26 05:12:29 theanets.trainer:168 RmsProp 100 loss=152.541245 err=152.541245
I 2015-05-26 05:12:30 theanets.trainer:168 validation 10 loss=1783.390991 err=1783.390991
I 2015-05-26 05:13:19 theanets.trainer:168 RmsProp 101 loss=148.448532 err=148.448532
I 2015-05-26 05:14:10 theanets.trainer:168 RmsProp 102 loss=142.407333 err=142.407333
I 2015-05-26 05:15:00 theanets.trainer:168 RmsProp 103 loss=142.478683 err=142.478683
I 2015-05-26 05:15:51 theanets.trainer:168 RmsProp 104 loss=135.552628 err=135.552628
I 2015-05-26 05:16:41 theanets.trainer:168 RmsProp 105 loss=133.312683 err=133.312683
I 2015-05-26 05:17:32 theanets.trainer:168 RmsProp 106 loss=132.414032 err=132.414032
I 2015-05-26 05:18:22 theanets.trainer:168 RmsProp 107 loss=128.711273 err=128.711273
I 2015-05-26 05:19:13 theanets.trainer:168 RmsProp 108 loss=129.560532 err=129.560532
I 2015-05-26 05:20:03 theanets.trainer:168 RmsProp 109 loss=126.044991 err=126.044991
I 2015-05-26 05:20:53 theanets.trainer:168 RmsProp 110 loss=120.792076 err=120.792076
I 2015-05-26 05:20:54 theanets.trainer:168 validation 11 loss=1730.638672 err=1730.638672 *
I 2015-05-26 05:21:45 theanets.trainer:168 RmsProp 111 loss=118.880333 err=118.880333
I 2015-05-26 05:22:36 theanets.trainer:168 RmsProp 112 loss=113.638115 err=113.638115
I 2015-05-26 05:23:27 theanets.trainer:168 RmsProp 113 loss=114.981583 err=114.981583
I 2015-05-26 05:24:18 theanets.trainer:168 RmsProp 114 loss=109.035255 err=109.035255
I 2015-05-26 05:25:08 theanets.trainer:168 RmsProp 115 loss=109.180573 err=109.180573
I 2015-05-26 05:25:59 theanets.trainer:168 RmsProp 116 loss=106.272293 err=106.272293
I 2015-05-26 05:26:49 theanets.trainer:168 RmsProp 117 loss=103.474358 err=103.474358
I 2015-05-26 05:27:39 theanets.trainer:168 RmsProp 118 loss=102.358559 err=102.358559
I 2015-05-26 05:28:30 theanets.trainer:168 RmsProp 119 loss=100.680214 err=100.680214
I 2015-05-26 05:29:20 theanets.trainer:168 RmsProp 120 loss=99.464142 err=99.464142
I 2015-05-26 05:29:22 theanets.trainer:168 validation 12 loss=1778.261597 err=1778.261597
I 2015-05-26 05:30:12 theanets.trainer:168 RmsProp 121 loss=95.267143 err=95.267143
I 2015-05-26 05:31:03 theanets.trainer:168 RmsProp 122 loss=95.710915 err=95.710915
I 2015-05-26 05:31:54 theanets.trainer:168 RmsProp 123 loss=92.642548 err=92.642548
I 2015-05-26 05:32:45 theanets.trainer:168 RmsProp 124 loss=88.952705 err=88.952705
I 2015-05-26 05:33:35 theanets.trainer:168 RmsProp 125 loss=88.442772 err=88.442772
I 2015-05-26 05:34:26 theanets.trainer:168 RmsProp 126 loss=87.384544 err=87.384544
I 2015-05-26 05:35:17 theanets.trainer:168 RmsProp 127 loss=85.402809 err=85.402809
I 2015-05-26 05:36:08 theanets.trainer:168 RmsProp 128 loss=84.849579 err=84.849579
I 2015-05-26 05:36:58 theanets.trainer:168 RmsProp 129 loss=81.345192 err=81.345192
I 2015-05-26 05:37:48 theanets.trainer:168 RmsProp 130 loss=80.324364 err=80.324364
I 2015-05-26 05:37:49 theanets.trainer:168 validation 13 loss=1707.729370 err=1707.729370 *
I 2015-05-26 05:38:37 theanets.trainer:168 RmsProp 131 loss=77.875031 err=77.875031
I 2015-05-26 05:39:25 theanets.trainer:168 RmsProp 132 loss=76.814140 err=76.814140
I 2015-05-26 05:40:13 theanets.trainer:168 RmsProp 133 loss=75.712898 err=75.712898
I 2015-05-26 05:41:02 theanets.trainer:168 RmsProp 134 loss=73.518402 err=73.518402
I 2015-05-26 05:41:51 theanets.trainer:168 RmsProp 135 loss=71.534111 err=71.534111
I 2015-05-26 05:42:40 theanets.trainer:168 RmsProp 136 loss=70.208977 err=70.208977
I 2015-05-26 05:43:29 theanets.trainer:168 RmsProp 137 loss=69.076416 err=69.076416
I 2015-05-26 05:44:18 theanets.trainer:168 RmsProp 138 loss=66.868492 err=66.868492
I 2015-05-26 05:45:08 theanets.trainer:168 RmsProp 139 loss=66.915520 err=66.915520
I 2015-05-26 05:45:57 theanets.trainer:168 RmsProp 140 loss=63.614002 err=63.614002
I 2015-05-26 05:45:58 theanets.trainer:168 validation 14 loss=1686.868774 err=1686.868774 *
I 2015-05-26 05:46:48 theanets.trainer:168 RmsProp 141 loss=63.354908 err=63.354908
I 2015-05-26 05:47:38 theanets.trainer:168 RmsProp 142 loss=62.895958 err=62.895958
I 2015-05-26 05:48:27 theanets.trainer:168 RmsProp 143 loss=61.441322 err=61.441322
I 2015-05-26 05:49:17 theanets.trainer:168 RmsProp 144 loss=60.553799 err=60.553799
I 2015-05-26 05:50:07 theanets.trainer:168 RmsProp 145 loss=58.931625 err=58.931625
I 2015-05-26 05:50:57 theanets.trainer:168 RmsProp 146 loss=58.693127 err=58.693127
I 2015-05-26 05:51:46 theanets.trainer:168 RmsProp 147 loss=56.428642 err=56.428642
I 2015-05-26 05:52:35 theanets.trainer:168 RmsProp 148 loss=58.227135 err=58.227135
I 2015-05-26 05:53:24 theanets.trainer:168 RmsProp 149 loss=55.293949 err=55.293949
I 2015-05-26 05:54:14 theanets.trainer:168 RmsProp 150 loss=54.804512 err=54.804512
I 2015-05-26 05:54:15 theanets.trainer:168 validation 15 loss=1643.330933 err=1643.330933 *
I 2015-05-26 05:55:04 theanets.trainer:168 RmsProp 151 loss=53.741333 err=53.741333
I 2015-05-26 05:55:53 theanets.trainer:168 RmsProp 152 loss=51.652336 err=51.652336
I 2015-05-26 05:56:43 theanets.trainer:168 RmsProp 153 loss=51.625195 err=51.625195
I 2015-05-26 05:57:32 theanets.trainer:168 RmsProp 154 loss=50.246929 err=50.246929
I 2015-05-26 05:58:22 theanets.trainer:168 RmsProp 155 loss=49.437809 err=49.437809
I 2015-05-26 05:59:11 theanets.trainer:168 RmsProp 156 loss=47.652542 err=47.652542
I 2015-05-26 06:00:00 theanets.trainer:168 RmsProp 157 loss=47.095264 err=47.095264
I 2015-05-26 06:00:49 theanets.trainer:168 RmsProp 158 loss=46.676693 err=46.676693
I 2015-05-26 06:01:39 theanets.trainer:168 RmsProp 159 loss=47.763123 err=47.763123
I 2015-05-26 06:02:28 theanets.trainer:168 RmsProp 160 loss=45.953632 err=45.953632
I 2015-05-26 06:02:29 theanets.trainer:168 validation 16 loss=1668.159546 err=1668.159546
I 2015-05-26 06:03:19 theanets.trainer:168 RmsProp 161 loss=45.155323 err=45.155323
I 2015-05-26 06:04:09 theanets.trainer:168 RmsProp 162 loss=43.926731 err=43.926731
I 2015-05-26 06:04:58 theanets.trainer:168 RmsProp 163 loss=43.981335 err=43.981335
I 2015-05-26 06:05:47 theanets.trainer:168 RmsProp 164 loss=43.196133 err=43.196133
I 2015-05-26 06:06:37 theanets.trainer:168 RmsProp 165 loss=42.694992 err=42.694992
I 2015-05-26 06:07:24 theanets.trainer:168 RmsProp 166 loss=42.543232 err=42.543232
I 2015-05-26 06:08:11 theanets.trainer:168 RmsProp 167 loss=41.392681 err=41.392681
I 2015-05-26 06:09:01 theanets.trainer:168 RmsProp 168 loss=41.392612 err=41.392612
I 2015-05-26 06:09:50 theanets.trainer:168 RmsProp 169 loss=39.635399 err=39.635399
I 2015-05-26 06:10:39 theanets.trainer:168 RmsProp 170 loss=38.906071 err=38.906071
I 2015-05-26 06:10:40 theanets.trainer:168 validation 17 loss=1650.999390 err=1650.999390
I 2015-05-26 06:11:29 theanets.trainer:168 RmsProp 171 loss=38.170631 err=38.170631
I 2015-05-26 06:12:18 theanets.trainer:168 RmsProp 172 loss=37.472237 err=37.472237
I 2015-05-26 06:13:08 theanets.trainer:168 RmsProp 173 loss=37.999245 err=37.999245
I 2015-05-26 06:13:58 theanets.trainer:168 RmsProp 174 loss=36.136299 err=36.136299
I 2015-05-26 06:14:48 theanets.trainer:168 RmsProp 175 loss=36.725163 err=36.725163
I 2015-05-26 06:15:37 theanets.trainer:168 RmsProp 176 loss=36.852276 err=36.852276
I 2015-05-26 06:16:27 theanets.trainer:168 RmsProp 177 loss=35.241909 err=35.241909
I 2015-05-26 06:17:17 theanets.trainer:168 RmsProp 178 loss=34.420609 err=34.420609
I 2015-05-26 06:18:07 theanets.trainer:168 RmsProp 179 loss=34.266247 err=34.266247
I 2015-05-26 06:18:57 theanets.trainer:168 RmsProp 180 loss=33.470798 err=33.470798
I 2015-05-26 06:18:58 theanets.trainer:168 validation 18 loss=1641.126587 err=1641.126587 *
I 2015-05-26 06:19:46 theanets.trainer:168 RmsProp 181 loss=33.120506 err=33.120506
I 2015-05-26 06:20:33 theanets.trainer:168 RmsProp 182 loss=32.884472 err=32.884472
I 2015-05-26 06:21:22 theanets.trainer:168 RmsProp 183 loss=33.408890 err=33.408890
I 2015-05-26 06:22:11 theanets.trainer:168 RmsProp 184 loss=33.080151 err=33.080151
I 2015-05-26 06:23:00 theanets.trainer:168 RmsProp 185 loss=32.735123 err=32.735123
I 2015-05-26 06:23:49 theanets.trainer:168 RmsProp 186 loss=31.732836 err=31.732836
I 2015-05-26 06:24:38 theanets.trainer:168 RmsProp 187 loss=31.412170 err=31.412170
I 2015-05-26 06:25:27 theanets.trainer:168 RmsProp 188 loss=30.122719 err=30.122719
I 2015-05-26 06:26:16 theanets.trainer:168 RmsProp 189 loss=29.599236 err=29.599236
I 2015-05-26 06:27:05 theanets.trainer:168 RmsProp 190 loss=28.831049 err=28.831049
I 2015-05-26 06:27:06 theanets.trainer:168 validation 19 loss=1647.233032 err=1647.233032
I 2015-05-26 06:27:56 theanets.trainer:168 RmsProp 191 loss=29.118753 err=29.118753
I 2015-05-26 06:28:45 theanets.trainer:168 RmsProp 192 loss=28.550623 err=28.550623
I 2015-05-26 06:29:35 theanets.trainer:168 RmsProp 193 loss=28.310408 err=28.310408
I 2015-05-26 06:30:25 theanets.trainer:168 RmsProp 194 loss=28.506220 err=28.506220
I 2015-05-26 06:31:14 theanets.trainer:168 RmsProp 195 loss=26.830017 err=26.830017
I 2015-05-26 06:32:04 theanets.trainer:168 RmsProp 196 loss=26.535583 err=26.535583
I 2015-05-26 06:32:54 theanets.trainer:168 RmsProp 197 loss=26.086721 err=26.086721
I 2015-05-26 06:33:43 theanets.trainer:168 RmsProp 198 loss=26.470242 err=26.470242
I 2015-05-26 06:34:32 theanets.trainer:168 RmsProp 199 loss=26.523634 err=26.523634
I 2015-05-26 06:35:17 theanets.trainer:168 RmsProp 200 loss=25.038887 err=25.038887
I 2015-05-26 06:35:18 theanets.trainer:168 validation 20 loss=1619.022949 err=1619.022949 *
I 2015-05-26 06:36:04 theanets.trainer:168 RmsProp 201 loss=24.668495 err=24.668495
I 2015-05-26 06:36:50 theanets.trainer:168 RmsProp 202 loss=25.441658 err=25.441658
I 2015-05-26 06:37:37 theanets.trainer:168 RmsProp 203 loss=25.110430 err=25.110430
I 2015-05-26 06:38:23 theanets.trainer:168 RmsProp 204 loss=24.834690 err=24.834690
I 2015-05-26 06:39:10 theanets.trainer:168 RmsProp 205 loss=24.081148 err=24.081148
I 2015-05-26 06:39:57 theanets.trainer:168 RmsProp 206 loss=24.145140 err=24.145140
I 2015-05-26 06:40:42 theanets.trainer:168 RmsProp 207 loss=24.091162 err=24.091162
I 2015-05-26 06:41:28 theanets.trainer:168 RmsProp 208 loss=23.313562 err=23.313562
I 2015-05-26 06:42:13 theanets.trainer:168 RmsProp 209 loss=22.852436 err=22.852436
I 2015-05-26 06:42:58 theanets.trainer:168 RmsProp 210 loss=22.824825 err=22.824825
I 2015-05-26 06:42:59 theanets.trainer:168 validation 21 loss=1643.116577 err=1643.116577
I 2015-05-26 06:43:44 theanets.trainer:168 RmsProp 211 loss=22.675817 err=22.675817
I 2015-05-26 06:44:29 theanets.trainer:168 RmsProp 212 loss=21.409847 err=21.409847
I 2015-05-26 06:45:14 theanets.trainer:168 RmsProp 213 loss=21.671267 err=21.671267
I 2015-05-26 06:45:59 theanets.trainer:168 RmsProp 214 loss=22.475300 err=22.475300
I 2015-05-26 06:46:44 theanets.trainer:168 RmsProp 215 loss=20.173615 err=20.173615
I 2015-05-26 06:47:29 theanets.trainer:168 RmsProp 216 loss=20.246803 err=20.246803
I 2015-05-26 06:48:14 theanets.trainer:168 RmsProp 217 loss=21.622490 err=21.622490
I 2015-05-26 06:48:59 theanets.trainer:168 RmsProp 218 loss=18.838366 err=18.838366
I 2015-05-26 06:49:43 theanets.trainer:168 RmsProp 219 loss=17.186384 err=17.186384
I 2015-05-26 06:50:28 theanets.trainer:168 RmsProp 220 loss=16.483236 err=16.483236
I 2015-05-26 06:50:29 theanets.trainer:168 validation 22 loss=1516.957397 err=1516.957397 *
I 2015-05-26 06:51:15 theanets.trainer:168 RmsProp 221 loss=16.095009 err=16.095009
I 2015-05-26 06:52:00 theanets.trainer:168 RmsProp 222 loss=15.323170 err=15.323170
I 2015-05-26 06:52:44 theanets.trainer:168 RmsProp 223 loss=14.475236 err=14.475236
I 2015-05-26 06:53:29 theanets.trainer:168 RmsProp 224 loss=14.885715 err=14.885715
I 2015-05-26 06:54:14 theanets.trainer:168 RmsProp 225 loss=14.719496 err=14.719496
I 2015-05-26 06:54:59 theanets.trainer:168 RmsProp 226 loss=15.690963 err=15.690963
I 2015-05-26 06:55:44 theanets.trainer:168 RmsProp 227 loss=16.665289 err=16.665289
I 2015-05-26 06:56:30 theanets.trainer:168 RmsProp 228 loss=13.829077 err=13.829077
I 2015-05-26 06:57:15 theanets.trainer:168 RmsProp 229 loss=13.630144 err=13.630144
I 2015-05-26 06:57:58 theanets.trainer:168 RmsProp 230 loss=14.412347 err=14.412347
I 2015-05-26 06:57:59 theanets.trainer:168 validation 23 loss=1482.981934 err=1482.981934 *
I 2015-05-26 06:58:40 theanets.trainer:168 RmsProp 231 loss=13.374654 err=13.374654
I 2015-05-26 06:59:20 theanets.trainer:168 RmsProp 232 loss=13.396496 err=13.396496
I 2015-05-26 07:00:01 theanets.trainer:168 RmsProp 233 loss=13.632136 err=13.632136
I 2015-05-26 07:00:42 theanets.trainer:168 RmsProp 234 loss=15.016235 err=15.016235
I 2015-05-26 07:01:22 theanets.trainer:168 RmsProp 235 loss=15.715420 err=15.715420
I 2015-05-26 07:02:04 theanets.trainer:168 RmsProp 236 loss=17.851007 err=17.851007
I 2015-05-26 07:02:45 theanets.trainer:168 RmsProp 237 loss=15.991394 err=15.991394
I 2015-05-26 07:03:26 theanets.trainer:168 RmsProp 238 loss=16.666441 err=16.666441
I 2015-05-26 07:04:08 theanets.trainer:168 RmsProp 239 loss=14.516423 err=14.516423
I 2015-05-26 07:04:49 theanets.trainer:168 RmsProp 240 loss=14.166559 err=14.166559
I 2015-05-26 07:04:50 theanets.trainer:168 validation 24 loss=1597.662476 err=1597.662476
I 2015-05-26 07:05:29 theanets.trainer:168 RmsProp 241 loss=14.410300 err=14.410300
I 2015-05-26 07:06:07 theanets.trainer:168 RmsProp 242 loss=14.920312 err=14.920312
I 2015-05-26 07:06:47 theanets.trainer:168 RmsProp 243 loss=11.618058 err=11.618058
I 2015-05-26 07:07:29 theanets.trainer:168 RmsProp 244 loss=12.049311 err=12.049311
I 2015-05-26 07:08:10 theanets.trainer:168 RmsProp 245 loss=10.893497 err=10.893497
I 2015-05-26 07:08:52 theanets.trainer:168 RmsProp 246 loss=11.135324 err=11.135324
I 2015-05-26 07:09:32 theanets.trainer:168 RmsProp 247 loss=11.733603 err=11.733603
I 2015-05-26 07:10:14 theanets.trainer:168 RmsProp 248 loss=11.133177 err=11.133177
I 2015-05-26 07:10:55 theanets.trainer:168 RmsProp 249 loss=9.958033 err=9.958033
I 2015-05-26 07:11:36 theanets.trainer:168 RmsProp 250 loss=12.075258 err=12.075258
I 2015-05-26 07:11:37 theanets.trainer:168 validation 25 loss=1501.576538 err=1501.576538
I 2015-05-26 07:12:16 theanets.trainer:168 RmsProp 251 loss=11.955344 err=11.955344
I 2015-05-26 07:12:55 theanets.trainer:168 RmsProp 252 loss=10.420843 err=10.420843
I 2015-05-26 07:13:33 theanets.trainer:168 RmsProp 253 loss=9.896944 err=9.896944
I 2015-05-26 07:14:13 theanets.trainer:168 RmsProp 254 loss=9.545714 err=9.545714
I 2015-05-26 07:14:54 theanets.trainer:168 RmsProp 255 loss=9.609539 err=9.609539
I 2015-05-26 07:15:36 theanets.trainer:168 RmsProp 256 loss=9.750095 err=9.750095
I 2015-05-26 07:16:16 theanets.trainer:168 RmsProp 257 loss=11.713553 err=11.713553
I 2015-05-26 07:16:57 theanets.trainer:168 RmsProp 258 loss=9.727213 err=9.727213
I 2015-05-26 07:17:38 theanets.trainer:168 RmsProp 259 loss=9.502627 err=9.502627
I 2015-05-26 07:18:18 theanets.trainer:168 RmsProp 260 loss=11.505715 err=11.505715
I 2015-05-26 07:18:19 theanets.trainer:168 validation 26 loss=1423.217896 err=1423.217896 *
I 2015-05-26 07:19:00 theanets.trainer:168 RmsProp 261 loss=9.532592 err=9.532592
I 2015-05-26 07:19:41 theanets.trainer:168 RmsProp 262 loss=10.043916 err=10.043916
I 2015-05-26 07:20:22 theanets.trainer:168 RmsProp 263 loss=9.874613 err=9.874613
I 2015-05-26 07:21:03 theanets.trainer:168 RmsProp 264 loss=9.779941 err=9.779941
I 2015-05-26 07:21:44 theanets.trainer:168 RmsProp 265 loss=9.151062 err=9.151062
I 2015-05-26 07:22:24 theanets.trainer:168 RmsProp 266 loss=8.813365 err=8.813365
I 2015-05-26 07:23:05 theanets.trainer:168 RmsProp 267 loss=11.127776 err=11.127776
I 2015-05-26 07:23:47 theanets.trainer:168 RmsProp 268 loss=9.454379 err=9.454379
I 2015-05-26 07:24:28 theanets.trainer:168 RmsProp 269 loss=8.897722 err=8.897722
I 2015-05-26 07:25:08 theanets.trainer:168 RmsProp 270 loss=8.386565 err=8.386565
I 2015-05-26 07:25:09 theanets.trainer:168 validation 27 loss=1425.015625 err=1425.015625
I 2015-05-26 07:25:48 theanets.trainer:168 RmsProp 271 loss=7.755472 err=7.755472
I 2015-05-26 07:26:27 theanets.trainer:168 RmsProp 272 loss=8.043463 err=8.043463
I 2015-05-26 07:27:05 theanets.trainer:168 RmsProp 273 loss=8.028398 err=8.028398
I 2015-05-26 07:27:42 theanets.trainer:168 RmsProp 274 loss=7.814283 err=7.814283
I 2015-05-26 07:28:20 theanets.trainer:168 RmsProp 275 loss=8.410484 err=8.410484
I 2015-05-26 07:28:57 theanets.trainer:168 RmsProp 276 loss=8.508288 err=8.508288
I 2015-05-26 07:29:35 theanets.trainer:168 RmsProp 277 loss=7.400489 err=7.400489
I 2015-05-26 07:30:13 theanets.trainer:168 RmsProp 278 loss=7.713750 err=7.713750
I 2015-05-26 07:30:51 theanets.trainer:168 RmsProp 279 loss=7.412257 err=7.412257
I 2015-05-26 07:31:28 theanets.trainer:168 RmsProp 280 loss=9.076443 err=9.076443
I 2015-05-26 07:31:29 theanets.trainer:168 validation 28 loss=1517.993530 err=1517.993530
I 2015-05-26 07:32:05 theanets.trainer:168 RmsProp 281 loss=10.226266 err=10.226266
I 2015-05-26 07:32:41 theanets.trainer:168 RmsProp 282 loss=8.650895 err=8.650895
I 2015-05-26 07:33:16 theanets.trainer:168 RmsProp 283 loss=9.097754 err=9.097754
I 2015-05-26 07:33:54 theanets.trainer:168 RmsProp 284 loss=8.427108 err=8.427108
I 2015-05-26 07:34:31 theanets.trainer:168 RmsProp 285 loss=8.632618 err=8.632618
I 2015-05-26 07:35:08 theanets.trainer:168 RmsProp 286 loss=7.959765 err=7.959765
I 2015-05-26 07:35:45 theanets.trainer:168 RmsProp 287 loss=8.604465 err=8.604465
I 2015-05-26 07:36:23 theanets.trainer:168 RmsProp 288 loss=7.899676 err=7.899676
I 2015-05-26 07:37:00 theanets.trainer:168 RmsProp 289 loss=8.377084 err=8.377084
I 2015-05-26 07:37:37 theanets.trainer:168 RmsProp 290 loss=8.923568 err=8.923568
I 2015-05-26 07:37:38 theanets.trainer:168 validation 29 loss=1514.899414 err=1514.899414
I 2015-05-26 07:38:16 theanets.trainer:168 RmsProp 291 loss=7.460874 err=7.460874
I 2015-05-26 07:38:53 theanets.trainer:168 RmsProp 292 loss=8.634522 err=8.634522
I 2015-05-26 07:39:31 theanets.trainer:168 RmsProp 293 loss=8.722499 err=8.722499
I 2015-05-26 07:40:10 theanets.trainer:168 RmsProp 294 loss=7.432574 err=7.432574
I 2015-05-26 07:40:49 theanets.trainer:168 RmsProp 295 loss=7.454895 err=7.454895
I 2015-05-26 07:41:27 theanets.trainer:168 RmsProp 296 loss=8.307071 err=8.307071
I 2015-05-26 07:42:06 theanets.trainer:168 RmsProp 297 loss=7.682343 err=7.682343
I 2015-05-26 07:42:44 theanets.trainer:168 RmsProp 298 loss=6.572702 err=6.572702
I 2015-05-26 07:43:21 theanets.trainer:168 RmsProp 299 loss=6.784064 err=6.784064
I 2015-05-26 07:43:59 theanets.trainer:168 RmsProp 300 loss=7.488565 err=7.488565
I 2015-05-26 07:43:59 theanets.trainer:168 validation 30 loss=1486.066528 err=1486.066528
I 2015-05-26 07:44:36 theanets.trainer:168 RmsProp 301 loss=6.899729 err=6.899729
I 2015-05-26 07:45:13 theanets.trainer:168 RmsProp 302 loss=7.494013 err=7.494013
I 2015-05-26 07:45:49 theanets.trainer:168 RmsProp 303 loss=7.144827 err=7.144827
I 2015-05-26 07:46:26 theanets.trainer:168 RmsProp 304 loss=7.160117 err=7.160117
I 2015-05-26 07:47:02 theanets.trainer:168 RmsProp 305 loss=7.014248 err=7.014248
I 2015-05-26 07:47:39 theanets.trainer:168 RmsProp 306 loss=6.232300 err=6.232300
I 2015-05-26 07:48:15 theanets.trainer:168 RmsProp 307 loss=7.512650 err=7.512650
I 2015-05-26 07:48:52 theanets.trainer:168 RmsProp 308 loss=6.296593 err=6.296593
I 2015-05-26 07:49:28 theanets.trainer:168 RmsProp 309 loss=6.030237 err=6.030237
I 2015-05-26 07:50:03 theanets.trainer:168 RmsProp 310 loss=6.032945 err=6.032945
I 2015-05-26 07:50:04 theanets.trainer:168 validation 31 loss=1495.930542 err=1495.930542
I 2015-05-26 07:50:04 theanets.trainer:252 patience elapsed!
I 2015-05-26 07:50:04 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 07:50:04 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 07:50:04 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 07:50:04 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 07:50:04 theanets.main:89 --batch_size = 1024
I 2015-05-26 07:50:04 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 07:50:04 theanets.main:89 --hidden_l1 = None
I 2015-05-26 07:50:04 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 07:50:04 theanets.main:89 --train_batches = 10
I 2015-05-26 07:50:04 theanets.main:89 --valid_batches = 2
I 2015-05-26 07:50:04 theanets.main:89 --weight_l1 = None
I 2015-05-26 07:50:04 theanets.main:89 --weight_l2 = None
I 2015-05-26 07:50:04 theanets.trainer:134 compiling evaluation function
I 2015-05-26 07:50:13 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 07:51:48 theanets.trainer:168 validation 0 loss=1353.082397 err=1353.082397 *
I 2015-05-26 07:52:00 theanets.trainer:168 RmsProp 1 loss=6.741150 err=6.741150
I 2015-05-26 07:52:12 theanets.trainer:168 RmsProp 2 loss=3.912828 err=3.912828
I 2015-05-26 07:52:24 theanets.trainer:168 RmsProp 3 loss=2.863803 err=2.863803
I 2015-05-26 07:52:36 theanets.trainer:168 RmsProp 4 loss=2.308252 err=2.308252
I 2015-05-26 07:52:48 theanets.trainer:168 RmsProp 5 loss=1.988778 err=1.988778
I 2015-05-26 07:53:00 theanets.trainer:168 RmsProp 6 loss=1.810321 err=1.810321
I 2015-05-26 07:53:12 theanets.trainer:168 RmsProp 7 loss=1.640740 err=1.640740
I 2015-05-26 07:53:25 theanets.trainer:168 RmsProp 8 loss=1.559167 err=1.559167
I 2015-05-26 07:53:37 theanets.trainer:168 RmsProp 9 loss=1.429047 err=1.429047
I 2015-05-26 07:53:49 theanets.trainer:168 RmsProp 10 loss=1.335498 err=1.335498
I 2015-05-26 07:53:50 theanets.trainer:168 validation 1 loss=1342.148071 err=1342.148071 *
I 2015-05-26 07:54:02 theanets.trainer:168 RmsProp 11 loss=1.255943 err=1.255943
I 2015-05-26 07:54:15 theanets.trainer:168 RmsProp 12 loss=1.220677 err=1.220677
I 2015-05-26 07:54:27 theanets.trainer:168 RmsProp 13 loss=1.151908 err=1.151908
I 2015-05-26 07:54:39 theanets.trainer:168 RmsProp 14 loss=1.079465 err=1.079465
I 2015-05-26 07:54:51 theanets.trainer:168 RmsProp 15 loss=1.046510 err=1.046510
I 2015-05-26 07:55:03 theanets.trainer:168 RmsProp 16 loss=1.005297 err=1.005297
I 2015-05-26 07:55:16 theanets.trainer:168 RmsProp 17 loss=0.949382 err=0.949382
I 2015-05-26 07:55:28 theanets.trainer:168 RmsProp 18 loss=0.917199 err=0.917199
I 2015-05-26 07:55:40 theanets.trainer:168 RmsProp 19 loss=0.886654 err=0.886654
I 2015-05-26 07:55:52 theanets.trainer:168 RmsProp 20 loss=0.867732 err=0.867732
I 2015-05-26 07:55:53 theanets.trainer:168 validation 2 loss=1335.586792 err=1335.586792 *
I 2015-05-26 07:56:05 theanets.trainer:168 RmsProp 21 loss=0.848482 err=0.848482
I 2015-05-26 07:56:18 theanets.trainer:168 RmsProp 22 loss=0.813605 err=0.813605
I 2015-05-26 07:56:30 theanets.trainer:168 RmsProp 23 loss=0.792266 err=0.792266
I 2015-05-26 07:56:42 theanets.trainer:168 RmsProp 24 loss=0.776983 err=0.776983
I 2015-05-26 07:56:54 theanets.trainer:168 RmsProp 25 loss=0.751989 err=0.751989
I 2015-05-26 07:57:07 theanets.trainer:168 RmsProp 26 loss=0.727444 err=0.727444
I 2015-05-26 07:57:19 theanets.trainer:168 RmsProp 27 loss=0.725285 err=0.725285
I 2015-05-26 07:57:32 theanets.trainer:168 RmsProp 28 loss=0.697361 err=0.697361
I 2015-05-26 07:57:44 theanets.trainer:168 RmsProp 29 loss=0.681004 err=0.681004
I 2015-05-26 07:57:56 theanets.trainer:168 RmsProp 30 loss=0.699178 err=0.699178
I 2015-05-26 07:57:56 theanets.trainer:168 validation 3 loss=1325.893799 err=1325.893799 *
I 2015-05-26 07:58:08 theanets.trainer:168 RmsProp 31 loss=0.647455 err=0.647455
I 2015-05-26 07:58:20 theanets.trainer:168 RmsProp 32 loss=0.635924 err=0.635924
I 2015-05-26 07:58:31 theanets.trainer:168 RmsProp 33 loss=0.625617 err=0.625617
I 2015-05-26 07:58:43 theanets.trainer:168 RmsProp 34 loss=0.614589 err=0.614589
I 2015-05-26 07:58:55 theanets.trainer:168 RmsProp 35 loss=0.592548 err=0.592548
I 2015-05-26 07:59:06 theanets.trainer:168 RmsProp 36 loss=0.629188 err=0.629188
I 2015-05-26 07:59:18 theanets.trainer:168 RmsProp 37 loss=0.613038 err=0.613038
I 2015-05-26 07:59:29 theanets.trainer:168 RmsProp 38 loss=0.575867 err=0.575867
I 2015-05-26 07:59:41 theanets.trainer:168 RmsProp 39 loss=0.554925 err=0.554925
I 2015-05-26 07:59:53 theanets.trainer:168 RmsProp 40 loss=0.556696 err=0.556696
I 2015-05-26 07:59:54 theanets.trainer:168 validation 4 loss=1323.477051 err=1323.477051 *
I 2015-05-26 08:00:06 theanets.trainer:168 RmsProp 41 loss=0.567713 err=0.567713
I 2015-05-26 08:00:18 theanets.trainer:168 RmsProp 42 loss=0.544566 err=0.544566
I 2015-05-26 08:00:30 theanets.trainer:168 RmsProp 43 loss=0.542077 err=0.542077
I 2015-05-26 08:00:42 theanets.trainer:168 RmsProp 44 loss=0.523774 err=0.523774
I 2015-05-26 08:00:55 theanets.trainer:168 RmsProp 45 loss=0.507581 err=0.507581
I 2015-05-26 08:01:07 theanets.trainer:168 RmsProp 46 loss=0.517162 err=0.517162
I 2015-05-26 08:01:19 theanets.trainer:168 RmsProp 47 loss=0.509270 err=0.509270
I 2015-05-26 08:01:32 theanets.trainer:168 RmsProp 48 loss=0.491538 err=0.491538
I 2015-05-26 08:01:44 theanets.trainer:168 RmsProp 49 loss=0.506352 err=0.506352
I 2015-05-26 08:01:55 theanets.trainer:168 RmsProp 50 loss=0.476389 err=0.476389
I 2015-05-26 08:01:56 theanets.trainer:168 validation 5 loss=1324.314087 err=1324.314087
I 2015-05-26 08:02:06 theanets.trainer:168 RmsProp 51 loss=0.469518 err=0.469518
I 2015-05-26 08:02:17 theanets.trainer:168 RmsProp 52 loss=0.476531 err=0.476531
I 2015-05-26 08:02:27 theanets.trainer:168 RmsProp 53 loss=0.466895 err=0.466895
I 2015-05-26 08:02:37 theanets.trainer:168 RmsProp 54 loss=0.453974 err=0.453974
I 2015-05-26 08:02:48 theanets.trainer:168 RmsProp 55 loss=0.453061 err=0.453061
I 2015-05-26 08:02:58 theanets.trainer:168 RmsProp 56 loss=0.446340 err=0.446340
I 2015-05-26 08:03:09 theanets.trainer:168 RmsProp 57 loss=0.430376 err=0.430376
I 2015-05-26 08:03:19 theanets.trainer:168 RmsProp 58 loss=0.429983 err=0.429983
I 2015-05-26 08:03:29 theanets.trainer:168 RmsProp 59 loss=0.439818 err=0.439818
I 2015-05-26 08:03:40 theanets.trainer:168 RmsProp 60 loss=0.441727 err=0.441727
I 2015-05-26 08:03:40 theanets.trainer:168 validation 6 loss=1322.007446 err=1322.007446 *
I 2015-05-26 08:03:51 theanets.trainer:168 RmsProp 61 loss=0.425610 err=0.425610
I 2015-05-26 08:04:02 theanets.trainer:168 RmsProp 62 loss=0.411004 err=0.411004
I 2015-05-26 08:04:13 theanets.trainer:168 RmsProp 63 loss=0.412102 err=0.412102
I 2015-05-26 08:04:24 theanets.trainer:168 RmsProp 64 loss=0.407323 err=0.407323
I 2015-05-26 08:04:35 theanets.trainer:168 RmsProp 65 loss=0.410612 err=0.410612
I 2015-05-26 08:04:45 theanets.trainer:168 RmsProp 66 loss=0.406124 err=0.406124
I 2015-05-26 08:04:57 theanets.trainer:168 RmsProp 67 loss=0.399043 err=0.399043
I 2015-05-26 08:05:08 theanets.trainer:168 RmsProp 68 loss=0.407976 err=0.407976
I 2015-05-26 08:05:19 theanets.trainer:168 RmsProp 69 loss=0.389220 err=0.389220
I 2015-05-26 08:05:30 theanets.trainer:168 RmsProp 70 loss=0.392580 err=0.392580
I 2015-05-26 08:05:31 theanets.trainer:168 validation 7 loss=1315.971069 err=1315.971069 *
I 2015-05-26 08:05:41 theanets.trainer:168 RmsProp 71 loss=0.383693 err=0.383693
I 2015-05-26 08:05:52 theanets.trainer:168 RmsProp 72 loss=0.377151 err=0.377151
I 2015-05-26 08:06:03 theanets.trainer:168 RmsProp 73 loss=0.378209 err=0.378209
I 2015-05-26 08:06:14 theanets.trainer:168 RmsProp 74 loss=0.378442 err=0.378442
I 2015-05-26 08:06:25 theanets.trainer:168 RmsProp 75 loss=0.364401 err=0.364401
I 2015-05-26 08:06:36 theanets.trainer:168 RmsProp 76 loss=0.375145 err=0.375145
I 2015-05-26 08:06:48 theanets.trainer:168 RmsProp 77 loss=0.360699 err=0.360699
I 2015-05-26 08:06:59 theanets.trainer:168 RmsProp 78 loss=0.360822 err=0.360822
I 2015-05-26 08:07:10 theanets.trainer:168 RmsProp 79 loss=0.356298 err=0.356298
I 2015-05-26 08:07:21 theanets.trainer:168 RmsProp 80 loss=0.354272 err=0.354272
I 2015-05-26 08:07:22 theanets.trainer:168 validation 8 loss=1311.028198 err=1311.028198 *
I 2015-05-26 08:07:32 theanets.trainer:168 RmsProp 81 loss=0.368513 err=0.368513
I 2015-05-26 08:07:42 theanets.trainer:168 RmsProp 82 loss=0.350024 err=0.350024
I 2015-05-26 08:07:52 theanets.trainer:168 RmsProp 83 loss=0.352632 err=0.352632
I 2015-05-26 08:08:03 theanets.trainer:168 RmsProp 84 loss=0.342916 err=0.342916
I 2015-05-26 08:08:13 theanets.trainer:168 RmsProp 85 loss=0.337930 err=0.337930
I 2015-05-26 08:08:23 theanets.trainer:168 RmsProp 86 loss=0.321116 err=0.321116
I 2015-05-26 08:08:33 theanets.trainer:168 RmsProp 87 loss=0.328281 err=0.328281
I 2015-05-26 08:08:44 theanets.trainer:168 RmsProp 88 loss=0.326488 err=0.326488
I 2015-05-26 08:08:54 theanets.trainer:168 RmsProp 89 loss=0.326100 err=0.326100
I 2015-05-26 08:09:05 theanets.trainer:168 RmsProp 90 loss=0.333272 err=0.333272
I 2015-05-26 08:09:05 theanets.trainer:168 validation 9 loss=1308.523804 err=1308.523804 *
I 2015-05-26 08:09:16 theanets.trainer:168 RmsProp 91 loss=0.325632 err=0.325632
I 2015-05-26 08:09:27 theanets.trainer:168 RmsProp 92 loss=0.337455 err=0.337455
I 2015-05-26 08:09:38 theanets.trainer:168 RmsProp 93 loss=0.315611 err=0.315611
I 2015-05-26 08:09:50 theanets.trainer:168 RmsProp 94 loss=0.312039 err=0.312039
I 2015-05-26 08:10:01 theanets.trainer:168 RmsProp 95 loss=0.319359 err=0.319359
I 2015-05-26 08:10:12 theanets.trainer:168 RmsProp 96 loss=0.311514 err=0.311514
I 2015-05-26 08:10:23 theanets.trainer:168 RmsProp 97 loss=0.312192 err=0.312192
I 2015-05-26 08:10:34 theanets.trainer:168 RmsProp 98 loss=0.309600 err=0.309600
I 2015-05-26 08:10:45 theanets.trainer:168 RmsProp 99 loss=0.300107 err=0.300107
I 2015-05-26 08:10:56 theanets.trainer:168 RmsProp 100 loss=0.315833 err=0.315833
I 2015-05-26 08:10:56 theanets.trainer:168 validation 10 loss=1308.165283 err=1308.165283 *
I 2015-05-26 08:11:08 theanets.trainer:168 RmsProp 101 loss=0.301737 err=0.301737
I 2015-05-26 08:11:19 theanets.trainer:168 RmsProp 102 loss=0.307118 err=0.307118
I 2015-05-26 08:11:30 theanets.trainer:168 RmsProp 103 loss=0.303765 err=0.303765
I 2015-05-26 08:11:41 theanets.trainer:168 RmsProp 104 loss=0.294161 err=0.294161
I 2015-05-26 08:11:52 theanets.trainer:168 RmsProp 105 loss=0.296110 err=0.296110
I 2015-05-26 08:12:03 theanets.trainer:168 RmsProp 106 loss=0.297412 err=0.297412
I 2015-05-26 08:12:14 theanets.trainer:168 RmsProp 107 loss=0.283229 err=0.283229
I 2015-05-26 08:12:25 theanets.trainer:168 RmsProp 108 loss=0.285253 err=0.285253
I 2015-05-26 08:12:36 theanets.trainer:168 RmsProp 109 loss=0.279195 err=0.279195
I 2015-05-26 08:12:47 theanets.trainer:168 RmsProp 110 loss=0.282540 err=0.282540
I 2015-05-26 08:12:48 theanets.trainer:168 validation 11 loss=1305.975220 err=1305.975220 *
I 2015-05-26 08:12:59 theanets.trainer:168 RmsProp 111 loss=0.277044 err=0.277044
I 2015-05-26 08:13:10 theanets.trainer:168 RmsProp 112 loss=0.273601 err=0.273601
I 2015-05-26 08:13:22 theanets.trainer:168 RmsProp 113 loss=0.273889 err=0.273889
I 2015-05-26 08:13:33 theanets.trainer:168 RmsProp 114 loss=0.274570 err=0.274570
I 2015-05-26 08:13:44 theanets.trainer:168 RmsProp 115 loss=0.279796 err=0.279796
I 2015-05-26 08:13:55 theanets.trainer:168 RmsProp 116 loss=0.275782 err=0.275782
I 2015-05-26 08:14:06 theanets.trainer:168 RmsProp 117 loss=0.274894 err=0.274894
I 2015-05-26 08:14:17 theanets.trainer:168 RmsProp 118 loss=0.269340 err=0.269340
I 2015-05-26 08:14:28 theanets.trainer:168 RmsProp 119 loss=0.271250 err=0.271250
I 2015-05-26 08:14:40 theanets.trainer:168 RmsProp 120 loss=0.272262 err=0.272262
I 2015-05-26 08:14:40 theanets.trainer:168 validation 12 loss=1302.344971 err=1302.344971 *
I 2015-05-26 08:14:51 theanets.trainer:168 RmsProp 121 loss=0.273909 err=0.273909
I 2015-05-26 08:15:02 theanets.trainer:168 RmsProp 122 loss=0.265007 err=0.265007
I 2015-05-26 08:15:14 theanets.trainer:168 RmsProp 123 loss=0.259369 err=0.259369
I 2015-05-26 08:15:25 theanets.trainer:168 RmsProp 124 loss=0.254935 err=0.254935
I 2015-05-26 08:15:36 theanets.trainer:168 RmsProp 125 loss=0.258128 err=0.258128
I 2015-05-26 08:15:48 theanets.trainer:168 RmsProp 126 loss=0.257273 err=0.257273
I 2015-05-26 08:15:59 theanets.trainer:168 RmsProp 127 loss=0.250445 err=0.250445
I 2015-05-26 08:16:10 theanets.trainer:168 RmsProp 128 loss=0.253568 err=0.253568
I 2015-05-26 08:16:22 theanets.trainer:168 RmsProp 129 loss=0.254462 err=0.254462
I 2015-05-26 08:16:33 theanets.trainer:168 RmsProp 130 loss=0.261433 err=0.261433
I 2015-05-26 08:16:33 theanets.trainer:168 validation 13 loss=1297.927734 err=1297.927734 *
I 2015-05-26 08:16:44 theanets.trainer:168 RmsProp 131 loss=0.250641 err=0.250641
I 2015-05-26 08:16:55 theanets.trainer:168 RmsProp 132 loss=0.242340 err=0.242340
I 2015-05-26 08:17:06 theanets.trainer:168 RmsProp 133 loss=0.251872 err=0.251872
I 2015-05-26 08:17:18 theanets.trainer:168 RmsProp 134 loss=0.251932 err=0.251932
I 2015-05-26 08:17:28 theanets.trainer:168 RmsProp 135 loss=0.237152 err=0.237152
I 2015-05-26 08:17:39 theanets.trainer:168 RmsProp 136 loss=0.241888 err=0.241888
I 2015-05-26 08:17:51 theanets.trainer:168 RmsProp 137 loss=0.247812 err=0.247812
I 2015-05-26 08:18:01 theanets.trainer:168 RmsProp 138 loss=0.246557 err=0.246557
I 2015-05-26 08:18:13 theanets.trainer:168 RmsProp 139 loss=0.245103 err=0.245103
I 2015-05-26 08:18:24 theanets.trainer:168 RmsProp 140 loss=0.231851 err=0.231851
I 2015-05-26 08:18:24 theanets.trainer:168 validation 14 loss=1295.889160 err=1295.889160 *
I 2015-05-26 08:18:35 theanets.trainer:168 RmsProp 141 loss=0.234756 err=0.234756
I 2015-05-26 08:18:46 theanets.trainer:168 RmsProp 142 loss=0.231378 err=0.231378
I 2015-05-26 08:18:57 theanets.trainer:168 RmsProp 143 loss=0.237246 err=0.237246
I 2015-05-26 08:19:08 theanets.trainer:168 RmsProp 144 loss=0.232425 err=0.232425
I 2015-05-26 08:19:19 theanets.trainer:168 RmsProp 145 loss=0.234424 err=0.234424
I 2015-05-26 08:19:30 theanets.trainer:168 RmsProp 146 loss=0.224741 err=0.224741
I 2015-05-26 08:19:41 theanets.trainer:168 RmsProp 147 loss=0.225468 err=0.225468
I 2015-05-26 08:19:53 theanets.trainer:168 RmsProp 148 loss=0.231645 err=0.231645
I 2015-05-26 08:20:05 theanets.trainer:168 RmsProp 149 loss=0.228110 err=0.228110
I 2015-05-26 08:20:16 theanets.trainer:168 RmsProp 150 loss=0.232728 err=0.232728
I 2015-05-26 08:20:17 theanets.trainer:168 validation 15 loss=1296.343018 err=1296.343018
I 2015-05-26 08:20:28 theanets.trainer:168 RmsProp 151 loss=0.225791 err=0.225791
I 2015-05-26 08:20:39 theanets.trainer:168 RmsProp 152 loss=0.216702 err=0.216702
I 2015-05-26 08:20:51 theanets.trainer:168 RmsProp 153 loss=0.238728 err=0.238728
I 2015-05-26 08:21:02 theanets.trainer:168 RmsProp 154 loss=0.223058 err=0.223058
I 2015-05-26 08:21:14 theanets.trainer:168 RmsProp 155 loss=0.218961 err=0.218961
I 2015-05-26 08:21:25 theanets.trainer:168 RmsProp 156 loss=0.217566 err=0.217566
I 2015-05-26 08:21:36 theanets.trainer:168 RmsProp 157 loss=0.216906 err=0.216906
I 2015-05-26 08:21:48 theanets.trainer:168 RmsProp 158 loss=0.219160 err=0.219160
I 2015-05-26 08:21:59 theanets.trainer:168 RmsProp 159 loss=0.215942 err=0.215942
I 2015-05-26 08:22:11 theanets.trainer:168 RmsProp 160 loss=0.211936 err=0.211936
I 2015-05-26 08:22:11 theanets.trainer:168 validation 16 loss=1294.441040 err=1294.441040 *
I 2015-05-26 08:22:22 theanets.trainer:168 RmsProp 161 loss=0.215505 err=0.215505
I 2015-05-26 08:22:34 theanets.trainer:168 RmsProp 162 loss=0.218006 err=0.218006
I 2015-05-26 08:22:45 theanets.trainer:168 RmsProp 163 loss=0.207239 err=0.207239
I 2015-05-26 08:22:57 theanets.trainer:168 RmsProp 164 loss=0.208087 err=0.208087
I 2015-05-26 08:23:08 theanets.trainer:168 RmsProp 165 loss=0.209931 err=0.209931
I 2015-05-26 08:23:20 theanets.trainer:168 RmsProp 166 loss=0.210701 err=0.210701
I 2015-05-26 08:23:31 theanets.trainer:168 RmsProp 167 loss=0.216797 err=0.216797
I 2015-05-26 08:23:42 theanets.trainer:168 RmsProp 168 loss=0.207486 err=0.207486
I 2015-05-26 08:23:53 theanets.trainer:168 RmsProp 169 loss=0.206828 err=0.206828
I 2015-05-26 08:24:05 theanets.trainer:168 RmsProp 170 loss=0.210178 err=0.210178
I 2015-05-26 08:24:05 theanets.trainer:168 validation 17 loss=1290.781982 err=1290.781982 *
I 2015-05-26 08:24:16 theanets.trainer:168 RmsProp 171 loss=0.207464 err=0.207464
I 2015-05-26 08:24:28 theanets.trainer:168 RmsProp 172 loss=0.205176 err=0.205176
I 2015-05-26 08:24:39 theanets.trainer:168 RmsProp 173 loss=0.199857 err=0.199857
I 2015-05-26 08:24:51 theanets.trainer:168 RmsProp 174 loss=0.205344 err=0.205344
I 2015-05-26 08:25:02 theanets.trainer:168 RmsProp 175 loss=0.198917 err=0.198917
I 2015-05-26 08:25:13 theanets.trainer:168 RmsProp 176 loss=0.201148 err=0.201148
I 2015-05-26 08:25:25 theanets.trainer:168 RmsProp 177 loss=0.203306 err=0.203306
I 2015-05-26 08:25:36 theanets.trainer:168 RmsProp 178 loss=0.191670 err=0.191670
I 2015-05-26 08:25:48 theanets.trainer:168 RmsProp 179 loss=0.205166 err=0.205166
I 2015-05-26 08:25:59 theanets.trainer:168 RmsProp 180 loss=0.197444 err=0.197444
I 2015-05-26 08:26:00 theanets.trainer:168 validation 18 loss=1289.567261 err=1289.567261 *
I 2015-05-26 08:26:11 theanets.trainer:168 RmsProp 181 loss=0.197738 err=0.197738
I 2015-05-26 08:26:23 theanets.trainer:168 RmsProp 182 loss=0.190961 err=0.190961
I 2015-05-26 08:26:35 theanets.trainer:168 RmsProp 183 loss=0.196495 err=0.196495
I 2015-05-26 08:26:46 theanets.trainer:168 RmsProp 184 loss=0.191754 err=0.191754
I 2015-05-26 08:26:58 theanets.trainer:168 RmsProp 185 loss=0.199645 err=0.199645
I 2015-05-26 08:27:09 theanets.trainer:168 RmsProp 186 loss=0.194980 err=0.194980
I 2015-05-26 08:27:21 theanets.trainer:168 RmsProp 187 loss=0.194356 err=0.194356
I 2015-05-26 08:27:33 theanets.trainer:168 RmsProp 188 loss=0.192533 err=0.192533
I 2015-05-26 08:27:44 theanets.trainer:168 RmsProp 189 loss=0.198491 err=0.198491
I 2015-05-26 08:27:56 theanets.trainer:168 RmsProp 190 loss=0.194976 err=0.194976
I 2015-05-26 08:27:56 theanets.trainer:168 validation 19 loss=1284.680054 err=1284.680054 *
I 2015-05-26 08:28:08 theanets.trainer:168 RmsProp 191 loss=0.189586 err=0.189586
I 2015-05-26 08:28:19 theanets.trainer:168 RmsProp 192 loss=0.184221 err=0.184221
I 2015-05-26 08:28:30 theanets.trainer:168 RmsProp 193 loss=0.192255 err=0.192255
I 2015-05-26 08:28:41 theanets.trainer:168 RmsProp 194 loss=0.182846 err=0.182846
I 2015-05-26 08:28:52 theanets.trainer:168 RmsProp 195 loss=0.192676 err=0.192676
I 2015-05-26 08:29:04 theanets.trainer:168 RmsProp 196 loss=0.186492 err=0.186492
I 2015-05-26 08:29:15 theanets.trainer:168 RmsProp 197 loss=0.178847 err=0.178847
I 2015-05-26 08:29:27 theanets.trainer:168 RmsProp 198 loss=0.184255 err=0.184255
I 2015-05-26 08:29:38 theanets.trainer:168 RmsProp 199 loss=0.191833 err=0.191833
I 2015-05-26 08:29:50 theanets.trainer:168 RmsProp 200 loss=0.185850 err=0.185850
I 2015-05-26 08:29:50 theanets.trainer:168 validation 20 loss=1284.244507 err=1284.244507 *
I 2015-05-26 08:30:02 theanets.trainer:168 RmsProp 201 loss=0.177278 err=0.177278
I 2015-05-26 08:30:13 theanets.trainer:168 RmsProp 202 loss=0.175947 err=0.175947
I 2015-05-26 08:30:25 theanets.trainer:168 RmsProp 203 loss=0.189965 err=0.189965
I 2015-05-26 08:30:37 theanets.trainer:168 RmsProp 204 loss=0.178488 err=0.178488
I 2015-05-26 08:30:48 theanets.trainer:168 RmsProp 205 loss=0.177835 err=0.177835
I 2015-05-26 08:31:00 theanets.trainer:168 RmsProp 206 loss=0.181277 err=0.181277
I 2015-05-26 08:31:11 theanets.trainer:168 RmsProp 207 loss=0.173525 err=0.173525
I 2015-05-26 08:31:23 theanets.trainer:168 RmsProp 208 loss=0.189884 err=0.189884
I 2015-05-26 08:31:33 theanets.trainer:168 RmsProp 209 loss=0.180248 err=0.180248
I 2015-05-26 08:31:44 theanets.trainer:168 RmsProp 210 loss=0.181431 err=0.181431
I 2015-05-26 08:31:44 theanets.trainer:168 validation 21 loss=1281.669434 err=1281.669434 *
I 2015-05-26 08:31:55 theanets.trainer:168 RmsProp 211 loss=0.173511 err=0.173511
I 2015-05-26 08:32:05 theanets.trainer:168 RmsProp 212 loss=0.168845 err=0.168845
I 2015-05-26 08:32:15 theanets.trainer:168 RmsProp 213 loss=0.172039 err=0.172039
I 2015-05-26 08:32:26 theanets.trainer:168 RmsProp 214 loss=0.183810 err=0.183810
I 2015-05-26 08:32:37 theanets.trainer:168 RmsProp 215 loss=0.170299 err=0.170299
I 2015-05-26 08:32:47 theanets.trainer:168 RmsProp 216 loss=0.169168 err=0.169168
I 2015-05-26 08:32:58 theanets.trainer:168 RmsProp 217 loss=0.174769 err=0.174769
I 2015-05-26 08:33:09 theanets.trainer:168 RmsProp 218 loss=0.178313 err=0.178313
I 2015-05-26 08:33:19 theanets.trainer:168 RmsProp 219 loss=0.173072 err=0.173072
I 2015-05-26 08:33:29 theanets.trainer:168 RmsProp 220 loss=0.169884 err=0.169884
I 2015-05-26 08:33:30 theanets.trainer:168 validation 22 loss=1279.941650 err=1279.941650 *
I 2015-05-26 08:33:40 theanets.trainer:168 RmsProp 221 loss=0.166047 err=0.166047
I 2015-05-26 08:33:50 theanets.trainer:168 RmsProp 222 loss=0.170965 err=0.170965
I 2015-05-26 08:34:01 theanets.trainer:168 RmsProp 223 loss=0.168673 err=0.168673
I 2015-05-26 08:34:11 theanets.trainer:168 RmsProp 224 loss=0.164110 err=0.164110
I 2015-05-26 08:34:21 theanets.trainer:168 RmsProp 225 loss=0.163676 err=0.163676
I 2015-05-26 08:34:32 theanets.trainer:168 RmsProp 226 loss=0.172915 err=0.172915
I 2015-05-26 08:34:42 theanets.trainer:168 RmsProp 227 loss=0.165613 err=0.165613
I 2015-05-26 08:34:52 theanets.trainer:168 RmsProp 228 loss=0.160543 err=0.160543
I 2015-05-26 08:35:03 theanets.trainer:168 RmsProp 229 loss=0.163832 err=0.163832
I 2015-05-26 08:35:13 theanets.trainer:168 RmsProp 230 loss=0.163790 err=0.163790
I 2015-05-26 08:35:14 theanets.trainer:168 validation 23 loss=1279.547241 err=1279.547241 *
I 2015-05-26 08:35:24 theanets.trainer:168 RmsProp 231 loss=0.168474 err=0.168474
I 2015-05-26 08:35:35 theanets.trainer:168 RmsProp 232 loss=0.159418 err=0.159418
I 2015-05-26 08:35:45 theanets.trainer:168 RmsProp 233 loss=0.164556 err=0.164556
I 2015-05-26 08:35:55 theanets.trainer:168 RmsProp 234 loss=0.153261 err=0.153261
I 2015-05-26 08:36:06 theanets.trainer:168 RmsProp 235 loss=0.175369 err=0.175369
I 2015-05-26 08:36:16 theanets.trainer:168 RmsProp 236 loss=0.159404 err=0.159404
I 2015-05-26 08:36:27 theanets.trainer:168 RmsProp 237 loss=0.156672 err=0.156672
I 2015-05-26 08:36:37 theanets.trainer:168 RmsProp 238 loss=0.161493 err=0.161493
I 2015-05-26 08:36:47 theanets.trainer:168 RmsProp 239 loss=0.160231 err=0.160231
I 2015-05-26 08:36:58 theanets.trainer:168 RmsProp 240 loss=0.154279 err=0.154279
I 2015-05-26 08:36:58 theanets.trainer:168 validation 24 loss=1277.669800 err=1277.669800 *
I 2015-05-26 08:37:09 theanets.trainer:168 RmsProp 241 loss=0.157350 err=0.157350
I 2015-05-26 08:37:20 theanets.trainer:168 RmsProp 242 loss=0.150590 err=0.150590
I 2015-05-26 08:37:30 theanets.trainer:168 RmsProp 243 loss=0.167800 err=0.167800
I 2015-05-26 08:37:40 theanets.trainer:168 RmsProp 244 loss=0.162228 err=0.162228
I 2015-05-26 08:37:51 theanets.trainer:168 RmsProp 245 loss=0.152554 err=0.152554
I 2015-05-26 08:38:01 theanets.trainer:168 RmsProp 246 loss=0.156721 err=0.156721
I 2015-05-26 08:38:12 theanets.trainer:168 RmsProp 247 loss=0.160676 err=0.160676
I 2015-05-26 08:38:23 theanets.trainer:168 RmsProp 248 loss=0.157198 err=0.157198
I 2015-05-26 08:38:33 theanets.trainer:168 RmsProp 249 loss=0.154368 err=0.154368
I 2015-05-26 08:38:43 theanets.trainer:168 RmsProp 250 loss=0.151940 err=0.151940
I 2015-05-26 08:38:44 theanets.trainer:168 validation 25 loss=1275.927979 err=1275.927979 *
I 2015-05-26 08:38:54 theanets.trainer:168 RmsProp 251 loss=0.146819 err=0.146819
I 2015-05-26 08:39:04 theanets.trainer:168 RmsProp 252 loss=0.160278 err=0.160278
I 2015-05-26 08:39:15 theanets.trainer:168 RmsProp 253 loss=0.157519 err=0.157519
I 2015-05-26 08:39:25 theanets.trainer:168 RmsProp 254 loss=0.150749 err=0.150749
I 2015-05-26 08:39:36 theanets.trainer:168 RmsProp 255 loss=0.153451 err=0.153451
I 2015-05-26 08:39:46 theanets.trainer:168 RmsProp 256 loss=0.156035 err=0.156035
I 2015-05-26 08:39:57 theanets.trainer:168 RmsProp 257 loss=0.149855 err=0.149855
I 2015-05-26 08:40:08 theanets.trainer:168 RmsProp 258 loss=0.162863 err=0.162863
I 2015-05-26 08:40:19 theanets.trainer:168 RmsProp 259 loss=0.145468 err=0.145468
I 2015-05-26 08:40:29 theanets.trainer:168 RmsProp 260 loss=0.147086 err=0.147086
I 2015-05-26 08:40:29 theanets.trainer:168 validation 26 loss=1273.943237 err=1273.943237 *
I 2015-05-26 08:40:40 theanets.trainer:168 RmsProp 261 loss=0.152839 err=0.152839
I 2015-05-26 08:40:50 theanets.trainer:168 RmsProp 262 loss=0.151173 err=0.151173
I 2015-05-26 08:41:00 theanets.trainer:168 RmsProp 263 loss=0.151049 err=0.151049
I 2015-05-26 08:41:11 theanets.trainer:168 RmsProp 264 loss=0.144370 err=0.144370
I 2015-05-26 08:41:21 theanets.trainer:168 RmsProp 265 loss=0.150657 err=0.150657
I 2015-05-26 08:41:32 theanets.trainer:168 RmsProp 266 loss=0.143033 err=0.143033
I 2015-05-26 08:41:42 theanets.trainer:168 RmsProp 267 loss=0.153040 err=0.153040
I 2015-05-26 08:41:52 theanets.trainer:168 RmsProp 268 loss=0.144208 err=0.144208
I 2015-05-26 08:42:03 theanets.trainer:168 RmsProp 269 loss=0.142865 err=0.142865
I 2015-05-26 08:42:13 theanets.trainer:168 RmsProp 270 loss=0.146112 err=0.146112
I 2015-05-26 08:42:14 theanets.trainer:168 validation 27 loss=1274.188354 err=1274.188354
I 2015-05-26 08:42:24 theanets.trainer:168 RmsProp 271 loss=0.141946 err=0.141946
I 2015-05-26 08:42:34 theanets.trainer:168 RmsProp 272 loss=0.148693 err=0.148693
I 2015-05-26 08:42:44 theanets.trainer:168 RmsProp 273 loss=0.145942 err=0.145942
I 2015-05-26 08:42:54 theanets.trainer:168 RmsProp 274 loss=0.146298 err=0.146298
I 2015-05-26 08:43:05 theanets.trainer:168 RmsProp 275 loss=0.141272 err=0.141272
I 2015-05-26 08:43:15 theanets.trainer:168 RmsProp 276 loss=0.143417 err=0.143417
I 2015-05-26 08:43:25 theanets.trainer:168 RmsProp 277 loss=0.142506 err=0.142506
I 2015-05-26 08:43:36 theanets.trainer:168 RmsProp 278 loss=0.140711 err=0.140711
I 2015-05-26 08:43:46 theanets.trainer:168 RmsProp 279 loss=0.142552 err=0.142552
I 2015-05-26 08:43:57 theanets.trainer:168 RmsProp 280 loss=0.142492 err=0.142492
I 2015-05-26 08:43:57 theanets.trainer:168 validation 28 loss=1270.471069 err=1270.471069 *
I 2015-05-26 08:44:08 theanets.trainer:168 RmsProp 281 loss=0.138686 err=0.138686
I 2015-05-26 08:44:18 theanets.trainer:168 RmsProp 282 loss=0.144256 err=0.144256
I 2015-05-26 08:44:28 theanets.trainer:168 RmsProp 283 loss=0.139280 err=0.139280
I 2015-05-26 08:44:39 theanets.trainer:168 RmsProp 284 loss=0.141494 err=0.141494
I 2015-05-26 08:44:49 theanets.trainer:168 RmsProp 285 loss=0.139483 err=0.139483
I 2015-05-26 08:45:00 theanets.trainer:168 RmsProp 286 loss=0.137995 err=0.137995
I 2015-05-26 08:45:10 theanets.trainer:168 RmsProp 287 loss=0.137609 err=0.137609
I 2015-05-26 08:45:21 theanets.trainer:168 RmsProp 288 loss=0.141478 err=0.141478
I 2015-05-26 08:45:31 theanets.trainer:168 RmsProp 289 loss=0.136557 err=0.136557
I 2015-05-26 08:45:42 theanets.trainer:168 RmsProp 290 loss=0.138951 err=0.138951
I 2015-05-26 08:45:42 theanets.trainer:168 validation 29 loss=1269.058350 err=1269.058350 *
I 2015-05-26 08:45:53 theanets.trainer:168 RmsProp 291 loss=0.137297 err=0.137297
I 2015-05-26 08:46:03 theanets.trainer:168 RmsProp 292 loss=0.134954 err=0.134954
I 2015-05-26 08:46:13 theanets.trainer:168 RmsProp 293 loss=0.142950 err=0.142950
I 2015-05-26 08:46:23 theanets.trainer:168 RmsProp 294 loss=0.134936 err=0.134936
I 2015-05-26 08:46:33 theanets.trainer:168 RmsProp 295 loss=0.135658 err=0.135658
I 2015-05-26 08:46:43 theanets.trainer:168 RmsProp 296 loss=0.131823 err=0.131823
I 2015-05-26 08:46:53 theanets.trainer:168 RmsProp 297 loss=0.133328 err=0.133328
I 2015-05-26 08:47:03 theanets.trainer:168 RmsProp 298 loss=0.142397 err=0.142397
I 2015-05-26 08:47:13 theanets.trainer:168 RmsProp 299 loss=0.133670 err=0.133670
I 2015-05-26 08:47:22 theanets.trainer:168 RmsProp 300 loss=0.130792 err=0.130792
I 2015-05-26 08:47:23 theanets.trainer:168 validation 30 loss=1265.565796 err=1265.565796 *
I 2015-05-26 08:47:33 theanets.trainer:168 RmsProp 301 loss=0.138073 err=0.138073
I 2015-05-26 08:47:42 theanets.trainer:168 RmsProp 302 loss=0.134895 err=0.134895
I 2015-05-26 08:47:53 theanets.trainer:168 RmsProp 303 loss=0.135131 err=0.135131
I 2015-05-26 08:48:03 theanets.trainer:168 RmsProp 304 loss=0.134959 err=0.134959
I 2015-05-26 08:48:14 theanets.trainer:168 RmsProp 305 loss=0.126085 err=0.126085
I 2015-05-26 08:48:24 theanets.trainer:168 RmsProp 306 loss=0.139740 err=0.139740
I 2015-05-26 08:48:34 theanets.trainer:168 RmsProp 307 loss=0.133064 err=0.133064
I 2015-05-26 08:48:44 theanets.trainer:168 RmsProp 308 loss=0.128397 err=0.128397
I 2015-05-26 08:48:55 theanets.trainer:168 RmsProp 309 loss=0.126883 err=0.126883
I 2015-05-26 08:49:04 theanets.trainer:168 RmsProp 310 loss=0.129786 err=0.129786
I 2015-05-26 08:49:05 theanets.trainer:168 validation 31 loss=1263.733643 err=1263.733643 *
I 2015-05-26 08:49:15 theanets.trainer:168 RmsProp 311 loss=0.128384 err=0.128384
I 2015-05-26 08:49:25 theanets.trainer:168 RmsProp 312 loss=0.128985 err=0.128985
I 2015-05-26 08:49:35 theanets.trainer:168 RmsProp 313 loss=0.128093 err=0.128093
I 2015-05-26 08:49:45 theanets.trainer:168 RmsProp 314 loss=0.136955 err=0.136955
I 2015-05-26 08:49:55 theanets.trainer:168 RmsProp 315 loss=0.131353 err=0.131353
I 2015-05-26 08:50:05 theanets.trainer:168 RmsProp 316 loss=0.125983 err=0.125983
I 2015-05-26 08:50:15 theanets.trainer:168 RmsProp 317 loss=0.136130 err=0.136130
I 2015-05-26 08:50:25 theanets.trainer:168 RmsProp 318 loss=0.127562 err=0.127562
I 2015-05-26 08:50:35 theanets.trainer:168 RmsProp 319 loss=0.124855 err=0.124855
I 2015-05-26 08:50:45 theanets.trainer:168 RmsProp 320 loss=0.124195 err=0.124195
I 2015-05-26 08:50:45 theanets.trainer:168 validation 32 loss=1260.206177 err=1260.206177 *
I 2015-05-26 08:50:54 theanets.trainer:168 RmsProp 321 loss=0.132172 err=0.132172
I 2015-05-26 08:51:02 theanets.trainer:168 RmsProp 322 loss=0.131634 err=0.131634
I 2015-05-26 08:51:11 theanets.trainer:168 RmsProp 323 loss=0.129744 err=0.129744
I 2015-05-26 08:51:19 theanets.trainer:168 RmsProp 324 loss=0.124522 err=0.124522
I 2015-05-26 08:51:29 theanets.trainer:168 RmsProp 325 loss=0.126693 err=0.126693
I 2015-05-26 08:51:38 theanets.trainer:168 RmsProp 326 loss=0.128374 err=0.128374
I 2015-05-26 08:51:46 theanets.trainer:168 RmsProp 327 loss=0.131484 err=0.131484
I 2015-05-26 08:51:55 theanets.trainer:168 RmsProp 328 loss=0.126652 err=0.126652
I 2015-05-26 08:52:04 theanets.trainer:168 RmsProp 329 loss=0.130254 err=0.130254
I 2015-05-26 08:52:12 theanets.trainer:168 RmsProp 330 loss=0.120956 err=0.120956
I 2015-05-26 08:52:13 theanets.trainer:168 validation 33 loss=1259.976807 err=1259.976807 *
I 2015-05-26 08:52:21 theanets.trainer:168 RmsProp 331 loss=0.130612 err=0.130612
I 2015-05-26 08:52:30 theanets.trainer:168 RmsProp 332 loss=0.123762 err=0.123762
I 2015-05-26 08:52:38 theanets.trainer:168 RmsProp 333 loss=0.119859 err=0.119859
I 2015-05-26 08:52:47 theanets.trainer:168 RmsProp 334 loss=0.122375 err=0.122375
I 2015-05-26 08:52:56 theanets.trainer:168 RmsProp 335 loss=0.121279 err=0.121279
I 2015-05-26 08:53:04 theanets.trainer:168 RmsProp 336 loss=0.122809 err=0.122809
I 2015-05-26 08:53:13 theanets.trainer:168 RmsProp 337 loss=0.123224 err=0.123224
I 2015-05-26 08:53:21 theanets.trainer:168 RmsProp 338 loss=0.122201 err=0.122201
I 2015-05-26 08:53:29 theanets.trainer:168 RmsProp 339 loss=0.124829 err=0.124829
I 2015-05-26 08:53:38 theanets.trainer:168 RmsProp 340 loss=0.122886 err=0.122886
I 2015-05-26 08:53:38 theanets.trainer:168 validation 34 loss=1258.984131 err=1258.984131 *
I 2015-05-26 08:53:47 theanets.trainer:168 RmsProp 341 loss=0.125740 err=0.125740
I 2015-05-26 08:53:55 theanets.trainer:168 RmsProp 342 loss=0.118372 err=0.118372
I 2015-05-26 08:54:03 theanets.trainer:168 RmsProp 343 loss=0.122767 err=0.122767
I 2015-05-26 08:54:11 theanets.trainer:168 RmsProp 344 loss=0.119825 err=0.119825
I 2015-05-26 08:54:18 theanets.trainer:168 RmsProp 345 loss=0.114473 err=0.114473
I 2015-05-26 08:54:26 theanets.trainer:168 RmsProp 346 loss=0.124191 err=0.124191
I 2015-05-26 08:54:35 theanets.trainer:168 RmsProp 347 loss=0.123622 err=0.123622
I 2015-05-26 08:54:42 theanets.trainer:168 RmsProp 348 loss=0.125785 err=0.125785
I 2015-05-26 08:54:49 theanets.trainer:168 RmsProp 349 loss=0.117780 err=0.117780
I 2015-05-26 08:54:57 theanets.trainer:168 RmsProp 350 loss=0.120527 err=0.120527
I 2015-05-26 08:54:57 theanets.trainer:168 validation 35 loss=1255.933960 err=1255.933960 *
I 2015-05-26 08:55:04 theanets.trainer:168 RmsProp 351 loss=0.114828 err=0.114828
I 2015-05-26 08:55:12 theanets.trainer:168 RmsProp 352 loss=0.116915 err=0.116915
I 2015-05-26 08:55:20 theanets.trainer:168 RmsProp 353 loss=0.117181 err=0.117181
I 2015-05-26 08:55:28 theanets.trainer:168 RmsProp 354 loss=0.114451 err=0.114451
I 2015-05-26 08:55:36 theanets.trainer:168 RmsProp 355 loss=0.117710 err=0.117710
I 2015-05-26 08:55:43 theanets.trainer:168 RmsProp 356 loss=0.116422 err=0.116422
I 2015-05-26 08:55:50 theanets.trainer:168 RmsProp 357 loss=0.116802 err=0.116802
I 2015-05-26 08:55:57 theanets.trainer:168 RmsProp 358 loss=0.120347 err=0.120347
I 2015-05-26 08:56:05 theanets.trainer:168 RmsProp 359 loss=0.111233 err=0.111233
I 2015-05-26 08:56:13 theanets.trainer:168 RmsProp 360 loss=0.118067 err=0.118067
I 2015-05-26 08:56:13 theanets.trainer:168 validation 36 loss=1253.847290 err=1253.847290 *
I 2015-05-26 08:56:20 theanets.trainer:168 RmsProp 361 loss=0.121454 err=0.121454
I 2015-05-26 08:56:28 theanets.trainer:168 RmsProp 362 loss=0.115347 err=0.115347
I 2015-05-26 08:56:35 theanets.trainer:168 RmsProp 363 loss=0.114152 err=0.114152
I 2015-05-26 08:56:43 theanets.trainer:168 RmsProp 364 loss=0.108707 err=0.108707
I 2015-05-26 08:56:50 theanets.trainer:168 RmsProp 365 loss=0.123421 err=0.123421
I 2015-05-26 08:56:59 theanets.trainer:168 RmsProp 366 loss=0.113198 err=0.113198
I 2015-05-26 08:57:06 theanets.trainer:168 RmsProp 367 loss=0.109152 err=0.109152
I 2015-05-26 08:57:14 theanets.trainer:168 RmsProp 368 loss=0.117195 err=0.117195
I 2015-05-26 08:57:22 theanets.trainer:168 RmsProp 369 loss=0.114910 err=0.114910
I 2015-05-26 08:57:30 theanets.trainer:168 RmsProp 370 loss=0.112186 err=0.112186
I 2015-05-26 08:57:30 theanets.trainer:168 validation 37 loss=1256.935425 err=1256.935425
I 2015-05-26 08:57:37 theanets.trainer:168 RmsProp 371 loss=0.111979 err=0.111979
I 2015-05-26 08:57:45 theanets.trainer:168 RmsProp 372 loss=0.111429 err=0.111429
I 2015-05-26 08:57:53 theanets.trainer:168 RmsProp 373 loss=0.119686 err=0.119686
I 2015-05-26 08:58:01 theanets.trainer:168 RmsProp 374 loss=0.111966 err=0.111966
I 2015-05-26 08:58:09 theanets.trainer:168 RmsProp 375 loss=0.111800 err=0.111800
I 2015-05-26 08:58:17 theanets.trainer:168 RmsProp 376 loss=0.114070 err=0.114070
I 2015-05-26 08:58:25 theanets.trainer:168 RmsProp 377 loss=0.118547 err=0.118547
I 2015-05-26 08:58:32 theanets.trainer:168 RmsProp 378 loss=0.110085 err=0.110085
I 2015-05-26 08:58:40 theanets.trainer:168 RmsProp 379 loss=0.119160 err=0.119160
I 2015-05-26 08:58:47 theanets.trainer:168 RmsProp 380 loss=0.110285 err=0.110285
I 2015-05-26 08:58:47 theanets.trainer:168 validation 38 loss=1252.971069 err=1252.971069 *
I 2015-05-26 08:58:55 theanets.trainer:168 RmsProp 381 loss=0.111172 err=0.111172
I 2015-05-26 08:59:03 theanets.trainer:168 RmsProp 382 loss=0.110513 err=0.110513
I 2015-05-26 08:59:11 theanets.trainer:168 RmsProp 383 loss=0.110838 err=0.110838
I 2015-05-26 08:59:19 theanets.trainer:168 RmsProp 384 loss=0.115264 err=0.115264
I 2015-05-26 08:59:26 theanets.trainer:168 RmsProp 385 loss=0.107254 err=0.107254
I 2015-05-26 08:59:33 theanets.trainer:168 RmsProp 386 loss=0.108512 err=0.108512
I 2015-05-26 08:59:41 theanets.trainer:168 RmsProp 387 loss=0.114548 err=0.114548
I 2015-05-26 08:59:49 theanets.trainer:168 RmsProp 388 loss=0.114441 err=0.114441
I 2015-05-26 08:59:56 theanets.trainer:168 RmsProp 389 loss=0.110260 err=0.110260
I 2015-05-26 09:00:03 theanets.trainer:168 RmsProp 390 loss=0.104873 err=0.104873
I 2015-05-26 09:00:04 theanets.trainer:168 validation 39 loss=1253.310181 err=1253.310181
I 2015-05-26 09:00:11 theanets.trainer:168 RmsProp 391 loss=0.113743 err=0.113743
I 2015-05-26 09:00:18 theanets.trainer:168 RmsProp 392 loss=0.113168 err=0.113168
I 2015-05-26 09:00:25 theanets.trainer:168 RmsProp 393 loss=0.107893 err=0.107893
I 2015-05-26 09:00:32 theanets.trainer:168 RmsProp 394 loss=0.105209 err=0.105209
I 2015-05-26 09:00:40 theanets.trainer:168 RmsProp 395 loss=0.111625 err=0.111625
I 2015-05-26 09:00:48 theanets.trainer:168 RmsProp 396 loss=0.108191 err=0.108191
I 2015-05-26 09:00:55 theanets.trainer:168 RmsProp 397 loss=0.107147 err=0.107147
I 2015-05-26 09:01:03 theanets.trainer:168 RmsProp 398 loss=0.105841 err=0.105841
I 2015-05-26 09:01:11 theanets.trainer:168 RmsProp 399 loss=0.107283 err=0.107283
I 2015-05-26 09:01:17 theanets.trainer:168 RmsProp 400 loss=0.104290 err=0.104290
I 2015-05-26 09:01:18 theanets.trainer:168 validation 40 loss=1252.466797 err=1252.466797 *
I 2015-05-26 09:01:25 theanets.trainer:168 RmsProp 401 loss=0.105735 err=0.105735
I 2015-05-26 09:01:32 theanets.trainer:168 RmsProp 402 loss=0.106392 err=0.106392
I 2015-05-26 09:01:40 theanets.trainer:168 RmsProp 403 loss=0.108255 err=0.108255
I 2015-05-26 09:01:49 theanets.trainer:168 RmsProp 404 loss=0.104715 err=0.104715
I 2015-05-26 09:01:56 theanets.trainer:168 RmsProp 405 loss=0.105981 err=0.105981
I 2015-05-26 09:02:03 theanets.trainer:168 RmsProp 406 loss=0.105450 err=0.105450
I 2015-05-26 09:02:11 theanets.trainer:168 RmsProp 407 loss=0.108143 err=0.108143
I 2015-05-26 09:02:18 theanets.trainer:168 RmsProp 408 loss=0.101910 err=0.101910
I 2015-05-26 09:02:26 theanets.trainer:168 RmsProp 409 loss=0.105459 err=0.105459
I 2015-05-26 09:02:34 theanets.trainer:168 RmsProp 410 loss=0.105675 err=0.105675
I 2015-05-26 09:02:35 theanets.trainer:168 validation 41 loss=1249.741943 err=1249.741943 *
I 2015-05-26 09:02:42 theanets.trainer:168 RmsProp 411 loss=0.104940 err=0.104940
I 2015-05-26 09:02:50 theanets.trainer:168 RmsProp 412 loss=0.104297 err=0.104297
I 2015-05-26 09:02:57 theanets.trainer:168 RmsProp 413 loss=0.103163 err=0.103163
I 2015-05-26 09:03:04 theanets.trainer:168 RmsProp 414 loss=0.107249 err=0.107249
I 2015-05-26 09:03:13 theanets.trainer:168 RmsProp 415 loss=0.102767 err=0.102767
I 2015-05-26 09:03:21 theanets.trainer:168 RmsProp 416 loss=0.099485 err=0.099485
I 2015-05-26 09:03:29 theanets.trainer:168 RmsProp 417 loss=0.102542 err=0.102542
I 2015-05-26 09:03:37 theanets.trainer:168 RmsProp 418 loss=0.101342 err=0.101342
I 2015-05-26 09:03:45 theanets.trainer:168 RmsProp 419 loss=0.108536 err=0.108536
I 2015-05-26 09:03:53 theanets.trainer:168 RmsProp 420 loss=0.102170 err=0.102170
I 2015-05-26 09:03:53 theanets.trainer:168 validation 42 loss=1248.922119 err=1248.922119 *
I 2015-05-26 09:04:00 theanets.trainer:168 RmsProp 421 loss=0.099781 err=0.099781
I 2015-05-26 09:04:08 theanets.trainer:168 RmsProp 422 loss=0.110771 err=0.110771
I 2015-05-26 09:04:16 theanets.trainer:168 RmsProp 423 loss=0.101426 err=0.101426
I 2015-05-26 09:04:23 theanets.trainer:168 RmsProp 424 loss=0.103978 err=0.103978
I 2015-05-26 09:04:30 theanets.trainer:168 RmsProp 425 loss=0.102010 err=0.102010
I 2015-05-26 09:04:38 theanets.trainer:168 RmsProp 426 loss=0.102781 err=0.102781
I 2015-05-26 09:04:45 theanets.trainer:168 RmsProp 427 loss=0.099983 err=0.099983
I 2015-05-26 09:04:52 theanets.trainer:168 RmsProp 428 loss=0.104059 err=0.104059
I 2015-05-26 09:04:59 theanets.trainer:168 RmsProp 429 loss=0.106689 err=0.106689
I 2015-05-26 09:05:07 theanets.trainer:168 RmsProp 430 loss=0.099621 err=0.099621
I 2015-05-26 09:05:08 theanets.trainer:168 validation 43 loss=1247.529541 err=1247.529541 *
I 2015-05-26 09:05:15 theanets.trainer:168 RmsProp 431 loss=0.096011 err=0.096011
I 2015-05-26 09:05:23 theanets.trainer:168 RmsProp 432 loss=0.102580 err=0.102580
I 2015-05-26 09:05:31 theanets.trainer:168 RmsProp 433 loss=0.102372 err=0.102372
I 2015-05-26 09:05:38 theanets.trainer:168 RmsProp 434 loss=0.099615 err=0.099615
I 2015-05-26 09:05:46 theanets.trainer:168 RmsProp 435 loss=0.106232 err=0.106232
I 2015-05-26 09:05:54 theanets.trainer:168 RmsProp 436 loss=0.095841 err=0.095841
I 2015-05-26 09:06:01 theanets.trainer:168 RmsProp 437 loss=0.105108 err=0.105108
I 2015-05-26 09:06:08 theanets.trainer:168 RmsProp 438 loss=0.099006 err=0.099006
I 2015-05-26 09:06:15 theanets.trainer:168 RmsProp 439 loss=0.101178 err=0.101178
I 2015-05-26 09:06:22 theanets.trainer:168 RmsProp 440 loss=0.094539 err=0.094539
I 2015-05-26 09:06:22 theanets.trainer:168 validation 44 loss=1245.349487 err=1245.349487 *
I 2015-05-26 09:06:29 theanets.trainer:168 RmsProp 441 loss=0.100607 err=0.100607
I 2015-05-26 09:06:37 theanets.trainer:168 RmsProp 442 loss=0.102666 err=0.102666
I 2015-05-26 09:06:44 theanets.trainer:168 RmsProp 443 loss=0.091318 err=0.091318
I 2015-05-26 09:06:51 theanets.trainer:168 RmsProp 444 loss=0.100087 err=0.100087
I 2015-05-26 09:07:00 theanets.trainer:168 RmsProp 445 loss=0.103918 err=0.103918
I 2015-05-26 09:07:07 theanets.trainer:168 RmsProp 446 loss=0.099198 err=0.099198
I 2015-05-26 09:07:15 theanets.trainer:168 RmsProp 447 loss=0.102661 err=0.102661
I 2015-05-26 09:07:23 theanets.trainer:168 RmsProp 448 loss=0.097513 err=0.097513
I 2015-05-26 09:07:30 theanets.trainer:168 RmsProp 449 loss=0.100202 err=0.100202
I 2015-05-26 09:07:37 theanets.trainer:168 RmsProp 450 loss=0.098182 err=0.098182
I 2015-05-26 09:07:37 theanets.trainer:168 validation 45 loss=1245.172729 err=1245.172729 *
I 2015-05-26 09:07:45 theanets.trainer:168 RmsProp 451 loss=0.093510 err=0.093510
I 2015-05-26 09:07:53 theanets.trainer:168 RmsProp 452 loss=0.095964 err=0.095964
I 2015-05-26 09:08:00 theanets.trainer:168 RmsProp 453 loss=0.096777 err=0.096777
I 2015-05-26 09:08:08 theanets.trainer:168 RmsProp 454 loss=0.100223 err=0.100223
I 2015-05-26 09:08:16 theanets.trainer:168 RmsProp 455 loss=0.094690 err=0.094690
I 2015-05-26 09:08:24 theanets.trainer:168 RmsProp 456 loss=0.096059 err=0.096059
I 2015-05-26 09:08:32 theanets.trainer:168 RmsProp 457 loss=0.098711 err=0.098711
I 2015-05-26 09:08:40 theanets.trainer:168 RmsProp 458 loss=0.100831 err=0.100831
I 2015-05-26 09:08:47 theanets.trainer:168 RmsProp 459 loss=0.092705 err=0.092705
I 2015-05-26 09:08:55 theanets.trainer:168 RmsProp 460 loss=0.097714 err=0.097714
I 2015-05-26 09:08:55 theanets.trainer:168 validation 46 loss=1242.464844 err=1242.464844 *
I 2015-05-26 09:09:02 theanets.trainer:168 RmsProp 461 loss=0.097082 err=0.097082
I 2015-05-26 09:09:10 theanets.trainer:168 RmsProp 462 loss=0.104406 err=0.104406
I 2015-05-26 09:09:17 theanets.trainer:168 RmsProp 463 loss=0.093107 err=0.093107
I 2015-05-26 09:09:25 theanets.trainer:168 RmsProp 464 loss=0.091259 err=0.091259
I 2015-05-26 09:09:32 theanets.trainer:168 RmsProp 465 loss=0.097774 err=0.097774
I 2015-05-26 09:09:40 theanets.trainer:168 RmsProp 466 loss=0.100802 err=0.100802
I 2015-05-26 09:09:47 theanets.trainer:168 RmsProp 467 loss=0.094325 err=0.094325
I 2015-05-26 09:09:54 theanets.trainer:168 RmsProp 468 loss=0.091447 err=0.091447
I 2015-05-26 09:10:01 theanets.trainer:168 RmsProp 469 loss=0.098801 err=0.098801
I 2015-05-26 09:10:09 theanets.trainer:168 RmsProp 470 loss=0.093688 err=0.093688
I 2015-05-26 09:10:09 theanets.trainer:168 validation 47 loss=1240.086304 err=1240.086304 *
I 2015-05-26 09:10:16 theanets.trainer:168 RmsProp 471 loss=0.092821 err=0.092821
I 2015-05-26 09:10:24 theanets.trainer:168 RmsProp 472 loss=0.105223 err=0.105223
I 2015-05-26 09:10:32 theanets.trainer:168 RmsProp 473 loss=0.091996 err=0.091996
I 2015-05-26 09:10:39 theanets.trainer:168 RmsProp 474 loss=0.099963 err=0.099963
I 2015-05-26 09:10:47 theanets.trainer:168 RmsProp 475 loss=0.095453 err=0.095453
I 2015-05-26 09:10:56 theanets.trainer:168 RmsProp 476 loss=0.089648 err=0.089648
I 2015-05-26 09:11:03 theanets.trainer:168 RmsProp 477 loss=0.095126 err=0.095126
I 2015-05-26 09:11:10 theanets.trainer:168 RmsProp 478 loss=0.095345 err=0.095345
I 2015-05-26 09:11:17 theanets.trainer:168 RmsProp 479 loss=0.092644 err=0.092644
I 2015-05-26 09:11:24 theanets.trainer:168 RmsProp 480 loss=0.092167 err=0.092167
I 2015-05-26 09:11:25 theanets.trainer:168 validation 48 loss=1237.571777 err=1237.571777 *
I 2015-05-26 09:11:31 theanets.trainer:168 RmsProp 481 loss=0.089803 err=0.089803
I 2015-05-26 09:11:37 theanets.trainer:168 RmsProp 482 loss=0.094387 err=0.094387
I 2015-05-26 09:11:42 theanets.trainer:168 RmsProp 483 loss=0.093935 err=0.093935
I 2015-05-26 09:11:48 theanets.trainer:168 RmsProp 484 loss=0.088314 err=0.088314
I 2015-05-26 09:11:54 theanets.trainer:168 RmsProp 485 loss=0.095512 err=0.095512
I 2015-05-26 09:12:00 theanets.trainer:168 RmsProp 486 loss=0.092512 err=0.092512
I 2015-05-26 09:12:06 theanets.trainer:168 RmsProp 487 loss=0.091313 err=0.091313
I 2015-05-26 09:12:12 theanets.trainer:168 RmsProp 488 loss=0.093960 err=0.093960
I 2015-05-26 09:12:19 theanets.trainer:168 RmsProp 489 loss=0.089944 err=0.089944
I 2015-05-26 09:12:24 theanets.trainer:168 RmsProp 490 loss=0.091051 err=0.091051
I 2015-05-26 09:12:25 theanets.trainer:168 validation 49 loss=1234.738647 err=1234.738647 *
I 2015-05-26 09:12:31 theanets.trainer:168 RmsProp 491 loss=0.091507 err=0.091507
I 2015-05-26 09:12:37 theanets.trainer:168 RmsProp 492 loss=0.087802 err=0.087802
I 2015-05-26 09:12:43 theanets.trainer:168 RmsProp 493 loss=0.093442 err=0.093442
I 2015-05-26 09:12:49 theanets.trainer:168 RmsProp 494 loss=0.092310 err=0.092310
I 2015-05-26 09:12:56 theanets.trainer:168 RmsProp 495 loss=0.092899 err=0.092899
I 2015-05-26 09:13:01 theanets.trainer:168 RmsProp 496 loss=0.091021 err=0.091021
I 2015-05-26 09:13:08 theanets.trainer:168 RmsProp 497 loss=0.086958 err=0.086958
I 2015-05-26 09:13:15 theanets.trainer:168 RmsProp 498 loss=0.097105 err=0.097105
I 2015-05-26 09:13:21 theanets.trainer:168 RmsProp 499 loss=0.087227 err=0.087227
I 2015-05-26 09:13:28 theanets.trainer:168 RmsProp 500 loss=0.092626 err=0.092626
I 2015-05-26 09:13:28 theanets.trainer:168 validation 50 loss=1234.561157 err=1234.561157 *
I 2015-05-26 09:13:34 theanets.trainer:168 RmsProp 501 loss=0.090928 err=0.090928
I 2015-05-26 09:13:40 theanets.trainer:168 RmsProp 502 loss=0.088917 err=0.088917
I 2015-05-26 09:13:47 theanets.trainer:168 RmsProp 503 loss=0.090837 err=0.090837
I 2015-05-26 09:13:53 theanets.trainer:168 RmsProp 504 loss=0.089381 err=0.089381
I 2015-05-26 09:13:58 theanets.trainer:168 RmsProp 505 loss=0.087542 err=0.087542
I 2015-05-26 09:14:04 theanets.trainer:168 RmsProp 506 loss=0.091531 err=0.091531
I 2015-05-26 09:14:10 theanets.trainer:168 RmsProp 507 loss=0.087517 err=0.087517
I 2015-05-26 09:14:15 theanets.trainer:168 RmsProp 508 loss=0.091038 err=0.091038
I 2015-05-26 09:14:21 theanets.trainer:168 RmsProp 509 loss=0.087717 err=0.087717
I 2015-05-26 09:14:26 theanets.trainer:168 RmsProp 510 loss=0.089815 err=0.089815
I 2015-05-26 09:14:26 theanets.trainer:168 validation 51 loss=1236.355103 err=1236.355103
I 2015-05-26 09:14:32 theanets.trainer:168 RmsProp 511 loss=0.085496 err=0.085496
I 2015-05-26 09:14:37 theanets.trainer:168 RmsProp 512 loss=0.093482 err=0.093482
I 2015-05-26 09:14:43 theanets.trainer:168 RmsProp 513 loss=0.085782 err=0.085782
I 2015-05-26 09:14:48 theanets.trainer:168 RmsProp 514 loss=0.093636 err=0.093636
I 2015-05-26 09:14:53 theanets.trainer:168 RmsProp 515 loss=0.087459 err=0.087459
I 2015-05-26 09:14:58 theanets.trainer:168 RmsProp 516 loss=0.091891 err=0.091891
I 2015-05-26 09:15:04 theanets.trainer:168 RmsProp 517 loss=0.090612 err=0.090612
I 2015-05-26 09:15:09 theanets.trainer:168 RmsProp 518 loss=0.084295 err=0.084295
I 2015-05-26 09:15:14 theanets.trainer:168 RmsProp 519 loss=0.085677 err=0.085677
I 2015-05-26 09:15:19 theanets.trainer:168 RmsProp 520 loss=0.092884 err=0.092884
I 2015-05-26 09:15:20 theanets.trainer:168 validation 52 loss=1233.708374 err=1233.708374 *
I 2015-05-26 09:15:25 theanets.trainer:168 RmsProp 521 loss=0.089354 err=0.089354
I 2015-05-26 09:15:31 theanets.trainer:168 RmsProp 522 loss=0.090322 err=0.090322
I 2015-05-26 09:15:37 theanets.trainer:168 RmsProp 523 loss=0.090829 err=0.090829
I 2015-05-26 09:15:44 theanets.trainer:168 RmsProp 524 loss=0.084274 err=0.084274
I 2015-05-26 09:15:51 theanets.trainer:168 RmsProp 525 loss=0.085101 err=0.085101
I 2015-05-26 09:15:57 theanets.trainer:168 RmsProp 526 loss=0.093548 err=0.093548
I 2015-05-26 09:16:03 theanets.trainer:168 RmsProp 527 loss=0.084417 err=0.084417
I 2015-05-26 09:16:10 theanets.trainer:168 RmsProp 528 loss=0.090704 err=0.090704
I 2015-05-26 09:16:16 theanets.trainer:168 RmsProp 529 loss=0.082867 err=0.082867
I 2015-05-26 09:16:22 theanets.trainer:168 RmsProp 530 loss=0.086028 err=0.086028
I 2015-05-26 09:16:23 theanets.trainer:168 validation 53 loss=1232.925171 err=1232.925171 *
I 2015-05-26 09:16:29 theanets.trainer:168 RmsProp 531 loss=0.084761 err=0.084761
I 2015-05-26 09:16:35 theanets.trainer:168 RmsProp 532 loss=0.085980 err=0.085980
I 2015-05-26 09:16:42 theanets.trainer:168 RmsProp 533 loss=0.084543 err=0.084543
I 2015-05-26 09:16:49 theanets.trainer:168 RmsProp 534 loss=0.088624 err=0.088624
I 2015-05-26 09:16:55 theanets.trainer:168 RmsProp 535 loss=0.085263 err=0.085263
I 2015-05-26 09:17:01 theanets.trainer:168 RmsProp 536 loss=0.085059 err=0.085059
I 2015-05-26 09:17:07 theanets.trainer:168 RmsProp 537 loss=0.087125 err=0.087125
I 2015-05-26 09:17:13 theanets.trainer:168 RmsProp 538 loss=0.088705 err=0.088705
I 2015-05-26 09:17:20 theanets.trainer:168 RmsProp 539 loss=0.085794 err=0.085794
I 2015-05-26 09:17:25 theanets.trainer:168 RmsProp 540 loss=0.084174 err=0.084174
I 2015-05-26 09:17:26 theanets.trainer:168 validation 54 loss=1230.931396 err=1230.931396 *
I 2015-05-26 09:17:32 theanets.trainer:168 RmsProp 541 loss=0.090058 err=0.090058
I 2015-05-26 09:17:38 theanets.trainer:168 RmsProp 542 loss=0.085705 err=0.085705
I 2015-05-26 09:17:44 theanets.trainer:168 RmsProp 543 loss=0.083208 err=0.083208
I 2015-05-26 09:17:50 theanets.trainer:168 RmsProp 544 loss=0.083251 err=0.083251
I 2015-05-26 09:17:56 theanets.trainer:168 RmsProp 545 loss=0.082142 err=0.082142
I 2015-05-26 09:18:03 theanets.trainer:168 RmsProp 546 loss=0.092207 err=0.092207
I 2015-05-26 09:18:10 theanets.trainer:168 RmsProp 547 loss=0.084547 err=0.084547
I 2015-05-26 09:18:16 theanets.trainer:168 RmsProp 548 loss=0.081842 err=0.081842
I 2015-05-26 09:18:23 theanets.trainer:168 RmsProp 549 loss=0.079372 err=0.079372
I 2015-05-26 09:18:29 theanets.trainer:168 RmsProp 550 loss=0.092262 err=0.092262
I 2015-05-26 09:18:30 theanets.trainer:168 validation 55 loss=1229.218750 err=1229.218750 *
I 2015-05-26 09:18:36 theanets.trainer:168 RmsProp 551 loss=0.086102 err=0.086102
I 2015-05-26 09:18:42 theanets.trainer:168 RmsProp 552 loss=0.080016 err=0.080016
I 2015-05-26 09:18:49 theanets.trainer:168 RmsProp 553 loss=0.086010 err=0.086010
I 2015-05-26 09:18:55 theanets.trainer:168 RmsProp 554 loss=0.082650 err=0.082650
I 2015-05-26 09:19:02 theanets.trainer:168 RmsProp 555 loss=0.077679 err=0.077679
I 2015-05-26 09:19:08 theanets.trainer:168 RmsProp 556 loss=0.090324 err=0.090324
I 2015-05-26 09:19:14 theanets.trainer:168 RmsProp 557 loss=0.082224 err=0.082224
I 2015-05-26 09:19:20 theanets.trainer:168 RmsProp 558 loss=0.079252 err=0.079252
I 2015-05-26 09:19:27 theanets.trainer:168 RmsProp 559 loss=0.080283 err=0.080283
I 2015-05-26 09:19:33 theanets.trainer:168 RmsProp 560 loss=0.087845 err=0.087845
I 2015-05-26 09:19:33 theanets.trainer:168 validation 56 loss=1227.897339 err=1227.897339 *
I 2015-05-26 09:19:40 theanets.trainer:168 RmsProp 561 loss=0.078581 err=0.078581
I 2015-05-26 09:19:46 theanets.trainer:168 RmsProp 562 loss=0.080893 err=0.080893
I 2015-05-26 09:19:52 theanets.trainer:168 RmsProp 563 loss=0.078940 err=0.078940
I 2015-05-26 09:19:59 theanets.trainer:168 RmsProp 564 loss=0.084518 err=0.084518
I 2015-05-26 09:20:05 theanets.trainer:168 RmsProp 565 loss=0.081752 err=0.081752
I 2015-05-26 09:20:11 theanets.trainer:168 RmsProp 566 loss=0.085057 err=0.085057
I 2015-05-26 09:20:18 theanets.trainer:168 RmsProp 567 loss=0.082803 err=0.082803
I 2015-05-26 09:20:25 theanets.trainer:168 RmsProp 568 loss=0.084754 err=0.084754
I 2015-05-26 09:20:32 theanets.trainer:168 RmsProp 569 loss=0.080991 err=0.080991
I 2015-05-26 09:20:38 theanets.trainer:168 RmsProp 570 loss=0.081148 err=0.081148
I 2015-05-26 09:20:39 theanets.trainer:168 validation 57 loss=1224.524048 err=1224.524048 *
I 2015-05-26 09:20:45 theanets.trainer:168 RmsProp 571 loss=0.081916 err=0.081916
I 2015-05-26 09:20:51 theanets.trainer:168 RmsProp 572 loss=0.083275 err=0.083275
I 2015-05-26 09:20:57 theanets.trainer:168 RmsProp 573 loss=0.077148 err=0.077148
I 2015-05-26 09:21:04 theanets.trainer:168 RmsProp 574 loss=0.081024 err=0.081024
I 2015-05-26 09:21:11 theanets.trainer:168 RmsProp 575 loss=0.077444 err=0.077444
I 2015-05-26 09:21:17 theanets.trainer:168 RmsProp 576 loss=0.079759 err=0.079759
I 2015-05-26 09:21:23 theanets.trainer:168 RmsProp 577 loss=0.080552 err=0.080552
I 2015-05-26 09:21:30 theanets.trainer:168 RmsProp 578 loss=0.081867 err=0.081867
I 2015-05-26 09:21:36 theanets.trainer:168 RmsProp 579 loss=0.081238 err=0.081238
I 2015-05-26 09:21:43 theanets.trainer:168 RmsProp 580 loss=0.075132 err=0.075132
I 2015-05-26 09:21:43 theanets.trainer:168 validation 58 loss=1226.299072 err=1226.299072
I 2015-05-26 09:21:48 theanets.trainer:168 RmsProp 581 loss=0.079114 err=0.079114
I 2015-05-26 09:21:53 theanets.trainer:168 RmsProp 582 loss=0.081213 err=0.081213
I 2015-05-26 09:21:59 theanets.trainer:168 RmsProp 583 loss=0.083895 err=0.083895
I 2015-05-26 09:22:04 theanets.trainer:168 RmsProp 584 loss=0.083019 err=0.083019
I 2015-05-26 09:22:09 theanets.trainer:168 RmsProp 585 loss=0.077975 err=0.077975
I 2015-05-26 09:22:14 theanets.trainer:168 RmsProp 586 loss=0.078757 err=0.078757
I 2015-05-26 09:22:19 theanets.trainer:168 RmsProp 587 loss=0.083869 err=0.083869
I 2015-05-26 09:22:24 theanets.trainer:168 RmsProp 588 loss=0.080812 err=0.080812
I 2015-05-26 09:22:30 theanets.trainer:168 RmsProp 589 loss=0.077361 err=0.077361
I 2015-05-26 09:22:35 theanets.trainer:168 RmsProp 590 loss=0.074893 err=0.074893
I 2015-05-26 09:22:35 theanets.trainer:168 validation 59 loss=1224.677979 err=1224.677979
I 2015-05-26 09:22:41 theanets.trainer:168 RmsProp 591 loss=0.089600 err=0.089600
I 2015-05-26 09:22:45 theanets.trainer:168 RmsProp 592 loss=0.081879 err=0.081879
I 2015-05-26 09:22:50 theanets.trainer:168 RmsProp 593 loss=0.076554 err=0.076554
I 2015-05-26 09:22:55 theanets.trainer:168 RmsProp 594 loss=0.085591 err=0.085591
I 2015-05-26 09:22:59 theanets.trainer:168 RmsProp 595 loss=0.078204 err=0.078204
I 2015-05-26 09:23:03 theanets.trainer:168 RmsProp 596 loss=0.074789 err=0.074789
I 2015-05-26 09:23:07 theanets.trainer:168 RmsProp 597 loss=0.085234 err=0.085234
I 2015-05-26 09:23:11 theanets.trainer:168 RmsProp 598 loss=0.075039 err=0.075039
I 2015-05-26 09:23:15 theanets.trainer:168 RmsProp 599 loss=0.081719 err=0.081719
I 2015-05-26 09:23:19 theanets.trainer:168 RmsProp 600 loss=0.078099 err=0.078099
I 2015-05-26 09:23:19 theanets.trainer:168 validation 60 loss=1224.601929 err=1224.601929
I 2015-05-26 09:23:23 theanets.trainer:168 RmsProp 601 loss=0.075287 err=0.075287
I 2015-05-26 09:23:27 theanets.trainer:168 RmsProp 602 loss=0.076104 err=0.076104
I 2015-05-26 09:23:31 theanets.trainer:168 RmsProp 603 loss=0.082092 err=0.082092
I 2015-05-26 09:23:35 theanets.trainer:168 RmsProp 604 loss=0.073054 err=0.073054
I 2015-05-26 09:23:39 theanets.trainer:168 RmsProp 605 loss=0.079645 err=0.079645
I 2015-05-26 09:23:44 theanets.trainer:168 RmsProp 606 loss=0.078547 err=0.078547
I 2015-05-26 09:23:48 theanets.trainer:168 RmsProp 607 loss=0.076522 err=0.076522
I 2015-05-26 09:23:52 theanets.trainer:168 RmsProp 608 loss=0.078279 err=0.078279
I 2015-05-26 09:23:56 theanets.trainer:168 RmsProp 609 loss=0.076863 err=0.076863
I 2015-05-26 09:24:00 theanets.trainer:168 RmsProp 610 loss=0.081916 err=0.081916
I 2015-05-26 09:24:00 theanets.trainer:168 validation 61 loss=1223.636108 err=1223.636108 *
I 2015-05-26 09:24:05 theanets.trainer:168 RmsProp 611 loss=0.076635 err=0.076635
I 2015-05-26 09:24:09 theanets.trainer:168 RmsProp 612 loss=0.074204 err=0.074204
I 2015-05-26 09:24:13 theanets.trainer:168 RmsProp 613 loss=0.081549 err=0.081549
I 2015-05-26 09:24:18 theanets.trainer:168 RmsProp 614 loss=0.076545 err=0.076545
I 2015-05-26 09:24:23 theanets.trainer:168 RmsProp 615 loss=0.076590 err=0.076590
I 2015-05-26 09:24:27 theanets.trainer:168 RmsProp 616 loss=0.076302 err=0.076302
I 2015-05-26 09:24:31 theanets.trainer:168 RmsProp 617 loss=0.072095 err=0.072095
I 2015-05-26 09:24:36 theanets.trainer:168 RmsProp 618 loss=0.076216 err=0.076216
I 2015-05-26 09:24:40 theanets.trainer:168 RmsProp 619 loss=0.072065 err=0.072065
I 2015-05-26 09:24:44 theanets.trainer:168 RmsProp 620 loss=0.074752 err=0.074752
I 2015-05-26 09:24:44 theanets.trainer:168 validation 62 loss=1223.379272 err=1223.379272 *
I 2015-05-26 09:24:48 theanets.trainer:168 RmsProp 621 loss=0.087654 err=0.087654
I 2015-05-26 09:24:52 theanets.trainer:168 RmsProp 622 loss=0.073041 err=0.073041
I 2015-05-26 09:24:56 theanets.trainer:168 RmsProp 623 loss=0.080116 err=0.080116
I 2015-05-26 09:25:01 theanets.trainer:168 RmsProp 624 loss=0.077596 err=0.077596
I 2015-05-26 09:25:05 theanets.trainer:168 RmsProp 625 loss=0.076565 err=0.076565
I 2015-05-26 09:25:09 theanets.trainer:168 RmsProp 626 loss=0.072690 err=0.072690
I 2015-05-26 09:25:13 theanets.trainer:168 RmsProp 627 loss=0.072250 err=0.072250
I 2015-05-26 09:25:17 theanets.trainer:168 RmsProp 628 loss=0.084392 err=0.084392
I 2015-05-26 09:25:20 theanets.trainer:168 RmsProp 629 loss=0.077059 err=0.077059
I 2015-05-26 09:25:24 theanets.trainer:168 RmsProp 630 loss=0.074906 err=0.074906
I 2015-05-26 09:25:25 theanets.trainer:168 validation 63 loss=1220.295654 err=1220.295654 *
I 2015-05-26 09:25:29 theanets.trainer:168 RmsProp 631 loss=0.074303 err=0.074303
I 2015-05-26 09:25:33 theanets.trainer:168 RmsProp 632 loss=0.075009 err=0.075009
I 2015-05-26 09:25:37 theanets.trainer:168 RmsProp 633 loss=0.073630 err=0.073630
I 2015-05-26 09:25:42 theanets.trainer:168 RmsProp 634 loss=0.075163 err=0.075163
I 2015-05-26 09:25:46 theanets.trainer:168 RmsProp 635 loss=0.079197 err=0.079197
I 2015-05-26 09:25:50 theanets.trainer:168 RmsProp 636 loss=0.075840 err=0.075840
I 2015-05-26 09:25:55 theanets.trainer:168 RmsProp 637 loss=0.075427 err=0.075427
I 2015-05-26 09:25:58 theanets.trainer:168 RmsProp 638 loss=0.074007 err=0.074007
I 2015-05-26 09:26:02 theanets.trainer:168 RmsProp 639 loss=0.069997 err=0.069997
I 2015-05-26 09:26:06 theanets.trainer:168 RmsProp 640 loss=0.076091 err=0.076091
I 2015-05-26 09:26:07 theanets.trainer:168 validation 64 loss=1218.369507 err=1218.369507 *
I 2015-05-26 09:26:11 theanets.trainer:168 RmsProp 641 loss=0.070790 err=0.070790
I 2015-05-26 09:26:15 theanets.trainer:168 RmsProp 642 loss=0.072407 err=0.072407
I 2015-05-26 09:26:19 theanets.trainer:168 RmsProp 643 loss=0.076930 err=0.076930
I 2015-05-26 09:26:23 theanets.trainer:168 RmsProp 644 loss=0.072423 err=0.072423
I 2015-05-26 09:26:27 theanets.trainer:168 RmsProp 645 loss=0.074118 err=0.074118
I 2015-05-26 09:26:32 theanets.trainer:168 RmsProp 646 loss=0.075952 err=0.075952
I 2015-05-26 09:26:36 theanets.trainer:168 RmsProp 647 loss=0.072345 err=0.072345
I 2015-05-26 09:26:40 theanets.trainer:168 RmsProp 648 loss=0.071836 err=0.071836
I 2015-05-26 09:26:44 theanets.trainer:168 RmsProp 649 loss=0.073317 err=0.073317
I 2015-05-26 09:26:48 theanets.trainer:168 RmsProp 650 loss=0.076123 err=0.076123
I 2015-05-26 09:26:48 theanets.trainer:168 validation 65 loss=1216.111206 err=1216.111206 *
I 2015-05-26 09:26:52 theanets.trainer:168 RmsProp 651 loss=0.070919 err=0.070919
I 2015-05-26 09:26:57 theanets.trainer:168 RmsProp 652 loss=0.081109 err=0.081109
I 2015-05-26 09:27:01 theanets.trainer:168 RmsProp 653 loss=0.075083 err=0.075083
I 2015-05-26 09:27:05 theanets.trainer:168 RmsProp 654 loss=0.075783 err=0.075783
I 2015-05-26 09:27:10 theanets.trainer:168 RmsProp 655 loss=0.067981 err=0.067981
I 2015-05-26 09:27:14 theanets.trainer:168 RmsProp 656 loss=0.070014 err=0.070014
I 2015-05-26 09:27:18 theanets.trainer:168 RmsProp 657 loss=0.069458 err=0.069458
I 2015-05-26 09:27:22 theanets.trainer:168 RmsProp 658 loss=0.073685 err=0.073685
I 2015-05-26 09:27:26 theanets.trainer:168 RmsProp 659 loss=0.074757 err=0.074757
I 2015-05-26 09:27:30 theanets.trainer:168 RmsProp 660 loss=0.070136 err=0.070136
I 2015-05-26 09:27:30 theanets.trainer:168 validation 66 loss=1216.816895 err=1216.816895
I 2015-05-26 09:27:35 theanets.trainer:168 RmsProp 661 loss=0.072633 err=0.072633
I 2015-05-26 09:27:39 theanets.trainer:168 RmsProp 662 loss=0.067621 err=0.067621
I 2015-05-26 09:27:43 theanets.trainer:168 RmsProp 663 loss=0.075147 err=0.075147
I 2015-05-26 09:27:47 theanets.trainer:168 RmsProp 664 loss=0.068936 err=0.068936
I 2015-05-26 09:27:51 theanets.trainer:168 RmsProp 665 loss=0.067258 err=0.067258
I 2015-05-26 09:27:55 theanets.trainer:168 RmsProp 666 loss=0.077744 err=0.077744
I 2015-05-26 09:27:59 theanets.trainer:168 RmsProp 667 loss=0.074021 err=0.074021
I 2015-05-26 09:28:03 theanets.trainer:168 RmsProp 668 loss=0.074280 err=0.074280
I 2015-05-26 09:28:08 theanets.trainer:168 RmsProp 669 loss=0.076146 err=0.076146
I 2015-05-26 09:28:12 theanets.trainer:168 RmsProp 670 loss=0.071231 err=0.071231
I 2015-05-26 09:28:12 theanets.trainer:168 validation 67 loss=1215.196655 err=1215.196655 *
I 2015-05-26 09:28:16 theanets.trainer:168 RmsProp 671 loss=0.069241 err=0.069241
I 2015-05-26 09:28:20 theanets.trainer:168 RmsProp 672 loss=0.076885 err=0.076885
I 2015-05-26 09:28:24 theanets.trainer:168 RmsProp 673 loss=0.074180 err=0.074180
I 2015-05-26 09:28:28 theanets.trainer:168 RmsProp 674 loss=0.076371 err=0.076371
I 2015-05-26 09:28:32 theanets.trainer:168 RmsProp 675 loss=0.074582 err=0.074582
I 2015-05-26 09:28:36 theanets.trainer:168 RmsProp 676 loss=0.069870 err=0.069870
I 2015-05-26 09:28:40 theanets.trainer:168 RmsProp 677 loss=0.076698 err=0.076698
I 2015-05-26 09:28:45 theanets.trainer:168 RmsProp 678 loss=0.073134 err=0.073134
I 2015-05-26 09:28:48 theanets.trainer:168 RmsProp 679 loss=0.070812 err=0.070812
I 2015-05-26 09:28:52 theanets.trainer:168 RmsProp 680 loss=0.070280 err=0.070280
I 2015-05-26 09:28:53 theanets.trainer:168 validation 68 loss=1213.299194 err=1213.299194 *
I 2015-05-26 09:28:57 theanets.trainer:168 RmsProp 681 loss=0.067322 err=0.067322
I 2015-05-26 09:29:02 theanets.trainer:168 RmsProp 682 loss=0.075291 err=0.075291
I 2015-05-26 09:29:06 theanets.trainer:168 RmsProp 683 loss=0.076243 err=0.076243
I 2015-05-26 09:29:11 theanets.trainer:168 RmsProp 684 loss=0.069929 err=0.069929
I 2015-05-26 09:29:15 theanets.trainer:168 RmsProp 685 loss=0.070174 err=0.070174
I 2015-05-26 09:29:19 theanets.trainer:168 RmsProp 686 loss=0.073439 err=0.073439
I 2015-05-26 09:29:24 theanets.trainer:168 RmsProp 687 loss=0.066449 err=0.066449
I 2015-05-26 09:29:28 theanets.trainer:168 RmsProp 688 loss=0.073439 err=0.073439
I 2015-05-26 09:29:32 theanets.trainer:168 RmsProp 689 loss=0.066217 err=0.066217
I 2015-05-26 09:29:36 theanets.trainer:168 RmsProp 690 loss=0.069849 err=0.069849
I 2015-05-26 09:29:37 theanets.trainer:168 validation 69 loss=1210.251831 err=1210.251831 *
I 2015-05-26 09:29:41 theanets.trainer:168 RmsProp 691 loss=0.066828 err=0.066828
I 2015-05-26 09:29:46 theanets.trainer:168 RmsProp 692 loss=0.075891 err=0.075891
I 2015-05-26 09:29:50 theanets.trainer:168 RmsProp 693 loss=0.066225 err=0.066225
I 2015-05-26 09:29:54 theanets.trainer:168 RmsProp 694 loss=0.069221 err=0.069221
I 2015-05-26 09:29:58 theanets.trainer:168 RmsProp 695 loss=0.067243 err=0.067243
I 2015-05-26 09:30:03 theanets.trainer:168 RmsProp 696 loss=0.077034 err=0.077034
I 2015-05-26 09:30:07 theanets.trainer:168 RmsProp 697 loss=0.071410 err=0.071410
I 2015-05-26 09:30:11 theanets.trainer:168 RmsProp 698 loss=0.070363 err=0.070363
I 2015-05-26 09:30:15 theanets.trainer:168 RmsProp 699 loss=0.067738 err=0.067738
I 2015-05-26 09:30:19 theanets.trainer:168 RmsProp 700 loss=0.071560 err=0.071560
I 2015-05-26 09:30:19 theanets.trainer:168 validation 70 loss=1210.242432 err=1210.242432 *
I 2015-05-26 09:30:24 theanets.trainer:168 RmsProp 701 loss=0.068561 err=0.068561
I 2015-05-26 09:30:28 theanets.trainer:168 RmsProp 702 loss=0.072475 err=0.072475
I 2015-05-26 09:30:32 theanets.trainer:168 RmsProp 703 loss=0.068512 err=0.068512
I 2015-05-26 09:30:36 theanets.trainer:168 RmsProp 704 loss=0.070462 err=0.070462
I 2015-05-26 09:30:41 theanets.trainer:168 RmsProp 705 loss=0.071886 err=0.071886
I 2015-05-26 09:30:45 theanets.trainer:168 RmsProp 706 loss=0.074543 err=0.074543
I 2015-05-26 09:30:50 theanets.trainer:168 RmsProp 707 loss=0.065731 err=0.065731
I 2015-05-26 09:30:54 theanets.trainer:168 RmsProp 708 loss=0.066161 err=0.066161
I 2015-05-26 09:30:58 theanets.trainer:168 RmsProp 709 loss=0.067308 err=0.067308
I 2015-05-26 09:31:02 theanets.trainer:168 RmsProp 710 loss=0.068492 err=0.068492
I 2015-05-26 09:31:02 theanets.trainer:168 validation 71 loss=1207.240601 err=1207.240601 *
I 2015-05-26 09:31:07 theanets.trainer:168 RmsProp 711 loss=0.072267 err=0.072267
I 2015-05-26 09:31:12 theanets.trainer:168 RmsProp 712 loss=0.066191 err=0.066191
I 2015-05-26 09:31:16 theanets.trainer:168 RmsProp 713 loss=0.064365 err=0.064365
I 2015-05-26 09:31:20 theanets.trainer:168 RmsProp 714 loss=0.070228 err=0.070228
I 2015-05-26 09:31:24 theanets.trainer:168 RmsProp 715 loss=0.063281 err=0.063281
I 2015-05-26 09:31:28 theanets.trainer:168 RmsProp 716 loss=0.080657 err=0.080657
I 2015-05-26 09:31:32 theanets.trainer:168 RmsProp 717 loss=0.067119 err=0.067119
I 2015-05-26 09:31:37 theanets.trainer:168 RmsProp 718 loss=0.063155 err=0.063155
I 2015-05-26 09:31:41 theanets.trainer:168 RmsProp 719 loss=0.074774 err=0.074774
I 2015-05-26 09:31:45 theanets.trainer:168 RmsProp 720 loss=0.069970 err=0.069970
I 2015-05-26 09:31:45 theanets.trainer:168 validation 72 loss=1207.818604 err=1207.818604
I 2015-05-26 09:31:49 theanets.trainer:168 RmsProp 721 loss=0.068826 err=0.068826
I 2015-05-26 09:31:53 theanets.trainer:168 RmsProp 722 loss=0.064168 err=0.064168
I 2015-05-26 09:31:57 theanets.trainer:168 RmsProp 723 loss=0.074273 err=0.074273
I 2015-05-26 09:32:00 theanets.trainer:168 RmsProp 724 loss=0.068703 err=0.068703
I 2015-05-26 09:32:04 theanets.trainer:168 RmsProp 725 loss=0.065021 err=0.065021
I 2015-05-26 09:32:07 theanets.trainer:168 RmsProp 726 loss=0.070601 err=0.070601
I 2015-05-26 09:32:10 theanets.trainer:168 RmsProp 727 loss=0.063490 err=0.063490
I 2015-05-26 09:32:14 theanets.trainer:168 RmsProp 728 loss=0.067881 err=0.067881
I 2015-05-26 09:32:17 theanets.trainer:168 RmsProp 729 loss=0.071674 err=0.071674
I 2015-05-26 09:32:20 theanets.trainer:168 RmsProp 730 loss=0.066913 err=0.066913
I 2015-05-26 09:32:20 theanets.trainer:168 validation 73 loss=1207.223511 err=1207.223511 *
I 2015-05-26 09:32:23 theanets.trainer:168 RmsProp 731 loss=0.068147 err=0.068147
I 2015-05-26 09:32:27 theanets.trainer:168 RmsProp 732 loss=0.066397 err=0.066397
I 2015-05-26 09:32:30 theanets.trainer:168 RmsProp 733 loss=0.062674 err=0.062674
I 2015-05-26 09:32:34 theanets.trainer:168 RmsProp 734 loss=0.073497 err=0.073497
I 2015-05-26 09:32:37 theanets.trainer:168 RmsProp 735 loss=0.069065 err=0.069065
I 2015-05-26 09:32:40 theanets.trainer:168 RmsProp 736 loss=0.068808 err=0.068808
I 2015-05-26 09:32:44 theanets.trainer:168 RmsProp 737 loss=0.066636 err=0.066636
I 2015-05-26 09:32:47 theanets.trainer:168 RmsProp 738 loss=0.064590 err=0.064590
I 2015-05-26 09:32:50 theanets.trainer:168 RmsProp 739 loss=0.064831 err=0.064831
I 2015-05-26 09:32:53 theanets.trainer:168 RmsProp 740 loss=0.074108 err=0.074108
I 2015-05-26 09:32:53 theanets.trainer:168 validation 74 loss=1207.283569 err=1207.283569
I 2015-05-26 09:32:56 theanets.trainer:168 RmsProp 741 loss=0.065432 err=0.065432
I 2015-05-26 09:32:59 theanets.trainer:168 RmsProp 742 loss=0.062256 err=0.062256
I 2015-05-26 09:33:03 theanets.trainer:168 RmsProp 743 loss=0.069549 err=0.069549
I 2015-05-26 09:33:06 theanets.trainer:168 RmsProp 744 loss=0.065922 err=0.065922
I 2015-05-26 09:33:09 theanets.trainer:168 RmsProp 745 loss=0.065553 err=0.065553
I 2015-05-26 09:33:12 theanets.trainer:168 RmsProp 746 loss=0.064275 err=0.064275
I 2015-05-26 09:33:16 theanets.trainer:168 RmsProp 747 loss=0.067770 err=0.067770
I 2015-05-26 09:33:19 theanets.trainer:168 RmsProp 748 loss=0.065231 err=0.065231
I 2015-05-26 09:33:22 theanets.trainer:168 RmsProp 749 loss=0.060657 err=0.060657
I 2015-05-26 09:33:25 theanets.trainer:168 RmsProp 750 loss=0.068882 err=0.068882
I 2015-05-26 09:33:25 theanets.trainer:168 validation 75 loss=1207.354614 err=1207.354614
I 2015-05-26 09:33:28 theanets.trainer:168 RmsProp 751 loss=0.064399 err=0.064399
I 2015-05-26 09:33:32 theanets.trainer:168 RmsProp 752 loss=0.065376 err=0.065376
I 2015-05-26 09:33:35 theanets.trainer:168 RmsProp 753 loss=0.064877 err=0.064877
I 2015-05-26 09:33:38 theanets.trainer:168 RmsProp 754 loss=0.062299 err=0.062299
I 2015-05-26 09:33:41 theanets.trainer:168 RmsProp 755 loss=0.074647 err=0.074647
I 2015-05-26 09:33:45 theanets.trainer:168 RmsProp 756 loss=0.062714 err=0.062714
I 2015-05-26 09:33:48 theanets.trainer:168 RmsProp 757 loss=0.064247 err=0.064247
I 2015-05-26 09:33:51 theanets.trainer:168 RmsProp 758 loss=0.067989 err=0.067989
I 2015-05-26 09:33:54 theanets.trainer:168 RmsProp 759 loss=0.065222 err=0.065222
I 2015-05-26 09:33:58 theanets.trainer:168 RmsProp 760 loss=0.065021 err=0.065021
I 2015-05-26 09:33:58 theanets.trainer:168 validation 76 loss=1207.939331 err=1207.939331
I 2015-05-26 09:34:01 theanets.trainer:168 RmsProp 761 loss=0.069325 err=0.069325
I 2015-05-26 09:34:04 theanets.trainer:168 RmsProp 762 loss=0.062212 err=0.062212
I 2015-05-26 09:34:07 theanets.trainer:168 RmsProp 763 loss=0.062361 err=0.062361
I 2015-05-26 09:34:11 theanets.trainer:168 RmsProp 764 loss=0.065060 err=0.065060
I 2015-05-26 09:34:14 theanets.trainer:168 RmsProp 765 loss=0.065432 err=0.065432
I 2015-05-26 09:34:17 theanets.trainer:168 RmsProp 766 loss=0.065488 err=0.065488
I 2015-05-26 09:34:20 theanets.trainer:168 RmsProp 767 loss=0.061490 err=0.061490
I 2015-05-26 09:34:23 theanets.trainer:168 RmsProp 768 loss=0.068037 err=0.068037
I 2015-05-26 09:34:27 theanets.trainer:168 RmsProp 769 loss=0.063429 err=0.063429
I 2015-05-26 09:34:30 theanets.trainer:168 RmsProp 770 loss=0.064207 err=0.064207
I 2015-05-26 09:34:30 theanets.trainer:168 validation 77 loss=1205.026733 err=1205.026733 *
I 2015-05-26 09:34:33 theanets.trainer:168 RmsProp 771 loss=0.063914 err=0.063914
I 2015-05-26 09:34:36 theanets.trainer:168 RmsProp 772 loss=0.064014 err=0.064014
I 2015-05-26 09:34:39 theanets.trainer:168 RmsProp 773 loss=0.065981 err=0.065981
I 2015-05-26 09:34:43 theanets.trainer:168 RmsProp 774 loss=0.060527 err=0.060527
I 2015-05-26 09:34:46 theanets.trainer:168 RmsProp 775 loss=0.073941 err=0.073941
I 2015-05-26 09:34:49 theanets.trainer:168 RmsProp 776 loss=0.060611 err=0.060611
I 2015-05-26 09:34:52 theanets.trainer:168 RmsProp 777 loss=0.064750 err=0.064750
I 2015-05-26 09:34:55 theanets.trainer:168 RmsProp 778 loss=0.063646 err=0.063646
I 2015-05-26 09:34:59 theanets.trainer:168 RmsProp 779 loss=0.066007 err=0.066007
I 2015-05-26 09:35:01 theanets.trainer:168 RmsProp 780 loss=0.062613 err=0.062613
I 2015-05-26 09:35:02 theanets.trainer:168 validation 78 loss=1204.050537 err=1204.050537 *
I 2015-05-26 09:35:05 theanets.trainer:168 RmsProp 781 loss=0.062774 err=0.062774
I 2015-05-26 09:35:08 theanets.trainer:168 RmsProp 782 loss=0.064595 err=0.064595
I 2015-05-26 09:35:11 theanets.trainer:168 RmsProp 783 loss=0.064998 err=0.064998
I 2015-05-26 09:35:14 theanets.trainer:168 RmsProp 784 loss=0.063288 err=0.063288
I 2015-05-26 09:35:17 theanets.trainer:168 RmsProp 785 loss=0.059695 err=0.059695
I 2015-05-26 09:35:21 theanets.trainer:168 RmsProp 786 loss=0.065035 err=0.065035
I 2015-05-26 09:35:24 theanets.trainer:168 RmsProp 787 loss=0.066229 err=0.066229
I 2015-05-26 09:35:27 theanets.trainer:168 RmsProp 788 loss=0.061969 err=0.061969
I 2015-05-26 09:35:30 theanets.trainer:168 RmsProp 789 loss=0.061652 err=0.061652
I 2015-05-26 09:35:33 theanets.trainer:168 RmsProp 790 loss=0.064483 err=0.064483
I 2015-05-26 09:35:33 theanets.trainer:168 validation 79 loss=1203.007202 err=1203.007202 *
I 2015-05-26 09:35:37 theanets.trainer:168 RmsProp 791 loss=0.062955 err=0.062955
I 2015-05-26 09:35:40 theanets.trainer:168 RmsProp 792 loss=0.059106 err=0.059106
I 2015-05-26 09:35:44 theanets.trainer:168 RmsProp 793 loss=0.063623 err=0.063623
I 2015-05-26 09:35:47 theanets.trainer:168 RmsProp 794 loss=0.064727 err=0.064727
I 2015-05-26 09:35:50 theanets.trainer:168 RmsProp 795 loss=0.061427 err=0.061427
I 2015-05-26 09:35:53 theanets.trainer:168 RmsProp 796 loss=0.063138 err=0.063138
I 2015-05-26 09:35:57 theanets.trainer:168 RmsProp 797 loss=0.060611 err=0.060611
I 2015-05-26 09:36:00 theanets.trainer:168 RmsProp 798 loss=0.062375 err=0.062375
I 2015-05-26 09:36:03 theanets.trainer:168 RmsProp 799 loss=0.062260 err=0.062260
I 2015-05-26 09:36:07 theanets.trainer:168 RmsProp 800 loss=0.060542 err=0.060542
I 2015-05-26 09:36:07 theanets.trainer:168 validation 80 loss=1201.875732 err=1201.875732 *
I 2015-05-26 09:36:10 theanets.trainer:168 RmsProp 801 loss=0.060927 err=0.060927
I 2015-05-26 09:36:13 theanets.trainer:168 RmsProp 802 loss=0.064367 err=0.064367
I 2015-05-26 09:36:17 theanets.trainer:168 RmsProp 803 loss=0.061583 err=0.061583
I 2015-05-26 09:36:20 theanets.trainer:168 RmsProp 804 loss=0.060043 err=0.060043
I 2015-05-26 09:36:23 theanets.trainer:168 RmsProp 805 loss=0.065936 err=0.065936
I 2015-05-26 09:36:27 theanets.trainer:168 RmsProp 806 loss=0.061024 err=0.061024
I 2015-05-26 09:36:30 theanets.trainer:168 RmsProp 807 loss=0.064938 err=0.064938
I 2015-05-26 09:36:33 theanets.trainer:168 RmsProp 808 loss=0.061376 err=0.061376
I 2015-05-26 09:36:36 theanets.trainer:168 RmsProp 809 loss=0.059294 err=0.059294
I 2015-05-26 09:36:39 theanets.trainer:168 RmsProp 810 loss=0.067854 err=0.067854
I 2015-05-26 09:36:39 theanets.trainer:168 validation 81 loss=1201.631836 err=1201.631836 *
I 2015-05-26 09:36:43 theanets.trainer:168 RmsProp 811 loss=0.061879 err=0.061879
I 2015-05-26 09:36:46 theanets.trainer:168 RmsProp 812 loss=0.065452 err=0.065452
I 2015-05-26 09:36:49 theanets.trainer:168 RmsProp 813 loss=0.060649 err=0.060649
I 2015-05-26 09:36:53 theanets.trainer:168 RmsProp 814 loss=0.061879 err=0.061879
I 2015-05-26 09:36:56 theanets.trainer:168 RmsProp 815 loss=0.063893 err=0.063893
I 2015-05-26 09:36:59 theanets.trainer:168 RmsProp 816 loss=0.062176 err=0.062176
I 2015-05-26 09:37:02 theanets.trainer:168 RmsProp 817 loss=0.058752 err=0.058752
I 2015-05-26 09:37:05 theanets.trainer:168 RmsProp 818 loss=0.061524 err=0.061524
I 2015-05-26 09:37:09 theanets.trainer:168 RmsProp 819 loss=0.064080 err=0.064080
I 2015-05-26 09:37:12 theanets.trainer:168 RmsProp 820 loss=0.063265 err=0.063265
I 2015-05-26 09:37:12 theanets.trainer:168 validation 82 loss=1197.668213 err=1197.668213 *
I 2015-05-26 09:37:16 theanets.trainer:168 RmsProp 821 loss=0.058615 err=0.058615
I 2015-05-26 09:37:19 theanets.trainer:168 RmsProp 822 loss=0.062928 err=0.062928
I 2015-05-26 09:37:22 theanets.trainer:168 RmsProp 823 loss=0.062656 err=0.062656
I 2015-05-26 09:37:25 theanets.trainer:168 RmsProp 824 loss=0.060636 err=0.060636
I 2015-05-26 09:37:28 theanets.trainer:168 RmsProp 825 loss=0.062753 err=0.062753
I 2015-05-26 09:37:31 theanets.trainer:168 RmsProp 826 loss=0.062111 err=0.062111
I 2015-05-26 09:37:35 theanets.trainer:168 RmsProp 827 loss=0.059205 err=0.059205
I 2015-05-26 09:37:38 theanets.trainer:168 RmsProp 828 loss=0.059795 err=0.059795
I 2015-05-26 09:37:41 theanets.trainer:168 RmsProp 829 loss=0.059280 err=0.059280
I 2015-05-26 09:37:44 theanets.trainer:168 RmsProp 830 loss=0.064189 err=0.064189
I 2015-05-26 09:37:44 theanets.trainer:168 validation 83 loss=1198.664917 err=1198.664917
I 2015-05-26 09:37:47 theanets.trainer:168 RmsProp 831 loss=0.057716 err=0.057716
I 2015-05-26 09:37:51 theanets.trainer:168 RmsProp 832 loss=0.059332 err=0.059332
I 2015-05-26 09:37:54 theanets.trainer:168 RmsProp 833 loss=0.060063 err=0.060063
I 2015-05-26 09:37:58 theanets.trainer:168 RmsProp 834 loss=0.062238 err=0.062238
I 2015-05-26 09:38:01 theanets.trainer:168 RmsProp 835 loss=0.062665 err=0.062665
I 2015-05-26 09:38:04 theanets.trainer:168 RmsProp 836 loss=0.064125 err=0.064125
I 2015-05-26 09:38:07 theanets.trainer:168 RmsProp 837 loss=0.061139 err=0.061139
I 2015-05-26 09:38:10 theanets.trainer:168 RmsProp 838 loss=0.058461 err=0.058461
I 2015-05-26 09:38:14 theanets.trainer:168 RmsProp 839 loss=0.061000 err=0.061000
I 2015-05-26 09:38:17 theanets.trainer:168 RmsProp 840 loss=0.064765 err=0.064765
I 2015-05-26 09:38:17 theanets.trainer:168 validation 84 loss=1197.954712 err=1197.954712
I 2015-05-26 09:38:20 theanets.trainer:168 RmsProp 841 loss=0.059875 err=0.059875
I 2015-05-26 09:38:23 theanets.trainer:168 RmsProp 842 loss=0.059530 err=0.059530
I 2015-05-26 09:38:26 theanets.trainer:168 RmsProp 843 loss=0.058529 err=0.058529
I 2015-05-26 09:38:29 theanets.trainer:168 RmsProp 844 loss=0.063733 err=0.063733
I 2015-05-26 09:38:33 theanets.trainer:168 RmsProp 845 loss=0.057512 err=0.057512
I 2015-05-26 09:38:36 theanets.trainer:168 RmsProp 846 loss=0.061512 err=0.061512
I 2015-05-26 09:38:39 theanets.trainer:168 RmsProp 847 loss=0.059548 err=0.059548
I 2015-05-26 09:38:42 theanets.trainer:168 RmsProp 848 loss=0.056721 err=0.056721
I 2015-05-26 09:38:46 theanets.trainer:168 RmsProp 849 loss=0.061895 err=0.061895
I 2015-05-26 09:38:49 theanets.trainer:168 RmsProp 850 loss=0.061178 err=0.061178
I 2015-05-26 09:38:49 theanets.trainer:168 validation 85 loss=1195.839233 err=1195.839233 *
I 2015-05-26 09:38:52 theanets.trainer:168 RmsProp 851 loss=0.064285 err=0.064285
I 2015-05-26 09:38:56 theanets.trainer:168 RmsProp 852 loss=0.061963 err=0.061963
I 2015-05-26 09:39:00 theanets.trainer:168 RmsProp 853 loss=0.061008 err=0.061008
I 2015-05-26 09:39:03 theanets.trainer:168 RmsProp 854 loss=0.059991 err=0.059991
I 2015-05-26 09:39:06 theanets.trainer:168 RmsProp 855 loss=0.057029 err=0.057029
I 2015-05-26 09:39:10 theanets.trainer:168 RmsProp 856 loss=0.063913 err=0.063913
I 2015-05-26 09:39:13 theanets.trainer:168 RmsProp 857 loss=0.060858 err=0.060858
I 2015-05-26 09:39:16 theanets.trainer:168 RmsProp 858 loss=0.055932 err=0.055932
I 2015-05-26 09:39:19 theanets.trainer:168 RmsProp 859 loss=0.060510 err=0.060510
I 2015-05-26 09:39:23 theanets.trainer:168 RmsProp 860 loss=0.059699 err=0.059699
I 2015-05-26 09:39:23 theanets.trainer:168 validation 86 loss=1199.266724 err=1199.266724
I 2015-05-26 09:39:26 theanets.trainer:168 RmsProp 861 loss=0.054644 err=0.054644
I 2015-05-26 09:39:29 theanets.trainer:168 RmsProp 862 loss=0.062468 err=0.062468
I 2015-05-26 09:39:33 theanets.trainer:168 RmsProp 863 loss=0.059319 err=0.059319
I 2015-05-26 09:39:36 theanets.trainer:168 RmsProp 864 loss=0.057921 err=0.057921
I 2015-05-26 09:39:39 theanets.trainer:168 RmsProp 865 loss=0.057431 err=0.057431
I 2015-05-26 09:39:42 theanets.trainer:168 RmsProp 866 loss=0.063021 err=0.063021
I 2015-05-26 09:39:45 theanets.trainer:168 RmsProp 867 loss=0.056158 err=0.056158
I 2015-05-26 09:39:48 theanets.trainer:168 RmsProp 868 loss=0.063577 err=0.063577
I 2015-05-26 09:39:52 theanets.trainer:168 RmsProp 869 loss=0.057702 err=0.057702
I 2015-05-26 09:39:55 theanets.trainer:168 RmsProp 870 loss=0.056751 err=0.056751
I 2015-05-26 09:39:55 theanets.trainer:168 validation 87 loss=1196.599976 err=1196.599976
I 2015-05-26 09:39:58 theanets.trainer:168 RmsProp 871 loss=0.060051 err=0.060051
I 2015-05-26 09:40:01 theanets.trainer:168 RmsProp 872 loss=0.058317 err=0.058317
I 2015-05-26 09:40:04 theanets.trainer:168 RmsProp 873 loss=0.056905 err=0.056905
I 2015-05-26 09:40:08 theanets.trainer:168 RmsProp 874 loss=0.064045 err=0.064045
I 2015-05-26 09:40:11 theanets.trainer:168 RmsProp 875 loss=0.057882 err=0.057882
I 2015-05-26 09:40:14 theanets.trainer:168 RmsProp 876 loss=0.057329 err=0.057329
I 2015-05-26 09:40:18 theanets.trainer:168 RmsProp 877 loss=0.055906 err=0.055906
I 2015-05-26 09:40:21 theanets.trainer:168 RmsProp 878 loss=0.065837 err=0.065837
I 2015-05-26 09:40:25 theanets.trainer:168 RmsProp 879 loss=0.062747 err=0.062747
I 2015-05-26 09:40:28 theanets.trainer:168 RmsProp 880 loss=0.058183 err=0.058183
I 2015-05-26 09:40:28 theanets.trainer:168 validation 88 loss=1196.489014 err=1196.489014
I 2015-05-26 09:40:31 theanets.trainer:168 RmsProp 881 loss=0.058995 err=0.058995
I 2015-05-26 09:40:35 theanets.trainer:168 RmsProp 882 loss=0.059355 err=0.059355
I 2015-05-26 09:40:38 theanets.trainer:168 RmsProp 883 loss=0.060786 err=0.060786
I 2015-05-26 09:40:42 theanets.trainer:168 RmsProp 884 loss=0.058772 err=0.058772
I 2015-05-26 09:40:45 theanets.trainer:168 RmsProp 885 loss=0.060022 err=0.060022
I 2015-05-26 09:40:48 theanets.trainer:168 RmsProp 886 loss=0.058037 err=0.058037
I 2015-05-26 09:40:51 theanets.trainer:168 RmsProp 887 loss=0.057780 err=0.057780
I 2015-05-26 09:40:54 theanets.trainer:168 RmsProp 888 loss=0.056916 err=0.056916
I 2015-05-26 09:40:57 theanets.trainer:168 RmsProp 889 loss=0.056725 err=0.056725
I 2015-05-26 09:41:00 theanets.trainer:168 RmsProp 890 loss=0.060291 err=0.060291
I 2015-05-26 09:41:00 theanets.trainer:168 validation 89 loss=1195.969482 err=1195.969482
I 2015-05-26 09:41:04 theanets.trainer:168 RmsProp 891 loss=0.056501 err=0.056501
I 2015-05-26 09:41:07 theanets.trainer:168 RmsProp 892 loss=0.059208 err=0.059208
I 2015-05-26 09:41:10 theanets.trainer:168 RmsProp 893 loss=0.057927 err=0.057927
I 2015-05-26 09:41:14 theanets.trainer:168 RmsProp 894 loss=0.056953 err=0.056953
I 2015-05-26 09:41:18 theanets.trainer:168 RmsProp 895 loss=0.058618 err=0.058618
I 2015-05-26 09:41:21 theanets.trainer:168 RmsProp 896 loss=0.054884 err=0.054884
I 2015-05-26 09:41:24 theanets.trainer:168 RmsProp 897 loss=0.055774 err=0.055774
I 2015-05-26 09:41:27 theanets.trainer:168 RmsProp 898 loss=0.057004 err=0.057004
I 2015-05-26 09:41:31 theanets.trainer:168 RmsProp 899 loss=0.065063 err=0.065063
I 2015-05-26 09:41:34 theanets.trainer:168 RmsProp 900 loss=0.057920 err=0.057920
I 2015-05-26 09:41:34 theanets.trainer:168 validation 90 loss=1195.038452 err=1195.038452 *
I 2015-05-26 09:41:37 theanets.trainer:168 RmsProp 901 loss=0.052902 err=0.052902
I 2015-05-26 09:41:41 theanets.trainer:168 RmsProp 902 loss=0.060944 err=0.060944
I 2015-05-26 09:41:44 theanets.trainer:168 RmsProp 903 loss=0.058691 err=0.058691
I 2015-05-26 09:41:47 theanets.trainer:168 RmsProp 904 loss=0.052644 err=0.052644
I 2015-05-26 09:41:50 theanets.trainer:168 RmsProp 905 loss=0.057030 err=0.057030
I 2015-05-26 09:41:53 theanets.trainer:168 RmsProp 906 loss=0.055141 err=0.055141
I 2015-05-26 09:41:56 theanets.trainer:168 RmsProp 907 loss=0.058682 err=0.058682
I 2015-05-26 09:41:59 theanets.trainer:168 RmsProp 908 loss=0.057783 err=0.057783
I 2015-05-26 09:42:03 theanets.trainer:168 RmsProp 909 loss=0.058056 err=0.058056
I 2015-05-26 09:42:05 theanets.trainer:168 RmsProp 910 loss=0.055510 err=0.055510
I 2015-05-26 09:42:06 theanets.trainer:168 validation 91 loss=1194.484253 err=1194.484253 *
I 2015-05-26 09:42:09 theanets.trainer:168 RmsProp 911 loss=0.059872 err=0.059872
I 2015-05-26 09:42:13 theanets.trainer:168 RmsProp 912 loss=0.055275 err=0.055275
I 2015-05-26 09:42:16 theanets.trainer:168 RmsProp 913 loss=0.057368 err=0.057368
I 2015-05-26 09:42:19 theanets.trainer:168 RmsProp 914 loss=0.057056 err=0.057056
I 2015-05-26 09:42:22 theanets.trainer:168 RmsProp 915 loss=0.056932 err=0.056932
I 2015-05-26 09:42:26 theanets.trainer:168 RmsProp 916 loss=0.054333 err=0.054333
I 2015-05-26 09:42:29 theanets.trainer:168 RmsProp 917 loss=0.054961 err=0.054961
I 2015-05-26 09:42:32 theanets.trainer:168 RmsProp 918 loss=0.057806 err=0.057806
I 2015-05-26 09:42:36 theanets.trainer:168 RmsProp 919 loss=0.052308 err=0.052308
I 2015-05-26 09:42:39 theanets.trainer:168 RmsProp 920 loss=0.063447 err=0.063447
I 2015-05-26 09:42:39 theanets.trainer:168 validation 92 loss=1194.651245 err=1194.651245
I 2015-05-26 09:42:42 theanets.trainer:168 RmsProp 921 loss=0.054237 err=0.054237
I 2015-05-26 09:42:46 theanets.trainer:168 RmsProp 922 loss=0.052604 err=0.052604
I 2015-05-26 09:42:49 theanets.trainer:168 RmsProp 923 loss=0.054983 err=0.054983
I 2015-05-26 09:42:52 theanets.trainer:168 RmsProp 924 loss=0.057512 err=0.057512
I 2015-05-26 09:42:56 theanets.trainer:168 RmsProp 925 loss=0.055763 err=0.055763
I 2015-05-26 09:42:59 theanets.trainer:168 RmsProp 926 loss=0.054406 err=0.054406
I 2015-05-26 09:43:02 theanets.trainer:168 RmsProp 927 loss=0.057684 err=0.057684
I 2015-05-26 09:43:05 theanets.trainer:168 RmsProp 928 loss=0.056302 err=0.056302
I 2015-05-26 09:43:08 theanets.trainer:168 RmsProp 929 loss=0.053275 err=0.053275
I 2015-05-26 09:43:11 theanets.trainer:168 RmsProp 930 loss=0.062152 err=0.062152
I 2015-05-26 09:43:11 theanets.trainer:168 validation 93 loss=1191.343628 err=1191.343628 *
I 2015-05-26 09:43:14 theanets.trainer:168 RmsProp 931 loss=0.056547 err=0.056547
I 2015-05-26 09:43:16 theanets.trainer:168 RmsProp 932 loss=0.058186 err=0.058186
I 2015-05-26 09:43:19 theanets.trainer:168 RmsProp 933 loss=0.053692 err=0.053692
I 2015-05-26 09:43:22 theanets.trainer:168 RmsProp 934 loss=0.055796 err=0.055796
I 2015-05-26 09:43:25 theanets.trainer:168 RmsProp 935 loss=0.057501 err=0.057501
I 2015-05-26 09:43:27 theanets.trainer:168 RmsProp 936 loss=0.058883 err=0.058883
I 2015-05-26 09:43:30 theanets.trainer:168 RmsProp 937 loss=0.052415 err=0.052415
I 2015-05-26 09:43:33 theanets.trainer:168 RmsProp 938 loss=0.058912 err=0.058912
I 2015-05-26 09:43:36 theanets.trainer:168 RmsProp 939 loss=0.057130 err=0.057130
I 2015-05-26 09:43:38 theanets.trainer:168 RmsProp 940 loss=0.056678 err=0.056678
I 2015-05-26 09:43:38 theanets.trainer:168 validation 94 loss=1190.690674 err=1190.690674 *
I 2015-05-26 09:43:41 theanets.trainer:168 RmsProp 941 loss=0.060161 err=0.060161
I 2015-05-26 09:43:44 theanets.trainer:168 RmsProp 942 loss=0.052485 err=0.052485
I 2015-05-26 09:43:46 theanets.trainer:168 RmsProp 943 loss=0.057204 err=0.057204
I 2015-05-26 09:43:49 theanets.trainer:168 RmsProp 944 loss=0.053651 err=0.053651
I 2015-05-26 09:43:51 theanets.trainer:168 RmsProp 945 loss=0.056938 err=0.056938
I 2015-05-26 09:43:54 theanets.trainer:168 RmsProp 946 loss=0.052161 err=0.052161
I 2015-05-26 09:43:56 theanets.trainer:168 RmsProp 947 loss=0.055969 err=0.055969
I 2015-05-26 09:43:59 theanets.trainer:168 RmsProp 948 loss=0.052861 err=0.052861
I 2015-05-26 09:44:01 theanets.trainer:168 RmsProp 949 loss=0.055273 err=0.055273
I 2015-05-26 09:44:04 theanets.trainer:168 RmsProp 950 loss=0.053248 err=0.053248
I 2015-05-26 09:44:04 theanets.trainer:168 validation 95 loss=1191.956177 err=1191.956177
I 2015-05-26 09:44:07 theanets.trainer:168 RmsProp 951 loss=0.058150 err=0.058150
I 2015-05-26 09:44:10 theanets.trainer:168 RmsProp 952 loss=0.057197 err=0.057197
I 2015-05-26 09:44:13 theanets.trainer:168 RmsProp 953 loss=0.056238 err=0.056238
I 2015-05-26 09:44:15 theanets.trainer:168 RmsProp 954 loss=0.055573 err=0.055573
I 2015-05-26 09:44:18 theanets.trainer:168 RmsProp 955 loss=0.053756 err=0.053756
I 2015-05-26 09:44:21 theanets.trainer:168 RmsProp 956 loss=0.052684 err=0.052684
I 2015-05-26 09:44:23 theanets.trainer:168 RmsProp 957 loss=0.055302 err=0.055302
I 2015-05-26 09:44:26 theanets.trainer:168 RmsProp 958 loss=0.052346 err=0.052346
I 2015-05-26 09:44:29 theanets.trainer:168 RmsProp 959 loss=0.052660 err=0.052660
I 2015-05-26 09:44:31 theanets.trainer:168 RmsProp 960 loss=0.058042 err=0.058042
I 2015-05-26 09:44:31 theanets.trainer:168 validation 96 loss=1192.059570 err=1192.059570
I 2015-05-26 09:44:34 theanets.trainer:168 RmsProp 961 loss=0.052240 err=0.052240
I 2015-05-26 09:44:36 theanets.trainer:168 RmsProp 962 loss=0.057300 err=0.057300
I 2015-05-26 09:44:39 theanets.trainer:168 RmsProp 963 loss=0.049333 err=0.049333
I 2015-05-26 09:44:42 theanets.trainer:168 RmsProp 964 loss=0.059256 err=0.059256
I 2015-05-26 09:44:44 theanets.trainer:168 RmsProp 965 loss=0.058442 err=0.058442
I 2015-05-26 09:44:46 theanets.trainer:168 RmsProp 966 loss=0.057016 err=0.057016
I 2015-05-26 09:44:49 theanets.trainer:168 RmsProp 967 loss=0.050562 err=0.050562
I 2015-05-26 09:44:51 theanets.trainer:168 RmsProp 968 loss=0.065142 err=0.065142
I 2015-05-26 09:44:53 theanets.trainer:168 RmsProp 969 loss=0.052728 err=0.052728
I 2015-05-26 09:44:56 theanets.trainer:168 RmsProp 970 loss=0.052983 err=0.052983
I 2015-05-26 09:44:56 theanets.trainer:168 validation 97 loss=1190.184448 err=1190.184448 *
I 2015-05-26 09:44:59 theanets.trainer:168 RmsProp 971 loss=0.054500 err=0.054500
I 2015-05-26 09:45:01 theanets.trainer:168 RmsProp 972 loss=0.051519 err=0.051519
I 2015-05-26 09:45:04 theanets.trainer:168 RmsProp 973 loss=0.052930 err=0.052930
I 2015-05-26 09:45:07 theanets.trainer:168 RmsProp 974 loss=0.053152 err=0.053152
I 2015-05-26 09:45:09 theanets.trainer:168 RmsProp 975 loss=0.055756 err=0.055756
I 2015-05-26 09:45:12 theanets.trainer:168 RmsProp 976 loss=0.052954 err=0.052954
I 2015-05-26 09:45:15 theanets.trainer:168 RmsProp 977 loss=0.054559 err=0.054559
I 2015-05-26 09:45:17 theanets.trainer:168 RmsProp 978 loss=0.056562 err=0.056562
I 2015-05-26 09:45:20 theanets.trainer:168 RmsProp 979 loss=0.051252 err=0.051252
I 2015-05-26 09:45:23 theanets.trainer:168 RmsProp 980 loss=0.058342 err=0.058342
I 2015-05-26 09:45:23 theanets.trainer:168 validation 98 loss=1191.505249 err=1191.505249
I 2015-05-26 09:45:25 theanets.trainer:168 RmsProp 981 loss=0.055989 err=0.055989
I 2015-05-26 09:45:28 theanets.trainer:168 RmsProp 982 loss=0.051267 err=0.051267
I 2015-05-26 09:45:31 theanets.trainer:168 RmsProp 983 loss=0.053343 err=0.053343
I 2015-05-26 09:45:33 theanets.trainer:168 RmsProp 984 loss=0.052201 err=0.052201
I 2015-05-26 09:45:36 theanets.trainer:168 RmsProp 985 loss=0.058007 err=0.058007
I 2015-05-26 09:45:38 theanets.trainer:168 RmsProp 986 loss=0.051204 err=0.051204
I 2015-05-26 09:45:41 theanets.trainer:168 RmsProp 987 loss=0.053085 err=0.053085
I 2015-05-26 09:45:43 theanets.trainer:168 RmsProp 988 loss=0.057787 err=0.057787
I 2015-05-26 09:45:46 theanets.trainer:168 RmsProp 989 loss=0.049712 err=0.049712
I 2015-05-26 09:45:49 theanets.trainer:168 RmsProp 990 loss=0.053916 err=0.053916
I 2015-05-26 09:45:49 theanets.trainer:168 validation 99 loss=1191.466675 err=1191.466675
I 2015-05-26 09:45:52 theanets.trainer:168 RmsProp 991 loss=0.055635 err=0.055635
I 2015-05-26 09:45:54 theanets.trainer:168 RmsProp 992 loss=0.051777 err=0.051777
I 2015-05-26 09:45:57 theanets.trainer:168 RmsProp 993 loss=0.050339 err=0.050339
I 2015-05-26 09:46:00 theanets.trainer:168 RmsProp 994 loss=0.055456 err=0.055456
I 2015-05-26 09:46:02 theanets.trainer:168 RmsProp 995 loss=0.055224 err=0.055224
I 2015-05-26 09:46:05 theanets.trainer:168 RmsProp 996 loss=0.052621 err=0.052621
I 2015-05-26 09:46:07 theanets.trainer:168 RmsProp 997 loss=0.057599 err=0.057599
I 2015-05-26 09:46:10 theanets.trainer:168 RmsProp 998 loss=0.051014 err=0.051014
I 2015-05-26 09:46:13 theanets.trainer:168 RmsProp 999 loss=0.053902 err=0.053902
I 2015-05-26 09:46:15 theanets.trainer:168 RmsProp 1000 loss=0.055328 err=0.055328
I 2015-05-26 09:46:16 theanets.trainer:168 validation 100 loss=1187.250366 err=1187.250366 *
I 2015-05-26 09:46:18 theanets.trainer:168 RmsProp 1001 loss=0.050420 err=0.050420
I 2015-05-26 09:46:21 theanets.trainer:168 RmsProp 1002 loss=0.051620 err=0.051620
I 2015-05-26 09:46:24 theanets.trainer:168 RmsProp 1003 loss=0.056956 err=0.056956
I 2015-05-26 09:46:26 theanets.trainer:168 RmsProp 1004 loss=0.053618 err=0.053618
I 2015-05-26 09:46:29 theanets.trainer:168 RmsProp 1005 loss=0.051127 err=0.051127
I 2015-05-26 09:46:31 theanets.trainer:168 RmsProp 1006 loss=0.052601 err=0.052601
I 2015-05-26 09:46:34 theanets.trainer:168 RmsProp 1007 loss=0.052212 err=0.052212
I 2015-05-26 09:46:37 theanets.trainer:168 RmsProp 1008 loss=0.049959 err=0.049959
I 2015-05-26 09:46:40 theanets.trainer:168 RmsProp 1009 loss=0.051019 err=0.051019
I 2015-05-26 09:46:42 theanets.trainer:168 RmsProp 1010 loss=0.051887 err=0.051887
I 2015-05-26 09:46:43 theanets.trainer:168 validation 101 loss=1188.905884 err=1188.905884
I 2015-05-26 09:46:45 theanets.trainer:168 RmsProp 1011 loss=0.049437 err=0.049437
I 2015-05-26 09:46:48 theanets.trainer:168 RmsProp 1012 loss=0.056287 err=0.056287
I 2015-05-26 09:46:51 theanets.trainer:168 RmsProp 1013 loss=0.052426 err=0.052426
I 2015-05-26 09:46:54 theanets.trainer:168 RmsProp 1014 loss=0.052216 err=0.052216
I 2015-05-26 09:46:56 theanets.trainer:168 RmsProp 1015 loss=0.049504 err=0.049504
I 2015-05-26 09:46:59 theanets.trainer:168 RmsProp 1016 loss=0.047294 err=0.047294
I 2015-05-26 09:47:01 theanets.trainer:168 RmsProp 1017 loss=0.061225 err=0.061225
I 2015-05-26 09:47:04 theanets.trainer:168 RmsProp 1018 loss=0.049300 err=0.049300
I 2015-05-26 09:47:06 theanets.trainer:168 RmsProp 1019 loss=0.050447 err=0.050447
I 2015-05-26 09:47:09 theanets.trainer:168 RmsProp 1020 loss=0.054075 err=0.054075
I 2015-05-26 09:47:09 theanets.trainer:168 validation 102 loss=1186.755737 err=1186.755737 *
I 2015-05-26 09:47:12 theanets.trainer:168 RmsProp 1021 loss=0.051087 err=0.051087
I 2015-05-26 09:47:14 theanets.trainer:168 RmsProp 1022 loss=0.051536 err=0.051536
I 2015-05-26 09:47:17 theanets.trainer:168 RmsProp 1023 loss=0.051387 err=0.051387
I 2015-05-26 09:47:20 theanets.trainer:168 RmsProp 1024 loss=0.054616 err=0.054616
I 2015-05-26 09:47:22 theanets.trainer:168 RmsProp 1025 loss=0.050009 err=0.050009
I 2015-05-26 09:47:25 theanets.trainer:168 RmsProp 1026 loss=0.054376 err=0.054376
I 2015-05-26 09:47:28 theanets.trainer:168 RmsProp 1027 loss=0.049156 err=0.049156
I 2015-05-26 09:47:30 theanets.trainer:168 RmsProp 1028 loss=0.057722 err=0.057722
I 2015-05-26 09:47:33 theanets.trainer:168 RmsProp 1029 loss=0.051098 err=0.051098
I 2015-05-26 09:47:36 theanets.trainer:168 RmsProp 1030 loss=0.047206 err=0.047206
I 2015-05-26 09:47:36 theanets.trainer:168 validation 103 loss=1186.127808 err=1186.127808 *
I 2015-05-26 09:47:38 theanets.trainer:168 RmsProp 1031 loss=0.050416 err=0.050416
I 2015-05-26 09:47:41 theanets.trainer:168 RmsProp 1032 loss=0.053566 err=0.053566
I 2015-05-26 09:47:44 theanets.trainer:168 RmsProp 1033 loss=0.049155 err=0.049155
I 2015-05-26 09:47:46 theanets.trainer:168 RmsProp 1034 loss=0.050416 err=0.050416
I 2015-05-26 09:47:49 theanets.trainer:168 RmsProp 1035 loss=0.053635 err=0.053635
I 2015-05-26 09:47:51 theanets.trainer:168 RmsProp 1036 loss=0.049319 err=0.049319
I 2015-05-26 09:47:54 theanets.trainer:168 RmsProp 1037 loss=0.049658 err=0.049658
I 2015-05-26 09:47:56 theanets.trainer:168 RmsProp 1038 loss=0.053078 err=0.053078
I 2015-05-26 09:47:59 theanets.trainer:168 RmsProp 1039 loss=0.051075 err=0.051075
I 2015-05-26 09:48:02 theanets.trainer:168 RmsProp 1040 loss=0.050441 err=0.050441
I 2015-05-26 09:48:02 theanets.trainer:168 validation 104 loss=1184.943237 err=1184.943237 *
I 2015-05-26 09:48:04 theanets.trainer:168 RmsProp 1041 loss=0.047727 err=0.047727
I 2015-05-26 09:48:07 theanets.trainer:168 RmsProp 1042 loss=0.051457 err=0.051457
I 2015-05-26 09:48:10 theanets.trainer:168 RmsProp 1043 loss=0.048437 err=0.048437
I 2015-05-26 09:48:12 theanets.trainer:168 RmsProp 1044 loss=0.053615 err=0.053615
I 2015-05-26 09:48:15 theanets.trainer:168 RmsProp 1045 loss=0.049353 err=0.049353
I 2015-05-26 09:48:18 theanets.trainer:168 RmsProp 1046 loss=0.051795 err=0.051795
I 2015-05-26 09:48:20 theanets.trainer:168 RmsProp 1047 loss=0.054468 err=0.054468
I 2015-05-26 09:48:23 theanets.trainer:168 RmsProp 1048 loss=0.049908 err=0.049908
I 2015-05-26 09:48:26 theanets.trainer:168 RmsProp 1049 loss=0.049726 err=0.049726
I 2015-05-26 09:48:28 theanets.trainer:168 RmsProp 1050 loss=0.048767 err=0.048767
I 2015-05-26 09:48:28 theanets.trainer:168 validation 105 loss=1182.575073 err=1182.575073 *
I 2015-05-26 09:48:31 theanets.trainer:168 RmsProp 1051 loss=0.052181 err=0.052181
I 2015-05-26 09:48:34 theanets.trainer:168 RmsProp 1052 loss=0.049869 err=0.049869
I 2015-05-26 09:48:37 theanets.trainer:168 RmsProp 1053 loss=0.055512 err=0.055512
I 2015-05-26 09:48:39 theanets.trainer:168 RmsProp 1054 loss=0.051619 err=0.051619
I 2015-05-26 09:48:42 theanets.trainer:168 RmsProp 1055 loss=0.049490 err=0.049490
I 2015-05-26 09:48:44 theanets.trainer:168 RmsProp 1056 loss=0.052224 err=0.052224
I 2015-05-26 09:48:47 theanets.trainer:168 RmsProp 1057 loss=0.046857 err=0.046857
I 2015-05-26 09:48:49 theanets.trainer:168 RmsProp 1058 loss=0.049123 err=0.049123
I 2015-05-26 09:48:52 theanets.trainer:168 RmsProp 1059 loss=0.054136 err=0.054136
I 2015-05-26 09:48:54 theanets.trainer:168 RmsProp 1060 loss=0.053816 err=0.053816
I 2015-05-26 09:48:55 theanets.trainer:168 validation 106 loss=1180.493042 err=1180.493042 *
I 2015-05-26 09:48:57 theanets.trainer:168 RmsProp 1061 loss=0.050849 err=0.050849
I 2015-05-26 09:49:00 theanets.trainer:168 RmsProp 1062 loss=0.047826 err=0.047826
I 2015-05-26 09:49:02 theanets.trainer:168 RmsProp 1063 loss=0.051695 err=0.051695
I 2015-05-26 09:49:05 theanets.trainer:168 RmsProp 1064 loss=0.057392 err=0.057392
I 2015-05-26 09:49:08 theanets.trainer:168 RmsProp 1065 loss=0.048313 err=0.048313
I 2015-05-26 09:49:10 theanets.trainer:168 RmsProp 1066 loss=0.049760 err=0.049760
I 2015-05-26 09:49:13 theanets.trainer:168 RmsProp 1067 loss=0.048753 err=0.048753
I 2015-05-26 09:49:16 theanets.trainer:168 RmsProp 1068 loss=0.050224 err=0.050224
I 2015-05-26 09:49:18 theanets.trainer:168 RmsProp 1069 loss=0.047500 err=0.047500
I 2015-05-26 09:49:21 theanets.trainer:168 RmsProp 1070 loss=0.052987 err=0.052987
I 2015-05-26 09:49:21 theanets.trainer:168 validation 107 loss=1180.630371 err=1180.630371
I 2015-05-26 09:49:24 theanets.trainer:168 RmsProp 1071 loss=0.047963 err=0.047963
I 2015-05-26 09:49:27 theanets.trainer:168 RmsProp 1072 loss=0.050525 err=0.050525
I 2015-05-26 09:49:29 theanets.trainer:168 RmsProp 1073 loss=0.049495 err=0.049495
I 2015-05-26 09:49:32 theanets.trainer:168 RmsProp 1074 loss=0.049252 err=0.049252
I 2015-05-26 09:49:35 theanets.trainer:168 RmsProp 1075 loss=0.049150 err=0.049150
I 2015-05-26 09:49:37 theanets.trainer:168 RmsProp 1076 loss=0.051796 err=0.051796
I 2015-05-26 09:49:40 theanets.trainer:168 RmsProp 1077 loss=0.048164 err=0.048164
I 2015-05-26 09:49:43 theanets.trainer:168 RmsProp 1078 loss=0.053469 err=0.053469
I 2015-05-26 09:49:46 theanets.trainer:168 RmsProp 1079 loss=0.052979 err=0.052979
I 2015-05-26 09:49:49 theanets.trainer:168 RmsProp 1080 loss=0.048441 err=0.048441
I 2015-05-26 09:49:49 theanets.trainer:168 validation 108 loss=1179.717651 err=1179.717651 *
I 2015-05-26 09:49:51 theanets.trainer:168 RmsProp 1081 loss=0.048247 err=0.048247
I 2015-05-26 09:49:54 theanets.trainer:168 RmsProp 1082 loss=0.050635 err=0.050635
I 2015-05-26 09:49:57 theanets.trainer:168 RmsProp 1083 loss=0.049184 err=0.049184
I 2015-05-26 09:49:59 theanets.trainer:168 RmsProp 1084 loss=0.055380 err=0.055380
I 2015-05-26 09:50:02 theanets.trainer:168 RmsProp 1085 loss=0.046876 err=0.046876
I 2015-05-26 09:50:04 theanets.trainer:168 RmsProp 1086 loss=0.052902 err=0.052902
I 2015-05-26 09:50:07 theanets.trainer:168 RmsProp 1087 loss=0.045658 err=0.045658
I 2015-05-26 09:50:10 theanets.trainer:168 RmsProp 1088 loss=0.049222 err=0.049222
I 2015-05-26 09:50:13 theanets.trainer:168 RmsProp 1089 loss=0.049203 err=0.049203
I 2015-05-26 09:50:15 theanets.trainer:168 RmsProp 1090 loss=0.050375 err=0.050375
I 2015-05-26 09:50:15 theanets.trainer:168 validation 109 loss=1181.095947 err=1181.095947
I 2015-05-26 09:50:18 theanets.trainer:168 RmsProp 1091 loss=0.052762 err=0.052762
I 2015-05-26 09:50:21 theanets.trainer:168 RmsProp 1092 loss=0.046660 err=0.046660
I 2015-05-26 09:50:23 theanets.trainer:168 RmsProp 1093 loss=0.047031 err=0.047031
I 2015-05-26 09:50:26 theanets.trainer:168 RmsProp 1094 loss=0.049054 err=0.049054
I 2015-05-26 09:50:29 theanets.trainer:168 RmsProp 1095 loss=0.047835 err=0.047835
I 2015-05-26 09:50:32 theanets.trainer:168 RmsProp 1096 loss=0.048046 err=0.048046
I 2015-05-26 09:50:34 theanets.trainer:168 RmsProp 1097 loss=0.050488 err=0.050488
I 2015-05-26 09:50:37 theanets.trainer:168 RmsProp 1098 loss=0.046505 err=0.046505
I 2015-05-26 09:50:39 theanets.trainer:168 RmsProp 1099 loss=0.054273 err=0.054273
I 2015-05-26 09:50:42 theanets.trainer:168 RmsProp 1100 loss=0.047493 err=0.047493
I 2015-05-26 09:50:42 theanets.trainer:168 validation 110 loss=1179.892944 err=1179.892944
I 2015-05-26 09:50:45 theanets.trainer:168 RmsProp 1101 loss=0.048411 err=0.048411
I 2015-05-26 09:50:47 theanets.trainer:168 RmsProp 1102 loss=0.046253 err=0.046253
I 2015-05-26 09:50:50 theanets.trainer:168 RmsProp 1103 loss=0.049368 err=0.049368
I 2015-05-26 09:50:52 theanets.trainer:168 RmsProp 1104 loss=0.050261 err=0.050261
I 2015-05-26 09:50:55 theanets.trainer:168 RmsProp 1105 loss=0.048995 err=0.048995
I 2015-05-26 09:50:58 theanets.trainer:168 RmsProp 1106 loss=0.047216 err=0.047216
I 2015-05-26 09:51:00 theanets.trainer:168 RmsProp 1107 loss=0.049704 err=0.049704
I 2015-05-26 09:51:03 theanets.trainer:168 RmsProp 1108 loss=0.044957 err=0.044957
I 2015-05-26 09:51:06 theanets.trainer:168 RmsProp 1109 loss=0.055387 err=0.055387
I 2015-05-26 09:51:08 theanets.trainer:168 RmsProp 1110 loss=0.048302 err=0.048302
I 2015-05-26 09:51:09 theanets.trainer:168 validation 111 loss=1175.852173 err=1175.852173 *
I 2015-05-26 09:51:11 theanets.trainer:168 RmsProp 1111 loss=0.046067 err=0.046067
I 2015-05-26 09:51:14 theanets.trainer:168 RmsProp 1112 loss=0.045271 err=0.045271
I 2015-05-26 09:51:16 theanets.trainer:168 RmsProp 1113 loss=0.055137 err=0.055137
I 2015-05-26 09:51:19 theanets.trainer:168 RmsProp 1114 loss=0.044968 err=0.044968
I 2015-05-26 09:51:21 theanets.trainer:168 RmsProp 1115 loss=0.048669 err=0.048669
I 2015-05-26 09:51:24 theanets.trainer:168 RmsProp 1116 loss=0.046886 err=0.046886
I 2015-05-26 09:51:27 theanets.trainer:168 RmsProp 1117 loss=0.051175 err=0.051175
I 2015-05-26 09:51:29 theanets.trainer:168 RmsProp 1118 loss=0.044779 err=0.044779
I 2015-05-26 09:51:32 theanets.trainer:168 RmsProp 1119 loss=0.047192 err=0.047192
I 2015-05-26 09:51:35 theanets.trainer:168 RmsProp 1120 loss=0.054119 err=0.054119
I 2015-05-26 09:51:35 theanets.trainer:168 validation 112 loss=1176.306152 err=1176.306152
I 2015-05-26 09:51:37 theanets.trainer:168 RmsProp 1121 loss=0.046771 err=0.046771
I 2015-05-26 09:51:40 theanets.trainer:168 RmsProp 1122 loss=0.047993 err=0.047993
I 2015-05-26 09:51:43 theanets.trainer:168 RmsProp 1123 loss=0.049415 err=0.049415
I 2015-05-26 09:51:46 theanets.trainer:168 RmsProp 1124 loss=0.047515 err=0.047515
I 2015-05-26 09:51:48 theanets.trainer:168 RmsProp 1125 loss=0.048613 err=0.048613
I 2015-05-26 09:51:51 theanets.trainer:168 RmsProp 1126 loss=0.046650 err=0.046650
I 2015-05-26 09:51:54 theanets.trainer:168 RmsProp 1127 loss=0.051359 err=0.051359
I 2015-05-26 09:51:57 theanets.trainer:168 RmsProp 1128 loss=0.048334 err=0.048334
I 2015-05-26 09:51:59 theanets.trainer:168 RmsProp 1129 loss=0.047278 err=0.047278
I 2015-05-26 09:52:02 theanets.trainer:168 RmsProp 1130 loss=0.054345 err=0.054345
I 2015-05-26 09:52:02 theanets.trainer:168 validation 113 loss=1177.145142 err=1177.145142
I 2015-05-26 09:52:04 theanets.trainer:168 RmsProp 1131 loss=0.044272 err=0.044272
I 2015-05-26 09:52:07 theanets.trainer:168 RmsProp 1132 loss=0.050754 err=0.050754
I 2015-05-26 09:52:10 theanets.trainer:168 RmsProp 1133 loss=0.046129 err=0.046129
I 2015-05-26 09:52:12 theanets.trainer:168 RmsProp 1134 loss=0.047039 err=0.047039
I 2015-05-26 09:52:15 theanets.trainer:168 RmsProp 1135 loss=0.044300 err=0.044300
I 2015-05-26 09:52:17 theanets.trainer:168 RmsProp 1136 loss=0.050422 err=0.050422
I 2015-05-26 09:52:20 theanets.trainer:168 RmsProp 1137 loss=0.047643 err=0.047643
I 2015-05-26 09:52:22 theanets.trainer:168 RmsProp 1138 loss=0.046327 err=0.046327
I 2015-05-26 09:52:25 theanets.trainer:168 RmsProp 1139 loss=0.047844 err=0.047844
I 2015-05-26 09:52:28 theanets.trainer:168 RmsProp 1140 loss=0.048996 err=0.048996
I 2015-05-26 09:52:28 theanets.trainer:168 validation 114 loss=1177.019897 err=1177.019897
I 2015-05-26 09:52:31 theanets.trainer:168 RmsProp 1141 loss=0.048237 err=0.048237
I 2015-05-26 09:52:33 theanets.trainer:168 RmsProp 1142 loss=0.046358 err=0.046358
I 2015-05-26 09:52:36 theanets.trainer:168 RmsProp 1143 loss=0.050770 err=0.050770
I 2015-05-26 09:52:39 theanets.trainer:168 RmsProp 1144 loss=0.049283 err=0.049283
I 2015-05-26 09:52:41 theanets.trainer:168 RmsProp 1145 loss=0.047321 err=0.047321
I 2015-05-26 09:52:44 theanets.trainer:168 RmsProp 1146 loss=0.049344 err=0.049344
I 2015-05-26 09:52:47 theanets.trainer:168 RmsProp 1147 loss=0.045039 err=0.045039
I 2015-05-26 09:52:50 theanets.trainer:168 RmsProp 1148 loss=0.049319 err=0.049319
I 2015-05-26 09:52:53 theanets.trainer:168 RmsProp 1149 loss=0.049833 err=0.049833
I 2015-05-26 09:52:56 theanets.trainer:168 RmsProp 1150 loss=0.045153 err=0.045153
I 2015-05-26 09:52:56 theanets.trainer:168 validation 115 loss=1177.599976 err=1177.599976
I 2015-05-26 09:52:58 theanets.trainer:168 RmsProp 1151 loss=0.051228 err=0.051228
I 2015-05-26 09:53:01 theanets.trainer:168 RmsProp 1152 loss=0.046135 err=0.046135
I 2015-05-26 09:53:04 theanets.trainer:168 RmsProp 1153 loss=0.046482 err=0.046482
I 2015-05-26 09:53:07 theanets.trainer:168 RmsProp 1154 loss=0.044396 err=0.044396
I 2015-05-26 09:53:10 theanets.trainer:168 RmsProp 1155 loss=0.048140 err=0.048140
I 2015-05-26 09:53:12 theanets.trainer:168 RmsProp 1156 loss=0.045523 err=0.045523
I 2015-05-26 09:53:15 theanets.trainer:168 RmsProp 1157 loss=0.046795 err=0.046795
I 2015-05-26 09:53:17 theanets.trainer:168 RmsProp 1158 loss=0.048600 err=0.048600
I 2015-05-26 09:53:20 theanets.trainer:168 RmsProp 1159 loss=0.045509 err=0.045509
I 2015-05-26 09:53:23 theanets.trainer:168 RmsProp 1160 loss=0.048922 err=0.048922
I 2015-05-26 09:53:23 theanets.trainer:168 validation 116 loss=1176.225464 err=1176.225464
I 2015-05-26 09:53:23 theanets.trainer:252 patience elapsed!
I 2015-05-26 09:53:23 theanets.main:237 models_deep_post_code_sep/95136-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saving model
I 2015-05-26 09:53:23 theanets.graph:477 models_deep_post_code_sep/95136-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saved model parameters
