I 2015-05-26 22:05:11 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:11 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95120-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:11 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:11 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:11 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:11 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:11 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:11 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:11 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:11 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:11 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:11 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:11 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:27 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:09 theanets.trainer:168 validation 0 loss=14394.213867 err=14151.721680 *
I 2015-05-26 22:08:30 theanets.trainer:168 RmsProp 1 loss=13313.435547 err=13219.230469
I 2015-05-26 22:09:07 theanets.trainer:168 RmsProp 2 loss=13127.709961 err=13108.463867
I 2015-05-26 22:09:47 theanets.trainer:168 RmsProp 3 loss=13123.204102 err=13102.746094
I 2015-05-26 22:10:25 theanets.trainer:168 RmsProp 4 loss=12791.049805 err=12748.881836
I 2015-05-26 22:11:03 theanets.trainer:168 RmsProp 5 loss=11936.369141 err=11872.855469
I 2015-05-26 22:11:41 theanets.trainer:168 RmsProp 6 loss=10751.566406 err=10666.880859
I 2015-05-26 22:12:19 theanets.trainer:168 RmsProp 7 loss=10022.589844 err=9911.586914
I 2015-05-26 22:12:57 theanets.trainer:168 RmsProp 8 loss=9452.187500 err=9320.332031
I 2015-05-26 22:13:36 theanets.trainer:168 RmsProp 9 loss=9159.082031 err=9019.245117
I 2015-05-26 22:14:15 theanets.trainer:168 RmsProp 10 loss=8899.305664 err=8752.619141
I 2015-05-26 22:14:16 theanets.trainer:168 validation 1 loss=8251.727539 err=8097.435059 *
I 2015-05-26 22:14:54 theanets.trainer:168 RmsProp 11 loss=8539.051758 err=8375.430664
I 2015-05-26 22:15:33 theanets.trainer:168 RmsProp 12 loss=8273.722656 err=8085.652832
I 2015-05-26 22:16:12 theanets.trainer:168 RmsProp 13 loss=7915.612793 err=7711.896973
I 2015-05-26 22:16:50 theanets.trainer:168 RmsProp 14 loss=7793.096191 err=7571.072754
I 2015-05-26 22:17:29 theanets.trainer:168 RmsProp 15 loss=7598.643555 err=7354.626465
I 2015-05-26 22:18:08 theanets.trainer:168 RmsProp 16 loss=7731.176270 err=7466.628418
I 2015-05-26 22:18:46 theanets.trainer:168 RmsProp 17 loss=7005.719238 err=6724.508789
I 2015-05-26 22:19:24 theanets.trainer:168 RmsProp 18 loss=6648.517578 err=6347.634766
I 2015-05-26 22:20:02 theanets.trainer:168 RmsProp 19 loss=6517.788574 err=6194.976562
I 2015-05-26 22:20:40 theanets.trainer:168 RmsProp 20 loss=6266.403320 err=5929.388672
I 2015-05-26 22:20:41 theanets.trainer:168 validation 2 loss=5811.937500 err=5468.152344 *
I 2015-05-26 22:21:19 theanets.trainer:168 RmsProp 21 loss=6057.532227 err=5705.192871
I 2015-05-26 22:21:57 theanets.trainer:168 RmsProp 22 loss=5704.788574 err=5345.931641
I 2015-05-26 22:22:36 theanets.trainer:168 RmsProp 23 loss=5403.965332 err=5040.804688
I 2015-05-26 22:23:14 theanets.trainer:168 RmsProp 24 loss=5199.283203 err=4828.679688
I 2015-05-26 22:23:53 theanets.trainer:168 RmsProp 25 loss=4948.572754 err=4567.913086
I 2015-05-26 22:24:30 theanets.trainer:168 RmsProp 26 loss=4746.544922 err=4355.854980
I 2015-05-26 22:25:09 theanets.trainer:168 RmsProp 27 loss=4625.479492 err=4224.229492
I 2015-05-26 22:25:47 theanets.trainer:168 RmsProp 28 loss=4459.424316 err=4047.902100
I 2015-05-26 22:26:25 theanets.trainer:168 RmsProp 29 loss=4388.639648 err=3966.481689
I 2015-05-26 22:27:05 theanets.trainer:168 RmsProp 30 loss=4256.407227 err=3823.086182
I 2015-05-26 22:27:06 theanets.trainer:168 validation 3 loss=4034.429443 err=3595.128174 *
I 2015-05-26 22:27:44 theanets.trainer:168 RmsProp 31 loss=4152.371094 err=3708.602539
I 2015-05-26 22:28:23 theanets.trainer:168 RmsProp 32 loss=4021.288574 err=3567.038574
I 2015-05-26 22:29:02 theanets.trainer:168 RmsProp 33 loss=3914.006104 err=3447.211426
I 2015-05-26 22:29:41 theanets.trainer:168 RmsProp 34 loss=3775.573730 err=3299.190430
I 2015-05-26 22:30:19 theanets.trainer:168 RmsProp 35 loss=3621.620361 err=3137.096191
I 2015-05-26 22:30:58 theanets.trainer:168 RmsProp 36 loss=3539.669189 err=3045.701660
I 2015-05-26 22:31:37 theanets.trainer:168 RmsProp 37 loss=3434.115967 err=2930.903320
I 2015-05-26 22:32:15 theanets.trainer:168 RmsProp 38 loss=3310.818848 err=2799.470215
I 2015-05-26 22:32:54 theanets.trainer:168 RmsProp 39 loss=3224.393311 err=2705.795410
I 2015-05-26 22:33:33 theanets.trainer:168 RmsProp 40 loss=3171.431152 err=2644.023438
I 2015-05-26 22:33:34 theanets.trainer:168 validation 4 loss=3257.506592 err=2725.572021 *
I 2015-05-26 22:34:12 theanets.trainer:168 RmsProp 41 loss=3082.651123 err=2548.103027
I 2015-05-26 22:34:50 theanets.trainer:168 RmsProp 42 loss=3036.285156 err=2496.855713
I 2015-05-26 22:35:29 theanets.trainer:168 RmsProp 43 loss=2992.505615 err=2446.497314
I 2015-05-26 22:36:07 theanets.trainer:168 RmsProp 44 loss=2964.314209 err=2412.757568
I 2015-05-26 22:36:45 theanets.trainer:168 RmsProp 45 loss=2923.913086 err=2366.574707
I 2015-05-26 22:37:23 theanets.trainer:168 RmsProp 46 loss=2819.164795 err=2257.726318
I 2015-05-26 22:38:00 theanets.trainer:168 RmsProp 47 loss=2791.689941 err=2226.479736
I 2015-05-26 22:38:38 theanets.trainer:168 RmsProp 48 loss=2766.211182 err=2196.131104
I 2015-05-26 22:39:16 theanets.trainer:168 RmsProp 49 loss=2732.480469 err=2156.075439
I 2015-05-26 22:39:54 theanets.trainer:168 RmsProp 50 loss=2765.233887 err=2181.938232
I 2015-05-26 22:39:55 theanets.trainer:168 validation 5 loss=3307.742188 err=2718.580078
I 2015-05-26 22:40:32 theanets.trainer:168 RmsProp 51 loss=2725.666992 err=2134.891602
I 2015-05-26 22:41:10 theanets.trainer:168 RmsProp 52 loss=2651.835938 err=2058.653564
I 2015-05-26 22:41:48 theanets.trainer:168 RmsProp 53 loss=2611.125000 err=2014.704590
I 2015-05-26 22:42:26 theanets.trainer:168 RmsProp 54 loss=2567.949707 err=1967.228760
I 2015-05-26 22:43:04 theanets.trainer:168 RmsProp 55 loss=2510.093018 err=1905.807861
I 2015-05-26 22:43:42 theanets.trainer:168 RmsProp 56 loss=2477.964600 err=1872.036743
I 2015-05-26 22:44:21 theanets.trainer:168 RmsProp 57 loss=2501.672119 err=1892.117310
I 2015-05-26 22:45:01 theanets.trainer:168 RmsProp 58 loss=2512.903809 err=1897.926270
I 2015-05-26 22:45:39 theanets.trainer:168 RmsProp 59 loss=2478.101562 err=1859.315186
I 2015-05-26 22:46:18 theanets.trainer:168 RmsProp 60 loss=2452.621094 err=1830.186035
I 2015-05-26 22:46:19 theanets.trainer:168 validation 6 loss=3097.204346 err=2472.238037 *
I 2015-05-26 22:46:56 theanets.trainer:168 RmsProp 61 loss=2437.359131 err=1810.874878
I 2015-05-26 22:47:34 theanets.trainer:168 RmsProp 62 loss=2410.284912 err=1779.937988
I 2015-05-26 22:48:12 theanets.trainer:168 RmsProp 63 loss=2382.168213 err=1747.619385
I 2015-05-26 22:48:49 theanets.trainer:168 RmsProp 64 loss=2326.288574 err=1688.297607
I 2015-05-26 22:49:26 theanets.trainer:168 RmsProp 65 loss=2328.082764 err=1689.182251
I 2015-05-26 22:50:04 theanets.trainer:168 RmsProp 66 loss=2325.162354 err=1682.378052
I 2015-05-26 22:50:43 theanets.trainer:168 RmsProp 67 loss=2296.471924 err=1649.715088
I 2015-05-26 22:51:21 theanets.trainer:168 RmsProp 68 loss=2233.395752 err=1584.867432
I 2015-05-26 22:52:00 theanets.trainer:168 RmsProp 69 loss=2227.929443 err=1577.503662
I 2015-05-26 22:52:37 theanets.trainer:168 RmsProp 70 loss=2266.046875 err=1608.890991
I 2015-05-26 22:52:38 theanets.trainer:168 validation 7 loss=2937.227783 err=2275.737549 *
I 2015-05-26 22:53:16 theanets.trainer:168 RmsProp 71 loss=2213.890869 err=1552.876465
I 2015-05-26 22:53:56 theanets.trainer:168 RmsProp 72 loss=2199.810303 err=1535.760132
I 2015-05-26 22:54:36 theanets.trainer:168 RmsProp 73 loss=2157.289062 err=1491.158081
I 2015-05-26 22:55:15 theanets.trainer:168 RmsProp 74 loss=2219.020752 err=1551.931519
I 2015-05-26 22:55:53 theanets.trainer:168 RmsProp 75 loss=2225.140625 err=1551.822998
I 2015-05-26 22:56:32 theanets.trainer:168 RmsProp 76 loss=2150.188965 err=1477.218872
I 2015-05-26 22:57:11 theanets.trainer:168 RmsProp 77 loss=2350.836670 err=1670.841553
I 2015-05-26 22:57:50 theanets.trainer:168 RmsProp 78 loss=2289.963867 err=1600.741577
I 2015-05-26 22:58:30 theanets.trainer:168 RmsProp 79 loss=2158.311035 err=1470.576050
I 2015-05-26 22:59:09 theanets.trainer:168 RmsProp 80 loss=2128.686279 err=1441.746582
I 2015-05-26 22:59:10 theanets.trainer:168 validation 8 loss=2967.120361 err=2278.534668
I 2015-05-26 22:59:48 theanets.trainer:168 RmsProp 81 loss=2150.131592 err=1459.752808
I 2015-05-26 23:00:25 theanets.trainer:168 RmsProp 82 loss=2167.069336 err=1471.454590
I 2015-05-26 23:01:02 theanets.trainer:168 RmsProp 83 loss=2087.257324 err=1392.583374
I 2015-05-26 23:01:42 theanets.trainer:168 RmsProp 84 loss=2047.677368 err=1353.671143
I 2015-05-26 23:02:20 theanets.trainer:168 RmsProp 85 loss=2006.245850 err=1311.937866
I 2015-05-26 23:02:59 theanets.trainer:168 RmsProp 86 loss=2001.427124 err=1307.318848
I 2015-05-26 23:03:38 theanets.trainer:168 RmsProp 87 loss=2011.288208 err=1312.672607
I 2015-05-26 23:04:17 theanets.trainer:168 RmsProp 88 loss=2004.023315 err=1303.838501
I 2015-05-26 23:04:55 theanets.trainer:168 RmsProp 89 loss=1925.025635 err=1225.801514
I 2015-05-26 23:05:33 theanets.trainer:168 RmsProp 90 loss=1945.229370 err=1246.139160
I 2015-05-26 23:05:34 theanets.trainer:168 validation 9 loss=2672.603516 err=1972.574585 *
I 2015-05-26 23:06:11 theanets.trainer:168 RmsProp 91 loss=1907.374268 err=1207.108154
I 2015-05-26 23:06:49 theanets.trainer:168 RmsProp 92 loss=1890.445923 err=1190.090210
I 2015-05-26 23:07:28 theanets.trainer:168 RmsProp 93 loss=1875.606567 err=1174.554688
I 2015-05-26 23:08:07 theanets.trainer:168 RmsProp 94 loss=1842.523682 err=1141.975220
I 2015-05-26 23:08:46 theanets.trainer:168 RmsProp 95 loss=1835.972900 err=1135.204468
I 2015-05-26 23:09:25 theanets.trainer:168 RmsProp 96 loss=1866.538330 err=1164.111206
I 2015-05-26 23:10:03 theanets.trainer:168 RmsProp 97 loss=1899.097412 err=1190.411011
I 2015-05-26 23:10:41 theanets.trainer:168 RmsProp 98 loss=1855.213989 err=1146.326660
I 2015-05-26 23:11:19 theanets.trainer:168 RmsProp 99 loss=1804.287231 err=1096.166138
I 2015-05-26 23:11:57 theanets.trainer:168 RmsProp 100 loss=1756.542114 err=1052.014404
I 2015-05-26 23:11:58 theanets.trainer:168 validation 10 loss=2715.533936 err=2012.497437
I 2015-05-26 23:12:36 theanets.trainer:168 RmsProp 101 loss=1755.739014 err=1053.153320
I 2015-05-26 23:13:14 theanets.trainer:168 RmsProp 102 loss=1783.133057 err=1079.567017
I 2015-05-26 23:13:52 theanets.trainer:168 RmsProp 103 loss=1788.829590 err=1084.050171
I 2015-05-26 23:14:32 theanets.trainer:168 RmsProp 104 loss=1827.045654 err=1119.441772
I 2015-05-26 23:15:09 theanets.trainer:168 RmsProp 105 loss=1822.724976 err=1111.267334
I 2015-05-26 23:15:48 theanets.trainer:168 RmsProp 106 loss=1770.313843 err=1058.948486
I 2015-05-26 23:16:26 theanets.trainer:168 RmsProp 107 loss=1786.880737 err=1076.119385
I 2015-05-26 23:17:05 theanets.trainer:168 RmsProp 108 loss=1753.543457 err=1042.034912
I 2015-05-26 23:17:42 theanets.trainer:168 RmsProp 109 loss=1747.380493 err=1037.683594
I 2015-05-26 23:18:20 theanets.trainer:168 RmsProp 110 loss=1768.531494 err=1056.251953
I 2015-05-26 23:18:21 theanets.trainer:168 validation 11 loss=2781.563721 err=2068.600342
I 2015-05-26 23:18:57 theanets.trainer:168 RmsProp 111 loss=1743.185547 err=1030.732544
I 2015-05-26 23:19:34 theanets.trainer:168 RmsProp 112 loss=1743.479980 err=1029.998047
I 2015-05-26 23:20:11 theanets.trainer:168 RmsProp 113 loss=1679.107300 err=965.427429
I 2015-05-26 23:20:48 theanets.trainer:168 RmsProp 114 loss=1651.130249 err=941.440186
I 2015-05-26 23:21:26 theanets.trainer:168 RmsProp 115 loss=1651.617554 err=944.047424
I 2015-05-26 23:22:05 theanets.trainer:168 RmsProp 116 loss=1672.320923 err=964.497131
I 2015-05-26 23:22:42 theanets.trainer:168 RmsProp 117 loss=1666.545654 err=957.456299
I 2015-05-26 23:23:21 theanets.trainer:168 RmsProp 118 loss=1725.591431 err=1014.207397
I 2015-05-26 23:23:59 theanets.trainer:168 RmsProp 119 loss=1784.813110 err=1065.589233
I 2015-05-26 23:24:38 theanets.trainer:168 RmsProp 120 loss=1798.820923 err=1075.128296
I 2015-05-26 23:24:38 theanets.trainer:168 validation 12 loss=2610.571777 err=1885.885620 *
I 2015-05-26 23:25:16 theanets.trainer:168 RmsProp 121 loss=1689.754639 err=967.415161
I 2015-05-26 23:25:53 theanets.trainer:168 RmsProp 122 loss=1663.735229 err=946.650452
I 2015-05-26 23:26:31 theanets.trainer:168 RmsProp 123 loss=1643.501953 err=927.832092
I 2015-05-26 23:27:09 theanets.trainer:168 RmsProp 124 loss=1656.701782 err=940.973938
I 2015-05-26 23:27:46 theanets.trainer:168 RmsProp 125 loss=1650.310669 err=933.604187
I 2015-05-26 23:28:24 theanets.trainer:168 RmsProp 126 loss=1663.120239 err=945.644958
I 2015-05-26 23:29:03 theanets.trainer:168 RmsProp 127 loss=1701.989014 err=981.449463
I 2015-05-26 23:29:42 theanets.trainer:168 RmsProp 128 loss=1667.506714 err=945.945251
I 2015-05-26 23:30:20 theanets.trainer:168 RmsProp 129 loss=1646.093628 err=925.822021
I 2015-05-26 23:30:58 theanets.trainer:168 RmsProp 130 loss=1639.031738 err=918.169922
I 2015-05-26 23:30:59 theanets.trainer:168 validation 13 loss=2631.837891 err=1911.485229
I 2015-05-26 23:31:36 theanets.trainer:168 RmsProp 131 loss=1611.023193 err=892.433472
I 2015-05-26 23:32:13 theanets.trainer:168 RmsProp 132 loss=1654.066650 err=935.586182
I 2015-05-26 23:32:49 theanets.trainer:168 RmsProp 133 loss=1659.020142 err=936.131470
I 2015-05-26 23:33:25 theanets.trainer:168 RmsProp 134 loss=1626.801514 err=905.397339
I 2015-05-26 23:34:03 theanets.trainer:168 RmsProp 135 loss=1590.792603 err=871.683838
I 2015-05-26 23:34:42 theanets.trainer:168 RmsProp 136 loss=1621.312622 err=901.971008
I 2015-05-26 23:35:19 theanets.trainer:168 RmsProp 137 loss=1618.646362 err=897.133118
I 2015-05-26 23:35:56 theanets.trainer:168 RmsProp 138 loss=1609.396240 err=886.651672
I 2015-05-26 23:36:33 theanets.trainer:168 RmsProp 139 loss=1598.744995 err=876.547180
I 2015-05-26 23:37:12 theanets.trainer:168 RmsProp 140 loss=1625.599487 err=902.448914
I 2015-05-26 23:37:13 theanets.trainer:168 validation 14 loss=2671.817383 err=1947.552368
I 2015-05-26 23:37:51 theanets.trainer:168 RmsProp 141 loss=1598.186890 err=875.051086
I 2015-05-26 23:38:30 theanets.trainer:168 RmsProp 142 loss=1597.705444 err=876.109192
I 2015-05-26 23:39:08 theanets.trainer:168 RmsProp 143 loss=1631.452515 err=905.461914
I 2015-05-26 23:39:46 theanets.trainer:168 RmsProp 144 loss=1674.406860 err=945.452332
I 2015-05-26 23:40:24 theanets.trainer:168 RmsProp 145 loss=1644.675903 err=913.816528
I 2015-05-26 23:41:03 theanets.trainer:168 RmsProp 146 loss=1645.641846 err=914.262939
I 2015-05-26 23:41:42 theanets.trainer:168 RmsProp 147 loss=1597.601440 err=867.607056
I 2015-05-26 23:42:21 theanets.trainer:168 RmsProp 148 loss=1578.540649 err=851.254639
I 2015-05-26 23:43:00 theanets.trainer:168 RmsProp 149 loss=1584.626099 err=857.130676
I 2015-05-26 23:43:38 theanets.trainer:168 RmsProp 150 loss=1566.148438 err=839.221375
I 2015-05-26 23:43:39 theanets.trainer:168 validation 15 loss=2441.134033 err=1714.896484 *
I 2015-05-26 23:44:16 theanets.trainer:168 RmsProp 151 loss=1559.810059 err=833.614502
I 2015-05-26 23:44:54 theanets.trainer:168 RmsProp 152 loss=1552.372803 err=826.818726
I 2015-05-26 23:45:33 theanets.trainer:168 RmsProp 153 loss=1542.023560 err=816.675842
I 2015-05-26 23:46:11 theanets.trainer:168 RmsProp 154 loss=1581.345459 err=854.338928
I 2015-05-26 23:46:48 theanets.trainer:168 RmsProp 155 loss=1686.924316 err=954.179260
I 2015-05-26 23:47:25 theanets.trainer:168 RmsProp 156 loss=1721.222412 err=978.827576
I 2015-05-26 23:48:02 theanets.trainer:168 RmsProp 157 loss=1669.538574 err=928.606445
I 2015-05-26 23:48:39 theanets.trainer:168 RmsProp 158 loss=1616.700684 err=877.639221
I 2015-05-26 23:49:16 theanets.trainer:168 RmsProp 159 loss=1590.990112 err=853.506226
I 2015-05-26 23:49:55 theanets.trainer:168 RmsProp 160 loss=1586.060913 err=849.032166
I 2015-05-26 23:49:56 theanets.trainer:168 validation 16 loss=2480.872559 err=1743.758423
I 2015-05-26 23:50:32 theanets.trainer:168 RmsProp 161 loss=1593.531738 err=855.830627
I 2015-05-26 23:51:07 theanets.trainer:168 RmsProp 162 loss=1588.889893 err=850.593384
I 2015-05-26 23:51:41 theanets.trainer:168 RmsProp 163 loss=1588.911377 err=851.149353
I 2015-05-26 23:52:15 theanets.trainer:168 RmsProp 164 loss=1583.903198 err=847.022827
I 2015-05-26 23:52:52 theanets.trainer:168 RmsProp 165 loss=1576.613647 err=840.503784
I 2015-05-26 23:53:28 theanets.trainer:168 RmsProp 166 loss=1793.899170 err=1047.365479
I 2015-05-26 23:54:05 theanets.trainer:168 RmsProp 167 loss=1703.757446 err=948.416992
I 2015-05-26 23:54:43 theanets.trainer:168 RmsProp 168 loss=1600.659912 err=853.026306
I 2015-05-26 23:55:21 theanets.trainer:168 RmsProp 169 loss=1564.241699 err=822.275574
I 2015-05-26 23:55:58 theanets.trainer:168 RmsProp 170 loss=1662.860107 err=919.446716
I 2015-05-26 23:55:59 theanets.trainer:168 validation 17 loss=2582.616211 err=1835.101196
I 2015-05-26 23:56:36 theanets.trainer:168 RmsProp 171 loss=1721.070923 err=971.259888
I 2015-05-26 23:57:12 theanets.trainer:168 RmsProp 172 loss=1715.783447 err=961.812317
I 2015-05-26 23:57:48 theanets.trainer:168 RmsProp 173 loss=1779.830688 err=1024.317993
I 2015-05-26 23:58:23 theanets.trainer:168 RmsProp 174 loss=1709.455811 err=950.983276
I 2015-05-26 23:59:00 theanets.trainer:168 RmsProp 175 loss=1615.801392 err=862.349060
I 2015-05-26 23:59:37 theanets.trainer:168 RmsProp 176 loss=1725.718750 err=970.478455
I 2015-05-27 00:00:15 theanets.trainer:168 RmsProp 177 loss=1774.749512 err=1008.316833
I 2015-05-27 00:00:53 theanets.trainer:168 RmsProp 178 loss=1660.032349 err=896.239014
I 2015-05-27 00:01:30 theanets.trainer:168 RmsProp 179 loss=1608.240112 err=849.837219
I 2015-05-27 00:02:08 theanets.trainer:168 RmsProp 180 loss=1634.196411 err=877.629272
I 2015-05-27 00:02:09 theanets.trainer:168 validation 18 loss=2872.579346 err=2112.706787
I 2015-05-27 00:02:45 theanets.trainer:168 RmsProp 181 loss=1708.895264 err=946.367615
I 2015-05-27 00:03:22 theanets.trainer:168 RmsProp 182 loss=1634.525024 err=871.981628
I 2015-05-27 00:03:59 theanets.trainer:168 RmsProp 183 loss=1636.656128 err=873.896240
I 2015-05-27 00:04:36 theanets.trainer:168 RmsProp 184 loss=1625.814697 err=862.582031
I 2015-05-27 00:05:13 theanets.trainer:168 RmsProp 185 loss=1633.734497 err=870.110046
I 2015-05-27 00:05:50 theanets.trainer:168 RmsProp 186 loss=1620.674438 err=856.648376
I 2015-05-27 00:06:27 theanets.trainer:168 RmsProp 187 loss=1604.458618 err=841.738831
I 2015-05-27 00:07:04 theanets.trainer:168 RmsProp 188 loss=1629.781494 err=866.159729
I 2015-05-27 00:07:41 theanets.trainer:168 RmsProp 189 loss=1599.949829 err=834.813904
I 2015-05-27 00:08:17 theanets.trainer:168 RmsProp 190 loss=1712.153198 err=944.410156
I 2015-05-27 00:08:18 theanets.trainer:168 validation 19 loss=2630.320557 err=1857.735962
I 2015-05-27 00:08:54 theanets.trainer:168 RmsProp 191 loss=1765.574341 err=990.686157
I 2015-05-27 00:09:31 theanets.trainer:168 RmsProp 192 loss=1784.674927 err=1003.309326
I 2015-05-27 00:10:08 theanets.trainer:168 RmsProp 193 loss=1658.912476 err=877.022156
I 2015-05-27 00:10:44 theanets.trainer:168 RmsProp 194 loss=1623.911255 err=846.519409
I 2015-05-27 00:11:21 theanets.trainer:168 RmsProp 195 loss=1626.695435 err=851.227539
I 2015-05-27 00:11:56 theanets.trainer:168 RmsProp 196 loss=1609.560669 err=834.588623
I 2015-05-27 00:12:29 theanets.trainer:168 RmsProp 197 loss=1576.257935 err=803.043579
I 2015-05-27 00:13:04 theanets.trainer:168 RmsProp 198 loss=1561.962036 err=789.710022
I 2015-05-27 00:13:38 theanets.trainer:168 RmsProp 199 loss=1632.802124 err=860.669678
I 2015-05-27 00:14:12 theanets.trainer:168 RmsProp 200 loss=1709.839233 err=929.432800
I 2015-05-27 00:14:13 theanets.trainer:168 validation 20 loss=2604.305420 err=1823.249390
I 2015-05-27 00:14:13 theanets.trainer:252 patience elapsed!
I 2015-05-27 00:14:13 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 00:14:13 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 00:14:13 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 00:14:13 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 00:14:13 theanets.main:89 --batch_size = 1024
I 2015-05-27 00:14:13 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 00:14:13 theanets.main:89 --hidden_l1 = None
I 2015-05-27 00:14:13 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 00:14:13 theanets.main:89 --train_batches = 10
I 2015-05-27 00:14:13 theanets.main:89 --valid_batches = 2
I 2015-05-27 00:14:13 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 00:14:13 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 00:14:13 theanets.trainer:134 compiling evaluation function
I 2015-05-27 00:14:22 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 00:16:00 theanets.trainer:168 validation 0 loss=2423.118408 err=1696.880859 *
I 2015-05-27 00:16:10 theanets.trainer:168 RmsProp 1 loss=1320.799438 err=597.813843
I 2015-05-27 00:16:21 theanets.trainer:168 RmsProp 2 loss=1107.549683 err=387.119049
I 2015-05-27 00:16:31 theanets.trainer:168 RmsProp 3 loss=990.075317 err=271.645355
I 2015-05-27 00:16:41 theanets.trainer:168 RmsProp 4 loss=924.671204 err=208.307175
I 2015-05-27 00:16:52 theanets.trainer:168 RmsProp 5 loss=878.102844 err=163.971054
I 2015-05-27 00:17:02 theanets.trainer:168 RmsProp 6 loss=840.321289 err=128.753677
I 2015-05-27 00:17:12 theanets.trainer:168 RmsProp 7 loss=814.279724 err=105.741577
I 2015-05-27 00:17:23 theanets.trainer:168 RmsProp 8 loss=792.132812 err=87.082275
I 2015-05-27 00:17:33 theanets.trainer:168 RmsProp 9 loss=775.171082 err=74.029297
I 2015-05-27 00:17:44 theanets.trainer:168 RmsProp 10 loss=759.806763 err=62.777607
I 2015-05-27 00:17:44 theanets.trainer:168 validation 1 loss=1569.195435 err=874.461365 *
I 2015-05-27 00:17:55 theanets.trainer:168 RmsProp 11 loss=748.869019 err=56.024097
I 2015-05-27 00:18:05 theanets.trainer:168 RmsProp 12 loss=736.777588 err=48.284008
I 2015-05-27 00:18:16 theanets.trainer:168 RmsProp 13 loss=728.498718 err=44.700508
I 2015-05-27 00:18:27 theanets.trainer:168 RmsProp 14 loss=719.910767 err=40.842201
I 2015-05-27 00:18:37 theanets.trainer:168 RmsProp 15 loss=711.373657 err=36.946335
I 2015-05-27 00:18:47 theanets.trainer:168 RmsProp 16 loss=705.288696 err=35.534206
I 2015-05-27 00:18:57 theanets.trainer:168 RmsProp 17 loss=697.025879 err=31.876770
I 2015-05-27 00:19:07 theanets.trainer:168 RmsProp 18 loss=690.677856 err=30.001904
I 2015-05-27 00:19:18 theanets.trainer:168 RmsProp 19 loss=684.530029 err=28.271225
I 2015-05-27 00:19:29 theanets.trainer:168 RmsProp 20 loss=678.856384 err=27.001078
I 2015-05-27 00:19:29 theanets.trainer:168 validation 2 loss=1467.750977 err=818.294434 *
I 2015-05-27 00:19:40 theanets.trainer:168 RmsProp 21 loss=672.675415 err=25.171341
I 2015-05-27 00:19:50 theanets.trainer:168 RmsProp 22 loss=667.905457 err=24.744267
I 2015-05-27 00:20:00 theanets.trainer:168 RmsProp 23 loss=662.407410 err=23.404512
I 2015-05-27 00:20:11 theanets.trainer:168 RmsProp 24 loss=657.121216 err=22.183575
I 2015-05-27 00:20:21 theanets.trainer:168 RmsProp 25 loss=652.478577 err=21.598537
I 2015-05-27 00:20:32 theanets.trainer:168 RmsProp 26 loss=647.244446 err=20.389652
I 2015-05-27 00:20:43 theanets.trainer:168 RmsProp 27 loss=643.042908 err=20.226885
I 2015-05-27 00:20:53 theanets.trainer:168 RmsProp 28 loss=638.007324 err=19.117506
I 2015-05-27 00:21:04 theanets.trainer:168 RmsProp 29 loss=633.544556 err=18.501591
I 2015-05-27 00:21:15 theanets.trainer:168 RmsProp 30 loss=629.046326 err=17.841133
I 2015-05-27 00:21:15 theanets.trainer:168 validation 3 loss=1409.695801 err=800.560059 *
I 2015-05-27 00:21:25 theanets.trainer:168 RmsProp 31 loss=624.470337 err=17.032368
I 2015-05-27 00:21:36 theanets.trainer:168 RmsProp 32 loss=620.415405 err=16.777901
I 2015-05-27 00:21:47 theanets.trainer:168 RmsProp 33 loss=616.112122 err=16.264271
I 2015-05-27 00:21:57 theanets.trainer:168 RmsProp 34 loss=612.277710 err=16.081650
I 2015-05-27 00:22:08 theanets.trainer:168 RmsProp 35 loss=607.700317 err=15.069814
I 2015-05-27 00:22:19 theanets.trainer:168 RmsProp 36 loss=604.726318 err=15.660907
I 2015-05-27 00:22:29 theanets.trainer:168 RmsProp 37 loss=600.219604 err=14.626132
I 2015-05-27 00:22:40 theanets.trainer:168 RmsProp 38 loss=596.209351 err=13.945084
I 2015-05-27 00:22:51 theanets.trainer:168 RmsProp 39 loss=593.310974 err=14.478589
I 2015-05-27 00:23:01 theanets.trainer:168 RmsProp 40 loss=590.466370 err=15.037252
I 2015-05-27 00:23:02 theanets.trainer:168 validation 4 loss=1355.141846 err=781.447998 *
I 2015-05-27 00:23:12 theanets.trainer:168 RmsProp 41 loss=586.006348 err=13.663119
I 2015-05-27 00:23:23 theanets.trainer:168 RmsProp 42 loss=582.059204 err=12.706322
I 2015-05-27 00:23:33 theanets.trainer:168 RmsProp 43 loss=579.163147 err=12.928503
I 2015-05-27 00:23:43 theanets.trainer:168 RmsProp 44 loss=575.677368 err=12.651225
I 2015-05-27 00:23:54 theanets.trainer:168 RmsProp 45 loss=572.041748 err=12.191088
I 2015-05-27 00:24:04 theanets.trainer:168 RmsProp 46 loss=568.608582 err=11.898604
I 2015-05-27 00:24:15 theanets.trainer:168 RmsProp 47 loss=565.870178 err=12.280560
I 2015-05-27 00:24:25 theanets.trainer:168 RmsProp 48 loss=561.915588 err=11.401674
I 2015-05-27 00:24:36 theanets.trainer:168 RmsProp 49 loss=558.917114 err=11.451971
I 2015-05-27 00:24:47 theanets.trainer:168 RmsProp 50 loss=555.826477 err=11.394718
I 2015-05-27 00:24:47 theanets.trainer:168 validation 5 loss=1317.035156 err=774.268005 *
I 2015-05-27 00:24:58 theanets.trainer:168 RmsProp 51 loss=552.540405 err=11.112754
I 2015-05-27 00:25:08 theanets.trainer:168 RmsProp 52 loss=549.352234 err=10.876772
I 2015-05-27 00:25:18 theanets.trainer:168 RmsProp 53 loss=546.317566 err=10.766533
I 2015-05-27 00:25:28 theanets.trainer:168 RmsProp 54 loss=543.365784 err=10.713724
I 2015-05-27 00:25:39 theanets.trainer:168 RmsProp 55 loss=540.242004 err=10.431953
I 2015-05-27 00:25:49 theanets.trainer:168 RmsProp 56 loss=537.109741 err=10.088419
I 2015-05-27 00:26:00 theanets.trainer:168 RmsProp 57 loss=534.318787 err=10.075209
I 2015-05-27 00:26:10 theanets.trainer:168 RmsProp 58 loss=531.409546 err=9.935973
I 2015-05-27 00:26:21 theanets.trainer:168 RmsProp 59 loss=528.741089 err=10.006281
I 2015-05-27 00:26:31 theanets.trainer:168 RmsProp 60 loss=525.490784 err=9.452960
I 2015-05-27 00:26:32 theanets.trainer:168 validation 6 loss=1278.009644 err=763.444214 *
I 2015-05-27 00:26:42 theanets.trainer:168 RmsProp 61 loss=523.029236 err=9.679174
I 2015-05-27 00:26:52 theanets.trainer:168 RmsProp 62 loss=520.362000 err=9.660789
I 2015-05-27 00:27:02 theanets.trainer:168 RmsProp 63 loss=517.510010 err=9.384935
I 2015-05-27 00:27:13 theanets.trainer:168 RmsProp 64 loss=514.893677 err=9.306559
I 2015-05-27 00:27:23 theanets.trainer:168 RmsProp 65 loss=512.026489 err=8.963362
I 2015-05-27 00:27:33 theanets.trainer:168 RmsProp 66 loss=509.782532 err=9.245432
I 2015-05-27 00:27:44 theanets.trainer:168 RmsProp 67 loss=506.994629 err=8.951391
I 2015-05-27 00:27:54 theanets.trainer:168 RmsProp 68 loss=504.082947 err=8.508981
I 2015-05-27 00:28:04 theanets.trainer:168 RmsProp 69 loss=501.915863 err=8.818172
I 2015-05-27 00:28:14 theanets.trainer:168 RmsProp 70 loss=499.411926 err=8.749262
I 2015-05-27 00:28:15 theanets.trainer:168 validation 7 loss=1257.029419 err=767.679382 *
I 2015-05-27 00:28:25 theanets.trainer:168 RmsProp 71 loss=496.763336 err=8.484883
I 2015-05-27 00:28:35 theanets.trainer:168 RmsProp 72 loss=494.334381 err=8.427090
I 2015-05-27 00:28:45 theanets.trainer:168 RmsProp 73 loss=491.851074 err=8.292608
I 2015-05-27 00:28:56 theanets.trainer:168 RmsProp 74 loss=489.528870 err=8.309772
I 2015-05-27 00:29:07 theanets.trainer:168 RmsProp 75 loss=487.115875 err=8.220873
I 2015-05-27 00:29:17 theanets.trainer:168 RmsProp 76 loss=484.719238 err=8.114662
I 2015-05-27 00:29:28 theanets.trainer:168 RmsProp 77 loss=482.617371 err=8.279134
I 2015-05-27 00:29:38 theanets.trainer:168 RmsProp 78 loss=480.016418 err=7.897710
I 2015-05-27 00:29:49 theanets.trainer:168 RmsProp 79 loss=477.644592 err=7.734163
I 2015-05-27 00:29:59 theanets.trainer:168 RmsProp 80 loss=475.403229 err=7.703775
I 2015-05-27 00:30:00 theanets.trainer:168 validation 8 loss=1224.950684 err=758.465454 *
I 2015-05-27 00:30:10 theanets.trainer:168 RmsProp 81 loss=473.592865 err=8.088508
I 2015-05-27 00:30:20 theanets.trainer:168 RmsProp 82 loss=471.110535 err=7.746973
I 2015-05-27 00:30:30 theanets.trainer:168 RmsProp 83 loss=468.792664 err=7.519673
I 2015-05-27 00:30:41 theanets.trainer:168 RmsProp 84 loss=466.733978 err=7.556088
I 2015-05-27 00:30:51 theanets.trainer:168 RmsProp 85 loss=464.614349 err=7.532704
I 2015-05-27 00:31:01 theanets.trainer:168 RmsProp 86 loss=462.500061 err=7.504176
I 2015-05-27 00:31:12 theanets.trainer:168 RmsProp 87 loss=460.148529 err=7.222647
I 2015-05-27 00:31:22 theanets.trainer:168 RmsProp 88 loss=458.148285 err=7.273451
I 2015-05-27 00:31:32 theanets.trainer:168 RmsProp 89 loss=456.054535 err=7.213538
I 2015-05-27 00:31:42 theanets.trainer:168 RmsProp 90 loss=454.012604 err=7.169869
I 2015-05-27 00:31:43 theanets.trainer:168 validation 9 loss=1189.547607 err=743.789062 *
I 2015-05-27 00:31:53 theanets.trainer:168 RmsProp 91 loss=452.169128 err=7.308151
I 2015-05-27 00:32:03 theanets.trainer:168 RmsProp 92 loss=450.039368 err=7.166710
I 2015-05-27 00:32:14 theanets.trainer:168 RmsProp 93 loss=448.009094 err=7.096260
I 2015-05-27 00:32:24 theanets.trainer:168 RmsProp 94 loss=445.874023 err=6.881856
I 2015-05-27 00:32:35 theanets.trainer:168 RmsProp 95 loss=444.058411 err=6.982321
I 2015-05-27 00:32:45 theanets.trainer:168 RmsProp 96 loss=442.156433 err=6.985082
I 2015-05-27 00:32:55 theanets.trainer:168 RmsProp 97 loss=440.048645 err=6.746922
I 2015-05-27 00:33:06 theanets.trainer:168 RmsProp 98 loss=438.264954 err=6.816098
I 2015-05-27 00:33:16 theanets.trainer:168 RmsProp 99 loss=436.317688 err=6.711968
I 2015-05-27 00:33:26 theanets.trainer:168 RmsProp 100 loss=434.466797 err=6.686938
I 2015-05-27 00:33:27 theanets.trainer:168 validation 10 loss=1164.302490 err=737.518555 *
I 2015-05-27 00:33:37 theanets.trainer:168 RmsProp 101 loss=432.796814 err=6.822094
I 2015-05-27 00:33:47 theanets.trainer:168 RmsProp 102 loss=430.920715 err=6.718622
I 2015-05-27 00:33:58 theanets.trainer:168 RmsProp 103 loss=428.882660 err=6.430902
I 2015-05-27 00:34:08 theanets.trainer:168 RmsProp 104 loss=427.019196 err=6.334715
I 2015-05-27 00:34:19 theanets.trainer:168 RmsProp 105 loss=425.373474 err=6.464357
I 2015-05-27 00:34:29 theanets.trainer:168 RmsProp 106 loss=423.814514 err=6.665790
I 2015-05-27 00:34:40 theanets.trainer:168 RmsProp 107 loss=421.861176 err=6.426772
I 2015-05-27 00:34:50 theanets.trainer:168 RmsProp 108 loss=420.017639 err=6.288370
I 2015-05-27 00:35:01 theanets.trainer:168 RmsProp 109 loss=418.475525 err=6.447471
I 2015-05-27 00:35:12 theanets.trainer:168 RmsProp 110 loss=416.622314 err=6.270864
I 2015-05-27 00:35:12 theanets.trainer:168 validation 11 loss=1138.509521 err=729.075378 *
I 2015-05-27 00:35:23 theanets.trainer:168 RmsProp 111 loss=414.875580 err=6.192103
I 2015-05-27 00:35:33 theanets.trainer:168 RmsProp 112 loss=413.161804 err=6.133374
I 2015-05-27 00:35:44 theanets.trainer:168 RmsProp 113 loss=411.734711 err=6.367949
I 2015-05-27 00:35:54 theanets.trainer:168 RmsProp 114 loss=409.864441 err=6.134169
I 2015-05-27 00:36:05 theanets.trainer:168 RmsProp 115 loss=408.202362 err=6.079548
I 2015-05-27 00:36:15 theanets.trainer:168 RmsProp 116 loss=406.478302 err=5.954441
I 2015-05-27 00:36:25 theanets.trainer:168 RmsProp 117 loss=405.197083 err=6.256337
I 2015-05-27 00:36:36 theanets.trainer:168 RmsProp 118 loss=403.678528 err=6.295224
I 2015-05-27 00:36:46 theanets.trainer:168 RmsProp 119 loss=401.910828 err=6.051380
I 2015-05-27 00:36:57 theanets.trainer:168 RmsProp 120 loss=400.423462 err=6.086928
I 2015-05-27 00:36:57 theanets.trainer:168 validation 12 loss=1125.045654 err=731.536743 *
I 2015-05-27 00:37:08 theanets.trainer:168 RmsProp 121 loss=398.592773 err=5.752370
I 2015-05-27 00:37:18 theanets.trainer:168 RmsProp 122 loss=397.473846 err=6.133115
I 2015-05-27 00:37:28 theanets.trainer:168 RmsProp 123 loss=395.628357 err=5.793131
I 2015-05-27 00:37:39 theanets.trainer:168 RmsProp 124 loss=394.094696 err=5.748361
I 2015-05-27 00:37:50 theanets.trainer:168 RmsProp 125 loss=392.704407 err=5.846432
I 2015-05-27 00:38:00 theanets.trainer:168 RmsProp 126 loss=391.412292 err=6.016915
I 2015-05-27 00:38:10 theanets.trainer:168 RmsProp 127 loss=389.604065 err=5.657510
I 2015-05-27 00:38:21 theanets.trainer:168 RmsProp 128 loss=388.171448 err=5.675768
I 2015-05-27 00:38:31 theanets.trainer:168 RmsProp 129 loss=386.937775 err=5.881493
I 2015-05-27 00:38:41 theanets.trainer:168 RmsProp 130 loss=385.422211 err=5.787490
I 2015-05-27 00:38:42 theanets.trainer:168 validation 13 loss=1101.470215 err=722.610229 *
I 2015-05-27 00:38:52 theanets.trainer:168 RmsProp 131 loss=383.824310 err=5.591796
I 2015-05-27 00:39:02 theanets.trainer:168 RmsProp 132 loss=382.553284 err=5.720930
I 2015-05-27 00:39:12 theanets.trainer:168 RmsProp 133 loss=381.085480 err=5.639550
I 2015-05-27 00:39:22 theanets.trainer:168 RmsProp 134 loss=379.550354 err=5.477260
I 2015-05-27 00:39:33 theanets.trainer:168 RmsProp 135 loss=378.310944 err=5.605723
I 2015-05-27 00:39:43 theanets.trainer:168 RmsProp 136 loss=376.892761 err=5.541409
I 2015-05-27 00:39:54 theanets.trainer:168 RmsProp 137 loss=375.579865 err=5.578309
I 2015-05-27 00:40:04 theanets.trainer:168 RmsProp 138 loss=374.062439 err=5.392465
I 2015-05-27 00:40:14 theanets.trainer:168 RmsProp 139 loss=372.938141 err=5.589109
I 2015-05-27 00:40:24 theanets.trainer:168 RmsProp 140 loss=371.804932 err=5.761741
I 2015-05-27 00:40:25 theanets.trainer:168 validation 14 loss=1080.828613 err=715.494263 *
I 2015-05-27 00:40:35 theanets.trainer:168 RmsProp 141 loss=370.011566 err=5.256349
I 2015-05-27 00:40:46 theanets.trainer:168 RmsProp 142 loss=368.857422 err=5.400971
I 2015-05-27 00:40:56 theanets.trainer:168 RmsProp 143 loss=367.365814 err=5.203953
I 2015-05-27 00:41:07 theanets.trainer:168 RmsProp 144 loss=366.226715 err=5.370452
I 2015-05-27 00:41:17 theanets.trainer:168 RmsProp 145 loss=365.168060 err=5.587351
I 2015-05-27 00:41:27 theanets.trainer:168 RmsProp 146 loss=363.536316 err=5.215880
I 2015-05-27 00:41:37 theanets.trainer:168 RmsProp 147 loss=362.353027 err=5.288104
I 2015-05-27 00:41:48 theanets.trainer:168 RmsProp 148 loss=361.117767 err=5.299804
I 2015-05-27 00:41:58 theanets.trainer:168 RmsProp 149 loss=359.935944 err=5.360463
I 2015-05-27 00:42:08 theanets.trainer:168 RmsProp 150 loss=358.760986 err=5.406709
I 2015-05-27 00:42:09 theanets.trainer:168 validation 15 loss=1069.092285 err=716.395874 *
I 2015-05-27 00:42:19 theanets.trainer:168 RmsProp 151 loss=357.571472 err=5.421275
I 2015-05-27 00:42:29 theanets.trainer:168 RmsProp 152 loss=356.054718 err=5.086627
I 2015-05-27 00:42:40 theanets.trainer:168 RmsProp 153 loss=355.201019 err=5.409673
I 2015-05-27 00:42:50 theanets.trainer:168 RmsProp 154 loss=353.931061 err=5.306911
I 2015-05-27 00:43:01 theanets.trainer:168 RmsProp 155 loss=352.569458 err=5.108165
I 2015-05-27 00:43:11 theanets.trainer:168 RmsProp 156 loss=351.357300 err=5.064837
I 2015-05-27 00:43:21 theanets.trainer:168 RmsProp 157 loss=350.264557 err=5.150251
I 2015-05-27 00:43:32 theanets.trainer:168 RmsProp 158 loss=349.086853 err=5.138700
I 2015-05-27 00:43:42 theanets.trainer:168 RmsProp 159 loss=347.833771 err=5.033973
I 2015-05-27 00:43:52 theanets.trainer:168 RmsProp 160 loss=346.541718 err=4.877820
I 2015-05-27 00:43:53 theanets.trainer:168 validation 16 loss=1047.865845 err=706.833984 *
I 2015-05-27 00:44:03 theanets.trainer:168 RmsProp 161 loss=345.950867 err=5.423713
I 2015-05-27 00:44:14 theanets.trainer:168 RmsProp 162 loss=344.648529 err=5.239712
I 2015-05-27 00:44:24 theanets.trainer:168 RmsProp 163 loss=343.152802 err=4.849614
I 2015-05-27 00:44:35 theanets.trainer:168 RmsProp 164 loss=342.186066 err=4.993495
I 2015-05-27 00:44:45 theanets.trainer:168 RmsProp 165 loss=341.052307 err=4.973445
I 2015-05-27 00:44:56 theanets.trainer:168 RmsProp 166 loss=340.025879 err=5.050760
I 2015-05-27 00:45:06 theanets.trainer:168 RmsProp 167 loss=338.881042 err=4.997643
I 2015-05-27 00:45:16 theanets.trainer:168 RmsProp 168 loss=337.383240 err=4.584499
I 2015-05-27 00:45:27 theanets.trainer:168 RmsProp 169 loss=336.614777 err=4.903032
I 2015-05-27 00:45:37 theanets.trainer:168 RmsProp 170 loss=335.558655 err=4.928216
I 2015-05-27 00:45:38 theanets.trainer:168 validation 17 loss=1038.053833 err=708.011780 *
I 2015-05-27 00:45:48 theanets.trainer:168 RmsProp 171 loss=334.634308 err=5.073182
I 2015-05-27 00:45:59 theanets.trainer:168 RmsProp 172 loss=332.959381 err=4.458116
I 2015-05-27 00:46:09 theanets.trainer:168 RmsProp 173 loss=332.504822 err=5.063470
I 2015-05-27 00:46:20 theanets.trainer:168 RmsProp 174 loss=331.420593 err=5.027127
I 2015-05-27 00:46:30 theanets.trainer:168 RmsProp 175 loss=330.130310 err=4.767764
I 2015-05-27 00:46:40 theanets.trainer:168 RmsProp 176 loss=328.965332 err=4.635658
I 2015-05-27 00:46:51 theanets.trainer:168 RmsProp 177 loss=328.196472 err=4.896830
I 2015-05-27 00:47:01 theanets.trainer:168 RmsProp 178 loss=327.138611 err=4.857875
I 2015-05-27 00:47:12 theanets.trainer:168 RmsProp 179 loss=326.074036 err=4.806451
I 2015-05-27 00:47:22 theanets.trainer:168 RmsProp 180 loss=324.853333 err=4.587512
I 2015-05-27 00:47:23 theanets.trainer:168 validation 18 loss=1015.270203 err=695.547668 *
I 2015-05-27 00:47:33 theanets.trainer:168 RmsProp 181 loss=324.170593 err=4.902197
I 2015-05-27 00:47:44 theanets.trainer:168 RmsProp 182 loss=322.941742 err=4.664393
I 2015-05-27 00:47:55 theanets.trainer:168 RmsProp 183 loss=321.955933 err=4.660051
I 2015-05-27 00:48:05 theanets.trainer:168 RmsProp 184 loss=320.988708 err=4.666083
I 2015-05-27 00:48:16 theanets.trainer:168 RmsProp 185 loss=320.204407 err=4.854595
I 2015-05-27 00:48:27 theanets.trainer:168 RmsProp 186 loss=319.149963 err=4.761850
I 2015-05-27 00:48:38 theanets.trainer:168 RmsProp 187 loss=317.915466 err=4.487234
I 2015-05-27 00:48:48 theanets.trainer:168 RmsProp 188 loss=317.237610 err=4.769185
I 2015-05-27 00:48:59 theanets.trainer:168 RmsProp 189 loss=316.277832 err=4.761919
I 2015-05-27 00:49:10 theanets.trainer:168 RmsProp 190 loss=315.574158 err=4.990655
I 2015-05-27 00:49:11 theanets.trainer:168 validation 19 loss=1005.472656 err=695.395386 *
I 2015-05-27 00:49:21 theanets.trainer:168 RmsProp 191 loss=313.924011 err=4.240529
I 2015-05-27 00:49:32 theanets.trainer:168 RmsProp 192 loss=313.498199 err=4.714713
I 2015-05-27 00:49:42 theanets.trainer:168 RmsProp 193 loss=312.512756 err=4.648230
I 2015-05-27 00:49:53 theanets.trainer:168 RmsProp 194 loss=311.408844 err=4.455098
I 2015-05-27 00:50:04 theanets.trainer:168 RmsProp 195 loss=310.884094 err=4.846622
I 2015-05-27 00:50:14 theanets.trainer:168 RmsProp 196 loss=309.579742 err=4.441390
I 2015-05-27 00:50:25 theanets.trainer:168 RmsProp 197 loss=308.669220 err=4.417981
I 2015-05-27 00:50:36 theanets.trainer:168 RmsProp 198 loss=308.252533 err=4.893792
I 2015-05-27 00:50:46 theanets.trainer:168 RmsProp 199 loss=307.000275 err=4.517579
I 2015-05-27 00:50:57 theanets.trainer:168 RmsProp 200 loss=306.004852 err=4.388175
I 2015-05-27 00:50:57 theanets.trainer:168 validation 20 loss=994.295044 err=693.159973 *
I 2015-05-27 00:51:08 theanets.trainer:168 RmsProp 201 loss=305.437622 err=4.690548
I 2015-05-27 00:51:18 theanets.trainer:168 RmsProp 202 loss=304.178558 err=4.297712
I 2015-05-27 00:51:29 theanets.trainer:168 RmsProp 203 loss=303.610077 err=4.599372
I 2015-05-27 00:51:39 theanets.trainer:168 RmsProp 204 loss=302.751312 err=4.609521
I 2015-05-27 00:51:50 theanets.trainer:168 RmsProp 205 loss=301.113098 err=3.829674
I 2015-05-27 00:52:00 theanets.trainer:168 RmsProp 206 loss=301.865509 err=5.428491
I 2015-05-27 00:52:11 theanets.trainer:168 RmsProp 207 loss=300.118652 err=4.511345
I 2015-05-27 00:52:21 theanets.trainer:168 RmsProp 208 loss=299.075256 err=4.271242
I 2015-05-27 00:52:32 theanets.trainer:168 RmsProp 209 loss=298.450989 err=4.460296
I 2015-05-27 00:52:42 theanets.trainer:168 RmsProp 210 loss=297.497009 err=4.320117
I 2015-05-27 00:52:43 theanets.trainer:168 validation 21 loss=983.359070 err=690.623962 *
I 2015-05-27 00:52:53 theanets.trainer:168 RmsProp 211 loss=296.664459 err=4.303501
I 2015-05-27 00:53:04 theanets.trainer:168 RmsProp 212 loss=296.062561 err=4.516379
I 2015-05-27 00:53:14 theanets.trainer:168 RmsProp 213 loss=294.997040 err=4.254018
I 2015-05-27 00:53:25 theanets.trainer:168 RmsProp 214 loss=294.490753 err=4.551031
I 2015-05-27 00:53:35 theanets.trainer:168 RmsProp 215 loss=293.446960 err=4.308958
I 2015-05-27 00:53:46 theanets.trainer:168 RmsProp 216 loss=292.596130 err=4.259755
I 2015-05-27 00:53:56 theanets.trainer:168 RmsProp 217 loss=291.963928 err=4.428162
I 2015-05-27 00:54:07 theanets.trainer:168 RmsProp 218 loss=291.121521 err=4.380233
I 2015-05-27 00:54:17 theanets.trainer:168 RmsProp 219 loss=290.228394 err=4.265406
I 2015-05-27 00:54:28 theanets.trainer:168 RmsProp 220 loss=289.515869 err=4.319535
I 2015-05-27 00:54:28 theanets.trainer:168 validation 22 loss=965.045288 err=680.274109 *
I 2015-05-27 00:54:39 theanets.trainer:168 RmsProp 221 loss=288.920929 err=4.498985
I 2015-05-27 00:54:49 theanets.trainer:168 RmsProp 222 loss=287.918640 err=4.266278
I 2015-05-27 00:55:00 theanets.trainer:168 RmsProp 223 loss=287.354767 err=4.457477
I 2015-05-27 00:55:10 theanets.trainer:168 RmsProp 224 loss=286.314972 err=4.154494
I 2015-05-27 00:55:20 theanets.trainer:168 RmsProp 225 loss=285.633301 err=4.218432
I 2015-05-27 00:55:31 theanets.trainer:168 RmsProp 226 loss=284.856110 err=4.193392
I 2015-05-27 00:55:42 theanets.trainer:168 RmsProp 227 loss=283.998749 err=4.086442
I 2015-05-27 00:55:52 theanets.trainer:168 RmsProp 228 loss=283.430725 err=4.273732
I 2015-05-27 00:56:02 theanets.trainer:168 RmsProp 229 loss=282.523407 err=4.114955
I 2015-05-27 00:56:13 theanets.trainer:168 RmsProp 230 loss=281.975891 err=4.301754
I 2015-05-27 00:56:13 theanets.trainer:168 validation 23 loss=955.588013 err=678.319641 *
I 2015-05-27 00:56:24 theanets.trainer:168 RmsProp 231 loss=280.903503 err=3.967365
I 2015-05-27 00:56:35 theanets.trainer:168 RmsProp 232 loss=280.813995 err=4.607697
I 2015-05-27 00:56:45 theanets.trainer:168 RmsProp 233 loss=279.464050 err=3.977939
I 2015-05-27 00:56:55 theanets.trainer:168 RmsProp 234 loss=279.018372 err=4.236491
I 2015-05-27 00:57:06 theanets.trainer:168 RmsProp 235 loss=278.191956 err=4.113568
I 2015-05-27 00:57:16 theanets.trainer:168 RmsProp 236 loss=277.529022 err=4.154133
I 2015-05-27 00:57:27 theanets.trainer:168 RmsProp 237 loss=276.774994 err=4.110154
I 2015-05-27 00:57:37 theanets.trainer:168 RmsProp 238 loss=275.972473 err=4.011144
I 2015-05-27 00:57:48 theanets.trainer:168 RmsProp 239 loss=275.391357 err=4.131040
I 2015-05-27 00:57:58 theanets.trainer:168 RmsProp 240 loss=274.649536 err=4.092275
I 2015-05-27 00:57:59 theanets.trainer:168 validation 24 loss=942.681641 err=672.503418 *
I 2015-05-27 00:58:09 theanets.trainer:168 RmsProp 241 loss=274.055481 err=4.194409
I 2015-05-27 00:58:20 theanets.trainer:168 RmsProp 242 loss=272.976257 err=3.803446
I 2015-05-27 00:58:30 theanets.trainer:168 RmsProp 243 loss=272.669983 err=4.183746
I 2015-05-27 00:58:40 theanets.trainer:168 RmsProp 244 loss=271.797607 err=4.001596
I 2015-05-27 00:58:51 theanets.trainer:168 RmsProp 245 loss=271.241760 err=4.125812
I 2015-05-27 00:59:01 theanets.trainer:168 RmsProp 246 loss=270.635590 err=4.191047
I 2015-05-27 00:59:12 theanets.trainer:168 RmsProp 247 loss=269.836212 err=4.052504
I 2015-05-27 00:59:22 theanets.trainer:168 RmsProp 248 loss=269.142456 err=4.016571
I 2015-05-27 00:59:33 theanets.trainer:168 RmsProp 249 loss=268.551422 err=4.084900
I 2015-05-27 00:59:43 theanets.trainer:168 RmsProp 250 loss=267.946014 err=4.130771
I 2015-05-27 00:59:44 theanets.trainer:168 validation 25 loss=931.997437 err=668.543396 *
I 2015-05-27 00:59:54 theanets.trainer:168 RmsProp 251 loss=267.228943 err=4.064749
I 2015-05-27 01:00:04 theanets.trainer:168 RmsProp 252 loss=266.409332 err=3.890098
I 2015-05-27 01:00:14 theanets.trainer:168 RmsProp 253 loss=265.646423 err=3.774409
I 2015-05-27 01:00:25 theanets.trainer:168 RmsProp 254 loss=265.634613 err=4.402039
I 2015-05-27 01:00:35 theanets.trainer:168 RmsProp 255 loss=264.668976 err=4.059582
I 2015-05-27 01:00:45 theanets.trainer:168 RmsProp 256 loss=264.173126 err=4.176367
I 2015-05-27 01:00:55 theanets.trainer:168 RmsProp 257 loss=263.229218 err=3.840529
I 2015-05-27 01:01:05 theanets.trainer:168 RmsProp 258 loss=262.946747 err=4.168504
I 2015-05-27 01:01:15 theanets.trainer:168 RmsProp 259 loss=262.189850 err=4.024350
I 2015-05-27 01:01:26 theanets.trainer:168 RmsProp 260 loss=261.429016 err=3.880047
I 2015-05-27 01:01:26 theanets.trainer:168 validation 26 loss=922.937195 err=665.729675 *
I 2015-05-27 01:01:36 theanets.trainer:168 RmsProp 261 loss=260.883026 err=3.949843
I 2015-05-27 01:01:46 theanets.trainer:168 RmsProp 262 loss=260.097107 err=3.779501
I 2015-05-27 01:01:57 theanets.trainer:168 RmsProp 263 loss=259.752991 err=4.057801
I 2015-05-27 01:02:07 theanets.trainer:168 RmsProp 264 loss=258.943512 err=3.857113
I 2015-05-27 01:02:17 theanets.trainer:168 RmsProp 265 loss=258.432800 err=3.951765
I 2015-05-27 01:02:28 theanets.trainer:168 RmsProp 266 loss=257.797302 err=3.915826
I 2015-05-27 01:02:38 theanets.trainer:168 RmsProp 267 loss=256.901733 err=3.611723
I 2015-05-27 01:02:49 theanets.trainer:168 RmsProp 268 loss=256.780212 err=4.083263
I 2015-05-27 01:02:59 theanets.trainer:168 RmsProp 269 loss=255.947876 err=3.846915
I 2015-05-27 01:03:10 theanets.trainer:168 RmsProp 270 loss=255.374298 err=3.862509
I 2015-05-27 01:03:10 theanets.trainer:168 validation 27 loss=919.915894 err=668.715942 *
I 2015-05-27 01:03:20 theanets.trainer:168 RmsProp 271 loss=254.714813 err=3.784391
I 2015-05-27 01:03:31 theanets.trainer:168 RmsProp 272 loss=254.262741 err=3.920930
I 2015-05-27 01:03:41 theanets.trainer:168 RmsProp 273 loss=253.675873 err=3.921039
I 2015-05-27 01:03:52 theanets.trainer:168 RmsProp 274 loss=253.060226 err=3.884650
I 2015-05-27 01:04:02 theanets.trainer:168 RmsProp 275 loss=252.698486 err=4.092772
I 2015-05-27 01:04:13 theanets.trainer:168 RmsProp 276 loss=251.672150 err=3.627403
I 2015-05-27 01:04:23 theanets.trainer:168 RmsProp 277 loss=251.290329 err=3.802039
I 2015-05-27 01:04:34 theanets.trainer:168 RmsProp 278 loss=250.659027 err=3.730729
I 2015-05-27 01:04:44 theanets.trainer:168 RmsProp 279 loss=250.547806 err=4.179698
I 2015-05-27 01:04:55 theanets.trainer:168 RmsProp 280 loss=249.775116 err=3.951553
I 2015-05-27 01:04:56 theanets.trainer:168 validation 28 loss=910.978821 err=665.450378 *
I 2015-05-27 01:05:06 theanets.trainer:168 RmsProp 281 loss=249.237579 err=3.949198
I 2015-05-27 01:05:17 theanets.trainer:168 RmsProp 282 loss=248.511063 err=3.760775
I 2015-05-27 01:05:28 theanets.trainer:168 RmsProp 283 loss=247.963181 err=3.756097
I 2015-05-27 01:05:39 theanets.trainer:168 RmsProp 284 loss=247.658813 err=3.998085
I 2015-05-27 01:05:49 theanets.trainer:168 RmsProp 285 loss=246.665009 err=3.544953
I 2015-05-27 01:06:00 theanets.trainer:168 RmsProp 286 loss=246.321686 err=3.744188
I 2015-05-27 01:06:10 theanets.trainer:168 RmsProp 287 loss=245.908356 err=3.876174
I 2015-05-27 01:06:21 theanets.trainer:168 RmsProp 288 loss=245.253998 err=3.762996
I 2015-05-27 01:06:31 theanets.trainer:168 RmsProp 289 loss=244.511841 err=3.549757
I 2015-05-27 01:06:42 theanets.trainer:168 RmsProp 290 loss=244.282791 err=3.849965
I 2015-05-27 01:06:42 theanets.trainer:168 validation 29 loss=895.721680 err=655.576355 *
I 2015-05-27 01:06:53 theanets.trainer:168 RmsProp 291 loss=244.014694 err=4.111299
I 2015-05-27 01:07:04 theanets.trainer:168 RmsProp 292 loss=242.928192 err=3.537296
I 2015-05-27 01:07:14 theanets.trainer:168 RmsProp 293 loss=242.512772 err=3.638523
I 2015-05-27 01:07:25 theanets.trainer:168 RmsProp 294 loss=242.095657 err=3.744435
I 2015-05-27 01:07:35 theanets.trainer:168 RmsProp 295 loss=241.494415 err=3.662872
I 2015-05-27 01:07:46 theanets.trainer:168 RmsProp 296 loss=241.001999 err=3.687811
I 2015-05-27 01:07:56 theanets.trainer:168 RmsProp 297 loss=240.443146 err=3.640204
I 2015-05-27 01:08:07 theanets.trainer:168 RmsProp 298 loss=239.988068 err=3.705266
I 2015-05-27 01:08:18 theanets.trainer:168 RmsProp 299 loss=239.392242 err=3.621417
I 2015-05-27 01:08:29 theanets.trainer:168 RmsProp 300 loss=239.064377 err=3.804848
I 2015-05-27 01:08:29 theanets.trainer:168 validation 30 loss=890.135071 err=655.158264 *
I 2015-05-27 01:08:40 theanets.trainer:168 RmsProp 301 loss=238.413132 err=3.666487
I 2015-05-27 01:08:50 theanets.trainer:168 RmsProp 302 loss=237.953766 err=3.709860
I 2015-05-27 01:09:01 theanets.trainer:168 RmsProp 303 loss=237.284103 err=3.545605
I 2015-05-27 01:09:12 theanets.trainer:168 RmsProp 304 loss=237.076370 err=3.834088
I 2015-05-27 01:09:22 theanets.trainer:168 RmsProp 305 loss=236.290619 err=3.541531
I 2015-05-27 01:09:33 theanets.trainer:168 RmsProp 306 loss=235.790771 err=3.523991
I 2015-05-27 01:09:44 theanets.trainer:168 RmsProp 307 loss=235.591431 err=3.812216
I 2015-05-27 01:09:55 theanets.trainer:168 RmsProp 308 loss=235.041061 err=3.746328
I 2015-05-27 01:10:06 theanets.trainer:168 RmsProp 309 loss=234.485748 err=3.667140
I 2015-05-27 01:10:16 theanets.trainer:168 RmsProp 310 loss=233.766235 err=3.431906
I 2015-05-27 01:10:17 theanets.trainer:168 validation 31 loss=888.286499 err=658.212036 *
I 2015-05-27 01:10:27 theanets.trainer:168 RmsProp 311 loss=233.791412 err=3.934562
I 2015-05-27 01:10:38 theanets.trainer:168 RmsProp 312 loss=232.765625 err=3.394403
I 2015-05-27 01:10:49 theanets.trainer:168 RmsProp 313 loss=232.749512 err=3.858983
I 2015-05-27 01:11:00 theanets.trainer:168 RmsProp 314 loss=232.079880 err=3.663597
I 2015-05-27 01:11:11 theanets.trainer:168 RmsProp 315 loss=231.708130 err=3.752303
I 2015-05-27 01:11:22 theanets.trainer:168 RmsProp 316 loss=230.954010 err=3.453603
I 2015-05-27 01:11:33 theanets.trainer:168 RmsProp 317 loss=230.746185 err=3.711252
I 2015-05-27 01:11:43 theanets.trainer:168 RmsProp 318 loss=230.179611 err=3.610075
I 2015-05-27 01:11:54 theanets.trainer:168 RmsProp 319 loss=229.787277 err=3.675483
I 2015-05-27 01:12:05 theanets.trainer:168 RmsProp 320 loss=229.129913 err=3.477045
I 2015-05-27 01:12:05 theanets.trainer:168 validation 32 loss=873.745789 err=648.340210 *
I 2015-05-27 01:12:16 theanets.trainer:168 RmsProp 321 loss=228.889679 err=3.695594
I 2015-05-27 01:12:27 theanets.trainer:168 RmsProp 322 loss=228.474731 err=3.732126
I 2015-05-27 01:12:37 theanets.trainer:168 RmsProp 323 loss=227.723389 err=3.424157
I 2015-05-27 01:12:48 theanets.trainer:168 RmsProp 324 loss=227.195892 err=3.346120
I 2015-05-27 01:12:59 theanets.trainer:168 RmsProp 325 loss=226.968170 err=3.572427
I 2015-05-27 01:13:10 theanets.trainer:168 RmsProp 326 loss=226.590057 err=3.647748
I 2015-05-27 01:13:20 theanets.trainer:168 RmsProp 327 loss=226.255737 err=3.756173
I 2015-05-27 01:13:31 theanets.trainer:168 RmsProp 328 loss=225.625397 err=3.570437
I 2015-05-27 01:13:41 theanets.trainer:168 RmsProp 329 loss=225.194550 err=3.572539
I 2015-05-27 01:13:52 theanets.trainer:168 RmsProp 330 loss=224.742767 err=3.558704
I 2015-05-27 01:13:52 theanets.trainer:168 validation 33 loss=866.207886 err=645.265686 *
I 2015-05-27 01:14:03 theanets.trainer:168 RmsProp 331 loss=224.140656 err=3.390056
I 2015-05-27 01:14:13 theanets.trainer:168 RmsProp 332 loss=224.084930 err=3.759402
I 2015-05-27 01:14:23 theanets.trainer:168 RmsProp 333 loss=223.443817 err=3.546287
I 2015-05-27 01:14:33 theanets.trainer:168 RmsProp 334 loss=222.977295 err=3.506696
I 2015-05-27 01:14:44 theanets.trainer:168 RmsProp 335 loss=222.278885 err=3.237377
I 2015-05-27 01:14:54 theanets.trainer:168 RmsProp 336 loss=222.123856 err=3.513881
I 2015-05-27 01:15:05 theanets.trainer:168 RmsProp 337 loss=222.018951 err=3.838833
I 2015-05-27 01:15:15 theanets.trainer:168 RmsProp 338 loss=221.115143 err=3.361169
I 2015-05-27 01:15:25 theanets.trainer:168 RmsProp 339 loss=220.797272 err=3.462925
I 2015-05-27 01:15:36 theanets.trainer:168 RmsProp 340 loss=220.474243 err=3.563390
I 2015-05-27 01:15:36 theanets.trainer:168 validation 34 loss=861.561340 err=644.884399 *
I 2015-05-27 01:15:47 theanets.trainer:168 RmsProp 341 loss=219.880569 err=3.386293
I 2015-05-27 01:15:57 theanets.trainer:168 RmsProp 342 loss=219.371002 err=3.290637
I 2015-05-27 01:16:08 theanets.trainer:168 RmsProp 343 loss=219.180862 err=3.517271
I 2015-05-27 01:16:18 theanets.trainer:168 RmsProp 344 loss=218.997147 err=3.746804
I 2015-05-27 01:16:29 theanets.trainer:168 RmsProp 345 loss=218.114532 err=3.275703
I 2015-05-27 01:16:40 theanets.trainer:168 RmsProp 346 loss=217.594452 err=3.169225
I 2015-05-27 01:16:50 theanets.trainer:168 RmsProp 347 loss=217.598099 err=3.592787
I 2015-05-27 01:17:01 theanets.trainer:168 RmsProp 348 loss=216.879517 err=3.290547
I 2015-05-27 01:17:11 theanets.trainer:168 RmsProp 349 loss=216.711090 err=3.532972
I 2015-05-27 01:17:21 theanets.trainer:168 RmsProp 350 loss=216.237137 err=3.461076
I 2015-05-27 01:17:22 theanets.trainer:168 validation 35 loss=861.674988 err=649.113464
I 2015-05-27 01:17:32 theanets.trainer:168 RmsProp 351 loss=215.777466 err=3.404179
I 2015-05-27 01:17:43 theanets.trainer:168 RmsProp 352 loss=215.332275 err=3.358856
I 2015-05-27 01:17:53 theanets.trainer:168 RmsProp 353 loss=215.008469 err=3.436338
I 2015-05-27 01:18:04 theanets.trainer:168 RmsProp 354 loss=214.713226 err=3.540443
I 2015-05-27 01:18:15 theanets.trainer:168 RmsProp 355 loss=214.368683 err=3.587097
I 2015-05-27 01:18:26 theanets.trainer:168 RmsProp 356 loss=213.662140 err=3.271363
I 2015-05-27 01:18:36 theanets.trainer:168 RmsProp 357 loss=213.499588 err=3.488517
I 2015-05-27 01:18:47 theanets.trainer:168 RmsProp 358 loss=212.869537 err=3.247060
I 2015-05-27 01:18:58 theanets.trainer:168 RmsProp 359 loss=212.729691 err=3.498264
I 2015-05-27 01:19:09 theanets.trainer:168 RmsProp 360 loss=212.121292 err=3.277404
I 2015-05-27 01:19:09 theanets.trainer:168 validation 36 loss=848.814453 err=640.187805 *
I 2015-05-27 01:19:20 theanets.trainer:168 RmsProp 361 loss=211.977737 err=3.525066
I 2015-05-27 01:19:30 theanets.trainer:168 RmsProp 362 loss=211.295090 err=3.226918
I 2015-05-27 01:19:41 theanets.trainer:168 RmsProp 363 loss=211.054657 err=3.373074
I 2015-05-27 01:19:52 theanets.trainer:168 RmsProp 364 loss=210.614746 err=3.316890
I 2015-05-27 01:20:02 theanets.trainer:168 RmsProp 365 loss=210.555695 err=3.636447
I 2015-05-27 01:20:13 theanets.trainer:168 RmsProp 366 loss=210.109451 err=3.556099
I 2015-05-27 01:20:24 theanets.trainer:168 RmsProp 367 loss=209.235199 err=3.043075
I 2015-05-27 01:20:35 theanets.trainer:168 RmsProp 368 loss=209.346756 err=3.518735
I 2015-05-27 01:20:45 theanets.trainer:168 RmsProp 369 loss=208.793427 err=3.334342
I 2015-05-27 01:20:56 theanets.trainer:168 RmsProp 370 loss=208.553665 err=3.467596
I 2015-05-27 01:20:57 theanets.trainer:168 validation 37 loss=848.701294 err=643.820435 *
I 2015-05-27 01:21:07 theanets.trainer:168 RmsProp 371 loss=207.674591 err=2.961638
I 2015-05-27 01:21:17 theanets.trainer:168 RmsProp 372 loss=207.977692 err=3.634241
I 2015-05-27 01:21:28 theanets.trainer:168 RmsProp 373 loss=207.133102 err=3.161549
I 2015-05-27 01:21:38 theanets.trainer:168 RmsProp 374 loss=207.132690 err=3.519550
I 2015-05-27 01:21:49 theanets.trainer:168 RmsProp 375 loss=206.661011 err=3.410363
I 2015-05-27 01:22:00 theanets.trainer:168 RmsProp 376 loss=206.207840 err=3.317629
I 2015-05-27 01:22:10 theanets.trainer:168 RmsProp 377 loss=205.901901 err=3.372999
I 2015-05-27 01:22:21 theanets.trainer:168 RmsProp 378 loss=205.492706 err=3.320728
I 2015-05-27 01:22:32 theanets.trainer:168 RmsProp 379 loss=204.700531 err=2.891507
I 2015-05-27 01:22:42 theanets.trainer:168 RmsProp 380 loss=204.928635 err=3.478904
I 2015-05-27 01:22:43 theanets.trainer:168 validation 38 loss=842.394348 err=641.134949 *
I 2015-05-27 01:22:54 theanets.trainer:168 RmsProp 381 loss=204.498093 err=3.400257
I 2015-05-27 01:23:04 theanets.trainer:168 RmsProp 382 loss=204.149460 err=3.404581
I 2015-05-27 01:23:14 theanets.trainer:168 RmsProp 383 loss=203.845779 err=3.451677
I 2015-05-27 01:23:25 theanets.trainer:168 RmsProp 384 loss=203.335831 err=3.289804
I 2015-05-27 01:23:36 theanets.trainer:168 RmsProp 385 loss=202.993607 err=3.286460
I 2015-05-27 01:23:47 theanets.trainer:168 RmsProp 386 loss=202.746536 err=3.380255
I 2015-05-27 01:23:57 theanets.trainer:168 RmsProp 387 loss=202.603027 err=3.575623
I 2015-05-27 01:24:08 theanets.trainer:168 RmsProp 388 loss=201.684601 err=2.997057
I 2015-05-27 01:24:19 theanets.trainer:168 RmsProp 389 loss=201.775177 err=3.426064
I 2015-05-27 01:24:29 theanets.trainer:168 RmsProp 390 loss=201.520844 err=3.507919
I 2015-05-27 01:24:30 theanets.trainer:168 validation 39 loss=839.587402 err=641.752014 *
I 2015-05-27 01:24:41 theanets.trainer:168 RmsProp 391 loss=200.876602 err=3.200129
I 2015-05-27 01:24:52 theanets.trainer:168 RmsProp 392 loss=200.683380 err=3.339406
I 2015-05-27 01:25:02 theanets.trainer:168 RmsProp 393 loss=200.267456 err=3.261327
I 2015-05-27 01:25:13 theanets.trainer:168 RmsProp 394 loss=200.077606 err=3.403368
I 2015-05-27 01:25:24 theanets.trainer:168 RmsProp 395 loss=199.506439 err=3.160459
I 2015-05-27 01:25:35 theanets.trainer:168 RmsProp 396 loss=199.398148 err=3.381398
I 2015-05-27 01:25:45 theanets.trainer:168 RmsProp 397 loss=199.052917 err=3.364557
I 2015-05-27 01:25:56 theanets.trainer:168 RmsProp 398 loss=198.439377 err=3.082555
I 2015-05-27 01:26:07 theanets.trainer:168 RmsProp 399 loss=198.067459 err=3.042542
I 2015-05-27 01:26:17 theanets.trainer:168 RmsProp 400 loss=198.044952 err=3.353910
I 2015-05-27 01:26:18 theanets.trainer:168 validation 40 loss=827.777283 err=633.275452 *
I 2015-05-27 01:26:29 theanets.trainer:168 RmsProp 401 loss=197.662659 err=3.301189
I 2015-05-27 01:26:39 theanets.trainer:168 RmsProp 402 loss=197.154083 err=3.120281
I 2015-05-27 01:26:49 theanets.trainer:168 RmsProp 403 loss=196.960403 err=3.250240
I 2015-05-27 01:26:59 theanets.trainer:168 RmsProp 404 loss=196.572586 err=3.183074
I 2015-05-27 01:27:09 theanets.trainer:168 RmsProp 405 loss=196.251068 err=3.189007
I 2015-05-27 01:27:19 theanets.trainer:168 RmsProp 406 loss=196.144867 err=3.403518
I 2015-05-27 01:27:30 theanets.trainer:168 RmsProp 407 loss=195.553925 err=3.133063
I 2015-05-27 01:27:39 theanets.trainer:168 RmsProp 408 loss=195.277374 err=3.175469
I 2015-05-27 01:27:49 theanets.trainer:168 RmsProp 409 loss=195.249939 err=3.454858
I 2015-05-27 01:27:59 theanets.trainer:168 RmsProp 410 loss=194.334045 err=2.857318
I 2015-05-27 01:28:00 theanets.trainer:168 validation 41 loss=824.699646 err=633.394714 *
I 2015-05-27 01:28:10 theanets.trainer:168 RmsProp 411 loss=194.981400 err=3.812265
I 2015-05-27 01:28:19 theanets.trainer:168 RmsProp 412 loss=193.778061 err=2.922890
I 2015-05-27 01:28:29 theanets.trainer:168 RmsProp 413 loss=193.897064 err=3.348913
I 2015-05-27 01:28:40 theanets.trainer:168 RmsProp 414 loss=193.432144 err=3.193022
I 2015-05-27 01:28:50 theanets.trainer:168 RmsProp 415 loss=192.976837 err=3.046637
I 2015-05-27 01:29:01 theanets.trainer:168 RmsProp 416 loss=192.858810 err=3.237478
I 2015-05-27 01:29:12 theanets.trainer:168 RmsProp 417 loss=192.515869 err=3.198351
I 2015-05-27 01:29:22 theanets.trainer:168 RmsProp 418 loss=192.163818 err=3.148033
I 2015-05-27 01:29:33 theanets.trainer:168 RmsProp 419 loss=191.849777 err=3.142406
I 2015-05-27 01:29:43 theanets.trainer:168 RmsProp 420 loss=191.620285 err=3.219964
I 2015-05-27 01:29:44 theanets.trainer:168 validation 42 loss=822.461975 err=634.223511 *
I 2015-05-27 01:29:54 theanets.trainer:168 RmsProp 421 loss=191.183655 err=3.086221
I 2015-05-27 01:30:05 theanets.trainer:168 RmsProp 422 loss=190.971603 err=3.176479
I 2015-05-27 01:30:15 theanets.trainer:168 RmsProp 423 loss=190.670044 err=3.176308
I 2015-05-27 01:30:26 theanets.trainer:168 RmsProp 424 loss=190.388062 err=3.193343
I 2015-05-27 01:30:37 theanets.trainer:168 RmsProp 425 loss=190.037643 err=3.139822
I 2015-05-27 01:30:47 theanets.trainer:168 RmsProp 426 loss=189.936234 err=3.335813
I 2015-05-27 01:30:58 theanets.trainer:168 RmsProp 427 loss=189.532532 err=3.227860
I 2015-05-27 01:31:08 theanets.trainer:168 RmsProp 428 loss=189.146225 err=3.132474
I 2015-05-27 01:31:19 theanets.trainer:168 RmsProp 429 loss=188.809128 err=3.086630
I 2015-05-27 01:31:30 theanets.trainer:168 RmsProp 430 loss=188.484283 err=3.048001
I 2015-05-27 01:31:30 theanets.trainer:168 validation 43 loss=818.501953 err=633.224731 *
I 2015-05-27 01:31:41 theanets.trainer:168 RmsProp 431 loss=188.550751 err=3.405750
I 2015-05-27 01:31:51 theanets.trainer:168 RmsProp 432 loss=188.143158 err=3.283398
I 2015-05-27 01:32:01 theanets.trainer:168 RmsProp 433 loss=187.543365 err=2.971894
I 2015-05-27 01:32:12 theanets.trainer:168 RmsProp 434 loss=187.537689 err=3.251810
I 2015-05-27 01:32:23 theanets.trainer:168 RmsProp 435 loss=187.041245 err=3.046679
I 2015-05-27 01:32:33 theanets.trainer:168 RmsProp 436 loss=186.808990 err=3.101567
I 2015-05-27 01:32:43 theanets.trainer:168 RmsProp 437 loss=186.398056 err=2.972323
I 2015-05-27 01:32:54 theanets.trainer:168 RmsProp 438 loss=186.481110 err=3.336486
I 2015-05-27 01:33:04 theanets.trainer:168 RmsProp 439 loss=185.807419 err=2.947613
I 2015-05-27 01:33:15 theanets.trainer:168 RmsProp 440 loss=185.661667 err=3.084424
I 2015-05-27 01:33:15 theanets.trainer:168 validation 44 loss=821.620972 err=639.195740
I 2015-05-27 01:33:26 theanets.trainer:168 RmsProp 441 loss=185.627396 err=3.330186
I 2015-05-27 01:33:37 theanets.trainer:168 RmsProp 442 loss=185.212692 err=3.194419
I 2015-05-27 01:33:48 theanets.trainer:168 RmsProp 443 loss=184.825409 err=3.085595
I 2015-05-27 01:33:58 theanets.trainer:168 RmsProp 444 loss=184.682327 err=3.216391
I 2015-05-27 01:34:09 theanets.trainer:168 RmsProp 445 loss=184.109390 err=2.917448
I 2015-05-27 01:34:20 theanets.trainer:168 RmsProp 446 loss=184.095612 err=3.175504
I 2015-05-27 01:34:30 theanets.trainer:168 RmsProp 447 loss=183.855087 err=3.210761
I 2015-05-27 01:34:40 theanets.trainer:168 RmsProp 448 loss=183.279297 err=2.911629
I 2015-05-27 01:34:51 theanets.trainer:168 RmsProp 449 loss=183.389938 err=3.294247
I 2015-05-27 01:35:01 theanets.trainer:168 RmsProp 450 loss=182.861359 err=3.042088
I 2015-05-27 01:35:02 theanets.trainer:168 validation 45 loss=812.263794 err=632.584412 *
I 2015-05-27 01:35:12 theanets.trainer:168 RmsProp 451 loss=182.568115 err=3.018274
I 2015-05-27 01:35:23 theanets.trainer:168 RmsProp 452 loss=182.445221 err=3.169237
I 2015-05-27 01:35:33 theanets.trainer:168 RmsProp 453 loss=182.037628 err=3.028407
I 2015-05-27 01:35:44 theanets.trainer:168 RmsProp 454 loss=181.617554 err=2.878719
I 2015-05-27 01:35:54 theanets.trainer:168 RmsProp 455 loss=181.527542 err=3.061227
I 2015-05-27 01:36:05 theanets.trainer:168 RmsProp 456 loss=181.401642 err=3.205252
I 2015-05-27 01:36:15 theanets.trainer:168 RmsProp 457 loss=180.916901 err=2.988684
I 2015-05-27 01:36:25 theanets.trainer:168 RmsProp 458 loss=180.791443 err=3.130991
I 2015-05-27 01:36:36 theanets.trainer:168 RmsProp 459 loss=180.450989 err=3.059553
I 2015-05-27 01:36:47 theanets.trainer:168 RmsProp 460 loss=180.153641 err=3.021597
I 2015-05-27 01:36:47 theanets.trainer:168 validation 46 loss=813.671387 err=636.682617
I 2015-05-27 01:36:58 theanets.trainer:168 RmsProp 461 loss=179.986145 err=3.114866
I 2015-05-27 01:37:09 theanets.trainer:168 RmsProp 462 loss=179.881287 err=3.266831
I 2015-05-27 01:37:19 theanets.trainer:168 RmsProp 463 loss=179.411530 err=3.052104
I 2015-05-27 01:37:30 theanets.trainer:168 RmsProp 464 loss=179.074707 err=2.974528
I 2015-05-27 01:37:41 theanets.trainer:168 RmsProp 465 loss=178.796417 err=2.954465
I 2015-05-27 01:37:51 theanets.trainer:168 RmsProp 466 loss=178.647446 err=3.063063
I 2015-05-27 01:38:02 theanets.trainer:168 RmsProp 467 loss=178.481949 err=3.154245
I 2015-05-27 01:38:13 theanets.trainer:168 RmsProp 468 loss=178.156403 err=3.089106
I 2015-05-27 01:38:24 theanets.trainer:168 RmsProp 469 loss=177.670929 err=2.862442
I 2015-05-27 01:38:35 theanets.trainer:168 RmsProp 470 loss=177.330673 err=2.779938
I 2015-05-27 01:38:35 theanets.trainer:168 validation 47 loss=807.511230 err=633.110291 *
I 2015-05-27 01:38:46 theanets.trainer:168 RmsProp 471 loss=177.344254 err=3.053600
I 2015-05-27 01:38:56 theanets.trainer:168 RmsProp 472 loss=177.234711 err=3.201080
I 2015-05-27 01:39:07 theanets.trainer:168 RmsProp 473 loss=176.765106 err=2.985820
I 2015-05-27 01:39:17 theanets.trainer:168 RmsProp 474 loss=176.685760 err=3.156983
I 2015-05-27 01:39:28 theanets.trainer:168 RmsProp 475 loss=176.182037 err=2.909230
I 2015-05-27 01:39:38 theanets.trainer:168 RmsProp 476 loss=176.170639 err=3.147682
I 2015-05-27 01:39:49 theanets.trainer:168 RmsProp 477 loss=175.891998 err=3.115613
I 2015-05-27 01:39:59 theanets.trainer:168 RmsProp 478 loss=175.418488 err=2.892183
I 2015-05-27 01:40:10 theanets.trainer:168 RmsProp 479 loss=175.334991 err=3.054693
I 2015-05-27 01:40:21 theanets.trainer:168 RmsProp 480 loss=175.120316 err=3.087893
I 2015-05-27 01:40:22 theanets.trainer:168 validation 48 loss=809.977417 err=638.064697
I 2015-05-27 01:40:32 theanets.trainer:168 RmsProp 481 loss=174.891083 err=3.100970
I 2015-05-27 01:40:43 theanets.trainer:168 RmsProp 482 loss=174.380814 err=2.838858
I 2015-05-27 01:40:54 theanets.trainer:168 RmsProp 483 loss=174.501297 err=3.203259
I 2015-05-27 01:41:04 theanets.trainer:168 RmsProp 484 loss=174.001144 err=2.948328
I 2015-05-27 01:41:14 theanets.trainer:168 RmsProp 485 loss=173.676865 err=2.870780
I 2015-05-27 01:41:24 theanets.trainer:168 RmsProp 486 loss=173.476913 err=2.915177
I 2015-05-27 01:41:33 theanets.trainer:168 RmsProp 487 loss=173.020477 err=2.706915
I 2015-05-27 01:41:43 theanets.trainer:168 RmsProp 488 loss=172.987625 err=2.924896
I 2015-05-27 01:41:52 theanets.trainer:168 RmsProp 489 loss=172.974731 err=3.160150
I 2015-05-27 01:42:02 theanets.trainer:168 RmsProp 490 loss=172.384537 err=2.813540
I 2015-05-27 01:42:02 theanets.trainer:168 validation 49 loss=805.179138 err=635.745605 *
I 2015-05-27 01:42:12 theanets.trainer:168 RmsProp 491 loss=172.385391 err=3.056234
I 2015-05-27 01:42:22 theanets.trainer:168 RmsProp 492 loss=172.146454 err=3.059443
I 2015-05-27 01:42:31 theanets.trainer:168 RmsProp 493 loss=172.120819 err=3.265615
I 2015-05-27 01:42:41 theanets.trainer:168 RmsProp 494 loss=171.567566 err=2.945800
I 2015-05-27 01:42:50 theanets.trainer:168 RmsProp 495 loss=171.361038 err=2.967872
I 2015-05-27 01:42:59 theanets.trainer:168 RmsProp 496 loss=171.044235 err=2.883626
I 2015-05-27 01:43:09 theanets.trainer:168 RmsProp 497 loss=170.800369 err=2.872851
I 2015-05-27 01:43:18 theanets.trainer:168 RmsProp 498 loss=170.568634 err=2.875472
I 2015-05-27 01:43:27 theanets.trainer:168 RmsProp 499 loss=170.598999 err=3.139860
I 2015-05-27 01:43:37 theanets.trainer:168 RmsProp 500 loss=169.898300 err=2.675178
I 2015-05-27 01:43:37 theanets.trainer:168 validation 50 loss=798.832275 err=631.746582 *
I 2015-05-27 01:43:47 theanets.trainer:168 RmsProp 501 loss=170.169037 err=3.178860
I 2015-05-27 01:43:56 theanets.trainer:168 RmsProp 502 loss=169.662430 err=2.903600
I 2015-05-27 01:44:05 theanets.trainer:168 RmsProp 503 loss=169.421997 err=2.896371
I 2015-05-27 01:44:14 theanets.trainer:168 RmsProp 504 loss=169.217606 err=2.922722
I 2015-05-27 01:44:24 theanets.trainer:168 RmsProp 505 loss=169.028290 err=2.960337
I 2015-05-27 01:44:33 theanets.trainer:168 RmsProp 506 loss=168.738129 err=2.899187
I 2015-05-27 01:44:43 theanets.trainer:168 RmsProp 507 loss=168.896820 err=3.280282
I 2015-05-27 01:44:52 theanets.trainer:168 RmsProp 508 loss=168.296539 err=2.907964
I 2015-05-27 01:45:02 theanets.trainer:168 RmsProp 509 loss=168.130402 err=2.967436
I 2015-05-27 01:45:11 theanets.trainer:168 RmsProp 510 loss=167.874863 err=2.935697
I 2015-05-27 01:45:12 theanets.trainer:168 validation 51 loss=801.231750 err=636.407349
I 2015-05-27 01:45:21 theanets.trainer:168 RmsProp 511 loss=167.610870 err=2.892774
I 2015-05-27 01:45:31 theanets.trainer:168 RmsProp 512 loss=167.298569 err=2.801500
I 2015-05-27 01:45:41 theanets.trainer:168 RmsProp 513 loss=167.375900 err=3.102309
I 2015-05-27 01:45:50 theanets.trainer:168 RmsProp 514 loss=166.944168 err=2.892482
I 2015-05-27 01:46:00 theanets.trainer:168 RmsProp 515 loss=166.777405 err=2.948633
I 2015-05-27 01:46:09 theanets.trainer:168 RmsProp 516 loss=166.681686 err=3.070982
I 2015-05-27 01:46:19 theanets.trainer:168 RmsProp 517 loss=166.278015 err=2.890772
I 2015-05-27 01:46:29 theanets.trainer:168 RmsProp 518 loss=166.082275 err=2.915250
I 2015-05-27 01:46:38 theanets.trainer:168 RmsProp 519 loss=165.768906 err=2.822504
I 2015-05-27 01:46:48 theanets.trainer:168 RmsProp 520 loss=165.566360 err=2.839910
I 2015-05-27 01:46:48 theanets.trainer:168 validation 52 loss=794.217285 err=631.614380 *
I 2015-05-27 01:46:58 theanets.trainer:168 RmsProp 521 loss=165.541855 err=3.033823
I 2015-05-27 01:47:07 theanets.trainer:168 RmsProp 522 loss=165.138367 err=2.847605
I 2015-05-27 01:47:16 theanets.trainer:168 RmsProp 523 loss=164.803879 err=2.725535
I 2015-05-27 01:47:26 theanets.trainer:168 RmsProp 524 loss=164.806793 err=2.947723
I 2015-05-27 01:47:35 theanets.trainer:168 RmsProp 525 loss=164.612366 err=2.970865
I 2015-05-27 01:47:45 theanets.trainer:168 RmsProp 526 loss=164.583801 err=3.155360
I 2015-05-27 01:47:54 theanets.trainer:168 RmsProp 527 loss=164.074142 err=2.861074
I 2015-05-27 01:48:04 theanets.trainer:168 RmsProp 528 loss=163.915710 err=2.912006
I 2015-05-27 01:48:13 theanets.trainer:168 RmsProp 529 loss=163.724243 err=2.926300
I 2015-05-27 01:48:22 theanets.trainer:168 RmsProp 530 loss=163.580048 err=2.988824
I 2015-05-27 01:48:23 theanets.trainer:168 validation 53 loss=795.377930 err=634.896362
I 2015-05-27 01:48:32 theanets.trainer:168 RmsProp 531 loss=163.418365 err=3.035290
I 2015-05-27 01:48:42 theanets.trainer:168 RmsProp 532 loss=162.911346 err=2.737134
I 2015-05-27 01:48:51 theanets.trainer:168 RmsProp 533 loss=162.800735 err=2.831429
I 2015-05-27 01:49:01 theanets.trainer:168 RmsProp 534 loss=162.638947 err=2.880690
I 2015-05-27 01:49:10 theanets.trainer:168 RmsProp 535 loss=162.372955 err=2.823726
I 2015-05-27 01:49:19 theanets.trainer:168 RmsProp 536 loss=162.221512 err=2.886092
I 2015-05-27 01:49:28 theanets.trainer:168 RmsProp 537 loss=162.021378 err=2.893726
I 2015-05-27 01:49:37 theanets.trainer:168 RmsProp 538 loss=161.966278 err=3.042781
I 2015-05-27 01:49:46 theanets.trainer:168 RmsProp 539 loss=161.709808 err=2.989692
I 2015-05-27 01:49:54 theanets.trainer:168 RmsProp 540 loss=161.243683 err=2.729669
I 2015-05-27 01:49:55 theanets.trainer:168 validation 54 loss=789.385742 err=630.980286 *
I 2015-05-27 01:50:04 theanets.trainer:168 RmsProp 541 loss=161.167145 err=2.857607
I 2015-05-27 01:50:12 theanets.trainer:168 RmsProp 542 loss=161.174744 err=3.069489
I 2015-05-27 01:50:21 theanets.trainer:168 RmsProp 543 loss=160.518463 err=2.620559
I 2015-05-27 01:50:30 theanets.trainer:168 RmsProp 544 loss=160.425415 err=2.730915
I 2015-05-27 01:50:39 theanets.trainer:168 RmsProp 545 loss=160.707718 err=3.213524
I 2015-05-27 01:50:47 theanets.trainer:168 RmsProp 546 loss=160.161942 err=2.867482
I 2015-05-27 01:50:56 theanets.trainer:168 RmsProp 547 loss=159.756729 err=2.663903
I 2015-05-27 01:51:05 theanets.trainer:168 RmsProp 548 loss=159.876144 err=2.984317
I 2015-05-27 01:51:14 theanets.trainer:168 RmsProp 549 loss=159.588852 err=2.894655
I 2015-05-27 01:51:24 theanets.trainer:168 RmsProp 550 loss=159.235214 err=2.739543
I 2015-05-27 01:51:25 theanets.trainer:168 validation 55 loss=791.618286 err=635.226929
I 2015-05-27 01:51:35 theanets.trainer:168 RmsProp 551 loss=159.141357 err=2.843884
I 2015-05-27 01:51:44 theanets.trainer:168 RmsProp 552 loss=159.147415 err=3.050516
I 2015-05-27 01:51:54 theanets.trainer:168 RmsProp 553 loss=158.846832 err=2.948745
I 2015-05-27 01:52:04 theanets.trainer:168 RmsProp 554 loss=158.462814 err=2.763740
I 2015-05-27 01:52:14 theanets.trainer:168 RmsProp 555 loss=158.331024 err=2.829553
I 2015-05-27 01:52:24 theanets.trainer:168 RmsProp 556 loss=158.320084 err=3.011389
I 2015-05-27 01:52:34 theanets.trainer:168 RmsProp 557 loss=157.665253 err=2.554164
I 2015-05-27 01:52:43 theanets.trainer:168 RmsProp 558 loss=157.898392 err=2.980397
I 2015-05-27 01:52:53 theanets.trainer:168 RmsProp 559 loss=157.616318 err=2.895407
I 2015-05-27 01:53:03 theanets.trainer:168 RmsProp 560 loss=157.402252 err=2.870622
I 2015-05-27 01:53:03 theanets.trainer:168 validation 56 loss=783.033386 err=628.600769 *
I 2015-05-27 01:53:13 theanets.trainer:168 RmsProp 561 loss=157.220901 err=2.881141
I 2015-05-27 01:53:22 theanets.trainer:168 RmsProp 562 loss=156.921967 err=2.779464
I 2015-05-27 01:53:32 theanets.trainer:168 RmsProp 563 loss=156.818085 err=2.868477
I 2015-05-27 01:53:42 theanets.trainer:168 RmsProp 564 loss=156.532776 err=2.778542
I 2015-05-27 01:53:51 theanets.trainer:168 RmsProp 565 loss=156.347961 err=2.788542
I 2015-05-27 01:54:01 theanets.trainer:168 RmsProp 566 loss=156.213654 err=2.847237
I 2015-05-27 01:54:11 theanets.trainer:168 RmsProp 567 loss=155.869385 err=2.692649
I 2015-05-27 01:54:20 theanets.trainer:168 RmsProp 568 loss=155.752457 err=2.764866
I 2015-05-27 01:54:30 theanets.trainer:168 RmsProp 569 loss=155.820374 err=3.023077
I 2015-05-27 01:54:40 theanets.trainer:168 RmsProp 570 loss=155.485809 err=2.873316
I 2015-05-27 01:54:40 theanets.trainer:168 validation 57 loss=787.286377 err=634.772644
I 2015-05-27 01:54:50 theanets.trainer:168 RmsProp 571 loss=155.472031 err=3.046790
I 2015-05-27 01:54:59 theanets.trainer:168 RmsProp 572 loss=154.934082 err=2.692188
I 2015-05-27 01:55:09 theanets.trainer:168 RmsProp 573 loss=154.715652 err=2.658171
I 2015-05-27 01:55:18 theanets.trainer:168 RmsProp 574 loss=154.701935 err=2.826739
I 2015-05-27 01:55:28 theanets.trainer:168 RmsProp 575 loss=154.419647 err=2.731537
I 2015-05-27 01:55:38 theanets.trainer:168 RmsProp 576 loss=154.526688 err=3.023736
I 2015-05-27 01:55:48 theanets.trainer:168 RmsProp 577 loss=154.037933 err=2.722193
I 2015-05-27 01:55:57 theanets.trainer:168 RmsProp 578 loss=154.006027 err=2.876575
I 2015-05-27 01:56:07 theanets.trainer:168 RmsProp 579 loss=153.769897 err=2.825754
I 2015-05-27 01:56:16 theanets.trainer:168 RmsProp 580 loss=153.624390 err=2.863856
I 2015-05-27 01:56:17 theanets.trainer:168 validation 58 loss=779.343628 err=628.686157 *
I 2015-05-27 01:56:26 theanets.trainer:168 RmsProp 581 loss=153.315460 err=2.734457
I 2015-05-27 01:56:36 theanets.trainer:168 RmsProp 582 loss=153.095047 err=2.694864
I 2015-05-27 01:56:46 theanets.trainer:168 RmsProp 583 loss=152.968674 err=2.749430
I 2015-05-27 01:56:56 theanets.trainer:168 RmsProp 584 loss=152.870071 err=2.832488
I 2015-05-27 01:57:05 theanets.trainer:168 RmsProp 585 loss=152.941696 err=3.088195
I 2015-05-27 01:57:15 theanets.trainer:168 RmsProp 586 loss=152.418411 err=2.741945
I 2015-05-27 01:57:25 theanets.trainer:168 RmsProp 587 loss=152.005280 err=2.513787
I 2015-05-27 01:57:35 theanets.trainer:168 RmsProp 588 loss=152.169235 err=2.854801
I 2015-05-27 01:57:44 theanets.trainer:168 RmsProp 589 loss=152.095734 err=2.961342
I 2015-05-27 01:57:54 theanets.trainer:168 RmsProp 590 loss=151.577164 err=2.622894
I 2015-05-27 01:57:54 theanets.trainer:168 validation 59 loss=776.293030 err=627.438416 *
I 2015-05-27 01:58:04 theanets.trainer:168 RmsProp 591 loss=151.433517 err=2.659500
I 2015-05-27 01:58:14 theanets.trainer:168 RmsProp 592 loss=151.254013 err=2.658382
I 2015-05-27 01:58:23 theanets.trainer:168 RmsProp 593 loss=151.400284 err=2.982256
I 2015-05-27 01:58:33 theanets.trainer:168 RmsProp 594 loss=151.000870 err=2.765752
I 2015-05-27 01:58:42 theanets.trainer:168 RmsProp 595 loss=150.889893 err=2.831077
I 2015-05-27 01:58:52 theanets.trainer:168 RmsProp 596 loss=150.487091 err=2.602035
I 2015-05-27 01:59:02 theanets.trainer:168 RmsProp 597 loss=150.512558 err=2.804400
I 2015-05-27 01:59:11 theanets.trainer:168 RmsProp 598 loss=150.216629 err=2.685274
I 2015-05-27 01:59:21 theanets.trainer:168 RmsProp 599 loss=150.114136 err=2.758383
I 2015-05-27 01:59:31 theanets.trainer:168 RmsProp 600 loss=149.949799 err=2.765213
I 2015-05-27 01:59:31 theanets.trainer:168 validation 60 loss=775.278870 err=628.185974 *
I 2015-05-27 01:59:41 theanets.trainer:168 RmsProp 601 loss=149.871979 err=2.862523
I 2015-05-27 01:59:51 theanets.trainer:168 RmsProp 602 loss=149.631454 err=2.795185
I 2015-05-27 02:00:00 theanets.trainer:168 RmsProp 603 loss=149.241211 err=2.582531
I 2015-05-27 02:00:10 theanets.trainer:168 RmsProp 604 loss=149.612991 err=3.121715
I 2015-05-27 02:00:20 theanets.trainer:168 RmsProp 605 loss=148.785934 err=2.467746
I 2015-05-27 02:00:30 theanets.trainer:168 RmsProp 606 loss=149.005920 err=2.861483
I 2015-05-27 02:00:40 theanets.trainer:168 RmsProp 607 loss=148.727188 err=2.754613
I 2015-05-27 02:00:50 theanets.trainer:168 RmsProp 608 loss=148.521576 err=2.718904
I 2015-05-27 02:01:00 theanets.trainer:168 RmsProp 609 loss=148.253448 err=2.621600
I 2015-05-27 02:01:10 theanets.trainer:168 RmsProp 610 loss=148.166779 err=2.706897
I 2015-05-27 02:01:11 theanets.trainer:168 validation 61 loss=777.832520 err=632.471497
I 2015-05-27 02:01:20 theanets.trainer:168 RmsProp 611 loss=148.110962 err=2.820952
I 2015-05-27 02:01:30 theanets.trainer:168 RmsProp 612 loss=147.724304 err=2.606571
I 2015-05-27 02:01:40 theanets.trainer:168 RmsProp 613 loss=147.709579 err=2.763437
I 2015-05-27 02:01:49 theanets.trainer:168 RmsProp 614 loss=147.534241 err=2.756394
I 2015-05-27 02:01:59 theanets.trainer:168 RmsProp 615 loss=147.327057 err=2.718621
I 2015-05-27 02:02:08 theanets.trainer:168 RmsProp 616 loss=147.439011 err=2.997522
I 2015-05-27 02:02:18 theanets.trainer:168 RmsProp 617 loss=146.945236 err=2.672195
I 2015-05-27 02:02:28 theanets.trainer:168 RmsProp 618 loss=146.980560 err=2.868531
I 2015-05-27 02:02:38 theanets.trainer:168 RmsProp 619 loss=146.606155 err=2.658707
I 2015-05-27 02:02:48 theanets.trainer:168 RmsProp 620 loss=146.642761 err=2.859516
I 2015-05-27 02:02:48 theanets.trainer:168 validation 62 loss=772.835266 err=629.145813 *
I 2015-05-27 02:02:58 theanets.trainer:168 RmsProp 621 loss=146.214478 err=2.596169
I 2015-05-27 02:03:07 theanets.trainer:168 RmsProp 622 loss=146.188995 err=2.735078
I 2015-05-27 02:03:17 theanets.trainer:168 RmsProp 623 loss=145.981537 err=2.692594
I 2015-05-27 02:03:27 theanets.trainer:168 RmsProp 624 loss=145.705475 err=2.584092
I 2015-05-27 02:03:36 theanets.trainer:168 RmsProp 625 loss=145.754669 err=2.797135
I 2015-05-27 02:03:46 theanets.trainer:168 RmsProp 626 loss=145.625427 err=2.828834
I 2015-05-27 02:03:56 theanets.trainer:168 RmsProp 627 loss=145.274536 err=2.644701
I 2015-05-27 02:04:05 theanets.trainer:168 RmsProp 628 loss=145.109726 err=2.644785
I 2015-05-27 02:04:15 theanets.trainer:168 RmsProp 629 loss=145.030151 err=2.727898
I 2015-05-27 02:04:25 theanets.trainer:168 RmsProp 630 loss=144.904205 err=2.764430
I 2015-05-27 02:04:26 theanets.trainer:168 validation 63 loss=776.729980 err=634.668396
I 2015-05-27 02:04:35 theanets.trainer:168 RmsProp 631 loss=144.743088 err=2.763813
I 2015-05-27 02:04:45 theanets.trainer:168 RmsProp 632 loss=144.447067 err=2.631613
I 2015-05-27 02:04:55 theanets.trainer:168 RmsProp 633 loss=144.335602 err=2.685531
I 2015-05-27 02:05:05 theanets.trainer:168 RmsProp 634 loss=144.314056 err=2.823575
I 2015-05-27 02:05:15 theanets.trainer:168 RmsProp 635 loss=144.120743 err=2.787236
I 2015-05-27 02:05:25 theanets.trainer:168 RmsProp 636 loss=143.873871 err=2.698022
I 2015-05-27 02:05:34 theanets.trainer:168 RmsProp 637 loss=143.394196 err=2.375119
I 2015-05-27 02:05:44 theanets.trainer:168 RmsProp 638 loss=143.849487 err=2.986376
I 2015-05-27 02:05:54 theanets.trainer:168 RmsProp 639 loss=143.470352 err=2.766243
I 2015-05-27 02:06:04 theanets.trainer:168 RmsProp 640 loss=143.123413 err=2.574730
I 2015-05-27 02:06:04 theanets.trainer:168 validation 64 loss=769.656677 err=629.203125 *
I 2015-05-27 02:06:14 theanets.trainer:168 RmsProp 641 loss=143.104568 err=2.716375
I 2015-05-27 02:06:24 theanets.trainer:168 RmsProp 642 loss=142.786575 err=2.553118
I 2015-05-27 02:06:33 theanets.trainer:168 RmsProp 643 loss=142.656509 err=2.579167
I 2015-05-27 02:06:43 theanets.trainer:168 RmsProp 644 loss=142.748856 err=2.828874
I 2015-05-27 02:06:53 theanets.trainer:168 RmsProp 645 loss=142.712555 err=2.949415
I 2015-05-27 02:07:03 theanets.trainer:168 RmsProp 646 loss=142.262680 err=2.655441
I 2015-05-27 02:07:13 theanets.trainer:168 RmsProp 647 loss=142.111359 err=2.659523
I 2015-05-27 02:07:23 theanets.trainer:168 RmsProp 648 loss=141.932343 err=2.635076
I 2015-05-27 02:07:33 theanets.trainer:168 RmsProp 649 loss=141.781342 err=2.639559
I 2015-05-27 02:07:43 theanets.trainer:168 RmsProp 650 loss=141.699814 err=2.717573
I 2015-05-27 02:07:43 theanets.trainer:168 validation 65 loss=770.248108 err=631.356934
I 2015-05-27 02:07:53 theanets.trainer:168 RmsProp 651 loss=141.341766 err=2.517278
I 2015-05-27 02:08:03 theanets.trainer:168 RmsProp 652 loss=141.516541 err=2.844899
I 2015-05-27 02:08:13 theanets.trainer:168 RmsProp 653 loss=141.178497 err=2.662918
I 2015-05-27 02:08:22 theanets.trainer:168 RmsProp 654 loss=141.024994 err=2.660207
I 2015-05-27 02:08:32 theanets.trainer:168 RmsProp 655 loss=140.925079 err=2.715076
I 2015-05-27 02:08:42 theanets.trainer:168 RmsProp 656 loss=140.825165 err=2.761596
I 2015-05-27 02:08:52 theanets.trainer:168 RmsProp 657 loss=140.445679 err=2.536915
I 2015-05-27 02:09:02 theanets.trainer:168 RmsProp 658 loss=140.438370 err=2.680670
I 2015-05-27 02:09:11 theanets.trainer:168 RmsProp 659 loss=140.244614 err=2.639863
I 2015-05-27 02:09:21 theanets.trainer:168 RmsProp 660 loss=140.079056 err=2.627438
I 2015-05-27 02:09:22 theanets.trainer:168 validation 66 loss=769.601929 err=632.226257 *
I 2015-05-27 02:09:32 theanets.trainer:168 RmsProp 661 loss=139.762360 err=2.463129
I 2015-05-27 02:09:42 theanets.trainer:168 RmsProp 662 loss=139.624039 err=2.480061
I 2015-05-27 02:09:51 theanets.trainer:168 RmsProp 663 loss=139.690872 err=2.699754
I 2015-05-27 02:10:01 theanets.trainer:168 RmsProp 664 loss=139.767700 err=2.926890
I 2015-05-27 02:10:10 theanets.trainer:168 RmsProp 665 loss=139.360001 err=2.666597
I 2015-05-27 02:10:20 theanets.trainer:168 RmsProp 666 loss=139.103348 err=2.557318
I 2015-05-27 02:10:30 theanets.trainer:168 RmsProp 667 loss=138.885727 err=2.489309
I 2015-05-27 02:10:39 theanets.trainer:168 RmsProp 668 loss=138.864456 err=2.617060
I 2015-05-27 02:10:49 theanets.trainer:168 RmsProp 669 loss=138.812561 err=2.713411
I 2015-05-27 02:10:58 theanets.trainer:168 RmsProp 670 loss=138.531555 err=2.580318
I 2015-05-27 02:10:59 theanets.trainer:168 validation 67 loss=772.715271 err=636.843994
I 2015-05-27 02:11:09 theanets.trainer:168 RmsProp 671 loss=138.633575 err=2.831084
I 2015-05-27 02:11:18 theanets.trainer:168 RmsProp 672 loss=138.122101 err=2.469531
I 2015-05-27 02:11:28 theanets.trainer:168 RmsProp 673 loss=138.225311 err=2.718478
I 2015-05-27 02:11:38 theanets.trainer:168 RmsProp 674 loss=138.150925 err=2.788439
I 2015-05-27 02:11:48 theanets.trainer:168 RmsProp 675 loss=137.827377 err=2.610905
I 2015-05-27 02:11:57 theanets.trainer:168 RmsProp 676 loss=137.649445 err=2.578782
I 2015-05-27 02:12:07 theanets.trainer:168 RmsProp 677 loss=137.380508 err=2.456798
I 2015-05-27 02:12:16 theanets.trainer:168 RmsProp 678 loss=137.526978 err=2.751368
I 2015-05-27 02:12:26 theanets.trainer:168 RmsProp 679 loss=137.376785 err=2.747434
I 2015-05-27 02:12:36 theanets.trainer:168 RmsProp 680 loss=137.066330 err=2.585657
I 2015-05-27 02:12:36 theanets.trainer:168 validation 68 loss=769.474792 err=635.078918 *
I 2015-05-27 02:12:46 theanets.trainer:168 RmsProp 681 loss=136.940216 err=2.602168
I 2015-05-27 02:12:56 theanets.trainer:168 RmsProp 682 loss=136.798859 err=2.602215
I 2015-05-27 02:13:06 theanets.trainer:168 RmsProp 683 loss=136.591110 err=2.538999
I 2015-05-27 02:13:16 theanets.trainer:168 RmsProp 684 loss=136.590927 err=2.679890
I 2015-05-27 02:13:26 theanets.trainer:168 RmsProp 685 loss=136.497162 err=2.728366
I 2015-05-27 02:13:35 theanets.trainer:168 RmsProp 686 loss=136.492889 err=2.860557
I 2015-05-27 02:13:45 theanets.trainer:168 RmsProp 687 loss=136.024078 err=2.532903
I 2015-05-27 02:13:55 theanets.trainer:168 RmsProp 688 loss=135.890381 err=2.538017
I 2015-05-27 02:14:04 theanets.trainer:168 RmsProp 689 loss=135.836899 err=2.626272
I 2015-05-27 02:14:14 theanets.trainer:168 RmsProp 690 loss=135.523758 err=2.454228
I 2015-05-27 02:14:15 theanets.trainer:168 validation 69 loss=771.150818 err=638.150635
I 2015-05-27 02:14:24 theanets.trainer:168 RmsProp 691 loss=135.881760 err=2.948960
I 2015-05-27 02:14:33 theanets.trainer:168 RmsProp 692 loss=135.433014 err=2.639368
I 2015-05-27 02:14:42 theanets.trainer:168 RmsProp 693 loss=135.369415 err=2.712181
I 2015-05-27 02:14:52 theanets.trainer:168 RmsProp 694 loss=134.968582 err=2.450197
I 2015-05-27 02:15:01 theanets.trainer:168 RmsProp 695 loss=134.869171 err=2.492023
I 2015-05-27 02:15:10 theanets.trainer:168 RmsProp 696 loss=134.919693 err=2.678420
I 2015-05-27 02:15:20 theanets.trainer:168 RmsProp 697 loss=134.669083 err=2.566264
I 2015-05-27 02:15:29 theanets.trainer:168 RmsProp 698 loss=134.667725 err=2.703920
I 2015-05-27 02:15:39 theanets.trainer:168 RmsProp 699 loss=134.376846 err=2.553485
I 2015-05-27 02:15:48 theanets.trainer:168 RmsProp 700 loss=134.065521 err=2.380382
I 2015-05-27 02:15:49 theanets.trainer:168 validation 70 loss=768.894104 err=637.284302 *
I 2015-05-27 02:15:58 theanets.trainer:168 RmsProp 701 loss=134.250458 err=2.702186
I 2015-05-27 02:16:06 theanets.trainer:168 RmsProp 702 loss=134.350113 err=2.942033
I 2015-05-27 02:16:15 theanets.trainer:168 RmsProp 703 loss=133.785248 err=2.514887
I 2015-05-27 02:16:24 theanets.trainer:168 RmsProp 704 loss=133.701752 err=2.565684
I 2015-05-27 02:16:32 theanets.trainer:168 RmsProp 705 loss=133.564972 err=2.563676
I 2015-05-27 02:16:40 theanets.trainer:168 RmsProp 706 loss=133.353973 err=2.488355
I 2015-05-27 02:16:48 theanets.trainer:168 RmsProp 707 loss=133.239960 err=2.508186
I 2015-05-27 02:16:56 theanets.trainer:168 RmsProp 708 loss=133.277206 err=2.681427
I 2015-05-27 02:17:04 theanets.trainer:168 RmsProp 709 loss=133.123322 err=2.662887
I 2015-05-27 02:17:12 theanets.trainer:168 RmsProp 710 loss=132.854462 err=2.527998
I 2015-05-27 02:17:13 theanets.trainer:168 validation 71 loss=770.415894 err=640.160095
I 2015-05-27 02:17:21 theanets.trainer:168 RmsProp 711 loss=132.888702 err=2.698831
I 2015-05-27 02:17:29 theanets.trainer:168 RmsProp 712 loss=132.620422 err=2.561265
I 2015-05-27 02:17:37 theanets.trainer:168 RmsProp 713 loss=132.582565 err=2.658710
I 2015-05-27 02:17:45 theanets.trainer:168 RmsProp 714 loss=132.367523 err=2.583259
I 2015-05-27 02:17:54 theanets.trainer:168 RmsProp 715 loss=132.226440 err=2.574456
I 2015-05-27 02:18:01 theanets.trainer:168 RmsProp 716 loss=132.092743 err=2.574382
I 2015-05-27 02:18:09 theanets.trainer:168 RmsProp 717 loss=131.939407 err=2.552748
I 2015-05-27 02:18:18 theanets.trainer:168 RmsProp 718 loss=131.700409 err=2.446473
I 2015-05-27 02:18:26 theanets.trainer:168 RmsProp 719 loss=131.775757 err=2.652675
I 2015-05-27 02:18:34 theanets.trainer:168 RmsProp 720 loss=131.518616 err=2.530057
I 2015-05-27 02:18:35 theanets.trainer:168 validation 72 loss=763.902588 err=634.987915 *
I 2015-05-27 02:18:43 theanets.trainer:168 RmsProp 721 loss=131.493500 err=2.635573
I 2015-05-27 02:18:50 theanets.trainer:168 RmsProp 722 loss=131.221588 err=2.496162
I 2015-05-27 02:18:59 theanets.trainer:168 RmsProp 723 loss=131.027924 err=2.437774
I 2015-05-27 02:19:06 theanets.trainer:168 RmsProp 724 loss=131.165192 err=2.703014
I 2015-05-27 02:19:13 theanets.trainer:168 RmsProp 725 loss=131.037750 err=2.706191
I 2015-05-27 02:19:21 theanets.trainer:168 RmsProp 726 loss=130.802353 err=2.599279
I 2015-05-27 02:19:29 theanets.trainer:168 RmsProp 727 loss=130.811600 err=2.732686
I 2015-05-27 02:19:38 theanets.trainer:168 RmsProp 728 loss=130.398239 err=2.446670
I 2015-05-27 02:19:45 theanets.trainer:168 RmsProp 729 loss=130.392395 err=2.568972
I 2015-05-27 02:19:54 theanets.trainer:168 RmsProp 730 loss=130.072968 err=2.380001
I 2015-05-27 02:19:54 theanets.trainer:168 validation 73 loss=769.980957 err=642.355225
I 2015-05-27 02:20:02 theanets.trainer:168 RmsProp 731 loss=130.245972 err=2.675737
I 2015-05-27 02:20:10 theanets.trainer:168 RmsProp 732 loss=130.009369 err=2.570098
I 2015-05-27 02:20:18 theanets.trainer:168 RmsProp 733 loss=130.033295 err=2.721230
I 2015-05-27 02:20:25 theanets.trainer:168 RmsProp 734 loss=129.652893 err=2.471804
I 2015-05-27 02:20:32 theanets.trainer:168 RmsProp 735 loss=129.823792 err=2.764794
I 2015-05-27 02:20:39 theanets.trainer:168 RmsProp 736 loss=129.237823 err=2.305763
I 2015-05-27 02:20:47 theanets.trainer:168 RmsProp 737 loss=129.261292 err=2.456531
I 2015-05-27 02:20:55 theanets.trainer:168 RmsProp 738 loss=129.403961 err=2.722768
I 2015-05-27 02:21:03 theanets.trainer:168 RmsProp 739 loss=129.180466 err=2.623602
I 2015-05-27 02:21:10 theanets.trainer:168 RmsProp 740 loss=128.901230 err=2.470665
I 2015-05-27 02:21:11 theanets.trainer:168 validation 74 loss=767.917297 err=641.549316
I 2015-05-27 02:21:18 theanets.trainer:168 RmsProp 741 loss=129.099106 err=2.793375
I 2015-05-27 02:21:26 theanets.trainer:168 RmsProp 742 loss=128.708710 err=2.527690
I 2015-05-27 02:21:34 theanets.trainer:168 RmsProp 743 loss=128.450943 err=2.395287
I 2015-05-27 02:21:41 theanets.trainer:168 RmsProp 744 loss=128.387299 err=2.455929
I 2015-05-27 02:21:49 theanets.trainer:168 RmsProp 745 loss=128.472244 err=2.661455
I 2015-05-27 02:21:57 theanets.trainer:168 RmsProp 746 loss=128.237823 err=2.551909
I 2015-05-27 02:22:05 theanets.trainer:168 RmsProp 747 loss=128.204346 err=2.643996
I 2015-05-27 02:22:13 theanets.trainer:168 RmsProp 748 loss=127.864197 err=2.429845
I 2015-05-27 02:22:20 theanets.trainer:168 RmsProp 749 loss=128.118927 err=2.800823
I 2015-05-27 02:22:28 theanets.trainer:168 RmsProp 750 loss=127.585861 err=2.387974
I 2015-05-27 02:22:28 theanets.trainer:168 validation 75 loss=766.864380 err=641.740234
I 2015-05-27 02:22:36 theanets.trainer:168 RmsProp 751 loss=127.566856 err=2.494262
I 2015-05-27 02:22:44 theanets.trainer:168 RmsProp 752 loss=127.627525 err=2.678170
I 2015-05-27 02:22:52 theanets.trainer:168 RmsProp 753 loss=127.239029 err=2.417032
I 2015-05-27 02:22:59 theanets.trainer:168 RmsProp 754 loss=127.145706 err=2.446448
I 2015-05-27 02:23:06 theanets.trainer:168 RmsProp 755 loss=127.262794 err=2.688730
I 2015-05-27 02:23:14 theanets.trainer:168 RmsProp 756 loss=126.887512 err=2.436824
I 2015-05-27 02:23:21 theanets.trainer:168 RmsProp 757 loss=126.901199 err=2.571016
I 2015-05-27 02:23:28 theanets.trainer:168 RmsProp 758 loss=126.662949 err=2.453205
I 2015-05-27 02:23:36 theanets.trainer:168 RmsProp 759 loss=126.595665 err=2.509520
I 2015-05-27 02:23:44 theanets.trainer:168 RmsProp 760 loss=126.476585 err=2.508731
I 2015-05-27 02:23:44 theanets.trainer:168 validation 76 loss=765.296753 err=641.397949
I 2015-05-27 02:23:51 theanets.trainer:168 RmsProp 761 loss=126.262756 err=2.416255
I 2015-05-27 02:23:58 theanets.trainer:168 RmsProp 762 loss=126.193985 err=2.470876
I 2015-05-27 02:24:06 theanets.trainer:168 RmsProp 763 loss=126.172585 err=2.567966
I 2015-05-27 02:24:13 theanets.trainer:168 RmsProp 764 loss=126.034378 err=2.547785
I 2015-05-27 02:24:20 theanets.trainer:168 RmsProp 765 loss=125.784958 err=2.417739
I 2015-05-27 02:24:28 theanets.trainer:168 RmsProp 766 loss=125.813034 err=2.564904
I 2015-05-27 02:24:37 theanets.trainer:168 RmsProp 767 loss=125.698120 err=2.572089
I 2015-05-27 02:24:44 theanets.trainer:168 RmsProp 768 loss=125.435280 err=2.429534
I 2015-05-27 02:24:51 theanets.trainer:168 RmsProp 769 loss=125.567032 err=2.679757
I 2015-05-27 02:24:59 theanets.trainer:168 RmsProp 770 loss=125.347130 err=2.577729
I 2015-05-27 02:24:59 theanets.trainer:168 validation 77 loss=766.607971 err=643.900940
I 2015-05-27 02:24:59 theanets.trainer:252 patience elapsed!
I 2015-05-27 02:24:59 theanets.main:237 models_deep_post_code_sep/95120-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 02:24:59 theanets.graph:477 models_deep_post_code_sep/95120-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
