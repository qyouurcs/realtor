I 2015-05-27 15:54:43 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-27 15:54:43 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-27 15:54:43 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-27 15:54:43 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-27 15:54:43 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-27 15:54:43 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-27 15:54:43 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-27 15:54:43 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-27 15:54:43 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95131-models-sep_san_jose_realtor_200_100.conf-1024-None-0.1-0.01.pkl
I 2015-05-27 15:54:43 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-27 15:54:43 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-27 15:54:43 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 15:54:43 theanets.main:89 --batch_size = 1024
I 2015-05-27 15:54:43 theanets.main:89 --gradient_clip = 1
I 2015-05-27 15:54:43 theanets.main:89 --hidden_l1 = None
I 2015-05-27 15:54:43 theanets.main:89 --learning_rate = 0.001
I 2015-05-27 15:54:43 theanets.main:89 --train_batches = 30
I 2015-05-27 15:54:43 theanets.main:89 --valid_batches = 3
I 2015-05-27 15:54:43 theanets.main:89 --weight_l1 = 0.1
I 2015-05-27 15:54:43 theanets.main:89 --weight_l2 = 0.01
I 2015-05-27 15:54:43 theanets.trainer:134 compiling evaluation function
I 2015-05-27 15:54:54 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 15:57:38 theanets.trainer:168 validation 0 loss=16572.386719 err=14150.512695 *
I 2015-05-27 15:58:14 theanets.trainer:168 RmsProp 1 loss=14184.008789 err=13137.826172
I 2015-05-27 15:58:51 theanets.trainer:168 RmsProp 2 loss=13443.933594 err=13174.782227
I 2015-05-27 15:59:28 theanets.trainer:168 RmsProp 3 loss=13403.672852 err=13252.140625
I 2015-05-27 16:00:06 theanets.trainer:168 RmsProp 4 loss=13302.932617 err=13163.541016
I 2015-05-27 16:00:44 theanets.trainer:168 RmsProp 5 loss=13299.564453 err=13161.637695
I 2015-05-27 16:01:23 theanets.trainer:168 RmsProp 6 loss=13366.208008 err=13227.647461
I 2015-05-27 16:02:01 theanets.trainer:168 RmsProp 7 loss=13332.055664 err=13191.816406
I 2015-05-27 16:02:39 theanets.trainer:168 RmsProp 8 loss=13353.750977 err=13215.788086
I 2015-05-27 16:03:17 theanets.trainer:168 RmsProp 9 loss=13212.264648 err=13072.916992
I 2015-05-27 16:03:54 theanets.trainer:168 RmsProp 10 loss=13255.605469 err=13116.998047
I 2015-05-27 16:03:55 theanets.trainer:168 validation 1 loss=14292.499023 err=14161.038086 *
I 2015-05-27 16:04:34 theanets.trainer:168 RmsProp 11 loss=13258.521484 err=13120.958008
I 2015-05-27 16:05:12 theanets.trainer:168 RmsProp 12 loss=13284.791016 err=13146.604492
I 2015-05-27 16:05:49 theanets.trainer:168 RmsProp 13 loss=13236.306641 err=13096.822266
I 2015-05-27 16:06:27 theanets.trainer:168 RmsProp 14 loss=13433.068359 err=13294.925781
I 2015-05-27 16:07:05 theanets.trainer:168 RmsProp 15 loss=13311.239258 err=13172.839844
I 2015-05-27 16:07:41 theanets.trainer:168 RmsProp 16 loss=13312.431641 err=13172.345703
I 2015-05-27 16:08:19 theanets.trainer:168 RmsProp 17 loss=13304.405273 err=13164.780273
I 2015-05-27 16:08:57 theanets.trainer:168 RmsProp 18 loss=13331.115234 err=13191.836914
I 2015-05-27 16:09:35 theanets.trainer:168 RmsProp 19 loss=13186.803711 err=13046.423828
I 2015-05-27 16:10:13 theanets.trainer:168 RmsProp 20 loss=13296.345703 err=13155.869141
I 2015-05-27 16:10:14 theanets.trainer:168 validation 2 loss=14300.655273 err=14161.334961
I 2015-05-27 16:10:51 theanets.trainer:168 RmsProp 21 loss=13353.603516 err=13212.953125
I 2015-05-27 16:11:29 theanets.trainer:168 RmsProp 22 loss=13336.008789 err=13194.739258
I 2015-05-27 16:12:06 theanets.trainer:168 RmsProp 23 loss=13381.644531 err=13240.386719
I 2015-05-27 16:12:44 theanets.trainer:168 RmsProp 24 loss=13279.593750 err=13138.230469
I 2015-05-27 16:13:22 theanets.trainer:168 RmsProp 25 loss=13190.675781 err=13050.556641
I 2015-05-27 16:14:00 theanets.trainer:168 RmsProp 26 loss=13329.966797 err=13189.809570
I 2015-05-27 16:14:38 theanets.trainer:168 RmsProp 27 loss=13188.938477 err=13048.122070
I 2015-05-27 16:15:17 theanets.trainer:168 RmsProp 28 loss=13319.814453 err=13178.354492
I 2015-05-27 16:15:56 theanets.trainer:168 RmsProp 29 loss=13298.673828 err=13156.517578
I 2015-05-27 16:16:34 theanets.trainer:168 RmsProp 30 loss=13355.796875 err=13213.508789
I 2015-05-27 16:16:34 theanets.trainer:168 validation 3 loss=14299.213867 err=14157.709961
I 2015-05-27 16:17:12 theanets.trainer:168 RmsProp 31 loss=13310.495117 err=13167.522461
I 2015-05-27 16:17:52 theanets.trainer:168 RmsProp 32 loss=13389.240234 err=13246.943359
I 2015-05-27 16:18:30 theanets.trainer:168 RmsProp 33 loss=13406.372070 err=13264.013672
I 2015-05-27 16:19:09 theanets.trainer:168 RmsProp 34 loss=13331.614258 err=13188.762695
I 2015-05-27 16:19:47 theanets.trainer:168 RmsProp 35 loss=13252.637695 err=13110.268555
I 2015-05-27 16:20:25 theanets.trainer:168 RmsProp 36 loss=13327.541016 err=13184.077148
I 2015-05-27 16:21:04 theanets.trainer:168 RmsProp 37 loss=13204.931641 err=13061.368164
I 2015-05-27 16:21:42 theanets.trainer:168 RmsProp 38 loss=13404.473633 err=13260.833008
I 2015-05-27 16:22:21 theanets.trainer:168 RmsProp 39 loss=13306.987305 err=13163.657227
I 2015-05-27 16:22:59 theanets.trainer:168 RmsProp 40 loss=13281.564453 err=13137.373047
I 2015-05-27 16:23:00 theanets.trainer:168 validation 4 loss=14310.997070 err=14167.342773
I 2015-05-27 16:23:38 theanets.trainer:168 RmsProp 41 loss=13372.780273 err=13227.833984
I 2015-05-27 16:24:17 theanets.trainer:168 RmsProp 42 loss=13367.269531 err=13222.231445
I 2015-05-27 16:24:55 theanets.trainer:168 RmsProp 43 loss=13342.015625 err=13197.931641
I 2015-05-27 16:25:34 theanets.trainer:168 RmsProp 44 loss=13317.302734 err=13171.296875
I 2015-05-27 16:26:13 theanets.trainer:168 RmsProp 45 loss=13304.361328 err=13158.993164
I 2015-05-27 16:26:53 theanets.trainer:168 RmsProp 46 loss=13238.847656 err=13094.222656
I 2015-05-27 16:27:33 theanets.trainer:168 RmsProp 47 loss=13309.421875 err=13164.817383
I 2015-05-27 16:28:14 theanets.trainer:168 RmsProp 48 loss=13264.825195 err=13119.696289
I 2015-05-27 16:28:54 theanets.trainer:168 RmsProp 49 loss=13343.746094 err=13198.902344
I 2015-05-27 16:29:34 theanets.trainer:168 RmsProp 50 loss=13359.957031 err=13215.251953
I 2015-05-27 16:29:35 theanets.trainer:168 validation 5 loss=14308.847656 err=14164.049805
I 2015-05-27 16:30:15 theanets.trainer:168 RmsProp 51 loss=13410.265625 err=13265.130859
I 2015-05-27 16:30:55 theanets.trainer:168 RmsProp 52 loss=13374.158203 err=13228.845703
I 2015-05-27 16:31:34 theanets.trainer:168 RmsProp 53 loss=13358.472656 err=13214.169922
I 2015-05-27 16:32:14 theanets.trainer:168 RmsProp 54 loss=13522.060547 err=13377.193359
I 2015-05-27 16:32:53 theanets.trainer:168 RmsProp 55 loss=13283.248047 err=13138.462891
I 2015-05-27 16:33:32 theanets.trainer:168 RmsProp 56 loss=13333.575195 err=13188.752930
I 2015-05-27 16:34:11 theanets.trainer:168 RmsProp 57 loss=13364.021484 err=13219.286133
I 2015-05-27 16:34:50 theanets.trainer:168 RmsProp 58 loss=13338.958984 err=13194.103516
I 2015-05-27 16:35:34 theanets.trainer:168 RmsProp 59 loss=13428.041016 err=13282.324219
I 2015-05-27 16:36:16 theanets.trainer:168 RmsProp 60 loss=13359.537109 err=13213.583984
I 2015-05-27 16:36:17 theanets.trainer:168 validation 6 loss=14299.058594 err=14158.036133
I 2015-05-27 16:36:17 theanets.trainer:252 patience elapsed!
I 2015-05-27 16:36:17 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 16:36:17 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 16:36:17 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 16:36:17 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 16:36:17 theanets.main:89 --batch_size = 1024
I 2015-05-27 16:36:17 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 16:36:17 theanets.main:89 --hidden_l1 = None
I 2015-05-27 16:36:17 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 16:36:17 theanets.main:89 --train_batches = 10
I 2015-05-27 16:36:17 theanets.main:89 --valid_batches = 2
I 2015-05-27 16:36:17 theanets.main:89 --weight_l1 = 0.1
I 2015-05-27 16:36:17 theanets.main:89 --weight_l2 = 0.01
I 2015-05-27 16:36:18 theanets.trainer:134 compiling evaluation function
I 2015-05-27 16:36:31 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 16:38:29 theanets.trainer:168 validation 0 loss=10734.399414 err=10602.938477 *
I 2015-05-27 16:38:40 theanets.trainer:168 RmsProp 1 loss=13504.034180 err=13416.143555
I 2015-05-27 16:38:52 theanets.trainer:168 RmsProp 2 loss=13810.986328 err=13745.974609
I 2015-05-27 16:39:04 theanets.trainer:168 RmsProp 3 loss=13580.135742 err=13537.156250
I 2015-05-27 16:39:16 theanets.trainer:168 RmsProp 4 loss=13489.331055 err=13459.698242
I 2015-05-27 16:39:28 theanets.trainer:168 RmsProp 5 loss=13473.095703 err=13451.234375
I 2015-05-27 16:39:40 theanets.trainer:168 RmsProp 6 loss=13260.315430 err=13241.177734
I 2015-05-27 16:39:52 theanets.trainer:168 RmsProp 7 loss=13695.918945 err=13678.228516
I 2015-05-27 16:40:04 theanets.trainer:168 RmsProp 8 loss=13771.919922 err=13755.447266
I 2015-05-27 16:40:17 theanets.trainer:168 RmsProp 9 loss=13377.551758 err=13360.396484
I 2015-05-27 16:40:29 theanets.trainer:168 RmsProp 10 loss=13533.771484 err=13517.331055
I 2015-05-27 16:40:30 theanets.trainer:168 validation 1 loss=10480.407227 err=10462.556641 *
I 2015-05-27 16:40:42 theanets.trainer:168 RmsProp 11 loss=13507.393555 err=13490.740234
I 2015-05-27 16:40:54 theanets.trainer:168 RmsProp 12 loss=13369.044922 err=13352.583984
I 2015-05-27 16:41:06 theanets.trainer:168 RmsProp 13 loss=13481.876953 err=13465.309570
I 2015-05-27 16:41:18 theanets.trainer:168 RmsProp 14 loss=13480.909180 err=13463.974609
I 2015-05-27 16:41:30 theanets.trainer:168 RmsProp 15 loss=13315.945312 err=13298.872070
I 2015-05-27 16:41:42 theanets.trainer:168 RmsProp 16 loss=13296.463867 err=13278.666016
I 2015-05-27 16:41:55 theanets.trainer:168 RmsProp 17 loss=13626.740234 err=13607.658203
I 2015-05-27 16:42:08 theanets.trainer:168 RmsProp 18 loss=13413.182617 err=13387.406250
I 2015-05-27 16:42:20 theanets.trainer:168 RmsProp 19 loss=13439.978516 err=13404.791016
I 2015-05-27 16:42:33 theanets.trainer:168 RmsProp 20 loss=13257.926758 err=13213.122070
I 2015-05-27 16:42:33 theanets.trainer:168 validation 2 loss=10271.927734 err=10219.402344 *
I 2015-05-27 16:42:45 theanets.trainer:168 RmsProp 21 loss=12916.831055 err=12859.069336
I 2015-05-27 16:42:58 theanets.trainer:168 RmsProp 22 loss=13152.935547 err=13081.739258
I 2015-05-27 16:43:10 theanets.trainer:168 RmsProp 23 loss=12600.218750 err=12516.040039
I 2015-05-27 16:43:23 theanets.trainer:168 RmsProp 24 loss=12509.538086 err=12415.315430
I 2015-05-27 16:43:35 theanets.trainer:168 RmsProp 25 loss=11938.269531 err=11833.796875
I 2015-05-27 16:43:48 theanets.trainer:168 RmsProp 26 loss=12349.646484 err=12238.279297
I 2015-05-27 16:44:00 theanets.trainer:168 RmsProp 27 loss=12184.087891 err=12066.388672
I 2015-05-27 16:44:12 theanets.trainer:168 RmsProp 28 loss=11900.019531 err=11779.019531
I 2015-05-27 16:44:25 theanets.trainer:168 RmsProp 29 loss=11878.408203 err=11756.814453
I 2015-05-27 16:44:37 theanets.trainer:168 RmsProp 30 loss=11831.303711 err=11709.615234
I 2015-05-27 16:44:38 theanets.trainer:168 validation 3 loss=9195.260742 err=9073.325195 *
I 2015-05-27 16:44:50 theanets.trainer:168 RmsProp 31 loss=11754.077148 err=11631.376953
I 2015-05-27 16:45:03 theanets.trainer:168 RmsProp 32 loss=11181.070312 err=11058.026367
I 2015-05-27 16:45:15 theanets.trainer:168 RmsProp 33 loss=11343.853516 err=11218.936523
I 2015-05-27 16:45:28 theanets.trainer:168 RmsProp 34 loss=10864.947266 err=10734.242188
I 2015-05-27 16:45:40 theanets.trainer:168 RmsProp 35 loss=10740.853516 err=10603.626953
I 2015-05-27 16:45:53 theanets.trainer:168 RmsProp 36 loss=10490.717773 err=10347.984375
I 2015-05-27 16:46:05 theanets.trainer:168 RmsProp 37 loss=10030.992188 err=9883.659180
I 2015-05-27 16:46:18 theanets.trainer:168 RmsProp 38 loss=9786.536133 err=9635.703125
I 2015-05-27 16:46:31 theanets.trainer:168 RmsProp 39 loss=9837.449219 err=9682.775391
I 2015-05-27 16:46:43 theanets.trainer:168 RmsProp 40 loss=9651.458984 err=9494.770508
I 2015-05-27 16:46:43 theanets.trainer:168 validation 4 loss=7697.458984 err=7539.329590 *
I 2015-05-27 16:46:56 theanets.trainer:168 RmsProp 41 loss=9437.510742 err=9278.202148
I 2015-05-27 16:47:08 theanets.trainer:168 RmsProp 42 loss=9216.894531 err=9055.388672
I 2015-05-27 16:47:21 theanets.trainer:168 RmsProp 43 loss=8982.679688 err=8817.945312
I 2015-05-27 16:47:33 theanets.trainer:168 RmsProp 44 loss=8862.212891 err=8693.354492
I 2015-05-27 16:47:46 theanets.trainer:168 RmsProp 45 loss=8587.716797 err=8413.916016
I 2015-05-27 16:47:58 theanets.trainer:168 RmsProp 46 loss=8294.916992 err=8116.523438
I 2015-05-27 16:48:10 theanets.trainer:168 RmsProp 47 loss=8065.356934 err=7883.135254
I 2015-05-27 16:48:22 theanets.trainer:168 RmsProp 48 loss=7784.637695 err=7597.652344
I 2015-05-27 16:48:34 theanets.trainer:168 RmsProp 49 loss=7561.053711 err=7368.798340
I 2015-05-27 16:48:46 theanets.trainer:168 RmsProp 50 loss=7395.764160 err=7197.436035
I 2015-05-27 16:48:47 theanets.trainer:168 validation 5 loss=6071.942871 err=5869.366699 *
I 2015-05-27 16:48:59 theanets.trainer:168 RmsProp 51 loss=7023.846191 err=6819.386719
I 2015-05-27 16:49:11 theanets.trainer:168 RmsProp 52 loss=6923.885742 err=6713.243652
I 2015-05-27 16:49:24 theanets.trainer:168 RmsProp 53 loss=6527.190430 err=6308.912598
I 2015-05-27 16:49:36 theanets.trainer:168 RmsProp 54 loss=6241.946289 err=6016.155273
I 2015-05-27 16:49:48 theanets.trainer:168 RmsProp 55 loss=5846.593262 err=5612.192871
I 2015-05-27 16:50:01 theanets.trainer:168 RmsProp 56 loss=5492.516113 err=5250.052246
I 2015-05-27 16:50:13 theanets.trainer:168 RmsProp 57 loss=5134.444336 err=4884.698730
I 2015-05-27 16:50:26 theanets.trainer:168 RmsProp 58 loss=4809.469727 err=4552.568848
I 2015-05-27 16:50:38 theanets.trainer:168 RmsProp 59 loss=4509.972656 err=4246.788086
I 2015-05-27 16:50:50 theanets.trainer:168 RmsProp 60 loss=4205.721191 err=3936.616455
I 2015-05-27 16:50:51 theanets.trainer:168 validation 6 loss=3750.985840 err=3478.848389 *
I 2015-05-27 16:51:03 theanets.trainer:168 RmsProp 61 loss=3978.294189 err=3704.094971
I 2015-05-27 16:51:16 theanets.trainer:168 RmsProp 62 loss=3750.240967 err=3470.968750
I 2015-05-27 16:51:29 theanets.trainer:168 RmsProp 63 loss=3434.828857 err=3150.716797
I 2015-05-27 16:51:41 theanets.trainer:168 RmsProp 64 loss=3204.520752 err=2915.968018
I 2015-05-27 16:51:54 theanets.trainer:168 RmsProp 65 loss=3020.891602 err=2728.521729
I 2015-05-27 16:52:06 theanets.trainer:168 RmsProp 66 loss=2882.497314 err=2586.897949
I 2015-05-27 16:52:18 theanets.trainer:168 RmsProp 67 loss=2745.394043 err=2446.234375
I 2015-05-27 16:52:31 theanets.trainer:168 RmsProp 68 loss=2567.837891 err=2265.864990
I 2015-05-27 16:52:42 theanets.trainer:168 RmsProp 69 loss=2412.877686 err=2108.077637
I 2015-05-27 16:52:53 theanets.trainer:168 RmsProp 70 loss=2289.093750 err=1982.458740
I 2015-05-27 16:52:54 theanets.trainer:168 validation 7 loss=2460.147949 err=2153.145752 *
I 2015-05-27 16:53:04 theanets.trainer:168 RmsProp 71 loss=2219.023682 err=1910.477783
I 2015-05-27 16:53:15 theanets.trainer:168 RmsProp 72 loss=2064.944824 err=1754.297119
I 2015-05-27 16:53:26 theanets.trainer:168 RmsProp 73 loss=1966.749390 err=1654.223267
I 2015-05-27 16:53:37 theanets.trainer:168 RmsProp 74 loss=1857.481201 err=1543.282471
I 2015-05-27 16:53:48 theanets.trainer:168 RmsProp 75 loss=1766.122314 err=1450.704956
I 2015-05-27 16:53:59 theanets.trainer:168 RmsProp 76 loss=1681.302490 err=1364.461914
I 2015-05-27 16:54:10 theanets.trainer:168 RmsProp 77 loss=1617.597900 err=1299.979858
I 2015-05-27 16:54:22 theanets.trainer:168 RmsProp 78 loss=1536.732178 err=1218.539307
I 2015-05-27 16:54:33 theanets.trainer:168 RmsProp 79 loss=1481.802002 err=1163.160889
I 2015-05-27 16:54:43 theanets.trainer:168 RmsProp 80 loss=1420.000488 err=1101.255737
I 2015-05-27 16:54:44 theanets.trainer:168 validation 8 loss=1906.892090 err=1587.475586 *
I 2015-05-27 16:54:53 theanets.trainer:168 RmsProp 81 loss=1345.737061 err=1026.525269
I 2015-05-27 16:55:03 theanets.trainer:168 RmsProp 82 loss=1315.641357 err=996.251648
I 2015-05-27 16:55:14 theanets.trainer:168 RmsProp 83 loss=1264.470459 err=944.753723
I 2015-05-27 16:55:24 theanets.trainer:168 RmsProp 84 loss=1231.855347 err=911.782715
I 2015-05-27 16:55:34 theanets.trainer:168 RmsProp 85 loss=1185.005981 err=864.501770
I 2015-05-27 16:55:45 theanets.trainer:168 RmsProp 86 loss=1138.052490 err=817.308228
I 2015-05-27 16:55:55 theanets.trainer:168 RmsProp 87 loss=1087.279053 err=766.581848
I 2015-05-27 16:56:05 theanets.trainer:168 RmsProp 88 loss=1049.662109 err=728.791443
I 2015-05-27 16:56:16 theanets.trainer:168 RmsProp 89 loss=1034.684204 err=714.328247
I 2015-05-27 16:56:24 theanets.trainer:168 RmsProp 90 loss=993.292664 err=672.590820
I 2015-05-27 16:56:25 theanets.trainer:168 validation 9 loss=1607.064331 err=1286.041016 *
I 2015-05-27 16:56:33 theanets.trainer:168 RmsProp 91 loss=960.202637 err=639.482483
I 2015-05-27 16:56:39 theanets.trainer:168 RmsProp 92 loss=944.775269 err=624.272400
I 2015-05-27 16:56:47 theanets.trainer:168 RmsProp 93 loss=893.799316 err=573.235901
I 2015-05-27 16:56:55 theanets.trainer:168 RmsProp 94 loss=872.605164 err=552.147644
I 2015-05-27 16:57:02 theanets.trainer:168 RmsProp 95 loss=843.209656 err=522.537964
I 2015-05-27 16:57:10 theanets.trainer:168 RmsProp 96 loss=810.389771 err=489.818054
I 2015-05-27 16:57:17 theanets.trainer:168 RmsProp 97 loss=795.484070 err=474.674255
I 2015-05-27 16:57:25 theanets.trainer:168 RmsProp 98 loss=765.700134 err=445.032166
I 2015-05-27 16:57:32 theanets.trainer:168 RmsProp 99 loss=744.741577 err=424.076965
I 2015-05-27 16:57:39 theanets.trainer:168 RmsProp 100 loss=713.710083 err=393.130310
I 2015-05-27 16:57:39 theanets.trainer:168 validation 10 loss=1412.314087 err=1091.977905 *
I 2015-05-27 16:57:46 theanets.trainer:168 RmsProp 101 loss=703.290161 err=383.265503
I 2015-05-27 16:57:53 theanets.trainer:168 RmsProp 102 loss=684.284119 err=364.290466
I 2015-05-27 16:58:00 theanets.trainer:168 RmsProp 103 loss=659.527405 err=340.376129
I 2015-05-27 16:58:06 theanets.trainer:168 RmsProp 104 loss=655.362183 err=336.830048
I 2015-05-27 16:58:13 theanets.trainer:168 RmsProp 105 loss=644.226807 err=326.143768
I 2015-05-27 16:58:20 theanets.trainer:168 RmsProp 106 loss=619.877930 err=302.723328
I 2015-05-27 16:58:27 theanets.trainer:168 RmsProp 107 loss=614.691345 err=298.380463
I 2015-05-27 16:58:33 theanets.trainer:168 RmsProp 108 loss=605.943542 err=290.478943
I 2015-05-27 16:58:40 theanets.trainer:168 RmsProp 109 loss=595.361389 err=280.451813
I 2015-05-27 16:58:46 theanets.trainer:168 RmsProp 110 loss=587.229065 err=273.275574
I 2015-05-27 16:58:47 theanets.trainer:168 validation 11 loss=1319.200562 err=1005.490662 *
I 2015-05-27 16:58:52 theanets.trainer:168 RmsProp 111 loss=581.085266 err=267.666229
I 2015-05-27 16:58:58 theanets.trainer:168 RmsProp 112 loss=565.241028 err=252.877045
I 2015-05-27 16:59:04 theanets.trainer:168 RmsProp 113 loss=558.391602 err=246.998322
I 2015-05-27 16:59:11 theanets.trainer:168 RmsProp 114 loss=559.531311 err=248.789032
I 2015-05-27 16:59:17 theanets.trainer:168 RmsProp 115 loss=546.625977 err=236.814484
I 2015-05-27 16:59:24 theanets.trainer:168 RmsProp 116 loss=535.462769 err=226.260223
I 2015-05-27 16:59:29 theanets.trainer:168 RmsProp 117 loss=526.070862 err=217.761200
I 2015-05-27 16:59:35 theanets.trainer:168 RmsProp 118 loss=532.012878 err=224.480759
I 2015-05-27 16:59:41 theanets.trainer:168 RmsProp 119 loss=516.030640 err=209.261230
I 2015-05-27 16:59:46 theanets.trainer:168 RmsProp 120 loss=514.489136 err=208.610199
I 2015-05-27 16:59:46 theanets.trainer:168 validation 12 loss=1230.826538 err=925.009399 *
I 2015-05-27 16:59:50 theanets.trainer:168 RmsProp 121 loss=506.589294 err=201.284470
I 2015-05-27 16:59:55 theanets.trainer:168 RmsProp 122 loss=500.814453 err=196.411179
I 2015-05-27 16:59:59 theanets.trainer:168 RmsProp 123 loss=496.885101 err=193.022537
I 2015-05-27 17:00:03 theanets.trainer:168 RmsProp 124 loss=489.480865 err=186.446274
I 2015-05-27 17:00:07 theanets.trainer:168 RmsProp 125 loss=499.147766 err=196.551300
I 2015-05-27 17:00:11 theanets.trainer:168 RmsProp 126 loss=486.004883 err=184.015594
I 2015-05-27 17:00:15 theanets.trainer:168 RmsProp 127 loss=475.508881 err=174.482437
I 2015-05-27 17:00:20 theanets.trainer:168 RmsProp 128 loss=464.901062 err=164.499252
I 2015-05-27 17:00:24 theanets.trainer:168 RmsProp 129 loss=472.127136 err=172.647156
I 2015-05-27 17:00:28 theanets.trainer:168 RmsProp 130 loss=482.025055 err=182.615005
I 2015-05-27 17:00:28 theanets.trainer:168 validation 13 loss=1181.531128 err=882.362305 *
I 2015-05-27 17:00:32 theanets.trainer:168 RmsProp 131 loss=457.041107 err=158.507401
I 2015-05-27 17:00:36 theanets.trainer:168 RmsProp 132 loss=448.197357 err=150.419037
I 2015-05-27 17:00:40 theanets.trainer:168 RmsProp 133 loss=449.391541 err=152.231323
I 2015-05-27 17:00:44 theanets.trainer:168 RmsProp 134 loss=443.794922 err=147.330994
I 2015-05-27 17:00:47 theanets.trainer:168 RmsProp 135 loss=439.374756 err=143.357269
I 2015-05-27 17:00:51 theanets.trainer:168 RmsProp 136 loss=434.353210 err=139.220367
I 2015-05-27 17:00:54 theanets.trainer:168 RmsProp 137 loss=435.745941 err=141.146820
I 2015-05-27 17:00:58 theanets.trainer:168 RmsProp 138 loss=436.798737 err=142.681046
I 2015-05-27 17:01:02 theanets.trainer:168 RmsProp 139 loss=427.660156 err=134.073654
I 2015-05-27 17:01:06 theanets.trainer:168 RmsProp 140 loss=421.000732 err=128.066101
I 2015-05-27 17:01:06 theanets.trainer:168 validation 14 loss=1172.350342 err=879.971863 *
I 2015-05-27 17:01:10 theanets.trainer:168 RmsProp 141 loss=414.290192 err=121.918297
I 2015-05-27 17:01:13 theanets.trainer:168 RmsProp 142 loss=417.816315 err=125.955063
I 2015-05-27 17:01:18 theanets.trainer:168 RmsProp 143 loss=408.586456 err=117.379623
I 2015-05-27 17:01:22 theanets.trainer:168 RmsProp 144 loss=407.668121 err=116.906387
I 2015-05-27 17:01:26 theanets.trainer:168 RmsProp 145 loss=402.013428 err=111.913109
I 2015-05-27 17:01:30 theanets.trainer:168 RmsProp 146 loss=406.202026 err=116.602943
I 2015-05-27 17:01:34 theanets.trainer:168 RmsProp 147 loss=399.463959 err=110.363243
I 2015-05-27 17:01:39 theanets.trainer:168 RmsProp 148 loss=395.327026 err=106.924660
I 2015-05-27 17:01:43 theanets.trainer:168 RmsProp 149 loss=393.220032 err=105.218689
I 2015-05-27 17:01:47 theanets.trainer:168 RmsProp 150 loss=389.490417 err=102.115463
I 2015-05-27 17:01:47 theanets.trainer:168 validation 15 loss=1136.368652 err=849.088074 *
I 2015-05-27 17:01:51 theanets.trainer:168 RmsProp 151 loss=394.953003 err=107.913940
I 2015-05-27 17:01:56 theanets.trainer:168 RmsProp 152 loss=387.571350 err=101.218582
I 2015-05-27 17:02:00 theanets.trainer:168 RmsProp 153 loss=386.909851 err=100.940262
I 2015-05-27 17:02:04 theanets.trainer:168 RmsProp 154 loss=380.840302 err=95.477257
I 2015-05-27 17:02:08 theanets.trainer:168 RmsProp 155 loss=378.762665 err=94.089363
I 2015-05-27 17:02:12 theanets.trainer:168 RmsProp 156 loss=376.497040 err=92.270340
I 2015-05-27 17:02:16 theanets.trainer:168 RmsProp 157 loss=377.113190 err=93.449539
I 2015-05-27 17:02:21 theanets.trainer:168 RmsProp 158 loss=373.792175 err=90.522720
I 2015-05-27 17:02:25 theanets.trainer:168 RmsProp 159 loss=366.683289 err=84.068199
I 2015-05-27 17:02:29 theanets.trainer:168 RmsProp 160 loss=374.452209 err=92.271461
I 2015-05-27 17:02:30 theanets.trainer:168 validation 16 loss=1133.203979 err=851.051575 *
I 2015-05-27 17:02:34 theanets.trainer:168 RmsProp 161 loss=363.916656 err=82.302948
I 2015-05-27 17:02:38 theanets.trainer:168 RmsProp 162 loss=359.878357 err=78.897141
I 2015-05-27 17:02:42 theanets.trainer:168 RmsProp 163 loss=369.206329 err=88.676216
I 2015-05-27 17:02:46 theanets.trainer:168 RmsProp 164 loss=380.740662 err=100.469589
I 2015-05-27 17:02:51 theanets.trainer:168 RmsProp 165 loss=364.191742 err=84.095573
I 2015-05-27 17:02:55 theanets.trainer:168 RmsProp 166 loss=357.386932 err=78.102074
I 2015-05-27 17:02:59 theanets.trainer:168 RmsProp 167 loss=353.751068 err=74.951996
I 2015-05-27 17:03:03 theanets.trainer:168 RmsProp 168 loss=354.463806 err=76.154335
I 2015-05-27 17:03:07 theanets.trainer:168 RmsProp 169 loss=350.715393 err=72.894707
I 2015-05-27 17:03:11 theanets.trainer:168 RmsProp 170 loss=350.739838 err=73.470520
I 2015-05-27 17:03:12 theanets.trainer:168 validation 17 loss=1111.016235 err=834.022156 *
I 2015-05-27 17:03:15 theanets.trainer:168 RmsProp 171 loss=349.697083 err=73.041153
I 2015-05-27 17:03:17 theanets.trainer:168 RmsProp 172 loss=347.706390 err=71.390335
I 2015-05-27 17:03:20 theanets.trainer:168 RmsProp 173 loss=347.248047 err=71.595703
I 2015-05-27 17:03:23 theanets.trainer:168 RmsProp 174 loss=344.962585 err=69.703613
I 2015-05-27 17:03:25 theanets.trainer:168 RmsProp 175 loss=343.235657 err=68.492401
I 2015-05-27 17:03:28 theanets.trainer:168 RmsProp 176 loss=342.635345 err=68.424339
I 2015-05-27 17:03:30 theanets.trainer:168 RmsProp 177 loss=340.032135 err=66.150116
I 2015-05-27 17:03:32 theanets.trainer:168 RmsProp 178 loss=341.132874 err=67.900665
I 2015-05-27 17:03:35 theanets.trainer:168 RmsProp 179 loss=338.898041 err=65.976120
I 2015-05-27 17:03:39 theanets.trainer:168 RmsProp 180 loss=336.812164 err=64.438721
I 2015-05-27 17:03:39 theanets.trainer:168 validation 18 loss=1106.408203 err=834.416138 *
I 2015-05-27 17:03:42 theanets.trainer:168 RmsProp 181 loss=337.346558 err=65.271164
I 2015-05-27 17:03:45 theanets.trainer:168 RmsProp 182 loss=334.163361 err=62.586018
I 2015-05-27 17:03:48 theanets.trainer:168 RmsProp 183 loss=333.474182 err=62.387085
I 2015-05-27 17:03:50 theanets.trainer:168 RmsProp 184 loss=329.558167 err=58.850807
I 2015-05-27 17:03:53 theanets.trainer:168 RmsProp 185 loss=329.610962 err=59.568062
I 2015-05-27 17:03:56 theanets.trainer:168 RmsProp 186 loss=330.992950 err=61.235615
I 2015-05-27 17:03:58 theanets.trainer:168 RmsProp 187 loss=327.214844 err=57.958565
I 2015-05-27 17:04:01 theanets.trainer:168 RmsProp 188 loss=326.983643 err=58.186798
I 2015-05-27 17:04:04 theanets.trainer:168 RmsProp 189 loss=327.730286 err=59.312347
I 2015-05-27 17:04:06 theanets.trainer:168 RmsProp 190 loss=322.970703 err=55.115753
I 2015-05-27 17:04:07 theanets.trainer:168 validation 19 loss=1087.690063 err=819.702148 *
I 2015-05-27 17:04:09 theanets.trainer:168 RmsProp 191 loss=325.132751 err=57.633930
I 2015-05-27 17:04:12 theanets.trainer:168 RmsProp 192 loss=329.697754 err=62.618080
I 2015-05-27 17:04:14 theanets.trainer:168 RmsProp 193 loss=325.434631 err=58.571918
I 2015-05-27 17:04:17 theanets.trainer:168 RmsProp 194 loss=320.912384 err=54.665913
I 2015-05-27 17:04:20 theanets.trainer:168 RmsProp 195 loss=319.487732 err=53.535912
I 2015-05-27 17:04:23 theanets.trainer:168 RmsProp 196 loss=321.581543 err=56.005299
I 2015-05-27 17:04:28 theanets.trainer:168 RmsProp 197 loss=317.661743 err=52.566505
I 2015-05-27 17:04:32 theanets.trainer:168 RmsProp 198 loss=319.569580 err=54.717724
I 2015-05-27 17:04:36 theanets.trainer:168 RmsProp 199 loss=314.659729 err=50.424618
I 2015-05-27 17:04:40 theanets.trainer:168 RmsProp 200 loss=315.538666 err=51.552673
I 2015-05-27 17:04:41 theanets.trainer:168 validation 20 loss=1079.854004 err=815.659912 *
I 2015-05-27 17:04:45 theanets.trainer:168 RmsProp 201 loss=315.764252 err=52.099243
I 2015-05-27 17:04:49 theanets.trainer:168 RmsProp 202 loss=311.004700 err=47.727013
I 2015-05-27 17:04:53 theanets.trainer:168 RmsProp 203 loss=321.537811 err=58.572407
I 2015-05-27 17:04:57 theanets.trainer:168 RmsProp 204 loss=313.495422 err=50.948250
I 2015-05-27 17:05:02 theanets.trainer:168 RmsProp 205 loss=305.694855 err=43.547981
I 2015-05-27 17:05:06 theanets.trainer:168 RmsProp 206 loss=320.617432 err=58.865562
I 2015-05-27 17:05:10 theanets.trainer:168 RmsProp 207 loss=311.220581 err=49.576393
I 2015-05-27 17:05:14 theanets.trainer:168 RmsProp 208 loss=306.366913 err=45.316765
I 2015-05-27 17:05:18 theanets.trainer:168 RmsProp 209 loss=311.413635 err=50.723747
I 2015-05-27 17:05:23 theanets.trainer:168 RmsProp 210 loss=306.056519 err=45.693920
I 2015-05-27 17:05:23 theanets.trainer:168 validation 21 loss=1086.637817 err=827.123962
I 2015-05-27 17:05:26 theanets.trainer:168 RmsProp 211 loss=307.275696 err=47.337975
I 2015-05-27 17:05:30 theanets.trainer:168 RmsProp 212 loss=305.662903 err=46.024414
I 2015-05-27 17:05:35 theanets.trainer:168 RmsProp 213 loss=305.649231 err=46.351906
I 2015-05-27 17:05:39 theanets.trainer:168 RmsProp 214 loss=302.942688 err=43.895287
I 2015-05-27 17:05:43 theanets.trainer:168 RmsProp 215 loss=303.740479 err=45.243271
I 2015-05-27 17:05:47 theanets.trainer:168 RmsProp 216 loss=304.176697 err=45.979374
I 2015-05-27 17:05:51 theanets.trainer:168 RmsProp 217 loss=300.990906 err=43.104542
I 2015-05-27 17:05:55 theanets.trainer:168 RmsProp 218 loss=304.757538 err=47.355835
I 2015-05-27 17:05:59 theanets.trainer:168 RmsProp 219 loss=302.766663 err=45.464432
I 2015-05-27 17:06:03 theanets.trainer:168 RmsProp 220 loss=301.406342 err=44.598114
I 2015-05-27 17:06:03 theanets.trainer:168 validation 22 loss=1064.188843 err=807.245117 *
I 2015-05-27 17:06:07 theanets.trainer:168 RmsProp 221 loss=298.308136 err=41.739246
I 2015-05-27 17:06:11 theanets.trainer:168 RmsProp 222 loss=300.381897 err=44.250252
I 2015-05-27 17:06:15 theanets.trainer:168 RmsProp 223 loss=298.393982 err=42.419823
I 2015-05-27 17:06:19 theanets.trainer:168 RmsProp 224 loss=293.673950 err=38.147892
I 2015-05-27 17:06:23 theanets.trainer:168 RmsProp 225 loss=310.637787 err=55.155769
I 2015-05-27 17:06:27 theanets.trainer:168 RmsProp 226 loss=299.808258 err=44.418331
I 2015-05-27 17:06:31 theanets.trainer:168 RmsProp 227 loss=296.145325 err=41.326515
I 2015-05-27 17:06:35 theanets.trainer:168 RmsProp 228 loss=294.543030 err=39.958862
I 2015-05-27 17:06:39 theanets.trainer:168 RmsProp 229 loss=295.569885 err=41.457905
I 2015-05-27 17:06:43 theanets.trainer:168 RmsProp 230 loss=294.244080 err=40.432114
I 2015-05-27 17:06:44 theanets.trainer:168 validation 23 loss=1060.568115 err=806.404480 *
I 2015-05-27 17:06:46 theanets.trainer:168 RmsProp 231 loss=294.097748 err=40.476318
I 2015-05-27 17:06:49 theanets.trainer:168 RmsProp 232 loss=293.069519 err=39.868187
I 2015-05-27 17:06:52 theanets.trainer:168 RmsProp 233 loss=292.325989 err=39.379753
I 2015-05-27 17:06:54 theanets.trainer:168 RmsProp 234 loss=291.321899 err=38.824829
I 2015-05-27 17:06:57 theanets.trainer:168 RmsProp 235 loss=293.666809 err=41.293331
I 2015-05-27 17:06:59 theanets.trainer:168 RmsProp 236 loss=287.522186 err=35.665428
I 2015-05-27 17:07:02 theanets.trainer:168 RmsProp 237 loss=290.545471 err=38.872051
I 2015-05-27 17:07:05 theanets.trainer:168 RmsProp 238 loss=292.297577 err=40.906143
I 2015-05-27 17:07:08 theanets.trainer:168 RmsProp 239 loss=288.102234 err=37.150593
I 2015-05-27 17:07:10 theanets.trainer:168 RmsProp 240 loss=289.191132 err=38.382999
I 2015-05-27 17:07:11 theanets.trainer:168 validation 24 loss=1055.768677 err=805.407349 *
I 2015-05-27 17:07:14 theanets.trainer:168 RmsProp 241 loss=288.460754 err=38.062965
I 2015-05-27 17:07:17 theanets.trainer:168 RmsProp 242 loss=287.343384 err=37.161530
I 2015-05-27 17:07:20 theanets.trainer:168 RmsProp 243 loss=286.529846 err=36.701042
I 2015-05-27 17:07:22 theanets.trainer:168 RmsProp 244 loss=286.454285 err=36.841019
I 2015-05-27 17:07:25 theanets.trainer:168 RmsProp 245 loss=286.356903 err=37.104027
I 2015-05-27 17:07:28 theanets.trainer:168 RmsProp 246 loss=285.283417 err=36.323811
I 2015-05-27 17:07:31 theanets.trainer:168 RmsProp 247 loss=286.432770 err=37.553932
I 2015-05-27 17:07:33 theanets.trainer:168 RmsProp 248 loss=283.846161 err=35.434689
I 2015-05-27 17:07:36 theanets.trainer:168 RmsProp 249 loss=286.825714 err=38.456352
I 2015-05-27 17:07:38 theanets.trainer:168 RmsProp 250 loss=283.416016 err=35.460831
I 2015-05-27 17:07:38 theanets.trainer:168 validation 25 loss=1049.898682 err=802.125610 *
I 2015-05-27 17:07:41 theanets.trainer:168 RmsProp 251 loss=284.488281 err=36.801037
I 2015-05-27 17:07:43 theanets.trainer:168 RmsProp 252 loss=284.528809 err=37.018017
I 2015-05-27 17:07:46 theanets.trainer:168 RmsProp 253 loss=279.874207 err=32.792500
I 2015-05-27 17:07:48 theanets.trainer:168 RmsProp 254 loss=282.307617 err=35.455608
I 2015-05-27 17:07:51 theanets.trainer:168 RmsProp 255 loss=281.859589 err=35.312748
I 2015-05-27 17:07:53 theanets.trainer:168 RmsProp 256 loss=279.553711 err=33.163319
I 2015-05-27 17:07:56 theanets.trainer:168 RmsProp 257 loss=281.023468 err=35.050003
I 2015-05-27 17:07:58 theanets.trainer:168 RmsProp 258 loss=279.159119 err=33.362610
I 2015-05-27 17:08:02 theanets.trainer:168 RmsProp 259 loss=280.257721 err=34.716652
I 2015-05-27 17:08:05 theanets.trainer:168 RmsProp 260 loss=278.469910 err=33.366089
I 2015-05-27 17:08:05 theanets.trainer:168 validation 26 loss=1055.078979 err=809.628845
I 2015-05-27 17:08:08 theanets.trainer:168 RmsProp 261 loss=279.782990 err=34.760315
I 2015-05-27 17:08:11 theanets.trainer:168 RmsProp 262 loss=276.963043 err=32.366127
I 2015-05-27 17:08:14 theanets.trainer:168 RmsProp 263 loss=278.653625 err=34.163078
I 2015-05-27 17:08:17 theanets.trainer:168 RmsProp 264 loss=277.087341 err=32.936806
I 2015-05-27 17:08:20 theanets.trainer:168 RmsProp 265 loss=276.276520 err=32.284328
I 2015-05-27 17:08:23 theanets.trainer:168 RmsProp 266 loss=275.462860 err=31.847565
I 2015-05-27 17:08:26 theanets.trainer:168 RmsProp 267 loss=277.042908 err=33.651463
I 2015-05-27 17:08:29 theanets.trainer:168 RmsProp 268 loss=275.929871 err=32.661846
I 2015-05-27 17:08:31 theanets.trainer:168 RmsProp 269 loss=275.164185 err=32.339046
I 2015-05-27 17:08:34 theanets.trainer:168 RmsProp 270 loss=273.868896 err=31.064198
I 2015-05-27 17:08:34 theanets.trainer:168 validation 27 loss=1052.196533 err=809.477478
I 2015-05-27 17:08:37 theanets.trainer:168 RmsProp 271 loss=276.176514 err=33.691753
I 2015-05-27 17:08:39 theanets.trainer:168 RmsProp 272 loss=273.808716 err=31.573826
I 2015-05-27 17:08:42 theanets.trainer:168 RmsProp 273 loss=274.156799 err=32.095119
I 2015-05-27 17:08:44 theanets.trainer:168 RmsProp 274 loss=272.445068 err=30.699215
I 2015-05-27 17:08:47 theanets.trainer:168 RmsProp 275 loss=272.486755 err=30.917561
I 2015-05-27 17:08:49 theanets.trainer:168 RmsProp 276 loss=273.556458 err=32.369171
I 2015-05-27 17:08:52 theanets.trainer:168 RmsProp 277 loss=272.808960 err=31.675320
I 2015-05-27 17:08:54 theanets.trainer:168 RmsProp 278 loss=271.091492 err=30.340902
I 2015-05-27 17:08:57 theanets.trainer:168 RmsProp 279 loss=271.975891 err=31.248337
I 2015-05-27 17:09:00 theanets.trainer:168 RmsProp 280 loss=269.074280 err=28.675030
I 2015-05-27 17:09:00 theanets.trainer:168 validation 28 loss=1065.942871 err=826.091797
I 2015-05-27 17:09:03 theanets.trainer:168 RmsProp 281 loss=272.752991 err=32.619110
I 2015-05-27 17:09:05 theanets.trainer:168 RmsProp 282 loss=270.154938 err=30.122448
I 2015-05-27 17:09:08 theanets.trainer:168 RmsProp 283 loss=269.804840 err=30.149033
I 2015-05-27 17:09:11 theanets.trainer:168 RmsProp 284 loss=268.298431 err=28.788580
I 2015-05-27 17:09:14 theanets.trainer:168 RmsProp 285 loss=270.307495 err=31.085974
I 2015-05-27 17:09:16 theanets.trainer:168 RmsProp 286 loss=268.519562 err=29.477392
I 2015-05-27 17:09:19 theanets.trainer:168 RmsProp 287 loss=267.972351 err=29.179148
I 2015-05-27 17:09:21 theanets.trainer:168 RmsProp 288 loss=267.084137 err=28.563465
I 2015-05-27 17:09:24 theanets.trainer:168 RmsProp 289 loss=268.060913 err=29.563808
I 2015-05-27 17:09:26 theanets.trainer:168 RmsProp 290 loss=267.871063 err=29.768194
I 2015-05-27 17:09:26 theanets.trainer:168 validation 29 loss=1036.901978 err=798.472595 *
I 2015-05-27 17:09:29 theanets.trainer:168 RmsProp 291 loss=266.586517 err=28.508844
I 2015-05-27 17:09:31 theanets.trainer:168 RmsProp 292 loss=266.032928 err=28.323507
I 2015-05-27 17:09:34 theanets.trainer:168 RmsProp 293 loss=267.356934 err=29.816717
I 2015-05-27 17:09:36 theanets.trainer:168 RmsProp 294 loss=266.446289 err=29.049030
I 2015-05-27 17:09:38 theanets.trainer:168 RmsProp 295 loss=265.158417 err=28.059570
I 2015-05-27 17:09:41 theanets.trainer:168 RmsProp 296 loss=265.876129 err=28.907719
I 2015-05-27 17:09:44 theanets.trainer:168 RmsProp 297 loss=264.176666 err=27.508564
I 2015-05-27 17:09:47 theanets.trainer:168 RmsProp 298 loss=267.154633 err=30.509222
I 2015-05-27 17:09:50 theanets.trainer:168 RmsProp 299 loss=264.429626 err=28.160563
I 2015-05-27 17:09:53 theanets.trainer:168 RmsProp 300 loss=264.523285 err=28.350193
I 2015-05-27 17:09:53 theanets.trainer:168 validation 30 loss=1031.907104 err=795.584534 *
I 2015-05-27 17:09:56 theanets.trainer:168 RmsProp 301 loss=263.220551 err=27.187998
I 2015-05-27 17:09:59 theanets.trainer:168 RmsProp 302 loss=263.240540 err=27.570593
I 2015-05-27 17:10:02 theanets.trainer:168 RmsProp 303 loss=263.264557 err=27.623348
I 2015-05-27 17:10:05 theanets.trainer:168 RmsProp 304 loss=262.487396 err=27.154337
I 2015-05-27 17:10:08 theanets.trainer:168 RmsProp 305 loss=261.971069 err=26.729599
I 2015-05-27 17:10:11 theanets.trainer:168 RmsProp 306 loss=262.936859 err=27.957712
I 2015-05-27 17:10:14 theanets.trainer:168 RmsProp 307 loss=261.070343 err=26.202435
I 2015-05-27 17:10:17 theanets.trainer:168 RmsProp 308 loss=261.225647 err=26.631586
I 2015-05-27 17:10:20 theanets.trainer:168 RmsProp 309 loss=261.311859 err=26.889893
I 2015-05-27 17:10:23 theanets.trainer:168 RmsProp 310 loss=260.425598 err=26.102459
I 2015-05-27 17:10:23 theanets.trainer:168 validation 31 loss=1038.750244 err=804.680664
I 2015-05-27 17:10:26 theanets.trainer:168 RmsProp 311 loss=261.265411 err=27.287243
I 2015-05-27 17:10:29 theanets.trainer:168 RmsProp 312 loss=261.147034 err=27.161783
I 2015-05-27 17:10:32 theanets.trainer:168 RmsProp 313 loss=261.301605 err=27.564495
I 2015-05-27 17:10:34 theanets.trainer:168 RmsProp 314 loss=259.093842 err=25.533091
I 2015-05-27 17:10:37 theanets.trainer:168 RmsProp 315 loss=260.129547 err=26.652868
I 2015-05-27 17:10:39 theanets.trainer:168 RmsProp 316 loss=259.822235 err=26.570347
I 2015-05-27 17:10:41 theanets.trainer:168 RmsProp 317 loss=260.154297 err=26.985464
I 2015-05-27 17:10:43 theanets.trainer:168 RmsProp 318 loss=258.320862 err=25.444935
I 2015-05-27 17:10:45 theanets.trainer:168 RmsProp 319 loss=258.987366 err=26.112606
I 2015-05-27 17:10:47 theanets.trainer:168 RmsProp 320 loss=257.946472 err=25.384380
I 2015-05-27 17:10:47 theanets.trainer:168 validation 32 loss=1046.899780 err=814.290283
I 2015-05-27 17:10:49 theanets.trainer:168 RmsProp 321 loss=259.426483 err=26.858267
I 2015-05-27 17:10:51 theanets.trainer:168 RmsProp 322 loss=257.811951 err=25.478374
I 2015-05-27 17:10:52 theanets.trainer:168 RmsProp 323 loss=256.762390 err=24.666275
I 2015-05-27 17:10:54 theanets.trainer:168 RmsProp 324 loss=256.725403 err=24.671024
I 2015-05-27 17:10:56 theanets.trainer:168 RmsProp 325 loss=257.617004 err=25.883289
I 2015-05-27 17:10:58 theanets.trainer:168 RmsProp 326 loss=257.014709 err=25.352901
I 2015-05-27 17:11:00 theanets.trainer:168 RmsProp 327 loss=256.436218 err=24.999594
I 2015-05-27 17:11:02 theanets.trainer:168 RmsProp 328 loss=255.878220 err=24.543915
I 2015-05-27 17:11:04 theanets.trainer:168 RmsProp 329 loss=255.787231 err=24.660254
I 2015-05-27 17:11:06 theanets.trainer:168 RmsProp 330 loss=254.899200 err=24.000431
I 2015-05-27 17:11:06 theanets.trainer:168 validation 33 loss=1022.182312 err=791.119873 *
I 2015-05-27 17:11:08 theanets.trainer:168 RmsProp 331 loss=256.059509 err=25.200077
I 2015-05-27 17:11:10 theanets.trainer:168 RmsProp 332 loss=253.297607 err=22.852135
I 2015-05-27 17:11:12 theanets.trainer:168 RmsProp 333 loss=256.568176 err=26.004765
I 2015-05-27 17:11:14 theanets.trainer:168 RmsProp 334 loss=255.047928 err=24.794607
I 2015-05-27 17:11:16 theanets.trainer:168 RmsProp 335 loss=255.015472 err=24.886391
I 2015-05-27 17:11:17 theanets.trainer:168 RmsProp 336 loss=252.248810 err=22.294605
I 2015-05-27 17:11:19 theanets.trainer:168 RmsProp 337 loss=255.734772 err=25.990559
I 2015-05-27 17:11:21 theanets.trainer:168 RmsProp 338 loss=253.264206 err=23.661600
I 2015-05-27 17:11:23 theanets.trainer:168 RmsProp 339 loss=253.048340 err=23.711714
I 2015-05-27 17:11:25 theanets.trainer:168 RmsProp 340 loss=252.463043 err=23.134863
I 2015-05-27 17:11:25 theanets.trainer:168 validation 34 loss=1026.371704 err=796.981262
I 2015-05-27 17:11:27 theanets.trainer:168 RmsProp 341 loss=252.069733 err=23.096643
I 2015-05-27 17:11:29 theanets.trainer:168 RmsProp 342 loss=252.945602 err=24.015854
I 2015-05-27 17:11:31 theanets.trainer:168 RmsProp 343 loss=252.663040 err=23.884089
I 2015-05-27 17:11:33 theanets.trainer:168 RmsProp 344 loss=253.053513 err=24.498093
I 2015-05-27 17:11:35 theanets.trainer:168 RmsProp 345 loss=251.395508 err=22.836254
I 2015-05-27 17:11:37 theanets.trainer:168 RmsProp 346 loss=251.110886 err=22.946375
I 2015-05-27 17:11:39 theanets.trainer:168 RmsProp 347 loss=251.555573 err=23.413610
I 2015-05-27 17:11:41 theanets.trainer:168 RmsProp 348 loss=250.653244 err=22.780523
I 2015-05-27 17:11:43 theanets.trainer:168 RmsProp 349 loss=251.027008 err=23.243576
I 2015-05-27 17:11:45 theanets.trainer:168 RmsProp 350 loss=251.487259 err=23.883108
I 2015-05-27 17:11:45 theanets.trainer:168 validation 35 loss=1019.530029 err=792.287415 *
I 2015-05-27 17:11:47 theanets.trainer:168 RmsProp 351 loss=249.622437 err=22.199753
I 2015-05-27 17:11:49 theanets.trainer:168 RmsProp 352 loss=251.092819 err=23.753710
I 2015-05-27 17:11:51 theanets.trainer:168 RmsProp 353 loss=249.331421 err=22.298046
I 2015-05-27 17:11:52 theanets.trainer:168 RmsProp 354 loss=249.296463 err=22.244734
I 2015-05-27 17:11:54 theanets.trainer:168 RmsProp 355 loss=250.180206 err=23.418066
I 2015-05-27 17:11:56 theanets.trainer:168 RmsProp 356 loss=249.111298 err=22.472746
I 2015-05-27 17:11:58 theanets.trainer:168 RmsProp 357 loss=249.293182 err=22.717236
I 2015-05-27 17:12:00 theanets.trainer:168 RmsProp 358 loss=247.859451 err=21.567574
I 2015-05-27 17:12:02 theanets.trainer:168 RmsProp 359 loss=248.783493 err=22.550434
I 2015-05-27 17:12:04 theanets.trainer:168 RmsProp 360 loss=247.985443 err=22.023331
I 2015-05-27 17:12:04 theanets.trainer:168 validation 36 loss=1027.970459 err=801.941589
I 2015-05-27 17:12:06 theanets.trainer:168 RmsProp 361 loss=248.509079 err=22.520302
I 2015-05-27 17:12:08 theanets.trainer:168 RmsProp 362 loss=248.074554 err=22.364223
I 2015-05-27 17:12:10 theanets.trainer:168 RmsProp 363 loss=247.507538 err=21.862820
I 2015-05-27 17:12:12 theanets.trainer:168 RmsProp 364 loss=246.924713 err=21.468435
I 2015-05-27 17:12:14 theanets.trainer:168 RmsProp 365 loss=248.855682 err=23.619228
I 2015-05-27 17:12:16 theanets.trainer:168 RmsProp 366 loss=246.612595 err=21.390606
I 2015-05-27 17:12:17 theanets.trainer:168 RmsProp 367 loss=246.719452 err=21.817225
I 2015-05-27 17:12:19 theanets.trainer:168 RmsProp 368 loss=247.714355 err=22.830746
I 2015-05-27 17:12:21 theanets.trainer:168 RmsProp 369 loss=247.166458 err=22.474617
I 2015-05-27 17:12:23 theanets.trainer:168 RmsProp 370 loss=246.364716 err=21.758545
I 2015-05-27 17:12:23 theanets.trainer:168 validation 37 loss=1015.865723 err=790.998535 *
I 2015-05-27 17:12:25 theanets.trainer:168 RmsProp 371 loss=245.219604 err=20.798382
I 2015-05-27 17:12:27 theanets.trainer:168 RmsProp 372 loss=246.655029 err=22.402203
I 2015-05-27 17:12:29 theanets.trainer:168 RmsProp 373 loss=245.248993 err=21.017986
I 2015-05-27 17:12:31 theanets.trainer:168 RmsProp 374 loss=245.406097 err=21.502224
I 2015-05-27 17:12:33 theanets.trainer:168 RmsProp 375 loss=245.840424 err=21.900597
I 2015-05-27 17:12:35 theanets.trainer:168 RmsProp 376 loss=245.158157 err=21.473949
I 2015-05-27 17:12:37 theanets.trainer:168 RmsProp 377 loss=244.782135 err=21.207920
I 2015-05-27 17:12:39 theanets.trainer:168 RmsProp 378 loss=244.746780 err=21.265232
I 2015-05-27 17:12:41 theanets.trainer:168 RmsProp 379 loss=245.270905 err=22.005657
I 2015-05-27 17:12:42 theanets.trainer:168 RmsProp 380 loss=244.319702 err=21.123661
I 2015-05-27 17:12:43 theanets.trainer:168 validation 38 loss=1013.680725 err=790.549255 *
I 2015-05-27 17:12:45 theanets.trainer:168 RmsProp 381 loss=242.428619 err=19.464561
I 2015-05-27 17:12:46 theanets.trainer:168 RmsProp 382 loss=245.617722 err=22.629210
I 2015-05-27 17:12:48 theanets.trainer:168 RmsProp 383 loss=243.647751 err=20.939852
I 2015-05-27 17:12:50 theanets.trainer:168 RmsProp 384 loss=244.701202 err=22.028072
I 2015-05-27 17:12:52 theanets.trainer:168 RmsProp 385 loss=243.235397 err=20.709299
I 2015-05-27 17:12:54 theanets.trainer:168 RmsProp 386 loss=243.425690 err=21.137053
I 2015-05-27 17:12:56 theanets.trainer:168 RmsProp 387 loss=242.510284 err=20.192717
I 2015-05-27 17:12:58 theanets.trainer:168 RmsProp 388 loss=243.083420 err=21.094061
I 2015-05-27 17:13:00 theanets.trainer:168 RmsProp 389 loss=242.715057 err=20.715405
I 2015-05-27 17:13:02 theanets.trainer:168 RmsProp 390 loss=243.198807 err=21.393076
I 2015-05-27 17:13:02 theanets.trainer:168 validation 39 loss=1019.590454 err=797.964478
I 2015-05-27 17:13:04 theanets.trainer:168 RmsProp 391 loss=244.369995 err=22.604481
I 2015-05-27 17:13:06 theanets.trainer:168 RmsProp 392 loss=242.638016 err=21.048344
I 2015-05-27 17:13:07 theanets.trainer:168 RmsProp 393 loss=241.556473 err=20.102921
I 2015-05-27 17:13:09 theanets.trainer:168 RmsProp 394 loss=242.163330 err=20.767138
I 2015-05-27 17:13:11 theanets.trainer:168 RmsProp 395 loss=241.918915 err=20.821552
I 2015-05-27 17:13:13 theanets.trainer:168 RmsProp 396 loss=240.635712 err=19.505667
I 2015-05-27 17:13:15 theanets.trainer:168 RmsProp 397 loss=241.527863 err=20.656322
I 2015-05-27 17:13:17 theanets.trainer:168 RmsProp 398 loss=241.352661 err=20.598228
I 2015-05-27 17:13:19 theanets.trainer:168 RmsProp 399 loss=241.789261 err=21.073158
I 2015-05-27 17:13:21 theanets.trainer:168 RmsProp 400 loss=241.129791 err=20.622391
I 2015-05-27 17:13:21 theanets.trainer:168 validation 40 loss=1021.738708 err=800.851196
I 2015-05-27 17:13:23 theanets.trainer:168 RmsProp 401 loss=242.167389 err=21.681799
I 2015-05-27 17:13:25 theanets.trainer:168 RmsProp 402 loss=241.067184 err=20.814045
I 2015-05-27 17:13:27 theanets.trainer:168 RmsProp 403 loss=240.469727 err=20.207937
I 2015-05-27 17:13:29 theanets.trainer:168 RmsProp 404 loss=241.017044 err=21.027138
I 2015-05-27 17:13:31 theanets.trainer:168 RmsProp 405 loss=241.691254 err=21.683764
I 2015-05-27 17:13:32 theanets.trainer:168 RmsProp 406 loss=238.674149 err=18.819721
I 2015-05-27 17:13:34 theanets.trainer:168 RmsProp 407 loss=241.041656 err=21.413439
I 2015-05-27 17:13:36 theanets.trainer:168 RmsProp 408 loss=238.088425 err=18.448956
I 2015-05-27 17:13:38 theanets.trainer:168 RmsProp 409 loss=240.112869 err=20.728565
I 2015-05-27 17:13:40 theanets.trainer:168 RmsProp 410 loss=239.322998 err=19.988949
I 2015-05-27 17:13:40 theanets.trainer:168 validation 41 loss=1011.563904 err=792.028381 *
I 2015-05-27 17:13:42 theanets.trainer:168 RmsProp 411 loss=239.499908 err=20.330048
I 2015-05-27 17:13:44 theanets.trainer:168 RmsProp 412 loss=240.146576 err=21.053833
I 2015-05-27 17:13:46 theanets.trainer:168 RmsProp 413 loss=238.756561 err=19.814672
I 2015-05-27 17:13:48 theanets.trainer:168 RmsProp 414 loss=239.770187 err=20.972416
I 2015-05-27 17:13:50 theanets.trainer:168 RmsProp 415 loss=237.378784 err=18.587345
I 2015-05-27 17:13:52 theanets.trainer:168 RmsProp 416 loss=239.890457 err=21.400305
I 2015-05-27 17:13:54 theanets.trainer:168 RmsProp 417 loss=236.861176 err=18.251671
I 2015-05-27 17:13:55 theanets.trainer:168 RmsProp 418 loss=238.301117 err=19.980789
I 2015-05-27 17:13:57 theanets.trainer:168 RmsProp 419 loss=237.801971 err=19.550274
I 2015-05-27 17:13:59 theanets.trainer:168 RmsProp 420 loss=237.740112 err=19.601892
I 2015-05-27 17:13:59 theanets.trainer:168 validation 42 loss=1005.787048 err=788.314758 *
I 2015-05-27 17:14:01 theanets.trainer:168 RmsProp 421 loss=236.854462 err=18.910805
I 2015-05-27 17:14:03 theanets.trainer:168 RmsProp 422 loss=237.533859 err=19.671713
I 2015-05-27 17:14:05 theanets.trainer:168 RmsProp 423 loss=237.094208 err=19.407078
I 2015-05-27 17:14:07 theanets.trainer:168 RmsProp 424 loss=238.417358 err=20.699121
I 2015-05-27 17:14:09 theanets.trainer:168 RmsProp 425 loss=236.579834 err=19.105444
I 2015-05-27 17:14:11 theanets.trainer:168 RmsProp 426 loss=237.684158 err=20.227911
I 2015-05-27 17:14:13 theanets.trainer:168 RmsProp 427 loss=237.282028 err=19.896885
I 2015-05-27 17:14:15 theanets.trainer:168 RmsProp 428 loss=235.945023 err=18.838078
I 2015-05-27 17:14:16 theanets.trainer:168 RmsProp 429 loss=237.461700 err=20.246609
I 2015-05-27 17:14:18 theanets.trainer:168 RmsProp 430 loss=236.045731 err=19.116322
I 2015-05-27 17:14:19 theanets.trainer:168 validation 43 loss=1017.891541 err=800.696289
I 2015-05-27 17:14:20 theanets.trainer:168 RmsProp 431 loss=236.972000 err=20.034672
I 2015-05-27 17:14:22 theanets.trainer:168 RmsProp 432 loss=237.456329 err=20.721966
I 2015-05-27 17:14:24 theanets.trainer:168 RmsProp 433 loss=235.513306 err=18.820698
I 2015-05-27 17:14:26 theanets.trainer:168 RmsProp 434 loss=236.026489 err=19.493587
I 2015-05-27 17:14:28 theanets.trainer:168 RmsProp 435 loss=234.989655 err=18.597139
I 2015-05-27 17:14:30 theanets.trainer:168 RmsProp 436 loss=235.479126 err=19.125683
I 2015-05-27 17:14:32 theanets.trainer:168 RmsProp 437 loss=235.798660 err=19.705330
I 2015-05-27 17:14:34 theanets.trainer:168 RmsProp 438 loss=235.777924 err=19.589264
I 2015-05-27 17:14:36 theanets.trainer:168 RmsProp 439 loss=235.084381 err=19.126328
I 2015-05-27 17:14:38 theanets.trainer:168 RmsProp 440 loss=234.417816 err=18.551664
I 2015-05-27 17:14:38 theanets.trainer:168 validation 44 loss=1003.955200 err=787.725891 *
I 2015-05-27 17:14:40 theanets.trainer:168 RmsProp 441 loss=235.049072 err=19.250835
I 2015-05-27 17:14:42 theanets.trainer:168 RmsProp 442 loss=234.435028 err=18.810852
I 2015-05-27 17:14:43 theanets.trainer:168 RmsProp 443 loss=233.820953 err=18.235531
I 2015-05-27 17:14:45 theanets.trainer:168 RmsProp 444 loss=235.027985 err=19.657770
I 2015-05-27 17:14:47 theanets.trainer:168 RmsProp 445 loss=234.526077 err=19.108496
I 2015-05-27 17:14:49 theanets.trainer:168 RmsProp 446 loss=235.431732 err=20.280704
I 2015-05-27 17:14:51 theanets.trainer:168 RmsProp 447 loss=234.114822 err=18.926670
I 2015-05-27 17:14:53 theanets.trainer:168 RmsProp 448 loss=233.102814 err=18.065735
I 2015-05-27 17:14:55 theanets.trainer:168 RmsProp 449 loss=234.021317 err=19.182789
I 2015-05-27 17:14:57 theanets.trainer:168 RmsProp 450 loss=233.815262 err=18.892107
I 2015-05-27 17:14:57 theanets.trainer:168 validation 45 loss=1002.382446 err=787.767883 *
I 2015-05-27 17:14:59 theanets.trainer:168 RmsProp 451 loss=233.380829 err=18.726282
I 2015-05-27 17:15:01 theanets.trainer:168 RmsProp 452 loss=232.114670 err=17.485952
I 2015-05-27 17:15:03 theanets.trainer:168 RmsProp 453 loss=233.627167 err=19.155464
I 2015-05-27 17:15:05 theanets.trainer:168 RmsProp 454 loss=234.542068 err=20.102518
I 2015-05-27 17:15:07 theanets.trainer:168 RmsProp 455 loss=231.025955 err=16.770567
I 2015-05-27 17:15:09 theanets.trainer:168 RmsProp 456 loss=234.238922 err=20.101437
I 2015-05-27 17:15:11 theanets.trainer:168 RmsProp 457 loss=232.531448 err=18.352907
I 2015-05-27 17:15:13 theanets.trainer:168 RmsProp 458 loss=232.581909 err=18.708551
I 2015-05-27 17:15:15 theanets.trainer:168 RmsProp 459 loss=231.912033 err=17.930605
I 2015-05-27 17:15:16 theanets.trainer:168 RmsProp 460 loss=233.371384 err=19.637100
I 2015-05-27 17:15:17 theanets.trainer:168 validation 46 loss=1000.812378 err=787.010559 *
I 2015-05-27 17:15:19 theanets.trainer:168 RmsProp 461 loss=231.702438 err=17.957932
I 2015-05-27 17:15:21 theanets.trainer:168 RmsProp 462 loss=231.137238 err=17.497723
I 2015-05-27 17:15:23 theanets.trainer:168 RmsProp 463 loss=232.657639 err=19.182116
I 2015-05-27 17:15:25 theanets.trainer:168 RmsProp 464 loss=230.418854 err=17.012341
I 2015-05-27 17:15:27 theanets.trainer:168 RmsProp 465 loss=232.699509 err=19.432394
I 2015-05-27 17:15:29 theanets.trainer:168 RmsProp 466 loss=231.958984 err=18.662151
I 2015-05-27 17:15:31 theanets.trainer:168 RmsProp 467 loss=229.921783 err=16.894094
I 2015-05-27 17:15:33 theanets.trainer:168 RmsProp 468 loss=231.859055 err=18.807600
I 2015-05-27 17:15:35 theanets.trainer:168 RmsProp 469 loss=232.245453 err=19.286209
I 2015-05-27 17:15:37 theanets.trainer:168 RmsProp 470 loss=231.810135 err=19.055534
I 2015-05-27 17:15:37 theanets.trainer:168 validation 47 loss=1000.832153 err=787.595215
I 2015-05-27 17:15:39 theanets.trainer:168 RmsProp 471 loss=230.423874 err=17.586607
I 2015-05-27 17:15:41 theanets.trainer:168 RmsProp 472 loss=230.094559 err=17.555843
I 2015-05-27 17:15:42 theanets.trainer:168 RmsProp 473 loss=231.526581 err=18.922106
I 2015-05-27 17:15:44 theanets.trainer:168 RmsProp 474 loss=230.114380 err=17.691149
I 2015-05-27 17:15:46 theanets.trainer:168 RmsProp 475 loss=230.107788 err=17.682858
I 2015-05-27 17:15:48 theanets.trainer:168 RmsProp 476 loss=232.167038 err=19.861469
I 2015-05-27 17:15:50 theanets.trainer:168 RmsProp 477 loss=231.028717 err=18.761992
I 2015-05-27 17:15:52 theanets.trainer:168 RmsProp 478 loss=230.748383 err=18.512503
I 2015-05-27 17:15:54 theanets.trainer:168 RmsProp 479 loss=229.262650 err=17.290720
I 2015-05-27 17:15:56 theanets.trainer:168 RmsProp 480 loss=229.921234 err=17.883734
I 2015-05-27 17:15:56 theanets.trainer:168 validation 48 loss=1004.561890 err=792.570374
I 2015-05-27 17:15:58 theanets.trainer:168 RmsProp 481 loss=229.872513 err=18.050003
I 2015-05-27 17:16:00 theanets.trainer:168 RmsProp 482 loss=229.071686 err=17.330870
I 2015-05-27 17:16:02 theanets.trainer:168 RmsProp 483 loss=229.871613 err=18.165936
I 2015-05-27 17:16:04 theanets.trainer:168 RmsProp 484 loss=229.922241 err=18.381170
I 2015-05-27 17:16:06 theanets.trainer:168 RmsProp 485 loss=228.880157 err=17.357162
I 2015-05-27 17:16:07 theanets.trainer:168 RmsProp 486 loss=229.453857 err=18.134241
I 2015-05-27 17:16:09 theanets.trainer:168 RmsProp 487 loss=229.460907 err=18.072147
I 2015-05-27 17:16:11 theanets.trainer:168 RmsProp 488 loss=229.567551 err=18.445469
I 2015-05-27 17:16:13 theanets.trainer:168 RmsProp 489 loss=228.639374 err=17.458294
I 2015-05-27 17:16:15 theanets.trainer:168 RmsProp 490 loss=227.954193 err=16.903551
I 2015-05-27 17:16:15 theanets.trainer:168 validation 49 loss=998.978455 err=788.414185 *
I 2015-05-27 17:16:17 theanets.trainer:168 RmsProp 491 loss=229.824310 err=18.943493
I 2015-05-27 17:16:19 theanets.trainer:168 RmsProp 492 loss=227.771393 err=16.840174
I 2015-05-27 17:16:21 theanets.trainer:168 RmsProp 493 loss=229.290619 err=18.588583
I 2015-05-27 17:16:23 theanets.trainer:168 RmsProp 494 loss=228.457230 err=17.768780
I 2015-05-27 17:16:25 theanets.trainer:168 RmsProp 495 loss=228.433197 err=17.879484
I 2015-05-27 17:16:27 theanets.trainer:168 RmsProp 496 loss=227.804657 err=17.283073
I 2015-05-27 17:16:29 theanets.trainer:168 RmsProp 497 loss=228.184494 err=17.791040
I 2015-05-27 17:16:30 theanets.trainer:168 RmsProp 498 loss=227.575836 err=17.311104
I 2015-05-27 17:16:32 theanets.trainer:168 RmsProp 499 loss=227.757111 err=17.469782
I 2015-05-27 17:16:34 theanets.trainer:168 RmsProp 500 loss=227.789627 err=17.777088
I 2015-05-27 17:16:34 theanets.trainer:168 validation 50 loss=1005.555542 err=795.149231
I 2015-05-27 17:16:36 theanets.trainer:168 RmsProp 501 loss=228.055756 err=17.924011
I 2015-05-27 17:16:38 theanets.trainer:168 RmsProp 502 loss=227.256668 err=17.370266
I 2015-05-27 17:16:40 theanets.trainer:168 RmsProp 503 loss=227.862671 err=17.979973
I 2015-05-27 17:16:42 theanets.trainer:168 RmsProp 504 loss=226.900146 err=17.071507
I 2015-05-27 17:16:44 theanets.trainer:168 RmsProp 505 loss=227.025848 err=17.344082
I 2015-05-27 17:16:46 theanets.trainer:168 RmsProp 506 loss=226.513214 err=16.877695
I 2015-05-27 17:16:48 theanets.trainer:168 RmsProp 507 loss=226.740768 err=17.267715
I 2015-05-27 17:16:50 theanets.trainer:168 RmsProp 508 loss=227.676605 err=18.179424
I 2015-05-27 17:16:52 theanets.trainer:168 RmsProp 509 loss=226.242142 err=16.953403
I 2015-05-27 17:16:53 theanets.trainer:168 RmsProp 510 loss=226.124802 err=16.848454
I 2015-05-27 17:16:54 theanets.trainer:168 validation 51 loss=1003.002869 err=793.618835
I 2015-05-27 17:16:56 theanets.trainer:168 RmsProp 511 loss=225.914352 err=16.724339
I 2015-05-27 17:16:57 theanets.trainer:168 RmsProp 512 loss=226.433426 err=17.468199
I 2015-05-27 17:16:59 theanets.trainer:168 RmsProp 513 loss=226.341797 err=17.255796
I 2015-05-27 17:17:01 theanets.trainer:168 RmsProp 514 loss=226.451416 err=17.611706
I 2015-05-27 17:17:03 theanets.trainer:168 RmsProp 515 loss=225.507126 err=16.633259
I 2015-05-27 17:17:05 theanets.trainer:168 RmsProp 516 loss=226.857269 err=18.155344
I 2015-05-27 17:17:07 theanets.trainer:168 RmsProp 517 loss=226.283524 err=17.603565
I 2015-05-27 17:17:09 theanets.trainer:168 RmsProp 518 loss=225.009430 err=16.471922
I 2015-05-27 17:17:11 theanets.trainer:168 RmsProp 519 loss=225.068268 err=16.626659
I 2015-05-27 17:17:13 theanets.trainer:168 RmsProp 520 loss=225.718430 err=17.257936
I 2015-05-27 17:17:13 theanets.trainer:168 validation 52 loss=1009.522949 err=801.160461
I 2015-05-27 17:17:15 theanets.trainer:168 RmsProp 521 loss=226.846558 err=18.606007
I 2015-05-27 17:17:17 theanets.trainer:168 RmsProp 522 loss=225.327347 err=16.983860
I 2015-05-27 17:17:19 theanets.trainer:168 RmsProp 523 loss=225.774124 err=17.632938
I 2015-05-27 17:17:20 theanets.trainer:168 RmsProp 524 loss=225.091156 err=16.980816
I 2015-05-27 17:17:22 theanets.trainer:168 RmsProp 525 loss=224.726120 err=16.629686
I 2015-05-27 17:17:24 theanets.trainer:168 RmsProp 526 loss=226.355347 err=18.434872
I 2015-05-27 17:17:26 theanets.trainer:168 RmsProp 527 loss=225.170609 err=17.266314
I 2015-05-27 17:17:28 theanets.trainer:168 RmsProp 528 loss=224.978851 err=17.274239
I 2015-05-27 17:17:30 theanets.trainer:168 RmsProp 529 loss=224.364456 err=16.578342
I 2015-05-27 17:17:32 theanets.trainer:168 RmsProp 530 loss=224.331635 err=16.828808
I 2015-05-27 17:17:32 theanets.trainer:168 validation 53 loss=995.233521 err=787.620544 *
I 2015-05-27 17:17:34 theanets.trainer:168 RmsProp 531 loss=224.480026 err=16.900316
I 2015-05-27 17:17:36 theanets.trainer:168 RmsProp 532 loss=223.965240 err=16.503181
I 2015-05-27 17:17:38 theanets.trainer:168 RmsProp 533 loss=224.370575 err=17.067265
I 2015-05-27 17:17:40 theanets.trainer:168 RmsProp 534 loss=224.598236 err=17.222994
I 2015-05-27 17:17:42 theanets.trainer:168 RmsProp 535 loss=224.007980 err=16.852797
I 2015-05-27 17:17:44 theanets.trainer:168 RmsProp 536 loss=223.639374 err=16.475054
I 2015-05-27 17:17:45 theanets.trainer:168 RmsProp 537 loss=224.360229 err=17.300297
I 2015-05-27 17:17:47 theanets.trainer:168 RmsProp 538 loss=223.268829 err=16.232281
I 2015-05-27 17:17:49 theanets.trainer:168 RmsProp 539 loss=223.856476 err=16.936703
I 2015-05-27 17:17:51 theanets.trainer:168 RmsProp 540 loss=223.245285 err=16.433231
I 2015-05-27 17:17:51 theanets.trainer:168 validation 54 loss=1003.445618 err=796.469421
I 2015-05-27 17:17:53 theanets.trainer:168 RmsProp 541 loss=223.428192 err=16.584219
I 2015-05-27 17:17:55 theanets.trainer:168 RmsProp 542 loss=224.769165 err=18.172356
I 2015-05-27 17:17:57 theanets.trainer:168 RmsProp 543 loss=221.660156 err=14.959862
I 2015-05-27 17:17:59 theanets.trainer:168 RmsProp 544 loss=224.493240 err=18.014143
I 2015-05-27 17:18:01 theanets.trainer:168 RmsProp 545 loss=224.115601 err=17.629469
I 2015-05-27 17:18:03 theanets.trainer:168 RmsProp 546 loss=222.856934 err=16.443369
I 2015-05-27 17:18:05 theanets.trainer:168 RmsProp 547 loss=222.031403 err=15.780428
I 2015-05-27 17:18:07 theanets.trainer:168 RmsProp 548 loss=223.897980 err=17.644138
I 2015-05-27 17:18:08 theanets.trainer:168 RmsProp 549 loss=221.890305 err=15.783338
I 2015-05-27 17:18:10 theanets.trainer:168 RmsProp 550 loss=223.409225 err=17.263735
I 2015-05-27 17:18:11 theanets.trainer:168 validation 55 loss=998.859802 err=792.570984
I 2015-05-27 17:18:12 theanets.trainer:168 RmsProp 551 loss=222.274170 err=16.346565
I 2015-05-27 17:18:14 theanets.trainer:168 RmsProp 552 loss=222.860672 err=16.889849
I 2015-05-27 17:18:16 theanets.trainer:168 RmsProp 553 loss=221.173538 err=15.301227
I 2015-05-27 17:18:18 theanets.trainer:168 RmsProp 554 loss=223.848541 err=18.145252
I 2015-05-27 17:18:20 theanets.trainer:168 RmsProp 555 loss=221.935257 err=16.151579
I 2015-05-27 17:18:22 theanets.trainer:168 RmsProp 556 loss=221.870758 err=16.334635
I 2015-05-27 17:18:24 theanets.trainer:168 RmsProp 557 loss=222.047073 err=16.439686
I 2015-05-27 17:18:26 theanets.trainer:168 RmsProp 558 loss=222.043549 err=16.580143
I 2015-05-27 17:18:28 theanets.trainer:168 RmsProp 559 loss=221.822662 err=16.350101
I 2015-05-27 17:18:30 theanets.trainer:168 RmsProp 560 loss=221.901047 err=16.580463
I 2015-05-27 17:18:30 theanets.trainer:168 validation 56 loss=993.445618 err=788.437927 *
I 2015-05-27 17:18:32 theanets.trainer:168 RmsProp 561 loss=221.789139 err=16.529541
I 2015-05-27 17:18:34 theanets.trainer:168 RmsProp 562 loss=221.101761 err=15.813070
I 2015-05-27 17:18:35 theanets.trainer:168 RmsProp 563 loss=221.240280 err=16.223070
I 2015-05-27 17:18:37 theanets.trainer:168 RmsProp 564 loss=221.448730 err=16.299755
I 2015-05-27 17:18:39 theanets.trainer:168 RmsProp 565 loss=221.386429 err=16.434450
I 2015-05-27 17:18:41 theanets.trainer:168 RmsProp 566 loss=221.159027 err=16.264442
I 2015-05-27 17:18:43 theanets.trainer:168 RmsProp 567 loss=221.573410 err=16.675560
I 2015-05-27 17:18:45 theanets.trainer:168 RmsProp 568 loss=220.680420 err=15.949519
I 2015-05-27 17:18:47 theanets.trainer:168 RmsProp 569 loss=221.214920 err=16.448666
I 2015-05-27 17:18:49 theanets.trainer:168 RmsProp 570 loss=221.258911 err=16.679529
I 2015-05-27 17:18:49 theanets.trainer:168 validation 57 loss=1001.650574 err=796.950500
I 2015-05-27 17:18:51 theanets.trainer:168 RmsProp 571 loss=221.203659 err=16.545410
I 2015-05-27 17:18:53 theanets.trainer:168 RmsProp 572 loss=220.734894 err=16.318674
I 2015-05-27 17:18:55 theanets.trainer:168 RmsProp 573 loss=221.511688 err=17.005278
I 2015-05-27 17:18:57 theanets.trainer:168 RmsProp 574 loss=220.468185 err=16.062284
I 2015-05-27 17:18:59 theanets.trainer:168 RmsProp 575 loss=219.434525 err=15.211833
I 2015-05-27 17:19:01 theanets.trainer:168 RmsProp 576 loss=221.183502 err=16.878674
I 2015-05-27 17:19:02 theanets.trainer:168 RmsProp 577 loss=220.496872 err=16.414127
I 2015-05-27 17:19:04 theanets.trainer:168 RmsProp 578 loss=219.780060 err=15.663646
I 2015-05-27 17:19:06 theanets.trainer:168 RmsProp 579 loss=219.905197 err=15.934331
I 2015-05-27 17:19:08 theanets.trainer:168 RmsProp 580 loss=220.553665 err=16.562389
I 2015-05-27 17:19:08 theanets.trainer:168 validation 58 loss=991.330322 err=787.028198 *
I 2015-05-27 17:19:10 theanets.trainer:168 RmsProp 581 loss=219.922852 err=16.022087
I 2015-05-27 17:19:12 theanets.trainer:168 RmsProp 582 loss=220.122391 err=16.321503
I 2015-05-27 17:19:14 theanets.trainer:168 RmsProp 583 loss=219.267944 err=15.462016
I 2015-05-27 17:19:16 theanets.trainer:168 RmsProp 584 loss=220.290985 err=16.744160
I 2015-05-27 17:19:18 theanets.trainer:168 RmsProp 585 loss=219.436676 err=15.740687
I 2015-05-27 17:19:20 theanets.trainer:168 RmsProp 586 loss=218.962921 err=15.494087
I 2015-05-27 17:19:22 theanets.trainer:168 RmsProp 587 loss=219.144440 err=15.682053
I 2015-05-27 17:19:24 theanets.trainer:168 RmsProp 588 loss=218.663818 err=15.250110
I 2015-05-27 17:19:26 theanets.trainer:168 RmsProp 589 loss=218.888138 err=15.612902
I 2015-05-27 17:19:28 theanets.trainer:168 RmsProp 590 loss=219.200317 err=15.944641
I 2015-05-27 17:19:28 theanets.trainer:168 validation 59 loss=1004.961975 err=801.717651
I 2015-05-27 17:19:30 theanets.trainer:168 RmsProp 591 loss=217.902054 err=14.803205
I 2015-05-27 17:19:32 theanets.trainer:168 RmsProp 592 loss=219.892044 err=16.739025
I 2015-05-27 17:19:34 theanets.trainer:168 RmsProp 593 loss=219.290131 err=16.336166
I 2015-05-27 17:19:35 theanets.trainer:168 RmsProp 594 loss=218.775879 err=15.783113
I 2015-05-27 17:19:37 theanets.trainer:168 RmsProp 595 loss=217.672729 err=14.778775
I 2015-05-27 17:19:39 theanets.trainer:168 RmsProp 596 loss=218.227142 err=15.513964
I 2015-05-27 17:19:41 theanets.trainer:168 RmsProp 597 loss=218.980270 err=16.128521
I 2015-05-27 17:19:43 theanets.trainer:168 RmsProp 598 loss=218.453812 err=15.844134
I 2015-05-27 17:19:45 theanets.trainer:168 RmsProp 599 loss=217.206421 err=14.586034
I 2015-05-27 17:19:47 theanets.trainer:168 RmsProp 600 loss=219.641602 err=17.140577
I 2015-05-27 17:19:47 theanets.trainer:168 validation 60 loss=1006.694763 err=804.364075
I 2015-05-27 17:19:49 theanets.trainer:168 RmsProp 601 loss=218.699951 err=16.180307
I 2015-05-27 17:19:51 theanets.trainer:168 RmsProp 602 loss=217.539215 err=15.169993
I 2015-05-27 17:19:53 theanets.trainer:168 RmsProp 603 loss=218.207474 err=15.910238
I 2015-05-27 17:19:55 theanets.trainer:168 RmsProp 604 loss=217.487137 err=15.151230
I 2015-05-27 17:19:57 theanets.trainer:168 RmsProp 605 loss=218.239227 err=16.152185
I 2015-05-27 17:19:59 theanets.trainer:168 RmsProp 606 loss=217.175934 err=14.982109
I 2015-05-27 17:20:00 theanets.trainer:168 RmsProp 607 loss=218.257401 err=16.246767
I 2015-05-27 17:20:02 theanets.trainer:168 RmsProp 608 loss=217.159454 err=15.191042
I 2015-05-27 17:20:04 theanets.trainer:168 RmsProp 609 loss=217.588455 err=15.634618
I 2015-05-27 17:20:06 theanets.trainer:168 RmsProp 610 loss=217.825119 err=16.030020
I 2015-05-27 17:20:06 theanets.trainer:168 validation 61 loss=998.660583 err=796.400208
I 2015-05-27 17:20:08 theanets.trainer:168 RmsProp 611 loss=217.606354 err=15.768202
I 2015-05-27 17:20:10 theanets.trainer:168 RmsProp 612 loss=217.322098 err=15.659183
I 2015-05-27 17:20:12 theanets.trainer:168 RmsProp 613 loss=217.131958 err=15.403214
I 2015-05-27 17:20:14 theanets.trainer:168 RmsProp 614 loss=217.342896 err=15.855565
I 2015-05-27 17:20:16 theanets.trainer:168 RmsProp 615 loss=216.468994 err=14.893553
I 2015-05-27 17:20:18 theanets.trainer:168 RmsProp 616 loss=217.421097 err=15.943263
I 2015-05-27 17:20:20 theanets.trainer:168 RmsProp 617 loss=217.056076 err=15.750221
I 2015-05-27 17:20:22 theanets.trainer:168 RmsProp 618 loss=216.764084 err=15.365219
I 2015-05-27 17:20:24 theanets.trainer:168 RmsProp 619 loss=216.371246 err=15.160858
I 2015-05-27 17:20:26 theanets.trainer:168 RmsProp 620 loss=216.924881 err=15.706457
I 2015-05-27 17:20:26 theanets.trainer:168 validation 62 loss=990.297729 err=788.817383 *
I 2015-05-27 17:20:28 theanets.trainer:168 RmsProp 621 loss=216.489670 err=15.390233
I 2015-05-27 17:20:30 theanets.trainer:168 RmsProp 622 loss=216.692673 err=15.598570
I 2015-05-27 17:20:31 theanets.trainer:168 RmsProp 623 loss=216.898727 err=15.900253
I 2015-05-27 17:20:33 theanets.trainer:168 RmsProp 624 loss=215.542923 err=14.670404
I 2015-05-27 17:20:35 theanets.trainer:168 RmsProp 625 loss=216.824875 err=15.906639
I 2015-05-27 17:20:37 theanets.trainer:168 RmsProp 626 loss=216.302170 err=15.639656
I 2015-05-27 17:20:39 theanets.trainer:168 RmsProp 627 loss=215.260040 err=14.461233
I 2015-05-27 17:20:41 theanets.trainer:168 RmsProp 628 loss=216.150543 err=15.581060
I 2015-05-27 17:20:43 theanets.trainer:168 RmsProp 629 loss=216.575027 err=16.008141
I 2015-05-27 17:20:45 theanets.trainer:168 RmsProp 630 loss=214.849457 err=14.324396
I 2015-05-27 17:20:45 theanets.trainer:168 validation 63 loss=990.923767 err=790.948181
I 2015-05-27 17:20:47 theanets.trainer:168 RmsProp 631 loss=216.109177 err=15.699231
I 2015-05-27 17:20:49 theanets.trainer:168 RmsProp 632 loss=215.527786 err=15.123739
I 2015-05-27 17:20:51 theanets.trainer:168 RmsProp 633 loss=215.315918 err=15.059545
I 2015-05-27 17:20:53 theanets.trainer:168 RmsProp 634 loss=216.461868 err=16.143675
I 2015-05-27 17:20:55 theanets.trainer:168 RmsProp 635 loss=215.452667 err=15.324112
I 2015-05-27 17:20:57 theanets.trainer:168 RmsProp 636 loss=213.810501 err=13.682669
I 2015-05-27 17:20:59 theanets.trainer:168 RmsProp 637 loss=215.523849 err=15.444237
I 2015-05-27 17:21:00 theanets.trainer:168 RmsProp 638 loss=215.209442 err=15.320074
I 2015-05-27 17:21:02 theanets.trainer:168 RmsProp 639 loss=215.272949 err=15.254686
I 2015-05-27 17:21:04 theanets.trainer:168 RmsProp 640 loss=215.498871 err=15.701563
I 2015-05-27 17:21:04 theanets.trainer:168 validation 64 loss=1003.616699 err=803.495789
I 2015-05-27 17:21:06 theanets.trainer:168 RmsProp 641 loss=215.877151 err=16.022619
I 2015-05-27 17:21:08 theanets.trainer:168 RmsProp 642 loss=214.556107 err=14.843875
I 2015-05-27 17:21:10 theanets.trainer:168 RmsProp 643 loss=215.099808 err=15.368106
I 2015-05-27 17:21:12 theanets.trainer:168 RmsProp 644 loss=214.070160 err=14.443690
I 2015-05-27 17:21:14 theanets.trainer:168 RmsProp 645 loss=214.728149 err=15.168344
I 2015-05-27 17:21:16 theanets.trainer:168 RmsProp 646 loss=214.624054 err=15.040422
I 2015-05-27 17:21:18 theanets.trainer:168 RmsProp 647 loss=213.836624 err=14.501783
I 2015-05-27 17:21:20 theanets.trainer:168 RmsProp 648 loss=214.814163 err=15.354321
I 2015-05-27 17:21:22 theanets.trainer:168 RmsProp 649 loss=213.868622 err=14.586439
I 2015-05-27 17:21:24 theanets.trainer:168 RmsProp 650 loss=214.414032 err=15.171702
I 2015-05-27 17:21:24 theanets.trainer:168 validation 65 loss=993.611450 err=793.952942
I 2015-05-27 17:21:26 theanets.trainer:168 RmsProp 651 loss=214.172150 err=14.935242
I 2015-05-27 17:21:28 theanets.trainer:168 RmsProp 652 loss=214.819122 err=15.724310
I 2015-05-27 17:21:30 theanets.trainer:168 RmsProp 653 loss=214.923615 err=15.787085
I 2015-05-27 17:21:31 theanets.trainer:168 RmsProp 654 loss=213.616699 err=14.646581
I 2015-05-27 17:21:33 theanets.trainer:168 RmsProp 655 loss=215.278610 err=16.205536
I 2015-05-27 17:21:35 theanets.trainer:168 RmsProp 656 loss=213.439255 err=14.600080
I 2015-05-27 17:21:37 theanets.trainer:168 RmsProp 657 loss=213.711334 err=14.806997
I 2015-05-27 17:21:39 theanets.trainer:168 RmsProp 658 loss=213.503143 err=14.684107
I 2015-05-27 17:21:41 theanets.trainer:168 RmsProp 659 loss=213.400436 err=14.725245
I 2015-05-27 17:21:43 theanets.trainer:168 RmsProp 660 loss=213.356201 err=14.598979
I 2015-05-27 17:21:43 theanets.trainer:168 validation 66 loss=990.013306 err=791.530762 *
I 2015-05-27 17:21:45 theanets.trainer:168 RmsProp 661 loss=213.037064 err=14.486232
I 2015-05-27 17:21:47 theanets.trainer:168 RmsProp 662 loss=213.287506 err=14.694613
I 2015-05-27 17:21:49 theanets.trainer:168 RmsProp 663 loss=212.131836 err=13.674602
I 2015-05-27 17:21:51 theanets.trainer:168 RmsProp 664 loss=213.680634 err=15.226598
I 2015-05-27 17:21:53 theanets.trainer:168 RmsProp 665 loss=212.792389 err=14.429385
I 2015-05-27 17:21:55 theanets.trainer:168 RmsProp 666 loss=213.378082 err=15.112013
I 2015-05-27 17:21:56 theanets.trainer:168 RmsProp 667 loss=214.110840 err=15.792557
I 2015-05-27 17:21:58 theanets.trainer:168 RmsProp 668 loss=212.505783 err=14.448359
I 2015-05-27 17:22:00 theanets.trainer:168 RmsProp 669 loss=212.867432 err=14.660551
I 2015-05-27 17:22:02 theanets.trainer:168 RmsProp 670 loss=212.516312 err=14.477850
I 2015-05-27 17:22:02 theanets.trainer:168 validation 67 loss=989.917969 err=791.830017 *
I 2015-05-27 17:22:04 theanets.trainer:168 RmsProp 671 loss=213.163055 err=15.114682
I 2015-05-27 17:22:06 theanets.trainer:168 RmsProp 672 loss=212.889496 err=14.870809
I 2015-05-27 17:22:08 theanets.trainer:168 RmsProp 673 loss=212.277985 err=14.391955
I 2015-05-27 17:22:10 theanets.trainer:168 RmsProp 674 loss=212.795258 err=14.914879
I 2015-05-27 17:22:12 theanets.trainer:168 RmsProp 675 loss=211.769531 err=14.014181
I 2015-05-27 17:22:14 theanets.trainer:168 RmsProp 676 loss=212.088699 err=14.278006
I 2015-05-27 17:22:16 theanets.trainer:168 RmsProp 677 loss=212.947922 err=15.328178
I 2015-05-27 17:22:18 theanets.trainer:168 RmsProp 678 loss=212.636444 err=14.955545
I 2015-05-27 17:22:20 theanets.trainer:168 RmsProp 679 loss=212.263351 err=14.645169
I 2015-05-27 17:22:21 theanets.trainer:168 RmsProp 680 loss=211.360382 err=13.943153
I 2015-05-27 17:22:22 theanets.trainer:168 validation 68 loss=1000.635986 err=802.716248
I 2015-05-27 17:22:24 theanets.trainer:168 RmsProp 681 loss=212.212601 err=14.653778
I 2015-05-27 17:22:25 theanets.trainer:168 RmsProp 682 loss=212.167313 err=14.823117
I 2015-05-27 17:22:27 theanets.trainer:168 RmsProp 683 loss=212.026657 err=14.615934
I 2015-05-27 17:22:29 theanets.trainer:168 RmsProp 684 loss=212.772171 err=15.466481
I 2015-05-27 17:22:31 theanets.trainer:168 RmsProp 685 loss=212.209869 err=14.895228
I 2015-05-27 17:22:33 theanets.trainer:168 RmsProp 686 loss=211.645462 err=14.447108
I 2015-05-27 17:22:35 theanets.trainer:168 RmsProp 687 loss=212.283127 err=15.132986
I 2015-05-27 17:22:37 theanets.trainer:168 RmsProp 688 loss=211.308762 err=14.142085
I 2015-05-27 17:22:39 theanets.trainer:168 RmsProp 689 loss=211.715820 err=14.774976
I 2015-05-27 17:22:41 theanets.trainer:168 RmsProp 690 loss=211.648727 err=14.559911
I 2015-05-27 17:22:41 theanets.trainer:168 validation 69 loss=993.062500 err=795.995605
I 2015-05-27 17:22:43 theanets.trainer:168 RmsProp 691 loss=211.576859 err=14.676788
I 2015-05-27 17:22:45 theanets.trainer:168 RmsProp 692 loss=211.506516 err=14.638049
I 2015-05-27 17:22:47 theanets.trainer:168 RmsProp 693 loss=210.491653 err=13.607153
I 2015-05-27 17:22:49 theanets.trainer:168 RmsProp 694 loss=210.841095 err=14.146594
I 2015-05-27 17:22:51 theanets.trainer:168 RmsProp 695 loss=211.142166 err=14.419695
I 2015-05-27 17:22:52 theanets.trainer:168 RmsProp 696 loss=210.958160 err=14.380936
I 2015-05-27 17:22:54 theanets.trainer:168 RmsProp 697 loss=211.256592 err=14.600420
I 2015-05-27 17:22:56 theanets.trainer:168 RmsProp 698 loss=210.710007 err=14.269984
I 2015-05-27 17:22:58 theanets.trainer:168 RmsProp 699 loss=211.125778 err=14.603434
I 2015-05-27 17:23:00 theanets.trainer:168 RmsProp 700 loss=210.771606 err=14.306643
I 2015-05-27 17:23:00 theanets.trainer:168 validation 70 loss=991.457886 err=795.411316
I 2015-05-27 17:23:02 theanets.trainer:168 RmsProp 701 loss=210.310272 err=14.008921
I 2015-05-27 17:23:04 theanets.trainer:168 RmsProp 702 loss=211.212982 err=14.822830
I 2015-05-27 17:23:06 theanets.trainer:168 RmsProp 703 loss=210.174484 err=13.957850
I 2015-05-27 17:23:08 theanets.trainer:168 RmsProp 704 loss=211.647064 err=15.401402
I 2015-05-27 17:23:10 theanets.trainer:168 RmsProp 705 loss=210.696945 err=14.552221
I 2015-05-27 17:23:12 theanets.trainer:168 RmsProp 706 loss=210.635941 err=14.464586
I 2015-05-27 17:23:14 theanets.trainer:168 RmsProp 707 loss=210.218994 err=14.131142
I 2015-05-27 17:23:16 theanets.trainer:168 RmsProp 708 loss=209.617767 err=13.632391
I 2015-05-27 17:23:18 theanets.trainer:168 RmsProp 709 loss=210.350677 err=14.294554
I 2015-05-27 17:23:19 theanets.trainer:168 RmsProp 710 loss=211.010300 err=15.173281
I 2015-05-27 17:23:20 theanets.trainer:168 validation 71 loss=994.844116 err=798.527405
I 2015-05-27 17:23:22 theanets.trainer:168 RmsProp 711 loss=210.585602 err=14.602890
I 2015-05-27 17:23:23 theanets.trainer:168 RmsProp 712 loss=211.112350 err=15.320226
I 2015-05-27 17:23:25 theanets.trainer:168 RmsProp 713 loss=209.305939 err=13.519633
I 2015-05-27 17:23:27 theanets.trainer:168 RmsProp 714 loss=211.346771 err=15.580106
I 2015-05-27 17:23:29 theanets.trainer:168 RmsProp 715 loss=209.106720 err=13.490089
I 2015-05-27 17:23:31 theanets.trainer:168 RmsProp 716 loss=209.591156 err=13.961026
I 2015-05-27 17:23:33 theanets.trainer:168 RmsProp 717 loss=211.071335 err=15.522453
I 2015-05-27 17:23:35 theanets.trainer:168 RmsProp 718 loss=209.160568 err=13.568339
I 2015-05-27 17:23:37 theanets.trainer:168 RmsProp 719 loss=210.316360 err=14.923167
I 2015-05-27 17:23:39 theanets.trainer:168 RmsProp 720 loss=209.389069 err=13.914691
I 2015-05-27 17:23:39 theanets.trainer:168 validation 72 loss=989.568970 err=793.955261 *
I 2015-05-27 17:23:41 theanets.trainer:168 RmsProp 721 loss=207.971634 err=12.593139
I 2015-05-27 17:23:43 theanets.trainer:168 RmsProp 722 loss=209.648514 err=14.434812
I 2015-05-27 17:23:45 theanets.trainer:168 RmsProp 723 loss=208.998932 err=13.660541
I 2015-05-27 17:23:47 theanets.trainer:168 RmsProp 724 loss=209.139481 err=14.021937
I 2015-05-27 17:23:48 theanets.trainer:168 RmsProp 725 loss=208.720749 err=13.564096
I 2015-05-27 17:23:50 theanets.trainer:168 RmsProp 726 loss=209.248810 err=14.202057
I 2015-05-27 17:23:52 theanets.trainer:168 RmsProp 727 loss=209.142578 err=14.074312
I 2015-05-27 17:23:54 theanets.trainer:168 RmsProp 728 loss=209.309158 err=14.348379
I 2015-05-27 17:23:56 theanets.trainer:168 RmsProp 729 loss=208.642426 err=13.739601
I 2015-05-27 17:23:58 theanets.trainer:168 RmsProp 730 loss=208.619720 err=13.683393
I 2015-05-27 17:23:58 theanets.trainer:168 validation 73 loss=987.004211 err=792.181030 *
I 2015-05-27 17:24:00 theanets.trainer:168 RmsProp 731 loss=208.850342 err=14.149824
I 2015-05-27 17:24:02 theanets.trainer:168 RmsProp 732 loss=208.761429 err=13.923495
I 2015-05-27 17:24:04 theanets.trainer:168 RmsProp 733 loss=208.704956 err=14.042961
I 2015-05-27 17:24:06 theanets.trainer:168 RmsProp 734 loss=209.258148 err=14.611525
I 2015-05-27 17:24:08 theanets.trainer:168 RmsProp 735 loss=208.087448 err=13.431005
I 2015-05-27 17:24:10 theanets.trainer:168 RmsProp 736 loss=208.760895 err=14.265348
I 2015-05-27 17:24:12 theanets.trainer:168 RmsProp 737 loss=208.769562 err=14.214073
I 2015-05-27 17:24:14 theanets.trainer:168 RmsProp 738 loss=208.210785 err=13.827724
I 2015-05-27 17:24:16 theanets.trainer:168 RmsProp 739 loss=209.161224 err=14.685321
I 2015-05-27 17:24:17 theanets.trainer:168 RmsProp 740 loss=207.845825 err=13.569017
I 2015-05-27 17:24:18 theanets.trainer:168 validation 74 loss=987.614075 err=793.260681
I 2015-05-27 17:24:20 theanets.trainer:168 RmsProp 741 loss=208.337112 err=13.989122
I 2015-05-27 17:24:21 theanets.trainer:168 RmsProp 742 loss=208.066650 err=13.788745
I 2015-05-27 17:24:23 theanets.trainer:168 RmsProp 743 loss=207.865204 err=13.738581
I 2015-05-27 17:24:25 theanets.trainer:168 RmsProp 744 loss=208.974243 err=14.726160
I 2015-05-27 17:24:27 theanets.trainer:168 RmsProp 745 loss=207.268280 err=13.230219
I 2015-05-27 17:24:29 theanets.trainer:168 RmsProp 746 loss=207.930634 err=13.835579
I 2015-05-27 17:24:31 theanets.trainer:168 RmsProp 747 loss=207.657257 err=13.648084
I 2015-05-27 17:24:33 theanets.trainer:168 RmsProp 748 loss=208.017822 err=14.014132
I 2015-05-27 17:24:35 theanets.trainer:168 RmsProp 749 loss=208.349655 err=14.412111
I 2015-05-27 17:24:37 theanets.trainer:168 RmsProp 750 loss=207.991989 err=14.142825
I 2015-05-27 17:24:37 theanets.trainer:168 validation 75 loss=985.757751 err=791.697937 *
I 2015-05-27 17:24:39 theanets.trainer:168 RmsProp 751 loss=207.417801 err=13.526609
I 2015-05-27 17:24:41 theanets.trainer:168 RmsProp 752 loss=207.669022 err=14.017596
I 2015-05-27 17:24:43 theanets.trainer:168 RmsProp 753 loss=207.742020 err=13.934603
I 2015-05-27 17:24:45 theanets.trainer:168 RmsProp 754 loss=207.248138 err=13.631518
I 2015-05-27 17:24:47 theanets.trainer:168 RmsProp 755 loss=208.186356 err=14.564585
I 2015-05-27 17:24:48 theanets.trainer:168 RmsProp 756 loss=207.993622 err=14.378799
I 2015-05-27 17:24:50 theanets.trainer:168 RmsProp 757 loss=207.070160 err=13.578009
I 2015-05-27 17:24:52 theanets.trainer:168 RmsProp 758 loss=207.075638 err=13.578692
I 2015-05-27 17:24:54 theanets.trainer:168 RmsProp 759 loss=208.067413 err=14.685018
I 2015-05-27 17:24:56 theanets.trainer:168 RmsProp 760 loss=206.336090 err=12.903185
I 2015-05-27 17:24:56 theanets.trainer:168 validation 76 loss=986.056763 err=792.498169
I 2015-05-27 17:24:58 theanets.trainer:168 RmsProp 761 loss=207.400589 err=14.158026
I 2015-05-27 17:25:00 theanets.trainer:168 RmsProp 762 loss=206.894974 err=13.585592
I 2015-05-27 17:25:02 theanets.trainer:168 RmsProp 763 loss=206.731369 err=13.478140
I 2015-05-27 17:25:04 theanets.trainer:168 RmsProp 764 loss=206.972687 err=13.867655
I 2015-05-27 17:25:06 theanets.trainer:168 RmsProp 765 loss=207.098602 err=13.874117
I 2015-05-27 17:25:08 theanets.trainer:168 RmsProp 766 loss=206.428177 err=13.412413
I 2015-05-27 17:25:10 theanets.trainer:168 RmsProp 767 loss=206.445389 err=13.378794
I 2015-05-27 17:25:12 theanets.trainer:168 RmsProp 768 loss=206.425018 err=13.490399
I 2015-05-27 17:25:13 theanets.trainer:168 RmsProp 769 loss=206.364014 err=13.403028
I 2015-05-27 17:25:15 theanets.trainer:168 RmsProp 770 loss=206.099518 err=13.246509
I 2015-05-27 17:25:16 theanets.trainer:168 validation 77 loss=984.798340 err=792.263550 *
I 2015-05-27 17:25:17 theanets.trainer:168 RmsProp 771 loss=207.438522 err=14.622981
I 2015-05-27 17:25:19 theanets.trainer:168 RmsProp 772 loss=206.186188 err=13.312353
I 2015-05-27 17:25:21 theanets.trainer:168 RmsProp 773 loss=206.412201 err=13.750857
I 2015-05-27 17:25:23 theanets.trainer:168 RmsProp 774 loss=206.191193 err=13.408757
I 2015-05-27 17:25:25 theanets.trainer:168 RmsProp 775 loss=206.205811 err=13.585701
I 2015-05-27 17:25:27 theanets.trainer:168 RmsProp 776 loss=205.952438 err=13.353365
I 2015-05-27 17:25:29 theanets.trainer:168 RmsProp 777 loss=206.118362 err=13.510382
I 2015-05-27 17:25:31 theanets.trainer:168 RmsProp 778 loss=206.126953 err=13.666534
I 2015-05-27 17:25:33 theanets.trainer:168 RmsProp 779 loss=205.776123 err=13.273433
I 2015-05-27 17:25:35 theanets.trainer:168 RmsProp 780 loss=206.212799 err=13.860594
I 2015-05-27 17:25:35 theanets.trainer:168 validation 78 loss=988.908142 err=796.399719
I 2015-05-27 17:25:37 theanets.trainer:168 RmsProp 781 loss=205.837128 err=13.386053
I 2015-05-27 17:25:39 theanets.trainer:168 RmsProp 782 loss=205.591278 err=13.355886
I 2015-05-27 17:25:41 theanets.trainer:168 RmsProp 783 loss=206.800461 err=14.449631
I 2015-05-27 17:25:43 theanets.trainer:168 RmsProp 784 loss=205.480057 err=13.205603
I 2015-05-27 17:25:44 theanets.trainer:168 RmsProp 785 loss=207.254425 err=15.099841
I 2015-05-27 17:25:46 theanets.trainer:168 RmsProp 786 loss=205.539795 err=13.309033
I 2015-05-27 17:25:48 theanets.trainer:168 RmsProp 787 loss=205.306442 err=13.277148
I 2015-05-27 17:25:50 theanets.trainer:168 RmsProp 788 loss=205.843307 err=13.768051
I 2015-05-27 17:25:52 theanets.trainer:168 RmsProp 789 loss=204.852753 err=12.862854
I 2015-05-27 17:25:54 theanets.trainer:168 RmsProp 790 loss=205.338348 err=13.349543
I 2015-05-27 17:25:54 theanets.trainer:168 validation 79 loss=993.340454 err=801.045349
I 2015-05-27 17:25:56 theanets.trainer:168 RmsProp 791 loss=205.381073 err=13.481613
I 2015-05-27 17:25:58 theanets.trainer:168 RmsProp 792 loss=204.820755 err=13.015347
I 2015-05-27 17:26:00 theanets.trainer:168 RmsProp 793 loss=205.397018 err=13.520792
I 2015-05-27 17:26:02 theanets.trainer:168 RmsProp 794 loss=205.687103 err=14.065808
I 2015-05-27 17:26:04 theanets.trainer:168 RmsProp 795 loss=205.245926 err=13.469193
I 2015-05-27 17:26:06 theanets.trainer:168 RmsProp 796 loss=204.662506 err=13.073642
I 2015-05-27 17:26:08 theanets.trainer:168 RmsProp 797 loss=204.567139 err=12.976995
I 2015-05-27 17:26:09 theanets.trainer:168 RmsProp 798 loss=205.386139 err=13.790415
I 2015-05-27 17:26:11 theanets.trainer:168 RmsProp 799 loss=205.942871 err=14.477690
I 2015-05-27 17:26:13 theanets.trainer:168 RmsProp 800 loss=203.803864 err=12.330339
I 2015-05-27 17:26:13 theanets.trainer:168 validation 80 loss=988.710754 err=797.196289
I 2015-05-27 17:26:15 theanets.trainer:168 RmsProp 801 loss=205.225342 err=13.865605
I 2015-05-27 17:26:17 theanets.trainer:168 RmsProp 802 loss=206.005585 err=14.532290
I 2015-05-27 17:26:19 theanets.trainer:168 RmsProp 803 loss=203.316589 err=12.071380
I 2015-05-27 17:26:21 theanets.trainer:168 RmsProp 804 loss=204.701111 err=13.388006
I 2015-05-27 17:26:23 theanets.trainer:168 RmsProp 805 loss=204.840363 err=13.570651
I 2015-05-27 17:26:25 theanets.trainer:168 RmsProp 806 loss=203.850449 err=12.764044
I 2015-05-27 17:26:27 theanets.trainer:168 RmsProp 807 loss=204.795395 err=13.563881
I 2015-05-27 17:26:29 theanets.trainer:168 RmsProp 808 loss=203.944611 err=12.948483
I 2015-05-27 17:26:31 theanets.trainer:168 RmsProp 809 loss=204.612579 err=13.562433
I 2015-05-27 17:26:33 theanets.trainer:168 RmsProp 810 loss=203.790726 err=12.864161
I 2015-05-27 17:26:33 theanets.trainer:168 validation 81 loss=993.796448 err=803.000793
I 2015-05-27 17:26:35 theanets.trainer:168 RmsProp 811 loss=204.970505 err=13.994383
I 2015-05-27 17:26:37 theanets.trainer:168 RmsProp 812 loss=203.421448 err=12.557144
I 2015-05-27 17:26:38 theanets.trainer:168 RmsProp 813 loss=204.474701 err=13.655116
I 2015-05-27 17:26:40 theanets.trainer:168 RmsProp 814 loss=205.113922 err=14.242249
I 2015-05-27 17:26:42 theanets.trainer:168 RmsProp 815 loss=203.214142 err=12.563205
I 2015-05-27 17:26:44 theanets.trainer:168 RmsProp 816 loss=204.223251 err=13.411046
I 2015-05-27 17:26:46 theanets.trainer:168 RmsProp 817 loss=203.886047 err=13.216530
I 2015-05-27 17:26:48 theanets.trainer:168 RmsProp 818 loss=203.872574 err=13.252841
I 2015-05-27 17:26:50 theanets.trainer:168 RmsProp 819 loss=203.431656 err=12.800711
I 2015-05-27 17:26:52 theanets.trainer:168 RmsProp 820 loss=203.852493 err=13.363806
I 2015-05-27 17:26:52 theanets.trainer:168 validation 82 loss=1001.847168 err=810.917480
I 2015-05-27 17:26:52 theanets.trainer:252 patience elapsed!
I 2015-05-27 17:26:52 theanets.main:237 models_deep_post_code_sep/95131-models-sep_san_jose_realtor_200_100.conf-1024-None-0.1-0.01.pkl: saving model
I 2015-05-27 17:26:52 theanets.graph:477 models_deep_post_code_sep/95131-models-sep_san_jose_realtor_200_100.conf-1024-None-0.1-0.01.pkl: saved model parameters
