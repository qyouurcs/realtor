I 2015-05-26 22:05:12 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:12 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95116-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:12 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:12 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:12 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:12 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:12 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:12 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:12 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:12 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:12 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:12 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:12 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:28 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:15 theanets.trainer:168 validation 0 loss=14401.148438 err=14158.706055 *
I 2015-05-26 22:08:47 theanets.trainer:168 RmsProp 1 loss=13280.378906 err=13184.680664
I 2015-05-26 22:09:26 theanets.trainer:168 RmsProp 2 loss=13243.544922 err=13221.870117
I 2015-05-26 22:10:05 theanets.trainer:168 RmsProp 3 loss=13052.443359 err=13015.692383
I 2015-05-26 22:10:43 theanets.trainer:168 RmsProp 4 loss=12463.508789 err=12402.230469
I 2015-05-26 22:11:21 theanets.trainer:168 RmsProp 5 loss=11419.142578 err=11332.735352
I 2015-05-26 22:11:59 theanets.trainer:168 RmsProp 6 loss=10422.458984 err=10314.356445
I 2015-05-26 22:12:37 theanets.trainer:168 RmsProp 7 loss=9915.145508 err=9788.552734
I 2015-05-26 22:13:15 theanets.trainer:168 RmsProp 8 loss=9213.628906 err=9065.610352
I 2015-05-26 22:13:54 theanets.trainer:168 RmsProp 9 loss=8509.870117 err=8336.209961
I 2015-05-26 22:14:33 theanets.trainer:168 RmsProp 10 loss=7823.739746 err=7624.203125
I 2015-05-26 22:14:34 theanets.trainer:168 validation 1 loss=6551.650879 err=6340.614746 *
I 2015-05-26 22:15:12 theanets.trainer:168 RmsProp 11 loss=7498.193359 err=7276.069824
I 2015-05-26 22:15:51 theanets.trainer:168 RmsProp 12 loss=7172.151855 err=6928.721680
I 2015-05-26 22:16:29 theanets.trainer:168 RmsProp 13 loss=6957.637695 err=6692.967773
I 2015-05-26 22:17:08 theanets.trainer:168 RmsProp 14 loss=6571.869629 err=6286.967773
I 2015-05-26 22:17:48 theanets.trainer:168 RmsProp 15 loss=6359.698730 err=6055.630859
I 2015-05-26 22:18:26 theanets.trainer:168 RmsProp 16 loss=6166.315430 err=5843.022461
I 2015-05-26 22:19:04 theanets.trainer:168 RmsProp 17 loss=5632.232422 err=5290.987305
I 2015-05-26 22:19:43 theanets.trainer:168 RmsProp 18 loss=5249.075195 err=4888.756836
I 2015-05-26 22:20:21 theanets.trainer:168 RmsProp 19 loss=4843.153809 err=4470.640137
I 2015-05-26 22:21:00 theanets.trainer:168 RmsProp 20 loss=4514.843262 err=4128.644043
I 2015-05-26 22:21:01 theanets.trainer:168 validation 2 loss=3931.225342 err=3538.891357 *
I 2015-05-26 22:21:39 theanets.trainer:168 RmsProp 21 loss=4330.122559 err=3931.104736
I 2015-05-26 22:22:18 theanets.trainer:168 RmsProp 22 loss=4197.998535 err=3785.868164
I 2015-05-26 22:22:56 theanets.trainer:168 RmsProp 23 loss=3996.209473 err=3573.047607
I 2015-05-26 22:23:35 theanets.trainer:168 RmsProp 24 loss=3821.961426 err=3389.700684
I 2015-05-26 22:24:13 theanets.trainer:168 RmsProp 25 loss=3705.876709 err=3263.605225
I 2015-05-26 22:24:51 theanets.trainer:168 RmsProp 26 loss=3558.708252 err=3106.937988
I 2015-05-26 22:25:29 theanets.trainer:168 RmsProp 27 loss=3442.677490 err=2980.882080
I 2015-05-26 22:26:07 theanets.trainer:168 RmsProp 28 loss=3375.572998 err=2904.006104
I 2015-05-26 22:26:47 theanets.trainer:168 RmsProp 29 loss=3262.871094 err=2782.509521
I 2015-05-26 22:27:26 theanets.trainer:168 RmsProp 30 loss=3167.171387 err=2679.123291
I 2015-05-26 22:27:27 theanets.trainer:168 validation 3 loss=3240.818115 err=2749.935303 *
I 2015-05-26 22:28:05 theanets.trainer:168 RmsProp 31 loss=3060.607910 err=2565.480713
I 2015-05-26 22:28:44 theanets.trainer:168 RmsProp 32 loss=3017.055664 err=2513.937256
I 2015-05-26 22:29:23 theanets.trainer:168 RmsProp 33 loss=2915.955322 err=2403.875732
I 2015-05-26 22:30:02 theanets.trainer:168 RmsProp 34 loss=2820.037354 err=2303.084473
I 2015-05-26 22:30:41 theanets.trainer:168 RmsProp 35 loss=2758.661133 err=2236.704590
I 2015-05-26 22:31:20 theanets.trainer:168 RmsProp 36 loss=2694.939209 err=2167.666260
I 2015-05-26 22:31:58 theanets.trainer:168 RmsProp 37 loss=2701.723877 err=2166.491211
I 2015-05-26 22:32:37 theanets.trainer:168 RmsProp 38 loss=2645.661621 err=2101.411865
I 2015-05-26 22:33:16 theanets.trainer:168 RmsProp 39 loss=2664.000488 err=2112.315918
I 2015-05-26 22:33:54 theanets.trainer:168 RmsProp 40 loss=2598.878174 err=2042.351685
I 2015-05-26 22:33:55 theanets.trainer:168 validation 4 loss=3472.033447 err=2912.661133
I 2015-05-26 22:34:33 theanets.trainer:168 RmsProp 41 loss=2604.490723 err=2038.902588
I 2015-05-26 22:35:12 theanets.trainer:168 RmsProp 42 loss=2581.821045 err=2009.193359
I 2015-05-26 22:35:51 theanets.trainer:168 RmsProp 43 loss=2520.255615 err=1944.857422
I 2015-05-26 22:36:29 theanets.trainer:168 RmsProp 44 loss=2515.520020 err=1934.942139
I 2015-05-26 22:37:06 theanets.trainer:168 RmsProp 45 loss=2467.374023 err=1880.763794
I 2015-05-26 22:37:45 theanets.trainer:168 RmsProp 46 loss=2415.981934 err=1827.705200
I 2015-05-26 22:38:22 theanets.trainer:168 RmsProp 47 loss=2474.484863 err=1881.671265
I 2015-05-26 22:39:01 theanets.trainer:168 RmsProp 48 loss=2576.602051 err=1971.879395
I 2015-05-26 22:39:39 theanets.trainer:168 RmsProp 49 loss=2509.668213 err=1898.677368
I 2015-05-26 22:40:16 theanets.trainer:168 RmsProp 50 loss=2449.075439 err=1836.204712
I 2015-05-26 22:40:17 theanets.trainer:168 validation 5 loss=3298.489014 err=2682.708008
I 2015-05-26 22:40:55 theanets.trainer:168 RmsProp 51 loss=2485.525635 err=1866.729370
I 2015-05-26 22:41:33 theanets.trainer:168 RmsProp 52 loss=2601.664307 err=1977.101562
I 2015-05-26 22:42:11 theanets.trainer:168 RmsProp 53 loss=2559.647217 err=1924.989380
I 2015-05-26 22:42:50 theanets.trainer:168 RmsProp 54 loss=2386.555176 err=1751.666626
I 2015-05-26 22:43:28 theanets.trainer:168 RmsProp 55 loss=2527.846436 err=1889.414185
I 2015-05-26 22:44:06 theanets.trainer:168 RmsProp 56 loss=2482.982666 err=1833.911865
I 2015-05-26 22:44:45 theanets.trainer:168 RmsProp 57 loss=2410.692871 err=1759.903564
I 2015-05-26 22:45:23 theanets.trainer:168 RmsProp 58 loss=2511.408936 err=1854.919189
I 2015-05-26 22:46:01 theanets.trainer:168 RmsProp 59 loss=2533.786865 err=1867.104004
I 2015-05-26 22:46:39 theanets.trainer:168 RmsProp 60 loss=2315.846436 err=1650.466431
I 2015-05-26 22:46:40 theanets.trainer:168 validation 6 loss=3105.958984 err=2443.922607 *
I 2015-05-26 22:47:18 theanets.trainer:168 RmsProp 61 loss=2201.645020 err=1542.212158
I 2015-05-26 22:47:56 theanets.trainer:168 RmsProp 62 loss=2143.168457 err=1487.749512
I 2015-05-26 22:48:33 theanets.trainer:168 RmsProp 63 loss=2160.878662 err=1505.543335
I 2015-05-26 22:49:11 theanets.trainer:168 RmsProp 64 loss=2114.146973 err=1458.025024
I 2015-05-26 22:49:49 theanets.trainer:168 RmsProp 65 loss=2105.090332 err=1449.237671
I 2015-05-26 22:50:27 theanets.trainer:168 RmsProp 66 loss=2080.207520 err=1425.283813
I 2015-05-26 22:51:06 theanets.trainer:168 RmsProp 67 loss=2077.439697 err=1420.096436
I 2015-05-26 22:51:44 theanets.trainer:168 RmsProp 68 loss=2018.196777 err=1361.430420
I 2015-05-26 22:52:22 theanets.trainer:168 RmsProp 69 loss=1987.889526 err=1331.900024
I 2015-05-26 22:53:01 theanets.trainer:168 RmsProp 70 loss=1942.038696 err=1287.505249
I 2015-05-26 22:53:02 theanets.trainer:168 validation 7 loss=3136.072510 err=2481.868164
I 2015-05-26 22:53:41 theanets.trainer:168 RmsProp 71 loss=1953.957886 err=1298.804688
I 2015-05-26 22:54:22 theanets.trainer:168 RmsProp 72 loss=1908.884644 err=1255.549683
I 2015-05-26 22:55:01 theanets.trainer:168 RmsProp 73 loss=1882.984253 err=1231.308350
I 2015-05-26 22:55:39 theanets.trainer:168 RmsProp 74 loss=1879.459839 err=1228.340576
I 2015-05-26 22:56:18 theanets.trainer:168 RmsProp 75 loss=1937.940552 err=1282.556763
I 2015-05-26 22:56:57 theanets.trainer:168 RmsProp 76 loss=1948.291260 err=1290.151489
I 2015-05-26 22:57:37 theanets.trainer:168 RmsProp 77 loss=1906.044067 err=1246.704590
I 2015-05-26 22:58:17 theanets.trainer:168 RmsProp 78 loss=1874.026489 err=1215.760864
I 2015-05-26 22:58:56 theanets.trainer:168 RmsProp 79 loss=1845.709351 err=1188.251953
I 2015-05-26 22:59:35 theanets.trainer:168 RmsProp 80 loss=1820.016479 err=1163.308716
I 2015-05-26 22:59:35 theanets.trainer:168 validation 8 loss=2775.441162 err=2119.161133 *
I 2015-05-26 23:00:12 theanets.trainer:168 RmsProp 81 loss=1794.155151 err=1138.624268
I 2015-05-26 23:00:50 theanets.trainer:168 RmsProp 82 loss=1778.701294 err=1124.272949
I 2015-05-26 23:01:29 theanets.trainer:168 RmsProp 83 loss=1753.587402 err=1100.154419
I 2015-05-26 23:02:07 theanets.trainer:168 RmsProp 84 loss=1793.739868 err=1139.624756
I 2015-05-26 23:02:46 theanets.trainer:168 RmsProp 85 loss=1797.207642 err=1141.507080
I 2015-05-26 23:03:25 theanets.trainer:168 RmsProp 86 loss=1771.181396 err=1115.046753
I 2015-05-26 23:04:03 theanets.trainer:168 RmsProp 87 loss=1765.434814 err=1109.233521
I 2015-05-26 23:04:41 theanets.trainer:168 RmsProp 88 loss=1767.604126 err=1109.742310
I 2015-05-26 23:05:20 theanets.trainer:168 RmsProp 89 loss=1735.324585 err=1078.660889
I 2015-05-26 23:05:57 theanets.trainer:168 RmsProp 90 loss=1736.828735 err=1081.148560
I 2015-05-26 23:05:57 theanets.trainer:168 validation 9 loss=2678.042236 err=2020.977539 *
I 2015-05-26 23:06:34 theanets.trainer:168 RmsProp 91 loss=1720.276733 err=1063.223145
I 2015-05-26 23:07:13 theanets.trainer:168 RmsProp 92 loss=1726.296387 err=1069.156616
I 2015-05-26 23:07:52 theanets.trainer:168 RmsProp 93 loss=1729.088135 err=1070.236572
I 2015-05-26 23:08:32 theanets.trainer:168 RmsProp 94 loss=1710.454956 err=1051.263306
I 2015-05-26 23:09:10 theanets.trainer:168 RmsProp 95 loss=1690.325562 err=1031.565552
I 2015-05-26 23:09:50 theanets.trainer:168 RmsProp 96 loss=1662.254272 err=1004.892578
I 2015-05-26 23:10:28 theanets.trainer:168 RmsProp 97 loss=1672.579224 err=1014.502930
I 2015-05-26 23:11:06 theanets.trainer:168 RmsProp 98 loss=1650.076172 err=991.986694
I 2015-05-26 23:11:43 theanets.trainer:168 RmsProp 99 loss=1651.988770 err=994.589844
I 2015-05-26 23:12:21 theanets.trainer:168 RmsProp 100 loss=1621.220459 err=964.619507
I 2015-05-26 23:12:22 theanets.trainer:168 validation 10 loss=2650.897217 err=1995.149048 *
I 2015-05-26 23:13:00 theanets.trainer:168 RmsProp 101 loss=1622.661743 err=967.278748
I 2015-05-26 23:13:39 theanets.trainer:168 RmsProp 102 loss=1597.667847 err=943.673462
I 2015-05-26 23:14:17 theanets.trainer:168 RmsProp 103 loss=1585.390137 err=931.945984
I 2015-05-26 23:14:57 theanets.trainer:168 RmsProp 104 loss=1569.711548 err=917.610657
I 2015-05-26 23:15:35 theanets.trainer:168 RmsProp 105 loss=1569.136475 err=917.584106
I 2015-05-26 23:16:13 theanets.trainer:168 RmsProp 106 loss=1603.910400 err=949.907104
I 2015-05-26 23:16:52 theanets.trainer:168 RmsProp 107 loss=1587.411621 err=932.709229
I 2015-05-26 23:17:30 theanets.trainer:168 RmsProp 108 loss=1571.417725 err=916.585205
I 2015-05-26 23:18:07 theanets.trainer:168 RmsProp 109 loss=1562.288940 err=907.468384
I 2015-05-26 23:18:45 theanets.trainer:168 RmsProp 110 loss=1559.447998 err=903.464661
I 2015-05-26 23:18:46 theanets.trainer:168 validation 11 loss=2625.913086 err=1970.487671 *
I 2015-05-26 23:19:22 theanets.trainer:168 RmsProp 111 loss=1525.227417 err=870.848022
I 2015-05-26 23:20:00 theanets.trainer:168 RmsProp 112 loss=1542.250000 err=887.547852
I 2015-05-26 23:20:37 theanets.trainer:168 RmsProp 113 loss=1533.755005 err=878.608704
I 2015-05-26 23:21:15 theanets.trainer:168 RmsProp 114 loss=1542.270142 err=886.636658
I 2015-05-26 23:21:53 theanets.trainer:168 RmsProp 115 loss=1681.713501 err=1017.854736
I 2015-05-26 23:22:31 theanets.trainer:168 RmsProp 116 loss=1660.308594 err=990.330627
I 2015-05-26 23:23:09 theanets.trainer:168 RmsProp 117 loss=1698.020142 err=1024.827026
I 2015-05-26 23:23:48 theanets.trainer:168 RmsProp 118 loss=1673.721558 err=998.910583
I 2015-05-26 23:24:27 theanets.trainer:168 RmsProp 119 loss=1665.482056 err=989.567444
I 2015-05-26 23:25:05 theanets.trainer:168 RmsProp 120 loss=1616.806763 err=940.321472
I 2015-05-26 23:25:06 theanets.trainer:168 validation 12 loss=2863.299561 err=2187.607422
I 2015-05-26 23:25:43 theanets.trainer:168 RmsProp 121 loss=1671.719360 err=992.047668
I 2015-05-26 23:26:21 theanets.trainer:168 RmsProp 122 loss=1668.209106 err=984.569946
I 2015-05-26 23:26:58 theanets.trainer:168 RmsProp 123 loss=1648.391846 err=964.683533
I 2015-05-26 23:27:36 theanets.trainer:168 RmsProp 124 loss=1653.838013 err=969.725403
I 2015-05-26 23:28:15 theanets.trainer:168 RmsProp 125 loss=1610.491455 err=926.131042
I 2015-05-26 23:28:53 theanets.trainer:168 RmsProp 126 loss=1639.703857 err=952.792053
I 2015-05-26 23:29:32 theanets.trainer:168 RmsProp 127 loss=1619.884644 err=931.376587
I 2015-05-26 23:30:10 theanets.trainer:168 RmsProp 128 loss=1626.015259 err=937.088684
I 2015-05-26 23:30:48 theanets.trainer:168 RmsProp 129 loss=1637.015869 err=945.947693
I 2015-05-26 23:31:26 theanets.trainer:168 RmsProp 130 loss=1635.584717 err=939.473389
I 2015-05-26 23:31:27 theanets.trainer:168 validation 13 loss=2974.641846 err=2277.506592
I 2015-05-26 23:32:03 theanets.trainer:168 RmsProp 131 loss=1632.378418 err=934.614319
I 2015-05-26 23:32:40 theanets.trainer:168 RmsProp 132 loss=1595.071655 err=897.613892
I 2015-05-26 23:33:16 theanets.trainer:168 RmsProp 133 loss=1574.001831 err=877.008545
I 2015-05-26 23:33:55 theanets.trainer:168 RmsProp 134 loss=1610.762817 err=912.836182
I 2015-05-26 23:34:33 theanets.trainer:168 RmsProp 135 loss=1558.899658 err=859.953796
I 2015-05-26 23:35:10 theanets.trainer:168 RmsProp 136 loss=1545.468018 err=848.856323
I 2015-05-26 23:35:48 theanets.trainer:168 RmsProp 137 loss=1575.531616 err=877.426575
I 2015-05-26 23:36:25 theanets.trainer:168 RmsProp 138 loss=1562.847656 err=863.609436
I 2015-05-26 23:37:03 theanets.trainer:168 RmsProp 139 loss=1558.236816 err=857.638855
I 2015-05-26 23:37:41 theanets.trainer:168 RmsProp 140 loss=1550.568604 err=848.837463
I 2015-05-26 23:37:42 theanets.trainer:168 validation 14 loss=2741.430420 err=2039.397827
I 2015-05-26 23:38:21 theanets.trainer:168 RmsProp 141 loss=1526.437988 err=825.712646
I 2015-05-26 23:38:59 theanets.trainer:168 RmsProp 142 loss=1501.430298 err=801.835938
I 2015-05-26 23:39:36 theanets.trainer:168 RmsProp 143 loss=1469.339844 err=772.723877
I 2015-05-26 23:40:14 theanets.trainer:168 RmsProp 144 loss=1512.060181 err=815.466248
I 2015-05-26 23:40:52 theanets.trainer:168 RmsProp 145 loss=1577.619995 err=875.150269
I 2015-05-26 23:41:31 theanets.trainer:168 RmsProp 146 loss=1492.528687 err=790.001709
I 2015-05-26 23:42:11 theanets.trainer:168 RmsProp 147 loss=1451.277466 err=752.791809
I 2015-05-26 23:42:49 theanets.trainer:168 RmsProp 148 loss=1459.221436 err=762.568604
I 2015-05-26 23:43:28 theanets.trainer:168 RmsProp 149 loss=1502.657104 err=802.504150
I 2015-05-26 23:44:07 theanets.trainer:168 RmsProp 150 loss=1502.131226 err=799.088562
I 2015-05-26 23:44:08 theanets.trainer:168 validation 15 loss=2761.680420 err=2058.552734
I 2015-05-26 23:44:45 theanets.trainer:168 RmsProp 151 loss=1511.851562 err=807.763245
I 2015-05-26 23:45:24 theanets.trainer:168 RmsProp 152 loss=1514.255981 err=807.560364
I 2015-05-26 23:46:02 theanets.trainer:168 RmsProp 153 loss=1486.018188 err=778.439819
I 2015-05-26 23:46:40 theanets.trainer:168 RmsProp 154 loss=1426.448486 err=721.526611
I 2015-05-26 23:47:17 theanets.trainer:168 RmsProp 155 loss=1416.185181 err=714.443481
I 2015-05-26 23:47:54 theanets.trainer:168 RmsProp 156 loss=1429.135498 err=728.226135
I 2015-05-26 23:48:31 theanets.trainer:168 RmsProp 157 loss=1431.388916 err=729.000854
I 2015-05-26 23:49:08 theanets.trainer:168 RmsProp 158 loss=1404.889771 err=704.496033
I 2015-05-26 23:49:46 theanets.trainer:168 RmsProp 159 loss=1418.163330 err=718.109253
I 2015-05-26 23:50:23 theanets.trainer:168 RmsProp 160 loss=1435.173218 err=733.469360
I 2015-05-26 23:50:24 theanets.trainer:168 validation 16 loss=2768.269531 err=2065.013428
I 2015-05-26 23:50:24 theanets.trainer:252 patience elapsed!
I 2015-05-26 23:50:24 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 23:50:24 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 23:50:24 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 23:50:24 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 23:50:24 theanets.main:89 --batch_size = 1024
I 2015-05-26 23:50:24 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 23:50:24 theanets.main:89 --hidden_l1 = None
I 2015-05-26 23:50:24 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 23:50:24 theanets.main:89 --train_batches = 10
I 2015-05-26 23:50:24 theanets.main:89 --valid_batches = 2
I 2015-05-26 23:50:24 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 23:50:24 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 23:50:24 theanets.trainer:134 compiling evaluation function
I 2015-05-26 23:50:33 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 23:52:12 theanets.trainer:168 validation 0 loss=2676.974609 err=2021.549072 *
I 2015-05-26 23:52:23 theanets.trainer:168 RmsProp 1 loss=1661.387939 err=1008.952820
I 2015-05-26 23:52:34 theanets.trainer:168 RmsProp 2 loss=1330.751709 err=679.877625
I 2015-05-26 23:52:45 theanets.trainer:168 RmsProp 3 loss=1136.041748 err=486.431152
I 2015-05-26 23:52:57 theanets.trainer:168 RmsProp 4 loss=1037.046387 err=389.064209
I 2015-05-26 23:53:08 theanets.trainer:168 RmsProp 5 loss=947.593872 err=301.669281
I 2015-05-26 23:53:19 theanets.trainer:168 RmsProp 6 loss=889.591797 err=246.094284
I 2015-05-26 23:53:31 theanets.trainer:168 RmsProp 7 loss=836.593872 err=195.939636
I 2015-05-26 23:53:42 theanets.trainer:168 RmsProp 8 loss=799.055542 err=161.625061
I 2015-05-26 23:53:54 theanets.trainer:168 RmsProp 9 loss=771.391785 err=137.486023
I 2015-05-26 23:54:05 theanets.trainer:168 RmsProp 10 loss=746.987000 err=116.695847
I 2015-05-26 23:54:06 theanets.trainer:168 validation 1 loss=1674.758911 err=1046.516968 *
I 2015-05-26 23:54:18 theanets.trainer:168 RmsProp 11 loss=729.988342 err=103.481979
I 2015-05-26 23:54:29 theanets.trainer:168 RmsProp 12 loss=711.040771 err=88.332367
I 2015-05-26 23:54:41 theanets.trainer:168 RmsProp 13 loss=695.874695 err=76.949173
I 2015-05-26 23:54:52 theanets.trainer:168 RmsProp 14 loss=684.981995 err=70.051590
I 2015-05-26 23:55:04 theanets.trainer:168 RmsProp 15 loss=678.339661 err=67.272079
I 2015-05-26 23:55:16 theanets.trainer:168 RmsProp 16 loss=667.192627 err=59.682636
I 2015-05-26 23:55:27 theanets.trainer:168 RmsProp 17 loss=657.770874 err=53.741058
I 2015-05-26 23:55:39 theanets.trainer:168 RmsProp 18 loss=651.625366 err=51.261101
I 2015-05-26 23:55:50 theanets.trainer:168 RmsProp 19 loss=642.214844 err=45.614101
I 2015-05-26 23:56:02 theanets.trainer:168 RmsProp 20 loss=636.471558 err=43.626434
I 2015-05-26 23:56:02 theanets.trainer:168 validation 2 loss=1648.403076 err=1057.628540 *
I 2015-05-26 23:56:14 theanets.trainer:168 RmsProp 21 loss=631.774475 err=42.661964
I 2015-05-26 23:56:25 theanets.trainer:168 RmsProp 22 loss=624.280701 err=38.780216
I 2015-05-26 23:56:37 theanets.trainer:168 RmsProp 23 loss=617.588623 err=35.659870
I 2015-05-26 23:56:48 theanets.trainer:168 RmsProp 24 loss=612.659912 err=34.420860
I 2015-05-26 23:56:59 theanets.trainer:168 RmsProp 25 loss=606.164062 err=31.612614
I 2015-05-26 23:57:10 theanets.trainer:168 RmsProp 26 loss=600.556824 err=29.464016
I 2015-05-26 23:57:21 theanets.trainer:168 RmsProp 27 loss=598.371521 err=30.772406
I 2015-05-26 23:57:32 theanets.trainer:168 RmsProp 28 loss=593.390991 err=29.103764
I 2015-05-26 23:57:44 theanets.trainer:168 RmsProp 29 loss=587.632202 err=26.463345
I 2015-05-26 23:57:54 theanets.trainer:168 RmsProp 30 loss=584.521057 err=26.467529
I 2015-05-26 23:57:55 theanets.trainer:168 validation 3 loss=1646.538452 err=1090.211914 *
I 2015-05-26 23:58:06 theanets.trainer:168 RmsProp 31 loss=580.199890 err=25.338146
I 2015-05-26 23:58:17 theanets.trainer:168 RmsProp 32 loss=575.016113 err=23.458567
I 2015-05-26 23:58:27 theanets.trainer:168 RmsProp 33 loss=571.989441 err=23.814003
I 2015-05-26 23:58:39 theanets.trainer:168 RmsProp 34 loss=568.427429 err=23.533455
I 2015-05-26 23:58:50 theanets.trainer:168 RmsProp 35 loss=563.926758 err=22.068439
I 2015-05-26 23:59:02 theanets.trainer:168 RmsProp 36 loss=559.811279 err=20.860996
I 2015-05-26 23:59:14 theanets.trainer:168 RmsProp 37 loss=556.311829 err=20.333565
I 2015-05-26 23:59:25 theanets.trainer:168 RmsProp 38 loss=553.446167 err=20.560036
I 2015-05-26 23:59:37 theanets.trainer:168 RmsProp 39 loss=549.048279 err=19.167986
I 2015-05-26 23:59:49 theanets.trainer:168 RmsProp 40 loss=545.896423 err=19.042391
I 2015-05-26 23:59:49 theanets.trainer:168 validation 4 loss=1622.631226 err=1097.490601 *
I 2015-05-27 00:00:01 theanets.trainer:168 RmsProp 41 loss=542.217163 err=18.444494
I 2015-05-27 00:00:13 theanets.trainer:168 RmsProp 42 loss=538.260925 err=17.430048
I 2015-05-27 00:00:24 theanets.trainer:168 RmsProp 43 loss=536.073853 err=18.145176
I 2015-05-27 00:00:36 theanets.trainer:168 RmsProp 44 loss=531.676575 err=16.623486
I 2015-05-27 00:00:48 theanets.trainer:168 RmsProp 45 loss=529.079041 err=16.929455
I 2015-05-27 00:00:59 theanets.trainer:168 RmsProp 46 loss=526.396545 err=17.143661
I 2015-05-27 00:01:11 theanets.trainer:168 RmsProp 47 loss=521.931946 err=15.426959
I 2015-05-27 00:01:23 theanets.trainer:168 RmsProp 48 loss=519.596497 err=15.857526
I 2015-05-27 00:01:34 theanets.trainer:168 RmsProp 49 loss=516.395142 err=15.414873
I 2015-05-27 00:01:46 theanets.trainer:168 RmsProp 50 loss=512.817871 err=14.539538
I 2015-05-27 00:01:47 theanets.trainer:168 validation 5 loss=1581.360474 err=1084.590454 *
I 2015-05-27 00:01:58 theanets.trainer:168 RmsProp 51 loss=510.296295 err=14.768336
I 2015-05-27 00:02:10 theanets.trainer:168 RmsProp 52 loss=507.244232 err=14.415952
I 2015-05-27 00:02:21 theanets.trainer:168 RmsProp 53 loss=504.457855 err=14.287560
I 2015-05-27 00:02:33 theanets.trainer:168 RmsProp 54 loss=501.148987 err=13.584299
I 2015-05-27 00:02:44 theanets.trainer:168 RmsProp 55 loss=498.679932 err=13.690184
I 2015-05-27 00:02:56 theanets.trainer:168 RmsProp 56 loss=495.370911 err=12.972685
I 2015-05-27 00:03:07 theanets.trainer:168 RmsProp 57 loss=492.810608 err=13.004799
I 2015-05-27 00:03:19 theanets.trainer:168 RmsProp 58 loss=490.055725 err=12.850614
I 2015-05-27 00:03:30 theanets.trainer:168 RmsProp 59 loss=487.065765 err=12.452305
I 2015-05-27 00:03:42 theanets.trainer:168 RmsProp 60 loss=484.376129 err=12.279299
I 2015-05-27 00:03:43 theanets.trainer:168 validation 6 loss=1557.498901 err=1086.786133 *
I 2015-05-27 00:03:54 theanets.trainer:168 RmsProp 61 loss=482.510681 err=12.937826
I 2015-05-27 00:04:06 theanets.trainer:168 RmsProp 62 loss=479.437836 err=12.310748
I 2015-05-27 00:04:17 theanets.trainer:168 RmsProp 63 loss=476.497162 err=11.702785
I 2015-05-27 00:04:28 theanets.trainer:168 RmsProp 64 loss=474.020691 err=11.558526
I 2015-05-27 00:04:40 theanets.trainer:168 RmsProp 65 loss=471.532166 err=11.461634
I 2015-05-27 00:04:52 theanets.trainer:168 RmsProp 66 loss=469.282043 err=11.603552
I 2015-05-27 00:05:03 theanets.trainer:168 RmsProp 67 loss=466.152740 err=10.823462
I 2015-05-27 00:05:14 theanets.trainer:168 RmsProp 68 loss=463.934418 err=10.962873
I 2015-05-27 00:05:26 theanets.trainer:168 RmsProp 69 loss=460.944580 err=10.320027
I 2015-05-27 00:05:38 theanets.trainer:168 RmsProp 70 loss=460.261383 err=12.003222
I 2015-05-27 00:05:38 theanets.trainer:168 validation 7 loss=1531.524292 err=1084.529907 *
I 2015-05-27 00:05:50 theanets.trainer:168 RmsProp 71 loss=456.952301 err=10.946421
I 2015-05-27 00:06:01 theanets.trainer:168 RmsProp 72 loss=454.299561 err=10.446848
I 2015-05-27 00:06:13 theanets.trainer:168 RmsProp 73 loss=451.749695 err=10.052984
I 2015-05-27 00:06:24 theanets.trainer:168 RmsProp 74 loss=450.031830 err=10.525038
I 2015-05-27 00:06:36 theanets.trainer:168 RmsProp 75 loss=447.713287 err=10.380182
I 2015-05-27 00:06:47 theanets.trainer:168 RmsProp 76 loss=444.907227 err=9.726035
I 2015-05-27 00:06:59 theanets.trainer:168 RmsProp 77 loss=443.013977 err=9.997844
I 2015-05-27 00:07:10 theanets.trainer:168 RmsProp 78 loss=440.609619 err=9.742723
I 2015-05-27 00:07:22 theanets.trainer:168 RmsProp 79 loss=438.039062 err=9.311756
I 2015-05-27 00:07:34 theanets.trainer:168 RmsProp 80 loss=436.290436 err=9.721603
I 2015-05-27 00:07:34 theanets.trainer:168 validation 8 loss=1503.825684 err=1078.442749 *
I 2015-05-27 00:07:46 theanets.trainer:168 RmsProp 81 loss=434.349915 err=9.900885
I 2015-05-27 00:07:57 theanets.trainer:168 RmsProp 82 loss=431.854828 err=9.417513
I 2015-05-27 00:08:09 theanets.trainer:168 RmsProp 83 loss=429.540466 err=9.065713
I 2015-05-27 00:08:20 theanets.trainer:168 RmsProp 84 loss=427.315613 err=8.826570
I 2015-05-27 00:08:31 theanets.trainer:168 RmsProp 85 loss=425.717041 err=9.260226
I 2015-05-27 00:08:43 theanets.trainer:168 RmsProp 86 loss=423.150818 err=8.751249
I 2015-05-27 00:08:54 theanets.trainer:168 RmsProp 87 loss=421.499847 err=9.129217
I 2015-05-27 00:09:06 theanets.trainer:168 RmsProp 88 loss=418.910309 err=8.503588
I 2015-05-27 00:09:17 theanets.trainer:168 RmsProp 89 loss=417.101807 err=8.638913
I 2015-05-27 00:09:28 theanets.trainer:168 RmsProp 90 loss=415.589172 err=9.078272
I 2015-05-27 00:09:29 theanets.trainer:168 validation 9 loss=1484.401123 err=1078.913818 *
I 2015-05-27 00:09:40 theanets.trainer:168 RmsProp 91 loss=413.238861 err=8.579248
I 2015-05-27 00:09:52 theanets.trainer:168 RmsProp 92 loss=410.891205 err=8.042966
I 2015-05-27 00:10:03 theanets.trainer:168 RmsProp 93 loss=409.790710 err=8.784904
I 2015-05-27 00:10:15 theanets.trainer:168 RmsProp 94 loss=407.862793 err=8.696615
I 2015-05-27 00:10:26 theanets.trainer:168 RmsProp 95 loss=405.458923 err=8.103598
I 2015-05-27 00:10:37 theanets.trainer:168 RmsProp 96 loss=403.562195 err=7.992698
I 2015-05-27 00:10:49 theanets.trainer:168 RmsProp 97 loss=401.262512 err=7.519229
I 2015-05-27 00:11:00 theanets.trainer:168 RmsProp 98 loss=401.869629 err=9.981207
I 2015-05-27 00:11:11 theanets.trainer:168 RmsProp 99 loss=398.524963 err=8.337287
I 2015-05-27 00:11:23 theanets.trainer:168 RmsProp 100 loss=395.972015 err=7.422920
I 2015-05-27 00:11:23 theanets.trainer:168 validation 10 loss=1467.305298 err=1079.683350 *
I 2015-05-27 00:11:35 theanets.trainer:168 RmsProp 101 loss=394.726776 err=7.890204
I 2015-05-27 00:11:46 theanets.trainer:168 RmsProp 102 loss=392.704346 err=7.623534
I 2015-05-27 00:11:56 theanets.trainer:168 RmsProp 103 loss=390.881439 err=7.559590
I 2015-05-27 00:12:07 theanets.trainer:168 RmsProp 104 loss=389.446350 err=7.886391
I 2015-05-27 00:12:17 theanets.trainer:168 RmsProp 105 loss=387.528381 err=7.661260
I 2015-05-27 00:12:27 theanets.trainer:168 RmsProp 106 loss=385.526489 err=7.314726
I 2015-05-27 00:12:38 theanets.trainer:168 RmsProp 107 loss=384.725555 err=8.169199
I 2015-05-27 00:12:49 theanets.trainer:168 RmsProp 108 loss=382.847046 err=7.882294
I 2015-05-27 00:12:59 theanets.trainer:168 RmsProp 109 loss=380.338287 err=6.932119
I 2015-05-27 00:13:10 theanets.trainer:168 RmsProp 110 loss=378.309967 err=6.505264
I 2015-05-27 00:13:11 theanets.trainer:168 validation 11 loss=1451.294067 err=1080.408081 *
I 2015-05-27 00:13:21 theanets.trainer:168 RmsProp 111 loss=379.600525 err=9.443343
I 2015-05-27 00:13:31 theanets.trainer:168 RmsProp 112 loss=375.956909 err=7.332379
I 2015-05-27 00:13:42 theanets.trainer:168 RmsProp 113 loss=374.053864 err=6.889596
I 2015-05-27 00:13:52 theanets.trainer:168 RmsProp 114 loss=372.579956 err=6.914912
I 2015-05-27 00:14:03 theanets.trainer:168 RmsProp 115 loss=371.253357 err=7.137980
I 2015-05-27 00:14:14 theanets.trainer:168 RmsProp 116 loss=369.755554 err=7.203111
I 2015-05-27 00:14:24 theanets.trainer:168 RmsProp 117 loss=367.977356 err=6.963112
I 2015-05-27 00:14:34 theanets.trainer:168 RmsProp 118 loss=366.262329 err=6.779652
I 2015-05-27 00:14:44 theanets.trainer:168 RmsProp 119 loss=364.686127 err=6.728283
I 2015-05-27 00:14:54 theanets.trainer:168 RmsProp 120 loss=363.295013 err=6.869209
I 2015-05-27 00:14:54 theanets.trainer:168 validation 12 loss=1452.326782 err=1096.751953
I 2015-05-27 00:15:04 theanets.trainer:168 RmsProp 121 loss=362.146576 err=7.259933
I 2015-05-27 00:15:14 theanets.trainer:168 RmsProp 122 loss=359.969635 err=6.545523
I 2015-05-27 00:15:24 theanets.trainer:168 RmsProp 123 loss=358.651428 err=6.675819
I 2015-05-27 00:15:34 theanets.trainer:168 RmsProp 124 loss=356.875824 err=6.357805
I 2015-05-27 00:15:43 theanets.trainer:168 RmsProp 125 loss=355.387421 err=6.352526
I 2015-05-27 00:15:53 theanets.trainer:168 RmsProp 126 loss=354.226379 err=6.682233
I 2015-05-27 00:16:03 theanets.trainer:168 RmsProp 127 loss=352.731140 err=6.646174
I 2015-05-27 00:16:13 theanets.trainer:168 RmsProp 128 loss=351.034088 err=6.383479
I 2015-05-27 00:16:23 theanets.trainer:168 RmsProp 129 loss=349.284729 err=6.047991
I 2015-05-27 00:16:34 theanets.trainer:168 RmsProp 130 loss=347.936707 err=6.149400
I 2015-05-27 00:16:34 theanets.trainer:168 validation 13 loss=1437.977539 err=1096.986328 *
I 2015-05-27 00:16:44 theanets.trainer:168 RmsProp 131 loss=347.044983 err=6.698270
I 2015-05-27 00:16:55 theanets.trainer:168 RmsProp 132 loss=345.116058 err=6.174265
I 2015-05-27 00:17:05 theanets.trainer:168 RmsProp 133 loss=343.795837 err=6.228366
I 2015-05-27 00:17:16 theanets.trainer:168 RmsProp 134 loss=342.889832 err=6.684020
I 2015-05-27 00:17:26 theanets.trainer:168 RmsProp 135 loss=341.068115 err=6.189727
I 2015-05-27 00:17:37 theanets.trainer:168 RmsProp 136 loss=338.994873 err=5.439373
I 2015-05-27 00:17:48 theanets.trainer:168 RmsProp 137 loss=339.236664 err=7.034895
I 2015-05-27 00:17:58 theanets.trainer:168 RmsProp 138 loss=336.908417 err=6.010833
I 2015-05-27 00:18:09 theanets.trainer:168 RmsProp 139 loss=335.594421 err=5.971941
I 2015-05-27 00:18:19 theanets.trainer:168 RmsProp 140 loss=334.209656 err=5.886571
I 2015-05-27 00:18:20 theanets.trainer:168 validation 14 loss=1424.313721 err=1096.703491 *
I 2015-05-27 00:18:30 theanets.trainer:168 RmsProp 141 loss=333.435669 err=6.407231
I 2015-05-27 00:18:41 theanets.trainer:168 RmsProp 142 loss=331.415314 err=5.666760
I 2015-05-27 00:18:51 theanets.trainer:168 RmsProp 143 loss=330.309265 err=5.855855
I 2015-05-27 00:19:01 theanets.trainer:168 RmsProp 144 loss=329.180115 err=6.020581
I 2015-05-27 00:19:12 theanets.trainer:168 RmsProp 145 loss=328.208740 err=6.309325
I 2015-05-27 00:19:22 theanets.trainer:168 RmsProp 146 loss=326.482849 err=5.802720
I 2015-05-27 00:19:33 theanets.trainer:168 RmsProp 147 loss=325.301392 err=5.824498
I 2015-05-27 00:19:43 theanets.trainer:168 RmsProp 148 loss=324.123352 err=5.845218
I 2015-05-27 00:19:54 theanets.trainer:168 RmsProp 149 loss=322.694244 err=5.619768
I 2015-05-27 00:20:04 theanets.trainer:168 RmsProp 150 loss=321.538025 err=5.672533
I 2015-05-27 00:20:05 theanets.trainer:168 validation 15 loss=1402.077881 err=1086.879883 *
I 2015-05-27 00:20:15 theanets.trainer:168 RmsProp 151 loss=320.219482 err=5.568561
I 2015-05-27 00:20:26 theanets.trainer:168 RmsProp 152 loss=319.181091 err=5.745593
I 2015-05-27 00:20:36 theanets.trainer:168 RmsProp 153 loss=317.873322 err=5.658240
I 2015-05-27 00:20:46 theanets.trainer:168 RmsProp 154 loss=316.278259 err=5.251099
I 2015-05-27 00:20:57 theanets.trainer:168 RmsProp 155 loss=315.588074 err=5.754572
I 2015-05-27 00:21:08 theanets.trainer:168 RmsProp 156 loss=314.583923 err=5.931661
I 2015-05-27 00:21:18 theanets.trainer:168 RmsProp 157 loss=312.655121 err=5.145902
I 2015-05-27 00:21:28 theanets.trainer:168 RmsProp 158 loss=311.939148 err=5.583038
I 2015-05-27 00:21:39 theanets.trainer:168 RmsProp 159 loss=310.723602 err=5.524704
I 2015-05-27 00:21:49 theanets.trainer:168 RmsProp 160 loss=309.621979 err=5.559388
I 2015-05-27 00:21:50 theanets.trainer:168 validation 16 loss=1377.582275 err=1074.132690 *
I 2015-05-27 00:22:01 theanets.trainer:168 RmsProp 161 loss=307.924774 err=4.980133
I 2015-05-27 00:22:11 theanets.trainer:168 RmsProp 162 loss=308.289246 err=6.491972
I 2015-05-27 00:22:22 theanets.trainer:168 RmsProp 163 loss=306.762451 err=6.073443
I 2015-05-27 00:22:32 theanets.trainer:168 RmsProp 164 loss=304.760590 err=5.091133
I 2015-05-27 00:22:43 theanets.trainer:168 RmsProp 165 loss=303.763184 err=5.109346
I 2015-05-27 00:22:53 theanets.trainer:168 RmsProp 166 loss=302.929199 err=5.322938
I 2015-05-27 00:23:04 theanets.trainer:168 RmsProp 167 loss=301.536804 err=5.007365
I 2015-05-27 00:23:14 theanets.trainer:168 RmsProp 168 loss=300.975433 err=5.523404
I 2015-05-27 00:23:24 theanets.trainer:168 RmsProp 169 loss=299.556091 err=5.161708
I 2015-05-27 00:23:35 theanets.trainer:168 RmsProp 170 loss=298.626282 err=5.286170
I 2015-05-27 00:23:35 theanets.trainer:168 validation 17 loss=1367.848755 err=1075.076782 *
I 2015-05-27 00:23:45 theanets.trainer:168 RmsProp 171 loss=297.713562 err=5.412002
I 2015-05-27 00:23:56 theanets.trainer:168 RmsProp 172 loss=296.333679 err=5.055803
I 2015-05-27 00:24:06 theanets.trainer:168 RmsProp 173 loss=295.232330 err=4.992240
I 2015-05-27 00:24:17 theanets.trainer:168 RmsProp 174 loss=294.258453 err=5.057861
I 2015-05-27 00:24:28 theanets.trainer:168 RmsProp 175 loss=293.328400 err=5.160104
I 2015-05-27 00:24:38 theanets.trainer:168 RmsProp 176 loss=292.291199 err=5.152037
I 2015-05-27 00:24:49 theanets.trainer:168 RmsProp 177 loss=291.209778 err=5.086019
I 2015-05-27 00:24:59 theanets.trainer:168 RmsProp 178 loss=290.252625 err=5.123733
I 2015-05-27 00:25:09 theanets.trainer:168 RmsProp 179 loss=289.095947 err=4.949029
I 2015-05-27 00:25:20 theanets.trainer:168 RmsProp 180 loss=288.255676 err=5.082993
I 2015-05-27 00:25:20 theanets.trainer:168 validation 18 loss=1373.002686 err=1090.360962
I 2015-05-27 00:25:31 theanets.trainer:168 RmsProp 181 loss=287.216217 err=5.017426
I 2015-05-27 00:25:41 theanets.trainer:168 RmsProp 182 loss=285.928284 err=4.698491
I 2015-05-27 00:25:52 theanets.trainer:168 RmsProp 183 loss=285.430969 err=5.179890
I 2015-05-27 00:26:02 theanets.trainer:168 RmsProp 184 loss=284.482788 err=5.192863
I 2015-05-27 00:26:12 theanets.trainer:168 RmsProp 185 loss=283.051208 err=4.708482
I 2015-05-27 00:26:23 theanets.trainer:168 RmsProp 186 loss=282.424866 err=5.021630
I 2015-05-27 00:26:33 theanets.trainer:168 RmsProp 187 loss=281.341736 err=4.867568
I 2015-05-27 00:26:44 theanets.trainer:168 RmsProp 188 loss=280.711273 err=5.161592
I 2015-05-27 00:26:54 theanets.trainer:168 RmsProp 189 loss=279.450775 err=4.817384
I 2015-05-27 00:27:04 theanets.trainer:168 RmsProp 190 loss=278.579132 err=4.845495
I 2015-05-27 00:27:05 theanets.trainer:168 validation 19 loss=1363.752197 err=1090.518433 *
I 2015-05-27 00:27:15 theanets.trainer:168 RmsProp 191 loss=277.404572 err=4.572649
I 2015-05-27 00:27:25 theanets.trainer:168 RmsProp 192 loss=277.033478 err=5.102883
I 2015-05-27 00:27:36 theanets.trainer:168 RmsProp 193 loss=275.910004 err=4.880120
I 2015-05-27 00:27:46 theanets.trainer:168 RmsProp 194 loss=274.709198 err=4.572425
I 2015-05-27 00:27:56 theanets.trainer:168 RmsProp 195 loss=274.252106 err=5.010299
I 2015-05-27 00:28:06 theanets.trainer:168 RmsProp 196 loss=273.107727 err=4.749677
I 2015-05-27 00:28:16 theanets.trainer:168 RmsProp 197 loss=271.811615 err=4.343620
I 2015-05-27 00:28:27 theanets.trainer:168 RmsProp 198 loss=271.927887 err=5.351506
I 2015-05-27 00:28:37 theanets.trainer:168 RmsProp 199 loss=270.280945 err=4.562181
I 2015-05-27 00:28:47 theanets.trainer:168 RmsProp 200 loss=269.478455 err=4.611913
I 2015-05-27 00:28:47 theanets.trainer:168 validation 20 loss=1341.907715 err=1077.516479 *
I 2015-05-27 00:28:58 theanets.trainer:168 RmsProp 201 loss=268.650848 err=4.642715
I 2015-05-27 00:29:09 theanets.trainer:168 RmsProp 202 loss=267.817902 err=4.666990
I 2015-05-27 00:29:19 theanets.trainer:168 RmsProp 203 loss=266.876801 err=4.578761
I 2015-05-27 00:29:30 theanets.trainer:168 RmsProp 204 loss=266.353516 err=4.890891
I 2015-05-27 00:29:40 theanets.trainer:168 RmsProp 205 loss=265.389313 err=4.767733
I 2015-05-27 00:29:51 theanets.trainer:168 RmsProp 206 loss=264.323639 err=4.526814
I 2015-05-27 00:30:01 theanets.trainer:168 RmsProp 207 loss=263.549835 err=4.568933
I 2015-05-27 00:30:11 theanets.trainer:168 RmsProp 208 loss=262.795441 err=4.619364
I 2015-05-27 00:30:22 theanets.trainer:168 RmsProp 209 loss=261.830658 err=4.460285
I 2015-05-27 00:30:32 theanets.trainer:168 RmsProp 210 loss=261.299408 err=4.733018
I 2015-05-27 00:30:32 theanets.trainer:168 validation 21 loss=1344.949219 err=1088.821655
I 2015-05-27 00:30:42 theanets.trainer:168 RmsProp 211 loss=260.342712 err=4.575057
I 2015-05-27 00:30:53 theanets.trainer:168 RmsProp 212 loss=259.390472 err=4.411514
I 2015-05-27 00:31:03 theanets.trainer:168 RmsProp 213 loss=258.721069 err=4.533271
I 2015-05-27 00:31:14 theanets.trainer:168 RmsProp 214 loss=258.045105 err=4.646237
I 2015-05-27 00:31:24 theanets.trainer:168 RmsProp 215 loss=257.076355 err=4.457891
I 2015-05-27 00:31:34 theanets.trainer:168 RmsProp 216 loss=256.456543 err=4.615878
I 2015-05-27 00:31:44 theanets.trainer:168 RmsProp 217 loss=255.570801 err=4.501449
I 2015-05-27 00:31:55 theanets.trainer:168 RmsProp 218 loss=254.697601 err=4.385066
I 2015-05-27 00:32:05 theanets.trainer:168 RmsProp 219 loss=254.285126 err=4.733698
I 2015-05-27 00:32:15 theanets.trainer:168 RmsProp 220 loss=253.105179 err=4.301826
I 2015-05-27 00:32:16 theanets.trainer:168 validation 22 loss=1328.023804 err=1079.624023 *
I 2015-05-27 00:32:26 theanets.trainer:168 RmsProp 221 loss=252.504761 err=4.436965
I 2015-05-27 00:32:36 theanets.trainer:168 RmsProp 222 loss=251.552002 err=4.221474
I 2015-05-27 00:32:47 theanets.trainer:168 RmsProp 223 loss=251.227142 err=4.637753
I 2015-05-27 00:32:57 theanets.trainer:168 RmsProp 224 loss=250.426422 err=4.571244
I 2015-05-27 00:33:08 theanets.trainer:168 RmsProp 225 loss=249.402924 err=4.268449
I 2015-05-27 00:33:18 theanets.trainer:168 RmsProp 226 loss=248.583740 err=4.165472
I 2015-05-27 00:33:28 theanets.trainer:168 RmsProp 227 loss=248.266403 err=4.567529
I 2015-05-27 00:33:39 theanets.trainer:168 RmsProp 228 loss=247.236664 err=4.254265
I 2015-05-27 00:33:49 theanets.trainer:168 RmsProp 229 loss=246.491257 err=4.220693
I 2015-05-27 00:34:00 theanets.trainer:168 RmsProp 230 loss=245.967606 err=4.419368
I 2015-05-27 00:34:00 theanets.trainer:168 validation 23 loss=1328.325195 err=1087.177368
I 2015-05-27 00:34:11 theanets.trainer:168 RmsProp 231 loss=244.970779 err=4.145420
I 2015-05-27 00:34:21 theanets.trainer:168 RmsProp 232 loss=244.535980 err=4.424627
I 2015-05-27 00:34:32 theanets.trainer:168 RmsProp 233 loss=243.762772 err=4.359798
I 2015-05-27 00:34:42 theanets.trainer:168 RmsProp 234 loss=242.927277 err=4.218022
I 2015-05-27 00:34:53 theanets.trainer:168 RmsProp 235 loss=242.322662 err=4.309556
I 2015-05-27 00:35:03 theanets.trainer:168 RmsProp 236 loss=241.402496 err=4.077387
I 2015-05-27 00:35:14 theanets.trainer:168 RmsProp 237 loss=240.948273 err=4.316649
I 2015-05-27 00:35:25 theanets.trainer:168 RmsProp 238 loss=240.237579 err=4.287962
I 2015-05-27 00:35:35 theanets.trainer:168 RmsProp 239 loss=239.450882 err=4.170269
I 2015-05-27 00:35:46 theanets.trainer:168 RmsProp 240 loss=239.220657 err=4.598353
I 2015-05-27 00:35:46 theanets.trainer:168 validation 24 loss=1325.399780 err=1091.133911 *
I 2015-05-27 00:35:57 theanets.trainer:168 RmsProp 241 loss=238.024612 err=4.057565
I 2015-05-27 00:36:07 theanets.trainer:168 RmsProp 242 loss=237.484329 err=4.171195
I 2015-05-27 00:36:17 theanets.trainer:168 RmsProp 243 loss=236.888916 err=4.232619
I 2015-05-27 00:36:27 theanets.trainer:168 RmsProp 244 loss=236.046997 err=4.048328
I 2015-05-27 00:36:38 theanets.trainer:168 RmsProp 245 loss=235.629471 err=4.286079
I 2015-05-27 00:36:48 theanets.trainer:168 RmsProp 246 loss=234.888962 err=4.189800
I 2015-05-27 00:36:59 theanets.trainer:168 RmsProp 247 loss=234.013031 err=3.954293
I 2015-05-27 00:37:09 theanets.trainer:168 RmsProp 248 loss=233.714142 err=4.298677
I 2015-05-27 00:37:20 theanets.trainer:168 RmsProp 249 loss=232.924713 err=4.151872
I 2015-05-27 00:37:31 theanets.trainer:168 RmsProp 250 loss=232.011505 err=3.871877
I 2015-05-27 00:37:31 theanets.trainer:168 validation 25 loss=1306.946289 err=1079.150879 *
I 2015-05-27 00:37:42 theanets.trainer:168 RmsProp 251 loss=231.605621 err=4.101367
I 2015-05-27 00:37:52 theanets.trainer:168 RmsProp 252 loss=231.093216 err=4.218540
I 2015-05-27 00:38:02 theanets.trainer:168 RmsProp 253 loss=230.602203 err=4.344108
I 2015-05-27 00:38:13 theanets.trainer:168 RmsProp 254 loss=229.779953 err=4.127479
I 2015-05-27 00:38:23 theanets.trainer:168 RmsProp 255 loss=229.209106 err=4.151538
I 2015-05-27 00:38:33 theanets.trainer:168 RmsProp 256 loss=228.454544 err=3.994924
I 2015-05-27 00:38:43 theanets.trainer:168 RmsProp 257 loss=228.071075 err=4.207432
I 2015-05-27 00:38:54 theanets.trainer:168 RmsProp 258 loss=227.300537 err=4.038380
I 2015-05-27 00:39:04 theanets.trainer:168 RmsProp 259 loss=226.689301 err=4.016973
I 2015-05-27 00:39:15 theanets.trainer:168 RmsProp 260 loss=226.026443 err=3.950555
I 2015-05-27 00:39:15 theanets.trainer:168 validation 26 loss=1315.329102 err=1093.585083
I 2015-05-27 00:39:25 theanets.trainer:168 RmsProp 261 loss=225.556839 err=4.079404
I 2015-05-27 00:39:36 theanets.trainer:168 RmsProp 262 loss=224.808517 err=3.919391
I 2015-05-27 00:39:46 theanets.trainer:168 RmsProp 263 loss=224.413055 err=4.103853
I 2015-05-27 00:39:56 theanets.trainer:168 RmsProp 264 loss=223.833908 err=4.101977
I 2015-05-27 00:40:07 theanets.trainer:168 RmsProp 265 loss=222.670990 err=3.518770
I 2015-05-27 00:40:17 theanets.trainer:168 RmsProp 266 loss=223.169357 err=4.591012
I 2015-05-27 00:40:27 theanets.trainer:168 RmsProp 267 loss=221.921844 err=3.920207
I 2015-05-27 00:40:37 theanets.trainer:168 RmsProp 268 loss=221.119110 err=3.683751
I 2015-05-27 00:40:48 theanets.trainer:168 RmsProp 269 loss=220.915482 err=4.049331
I 2015-05-27 00:40:58 theanets.trainer:168 RmsProp 270 loss=220.501495 err=4.199781
I 2015-05-27 00:40:59 theanets.trainer:168 validation 27 loss=1299.300781 err=1083.295654 *
I 2015-05-27 00:41:09 theanets.trainer:168 RmsProp 271 loss=219.666672 err=3.911224
I 2015-05-27 00:41:19 theanets.trainer:168 RmsProp 272 loss=219.230789 err=4.014468
I 2015-05-27 00:41:29 theanets.trainer:168 RmsProp 273 loss=218.536652 err=3.862822
I 2015-05-27 00:41:40 theanets.trainer:168 RmsProp 274 loss=218.298904 err=4.164737
I 2015-05-27 00:41:50 theanets.trainer:168 RmsProp 275 loss=217.420731 err=3.825455
I 2015-05-27 00:42:00 theanets.trainer:168 RmsProp 276 loss=216.786774 err=3.725106
I 2015-05-27 00:42:11 theanets.trainer:168 RmsProp 277 loss=216.382370 err=3.852835
I 2015-05-27 00:42:21 theanets.trainer:168 RmsProp 278 loss=215.997101 err=4.001590
I 2015-05-27 00:42:31 theanets.trainer:168 RmsProp 279 loss=215.494217 err=4.032516
I 2015-05-27 00:42:42 theanets.trainer:168 RmsProp 280 loss=214.823029 err=3.885973
I 2015-05-27 00:42:42 theanets.trainer:168 validation 28 loss=1292.573975 err=1081.920166 *
I 2015-05-27 00:42:53 theanets.trainer:168 RmsProp 281 loss=213.895752 err=3.482430
I 2015-05-27 00:43:03 theanets.trainer:168 RmsProp 282 loss=214.167404 err=4.280507
I 2015-05-27 00:43:14 theanets.trainer:168 RmsProp 283 loss=213.332489 err=3.968991
I 2015-05-27 00:43:24 theanets.trainer:168 RmsProp 284 loss=212.558304 err=3.710276
I 2015-05-27 00:43:34 theanets.trainer:168 RmsProp 285 loss=212.194336 err=3.859713
I 2015-05-27 00:43:45 theanets.trainer:168 RmsProp 286 loss=211.496429 err=3.680858
I 2015-05-27 00:43:55 theanets.trainer:168 RmsProp 287 loss=211.294342 err=4.003155
I 2015-05-27 00:44:06 theanets.trainer:168 RmsProp 288 loss=210.763260 err=3.981911
I 2015-05-27 00:44:16 theanets.trainer:168 RmsProp 289 loss=209.882248 err=3.595669
I 2015-05-27 00:44:27 theanets.trainer:168 RmsProp 290 loss=209.773315 err=3.982138
I 2015-05-27 00:44:27 theanets.trainer:168 validation 29 loss=1304.550171 err=1099.032715
I 2015-05-27 00:44:38 theanets.trainer:168 RmsProp 291 loss=209.115997 err=3.825972
I 2015-05-27 00:44:48 theanets.trainer:168 RmsProp 292 loss=208.732590 err=3.935300
I 2015-05-27 00:44:59 theanets.trainer:168 RmsProp 293 loss=207.969315 err=3.664744
I 2015-05-27 00:45:09 theanets.trainer:168 RmsProp 294 loss=207.648727 err=3.833803
I 2015-05-27 00:45:19 theanets.trainer:168 RmsProp 295 loss=207.237183 err=3.904413
I 2015-05-27 00:45:30 theanets.trainer:168 RmsProp 296 loss=206.656860 err=3.801471
I 2015-05-27 00:45:41 theanets.trainer:168 RmsProp 297 loss=205.952881 err=3.570719
I 2015-05-27 00:45:51 theanets.trainer:168 RmsProp 298 loss=205.499481 err=3.600065
I 2015-05-27 00:46:02 theanets.trainer:168 RmsProp 299 loss=205.270554 err=3.854497
I 2015-05-27 00:46:12 theanets.trainer:168 RmsProp 300 loss=204.780899 err=3.848910
I 2015-05-27 00:46:12 theanets.trainer:168 validation 30 loss=1284.018799 err=1083.343140 *
I 2015-05-27 00:46:23 theanets.trainer:168 RmsProp 301 loss=204.071915 err=3.616781
I 2015-05-27 00:46:33 theanets.trainer:168 RmsProp 302 loss=203.714340 err=3.737546
I 2015-05-27 00:46:44 theanets.trainer:168 RmsProp 303 loss=203.308502 err=3.808213
I 2015-05-27 00:46:54 theanets.trainer:168 RmsProp 304 loss=202.765717 err=3.731106
I 2015-05-27 00:47:04 theanets.trainer:168 RmsProp 305 loss=202.084503 err=3.512988
I 2015-05-27 00:47:15 theanets.trainer:168 RmsProp 306 loss=201.909973 err=3.804017
I 2015-05-27 00:47:25 theanets.trainer:168 RmsProp 307 loss=201.331879 err=3.697443
I 2015-05-27 00:47:36 theanets.trainer:168 RmsProp 308 loss=200.910461 err=3.733522
I 2015-05-27 00:47:46 theanets.trainer:168 RmsProp 309 loss=200.268997 err=3.544606
I 2015-05-27 00:47:57 theanets.trainer:168 RmsProp 310 loss=200.316574 err=4.039123
I 2015-05-27 00:47:57 theanets.trainer:168 validation 31 loss=1292.153687 err=1096.122681
I 2015-05-27 00:48:08 theanets.trainer:168 RmsProp 311 loss=199.346390 err=3.511962
I 2015-05-27 00:48:19 theanets.trainer:168 RmsProp 312 loss=198.956116 err=3.562569
I 2015-05-27 00:48:29 theanets.trainer:168 RmsProp 313 loss=198.638077 err=3.690110
I 2015-05-27 00:48:40 theanets.trainer:168 RmsProp 314 loss=198.069733 err=3.569708
I 2015-05-27 00:48:51 theanets.trainer:168 RmsProp 315 loss=197.595245 err=3.536543
I 2015-05-27 00:49:01 theanets.trainer:168 RmsProp 316 loss=197.252243 err=3.632857
I 2015-05-27 00:49:12 theanets.trainer:168 RmsProp 317 loss=196.786957 err=3.610717
I 2015-05-27 00:49:23 theanets.trainer:168 RmsProp 318 loss=196.259659 err=3.518816
I 2015-05-27 00:49:33 theanets.trainer:168 RmsProp 319 loss=195.990082 err=3.687002
I 2015-05-27 00:49:44 theanets.trainer:168 RmsProp 320 loss=195.581024 err=3.711713
I 2015-05-27 00:49:45 theanets.trainer:168 validation 32 loss=1274.290283 err=1082.649414 *
I 2015-05-27 00:49:55 theanets.trainer:168 RmsProp 321 loss=195.305344 err=3.859072
I 2015-05-27 00:50:06 theanets.trainer:168 RmsProp 322 loss=194.555496 err=3.531987
I 2015-05-27 00:50:16 theanets.trainer:168 RmsProp 323 loss=194.148849 err=3.545089
I 2015-05-27 00:50:27 theanets.trainer:168 RmsProp 324 loss=193.748123 err=3.570170
I 2015-05-27 00:50:38 theanets.trainer:168 RmsProp 325 loss=193.348053 err=3.589000
I 2015-05-27 00:50:48 theanets.trainer:168 RmsProp 326 loss=192.773712 err=3.440130
I 2015-05-27 00:50:59 theanets.trainer:168 RmsProp 327 loss=192.616547 err=3.703957
I 2015-05-27 00:51:09 theanets.trainer:168 RmsProp 328 loss=191.986435 err=3.491156
I 2015-05-27 00:51:20 theanets.trainer:168 RmsProp 329 loss=191.505142 err=3.427273
I 2015-05-27 00:51:30 theanets.trainer:168 RmsProp 330 loss=191.358795 err=3.694871
I 2015-05-27 00:51:31 theanets.trainer:168 validation 33 loss=1272.400024 err=1084.960205 *
I 2015-05-27 00:51:41 theanets.trainer:168 RmsProp 331 loss=190.713501 err=3.461645
I 2015-05-27 00:51:52 theanets.trainer:168 RmsProp 332 loss=190.415314 err=3.573555
I 2015-05-27 00:52:02 theanets.trainer:168 RmsProp 333 loss=189.988693 err=3.555151
I 2015-05-27 00:52:13 theanets.trainer:168 RmsProp 334 loss=189.509445 err=3.479678
I 2015-05-27 00:52:23 theanets.trainer:168 RmsProp 335 loss=189.219086 err=3.592997
I 2015-05-27 00:52:34 theanets.trainer:168 RmsProp 336 loss=188.673157 err=3.447984
I 2015-05-27 00:52:45 theanets.trainer:168 RmsProp 337 loss=188.244186 err=3.413137
I 2015-05-27 00:52:55 theanets.trainer:168 RmsProp 338 loss=187.915009 err=3.477376
I 2015-05-27 00:53:06 theanets.trainer:168 RmsProp 339 loss=187.730774 err=3.682839
I 2015-05-27 00:53:16 theanets.trainer:168 RmsProp 340 loss=187.344406 err=3.683491
I 2015-05-27 00:53:16 theanets.trainer:168 validation 34 loss=1281.002441 err=1097.553589
I 2015-05-27 00:53:27 theanets.trainer:168 RmsProp 341 loss=186.649170 err=3.371196
I 2015-05-27 00:53:37 theanets.trainer:168 RmsProp 342 loss=186.498276 err=3.603652
I 2015-05-27 00:53:48 theanets.trainer:168 RmsProp 343 loss=186.042389 err=3.531391
I 2015-05-27 00:53:58 theanets.trainer:168 RmsProp 344 loss=185.506073 err=3.374299
I 2015-05-27 00:54:09 theanets.trainer:168 RmsProp 345 loss=185.186661 err=3.435987
I 2015-05-27 00:54:19 theanets.trainer:168 RmsProp 346 loss=184.740448 err=3.377244
I 2015-05-27 00:54:30 theanets.trainer:168 RmsProp 347 loss=184.508194 err=3.520070
I 2015-05-27 00:54:40 theanets.trainer:168 RmsProp 348 loss=184.089661 err=3.476889
I 2015-05-27 00:54:51 theanets.trainer:168 RmsProp 349 loss=183.443237 err=3.214188
I 2015-05-27 00:55:01 theanets.trainer:168 RmsProp 350 loss=183.447296 err=3.598266
I 2015-05-27 00:55:02 theanets.trainer:168 validation 35 loss=1264.635376 err=1084.992554 *
I 2015-05-27 00:55:13 theanets.trainer:168 RmsProp 351 loss=182.888962 err=3.416782
I 2015-05-27 00:55:23 theanets.trainer:168 RmsProp 352 loss=182.466690 err=3.371246
I 2015-05-27 00:55:34 theanets.trainer:168 RmsProp 353 loss=182.139648 err=3.426760
I 2015-05-27 00:55:44 theanets.trainer:168 RmsProp 354 loss=181.739288 err=3.404750
I 2015-05-27 00:55:55 theanets.trainer:168 RmsProp 355 loss=181.431244 err=3.460962
I 2015-05-27 00:56:05 theanets.trainer:168 RmsProp 356 loss=180.919556 err=3.320125
I 2015-05-27 00:56:15 theanets.trainer:168 RmsProp 357 loss=181.113449 err=3.868905
I 2015-05-27 00:56:26 theanets.trainer:168 RmsProp 358 loss=180.055237 err=3.168930
I 2015-05-27 00:56:37 theanets.trainer:168 RmsProp 359 loss=180.115799 err=3.590820
I 2015-05-27 00:56:47 theanets.trainer:168 RmsProp 360 loss=179.603897 err=3.434708
I 2015-05-27 00:56:48 theanets.trainer:168 validation 36 loss=1281.924194 err=1105.950073
I 2015-05-27 00:56:58 theanets.trainer:168 RmsProp 361 loss=179.003220 err=3.198233
I 2015-05-27 00:57:08 theanets.trainer:168 RmsProp 362 loss=179.225128 err=3.769369
I 2015-05-27 00:57:19 theanets.trainer:168 RmsProp 363 loss=178.466644 err=3.362440
I 2015-05-27 00:57:29 theanets.trainer:168 RmsProp 364 loss=178.314865 err=3.548398
I 2015-05-27 00:57:39 theanets.trainer:168 RmsProp 365 loss=177.907745 err=3.478510
I 2015-05-27 00:57:50 theanets.trainer:168 RmsProp 366 loss=177.286423 err=3.196529
I 2015-05-27 00:58:00 theanets.trainer:168 RmsProp 367 loss=177.508255 err=3.750197
I 2015-05-27 00:58:11 theanets.trainer:168 RmsProp 368 loss=176.694626 err=3.275465
I 2015-05-27 00:58:21 theanets.trainer:168 RmsProp 369 loss=176.520859 err=3.441310
I 2015-05-27 00:58:31 theanets.trainer:168 RmsProp 370 loss=176.000900 err=3.264244
I 2015-05-27 00:58:32 theanets.trainer:168 validation 37 loss=1264.401489 err=1091.854736 *
I 2015-05-27 00:58:42 theanets.trainer:168 RmsProp 371 loss=175.729889 err=3.329692
I 2015-05-27 00:58:53 theanets.trainer:168 RmsProp 372 loss=175.457916 err=3.391959
I 2015-05-27 00:59:03 theanets.trainer:168 RmsProp 373 loss=174.862000 err=3.136603
I 2015-05-27 00:59:14 theanets.trainer:168 RmsProp 374 loss=174.779297 err=3.389562
I 2015-05-27 00:59:24 theanets.trainer:168 RmsProp 375 loss=174.524628 err=3.471903
I 2015-05-27 00:59:35 theanets.trainer:168 RmsProp 376 loss=174.003677 err=3.278369
I 2015-05-27 00:59:45 theanets.trainer:168 RmsProp 377 loss=173.664597 err=3.268266
I 2015-05-27 00:59:55 theanets.trainer:168 RmsProp 378 loss=173.352631 err=3.289238
I 2015-05-27 01:00:06 theanets.trainer:168 RmsProp 379 loss=173.126251 err=3.391868
I 2015-05-27 01:00:16 theanets.trainer:168 RmsProp 380 loss=172.422119 err=3.024566
I 2015-05-27 01:00:17 theanets.trainer:168 validation 38 loss=1256.009888 err=1086.792847 *
I 2015-05-27 01:00:27 theanets.trainer:168 RmsProp 381 loss=172.859955 err=3.784746
I 2015-05-27 01:00:37 theanets.trainer:168 RmsProp 382 loss=172.032883 err=3.283989
I 2015-05-27 01:00:48 theanets.trainer:168 RmsProp 383 loss=171.564636 err=3.132730
I 2015-05-27 01:00:58 theanets.trainer:168 RmsProp 384 loss=171.364609 err=3.251302
I 2015-05-27 01:01:08 theanets.trainer:168 RmsProp 385 loss=171.173920 err=3.378381
I 2015-05-27 01:01:18 theanets.trainer:168 RmsProp 386 loss=170.772614 err=3.303033
I 2015-05-27 01:01:28 theanets.trainer:168 RmsProp 387 loss=170.652420 err=3.505122
I 2015-05-27 01:01:39 theanets.trainer:168 RmsProp 388 loss=170.017303 err=3.185234
I 2015-05-27 01:01:49 theanets.trainer:168 RmsProp 389 loss=169.794815 err=3.278838
I 2015-05-27 01:01:59 theanets.trainer:168 RmsProp 390 loss=169.578949 err=3.373506
I 2015-05-27 01:01:59 theanets.trainer:168 validation 39 loss=1251.103394 err=1085.055786 *
I 2015-05-27 01:02:10 theanets.trainer:168 RmsProp 391 loss=169.292999 err=3.394452
I 2015-05-27 01:02:20 theanets.trainer:168 RmsProp 392 loss=168.883087 err=3.291080
I 2015-05-27 01:02:31 theanets.trainer:168 RmsProp 393 loss=168.801544 err=3.510655
I 2015-05-27 01:02:41 theanets.trainer:168 RmsProp 394 loss=168.126328 err=3.137188
I 2015-05-27 01:02:51 theanets.trainer:168 RmsProp 395 loss=167.947098 err=3.261821
I 2015-05-27 01:03:02 theanets.trainer:168 RmsProp 396 loss=167.524811 err=3.149493
I 2015-05-27 01:03:12 theanets.trainer:168 RmsProp 397 loss=167.264923 err=3.194366
I 2015-05-27 01:03:22 theanets.trainer:168 RmsProp 398 loss=166.962234 err=3.202745
I 2015-05-27 01:03:33 theanets.trainer:168 RmsProp 399 loss=166.584808 err=3.137554
I 2015-05-27 01:03:43 theanets.trainer:168 RmsProp 400 loss=166.404007 err=3.265000
I 2015-05-27 01:03:44 theanets.trainer:168 validation 40 loss=1262.615845 err=1099.646729
I 2015-05-27 01:03:55 theanets.trainer:168 RmsProp 401 loss=165.700775 err=2.870039
I 2015-05-27 01:04:05 theanets.trainer:168 RmsProp 402 loss=166.021027 err=3.493083
I 2015-05-27 01:04:16 theanets.trainer:168 RmsProp 403 loss=165.602997 err=3.375384
I 2015-05-27 01:04:26 theanets.trainer:168 RmsProp 404 loss=165.094757 err=3.162477
I 2015-05-27 01:04:37 theanets.trainer:168 RmsProp 405 loss=164.726105 err=3.088771
I 2015-05-27 01:04:47 theanets.trainer:168 RmsProp 406 loss=164.699539 err=3.357346
I 2015-05-27 01:04:58 theanets.trainer:168 RmsProp 407 loss=164.126205 err=3.079040
I 2015-05-27 01:05:09 theanets.trainer:168 RmsProp 408 loss=163.829422 err=3.078021
I 2015-05-27 01:05:19 theanets.trainer:168 RmsProp 409 loss=163.743408 err=3.283112
I 2015-05-27 01:05:30 theanets.trainer:168 RmsProp 410 loss=163.277985 err=3.115149
I 2015-05-27 01:05:31 theanets.trainer:168 validation 41 loss=1246.938721 err=1086.937866 *
I 2015-05-27 01:05:41 theanets.trainer:168 RmsProp 411 loss=163.119019 err=3.245797
I 2015-05-27 01:05:52 theanets.trainer:168 RmsProp 412 loss=162.762009 err=3.177703
I 2015-05-27 01:06:02 theanets.trainer:168 RmsProp 413 loss=162.509659 err=3.215462
I 2015-05-27 01:06:13 theanets.trainer:168 RmsProp 414 loss=162.082001 err=3.079711
I 2015-05-27 01:06:24 theanets.trainer:168 RmsProp 415 loss=161.875214 err=3.157833
I 2015-05-27 01:06:34 theanets.trainer:168 RmsProp 416 loss=161.529205 err=3.091426
I 2015-05-27 01:06:45 theanets.trainer:168 RmsProp 417 loss=161.299011 err=3.144464
I 2015-05-27 01:06:55 theanets.trainer:168 RmsProp 418 loss=161.135956 err=3.263049
I 2015-05-27 01:07:06 theanets.trainer:168 RmsProp 419 loss=160.515137 err=2.928731
I 2015-05-27 01:07:16 theanets.trainer:168 RmsProp 420 loss=160.628647 err=3.320302
I 2015-05-27 01:07:17 theanets.trainer:168 validation 42 loss=1240.026123 err=1082.871460 *
I 2015-05-27 01:07:27 theanets.trainer:168 RmsProp 421 loss=160.178375 err=3.151267
I 2015-05-27 01:07:38 theanets.trainer:168 RmsProp 422 loss=159.834198 err=3.085788
I 2015-05-27 01:07:48 theanets.trainer:168 RmsProp 423 loss=159.565720 err=3.096679
I 2015-05-27 01:07:59 theanets.trainer:168 RmsProp 424 loss=159.243500 err=3.056648
I 2015-05-27 01:08:10 theanets.trainer:168 RmsProp 425 loss=159.244797 err=3.333467
I 2015-05-27 01:08:20 theanets.trainer:168 RmsProp 426 loss=158.631882 err=2.995977
I 2015-05-27 01:08:31 theanets.trainer:168 RmsProp 427 loss=158.481552 err=3.114309
I 2015-05-27 01:08:42 theanets.trainer:168 RmsProp 428 loss=158.118149 err=3.020561
I 2015-05-27 01:08:52 theanets.trainer:168 RmsProp 429 loss=158.043945 err=3.219735
I 2015-05-27 01:09:03 theanets.trainer:168 RmsProp 430 loss=157.703201 err=3.146977
I 2015-05-27 01:09:03 theanets.trainer:168 validation 43 loss=1242.201782 err=1087.799194
I 2015-05-27 01:09:14 theanets.trainer:168 RmsProp 431 loss=157.415939 err=3.128977
I 2015-05-27 01:09:25 theanets.trainer:168 RmsProp 432 loss=157.185089 err=3.166714
I 2015-05-27 01:09:35 theanets.trainer:168 RmsProp 433 loss=156.750580 err=2.995007
I 2015-05-27 01:09:46 theanets.trainer:168 RmsProp 434 loss=156.786224 err=3.296641
I 2015-05-27 01:09:57 theanets.trainer:168 RmsProp 435 loss=156.183029 err=2.959298
I 2015-05-27 01:10:07 theanets.trainer:168 RmsProp 436 loss=156.072769 err=3.107892
I 2015-05-27 01:10:18 theanets.trainer:168 RmsProp 437 loss=156.042587 err=3.332614
I 2015-05-27 01:10:28 theanets.trainer:168 RmsProp 438 loss=155.506607 err=3.055354
I 2015-05-27 01:10:39 theanets.trainer:168 RmsProp 439 loss=155.345291 err=3.145188
I 2015-05-27 01:10:50 theanets.trainer:168 RmsProp 440 loss=154.993317 err=3.052956
I 2015-05-27 01:10:51 theanets.trainer:168 validation 44 loss=1240.339355 err=1088.539673
I 2015-05-27 01:11:02 theanets.trainer:168 RmsProp 441 loss=154.690155 err=3.003947
I 2015-05-27 01:11:12 theanets.trainer:168 RmsProp 442 loss=154.451859 err=3.022015
I 2015-05-27 01:11:23 theanets.trainer:168 RmsProp 443 loss=154.379822 err=3.204181
I 2015-05-27 01:11:34 theanets.trainer:168 RmsProp 444 loss=154.062576 err=3.136749
I 2015-05-27 01:11:45 theanets.trainer:168 RmsProp 445 loss=153.546051 err=2.871554
I 2015-05-27 01:11:55 theanets.trainer:168 RmsProp 446 loss=153.816238 err=3.387773
I 2015-05-27 01:12:06 theanets.trainer:168 RmsProp 447 loss=153.100418 err=2.919724
I 2015-05-27 01:12:17 theanets.trainer:168 RmsProp 448 loss=152.865707 err=2.933350
I 2015-05-27 01:12:27 theanets.trainer:168 RmsProp 449 loss=152.629517 err=2.948107
I 2015-05-27 01:12:38 theanets.trainer:168 RmsProp 450 loss=152.523956 err=3.092446
I 2015-05-27 01:12:38 theanets.trainer:168 validation 45 loss=1249.399414 err=1100.099976
I 2015-05-27 01:12:49 theanets.trainer:168 RmsProp 451 loss=152.273758 err=3.086715
I 2015-05-27 01:12:59 theanets.trainer:168 RmsProp 452 loss=151.985901 err=3.048498
I 2015-05-27 01:13:10 theanets.trainer:168 RmsProp 453 loss=151.948761 err=3.255668
I 2015-05-27 01:13:21 theanets.trainer:168 RmsProp 454 loss=151.437531 err=2.986334
I 2015-05-27 01:13:31 theanets.trainer:168 RmsProp 455 loss=151.350296 err=3.138939
I 2015-05-27 01:13:41 theanets.trainer:168 RmsProp 456 loss=151.055450 err=3.086105
I 2015-05-27 01:13:52 theanets.trainer:168 RmsProp 457 loss=150.627869 err=2.895576
I 2015-05-27 01:14:02 theanets.trainer:168 RmsProp 458 loss=150.422394 err=2.927670
I 2015-05-27 01:14:13 theanets.trainer:168 RmsProp 459 loss=150.431213 err=3.177311
I 2015-05-27 01:14:23 theanets.trainer:168 RmsProp 460 loss=150.297073 err=3.276770
I 2015-05-27 01:14:23 theanets.trainer:168 validation 46 loss=1223.695068 err=1076.801147 *
I 2015-05-27 01:14:34 theanets.trainer:168 RmsProp 461 loss=149.754486 err=2.969157
I 2015-05-27 01:14:44 theanets.trainer:168 RmsProp 462 loss=149.706375 err=3.153560
I 2015-05-27 01:14:55 theanets.trainer:168 RmsProp 463 loss=149.567062 err=3.242637
I 2015-05-27 01:15:05 theanets.trainer:168 RmsProp 464 loss=148.990738 err=2.897308
I 2015-05-27 01:15:16 theanets.trainer:168 RmsProp 465 loss=148.866516 err=3.009972
I 2015-05-27 01:15:26 theanets.trainer:168 RmsProp 466 loss=148.707245 err=3.082298
I 2015-05-27 01:15:36 theanets.trainer:168 RmsProp 467 loss=148.266266 err=2.875996
I 2015-05-27 01:15:47 theanets.trainer:168 RmsProp 468 loss=148.395828 err=3.233565
I 2015-05-27 01:15:57 theanets.trainer:168 RmsProp 469 loss=147.953232 err=3.019543
I 2015-05-27 01:16:08 theanets.trainer:168 RmsProp 470 loss=147.817749 err=3.111902
I 2015-05-27 01:16:08 theanets.trainer:168 validation 47 loss=1219.852051 err=1075.270874 *
I 2015-05-27 01:16:19 theanets.trainer:168 RmsProp 471 loss=147.179459 err=2.702297
I 2015-05-27 01:16:30 theanets.trainer:168 RmsProp 472 loss=147.426773 err=3.177196
I 2015-05-27 01:16:40 theanets.trainer:168 RmsProp 473 loss=147.027313 err=3.008164
I 2015-05-27 01:16:51 theanets.trainer:168 RmsProp 474 loss=146.798950 err=3.002464
I 2015-05-27 01:17:01 theanets.trainer:168 RmsProp 475 loss=146.387848 err=2.819673
I 2015-05-27 01:17:11 theanets.trainer:168 RmsProp 476 loss=146.413788 err=3.072078
I 2015-05-27 01:17:21 theanets.trainer:168 RmsProp 477 loss=146.055573 err=2.946903
I 2015-05-27 01:17:32 theanets.trainer:168 RmsProp 478 loss=145.895706 err=3.013518
I 2015-05-27 01:17:42 theanets.trainer:168 RmsProp 479 loss=145.481308 err=2.824844
I 2015-05-27 01:17:53 theanets.trainer:168 RmsProp 480 loss=145.445709 err=3.013069
I 2015-05-27 01:17:54 theanets.trainer:168 validation 48 loss=1220.055176 err=1077.734619
I 2015-05-27 01:18:05 theanets.trainer:168 RmsProp 481 loss=145.188660 err=2.971801
I 2015-05-27 01:18:15 theanets.trainer:168 RmsProp 482 loss=144.943085 err=2.956784
I 2015-05-27 01:18:26 theanets.trainer:168 RmsProp 483 loss=144.700409 err=2.938991
I 2015-05-27 01:18:37 theanets.trainer:168 RmsProp 484 loss=144.537079 err=2.993112
I 2015-05-27 01:18:47 theanets.trainer:168 RmsProp 485 loss=144.156586 err=2.831783
I 2015-05-27 01:18:58 theanets.trainer:168 RmsProp 486 loss=144.068542 err=2.962707
I 2015-05-27 01:19:08 theanets.trainer:168 RmsProp 487 loss=143.781769 err=2.894947
I 2015-05-27 01:19:19 theanets.trainer:168 RmsProp 488 loss=143.596161 err=2.925626
I 2015-05-27 01:19:30 theanets.trainer:168 RmsProp 489 loss=143.494492 err=3.042792
I 2015-05-27 01:19:40 theanets.trainer:168 RmsProp 490 loss=143.489883 err=3.251595
I 2015-05-27 01:19:41 theanets.trainer:168 validation 49 loss=1224.765137 err=1084.648682
I 2015-05-27 01:19:52 theanets.trainer:168 RmsProp 491 loss=142.853058 err=2.832500
I 2015-05-27 01:20:02 theanets.trainer:168 RmsProp 492 loss=142.662582 err=2.856239
I 2015-05-27 01:20:13 theanets.trainer:168 RmsProp 493 loss=142.584274 err=2.988618
I 2015-05-27 01:20:24 theanets.trainer:168 RmsProp 494 loss=142.308990 err=2.926026
I 2015-05-27 01:20:34 theanets.trainer:168 RmsProp 495 loss=141.957458 err=2.791169
I 2015-05-27 01:20:45 theanets.trainer:168 RmsProp 496 loss=141.938171 err=2.980384
I 2015-05-27 01:20:56 theanets.trainer:168 RmsProp 497 loss=141.757111 err=3.008217
I 2015-05-27 01:21:06 theanets.trainer:168 RmsProp 498 loss=141.383469 err=2.842553
I 2015-05-27 01:21:16 theanets.trainer:168 RmsProp 499 loss=141.127274 err=2.800819
I 2015-05-27 01:21:27 theanets.trainer:168 RmsProp 500 loss=141.134109 err=3.017922
I 2015-05-27 01:21:27 theanets.trainer:168 validation 50 loss=1230.908325 err=1092.900269
I 2015-05-27 01:21:38 theanets.trainer:168 RmsProp 501 loss=140.879242 err=2.971704
I 2015-05-27 01:21:48 theanets.trainer:168 RmsProp 502 loss=140.576599 err=2.873554
I 2015-05-27 01:21:59 theanets.trainer:168 RmsProp 503 loss=140.270737 err=2.773444
I 2015-05-27 01:22:10 theanets.trainer:168 RmsProp 504 loss=140.237671 err=2.937831
I 2015-05-27 01:22:21 theanets.trainer:168 RmsProp 505 loss=139.949829 err=2.857439
I 2015-05-27 01:22:31 theanets.trainer:168 RmsProp 506 loss=139.916412 err=3.027821
I 2015-05-27 01:22:42 theanets.trainer:168 RmsProp 507 loss=139.622894 err=2.936100
I 2015-05-27 01:22:53 theanets.trainer:168 RmsProp 508 loss=139.511856 err=3.022753
I 2015-05-27 01:23:03 theanets.trainer:168 RmsProp 509 loss=139.095657 err=2.807859
I 2015-05-27 01:23:14 theanets.trainer:168 RmsProp 510 loss=138.765961 err=2.680266
I 2015-05-27 01:23:14 theanets.trainer:168 validation 51 loss=1198.993774 err=1063.009644 *
I 2015-05-27 01:23:25 theanets.trainer:168 RmsProp 511 loss=138.868988 err=2.983194
I 2015-05-27 01:23:35 theanets.trainer:168 RmsProp 512 loss=138.877441 err=3.189849
I 2015-05-27 01:23:46 theanets.trainer:168 RmsProp 513 loss=138.180664 err=2.693487
I 2015-05-27 01:23:57 theanets.trainer:168 RmsProp 514 loss=138.103714 err=2.808197
I 2015-05-27 01:24:07 theanets.trainer:168 RmsProp 515 loss=138.020844 err=2.923029
I 2015-05-27 01:24:18 theanets.trainer:168 RmsProp 516 loss=137.779800 err=2.878477
I 2015-05-27 01:24:29 theanets.trainer:168 RmsProp 517 loss=137.638367 err=2.934467
I 2015-05-27 01:24:40 theanets.trainer:168 RmsProp 518 loss=137.248291 err=2.735867
I 2015-05-27 01:24:51 theanets.trainer:168 RmsProp 519 loss=137.385971 err=3.067452
I 2015-05-27 01:25:01 theanets.trainer:168 RmsProp 520 loss=137.145355 err=3.022436
I 2015-05-27 01:25:02 theanets.trainer:168 validation 52 loss=1207.543823 err=1073.529419
I 2015-05-27 01:25:13 theanets.trainer:168 RmsProp 521 loss=136.757843 err=2.826045
I 2015-05-27 01:25:23 theanets.trainer:168 RmsProp 522 loss=136.529999 err=2.793331
I 2015-05-27 01:25:34 theanets.trainer:168 RmsProp 523 loss=136.328644 err=2.783576
I 2015-05-27 01:25:44 theanets.trainer:168 RmsProp 524 loss=136.203690 err=2.847959
I 2015-05-27 01:25:55 theanets.trainer:168 RmsProp 525 loss=136.362137 err=3.193616
I 2015-05-27 01:26:05 theanets.trainer:168 RmsProp 526 loss=135.825836 err=2.843242
I 2015-05-27 01:26:16 theanets.trainer:168 RmsProp 527 loss=135.516785 err=2.719142
I 2015-05-27 01:26:26 theanets.trainer:168 RmsProp 528 loss=135.550232 err=2.940741
I 2015-05-27 01:26:37 theanets.trainer:168 RmsProp 529 loss=135.206207 err=2.785244
I 2015-05-27 01:26:47 theanets.trainer:168 RmsProp 530 loss=135.038483 err=2.804802
I 2015-05-27 01:26:48 theanets.trainer:168 validation 53 loss=1205.608887 err=1073.481323
I 2015-05-27 01:26:58 theanets.trainer:168 RmsProp 531 loss=134.889130 err=2.844571
I 2015-05-27 01:27:08 theanets.trainer:168 RmsProp 532 loss=134.803406 err=2.940018
I 2015-05-27 01:27:18 theanets.trainer:168 RmsProp 533 loss=134.662445 err=2.978680
I 2015-05-27 01:27:28 theanets.trainer:168 RmsProp 534 loss=134.361588 err=2.860363
I 2015-05-27 01:27:38 theanets.trainer:168 RmsProp 535 loss=134.159760 err=2.846460
I 2015-05-27 01:27:48 theanets.trainer:168 RmsProp 536 loss=133.928665 err=2.797089
I 2015-05-27 01:27:57 theanets.trainer:168 RmsProp 537 loss=133.698898 err=2.750574
I 2015-05-27 01:28:07 theanets.trainer:168 RmsProp 538 loss=133.641541 err=2.878292
I 2015-05-27 01:28:17 theanets.trainer:168 RmsProp 539 loss=133.350006 err=2.766450
I 2015-05-27 01:28:27 theanets.trainer:168 RmsProp 540 loss=133.210876 err=2.805738
I 2015-05-27 01:28:27 theanets.trainer:168 validation 54 loss=1187.444458 err=1057.140015 *
I 2015-05-27 01:28:38 theanets.trainer:168 RmsProp 541 loss=132.975555 err=2.751811
I 2015-05-27 01:28:48 theanets.trainer:168 RmsProp 542 loss=132.920792 err=2.876838
I 2015-05-27 01:28:59 theanets.trainer:168 RmsProp 543 loss=132.655670 err=2.792520
I 2015-05-27 01:29:09 theanets.trainer:168 RmsProp 544 loss=132.445404 err=2.757010
I 2015-05-27 01:29:20 theanets.trainer:168 RmsProp 545 loss=132.379166 err=2.869148
I 2015-05-27 01:29:30 theanets.trainer:168 RmsProp 546 loss=132.162811 err=2.829195
I 2015-05-27 01:29:41 theanets.trainer:168 RmsProp 547 loss=131.911011 err=2.755204
I 2015-05-27 01:29:51 theanets.trainer:168 RmsProp 548 loss=131.787323 err=2.807076
I 2015-05-27 01:30:02 theanets.trainer:168 RmsProp 549 loss=131.434753 err=2.631913
I 2015-05-27 01:30:13 theanets.trainer:168 RmsProp 550 loss=131.765594 err=3.136209
I 2015-05-27 01:30:13 theanets.trainer:168 validation 55 loss=1178.222656 err=1049.688354 *
I 2015-05-27 01:30:24 theanets.trainer:168 RmsProp 551 loss=131.281296 err=2.826169
I 2015-05-27 01:30:34 theanets.trainer:168 RmsProp 552 loss=130.846802 err=2.564344
I 2015-05-27 01:30:45 theanets.trainer:168 RmsProp 553 loss=130.864166 err=2.754811
I 2015-05-27 01:30:55 theanets.trainer:168 RmsProp 554 loss=130.913040 err=2.976870
I 2015-05-27 01:31:06 theanets.trainer:168 RmsProp 555 loss=130.493073 err=2.735500
I 2015-05-27 01:31:17 theanets.trainer:168 RmsProp 556 loss=130.230011 err=2.644105
I 2015-05-27 01:31:27 theanets.trainer:168 RmsProp 557 loss=130.227402 err=2.811014
I 2015-05-27 01:31:38 theanets.trainer:168 RmsProp 558 loss=130.051178 err=2.804274
I 2015-05-27 01:31:48 theanets.trainer:168 RmsProp 559 loss=130.120941 err=3.038211
I 2015-05-27 01:31:59 theanets.trainer:168 RmsProp 560 loss=129.726242 err=2.808454
I 2015-05-27 01:31:59 theanets.trainer:168 validation 56 loss=1182.971436 err=1056.143799
I 2015-05-27 01:32:10 theanets.trainer:168 RmsProp 561 loss=129.406281 err=2.655001
I 2015-05-27 01:32:21 theanets.trainer:168 RmsProp 562 loss=129.531540 err=2.947873
I 2015-05-27 01:32:31 theanets.trainer:168 RmsProp 563 loss=129.042877 err=2.625399
I 2015-05-27 01:32:41 theanets.trainer:168 RmsProp 564 loss=129.082184 err=2.833086
I 2015-05-27 01:32:52 theanets.trainer:168 RmsProp 565 loss=128.815338 err=2.732222
I 2015-05-27 01:33:03 theanets.trainer:168 RmsProp 566 loss=128.653122 err=2.738889
I 2015-05-27 01:33:13 theanets.trainer:168 RmsProp 567 loss=128.507080 err=2.760758
I 2015-05-27 01:33:24 theanets.trainer:168 RmsProp 568 loss=128.299789 err=2.718094
I 2015-05-27 01:33:35 theanets.trainer:168 RmsProp 569 loss=128.180069 err=2.765226
I 2015-05-27 01:33:46 theanets.trainer:168 RmsProp 570 loss=127.854996 err=2.602246
I 2015-05-27 01:33:46 theanets.trainer:168 validation 57 loss=1171.277100 err=1046.103394 *
I 2015-05-27 01:33:57 theanets.trainer:168 RmsProp 571 loss=128.075378 err=2.984706
I 2015-05-27 01:34:08 theanets.trainer:168 RmsProp 572 loss=127.578140 err=2.650904
I 2015-05-27 01:34:18 theanets.trainer:168 RmsProp 573 loss=127.520775 err=2.758803
I 2015-05-27 01:34:29 theanets.trainer:168 RmsProp 574 loss=127.305031 err=2.708045
I 2015-05-27 01:34:39 theanets.trainer:168 RmsProp 575 loss=127.150650 err=2.717146
I 2015-05-27 01:34:50 theanets.trainer:168 RmsProp 576 loss=126.970177 err=2.696272
I 2015-05-27 01:35:00 theanets.trainer:168 RmsProp 577 loss=126.699341 err=2.586267
I 2015-05-27 01:35:11 theanets.trainer:168 RmsProp 578 loss=126.795067 err=2.843236
I 2015-05-27 01:35:22 theanets.trainer:168 RmsProp 579 loss=126.371178 err=2.581978
I 2015-05-27 01:35:32 theanets.trainer:168 RmsProp 580 loss=126.560631 err=2.931057
I 2015-05-27 01:35:32 theanets.trainer:168 validation 58 loss=1187.738403 err=1064.192383
I 2015-05-27 01:35:43 theanets.trainer:168 RmsProp 581 loss=126.059494 err=2.588850
I 2015-05-27 01:35:53 theanets.trainer:168 RmsProp 582 loss=126.022972 err=2.716064
I 2015-05-27 01:36:04 theanets.trainer:168 RmsProp 583 loss=125.843178 err=2.696895
I 2015-05-27 01:36:14 theanets.trainer:168 RmsProp 584 loss=126.016479 err=3.020025
I 2015-05-27 01:36:25 theanets.trainer:168 RmsProp 585 loss=125.317970 err=2.481875
I 2015-05-27 01:36:36 theanets.trainer:168 RmsProp 586 loss=125.395889 err=2.717181
I 2015-05-27 01:36:47 theanets.trainer:168 RmsProp 587 loss=125.496155 err=2.976836
I 2015-05-27 01:36:57 theanets.trainer:168 RmsProp 588 loss=125.141151 err=2.772926
I 2015-05-27 01:37:08 theanets.trainer:168 RmsProp 589 loss=124.920189 err=2.704777
I 2015-05-27 01:37:19 theanets.trainer:168 RmsProp 590 loss=124.718826 err=2.656547
I 2015-05-27 01:37:20 theanets.trainer:168 validation 59 loss=1167.101318 err=1045.126953 *
I 2015-05-27 01:37:30 theanets.trainer:168 RmsProp 591 loss=124.614380 err=2.705643
I 2015-05-27 01:37:41 theanets.trainer:168 RmsProp 592 loss=124.335876 err=2.583665
I 2015-05-27 01:37:51 theanets.trainer:168 RmsProp 593 loss=124.528122 err=2.926011
I 2015-05-27 01:38:02 theanets.trainer:168 RmsProp 594 loss=124.106812 err=2.660535
I 2015-05-27 01:38:13 theanets.trainer:168 RmsProp 595 loss=124.003479 err=2.708104
I 2015-05-27 01:38:24 theanets.trainer:168 RmsProp 596 loss=123.689720 err=2.546173
I 2015-05-27 01:38:34 theanets.trainer:168 RmsProp 597 loss=123.796646 err=2.806481
I 2015-05-27 01:38:45 theanets.trainer:168 RmsProp 598 loss=123.369705 err=2.533904
I 2015-05-27 01:38:55 theanets.trainer:168 RmsProp 599 loss=123.700424 err=3.009684
I 2015-05-27 01:39:06 theanets.trainer:168 RmsProp 600 loss=123.168320 err=2.628087
I 2015-05-27 01:39:07 theanets.trainer:168 validation 60 loss=1158.770874 err=1038.307129 *
I 2015-05-27 01:39:17 theanets.trainer:168 RmsProp 601 loss=122.940002 err=2.550468
I 2015-05-27 01:39:28 theanets.trainer:168 RmsProp 602 loss=122.684471 err=2.445425
I 2015-05-27 01:39:38 theanets.trainer:168 RmsProp 603 loss=122.890160 err=2.801871
I 2015-05-27 01:39:48 theanets.trainer:168 RmsProp 604 loss=122.478859 err=2.544203
I 2015-05-27 01:39:59 theanets.trainer:168 RmsProp 605 loss=122.577232 err=2.790341
I 2015-05-27 01:40:10 theanets.trainer:168 RmsProp 606 loss=122.285889 err=2.653297
I 2015-05-27 01:40:21 theanets.trainer:168 RmsProp 607 loss=122.098190 err=2.612875
I 2015-05-27 01:40:32 theanets.trainer:168 RmsProp 608 loss=122.200951 err=2.860604
I 2015-05-27 01:40:43 theanets.trainer:168 RmsProp 609 loss=121.927383 err=2.734020
I 2015-05-27 01:40:53 theanets.trainer:168 RmsProp 610 loss=121.945534 err=2.892780
I 2015-05-27 01:40:54 theanets.trainer:168 validation 61 loss=1151.097046 err=1032.125366 *
I 2015-05-27 01:41:04 theanets.trainer:168 RmsProp 611 loss=121.557022 err=2.646175
I 2015-05-27 01:41:14 theanets.trainer:168 RmsProp 612 loss=121.423477 err=2.656233
I 2015-05-27 01:41:24 theanets.trainer:168 RmsProp 613 loss=121.303406 err=2.684403
I 2015-05-27 01:41:33 theanets.trainer:168 RmsProp 614 loss=121.155991 err=2.677329
I 2015-05-27 01:41:43 theanets.trainer:168 RmsProp 615 loss=120.982056 err=2.646382
I 2015-05-27 01:41:53 theanets.trainer:168 RmsProp 616 loss=120.984192 err=2.789537
I 2015-05-27 01:42:02 theanets.trainer:168 RmsProp 617 loss=120.895424 err=2.841606
I 2015-05-27 01:42:12 theanets.trainer:168 RmsProp 618 loss=120.546448 err=2.634785
I 2015-05-27 01:42:21 theanets.trainer:168 RmsProp 619 loss=120.427391 err=2.653877
I 2015-05-27 01:42:31 theanets.trainer:168 RmsProp 620 loss=120.203613 err=2.573267
I 2015-05-27 01:42:31 theanets.trainer:168 validation 62 loss=1154.890015 err=1037.339233
I 2015-05-27 01:42:41 theanets.trainer:168 RmsProp 621 loss=120.109299 err=2.615584
I 2015-05-27 01:42:50 theanets.trainer:168 RmsProp 622 loss=120.016518 err=2.664465
I 2015-05-27 01:42:59 theanets.trainer:168 RmsProp 623 loss=119.784683 err=2.575264
I 2015-05-27 01:43:09 theanets.trainer:168 RmsProp 624 loss=119.759171 err=2.690085
I 2015-05-27 01:43:18 theanets.trainer:168 RmsProp 625 loss=119.474815 err=2.548063
I 2015-05-27 01:43:28 theanets.trainer:168 RmsProp 626 loss=119.417557 err=2.628928
I 2015-05-27 01:43:37 theanets.trainer:168 RmsProp 627 loss=119.280518 err=2.634146
I 2015-05-27 01:43:46 theanets.trainer:168 RmsProp 628 loss=119.263046 err=2.754747
I 2015-05-27 01:43:56 theanets.trainer:168 RmsProp 629 loss=118.880104 err=2.511905
I 2015-05-27 01:44:05 theanets.trainer:168 RmsProp 630 loss=119.017700 err=2.785176
I 2015-05-27 01:44:06 theanets.trainer:168 validation 63 loss=1141.141724 err=1024.976929 *
I 2015-05-27 01:44:15 theanets.trainer:168 RmsProp 631 loss=119.042114 err=2.946915
I 2015-05-27 01:44:24 theanets.trainer:168 RmsProp 632 loss=118.473854 err=2.515002
I 2015-05-27 01:44:34 theanets.trainer:168 RmsProp 633 loss=118.311569 err=2.493430
I 2015-05-27 01:44:44 theanets.trainer:168 RmsProp 634 loss=118.652847 err=2.963941
I 2015-05-27 01:44:53 theanets.trainer:168 RmsProp 635 loss=118.174400 err=2.617303
I 2015-05-27 01:45:03 theanets.trainer:168 RmsProp 636 loss=117.836205 err=2.415964
I 2015-05-27 01:45:12 theanets.trainer:168 RmsProp 637 loss=117.994972 err=2.705263
I 2015-05-27 01:45:22 theanets.trainer:168 RmsProp 638 loss=117.880898 err=2.727906
I 2015-05-27 01:45:31 theanets.trainer:168 RmsProp 639 loss=117.530235 err=2.514510
I 2015-05-27 01:45:41 theanets.trainer:168 RmsProp 640 loss=117.486916 err=2.607292
I 2015-05-27 01:45:42 theanets.trainer:168 validation 64 loss=1137.040649 err=1022.230652 *
I 2015-05-27 01:45:51 theanets.trainer:168 RmsProp 641 loss=117.561478 err=2.811397
I 2015-05-27 01:46:01 theanets.trainer:168 RmsProp 642 loss=117.195328 err=2.577477
I 2015-05-27 01:46:10 theanets.trainer:168 RmsProp 643 loss=116.973289 err=2.490617
I 2015-05-27 01:46:20 theanets.trainer:168 RmsProp 644 loss=116.911377 err=2.559427
I 2015-05-27 01:46:29 theanets.trainer:168 RmsProp 645 loss=116.949562 err=2.734158
I 2015-05-27 01:46:39 theanets.trainer:168 RmsProp 646 loss=116.646011 err=2.561853
I 2015-05-27 01:46:49 theanets.trainer:168 RmsProp 647 loss=116.570045 err=2.619402
I 2015-05-27 01:46:58 theanets.trainer:168 RmsProp 648 loss=116.333603 err=2.518603
I 2015-05-27 01:47:08 theanets.trainer:168 RmsProp 649 loss=116.639359 err=2.950786
I 2015-05-27 01:47:17 theanets.trainer:168 RmsProp 650 loss=116.109985 err=2.554667
I 2015-05-27 01:47:18 theanets.trainer:168 validation 65 loss=1154.789795 err=1041.303101
I 2015-05-27 01:47:27 theanets.trainer:168 RmsProp 651 loss=115.934410 err=2.509115
I 2015-05-27 01:47:37 theanets.trainer:168 RmsProp 652 loss=115.978561 err=2.683726
I 2015-05-27 01:47:46 theanets.trainer:168 RmsProp 653 loss=115.786537 err=2.623926
I 2015-05-27 01:47:56 theanets.trainer:168 RmsProp 654 loss=115.447487 err=2.418461
I 2015-05-27 01:48:05 theanets.trainer:168 RmsProp 655 loss=115.671066 err=2.773117
I 2015-05-27 01:48:15 theanets.trainer:168 RmsProp 656 loss=115.395164 err=2.624909
I 2015-05-27 01:48:24 theanets.trainer:168 RmsProp 657 loss=115.041992 err=2.406642
I 2015-05-27 01:48:34 theanets.trainer:168 RmsProp 658 loss=115.349350 err=2.838979
I 2015-05-27 01:48:43 theanets.trainer:168 RmsProp 659 loss=115.018875 err=2.635360
I 2015-05-27 01:48:53 theanets.trainer:168 RmsProp 660 loss=114.713402 err=2.461471
I 2015-05-27 01:48:53 theanets.trainer:168 validation 66 loss=1133.754150 err=1021.570801 *
I 2015-05-27 01:49:03 theanets.trainer:168 RmsProp 661 loss=114.733093 err=2.606980
I 2015-05-27 01:49:12 theanets.trainer:168 RmsProp 662 loss=114.640549 err=2.641382
I 2015-05-27 01:49:21 theanets.trainer:168 RmsProp 663 loss=114.508301 err=2.634858
I 2015-05-27 01:49:30 theanets.trainer:168 RmsProp 664 loss=114.350647 err=2.607100
I 2015-05-27 01:49:39 theanets.trainer:168 RmsProp 665 loss=114.118164 err=2.506082
I 2015-05-27 01:49:48 theanets.trainer:168 RmsProp 666 loss=114.117554 err=2.629399
I 2015-05-27 01:49:56 theanets.trainer:168 RmsProp 667 loss=113.872849 err=2.511394
I 2015-05-27 01:50:05 theanets.trainer:168 RmsProp 668 loss=113.815689 err=2.578249
I 2015-05-27 01:50:14 theanets.trainer:168 RmsProp 669 loss=113.727554 err=2.617538
I 2015-05-27 01:50:23 theanets.trainer:168 RmsProp 670 loss=113.753334 err=2.765135
I 2015-05-27 01:50:23 theanets.trainer:168 validation 67 loss=1125.185669 err=1014.265259 *
I 2015-05-27 01:50:32 theanets.trainer:168 RmsProp 671 loss=113.175049 err=2.315421
I 2015-05-27 01:50:41 theanets.trainer:168 RmsProp 672 loss=113.460022 err=2.721179
I 2015-05-27 01:50:50 theanets.trainer:168 RmsProp 673 loss=112.994766 err=2.379000
I 2015-05-27 01:50:58 theanets.trainer:168 RmsProp 674 loss=113.258316 err=2.765953
I 2015-05-27 01:51:08 theanets.trainer:168 RmsProp 675 loss=112.835732 err=2.468745
I 2015-05-27 01:51:17 theanets.trainer:168 RmsProp 676 loss=112.939842 err=2.694599
I 2015-05-27 01:51:27 theanets.trainer:168 RmsProp 677 loss=112.966225 err=2.839698
I 2015-05-27 01:51:37 theanets.trainer:168 RmsProp 678 loss=112.457993 err=2.452483
I 2015-05-27 01:51:47 theanets.trainer:168 RmsProp 679 loss=112.543579 err=2.660197
I 2015-05-27 01:51:57 theanets.trainer:168 RmsProp 680 loss=112.314659 err=2.553062
I 2015-05-27 01:51:58 theanets.trainer:168 validation 68 loss=1130.275879 err=1020.586121
I 2015-05-27 01:52:08 theanets.trainer:168 RmsProp 681 loss=112.120300 err=2.478422
I 2015-05-27 01:52:18 theanets.trainer:168 RmsProp 682 loss=112.215187 err=2.694385
I 2015-05-27 01:52:27 theanets.trainer:168 RmsProp 683 loss=111.928818 err=2.527970
I 2015-05-27 01:52:37 theanets.trainer:168 RmsProp 684 loss=111.871506 err=2.587470
I 2015-05-27 01:52:47 theanets.trainer:168 RmsProp 685 loss=111.920654 err=2.755963
I 2015-05-27 01:52:56 theanets.trainer:168 RmsProp 686 loss=111.585060 err=2.539530
I 2015-05-27 01:53:06 theanets.trainer:168 RmsProp 687 loss=111.406212 err=2.481142
I 2015-05-27 01:53:15 theanets.trainer:168 RmsProp 688 loss=111.406021 err=2.597416
I 2015-05-27 01:53:25 theanets.trainer:168 RmsProp 689 loss=111.362473 err=2.670753
I 2015-05-27 01:53:35 theanets.trainer:168 RmsProp 690 loss=111.035561 err=2.465420
I 2015-05-27 01:53:35 theanets.trainer:168 validation 69 loss=1122.458008 err=1013.949219 *
I 2015-05-27 01:53:45 theanets.trainer:168 RmsProp 691 loss=110.946999 err=2.495062
I 2015-05-27 01:53:54 theanets.trainer:168 RmsProp 692 loss=110.977585 err=2.645056
I 2015-05-27 01:54:04 theanets.trainer:168 RmsProp 693 loss=110.637535 err=2.420769
I 2015-05-27 01:54:14 theanets.trainer:168 RmsProp 694 loss=110.670738 err=2.565814
I 2015-05-27 01:54:23 theanets.trainer:168 RmsProp 695 loss=110.579727 err=2.591493
I 2015-05-27 01:54:33 theanets.trainer:168 RmsProp 696 loss=110.309189 err=2.443319
I 2015-05-27 01:54:43 theanets.trainer:168 RmsProp 697 loss=110.423058 err=2.674548
I 2015-05-27 01:54:52 theanets.trainer:168 RmsProp 698 loss=110.312828 err=2.678554
I 2015-05-27 01:55:02 theanets.trainer:168 RmsProp 699 loss=110.188866 err=2.668179
I 2015-05-27 01:55:11 theanets.trainer:168 RmsProp 700 loss=109.788734 err=2.382934
I 2015-05-27 01:55:12 theanets.trainer:168 validation 70 loss=1127.017090 err=1019.681274
I 2015-05-27 01:55:21 theanets.trainer:168 RmsProp 701 loss=109.950363 err=2.659922
I 2015-05-27 01:55:31 theanets.trainer:168 RmsProp 702 loss=109.653458 err=2.475017
I 2015-05-27 01:55:41 theanets.trainer:168 RmsProp 703 loss=109.472534 err=2.408384
I 2015-05-27 01:55:50 theanets.trainer:168 RmsProp 704 loss=109.558739 err=2.611795
I 2015-05-27 01:56:00 theanets.trainer:168 RmsProp 705 loss=109.605614 err=2.771542
I 2015-05-27 01:56:09 theanets.trainer:168 RmsProp 706 loss=109.195755 err=2.475827
I 2015-05-27 01:56:19 theanets.trainer:168 RmsProp 707 loss=109.088234 err=2.482573
I 2015-05-27 01:56:28 theanets.trainer:168 RmsProp 708 loss=109.076576 err=2.582100
I 2015-05-27 01:56:38 theanets.trainer:168 RmsProp 709 loss=108.734970 err=2.353103
I 2015-05-27 01:56:48 theanets.trainer:168 RmsProp 710 loss=108.908936 err=2.639347
I 2015-05-27 01:56:48 theanets.trainer:168 validation 71 loss=1134.492676 err=1028.281738
I 2015-05-27 01:56:58 theanets.trainer:168 RmsProp 711 loss=108.847672 err=2.693102
I 2015-05-27 01:57:07 theanets.trainer:168 RmsProp 712 loss=108.512466 err=2.470859
I 2015-05-27 01:57:17 theanets.trainer:168 RmsProp 713 loss=108.497604 err=2.566004
I 2015-05-27 01:57:27 theanets.trainer:168 RmsProp 714 loss=108.306313 err=2.487896
I 2015-05-27 01:57:37 theanets.trainer:168 RmsProp 715 loss=108.232933 err=2.526537
I 2015-05-27 01:57:46 theanets.trainer:168 RmsProp 716 loss=108.126198 err=2.530704
I 2015-05-27 01:57:56 theanets.trainer:168 RmsProp 717 loss=107.936852 err=2.450100
I 2015-05-27 01:58:05 theanets.trainer:168 RmsProp 718 loss=107.831200 err=2.460695
I 2015-05-27 01:58:15 theanets.trainer:168 RmsProp 719 loss=107.783119 err=2.522949
I 2015-05-27 01:58:25 theanets.trainer:168 RmsProp 720 loss=107.635941 err=2.487341
I 2015-05-27 01:58:25 theanets.trainer:168 validation 72 loss=1108.565918 err=1003.474426 *
I 2015-05-27 01:58:35 theanets.trainer:168 RmsProp 721 loss=107.616348 err=2.574791
I 2015-05-27 01:58:44 theanets.trainer:168 RmsProp 722 loss=107.499268 err=2.566949
I 2015-05-27 01:58:54 theanets.trainer:168 RmsProp 723 loss=107.324524 err=2.500710
I 2015-05-27 01:59:04 theanets.trainer:168 RmsProp 724 loss=107.104324 err=2.390124
I 2015-05-27 01:59:14 theanets.trainer:168 RmsProp 725 loss=106.900841 err=2.296870
I 2015-05-27 01:59:23 theanets.trainer:168 RmsProp 726 loss=107.456200 err=2.954955
I 2015-05-27 01:59:33 theanets.trainer:168 RmsProp 727 loss=106.916794 err=2.524888
I 2015-05-27 01:59:42 theanets.trainer:168 RmsProp 728 loss=106.824120 err=2.537339
I 2015-05-27 01:59:52 theanets.trainer:168 RmsProp 729 loss=106.779259 err=2.597585
I 2015-05-27 02:00:02 theanets.trainer:168 RmsProp 730 loss=106.776649 err=2.698982
I 2015-05-27 02:00:02 theanets.trainer:168 validation 73 loss=1112.801025 err=1008.784668
I 2015-05-27 02:00:12 theanets.trainer:168 RmsProp 731 loss=106.336716 err=2.364793
I 2015-05-27 02:00:22 theanets.trainer:168 RmsProp 732 loss=106.261864 err=2.398461
I 2015-05-27 02:00:32 theanets.trainer:168 RmsProp 733 loss=106.251221 err=2.489887
I 2015-05-27 02:00:41 theanets.trainer:168 RmsProp 734 loss=106.087936 err=2.437632
I 2015-05-27 02:00:51 theanets.trainer:168 RmsProp 735 loss=106.070168 err=2.526374
I 2015-05-27 02:01:01 theanets.trainer:168 RmsProp 736 loss=105.885025 err=2.450257
I 2015-05-27 02:01:11 theanets.trainer:168 RmsProp 737 loss=105.876976 err=2.546542
I 2015-05-27 02:01:21 theanets.trainer:168 RmsProp 738 loss=105.631271 err=2.407053
I 2015-05-27 02:01:30 theanets.trainer:168 RmsProp 739 loss=105.632141 err=2.512416
I 2015-05-27 02:01:40 theanets.trainer:168 RmsProp 740 loss=105.723366 err=2.705497
I 2015-05-27 02:01:41 theanets.trainer:168 validation 74 loss=1101.243530 err=998.277161 *
I 2015-05-27 02:01:50 theanets.trainer:168 RmsProp 741 loss=105.271461 err=2.360188
I 2015-05-27 02:02:00 theanets.trainer:168 RmsProp 742 loss=105.505417 err=2.697344
I 2015-05-27 02:02:09 theanets.trainer:168 RmsProp 743 loss=105.093117 err=2.389858
I 2015-05-27 02:02:19 theanets.trainer:168 RmsProp 744 loss=105.050583 err=2.453379
I 2015-05-27 02:02:29 theanets.trainer:168 RmsProp 745 loss=105.032898 err=2.542584
I 2015-05-27 02:02:38 theanets.trainer:168 RmsProp 746 loss=104.786255 err=2.402893
I 2015-05-27 02:02:49 theanets.trainer:168 RmsProp 747 loss=104.775314 err=2.492161
I 2015-05-27 02:02:58 theanets.trainer:168 RmsProp 748 loss=104.695847 err=2.514128
I 2015-05-27 02:03:08 theanets.trainer:168 RmsProp 749 loss=104.496178 err=2.417621
I 2015-05-27 02:03:18 theanets.trainer:168 RmsProp 750 loss=104.478249 err=2.502641
I 2015-05-27 02:03:18 theanets.trainer:168 validation 75 loss=1111.283081 err=1009.367493
I 2015-05-27 02:03:28 theanets.trainer:168 RmsProp 751 loss=104.228394 err=2.356316
I 2015-05-27 02:03:38 theanets.trainer:168 RmsProp 752 loss=104.296814 err=2.526509
I 2015-05-27 02:03:47 theanets.trainer:168 RmsProp 753 loss=104.456589 err=2.783225
I 2015-05-27 02:03:57 theanets.trainer:168 RmsProp 754 loss=103.940468 err=2.369018
I 2015-05-27 02:04:07 theanets.trainer:168 RmsProp 755 loss=104.048195 err=2.580316
I 2015-05-27 02:04:17 theanets.trainer:168 RmsProp 756 loss=103.848473 err=2.477238
I 2015-05-27 02:04:27 theanets.trainer:168 RmsProp 757 loss=103.737587 err=2.469442
I 2015-05-27 02:04:36 theanets.trainer:168 RmsProp 758 loss=103.548378 err=2.382599
I 2015-05-27 02:04:47 theanets.trainer:168 RmsProp 759 loss=103.510780 err=2.444706
I 2015-05-27 02:04:57 theanets.trainer:168 RmsProp 760 loss=103.499924 err=2.532716
I 2015-05-27 02:04:57 theanets.trainer:168 validation 76 loss=1094.409180 err=993.489685 *
I 2015-05-27 02:05:07 theanets.trainer:168 RmsProp 761 loss=103.607262 err=2.734059
I 2015-05-27 02:05:17 theanets.trainer:168 RmsProp 762 loss=103.174255 err=2.400727
I 2015-05-27 02:05:27 theanets.trainer:168 RmsProp 763 loss=103.147964 err=2.474200
I 2015-05-27 02:05:37 theanets.trainer:168 RmsProp 764 loss=103.228470 err=2.649550
I 2015-05-27 02:05:46 theanets.trainer:168 RmsProp 765 loss=102.718002 err=2.239871
I 2015-05-27 02:05:56 theanets.trainer:168 RmsProp 766 loss=102.903946 err=2.521732
I 2015-05-27 02:06:06 theanets.trainer:168 RmsProp 767 loss=102.719215 err=2.434220
I 2015-05-27 02:06:16 theanets.trainer:168 RmsProp 768 loss=102.632118 err=2.446619
I 2015-05-27 02:06:25 theanets.trainer:168 RmsProp 769 loss=102.461708 err=2.375864
I 2015-05-27 02:06:35 theanets.trainer:168 RmsProp 770 loss=102.404068 err=2.415705
I 2015-05-27 02:06:35 theanets.trainer:168 validation 77 loss=1090.651855 err=990.713074 *
I 2015-05-27 02:06:45 theanets.trainer:168 RmsProp 771 loss=102.079636 err=2.196946
I 2015-05-27 02:06:55 theanets.trainer:168 RmsProp 772 loss=102.296242 err=2.512402
I 2015-05-27 02:07:05 theanets.trainer:168 RmsProp 773 loss=102.182625 err=2.499481
I 2015-05-27 02:07:15 theanets.trainer:168 RmsProp 774 loss=102.019737 err=2.434947
I 2015-05-27 02:07:25 theanets.trainer:168 RmsProp 775 loss=101.864456 err=2.371321
I 2015-05-27 02:07:35 theanets.trainer:168 RmsProp 776 loss=101.791794 err=2.395281
I 2015-05-27 02:07:44 theanets.trainer:168 RmsProp 777 loss=101.839371 err=2.538348
I 2015-05-27 02:07:54 theanets.trainer:168 RmsProp 778 loss=101.638687 err=2.436812
I 2015-05-27 02:08:04 theanets.trainer:168 RmsProp 779 loss=101.775047 err=2.666821
I 2015-05-27 02:08:13 theanets.trainer:168 RmsProp 780 loss=101.124245 err=2.116518
I 2015-05-27 02:08:14 theanets.trainer:168 validation 78 loss=1084.869263 err=985.902161 *
I 2015-05-27 02:08:24 theanets.trainer:168 RmsProp 781 loss=101.559898 err=2.643019
I 2015-05-27 02:08:33 theanets.trainer:168 RmsProp 782 loss=101.219559 err=2.397152
I 2015-05-27 02:08:43 theanets.trainer:168 RmsProp 783 loss=101.226234 err=2.498161
I 2015-05-27 02:08:53 theanets.trainer:168 RmsProp 784 loss=101.106857 err=2.474292
I 2015-05-27 02:09:03 theanets.trainer:168 RmsProp 785 loss=100.910210 err=2.375008
I 2015-05-27 02:09:13 theanets.trainer:168 RmsProp 786 loss=100.672897 err=2.236079
I 2015-05-27 02:09:22 theanets.trainer:168 RmsProp 787 loss=101.139702 err=2.792113
I 2015-05-27 02:09:32 theanets.trainer:168 RmsProp 788 loss=100.600777 err=2.347964
I 2015-05-27 02:09:42 theanets.trainer:168 RmsProp 789 loss=100.519394 err=2.359218
I 2015-05-27 02:09:52 theanets.trainer:168 RmsProp 790 loss=100.582359 err=2.518198
I 2015-05-27 02:09:52 theanets.trainer:168 validation 79 loss=1088.279663 err=990.264282
I 2015-05-27 02:10:02 theanets.trainer:168 RmsProp 791 loss=100.369431 err=2.395464
I 2015-05-27 02:10:11 theanets.trainer:168 RmsProp 792 loss=100.336380 err=2.458497
I 2015-05-27 02:10:21 theanets.trainer:168 RmsProp 793 loss=100.132225 err=2.346509
I 2015-05-27 02:10:31 theanets.trainer:168 RmsProp 794 loss=100.132751 err=2.439117
I 2015-05-27 02:10:41 theanets.trainer:168 RmsProp 795 loss=99.974876 err=2.374502
I 2015-05-27 02:10:50 theanets.trainer:168 RmsProp 796 loss=99.859695 err=2.350207
I 2015-05-27 02:11:00 theanets.trainer:168 RmsProp 797 loss=99.893311 err=2.474822
I 2015-05-27 02:11:09 theanets.trainer:168 RmsProp 798 loss=100.077278 err=2.744544
I 2015-05-27 02:11:19 theanets.trainer:168 RmsProp 799 loss=99.523102 err=2.280920
I 2015-05-27 02:11:29 theanets.trainer:168 RmsProp 800 loss=99.510902 err=2.359502
I 2015-05-27 02:11:29 theanets.trainer:168 validation 80 loss=1097.534180 err=1000.433594
I 2015-05-27 02:11:39 theanets.trainer:168 RmsProp 801 loss=99.620239 err=2.560866
I 2015-05-27 02:11:49 theanets.trainer:168 RmsProp 802 loss=99.282974 err=2.314633
I 2015-05-27 02:11:58 theanets.trainer:168 RmsProp 803 loss=99.202721 err=2.322024
I 2015-05-27 02:12:08 theanets.trainer:168 RmsProp 804 loss=99.304611 err=2.516664
I 2015-05-27 02:12:17 theanets.trainer:168 RmsProp 805 loss=99.118050 err=2.420745
I 2015-05-27 02:12:27 theanets.trainer:168 RmsProp 806 loss=98.910133 err=2.304721
I 2015-05-27 02:12:37 theanets.trainer:168 RmsProp 807 loss=98.963577 err=2.448962
I 2015-05-27 02:12:47 theanets.trainer:168 RmsProp 808 loss=98.834610 err=2.407934
I 2015-05-27 02:12:57 theanets.trainer:168 RmsProp 809 loss=98.666000 err=2.329916
I 2015-05-27 02:13:07 theanets.trainer:168 RmsProp 810 loss=98.524094 err=2.279939
I 2015-05-27 02:13:07 theanets.trainer:168 validation 81 loss=1088.677246 err=992.484192
I 2015-05-27 02:13:17 theanets.trainer:168 RmsProp 811 loss=98.765022 err=2.606792
I 2015-05-27 02:13:27 theanets.trainer:168 RmsProp 812 loss=98.330894 err=2.260093
I 2015-05-27 02:13:36 theanets.trainer:168 RmsProp 813 loss=98.395500 err=2.411979
I 2015-05-27 02:13:46 theanets.trainer:168 RmsProp 814 loss=98.237320 err=2.343303
I 2015-05-27 02:13:56 theanets.trainer:168 RmsProp 815 loss=98.152504 err=2.347708
I 2015-05-27 02:14:05 theanets.trainer:168 RmsProp 816 loss=98.224037 err=2.503505
I 2015-05-27 02:14:15 theanets.trainer:168 RmsProp 817 loss=98.176460 err=2.543191
I 2015-05-27 02:14:24 theanets.trainer:168 RmsProp 818 loss=98.014297 err=2.471313
I 2015-05-27 02:14:34 theanets.trainer:168 RmsProp 819 loss=97.832016 err=2.377403
I 2015-05-27 02:14:43 theanets.trainer:168 RmsProp 820 loss=97.649193 err=2.282430
I 2015-05-27 02:14:44 theanets.trainer:168 validation 82 loss=1087.091187 err=991.781555
I 2015-05-27 02:14:53 theanets.trainer:168 RmsProp 821 loss=97.572029 err=2.295117
I 2015-05-27 02:15:02 theanets.trainer:168 RmsProp 822 loss=97.469635 err=2.276882
I 2015-05-27 02:15:12 theanets.trainer:168 RmsProp 823 loss=97.501221 err=2.394804
I 2015-05-27 02:15:21 theanets.trainer:168 RmsProp 824 loss=97.513046 err=2.492158
I 2015-05-27 02:15:31 theanets.trainer:168 RmsProp 825 loss=97.397430 err=2.469146
I 2015-05-27 02:15:40 theanets.trainer:168 RmsProp 826 loss=97.127640 err=2.283577
I 2015-05-27 02:15:50 theanets.trainer:168 RmsProp 827 loss=97.196732 err=2.438356
I 2015-05-27 02:15:58 theanets.trainer:168 RmsProp 828 loss=97.032784 err=2.363247
I 2015-05-27 02:16:07 theanets.trainer:168 RmsProp 829 loss=96.864098 err=2.277661
I 2015-05-27 02:16:16 theanets.trainer:168 RmsProp 830 loss=96.878067 err=2.373960
I 2015-05-27 02:16:17 theanets.trainer:168 validation 83 loss=1097.165771 err=1002.705994
I 2015-05-27 02:16:17 theanets.trainer:252 patience elapsed!
I 2015-05-27 02:16:17 theanets.main:237 models_deep_post_code_sep/95116-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 02:16:17 theanets.graph:477 models_deep_post_code_sep/95116-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
