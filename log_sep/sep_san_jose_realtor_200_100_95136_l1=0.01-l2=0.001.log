I 2015-05-26 22:05:12 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:12 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95136-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:12 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:12 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:12 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:12 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:12 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:12 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:12 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:12 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:12 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:12 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:12 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:30 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:14 theanets.trainer:168 validation 0 loss=14411.770508 err=14169.151367 *
I 2015-05-26 22:08:46 theanets.trainer:168 RmsProp 1 loss=13291.921875 err=13198.567383
I 2015-05-26 22:09:22 theanets.trainer:168 RmsProp 2 loss=13195.852539 err=13172.913086
I 2015-05-26 22:09:59 theanets.trainer:168 RmsProp 3 loss=12681.988281 err=12637.866211
I 2015-05-26 22:10:35 theanets.trainer:168 RmsProp 4 loss=11449.837891 err=11364.812500
I 2015-05-26 22:11:12 theanets.trainer:168 RmsProp 5 loss=10679.717773 err=10568.081055
I 2015-05-26 22:11:50 theanets.trainer:168 RmsProp 6 loss=10179.958008 err=10054.283203
I 2015-05-26 22:12:26 theanets.trainer:168 RmsProp 7 loss=9647.708984 err=9505.027344
I 2015-05-26 22:13:02 theanets.trainer:168 RmsProp 8 loss=9036.263672 err=8875.279297
I 2015-05-26 22:13:40 theanets.trainer:168 RmsProp 9 loss=8549.199219 err=8363.748047
I 2015-05-26 22:14:18 theanets.trainer:168 RmsProp 10 loss=8161.020508 err=7952.409668
I 2015-05-26 22:14:18 theanets.trainer:168 validation 1 loss=7005.839844 err=6786.183105 *
I 2015-05-26 22:14:55 theanets.trainer:168 RmsProp 11 loss=7833.649414 err=7602.943359
I 2015-05-26 22:15:33 theanets.trainer:168 RmsProp 12 loss=7576.770996 err=7327.968750
I 2015-05-26 22:16:11 theanets.trainer:168 RmsProp 13 loss=7153.062988 err=6883.193359
I 2015-05-26 22:16:49 theanets.trainer:168 RmsProp 14 loss=6749.645508 err=6455.257812
I 2015-05-26 22:17:26 theanets.trainer:168 RmsProp 15 loss=6431.844727 err=6116.625000
I 2015-05-26 22:18:03 theanets.trainer:168 RmsProp 16 loss=6247.270508 err=5911.274414
I 2015-05-26 22:18:40 theanets.trainer:168 RmsProp 17 loss=6123.921875 err=5762.460938
I 2015-05-26 22:19:16 theanets.trainer:168 RmsProp 18 loss=5890.896484 err=5509.438477
I 2015-05-26 22:19:53 theanets.trainer:168 RmsProp 19 loss=5620.698242 err=5225.255371
I 2015-05-26 22:20:31 theanets.trainer:168 RmsProp 20 loss=5472.410645 err=5064.164551
I 2015-05-26 22:20:31 theanets.trainer:168 validation 2 loss=5041.208496 err=4625.125000 *
I 2015-05-26 22:21:09 theanets.trainer:168 RmsProp 21 loss=5502.889160 err=5079.284180
I 2015-05-26 22:21:45 theanets.trainer:168 RmsProp 22 loss=5393.189941 err=4954.269043
I 2015-05-26 22:22:22 theanets.trainer:168 RmsProp 23 loss=4820.394043 err=4371.429199
I 2015-05-26 22:22:59 theanets.trainer:168 RmsProp 24 loss=4704.302246 err=4243.222168
I 2015-05-26 22:23:36 theanets.trainer:168 RmsProp 25 loss=4280.083008 err=3806.849121
I 2015-05-26 22:24:12 theanets.trainer:168 RmsProp 26 loss=3981.655029 err=3507.343018
I 2015-05-26 22:24:49 theanets.trainer:168 RmsProp 27 loss=3816.506836 err=3343.439941
I 2015-05-26 22:25:26 theanets.trainer:168 RmsProp 28 loss=3613.864014 err=3137.383057
I 2015-05-26 22:26:03 theanets.trainer:168 RmsProp 29 loss=3550.789551 err=3067.995605
I 2015-05-26 22:26:41 theanets.trainer:168 RmsProp 30 loss=3501.107178 err=3010.063965
I 2015-05-26 22:26:41 theanets.trainer:168 validation 3 loss=3440.896729 err=2944.348877 *
I 2015-05-26 22:27:18 theanets.trainer:168 RmsProp 31 loss=3538.466553 err=3035.620850
I 2015-05-26 22:27:55 theanets.trainer:168 RmsProp 32 loss=3421.343994 err=2912.147705
I 2015-05-26 22:28:33 theanets.trainer:168 RmsProp 33 loss=3393.159668 err=2879.347656
I 2015-05-26 22:29:11 theanets.trainer:168 RmsProp 34 loss=3324.336182 err=2800.580322
I 2015-05-26 22:29:49 theanets.trainer:168 RmsProp 35 loss=3258.606201 err=2727.152588
I 2015-05-26 22:30:27 theanets.trainer:168 RmsProp 36 loss=3147.159180 err=2613.534668
I 2015-05-26 22:31:05 theanets.trainer:168 RmsProp 37 loss=3074.666260 err=2538.058350
I 2015-05-26 22:31:42 theanets.trainer:168 RmsProp 38 loss=3009.648193 err=2467.014648
I 2015-05-26 22:32:20 theanets.trainer:168 RmsProp 39 loss=3116.358154 err=2564.139893
I 2015-05-26 22:32:57 theanets.trainer:168 RmsProp 40 loss=3135.296387 err=2570.614746
I 2015-05-26 22:32:58 theanets.trainer:168 validation 4 loss=3102.322510 err=2533.660400 *
I 2015-05-26 22:33:35 theanets.trainer:168 RmsProp 41 loss=3104.936523 err=2532.793213
I 2015-05-26 22:34:11 theanets.trainer:168 RmsProp 42 loss=3106.790039 err=2526.800537
I 2015-05-26 22:34:48 theanets.trainer:168 RmsProp 43 loss=3054.449951 err=2463.469238
I 2015-05-26 22:35:25 theanets.trainer:168 RmsProp 44 loss=2829.085693 err=2236.605469
I 2015-05-26 22:36:02 theanets.trainer:168 RmsProp 45 loss=2757.329590 err=2165.744629
I 2015-05-26 22:36:38 theanets.trainer:168 RmsProp 46 loss=2724.507324 err=2130.115967
I 2015-05-26 22:37:15 theanets.trainer:168 RmsProp 47 loss=2666.125732 err=2068.560303
I 2015-05-26 22:37:51 theanets.trainer:168 RmsProp 48 loss=2686.595459 err=2084.562988
I 2015-05-26 22:38:28 theanets.trainer:168 RmsProp 49 loss=2759.628662 err=2149.589355
I 2015-05-26 22:39:05 theanets.trainer:168 RmsProp 50 loss=2694.922852 err=2076.324219
I 2015-05-26 22:39:05 theanets.trainer:168 validation 5 loss=3012.295654 err=2391.419922 *
I 2015-05-26 22:39:42 theanets.trainer:168 RmsProp 51 loss=2599.222900 err=1978.726440
I 2015-05-26 22:40:18 theanets.trainer:168 RmsProp 52 loss=2561.055420 err=1937.948120
I 2015-05-26 22:40:54 theanets.trainer:168 RmsProp 53 loss=2596.686035 err=1968.432861
I 2015-05-26 22:41:31 theanets.trainer:168 RmsProp 54 loss=2578.018311 err=1945.446777
I 2015-05-26 22:42:07 theanets.trainer:168 RmsProp 55 loss=2540.614990 err=1903.074951
I 2015-05-26 22:42:44 theanets.trainer:168 RmsProp 56 loss=2647.371338 err=2001.617065
I 2015-05-26 22:43:21 theanets.trainer:168 RmsProp 57 loss=3127.822021 err=2467.550293
I 2015-05-26 22:43:57 theanets.trainer:168 RmsProp 58 loss=4332.228516 err=3637.513916
I 2015-05-26 22:44:35 theanets.trainer:168 RmsProp 59 loss=3957.982178 err=3222.983643
I 2015-05-26 22:45:13 theanets.trainer:168 RmsProp 60 loss=3215.071777 err=2479.427002
I 2015-05-26 22:45:14 theanets.trainer:168 validation 6 loss=3463.217529 err=2736.734131
I 2015-05-26 22:45:51 theanets.trainer:168 RmsProp 61 loss=2878.900635 err=2159.260010
I 2015-05-26 22:46:27 theanets.trainer:168 RmsProp 62 loss=2602.681152 err=1894.330933
I 2015-05-26 22:47:03 theanets.trainer:168 RmsProp 63 loss=2471.598389 err=1778.559204
I 2015-05-26 22:47:40 theanets.trainer:168 RmsProp 64 loss=2397.205322 err=1712.460083
I 2015-05-26 22:48:16 theanets.trainer:168 RmsProp 65 loss=2358.781006 err=1677.643921
I 2015-05-26 22:48:52 theanets.trainer:168 RmsProp 66 loss=2314.528320 err=1635.565918
I 2015-05-26 22:49:28 theanets.trainer:168 RmsProp 67 loss=2354.136475 err=1673.492065
I 2015-05-26 22:50:05 theanets.trainer:168 RmsProp 68 loss=2438.087402 err=1750.441162
I 2015-05-26 22:50:42 theanets.trainer:168 RmsProp 69 loss=2458.561523 err=1765.217529
I 2015-05-26 22:51:20 theanets.trainer:168 RmsProp 70 loss=2308.957520 err=1617.230347
I 2015-05-26 22:51:20 theanets.trainer:168 validation 7 loss=3022.885498 err=2331.707764
I 2015-05-26 22:51:57 theanets.trainer:168 RmsProp 71 loss=2273.336670 err=1582.879761
I 2015-05-26 22:52:34 theanets.trainer:168 RmsProp 72 loss=2220.630371 err=1531.469604
I 2015-05-26 22:53:10 theanets.trainer:168 RmsProp 73 loss=2192.370361 err=1504.072388
I 2015-05-26 22:53:49 theanets.trainer:168 RmsProp 74 loss=2352.732178 err=1655.521362
I 2015-05-26 22:54:28 theanets.trainer:168 RmsProp 75 loss=2360.763184 err=1656.910767
I 2015-05-26 22:55:05 theanets.trainer:168 RmsProp 76 loss=2196.273193 err=1494.944458
I 2015-05-26 22:55:42 theanets.trainer:168 RmsProp 77 loss=2135.692871 err=1436.705566
I 2015-05-26 22:56:19 theanets.trainer:168 RmsProp 78 loss=2095.094727 err=1396.569092
I 2015-05-26 22:56:56 theanets.trainer:168 RmsProp 79 loss=2086.815674 err=1386.585815
I 2015-05-26 22:57:34 theanets.trainer:168 RmsProp 80 loss=2250.102539 err=1544.136719
I 2015-05-26 22:57:35 theanets.trainer:168 validation 8 loss=3257.201172 err=2543.134766
I 2015-05-26 22:58:13 theanets.trainer:168 RmsProp 81 loss=2410.441895 err=1690.272705
I 2015-05-26 22:58:50 theanets.trainer:168 RmsProp 82 loss=2354.553223 err=1624.597534
I 2015-05-26 22:59:27 theanets.trainer:168 RmsProp 83 loss=2257.032227 err=1530.878906
I 2015-05-26 23:00:03 theanets.trainer:168 RmsProp 84 loss=2349.916992 err=1621.635132
I 2015-05-26 23:00:39 theanets.trainer:168 RmsProp 85 loss=2222.841309 err=1493.247681
I 2015-05-26 23:01:16 theanets.trainer:168 RmsProp 86 loss=2099.789551 err=1375.236328
I 2015-05-26 23:01:54 theanets.trainer:168 RmsProp 87 loss=2041.523071 err=1319.648926
I 2015-05-26 23:02:31 theanets.trainer:168 RmsProp 88 loss=2093.492920 err=1371.390503
I 2015-05-26 23:03:08 theanets.trainer:168 RmsProp 89 loss=2135.187012 err=1408.711792
I 2015-05-26 23:03:46 theanets.trainer:168 RmsProp 90 loss=2072.610840 err=1345.043213
I 2015-05-26 23:03:47 theanets.trainer:168 validation 9 loss=2781.789307 err=2054.709717 *
I 2015-05-26 23:04:24 theanets.trainer:168 RmsProp 91 loss=2773.402344 err=2040.899170
I 2015-05-26 23:05:01 theanets.trainer:168 RmsProp 92 loss=3035.344238 err=2272.656250
I 2015-05-26 23:05:37 theanets.trainer:168 RmsProp 93 loss=2621.228027 err=1854.521606
I 2015-05-26 23:06:13 theanets.trainer:168 RmsProp 94 loss=2501.910645 err=1733.185669
I 2015-05-26 23:06:50 theanets.trainer:168 RmsProp 95 loss=2360.397705 err=1589.419922
I 2015-05-26 23:07:27 theanets.trainer:168 RmsProp 96 loss=2245.156494 err=1478.728516
I 2015-05-26 23:08:04 theanets.trainer:168 RmsProp 97 loss=2170.062744 err=1406.114502
I 2015-05-26 23:08:42 theanets.trainer:168 RmsProp 98 loss=2144.694092 err=1380.168213
I 2015-05-26 23:09:20 theanets.trainer:168 RmsProp 99 loss=2034.810669 err=1272.344116
I 2015-05-26 23:09:57 theanets.trainer:168 RmsProp 100 loss=1937.041138 err=1180.107666
I 2015-05-26 23:09:58 theanets.trainer:168 validation 10 loss=3114.457275 err=2360.888184
I 2015-05-26 23:10:34 theanets.trainer:168 RmsProp 101 loss=2004.084106 err=1250.182861
I 2015-05-26 23:11:10 theanets.trainer:168 RmsProp 102 loss=2200.152344 err=1438.404175
I 2015-05-26 23:11:46 theanets.trainer:168 RmsProp 103 loss=2127.953369 err=1360.790161
I 2015-05-26 23:12:22 theanets.trainer:168 RmsProp 104 loss=2014.106934 err=1247.170044
I 2015-05-26 23:12:58 theanets.trainer:168 RmsProp 105 loss=1974.235107 err=1206.286621
I 2015-05-26 23:13:35 theanets.trainer:168 RmsProp 106 loss=1976.630981 err=1208.628906
I 2015-05-26 23:14:12 theanets.trainer:168 RmsProp 107 loss=2025.394409 err=1252.574463
I 2015-05-26 23:14:50 theanets.trainer:168 RmsProp 108 loss=1934.739136 err=1161.985596
I 2015-05-26 23:15:27 theanets.trainer:168 RmsProp 109 loss=1876.718018 err=1106.617798
I 2015-05-26 23:16:04 theanets.trainer:168 RmsProp 110 loss=1941.644531 err=1172.479614
I 2015-05-26 23:16:05 theanets.trainer:168 validation 11 loss=2710.740723 err=1935.649780 *
I 2015-05-26 23:16:42 theanets.trainer:168 RmsProp 111 loss=1961.061279 err=1184.634277
I 2015-05-26 23:17:19 theanets.trainer:168 RmsProp 112 loss=2673.127930 err=1872.561646
I 2015-05-26 23:17:55 theanets.trainer:168 RmsProp 113 loss=2155.223877 err=1349.547607
I 2015-05-26 23:18:30 theanets.trainer:168 RmsProp 114 loss=1929.064209 err=1136.826050
I 2015-05-26 23:19:06 theanets.trainer:168 RmsProp 115 loss=1855.537354 err=1074.412598
I 2015-05-26 23:19:41 theanets.trainer:168 RmsProp 116 loss=1879.515503 err=1102.665161
I 2015-05-26 23:20:17 theanets.trainer:168 RmsProp 117 loss=1890.914795 err=1112.043335
I 2015-05-26 23:20:52 theanets.trainer:168 RmsProp 118 loss=1880.446167 err=1099.331177
I 2015-05-26 23:21:28 theanets.trainer:168 RmsProp 119 loss=1849.472900 err=1070.021973
I 2015-05-26 23:22:04 theanets.trainer:168 RmsProp 120 loss=1929.622192 err=1145.259155
I 2015-05-26 23:22:05 theanets.trainer:168 validation 12 loss=2618.610107 err=1830.463745 *
I 2015-05-26 23:22:41 theanets.trainer:168 RmsProp 121 loss=1979.147827 err=1188.911865
I 2015-05-26 23:23:18 theanets.trainer:168 RmsProp 122 loss=1871.569092 err=1083.456177
I 2015-05-26 23:23:55 theanets.trainer:168 RmsProp 123 loss=1862.856689 err=1074.506836
I 2015-05-26 23:24:33 theanets.trainer:168 RmsProp 124 loss=1824.344238 err=1034.449463
I 2015-05-26 23:25:09 theanets.trainer:168 RmsProp 125 loss=1761.847534 err=973.716187
I 2015-05-26 23:25:45 theanets.trainer:168 RmsProp 126 loss=1746.895630 err=963.378967
I 2015-05-26 23:26:22 theanets.trainer:168 RmsProp 127 loss=1754.303223 err=970.759766
I 2015-05-26 23:26:59 theanets.trainer:168 RmsProp 128 loss=1769.958984 err=986.696533
I 2015-05-26 23:27:35 theanets.trainer:168 RmsProp 129 loss=1750.270142 err=966.246826
I 2015-05-26 23:28:12 theanets.trainer:168 RmsProp 130 loss=1724.339111 err=944.223572
I 2015-05-26 23:28:13 theanets.trainer:168 validation 13 loss=3145.422852 err=2366.026123
I 2015-05-26 23:28:49 theanets.trainer:168 RmsProp 131 loss=1728.975464 err=949.631592
I 2015-05-26 23:29:26 theanets.trainer:168 RmsProp 132 loss=1671.161621 err=893.840637
I 2015-05-26 23:30:03 theanets.trainer:168 RmsProp 133 loss=1651.469604 err=877.770691
I 2015-05-26 23:30:40 theanets.trainer:168 RmsProp 134 loss=1650.208740 err=878.342957
I 2015-05-26 23:31:17 theanets.trainer:168 RmsProp 135 loss=1666.666016 err=893.724731
I 2015-05-26 23:31:53 theanets.trainer:168 RmsProp 136 loss=1632.146606 err=860.644409
I 2015-05-26 23:32:30 theanets.trainer:168 RmsProp 137 loss=1632.927124 err=864.223389
I 2015-05-26 23:33:06 theanets.trainer:168 RmsProp 138 loss=1624.076660 err=854.735779
I 2015-05-26 23:33:43 theanets.trainer:168 RmsProp 139 loss=1602.230469 err=834.224976
I 2015-05-26 23:34:19 theanets.trainer:168 RmsProp 140 loss=1603.909912 err=835.906433
I 2015-05-26 23:34:20 theanets.trainer:168 validation 14 loss=2602.689209 err=1834.862915 *
I 2015-05-26 23:34:57 theanets.trainer:168 RmsProp 141 loss=1578.534058 err=812.530212
I 2015-05-26 23:35:33 theanets.trainer:168 RmsProp 142 loss=1567.863647 err=804.174927
I 2015-05-26 23:36:08 theanets.trainer:168 RmsProp 143 loss=1598.466553 err=835.293518
I 2015-05-26 23:36:45 theanets.trainer:168 RmsProp 144 loss=1609.986206 err=845.616211
I 2015-05-26 23:37:21 theanets.trainer:168 RmsProp 145 loss=1611.140137 err=846.343506
I 2015-05-26 23:37:58 theanets.trainer:168 RmsProp 146 loss=1578.149902 err=814.747131
I 2015-05-26 23:38:36 theanets.trainer:168 RmsProp 147 loss=1571.061646 err=808.467651
I 2015-05-26 23:39:13 theanets.trainer:168 RmsProp 148 loss=1613.728638 err=850.855530
I 2015-05-26 23:39:49 theanets.trainer:168 RmsProp 149 loss=1613.726685 err=848.094116
I 2015-05-26 23:40:25 theanets.trainer:168 RmsProp 150 loss=1643.188843 err=876.546997
I 2015-05-26 23:40:26 theanets.trainer:168 validation 15 loss=3020.541748 err=2252.718018
I 2015-05-26 23:41:03 theanets.trainer:168 RmsProp 151 loss=1694.771606 err=922.860779
I 2015-05-26 23:41:40 theanets.trainer:168 RmsProp 152 loss=1632.617188 err=859.010742
I 2015-05-26 23:42:17 theanets.trainer:168 RmsProp 153 loss=1574.801514 err=806.155701
I 2015-05-26 23:42:54 theanets.trainer:168 RmsProp 154 loss=1567.356812 err=801.164185
I 2015-05-26 23:43:31 theanets.trainer:168 RmsProp 155 loss=1566.739380 err=800.487915
I 2015-05-26 23:44:08 theanets.trainer:168 RmsProp 156 loss=1552.656006 err=787.223816
I 2015-05-26 23:44:44 theanets.trainer:168 RmsProp 157 loss=1534.525879 err=771.236145
I 2015-05-26 23:45:21 theanets.trainer:168 RmsProp 158 loss=1581.345947 err=817.097351
I 2015-05-26 23:45:58 theanets.trainer:168 RmsProp 159 loss=1693.403442 err=924.090576
I 2015-05-26 23:46:34 theanets.trainer:168 RmsProp 160 loss=1740.108643 err=962.559937
I 2015-05-26 23:46:34 theanets.trainer:168 validation 16 loss=2782.425049 err=2001.350952
I 2015-05-26 23:47:09 theanets.trainer:168 RmsProp 161 loss=1727.666382 err=943.739868
I 2015-05-26 23:47:44 theanets.trainer:168 RmsProp 162 loss=1700.532104 err=916.727661
I 2015-05-26 23:48:17 theanets.trainer:168 RmsProp 163 loss=1715.964966 err=930.591492
I 2015-05-26 23:48:52 theanets.trainer:168 RmsProp 164 loss=1678.650146 err=890.124573
I 2015-05-26 23:49:28 theanets.trainer:168 RmsProp 165 loss=1640.478027 err=854.438416
I 2015-05-26 23:50:04 theanets.trainer:168 RmsProp 166 loss=1746.724854 err=955.818237
I 2015-05-26 23:50:40 theanets.trainer:168 RmsProp 167 loss=2131.088135 err=1325.034058
I 2015-05-26 23:51:15 theanets.trainer:168 RmsProp 168 loss=2024.683594 err=1202.961182
I 2015-05-26 23:51:50 theanets.trainer:168 RmsProp 169 loss=1837.405640 err=1019.787659
I 2015-05-26 23:52:25 theanets.trainer:168 RmsProp 170 loss=1712.250244 err=899.349487
I 2015-05-26 23:52:25 theanets.trainer:168 validation 17 loss=2695.292480 err=1886.144531
I 2015-05-26 23:53:01 theanets.trainer:168 RmsProp 171 loss=1655.751709 err=849.764099
I 2015-05-26 23:53:36 theanets.trainer:168 RmsProp 172 loss=1683.005493 err=879.706604
I 2015-05-26 23:54:11 theanets.trainer:168 RmsProp 173 loss=1818.515259 err=1006.951172
I 2015-05-26 23:54:47 theanets.trainer:168 RmsProp 174 loss=1832.750000 err=1012.450134
I 2015-05-26 23:55:23 theanets.trainer:168 RmsProp 175 loss=1707.674072 err=889.398682
I 2015-05-26 23:55:59 theanets.trainer:168 RmsProp 176 loss=1727.804810 err=913.234009
I 2015-05-26 23:56:34 theanets.trainer:168 RmsProp 177 loss=1692.056152 err=877.174683
I 2015-05-26 23:57:09 theanets.trainer:168 RmsProp 178 loss=1624.305420 err=812.296509
I 2015-05-26 23:57:45 theanets.trainer:168 RmsProp 179 loss=1603.054810 err=795.831116
I 2015-05-26 23:58:20 theanets.trainer:168 RmsProp 180 loss=1586.930298 err=781.944641
I 2015-05-26 23:58:21 theanets.trainer:168 validation 18 loss=2590.284424 err=1785.384155 *
I 2015-05-26 23:58:56 theanets.trainer:168 RmsProp 181 loss=1602.353882 err=796.509155
I 2015-05-26 23:59:32 theanets.trainer:168 RmsProp 182 loss=1580.941406 err=777.364258
I 2015-05-27 00:00:08 theanets.trainer:168 RmsProp 183 loss=1655.872192 err=851.128052
I 2015-05-27 00:00:45 theanets.trainer:168 RmsProp 184 loss=1720.023682 err=905.395569
I 2015-05-27 00:01:21 theanets.trainer:168 RmsProp 185 loss=1650.248047 err=834.059753
I 2015-05-27 00:01:56 theanets.trainer:168 RmsProp 186 loss=1629.944580 err=816.304993
I 2015-05-27 00:02:32 theanets.trainer:168 RmsProp 187 loss=1637.581543 err=823.234009
I 2015-05-27 00:03:07 theanets.trainer:168 RmsProp 188 loss=1602.276978 err=788.946533
I 2015-05-27 00:03:43 theanets.trainer:168 RmsProp 189 loss=1574.299683 err=762.813782
I 2015-05-27 00:04:19 theanets.trainer:168 RmsProp 190 loss=1560.146606 err=750.627197
I 2015-05-27 00:04:19 theanets.trainer:168 validation 19 loss=2735.344482 err=1926.780151
I 2015-05-27 00:04:54 theanets.trainer:168 RmsProp 191 loss=1535.408203 err=728.267273
I 2015-05-27 00:05:28 theanets.trainer:168 RmsProp 192 loss=1544.762817 err=739.947571
I 2015-05-27 00:06:03 theanets.trainer:168 RmsProp 193 loss=1532.820435 err=729.593994
I 2015-05-27 00:06:39 theanets.trainer:168 RmsProp 194 loss=1515.056641 err=713.614014
I 2015-05-27 00:07:15 theanets.trainer:168 RmsProp 195 loss=1507.413940 err=707.827026
I 2015-05-27 00:07:51 theanets.trainer:168 RmsProp 196 loss=1487.162476 err=688.943787
I 2015-05-27 00:08:27 theanets.trainer:168 RmsProp 197 loss=1480.924072 err=684.880615
I 2015-05-27 00:09:02 theanets.trainer:168 RmsProp 198 loss=1488.356323 err=692.981140
I 2015-05-27 00:09:38 theanets.trainer:168 RmsProp 199 loss=1488.952393 err=694.185791
I 2015-05-27 00:10:13 theanets.trainer:168 RmsProp 200 loss=1469.516968 err=675.055237
I 2015-05-27 00:10:14 theanets.trainer:168 validation 20 loss=2675.054932 err=1881.836304
I 2015-05-27 00:10:48 theanets.trainer:168 RmsProp 201 loss=1454.502441 err=662.351562
I 2015-05-27 00:11:23 theanets.trainer:168 RmsProp 202 loss=1493.882446 err=700.193237
I 2015-05-27 00:11:56 theanets.trainer:168 RmsProp 203 loss=1468.060303 err=674.515991
I 2015-05-27 00:12:29 theanets.trainer:168 RmsProp 204 loss=1466.100708 err=674.165710
I 2015-05-27 00:13:03 theanets.trainer:168 RmsProp 205 loss=1466.360107 err=676.572266
I 2015-05-27 00:13:36 theanets.trainer:168 RmsProp 206 loss=1456.734497 err=665.955627
I 2015-05-27 00:14:10 theanets.trainer:168 RmsProp 207 loss=1429.435059 err=640.843018
I 2015-05-27 00:14:43 theanets.trainer:168 RmsProp 208 loss=1442.296997 err=655.368896
I 2015-05-27 00:15:16 theanets.trainer:168 RmsProp 209 loss=1442.618896 err=655.253357
I 2015-05-27 00:15:49 theanets.trainer:168 RmsProp 210 loss=1450.387085 err=662.426331
I 2015-05-27 00:15:50 theanets.trainer:168 validation 21 loss=2709.392822 err=1921.800171
I 2015-05-27 00:16:22 theanets.trainer:168 RmsProp 211 loss=1413.534912 err=627.489014
I 2015-05-27 00:16:55 theanets.trainer:168 RmsProp 212 loss=1441.061890 err=655.378967
I 2015-05-27 00:17:29 theanets.trainer:168 RmsProp 213 loss=1474.302124 err=685.080017
I 2015-05-27 00:18:02 theanets.trainer:168 RmsProp 214 loss=1630.669067 err=832.042542
I 2015-05-27 00:18:35 theanets.trainer:168 RmsProp 215 loss=1589.387329 err=786.571838
I 2015-05-27 00:19:08 theanets.trainer:168 RmsProp 216 loss=1492.890991 err=693.806396
I 2015-05-27 00:19:41 theanets.trainer:168 RmsProp 217 loss=1438.009277 err=644.800537
I 2015-05-27 00:20:15 theanets.trainer:168 RmsProp 218 loss=1423.904907 err=634.894775
I 2015-05-27 00:20:48 theanets.trainer:168 RmsProp 219 loss=1412.519531 err=626.856384
I 2015-05-27 00:21:22 theanets.trainer:168 RmsProp 220 loss=1415.305298 err=631.143188
I 2015-05-27 00:21:23 theanets.trainer:168 validation 22 loss=2599.967529 err=1816.140503
I 2015-05-27 00:21:57 theanets.trainer:168 RmsProp 221 loss=1490.141479 err=704.566223
I 2015-05-27 00:22:30 theanets.trainer:168 RmsProp 222 loss=1518.942017 err=728.738647
I 2015-05-27 00:23:04 theanets.trainer:168 RmsProp 223 loss=1460.546509 err=671.283875
I 2015-05-27 00:23:37 theanets.trainer:168 RmsProp 224 loss=1414.389893 err=628.996277
I 2015-05-27 00:24:10 theanets.trainer:168 RmsProp 225 loss=1387.771729 err=606.719910
I 2015-05-27 00:24:43 theanets.trainer:168 RmsProp 226 loss=1392.435791 err=613.864868
I 2015-05-27 00:25:17 theanets.trainer:168 RmsProp 227 loss=1449.324463 err=668.403381
I 2015-05-27 00:25:50 theanets.trainer:168 RmsProp 228 loss=1428.656982 err=647.495056
I 2015-05-27 00:26:23 theanets.trainer:168 RmsProp 229 loss=1410.588257 err=631.297424
I 2015-05-27 00:26:55 theanets.trainer:168 RmsProp 230 loss=1459.881104 err=677.944580
I 2015-05-27 00:26:56 theanets.trainer:168 validation 23 loss=2894.768799 err=2109.943848
I 2015-05-27 00:26:56 theanets.trainer:252 patience elapsed!
I 2015-05-27 00:26:56 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 00:26:56 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 00:26:56 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 00:26:56 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 00:26:56 theanets.main:89 --batch_size = 1024
I 2015-05-27 00:26:56 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 00:26:56 theanets.main:89 --hidden_l1 = None
I 2015-05-27 00:26:56 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 00:26:56 theanets.main:89 --train_batches = 10
I 2015-05-27 00:26:56 theanets.main:89 --valid_batches = 2
I 2015-05-27 00:26:56 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 00:26:56 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 00:26:56 theanets.trainer:134 compiling evaluation function
I 2015-05-27 00:27:05 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 00:28:43 theanets.trainer:168 validation 0 loss=2561.755859 err=1756.855713 *
I 2015-05-27 00:28:53 theanets.trainer:168 RmsProp 1 loss=1176.077637 err=374.966248
I 2015-05-27 00:29:04 theanets.trainer:168 RmsProp 2 loss=1053.003784 err=256.187286
I 2015-05-27 00:29:14 theanets.trainer:168 RmsProp 3 loss=980.553040 err=187.312622
I 2015-05-27 00:29:24 theanets.trainer:168 RmsProp 4 loss=938.258667 err=148.687119
I 2015-05-27 00:29:35 theanets.trainer:168 RmsProp 5 loss=906.959167 err=121.395958
I 2015-05-27 00:29:45 theanets.trainer:168 RmsProp 6 loss=878.140503 err=97.185806
I 2015-05-27 00:29:55 theanets.trainer:168 RmsProp 7 loss=855.824829 err=80.067245
I 2015-05-27 00:30:06 theanets.trainer:168 RmsProp 8 loss=838.393188 err=68.002953
I 2015-05-27 00:30:16 theanets.trainer:168 RmsProp 9 loss=823.649902 err=58.889198
I 2015-05-27 00:30:26 theanets.trainer:168 RmsProp 10 loss=811.201538 err=52.369213
I 2015-05-27 00:30:27 theanets.trainer:168 validation 1 loss=1878.189209 err=1122.627197 *
I 2015-05-27 00:30:36 theanets.trainer:168 RmsProp 11 loss=798.379822 err=45.516289
I 2015-05-27 00:30:46 theanets.trainer:168 RmsProp 12 loss=789.558228 err=42.799248
I 2015-05-27 00:30:56 theanets.trainer:168 RmsProp 13 loss=779.100159 err=38.340984
I 2015-05-27 00:31:07 theanets.trainer:168 RmsProp 14 loss=770.044250 err=35.164894
I 2015-05-27 00:31:17 theanets.trainer:168 RmsProp 15 loss=761.380981 err=32.405357
I 2015-05-27 00:31:27 theanets.trainer:168 RmsProp 16 loss=753.669556 err=30.642120
I 2015-05-27 00:31:37 theanets.trainer:168 RmsProp 17 loss=746.057922 err=28.905298
I 2015-05-27 00:31:47 theanets.trainer:168 RmsProp 18 loss=738.711182 err=27.430004
I 2015-05-27 00:31:58 theanets.trainer:168 RmsProp 19 loss=730.989868 err=25.602749
I 2015-05-27 00:32:08 theanets.trainer:168 RmsProp 20 loss=723.461365 err=23.868818
I 2015-05-27 00:32:08 theanets.trainer:168 validation 2 loss=1768.668823 err=1072.256226 *
I 2015-05-27 00:32:18 theanets.trainer:168 RmsProp 21 loss=717.449219 err=23.618610
I 2015-05-27 00:32:29 theanets.trainer:168 RmsProp 22 loss=710.052795 err=21.789459
I 2015-05-27 00:32:39 theanets.trainer:168 RmsProp 23 loss=703.830627 err=20.883636
I 2015-05-27 00:32:50 theanets.trainer:168 RmsProp 24 loss=697.607300 err=19.865200
I 2015-05-27 00:33:00 theanets.trainer:168 RmsProp 25 loss=692.096741 err=19.576757
I 2015-05-27 00:33:10 theanets.trainer:168 RmsProp 26 loss=686.276978 err=18.904497
I 2015-05-27 00:33:20 theanets.trainer:168 RmsProp 27 loss=680.227661 err=17.886753
I 2015-05-27 00:33:31 theanets.trainer:168 RmsProp 28 loss=674.357300 err=17.062181
I 2015-05-27 00:33:41 theanets.trainer:168 RmsProp 29 loss=669.383606 err=17.268257
I 2015-05-27 00:33:51 theanets.trainer:168 RmsProp 30 loss=663.109802 err=15.976290
I 2015-05-27 00:33:52 theanets.trainer:168 validation 3 loss=1699.083130 err=1054.594604 *
I 2015-05-27 00:34:02 theanets.trainer:168 RmsProp 31 loss=657.772156 err=15.481062
I 2015-05-27 00:34:13 theanets.trainer:168 RmsProp 32 loss=652.457397 err=15.067831
I 2015-05-27 00:34:23 theanets.trainer:168 RmsProp 33 loss=647.588928 err=15.063963
I 2015-05-27 00:34:34 theanets.trainer:168 RmsProp 34 loss=642.158813 err=14.326639
I 2015-05-27 00:34:44 theanets.trainer:168 RmsProp 35 loss=636.601135 err=13.351091
I 2015-05-27 00:34:55 theanets.trainer:168 RmsProp 36 loss=632.856445 err=14.188779
I 2015-05-27 00:35:05 theanets.trainer:168 RmsProp 37 loss=627.046814 err=12.824221
I 2015-05-27 00:35:15 theanets.trainer:168 RmsProp 38 loss=622.242981 err=12.487641
I 2015-05-27 00:35:26 theanets.trainer:168 RmsProp 39 loss=618.252502 err=13.050656
I 2015-05-27 00:35:36 theanets.trainer:168 RmsProp 40 loss=612.618530 err=11.820536
I 2015-05-27 00:35:37 theanets.trainer:168 validation 4 loss=1644.296997 err=1045.895386 *
I 2015-05-27 00:35:47 theanets.trainer:168 RmsProp 41 loss=608.175293 err=11.752639
I 2015-05-27 00:35:57 theanets.trainer:168 RmsProp 42 loss=603.786682 err=11.733573
I 2015-05-27 00:36:07 theanets.trainer:168 RmsProp 43 loss=598.727966 err=10.989554
I 2015-05-27 00:36:18 theanets.trainer:168 RmsProp 44 loss=594.881775 err=11.424184
I 2015-05-27 00:36:28 theanets.trainer:168 RmsProp 45 loss=590.112976 err=10.772267
I 2015-05-27 00:36:38 theanets.trainer:168 RmsProp 46 loss=586.030029 err=10.755495
I 2015-05-27 00:36:48 theanets.trainer:168 RmsProp 47 loss=581.854309 err=10.599991
I 2015-05-27 00:36:58 theanets.trainer:168 RmsProp 48 loss=577.858704 err=10.547864
I 2015-05-27 00:37:09 theanets.trainer:168 RmsProp 49 loss=573.507080 err=10.042475
I 2015-05-27 00:37:19 theanets.trainer:168 RmsProp 50 loss=569.535217 err=9.882913
I 2015-05-27 00:37:19 theanets.trainer:168 validation 5 loss=1592.848022 err=1035.302368 *
I 2015-05-27 00:37:30 theanets.trainer:168 RmsProp 51 loss=565.538696 err=9.723231
I 2015-05-27 00:37:41 theanets.trainer:168 RmsProp 52 loss=562.246948 err=10.226304
I 2015-05-27 00:37:51 theanets.trainer:168 RmsProp 53 loss=557.817810 err=9.370318
I 2015-05-27 00:38:01 theanets.trainer:168 RmsProp 54 loss=554.046265 err=9.104786
I 2015-05-27 00:38:11 theanets.trainer:168 RmsProp 55 loss=550.682007 err=9.326953
I 2015-05-27 00:38:21 theanets.trainer:168 RmsProp 56 loss=546.865601 err=9.084784
I 2015-05-27 00:38:32 theanets.trainer:168 RmsProp 57 loss=543.320435 err=9.062387
I 2015-05-27 00:38:42 theanets.trainer:168 RmsProp 58 loss=539.285461 err=8.486306
I 2015-05-27 00:38:52 theanets.trainer:168 RmsProp 59 loss=535.475708 err=8.126354
I 2015-05-27 00:39:02 theanets.trainer:168 RmsProp 60 loss=534.057129 err=10.239215
I 2015-05-27 00:39:03 theanets.trainer:168 validation 6 loss=1526.652344 err=1004.674927 *
I 2015-05-27 00:39:13 theanets.trainer:168 RmsProp 61 loss=529.555725 err=8.970559
I 2015-05-27 00:39:23 theanets.trainer:168 RmsProp 62 loss=525.600098 err=7.994541
I 2015-05-27 00:39:34 theanets.trainer:168 RmsProp 63 loss=522.858276 err=8.319798
I 2015-05-27 00:39:44 theanets.trainer:168 RmsProp 64 loss=519.319702 err=7.963483
I 2015-05-27 00:39:54 theanets.trainer:168 RmsProp 65 loss=516.325439 err=8.239794
I 2015-05-27 00:40:05 theanets.trainer:168 RmsProp 66 loss=513.445312 err=8.609085
I 2015-05-27 00:40:15 theanets.trainer:168 RmsProp 67 loss=509.490875 err=7.667041
I 2015-05-27 00:40:25 theanets.trainer:168 RmsProp 68 loss=506.992279 err=8.128232
I 2015-05-27 00:40:36 theanets.trainer:168 RmsProp 69 loss=503.664703 err=7.760623
I 2015-05-27 00:40:46 theanets.trainer:168 RmsProp 70 loss=500.682678 err=7.700864
I 2015-05-27 00:40:46 theanets.trainer:168 validation 7 loss=1494.138062 err=1002.755310 *
I 2015-05-27 00:40:56 theanets.trainer:168 RmsProp 71 loss=497.595123 err=7.527454
I 2015-05-27 00:41:07 theanets.trainer:168 RmsProp 72 loss=494.398438 err=7.267733
I 2015-05-27 00:41:17 theanets.trainer:168 RmsProp 73 loss=491.550629 err=7.378084
I 2015-05-27 00:41:27 theanets.trainer:168 RmsProp 74 loss=488.567444 err=7.350068
I 2015-05-27 00:41:37 theanets.trainer:168 RmsProp 75 loss=485.569489 err=7.264814
I 2015-05-27 00:41:47 theanets.trainer:168 RmsProp 76 loss=482.697601 err=7.231725
I 2015-05-27 00:41:57 theanets.trainer:168 RmsProp 77 loss=479.820618 err=7.147642
I 2015-05-27 00:42:07 theanets.trainer:168 RmsProp 78 loss=476.976959 err=7.041247
I 2015-05-27 00:42:18 theanets.trainer:168 RmsProp 79 loss=474.191650 err=6.972061
I 2015-05-27 00:42:28 theanets.trainer:168 RmsProp 80 loss=471.808990 err=7.267319
I 2015-05-27 00:42:29 theanets.trainer:168 validation 8 loss=1470.759155 err=1007.677368 *
I 2015-05-27 00:42:39 theanets.trainer:168 RmsProp 81 loss=468.856293 err=6.943007
I 2015-05-27 00:42:49 theanets.trainer:168 RmsProp 82 loss=465.763184 err=6.430205
I 2015-05-27 00:42:59 theanets.trainer:168 RmsProp 83 loss=463.872253 err=7.155725
I 2015-05-27 00:43:10 theanets.trainer:168 RmsProp 84 loss=460.597107 err=6.472617
I 2015-05-27 00:43:20 theanets.trainer:168 RmsProp 85 loss=458.567810 err=7.023198
I 2015-05-27 00:43:30 theanets.trainer:168 RmsProp 86 loss=455.889313 err=6.856899
I 2015-05-27 00:43:40 theanets.trainer:168 RmsProp 87 loss=453.121521 err=6.523017
I 2015-05-27 00:43:50 theanets.trainer:168 RmsProp 88 loss=450.801849 err=6.589436
I 2015-05-27 00:44:00 theanets.trainer:168 RmsProp 89 loss=448.224854 err=6.387607
I 2015-05-27 00:44:10 theanets.trainer:168 RmsProp 90 loss=445.968170 err=6.526857
I 2015-05-27 00:44:11 theanets.trainer:168 validation 9 loss=1439.329712 err=1001.197083 *
I 2015-05-27 00:44:21 theanets.trainer:168 RmsProp 91 loss=443.318115 err=6.257649
I 2015-05-27 00:44:31 theanets.trainer:168 RmsProp 92 loss=441.089264 err=6.399362
I 2015-05-27 00:44:41 theanets.trainer:168 RmsProp 93 loss=438.842773 err=6.506527
I 2015-05-27 00:44:51 theanets.trainer:168 RmsProp 94 loss=436.162537 err=6.131321
I 2015-05-27 00:45:01 theanets.trainer:168 RmsProp 95 loss=434.140289 err=6.376431
I 2015-05-27 00:45:11 theanets.trainer:168 RmsProp 96 loss=431.648621 err=6.129748
I 2015-05-27 00:45:21 theanets.trainer:168 RmsProp 97 loss=429.599274 err=6.328062
I 2015-05-27 00:45:31 theanets.trainer:168 RmsProp 98 loss=427.514648 err=6.468199
I 2015-05-27 00:45:42 theanets.trainer:168 RmsProp 99 loss=424.741211 err=5.842483
I 2015-05-27 00:45:52 theanets.trainer:168 RmsProp 100 loss=422.614655 err=5.860870
I 2015-05-27 00:45:53 theanets.trainer:168 validation 10 loss=1393.468262 err=977.907654 *
I 2015-05-27 00:46:03 theanets.trainer:168 RmsProp 101 loss=420.774506 err=6.189174
I 2015-05-27 00:46:13 theanets.trainer:168 RmsProp 102 loss=418.561127 err=6.122696
I 2015-05-27 00:46:24 theanets.trainer:168 RmsProp 103 loss=416.221252 err=5.883886
I 2015-05-27 00:46:34 theanets.trainer:168 RmsProp 104 loss=414.432129 err=6.171081
I 2015-05-27 00:46:44 theanets.trainer:168 RmsProp 105 loss=411.921783 err=5.704034
I 2015-05-27 00:46:55 theanets.trainer:168 RmsProp 106 loss=410.077942 err=5.888015
I 2015-05-27 00:47:06 theanets.trainer:168 RmsProp 107 loss=408.385223 err=6.214583
I 2015-05-27 00:47:16 theanets.trainer:168 RmsProp 108 loss=406.040436 err=5.824430
I 2015-05-27 00:47:27 theanets.trainer:168 RmsProp 109 loss=403.959747 err=5.647882
I 2015-05-27 00:47:37 theanets.trainer:168 RmsProp 110 loss=402.098907 err=5.713744
I 2015-05-27 00:47:38 theanets.trainer:168 validation 11 loss=1368.221924 err=972.919128 *
I 2015-05-27 00:47:48 theanets.trainer:168 RmsProp 111 loss=400.256287 err=5.829871
I 2015-05-27 00:47:59 theanets.trainer:168 RmsProp 112 loss=398.107147 err=5.595597
I 2015-05-27 00:48:10 theanets.trainer:168 RmsProp 113 loss=395.905365 err=5.318211
I 2015-05-27 00:48:20 theanets.trainer:168 RmsProp 114 loss=394.562103 err=5.907504
I 2015-05-27 00:48:31 theanets.trainer:168 RmsProp 115 loss=392.473328 err=5.690940
I 2015-05-27 00:48:42 theanets.trainer:168 RmsProp 116 loss=390.692322 err=5.737007
I 2015-05-27 00:48:53 theanets.trainer:168 RmsProp 117 loss=388.438416 err=5.281439
I 2015-05-27 00:49:03 theanets.trainer:168 RmsProp 118 loss=386.938171 err=5.581572
I 2015-05-27 00:49:14 theanets.trainer:168 RmsProp 119 loss=385.182343 err=5.617173
I 2015-05-27 00:49:25 theanets.trainer:168 RmsProp 120 loss=382.995941 err=5.196301
I 2015-05-27 00:49:25 theanets.trainer:168 validation 12 loss=1351.172729 err=974.354492 *
I 2015-05-27 00:49:36 theanets.trainer:168 RmsProp 121 loss=381.661682 err=5.645831
I 2015-05-27 00:49:46 theanets.trainer:168 RmsProp 122 loss=379.731293 err=5.477202
I 2015-05-27 00:49:57 theanets.trainer:168 RmsProp 123 loss=377.786560 err=5.269326
I 2015-05-27 00:50:07 theanets.trainer:168 RmsProp 124 loss=375.824371 err=5.044078
I 2015-05-27 00:50:18 theanets.trainer:168 RmsProp 125 loss=374.564392 err=5.531791
I 2015-05-27 00:50:29 theanets.trainer:168 RmsProp 126 loss=372.648987 err=5.326880
I 2015-05-27 00:50:39 theanets.trainer:168 RmsProp 127 loss=370.953247 err=5.305861
I 2015-05-27 00:50:50 theanets.trainer:168 RmsProp 128 loss=369.438812 err=5.439983
I 2015-05-27 00:51:00 theanets.trainer:168 RmsProp 129 loss=367.554810 err=5.176514
I 2015-05-27 00:51:11 theanets.trainer:168 RmsProp 130 loss=365.846619 err=5.089678
I 2015-05-27 00:51:11 theanets.trainer:168 validation 13 loss=1317.628296 err=957.765625 *
I 2015-05-27 00:51:22 theanets.trainer:168 RmsProp 131 loss=364.493286 err=5.365769
I 2015-05-27 00:51:32 theanets.trainer:168 RmsProp 132 loss=362.389526 err=4.878660
I 2015-05-27 00:51:42 theanets.trainer:168 RmsProp 133 loss=361.215546 err=5.330413
I 2015-05-27 00:51:53 theanets.trainer:168 RmsProp 134 loss=359.854401 err=5.570607
I 2015-05-27 00:52:03 theanets.trainer:168 RmsProp 135 loss=357.502136 err=4.737380
I 2015-05-27 00:52:14 theanets.trainer:168 RmsProp 136 loss=356.503387 err=5.270518
I 2015-05-27 00:52:24 theanets.trainer:168 RmsProp 137 loss=355.795532 err=6.102087
I 2015-05-27 00:52:35 theanets.trainer:168 RmsProp 138 loss=353.335754 err=5.066388
I 2015-05-27 00:52:45 theanets.trainer:168 RmsProp 139 loss=351.602173 err=4.713541
I 2015-05-27 00:52:56 theanets.trainer:168 RmsProp 140 loss=350.291748 err=4.848117
I 2015-05-27 00:52:56 theanets.trainer:168 validation 14 loss=1296.044922 err=951.423157 *
I 2015-05-27 00:53:07 theanets.trainer:168 RmsProp 141 loss=349.183197 err=5.235293
I 2015-05-27 00:53:17 theanets.trainer:168 RmsProp 142 loss=347.355347 err=4.893327
I 2015-05-27 00:53:27 theanets.trainer:168 RmsProp 143 loss=345.820496 err=4.831870
I 2015-05-27 00:53:38 theanets.trainer:168 RmsProp 144 loss=344.940643 err=5.419133
I 2015-05-27 00:53:48 theanets.trainer:168 RmsProp 145 loss=343.030365 err=4.912177
I 2015-05-27 00:53:58 theanets.trainer:168 RmsProp 146 loss=341.661865 err=4.922582
I 2015-05-27 00:54:09 theanets.trainer:168 RmsProp 147 loss=340.077942 err=4.720347
I 2015-05-27 00:54:19 theanets.trainer:168 RmsProp 148 loss=338.261230 err=4.303782
I 2015-05-27 00:54:29 theanets.trainer:168 RmsProp 149 loss=339.164490 err=6.644025
I 2015-05-27 00:54:40 theanets.trainer:168 RmsProp 150 loss=336.563354 err=5.365101
I 2015-05-27 00:54:40 theanets.trainer:168 validation 15 loss=1289.776733 err=959.246521 *
I 2015-05-27 00:54:51 theanets.trainer:168 RmsProp 151 loss=334.369781 err=4.396213
I 2015-05-27 00:55:01 theanets.trainer:168 RmsProp 152 loss=333.441467 err=4.723281
I 2015-05-27 00:55:12 theanets.trainer:168 RmsProp 153 loss=332.072693 err=4.677557
I 2015-05-27 00:55:22 theanets.trainer:168 RmsProp 154 loss=331.164612 err=5.124786
I 2015-05-27 00:55:32 theanets.trainer:168 RmsProp 155 loss=329.586975 err=4.870299
I 2015-05-27 00:55:43 theanets.trainer:168 RmsProp 156 loss=328.104675 err=4.664419
I 2015-05-27 00:55:53 theanets.trainer:168 RmsProp 157 loss=326.724152 err=4.559348
I 2015-05-27 00:56:03 theanets.trainer:168 RmsProp 158 loss=325.799011 err=4.940000
I 2015-05-27 00:56:14 theanets.trainer:168 RmsProp 159 loss=324.237122 err=4.666132
I 2015-05-27 00:56:24 theanets.trainer:168 RmsProp 160 loss=322.909851 err=4.596200
I 2015-05-27 00:56:25 theanets.trainer:168 validation 16 loss=1269.935669 err=952.308777 *
I 2015-05-27 00:56:35 theanets.trainer:168 RmsProp 161 loss=321.611694 err=4.552873
I 2015-05-27 00:56:46 theanets.trainer:168 RmsProp 162 loss=320.765991 err=4.976717
I 2015-05-27 00:56:56 theanets.trainer:168 RmsProp 163 loss=318.841370 err=4.301702
I 2015-05-27 00:57:06 theanets.trainer:168 RmsProp 164 loss=317.961731 err=4.646634
I 2015-05-27 00:57:17 theanets.trainer:168 RmsProp 165 loss=317.082184 err=4.982387
I 2015-05-27 00:57:27 theanets.trainer:168 RmsProp 166 loss=315.363831 err=4.450181
I 2015-05-27 00:57:37 theanets.trainer:168 RmsProp 167 loss=314.419037 err=4.700053
I 2015-05-27 00:57:48 theanets.trainer:168 RmsProp 168 loss=313.350983 err=4.811148
I 2015-05-27 00:57:58 theanets.trainer:168 RmsProp 169 loss=311.926514 err=4.531212
I 2015-05-27 00:58:08 theanets.trainer:168 RmsProp 170 loss=310.769104 err=4.507043
I 2015-05-27 00:58:09 theanets.trainer:168 validation 17 loss=1248.605347 err=942.968750 *
I 2015-05-27 00:58:19 theanets.trainer:168 RmsProp 171 loss=309.700134 err=4.578795
I 2015-05-27 00:58:29 theanets.trainer:168 RmsProp 172 loss=308.494995 err=4.519317
I 2015-05-27 00:58:39 theanets.trainer:168 RmsProp 173 loss=307.884003 err=5.033897
I 2015-05-27 00:58:49 theanets.trainer:168 RmsProp 174 loss=306.107483 err=4.349759
I 2015-05-27 00:59:00 theanets.trainer:168 RmsProp 175 loss=305.395660 err=4.722746
I 2015-05-27 00:59:11 theanets.trainer:168 RmsProp 176 loss=304.067230 err=4.484723
I 2015-05-27 00:59:21 theanets.trainer:168 RmsProp 177 loss=302.917969 err=4.412423
I 2015-05-27 00:59:32 theanets.trainer:168 RmsProp 178 loss=302.293762 err=4.861478
I 2015-05-27 00:59:42 theanets.trainer:168 RmsProp 179 loss=300.670044 err=4.291676
I 2015-05-27 00:59:52 theanets.trainer:168 RmsProp 180 loss=299.820557 err=4.496813
I 2015-05-27 00:59:53 theanets.trainer:168 validation 18 loss=1226.469360 err=931.729431 *
I 2015-05-27 01:00:03 theanets.trainer:168 RmsProp 181 loss=298.963074 err=4.703355
I 2015-05-27 01:00:13 theanets.trainer:168 RmsProp 182 loss=297.371674 err=4.151885
I 2015-05-27 01:00:23 theanets.trainer:168 RmsProp 183 loss=296.741608 err=4.555710
I 2015-05-27 01:00:33 theanets.trainer:168 RmsProp 184 loss=295.253632 err=4.108871
I 2015-05-27 01:00:43 theanets.trainer:168 RmsProp 185 loss=294.694580 err=4.596995
I 2015-05-27 01:00:52 theanets.trainer:168 RmsProp 186 loss=293.562805 err=4.499303
I 2015-05-27 01:01:02 theanets.trainer:168 RmsProp 187 loss=292.426514 err=4.376195
I 2015-05-27 01:01:12 theanets.trainer:168 RmsProp 188 loss=291.265778 err=4.227588
I 2015-05-27 01:01:22 theanets.trainer:168 RmsProp 189 loss=290.176422 err=4.153167
I 2015-05-27 01:01:32 theanets.trainer:168 RmsProp 190 loss=289.704407 err=4.681800
I 2015-05-27 01:01:33 theanets.trainer:168 validation 19 loss=1214.797119 err=930.323364 *
I 2015-05-27 01:01:42 theanets.trainer:168 RmsProp 191 loss=288.192566 err=4.152176
I 2015-05-27 01:01:52 theanets.trainer:168 RmsProp 192 loss=287.464539 err=4.405316
I 2015-05-27 01:02:03 theanets.trainer:168 RmsProp 193 loss=286.395599 err=4.319746
I 2015-05-27 01:02:13 theanets.trainer:168 RmsProp 194 loss=285.334778 err=4.224766
I 2015-05-27 01:02:23 theanets.trainer:168 RmsProp 195 loss=284.359772 err=4.209963
I 2015-05-27 01:02:34 theanets.trainer:168 RmsProp 196 loss=283.371887 err=4.175725
I 2015-05-27 01:02:44 theanets.trainer:168 RmsProp 197 loss=282.718262 err=4.475513
I 2015-05-27 01:02:55 theanets.trainer:168 RmsProp 198 loss=281.295715 err=4.001096
I 2015-05-27 01:03:05 theanets.trainer:168 RmsProp 199 loss=281.108765 err=4.761695
I 2015-05-27 01:03:15 theanets.trainer:168 RmsProp 200 loss=279.823395 err=4.397471
I 2015-05-27 01:03:16 theanets.trainer:168 validation 20 loss=1190.742310 err=915.796326 *
I 2015-05-27 01:03:26 theanets.trainer:168 RmsProp 201 loss=278.940948 err=4.385141
I 2015-05-27 01:03:37 theanets.trainer:168 RmsProp 202 loss=277.939667 err=4.240617
I 2015-05-27 01:03:47 theanets.trainer:168 RmsProp 203 loss=277.003876 err=4.172188
I 2015-05-27 01:03:58 theanets.trainer:168 RmsProp 204 loss=275.991516 err=4.038003
I 2015-05-27 01:04:09 theanets.trainer:168 RmsProp 205 loss=275.386047 err=4.321008
I 2015-05-27 01:04:19 theanets.trainer:168 RmsProp 206 loss=274.390259 err=4.207979
I 2015-05-27 01:04:30 theanets.trainer:168 RmsProp 207 loss=273.558014 err=4.244278
I 2015-05-27 01:04:41 theanets.trainer:168 RmsProp 208 loss=272.267029 err=3.822753
I 2015-05-27 01:04:52 theanets.trainer:168 RmsProp 209 loss=271.923950 err=4.363315
I 2015-05-27 01:05:02 theanets.trainer:168 RmsProp 210 loss=270.672485 err=3.986833
I 2015-05-27 01:05:03 theanets.trainer:168 validation 21 loss=1180.199219 err=913.983887 *
I 2015-05-27 01:05:14 theanets.trainer:168 RmsProp 211 loss=269.867981 err=4.038705
I 2015-05-27 01:05:25 theanets.trainer:168 RmsProp 212 loss=269.192871 err=4.218821
I 2015-05-27 01:05:35 theanets.trainer:168 RmsProp 213 loss=268.336914 err=4.215645
I 2015-05-27 01:05:45 theanets.trainer:168 RmsProp 214 loss=267.293701 err=4.009312
I 2015-05-27 01:05:56 theanets.trainer:168 RmsProp 215 loss=266.665192 err=4.203705
I 2015-05-27 01:06:06 theanets.trainer:168 RmsProp 216 loss=265.783020 err=4.143678
I 2015-05-27 01:06:17 theanets.trainer:168 RmsProp 217 loss=265.007629 err=4.177017
I 2015-05-27 01:06:27 theanets.trainer:168 RmsProp 218 loss=264.109314 err=4.084062
I 2015-05-27 01:06:38 theanets.trainer:168 RmsProp 219 loss=263.414185 err=4.189035
I 2015-05-27 01:06:48 theanets.trainer:168 RmsProp 220 loss=262.780823 err=4.332351
I 2015-05-27 01:06:49 theanets.trainer:168 validation 22 loss=1162.213867 err=904.184998 *
I 2015-05-27 01:06:59 theanets.trainer:168 RmsProp 221 loss=261.583038 err=3.897392
I 2015-05-27 01:07:10 theanets.trainer:168 RmsProp 222 loss=260.886536 err=3.962736
I 2015-05-27 01:07:21 theanets.trainer:168 RmsProp 223 loss=260.470459 err=4.332929
I 2015-05-27 01:07:31 theanets.trainer:168 RmsProp 224 loss=259.310242 err=3.954852
I 2015-05-27 01:07:41 theanets.trainer:168 RmsProp 225 loss=258.555847 err=3.963243
I 2015-05-27 01:07:52 theanets.trainer:168 RmsProp 226 loss=257.847748 err=4.019492
I 2015-05-27 01:08:03 theanets.trainer:168 RmsProp 227 loss=257.307373 err=4.242026
I 2015-05-27 01:08:14 theanets.trainer:168 RmsProp 228 loss=256.155090 err=3.847719
I 2015-05-27 01:08:24 theanets.trainer:168 RmsProp 229 loss=255.689056 err=4.125152
I 2015-05-27 01:08:35 theanets.trainer:168 RmsProp 230 loss=254.727570 err=3.905145
I 2015-05-27 01:08:36 theanets.trainer:168 validation 23 loss=1154.930908 err=904.511414 *
I 2015-05-27 01:08:46 theanets.trainer:168 RmsProp 231 loss=254.205521 err=4.120400
I 2015-05-27 01:08:57 theanets.trainer:168 RmsProp 232 loss=253.360199 err=4.008526
I 2015-05-27 01:09:08 theanets.trainer:168 RmsProp 233 loss=252.325348 err=3.697600
I 2015-05-27 01:09:19 theanets.trainer:168 RmsProp 234 loss=252.267242 err=4.355786
I 2015-05-27 01:09:30 theanets.trainer:168 RmsProp 235 loss=251.001144 err=3.815915
I 2015-05-27 01:09:41 theanets.trainer:168 RmsProp 236 loss=250.474731 err=4.009027
I 2015-05-27 01:09:52 theanets.trainer:168 RmsProp 237 loss=249.833450 err=4.081219
I 2015-05-27 01:10:02 theanets.trainer:168 RmsProp 238 loss=248.568390 err=3.516413
I 2015-05-27 01:10:13 theanets.trainer:168 RmsProp 239 loss=248.755829 err=4.400764
I 2015-05-27 01:10:24 theanets.trainer:168 RmsProp 240 loss=247.795624 err=4.131648
I 2015-05-27 01:10:24 theanets.trainer:168 validation 24 loss=1159.935059 err=916.633789
I 2015-05-27 01:10:35 theanets.trainer:168 RmsProp 241 loss=246.659515 err=3.672906
I 2015-05-27 01:10:46 theanets.trainer:168 RmsProp 242 loss=246.580078 err=4.284883
I 2015-05-27 01:10:57 theanets.trainer:168 RmsProp 243 loss=246.190826 err=4.570079
I 2015-05-27 01:11:07 theanets.trainer:168 RmsProp 244 loss=244.768585 err=3.793774
I 2015-05-27 01:11:18 theanets.trainer:168 RmsProp 245 loss=244.268188 err=3.927471
I 2015-05-27 01:11:30 theanets.trainer:168 RmsProp 246 loss=243.377075 err=3.688863
I 2015-05-27 01:11:40 theanets.trainer:168 RmsProp 247 loss=242.743973 err=3.722922
I 2015-05-27 01:11:51 theanets.trainer:168 RmsProp 248 loss=242.591309 err=4.236258
I 2015-05-27 01:12:02 theanets.trainer:168 RmsProp 249 loss=241.449631 err=3.754412
I 2015-05-27 01:12:13 theanets.trainer:168 RmsProp 250 loss=240.790863 err=3.746357
I 2015-05-27 01:12:14 theanets.trainer:168 validation 25 loss=1133.470337 err=896.785950 *
I 2015-05-27 01:12:25 theanets.trainer:168 RmsProp 251 loss=240.219803 err=3.833160
I 2015-05-27 01:12:35 theanets.trainer:168 RmsProp 252 loss=239.574265 err=3.840704
I 2015-05-27 01:12:46 theanets.trainer:168 RmsProp 253 loss=238.944016 err=3.861707
I 2015-05-27 01:12:57 theanets.trainer:168 RmsProp 254 loss=238.201202 err=3.768911
I 2015-05-27 01:13:08 theanets.trainer:168 RmsProp 255 loss=237.688278 err=3.902147
I 2015-05-27 01:13:18 theanets.trainer:168 RmsProp 256 loss=236.959442 err=3.811584
I 2015-05-27 01:13:29 theanets.trainer:168 RmsProp 257 loss=236.286331 err=3.770318
I 2015-05-27 01:13:39 theanets.trainer:168 RmsProp 258 loss=235.712402 err=3.823955
I 2015-05-27 01:13:50 theanets.trainer:168 RmsProp 259 loss=235.064255 err=3.792099
I 2015-05-27 01:14:00 theanets.trainer:168 RmsProp 260 loss=234.513580 err=3.851661
I 2015-05-27 01:14:01 theanets.trainer:168 validation 26 loss=1125.691406 err=895.371765 *
I 2015-05-27 01:14:11 theanets.trainer:168 RmsProp 261 loss=233.787766 err=3.743364
I 2015-05-27 01:14:22 theanets.trainer:168 RmsProp 262 loss=233.388153 err=3.956131
I 2015-05-27 01:14:32 theanets.trainer:168 RmsProp 263 loss=232.614838 err=3.787543
I 2015-05-27 01:14:42 theanets.trainer:168 RmsProp 264 loss=231.738770 err=3.507132
I 2015-05-27 01:14:53 theanets.trainer:168 RmsProp 265 loss=231.458664 err=3.823905
I 2015-05-27 01:15:03 theanets.trainer:168 RmsProp 266 loss=230.966797 err=3.933990
I 2015-05-27 01:15:14 theanets.trainer:168 RmsProp 267 loss=230.632233 err=4.182492
I 2015-05-27 01:15:24 theanets.trainer:168 RmsProp 268 loss=229.451324 err=3.570988
I 2015-05-27 01:15:34 theanets.trainer:168 RmsProp 269 loss=228.742401 err=3.429562
I 2015-05-27 01:15:45 theanets.trainer:168 RmsProp 270 loss=228.791702 err=4.060554
I 2015-05-27 01:15:45 theanets.trainer:168 validation 27 loss=1113.394897 err=888.975098 *
I 2015-05-27 01:15:56 theanets.trainer:168 RmsProp 271 loss=227.707840 err=3.551904
I 2015-05-27 01:16:06 theanets.trainer:168 RmsProp 272 loss=227.422455 err=3.841509
I 2015-05-27 01:16:17 theanets.trainer:168 RmsProp 273 loss=226.879593 err=3.870282
I 2015-05-27 01:16:28 theanets.trainer:168 RmsProp 274 loss=226.222488 err=3.778494
I 2015-05-27 01:16:38 theanets.trainer:168 RmsProp 275 loss=225.362228 err=3.478887
I 2015-05-27 01:16:49 theanets.trainer:168 RmsProp 276 loss=225.117599 err=3.788643
I 2015-05-27 01:17:00 theanets.trainer:168 RmsProp 277 loss=224.372604 err=3.598417
I 2015-05-27 01:17:10 theanets.trainer:168 RmsProp 278 loss=223.298981 err=3.083479
I 2015-05-27 01:17:20 theanets.trainer:168 RmsProp 279 loss=225.507080 err=5.836602
I 2015-05-27 01:17:31 theanets.trainer:168 RmsProp 280 loss=223.107010 err=3.947402
I 2015-05-27 01:17:32 theanets.trainer:168 validation 28 loss=1124.300293 err=905.403625
I 2015-05-27 01:17:42 theanets.trainer:168 RmsProp 281 loss=222.219086 err=3.546574
I 2015-05-27 01:17:53 theanets.trainer:168 RmsProp 282 loss=221.792114 err=3.611198
I 2015-05-27 01:18:04 theanets.trainer:168 RmsProp 283 loss=221.504959 err=3.830806
I 2015-05-27 01:18:15 theanets.trainer:168 RmsProp 284 loss=220.684479 err=3.539515
I 2015-05-27 01:18:26 theanets.trainer:168 RmsProp 285 loss=220.269897 err=3.649666
I 2015-05-27 01:18:37 theanets.trainer:168 RmsProp 286 loss=219.676834 err=3.578804
I 2015-05-27 01:18:48 theanets.trainer:168 RmsProp 287 loss=219.146805 err=3.569733
I 2015-05-27 01:18:58 theanets.trainer:168 RmsProp 288 loss=218.899368 err=3.848279
I 2015-05-27 01:19:09 theanets.trainer:168 RmsProp 289 loss=217.825470 err=3.297700
I 2015-05-27 01:19:20 theanets.trainer:168 RmsProp 290 loss=218.651978 err=4.650275
I 2015-05-27 01:19:21 theanets.trainer:168 validation 29 loss=1119.424438 err=905.698364
I 2015-05-27 01:19:31 theanets.trainer:168 RmsProp 291 loss=217.740433 err=4.235674
I 2015-05-27 01:19:42 theanets.trainer:168 RmsProp 292 loss=216.164703 err=3.135954
I 2015-05-27 01:19:53 theanets.trainer:168 RmsProp 293 loss=216.521515 err=3.970801
I 2015-05-27 01:20:04 theanets.trainer:168 RmsProp 294 loss=216.197174 err=4.124285
I 2015-05-27 01:20:15 theanets.trainer:168 RmsProp 295 loss=215.049759 err=3.452520
I 2015-05-27 01:20:26 theanets.trainer:168 RmsProp 296 loss=214.885468 err=3.763195
I 2015-05-27 01:20:37 theanets.trainer:168 RmsProp 297 loss=214.393951 err=3.747520
I 2015-05-27 01:20:48 theanets.trainer:168 RmsProp 298 loss=213.682648 err=3.510421
I 2015-05-27 01:20:58 theanets.trainer:168 RmsProp 299 loss=213.157715 err=3.463351
I 2015-05-27 01:21:09 theanets.trainer:168 RmsProp 300 loss=212.938995 err=3.735270
I 2015-05-27 01:21:09 theanets.trainer:168 validation 30 loss=1099.434692 err=890.497864 *
I 2015-05-27 01:21:20 theanets.trainer:168 RmsProp 301 loss=212.055328 err=3.336247
I 2015-05-27 01:21:30 theanets.trainer:168 RmsProp 302 loss=211.651901 err=3.422864
I 2015-05-27 01:21:41 theanets.trainer:168 RmsProp 303 loss=211.673004 err=3.931196
I 2015-05-27 01:21:51 theanets.trainer:168 RmsProp 304 loss=210.795929 err=3.532146
I 2015-05-27 01:22:02 theanets.trainer:168 RmsProp 305 loss=210.259125 err=3.463722
I 2015-05-27 01:22:13 theanets.trainer:168 RmsProp 306 loss=209.783295 err=3.453059
I 2015-05-27 01:22:24 theanets.trainer:168 RmsProp 307 loss=209.607132 err=3.746239
I 2015-05-27 01:22:35 theanets.trainer:168 RmsProp 308 loss=209.314651 err=3.911171
I 2015-05-27 01:22:46 theanets.trainer:168 RmsProp 309 loss=208.250732 err=3.302843
I 2015-05-27 01:22:57 theanets.trainer:168 RmsProp 310 loss=208.328659 err=3.834856
I 2015-05-27 01:22:57 theanets.trainer:168 validation 31 loss=1087.818970 err=883.572571 *
I 2015-05-27 01:23:08 theanets.trainer:168 RmsProp 311 loss=207.852127 err=3.804823
I 2015-05-27 01:23:19 theanets.trainer:168 RmsProp 312 loss=206.955276 err=3.350784
I 2015-05-27 01:23:29 theanets.trainer:168 RmsProp 313 loss=206.662231 err=3.493333
I 2015-05-27 01:23:40 theanets.trainer:168 RmsProp 314 loss=206.292191 err=3.565691
I 2015-05-27 01:23:51 theanets.trainer:168 RmsProp 315 loss=206.016083 err=3.731410
I 2015-05-27 01:24:02 theanets.trainer:168 RmsProp 316 loss=205.076691 err=3.237293
I 2015-05-27 01:24:12 theanets.trainer:168 RmsProp 317 loss=205.140335 err=3.741004
I 2015-05-27 01:24:23 theanets.trainer:168 RmsProp 318 loss=204.375412 err=3.419833
I 2015-05-27 01:24:34 theanets.trainer:168 RmsProp 319 loss=204.100250 err=3.583673
I 2015-05-27 01:24:45 theanets.trainer:168 RmsProp 320 loss=203.578476 err=3.494715
I 2015-05-27 01:24:46 theanets.trainer:168 validation 32 loss=1088.964966 err=889.119568
I 2015-05-27 01:24:57 theanets.trainer:168 RmsProp 321 loss=202.996017 err=3.345004
I 2015-05-27 01:25:07 theanets.trainer:168 RmsProp 322 loss=202.687897 err=3.466022
I 2015-05-27 01:25:18 theanets.trainer:168 RmsProp 323 loss=202.330856 err=3.537652
I 2015-05-27 01:25:29 theanets.trainer:168 RmsProp 324 loss=201.877289 err=3.511383
I 2015-05-27 01:25:39 theanets.trainer:168 RmsProp 325 loss=201.853806 err=3.904165
I 2015-05-27 01:25:50 theanets.trainer:168 RmsProp 326 loss=201.075195 err=3.537406
I 2015-05-27 01:26:01 theanets.trainer:168 RmsProp 327 loss=200.640152 err=3.504934
I 2015-05-27 01:26:12 theanets.trainer:168 RmsProp 328 loss=200.161957 err=3.430669
I 2015-05-27 01:26:22 theanets.trainer:168 RmsProp 329 loss=199.792679 err=3.471355
I 2015-05-27 01:26:32 theanets.trainer:168 RmsProp 330 loss=199.019257 err=3.112125
I 2015-05-27 01:26:33 theanets.trainer:168 validation 33 loss=1085.578735 err=889.909363 *
I 2015-05-27 01:26:44 theanets.trainer:168 RmsProp 331 loss=199.685242 err=4.185108
I 2015-05-27 01:26:54 theanets.trainer:168 RmsProp 332 loss=198.442413 err=3.347691
I 2015-05-27 01:27:04 theanets.trainer:168 RmsProp 333 loss=197.937531 err=3.237099
I 2015-05-27 01:27:15 theanets.trainer:168 RmsProp 334 loss=197.849564 err=3.546932
I 2015-05-27 01:27:25 theanets.trainer:168 RmsProp 335 loss=197.413483 err=3.519954
I 2015-05-27 01:27:36 theanets.trainer:168 RmsProp 336 loss=197.075150 err=3.574728
I 2015-05-27 01:27:46 theanets.trainer:168 RmsProp 337 loss=196.655014 err=3.536737
I 2015-05-27 01:27:56 theanets.trainer:168 RmsProp 338 loss=196.150421 err=3.414228
I 2015-05-27 01:28:06 theanets.trainer:168 RmsProp 339 loss=195.897247 err=3.548220
I 2015-05-27 01:28:16 theanets.trainer:168 RmsProp 340 loss=195.437469 err=3.474685
I 2015-05-27 01:28:17 theanets.trainer:168 validation 34 loss=1082.182983 err=890.430481 *
I 2015-05-27 01:28:27 theanets.trainer:168 RmsProp 341 loss=195.028000 err=3.451708
I 2015-05-27 01:28:38 theanets.trainer:168 RmsProp 342 loss=194.487320 err=3.299418
I 2015-05-27 01:28:48 theanets.trainer:168 RmsProp 343 loss=194.342072 err=3.538764
I 2015-05-27 01:28:59 theanets.trainer:168 RmsProp 344 loss=193.644012 err=3.224031
I 2015-05-27 01:29:09 theanets.trainer:168 RmsProp 345 loss=193.383331 err=3.347363
I 2015-05-27 01:29:20 theanets.trainer:168 RmsProp 346 loss=192.991882 err=3.344358
I 2015-05-27 01:29:30 theanets.trainer:168 RmsProp 347 loss=192.605560 err=3.344748
I 2015-05-27 01:29:40 theanets.trainer:168 RmsProp 348 loss=192.082443 err=3.206443
I 2015-05-27 01:29:51 theanets.trainer:168 RmsProp 349 loss=191.996246 err=3.501500
I 2015-05-27 01:30:01 theanets.trainer:168 RmsProp 350 loss=191.672211 err=3.548094
I 2015-05-27 01:30:02 theanets.trainer:168 validation 35 loss=1085.689697 err=897.756653
I 2015-05-27 01:30:12 theanets.trainer:168 RmsProp 351 loss=191.219910 err=3.458515
I 2015-05-27 01:30:22 theanets.trainer:168 RmsProp 352 loss=190.862091 err=3.458311
I 2015-05-27 01:30:33 theanets.trainer:168 RmsProp 353 loss=190.439285 err=3.389833
I 2015-05-27 01:30:44 theanets.trainer:168 RmsProp 354 loss=190.251190 err=3.559080
I 2015-05-27 01:30:54 theanets.trainer:168 RmsProp 355 loss=189.818726 err=3.479300
I 2015-05-27 01:31:04 theanets.trainer:168 RmsProp 356 loss=189.353546 err=3.364239
I 2015-05-27 01:31:15 theanets.trainer:168 RmsProp 357 loss=188.935989 err=3.295875
I 2015-05-27 01:31:26 theanets.trainer:168 RmsProp 358 loss=188.748871 err=3.458595
I 2015-05-27 01:31:36 theanets.trainer:168 RmsProp 359 loss=188.214569 err=3.278541
I 2015-05-27 01:31:47 theanets.trainer:168 RmsProp 360 loss=187.978516 err=3.395842
I 2015-05-27 01:31:47 theanets.trainer:168 validation 36 loss=1058.132202 err=873.737488 *
I 2015-05-27 01:31:58 theanets.trainer:168 RmsProp 361 loss=187.615250 err=3.377767
I 2015-05-27 01:32:08 theanets.trainer:168 RmsProp 362 loss=186.874969 err=2.985122
I 2015-05-27 01:32:18 theanets.trainer:168 RmsProp 363 loss=188.154770 err=4.607045
I 2015-05-27 01:32:29 theanets.trainer:168 RmsProp 364 loss=186.589081 err=3.373859
I 2015-05-27 01:32:39 theanets.trainer:168 RmsProp 365 loss=185.951599 err=3.060512
I 2015-05-27 01:32:50 theanets.trainer:168 RmsProp 366 loss=185.953186 err=3.383765
I 2015-05-27 01:33:00 theanets.trainer:168 RmsProp 367 loss=185.487183 err=3.253241
I 2015-05-27 01:33:11 theanets.trainer:168 RmsProp 368 loss=185.001663 err=3.109736
I 2015-05-27 01:33:21 theanets.trainer:168 RmsProp 369 loss=185.101089 err=3.546726
I 2015-05-27 01:33:32 theanets.trainer:168 RmsProp 370 loss=184.625168 err=3.409050
I 2015-05-27 01:33:33 theanets.trainer:168 validation 37 loss=1051.739746 err=870.708984 *
I 2015-05-27 01:33:43 theanets.trainer:168 RmsProp 371 loss=183.898697 err=3.019843
I 2015-05-27 01:33:54 theanets.trainer:168 RmsProp 372 loss=184.585083 err=4.035838
I 2015-05-27 01:34:05 theanets.trainer:168 RmsProp 373 loss=183.547455 err=3.323953
I 2015-05-27 01:34:15 theanets.trainer:168 RmsProp 374 loss=183.019302 err=3.110842
I 2015-05-27 01:34:26 theanets.trainer:168 RmsProp 375 loss=182.985214 err=3.392542
I 2015-05-27 01:34:36 theanets.trainer:168 RmsProp 376 loss=183.020432 err=3.741931
I 2015-05-27 01:34:47 theanets.trainer:168 RmsProp 377 loss=181.939743 err=2.986618
I 2015-05-27 01:34:57 theanets.trainer:168 RmsProp 378 loss=181.939392 err=3.303154
I 2015-05-27 01:35:07 theanets.trainer:168 RmsProp 379 loss=181.648956 err=3.337545
I 2015-05-27 01:35:18 theanets.trainer:168 RmsProp 380 loss=181.162750 err=3.171207
I 2015-05-27 01:35:18 theanets.trainer:168 validation 38 loss=1064.216187 err=886.397583
I 2015-05-27 01:35:29 theanets.trainer:168 RmsProp 381 loss=181.106857 err=3.438471
I 2015-05-27 01:35:39 theanets.trainer:168 RmsProp 382 loss=180.665833 err=3.316955
I 2015-05-27 01:35:50 theanets.trainer:168 RmsProp 383 loss=180.224579 err=3.186809
I 2015-05-27 01:36:00 theanets.trainer:168 RmsProp 384 loss=179.976471 err=3.254808
I 2015-05-27 01:36:10 theanets.trainer:168 RmsProp 385 loss=179.750320 err=3.339674
I 2015-05-27 01:36:21 theanets.trainer:168 RmsProp 386 loss=179.176682 err=3.081141
I 2015-05-27 01:36:31 theanets.trainer:168 RmsProp 387 loss=179.098511 err=3.317275
I 2015-05-27 01:36:42 theanets.trainer:168 RmsProp 388 loss=178.817108 err=3.345448
I 2015-05-27 01:36:53 theanets.trainer:168 RmsProp 389 loss=178.734253 err=3.568249
I 2015-05-27 01:37:04 theanets.trainer:168 RmsProp 390 loss=178.120224 err=3.255464
I 2015-05-27 01:37:04 theanets.trainer:168 validation 39 loss=1055.778564 err=881.070923
I 2015-05-27 01:37:15 theanets.trainer:168 RmsProp 391 loss=178.024246 err=3.450928
I 2015-05-27 01:37:26 theanets.trainer:168 RmsProp 392 loss=177.641479 err=3.360032
I 2015-05-27 01:37:36 theanets.trainer:168 RmsProp 393 loss=177.088226 err=3.102385
I 2015-05-27 01:37:47 theanets.trainer:168 RmsProp 394 loss=177.217377 err=3.524663
I 2015-05-27 01:37:58 theanets.trainer:168 RmsProp 395 loss=176.657089 err=3.256630
I 2015-05-27 01:38:09 theanets.trainer:168 RmsProp 396 loss=176.417923 err=3.312079
I 2015-05-27 01:38:20 theanets.trainer:168 RmsProp 397 loss=176.042175 err=3.229826
I 2015-05-27 01:38:31 theanets.trainer:168 RmsProp 398 loss=175.582443 err=3.066732
I 2015-05-27 01:38:41 theanets.trainer:168 RmsProp 399 loss=175.539032 err=3.319555
I 2015-05-27 01:38:52 theanets.trainer:168 RmsProp 400 loss=175.218842 err=3.296512
I 2015-05-27 01:38:52 theanets.trainer:168 validation 40 loss=1042.231445 err=870.477173 *
I 2015-05-27 01:39:03 theanets.trainer:168 RmsProp 401 loss=174.689270 err=3.063812
I 2015-05-27 01:39:14 theanets.trainer:168 RmsProp 402 loss=174.699860 err=3.364654
I 2015-05-27 01:39:24 theanets.trainer:168 RmsProp 403 loss=174.232208 err=3.190916
I 2015-05-27 01:39:35 theanets.trainer:168 RmsProp 404 loss=173.992554 err=3.235608
I 2015-05-27 01:39:45 theanets.trainer:168 RmsProp 405 loss=173.684158 err=3.214350
I 2015-05-27 01:39:56 theanets.trainer:168 RmsProp 406 loss=173.345551 err=3.160997
I 2015-05-27 01:40:07 theanets.trainer:168 RmsProp 407 loss=173.165192 err=3.265483
I 2015-05-27 01:40:18 theanets.trainer:168 RmsProp 408 loss=173.103119 err=3.484992
I 2015-05-27 01:40:29 theanets.trainer:168 RmsProp 409 loss=172.571198 err=3.226149
I 2015-05-27 01:40:40 theanets.trainer:168 RmsProp 410 loss=172.130737 err=3.062117
I 2015-05-27 01:40:40 theanets.trainer:168 validation 41 loss=1037.951904 err=869.036133 *
I 2015-05-27 01:40:51 theanets.trainer:168 RmsProp 411 loss=172.075714 err=3.281900
I 2015-05-27 01:41:02 theanets.trainer:168 RmsProp 412 loss=171.728439 err=3.216497
I 2015-05-27 01:41:12 theanets.trainer:168 RmsProp 413 loss=171.412140 err=3.180500
I 2015-05-27 01:41:22 theanets.trainer:168 RmsProp 414 loss=171.312378 err=3.354933
I 2015-05-27 01:41:33 theanets.trainer:168 RmsProp 415 loss=170.683136 err=3.001728
I 2015-05-27 01:41:43 theanets.trainer:168 RmsProp 416 loss=170.631790 err=3.218629
I 2015-05-27 01:41:54 theanets.trainer:168 RmsProp 417 loss=170.228973 err=3.088431
I 2015-05-27 01:42:04 theanets.trainer:168 RmsProp 418 loss=170.087875 err=3.217826
I 2015-05-27 01:42:14 theanets.trainer:168 RmsProp 419 loss=169.806427 err=3.210018
I 2015-05-27 01:42:24 theanets.trainer:168 RmsProp 420 loss=169.658737 err=3.333773
I 2015-05-27 01:42:25 theanets.trainer:168 validation 42 loss=1036.422852 err=870.242981 *
I 2015-05-27 01:42:34 theanets.trainer:168 RmsProp 421 loss=169.096634 err=3.039719
I 2015-05-27 01:42:44 theanets.trainer:168 RmsProp 422 loss=169.095367 err=3.303786
I 2015-05-27 01:42:54 theanets.trainer:168 RmsProp 423 loss=169.049362 err=3.509792
I 2015-05-27 01:43:04 theanets.trainer:168 RmsProp 424 loss=168.079758 err=2.800276
I 2015-05-27 01:43:14 theanets.trainer:168 RmsProp 425 loss=168.471069 err=3.451825
I 2015-05-27 01:43:24 theanets.trainer:168 RmsProp 426 loss=168.018829 err=3.259399
I 2015-05-27 01:43:35 theanets.trainer:168 RmsProp 427 loss=167.497940 err=2.997783
I 2015-05-27 01:43:45 theanets.trainer:168 RmsProp 428 loss=167.285767 err=3.043096
I 2015-05-27 01:43:55 theanets.trainer:168 RmsProp 429 loss=167.556915 err=3.565865
I 2015-05-27 01:44:05 theanets.trainer:168 RmsProp 430 loss=166.768768 err=3.035326
I 2015-05-27 01:44:05 theanets.trainer:168 validation 43 loss=1036.399658 err=872.812805 *
I 2015-05-27 01:44:15 theanets.trainer:168 RmsProp 431 loss=166.390656 err=2.913629
I 2015-05-27 01:44:25 theanets.trainer:168 RmsProp 432 loss=166.640823 err=3.412651
I 2015-05-27 01:44:36 theanets.trainer:168 RmsProp 433 loss=165.787079 err=2.818614
I 2015-05-27 01:44:46 theanets.trainer:168 RmsProp 434 loss=166.232422 err=3.509518
I 2015-05-27 01:44:56 theanets.trainer:168 RmsProp 435 loss=165.685730 err=3.214177
I 2015-05-27 01:45:06 theanets.trainer:168 RmsProp 436 loss=165.229904 err=3.008556
I 2015-05-27 01:45:16 theanets.trainer:168 RmsProp 437 loss=165.048874 err=3.071930
I 2015-05-27 01:45:27 theanets.trainer:168 RmsProp 438 loss=164.968231 err=3.236382
I 2015-05-27 01:45:37 theanets.trainer:168 RmsProp 439 loss=164.690079 err=3.203988
I 2015-05-27 01:45:47 theanets.trainer:168 RmsProp 440 loss=164.473343 err=3.227372
I 2015-05-27 01:45:48 theanets.trainer:168 validation 44 loss=1027.628540 err=866.518005 *
I 2015-05-27 01:45:58 theanets.trainer:168 RmsProp 441 loss=163.640411 err=2.643480
I 2015-05-27 01:46:08 theanets.trainer:168 RmsProp 442 loss=164.465363 err=3.708776
I 2015-05-27 01:46:18 theanets.trainer:168 RmsProp 443 loss=163.536636 err=3.025680
I 2015-05-27 01:46:29 theanets.trainer:168 RmsProp 444 loss=163.320557 err=3.051799
I 2015-05-27 01:46:39 theanets.trainer:168 RmsProp 445 loss=162.768906 err=2.744481
I 2015-05-27 01:46:49 theanets.trainer:168 RmsProp 446 loss=163.583801 err=3.791637
I 2015-05-27 01:46:58 theanets.trainer:168 RmsProp 447 loss=162.499466 err=2.949973
I 2015-05-27 01:47:09 theanets.trainer:168 RmsProp 448 loss=162.439987 err=3.123634
I 2015-05-27 01:47:19 theanets.trainer:168 RmsProp 449 loss=162.165497 err=3.082740
I 2015-05-27 01:47:29 theanets.trainer:168 RmsProp 450 loss=162.007797 err=3.158893
I 2015-05-27 01:47:29 theanets.trainer:168 validation 45 loss=1045.948364 err=887.213318
I 2015-05-27 01:47:40 theanets.trainer:168 RmsProp 451 loss=161.893494 err=3.276641
I 2015-05-27 01:47:50 theanets.trainer:168 RmsProp 452 loss=161.436478 err=3.052760
I 2015-05-27 01:48:00 theanets.trainer:168 RmsProp 453 loss=160.610748 err=2.463861
I 2015-05-27 01:48:10 theanets.trainer:168 RmsProp 454 loss=162.174957 err=4.254727
I 2015-05-27 01:48:20 theanets.trainer:168 RmsProp 455 loss=160.743683 err=3.053957
I 2015-05-27 01:48:31 theanets.trainer:168 RmsProp 456 loss=160.027939 err=2.569275
I 2015-05-27 01:48:41 theanets.trainer:168 RmsProp 457 loss=160.787125 err=3.548895
I 2015-05-27 01:48:51 theanets.trainer:168 RmsProp 458 loss=160.079926 err=3.073045
I 2015-05-27 01:49:01 theanets.trainer:168 RmsProp 459 loss=159.743881 err=2.963612
I 2015-05-27 01:49:11 theanets.trainer:168 RmsProp 460 loss=159.661713 err=3.107307
I 2015-05-27 01:49:12 theanets.trainer:168 validation 46 loss=1027.008545 err=870.582520 *
I 2015-05-27 01:49:22 theanets.trainer:168 RmsProp 461 loss=159.450348 err=3.124651
I 2015-05-27 01:49:32 theanets.trainer:168 RmsProp 462 loss=159.226608 err=3.126680
I 2015-05-27 01:49:41 theanets.trainer:168 RmsProp 463 loss=159.111237 err=3.231194
I 2015-05-27 01:49:51 theanets.trainer:168 RmsProp 464 loss=158.718506 err=3.061949
I 2015-05-27 01:50:01 theanets.trainer:168 RmsProp 465 loss=158.730026 err=3.288454
I 2015-05-27 01:50:11 theanets.trainer:168 RmsProp 466 loss=158.095749 err=2.875822
I 2015-05-27 01:50:21 theanets.trainer:168 RmsProp 467 loss=157.985718 err=2.983351
I 2015-05-27 01:50:31 theanets.trainer:168 RmsProp 468 loss=157.974945 err=3.194622
I 2015-05-27 01:50:41 theanets.trainer:168 RmsProp 469 loss=157.571564 err=3.015176
I 2015-05-27 01:50:50 theanets.trainer:168 RmsProp 470 loss=157.788284 err=3.444279
I 2015-05-27 01:50:51 theanets.trainer:168 validation 47 loss=1020.647095 err=866.430847 *
I 2015-05-27 01:51:01 theanets.trainer:168 RmsProp 471 loss=156.904068 err=2.783090
I 2015-05-27 01:51:11 theanets.trainer:168 RmsProp 472 loss=156.941498 err=3.035178
I 2015-05-27 01:51:21 theanets.trainer:168 RmsProp 473 loss=156.837021 err=3.148204
I 2015-05-27 01:51:31 theanets.trainer:168 RmsProp 474 loss=156.338211 err=2.868002
I 2015-05-27 01:51:41 theanets.trainer:168 RmsProp 475 loss=156.453308 err=3.199216
I 2015-05-27 01:51:52 theanets.trainer:168 RmsProp 476 loss=155.701645 err=2.667010
I 2015-05-27 01:52:02 theanets.trainer:168 RmsProp 477 loss=156.346100 err=3.524676
I 2015-05-27 01:52:12 theanets.trainer:168 RmsProp 478 loss=155.542572 err=2.938667
I 2015-05-27 01:52:23 theanets.trainer:168 RmsProp 479 loss=155.536865 err=3.140496
I 2015-05-27 01:52:33 theanets.trainer:168 RmsProp 480 loss=155.110168 err=2.930583
I 2015-05-27 01:52:33 theanets.trainer:168 validation 48 loss=1015.698059 err=863.625122 *
I 2015-05-27 01:52:43 theanets.trainer:168 RmsProp 481 loss=155.101425 err=3.130701
I 2015-05-27 01:52:53 theanets.trainer:168 RmsProp 482 loss=154.702545 err=2.945845
I 2015-05-27 01:53:03 theanets.trainer:168 RmsProp 483 loss=154.100632 err=2.558453
I 2015-05-27 01:53:13 theanets.trainer:168 RmsProp 484 loss=155.027802 err=3.686738
I 2015-05-27 01:53:23 theanets.trainer:168 RmsProp 485 loss=154.084305 err=2.956769
I 2015-05-27 01:53:33 theanets.trainer:168 RmsProp 486 loss=153.987091 err=3.060551
I 2015-05-27 01:53:43 theanets.trainer:168 RmsProp 487 loss=153.987778 err=3.267560
I 2015-05-27 01:53:53 theanets.trainer:168 RmsProp 488 loss=153.445099 err=2.925959
I 2015-05-27 01:54:03 theanets.trainer:168 RmsProp 489 loss=153.498520 err=3.184448
I 2015-05-27 01:54:13 theanets.trainer:168 RmsProp 490 loss=153.105576 err=2.992515
I 2015-05-27 01:54:14 theanets.trainer:168 validation 49 loss=1011.554504 err=861.549133 *
I 2015-05-27 01:54:24 theanets.trainer:168 RmsProp 491 loss=152.810822 err=2.899751
I 2015-05-27 01:54:34 theanets.trainer:168 RmsProp 492 loss=152.529755 err=2.820615
I 2015-05-27 01:54:44 theanets.trainer:168 RmsProp 493 loss=152.906250 err=3.398553
I 2015-05-27 01:54:54 theanets.trainer:168 RmsProp 494 loss=151.984406 err=2.681601
I 2015-05-27 01:55:03 theanets.trainer:168 RmsProp 495 loss=152.162109 err=3.060600
I 2015-05-27 01:55:13 theanets.trainer:168 RmsProp 496 loss=151.945648 err=3.046460
I 2015-05-27 01:55:23 theanets.trainer:168 RmsProp 497 loss=151.811646 err=3.112421
I 2015-05-27 01:55:33 theanets.trainer:168 RmsProp 498 loss=151.762909 err=3.260832
I 2015-05-27 01:55:44 theanets.trainer:168 RmsProp 499 loss=151.162552 err=2.861715
I 2015-05-27 01:55:54 theanets.trainer:168 RmsProp 500 loss=151.259628 err=3.154139
I 2015-05-27 01:55:54 theanets.trainer:168 validation 50 loss=1010.722900 err=862.725769 *
I 2015-05-27 01:56:04 theanets.trainer:168 RmsProp 501 loss=150.694046 err=2.787294
I 2015-05-27 01:56:14 theanets.trainer:168 RmsProp 502 loss=150.875946 err=3.165637
I 2015-05-27 01:56:24 theanets.trainer:168 RmsProp 503 loss=150.483063 err=2.966721
I 2015-05-27 01:56:34 theanets.trainer:168 RmsProp 504 loss=150.142853 err=2.821506
I 2015-05-27 01:56:44 theanets.trainer:168 RmsProp 505 loss=150.302261 err=3.173839
I 2015-05-27 01:56:54 theanets.trainer:168 RmsProp 506 loss=150.265778 err=3.327222
I 2015-05-27 01:57:04 theanets.trainer:168 RmsProp 507 loss=149.690704 err=2.944407
I 2015-05-27 01:57:14 theanets.trainer:168 RmsProp 508 loss=149.562469 err=3.006202
I 2015-05-27 01:57:25 theanets.trainer:168 RmsProp 509 loss=149.348190 err=2.982565
I 2015-05-27 01:57:35 theanets.trainer:168 RmsProp 510 loss=149.198578 err=3.019226
I 2015-05-27 01:57:35 theanets.trainer:168 validation 51 loss=1009.109253 err=863.023560 *
I 2015-05-27 01:57:46 theanets.trainer:168 RmsProp 511 loss=148.919281 err=2.926533
I 2015-05-27 01:57:56 theanets.trainer:168 RmsProp 512 loss=148.677979 err=2.875235
I 2015-05-27 01:58:06 theanets.trainer:168 RmsProp 513 loss=148.632874 err=3.020964
I 2015-05-27 01:58:16 theanets.trainer:168 RmsProp 514 loss=148.249496 err=2.830380
I 2015-05-27 01:58:26 theanets.trainer:168 RmsProp 515 loss=148.316360 err=3.085110
I 2015-05-27 01:58:37 theanets.trainer:168 RmsProp 516 loss=147.834625 err=2.793214
I 2015-05-27 01:58:47 theanets.trainer:168 RmsProp 517 loss=148.353455 err=3.494792
I 2015-05-27 01:58:57 theanets.trainer:168 RmsProp 518 loss=147.550888 err=2.876465
I 2015-05-27 01:59:08 theanets.trainer:168 RmsProp 519 loss=147.225616 err=2.738346
I 2015-05-27 01:59:18 theanets.trainer:168 RmsProp 520 loss=147.614594 err=3.303824
I 2015-05-27 01:59:19 theanets.trainer:168 validation 52 loss=1021.262207 err=877.053040
I 2015-05-27 01:59:29 theanets.trainer:168 RmsProp 521 loss=146.694473 err=2.573555
I 2015-05-27 01:59:39 theanets.trainer:168 RmsProp 522 loss=147.279327 err=3.340129
I 2015-05-27 01:59:49 theanets.trainer:168 RmsProp 523 loss=146.929230 err=3.168804
I 2015-05-27 01:59:59 theanets.trainer:168 RmsProp 524 loss=146.263718 err=2.687546
I 2015-05-27 02:00:09 theanets.trainer:168 RmsProp 525 loss=146.385590 err=2.987093
I 2015-05-27 02:00:19 theanets.trainer:168 RmsProp 526 loss=146.213928 err=2.997910
I 2015-05-27 02:00:29 theanets.trainer:168 RmsProp 527 loss=145.930008 err=2.893779
I 2015-05-27 02:00:40 theanets.trainer:168 RmsProp 528 loss=146.030426 err=3.169761
I 2015-05-27 02:00:50 theanets.trainer:168 RmsProp 529 loss=145.740204 err=3.058891
I 2015-05-27 02:01:01 theanets.trainer:168 RmsProp 530 loss=145.442719 err=2.941551
I 2015-05-27 02:01:01 theanets.trainer:168 validation 53 loss=1008.251892 err=865.855408 *
I 2015-05-27 02:01:11 theanets.trainer:168 RmsProp 531 loss=145.181732 err=2.866742
I 2015-05-27 02:01:21 theanets.trainer:168 RmsProp 532 loss=145.379349 err=3.231984
I 2015-05-27 02:01:31 theanets.trainer:168 RmsProp 533 loss=145.096741 err=3.124537
I 2015-05-27 02:01:42 theanets.trainer:168 RmsProp 534 loss=144.667725 err=2.866507
I 2015-05-27 02:01:52 theanets.trainer:168 RmsProp 535 loss=144.720917 err=3.089992
I 2015-05-27 02:02:01 theanets.trainer:168 RmsProp 536 loss=144.454437 err=2.997870
I 2015-05-27 02:02:11 theanets.trainer:168 RmsProp 537 loss=143.793198 err=2.513154
I 2015-05-27 02:02:22 theanets.trainer:168 RmsProp 538 loss=144.817902 err=3.703824
I 2015-05-27 02:02:32 theanets.trainer:168 RmsProp 539 loss=143.575790 err=2.636516
I 2015-05-27 02:02:43 theanets.trainer:168 RmsProp 540 loss=143.837769 err=3.070051
I 2015-05-27 02:02:43 theanets.trainer:168 validation 54 loss=1013.226624 err=872.556458
I 2015-05-27 02:02:54 theanets.trainer:168 RmsProp 541 loss=143.410614 err=2.817309
I 2015-05-27 02:03:04 theanets.trainer:168 RmsProp 542 loss=143.350494 err=2.927898
I 2015-05-27 02:03:14 theanets.trainer:168 RmsProp 543 loss=143.091553 err=2.840930
I 2015-05-27 02:03:24 theanets.trainer:168 RmsProp 544 loss=143.180222 err=3.101763
I 2015-05-27 02:03:34 theanets.trainer:168 RmsProp 545 loss=143.160645 err=3.249257
I 2015-05-27 02:03:45 theanets.trainer:168 RmsProp 546 loss=142.008728 err=2.276745
I 2015-05-27 02:03:55 theanets.trainer:168 RmsProp 547 loss=143.316147 err=3.744229
I 2015-05-27 02:04:05 theanets.trainer:168 RmsProp 548 loss=142.129852 err=2.726781
I 2015-05-27 02:04:15 theanets.trainer:168 RmsProp 549 loss=142.275269 err=3.039038
I 2015-05-27 02:04:25 theanets.trainer:168 RmsProp 550 loss=142.530548 err=3.451985
I 2015-05-27 02:04:26 theanets.trainer:168 validation 55 loss=1016.319580 err=877.335144
I 2015-05-27 02:04:36 theanets.trainer:168 RmsProp 551 loss=141.903534 err=2.987603
I 2015-05-27 02:04:47 theanets.trainer:168 RmsProp 552 loss=141.571075 err=2.820239
I 2015-05-27 02:04:57 theanets.trainer:168 RmsProp 553 loss=141.633682 err=3.041309
I 2015-05-27 02:05:07 theanets.trainer:168 RmsProp 554 loss=141.123810 err=2.698584
I 2015-05-27 02:05:18 theanets.trainer:168 RmsProp 555 loss=141.321533 err=3.058359
I 2015-05-27 02:05:29 theanets.trainer:168 RmsProp 556 loss=141.230530 err=3.128123
I 2015-05-27 02:05:39 theanets.trainer:168 RmsProp 557 loss=140.862076 err=2.926133
I 2015-05-27 02:05:50 theanets.trainer:168 RmsProp 558 loss=140.482147 err=2.710174
I 2015-05-27 02:06:00 theanets.trainer:168 RmsProp 559 loss=140.239609 err=2.636337
I 2015-05-27 02:06:11 theanets.trainer:168 RmsProp 560 loss=140.552902 err=3.110908
I 2015-05-27 02:06:11 theanets.trainer:168 validation 56 loss=1002.309937 err=864.960449 *
I 2015-05-27 02:06:21 theanets.trainer:168 RmsProp 561 loss=140.158813 err=2.880475
I 2015-05-27 02:06:32 theanets.trainer:168 RmsProp 562 loss=139.948029 err=2.831997
I 2015-05-27 02:06:42 theanets.trainer:168 RmsProp 563 loss=140.008789 err=3.054725
I 2015-05-27 02:06:52 theanets.trainer:168 RmsProp 564 loss=140.149292 err=3.350407
I 2015-05-27 02:07:03 theanets.trainer:168 RmsProp 565 loss=139.259735 err=2.618853
I 2015-05-27 02:07:13 theanets.trainer:168 RmsProp 566 loss=139.342819 err=2.859850
I 2015-05-27 02:07:24 theanets.trainer:168 RmsProp 567 loss=139.324249 err=2.999663
I 2015-05-27 02:07:34 theanets.trainer:168 RmsProp 568 loss=138.976944 err=2.809396
I 2015-05-27 02:07:44 theanets.trainer:168 RmsProp 569 loss=139.203903 err=3.192187
I 2015-05-27 02:07:55 theanets.trainer:168 RmsProp 570 loss=138.823029 err=2.963368
I 2015-05-27 02:07:55 theanets.trainer:168 validation 57 loss=1001.159241 err=865.392212 *
I 2015-05-27 02:08:06 theanets.trainer:168 RmsProp 571 loss=138.598846 err=2.893756
I 2015-05-27 02:08:16 theanets.trainer:168 RmsProp 572 loss=138.498489 err=2.943683
I 2015-05-27 02:08:26 theanets.trainer:168 RmsProp 573 loss=138.281235 err=2.883061
I 2015-05-27 02:08:36 theanets.trainer:168 RmsProp 574 loss=137.805634 err=2.563851
I 2015-05-27 02:08:47 theanets.trainer:168 RmsProp 575 loss=138.392609 err=3.300958
I 2015-05-27 02:08:57 theanets.trainer:168 RmsProp 576 loss=137.664536 err=2.729757
I 2015-05-27 02:09:07 theanets.trainer:168 RmsProp 577 loss=137.377655 err=2.596498
I 2015-05-27 02:09:18 theanets.trainer:168 RmsProp 578 loss=137.852936 err=3.224919
I 2015-05-27 02:09:28 theanets.trainer:168 RmsProp 579 loss=137.352814 err=2.876654
I 2015-05-27 02:09:39 theanets.trainer:168 RmsProp 580 loss=137.234161 err=2.911691
I 2015-05-27 02:09:39 theanets.trainer:168 validation 58 loss=995.042297 err=860.798767 *
I 2015-05-27 02:09:49 theanets.trainer:168 RmsProp 581 loss=137.322388 err=3.147627
I 2015-05-27 02:09:59 theanets.trainer:168 RmsProp 582 loss=136.648254 err=2.625041
I 2015-05-27 02:10:09 theanets.trainer:168 RmsProp 583 loss=136.892059 err=3.016810
I 2015-05-27 02:10:19 theanets.trainer:168 RmsProp 584 loss=136.828094 err=3.099120
I 2015-05-27 02:10:29 theanets.trainer:168 RmsProp 585 loss=136.499222 err=2.919887
I 2015-05-27 02:10:39 theanets.trainer:168 RmsProp 586 loss=136.235397 err=2.799079
I 2015-05-27 02:10:49 theanets.trainer:168 RmsProp 587 loss=136.244141 err=2.953821
I 2015-05-27 02:11:00 theanets.trainer:168 RmsProp 588 loss=136.254425 err=3.108565
I 2015-05-27 02:11:10 theanets.trainer:168 RmsProp 589 loss=135.867111 err=2.866020
I 2015-05-27 02:11:20 theanets.trainer:168 RmsProp 590 loss=135.740845 err=2.886659
I 2015-05-27 02:11:21 theanets.trainer:168 validation 59 loss=1000.160217 err=867.386047
I 2015-05-27 02:11:31 theanets.trainer:168 RmsProp 591 loss=135.593536 err=2.885660
I 2015-05-27 02:11:41 theanets.trainer:168 RmsProp 592 loss=135.331528 err=2.767510
I 2015-05-27 02:11:51 theanets.trainer:168 RmsProp 593 loss=135.078506 err=2.658962
I 2015-05-27 02:12:02 theanets.trainer:168 RmsProp 594 loss=135.541458 err=3.262731
I 2015-05-27 02:12:12 theanets.trainer:168 RmsProp 595 loss=135.022675 err=2.886341
I 2015-05-27 02:12:22 theanets.trainer:168 RmsProp 596 loss=134.855942 err=2.864831
I 2015-05-27 02:12:32 theanets.trainer:168 RmsProp 597 loss=134.694138 err=2.854921
I 2015-05-27 02:12:43 theanets.trainer:168 RmsProp 598 loss=134.491913 err=2.795532
I 2015-05-27 02:12:53 theanets.trainer:168 RmsProp 599 loss=134.270676 err=2.724989
I 2015-05-27 02:13:04 theanets.trainer:168 RmsProp 600 loss=134.476761 err=3.065041
I 2015-05-27 02:13:04 theanets.trainer:168 validation 60 loss=1004.505676 err=873.176392
I 2015-05-27 02:13:14 theanets.trainer:168 RmsProp 601 loss=134.102097 err=2.836306
I 2015-05-27 02:13:25 theanets.trainer:168 RmsProp 602 loss=133.913681 err=2.787992
I 2015-05-27 02:13:35 theanets.trainer:168 RmsProp 603 loss=133.891754 err=2.905167
I 2015-05-27 02:13:45 theanets.trainer:168 RmsProp 604 loss=133.580963 err=2.737892
I 2015-05-27 02:13:56 theanets.trainer:168 RmsProp 605 loss=133.663361 err=2.960389
I 2015-05-27 02:14:06 theanets.trainer:168 RmsProp 606 loss=133.613968 err=3.053838
I 2015-05-27 02:14:16 theanets.trainer:168 RmsProp 607 loss=133.246063 err=2.824811
I 2015-05-27 02:14:26 theanets.trainer:168 RmsProp 608 loss=133.041290 err=2.760513
I 2015-05-27 02:14:36 theanets.trainer:168 RmsProp 609 loss=132.924637 err=2.781858
I 2015-05-27 02:14:46 theanets.trainer:168 RmsProp 610 loss=132.809235 err=2.803982
I 2015-05-27 02:14:47 theanets.trainer:168 validation 61 loss=1013.699829 err=883.778748
I 2015-05-27 02:14:57 theanets.trainer:168 RmsProp 611 loss=132.677536 err=2.814071
I 2015-05-27 02:15:07 theanets.trainer:168 RmsProp 612 loss=132.764709 err=3.034810
I 2015-05-27 02:15:17 theanets.trainer:168 RmsProp 613 loss=132.519623 err=2.929761
I 2015-05-27 02:15:27 theanets.trainer:168 RmsProp 614 loss=132.233017 err=2.781367
I 2015-05-27 02:15:37 theanets.trainer:168 RmsProp 615 loss=132.270172 err=2.950962
I 2015-05-27 02:15:47 theanets.trainer:168 RmsProp 616 loss=132.028168 err=2.846097
I 2015-05-27 02:15:56 theanets.trainer:168 RmsProp 617 loss=131.830643 err=2.781243
I 2015-05-27 02:16:05 theanets.trainer:168 RmsProp 618 loss=132.111176 err=3.194854
I 2015-05-27 02:16:14 theanets.trainer:168 RmsProp 619 loss=131.339264 err=2.561712
I 2015-05-27 02:16:22 theanets.trainer:168 RmsProp 620 loss=131.626633 err=2.980862
I 2015-05-27 02:16:22 theanets.trainer:168 validation 62 loss=1000.268372 err=871.697876
I 2015-05-27 02:16:30 theanets.trainer:168 RmsProp 621 loss=131.228760 err=2.720769
I 2015-05-27 02:16:38 theanets.trainer:168 RmsProp 622 loss=131.282974 err=2.908863
I 2015-05-27 02:16:46 theanets.trainer:168 RmsProp 623 loss=130.973724 err=2.731137
I 2015-05-27 02:16:54 theanets.trainer:168 RmsProp 624 loss=130.876236 err=2.769447
I 2015-05-27 02:17:02 theanets.trainer:168 RmsProp 625 loss=130.841888 err=2.869379
I 2015-05-27 02:17:10 theanets.trainer:168 RmsProp 626 loss=130.600250 err=2.758981
I 2015-05-27 02:17:18 theanets.trainer:168 RmsProp 627 loss=130.564621 err=2.857995
I 2015-05-27 02:17:26 theanets.trainer:168 RmsProp 628 loss=130.764648 err=3.186647
I 2015-05-27 02:17:34 theanets.trainer:168 RmsProp 629 loss=130.141953 err=2.699246
I 2015-05-27 02:17:42 theanets.trainer:168 RmsProp 630 loss=130.106522 err=2.795371
I 2015-05-27 02:17:42 theanets.trainer:168 validation 63 loss=1004.587952 err=877.351746
I 2015-05-27 02:17:42 theanets.trainer:252 patience elapsed!
I 2015-05-27 02:17:42 theanets.main:237 models_deep_post_code_sep/95136-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 02:17:42 theanets.graph:477 models_deep_post_code_sep/95136-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
