I 2015-05-26 22:05:11 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:11 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95125-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:11 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:11 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:11 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:11 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:11 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:11 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:11 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:11 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:11 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:11 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:11 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:29 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:04 theano.gof.compilelock:266 Waiting for existing lock by process '29907' (I am process '29956')
I 2015-05-26 22:08:04 theano.gof.compilelock:268 To manually release the lock, delete /localdisk/qyou/.theano/compiledir_Linux-3.19-fc20.x86_64-x86_64-with-fedora-20-Heisenbug-x86_64-2.7.5-64/lock_dir
I 2015-05-26 22:08:23 theanets.trainer:168 validation 0 loss=14393.487305 err=14151.416992 *
I 2015-05-26 22:08:57 theanets.trainer:168 RmsProp 1 loss=13226.373047 err=13132.858398
I 2015-05-26 22:09:34 theanets.trainer:168 RmsProp 2 loss=13266.295898 err=13247.940430
I 2015-05-26 22:10:11 theanets.trainer:168 RmsProp 3 loss=13155.477539 err=13144.140625
I 2015-05-26 22:10:47 theanets.trainer:168 RmsProp 4 loss=13049.053711 err=13026.313477
I 2015-05-26 22:11:24 theanets.trainer:168 RmsProp 5 loss=12462.332031 err=12415.178711
I 2015-05-26 22:12:01 theanets.trainer:168 RmsProp 6 loss=11146.062500 err=11080.362305
I 2015-05-26 22:12:38 theanets.trainer:168 RmsProp 7 loss=10346.946289 err=10262.230469
I 2015-05-26 22:13:14 theanets.trainer:168 RmsProp 8 loss=9777.600586 err=9679.060547
I 2015-05-26 22:13:52 theanets.trainer:168 RmsProp 9 loss=9281.237305 err=9172.313477
I 2015-05-26 22:14:30 theanets.trainer:168 RmsProp 10 loss=8678.877930 err=8554.325195
I 2015-05-26 22:14:31 theanets.trainer:168 validation 1 loss=7722.317871 err=7589.359375 *
I 2015-05-26 22:15:08 theanets.trainer:168 RmsProp 11 loss=8221.095703 err=8078.565918
I 2015-05-26 22:15:46 theanets.trainer:168 RmsProp 12 loss=7674.854492 err=7516.223145
I 2015-05-26 22:16:24 theanets.trainer:168 RmsProp 13 loss=7444.008301 err=7272.344727
I 2015-05-26 22:17:01 theanets.trainer:168 RmsProp 14 loss=7101.015625 err=6912.945801
I 2015-05-26 22:17:39 theanets.trainer:168 RmsProp 15 loss=6621.440918 err=6416.148438
I 2015-05-26 22:18:16 theanets.trainer:168 RmsProp 16 loss=6383.927246 err=6161.708984
I 2015-05-26 22:18:52 theanets.trainer:168 RmsProp 17 loss=6240.805664 err=6001.799316
I 2015-05-26 22:19:29 theanets.trainer:168 RmsProp 18 loss=6076.823242 err=5820.793945
I 2015-05-26 22:20:05 theanets.trainer:168 RmsProp 19 loss=5881.931152 err=5613.645996
I 2015-05-26 22:20:43 theanets.trainer:168 RmsProp 20 loss=5745.993164 err=5466.089355
I 2015-05-26 22:20:43 theanets.trainer:168 validation 2 loss=5118.523438 err=4833.155273 *
I 2015-05-26 22:21:20 theanets.trainer:168 RmsProp 21 loss=5576.041504 err=5284.715820
I 2015-05-26 22:21:57 theanets.trainer:168 RmsProp 22 loss=5336.995605 err=5032.904785
I 2015-05-26 22:22:34 theanets.trainer:168 RmsProp 23 loss=5168.801270 err=4850.106934
I 2015-05-26 22:23:11 theanets.trainer:168 RmsProp 24 loss=5070.436523 err=4737.286621
I 2015-05-26 22:23:47 theanets.trainer:168 RmsProp 25 loss=4986.299316 err=4641.088379
I 2015-05-26 22:24:23 theanets.trainer:168 RmsProp 26 loss=4869.336426 err=4515.067871
I 2015-05-26 22:25:00 theanets.trainer:168 RmsProp 27 loss=4761.706543 err=4396.030273
I 2015-05-26 22:25:37 theanets.trainer:168 RmsProp 28 loss=4599.485840 err=4225.459961
I 2015-05-26 22:26:14 theanets.trainer:168 RmsProp 29 loss=4475.461426 err=4091.232910
I 2015-05-26 22:26:52 theanets.trainer:168 RmsProp 30 loss=4412.075684 err=4017.000732
I 2015-05-26 22:26:53 theanets.trainer:168 validation 3 loss=4010.235352 err=3609.854248 *
I 2015-05-26 22:27:29 theanets.trainer:168 RmsProp 31 loss=4334.883301 err=3928.637207
I 2015-05-26 22:28:06 theanets.trainer:168 RmsProp 32 loss=4230.208984 err=3813.095215
I 2015-05-26 22:28:44 theanets.trainer:168 RmsProp 33 loss=4104.244141 err=3676.670166
I 2015-05-26 22:29:22 theanets.trainer:168 RmsProp 34 loss=4110.322754 err=3673.636230
I 2015-05-26 22:30:00 theanets.trainer:168 RmsProp 35 loss=4022.119385 err=3576.111084
I 2015-05-26 22:30:38 theanets.trainer:168 RmsProp 36 loss=3928.464600 err=3474.852051
I 2015-05-26 22:31:16 theanets.trainer:168 RmsProp 37 loss=3894.483398 err=3432.165283
I 2015-05-26 22:31:53 theanets.trainer:168 RmsProp 38 loss=3799.028809 err=3328.399658
I 2015-05-26 22:32:31 theanets.trainer:168 RmsProp 39 loss=3738.926270 err=3261.705811
I 2015-05-26 22:33:08 theanets.trainer:168 RmsProp 40 loss=3664.857910 err=3177.828857
I 2015-05-26 22:33:09 theanets.trainer:168 validation 4 loss=3648.198486 err=3156.532471 *
I 2015-05-26 22:33:46 theanets.trainer:168 RmsProp 41 loss=3596.479736 err=3100.989990
I 2015-05-26 22:34:22 theanets.trainer:168 RmsProp 42 loss=3567.791992 err=3061.885742
I 2015-05-26 22:34:59 theanets.trainer:168 RmsProp 43 loss=3466.028809 err=2952.801514
I 2015-05-26 22:35:36 theanets.trainer:168 RmsProp 44 loss=3422.212158 err=2902.385986
I 2015-05-26 22:36:12 theanets.trainer:168 RmsProp 45 loss=3383.927002 err=2858.176514
I 2015-05-26 22:36:48 theanets.trainer:168 RmsProp 46 loss=3311.510742 err=2779.933594
I 2015-05-26 22:37:25 theanets.trainer:168 RmsProp 47 loss=3265.064941 err=2728.150879
I 2015-05-26 22:38:01 theanets.trainer:168 RmsProp 48 loss=3269.430420 err=2725.390625
I 2015-05-26 22:38:38 theanets.trainer:168 RmsProp 49 loss=3204.661133 err=2654.365723
I 2015-05-26 22:39:15 theanets.trainer:168 RmsProp 50 loss=3158.057617 err=2601.848145
I 2015-05-26 22:39:15 theanets.trainer:168 validation 5 loss=3343.871094 err=2784.969482 *
I 2015-05-26 22:39:52 theanets.trainer:168 RmsProp 51 loss=3144.271973 err=2581.699219
I 2015-05-26 22:40:28 theanets.trainer:168 RmsProp 52 loss=3164.377441 err=2589.020264
I 2015-05-26 22:41:05 theanets.trainer:168 RmsProp 53 loss=3109.359375 err=2528.698486
I 2015-05-26 22:41:41 theanets.trainer:168 RmsProp 54 loss=3192.856689 err=2606.742920
I 2015-05-26 22:42:18 theanets.trainer:168 RmsProp 55 loss=3371.972168 err=2771.586670
I 2015-05-26 22:42:55 theanets.trainer:168 RmsProp 56 loss=3305.759277 err=2693.299316
I 2015-05-26 22:43:32 theanets.trainer:168 RmsProp 57 loss=3185.645752 err=2569.610596
I 2015-05-26 22:44:09 theanets.trainer:168 RmsProp 58 loss=3168.912842 err=2546.553223
I 2015-05-26 22:44:47 theanets.trainer:168 RmsProp 59 loss=3034.758301 err=2412.959961
I 2015-05-26 22:45:24 theanets.trainer:168 RmsProp 60 loss=2968.945557 err=2348.031006
I 2015-05-26 22:45:25 theanets.trainer:168 validation 6 loss=3486.246094 err=2863.984131
I 2015-05-26 22:46:02 theanets.trainer:168 RmsProp 61 loss=2961.974854 err=2336.216064
I 2015-05-26 22:46:37 theanets.trainer:168 RmsProp 62 loss=2949.690674 err=2318.767090
I 2015-05-26 22:47:14 theanets.trainer:168 RmsProp 63 loss=2875.055664 err=2239.895752
I 2015-05-26 22:47:51 theanets.trainer:168 RmsProp 64 loss=2792.921387 err=2156.274658
I 2015-05-26 22:48:27 theanets.trainer:168 RmsProp 65 loss=2757.893311 err=2118.993408
I 2015-05-26 22:49:03 theanets.trainer:168 RmsProp 66 loss=2772.605713 err=2127.748047
I 2015-05-26 22:49:39 theanets.trainer:168 RmsProp 67 loss=2812.625244 err=2163.337891
I 2015-05-26 22:50:16 theanets.trainer:168 RmsProp 68 loss=2975.674805 err=2315.599365
I 2015-05-26 22:50:53 theanets.trainer:168 RmsProp 69 loss=2910.406982 err=2246.109131
I 2015-05-26 22:51:30 theanets.trainer:168 RmsProp 70 loss=2768.910156 err=2108.986084
I 2015-05-26 22:51:31 theanets.trainer:168 validation 7 loss=3566.070312 err=2906.167236
I 2015-05-26 22:52:08 theanets.trainer:168 RmsProp 71 loss=2660.390381 err=2000.472412
I 2015-05-26 22:52:44 theanets.trainer:168 RmsProp 72 loss=2630.936035 err=1969.730835
I 2015-05-26 22:53:22 theanets.trainer:168 RmsProp 73 loss=2553.983643 err=1891.541016
I 2015-05-26 22:54:01 theanets.trainer:168 RmsProp 74 loss=2554.719238 err=1891.439575
I 2015-05-26 22:54:39 theanets.trainer:168 RmsProp 75 loss=2498.796143 err=1834.337524
I 2015-05-26 22:55:16 theanets.trainer:168 RmsProp 76 loss=2490.555908 err=1823.675415
I 2015-05-26 22:55:52 theanets.trainer:168 RmsProp 77 loss=2475.869629 err=1805.224609
I 2015-05-26 22:56:29 theanets.trainer:168 RmsProp 78 loss=2416.408936 err=1744.712280
I 2015-05-26 22:57:07 theanets.trainer:168 RmsProp 79 loss=2396.385498 err=1725.537231
I 2015-05-26 22:57:45 theanets.trainer:168 RmsProp 80 loss=2386.748291 err=1714.328613
I 2015-05-26 22:57:46 theanets.trainer:168 validation 8 loss=3385.662842 err=2711.986084
I 2015-05-26 22:58:24 theanets.trainer:168 RmsProp 81 loss=2407.825684 err=1732.577515
I 2015-05-26 22:59:01 theanets.trainer:168 RmsProp 82 loss=2319.043457 err=1642.212769
I 2015-05-26 22:59:38 theanets.trainer:168 RmsProp 83 loss=2344.786377 err=1668.032959
I 2015-05-26 23:00:13 theanets.trainer:168 RmsProp 84 loss=2312.354492 err=1633.927246
I 2015-05-26 23:00:48 theanets.trainer:168 RmsProp 85 loss=2285.066650 err=1605.467651
I 2015-05-26 23:01:26 theanets.trainer:168 RmsProp 86 loss=2291.422363 err=1610.855103
I 2015-05-26 23:02:03 theanets.trainer:168 RmsProp 87 loss=2421.127197 err=1734.057739
I 2015-05-26 23:02:40 theanets.trainer:168 RmsProp 88 loss=2365.624023 err=1673.430298
I 2015-05-26 23:03:19 theanets.trainer:168 RmsProp 89 loss=2343.874756 err=1651.212646
I 2015-05-26 23:03:56 theanets.trainer:168 RmsProp 90 loss=2355.291992 err=1659.189941
I 2015-05-26 23:03:57 theanets.trainer:168 validation 9 loss=3263.364258 err=2566.673096 *
I 2015-05-26 23:04:34 theanets.trainer:168 RmsProp 91 loss=2279.774658 err=1583.325684
I 2015-05-26 23:05:10 theanets.trainer:168 RmsProp 92 loss=2240.513184 err=1544.006226
I 2015-05-26 23:05:47 theanets.trainer:168 RmsProp 93 loss=2196.358643 err=1500.175537
I 2015-05-26 23:06:22 theanets.trainer:168 RmsProp 94 loss=2225.937988 err=1528.633423
I 2015-05-26 23:06:59 theanets.trainer:168 RmsProp 95 loss=2268.081787 err=1566.368774
I 2015-05-26 23:07:37 theanets.trainer:168 RmsProp 96 loss=2311.805420 err=1606.232422
I 2015-05-26 23:08:14 theanets.trainer:168 RmsProp 97 loss=2358.635010 err=1647.409302
I 2015-05-26 23:08:52 theanets.trainer:168 RmsProp 98 loss=2248.138916 err=1536.770996
I 2015-05-26 23:09:30 theanets.trainer:168 RmsProp 99 loss=2187.152832 err=1477.801514
I 2015-05-26 23:10:07 theanets.trainer:168 RmsProp 100 loss=2162.482178 err=1453.292358
I 2015-05-26 23:10:07 theanets.trainer:168 validation 10 loss=3227.464111 err=2517.691895 *
I 2015-05-26 23:10:43 theanets.trainer:168 RmsProp 101 loss=2142.636475 err=1432.896851
I 2015-05-26 23:11:19 theanets.trainer:168 RmsProp 102 loss=2119.543457 err=1409.744019
I 2015-05-26 23:11:55 theanets.trainer:168 RmsProp 103 loss=2115.275879 err=1404.585449
I 2015-05-26 23:12:31 theanets.trainer:168 RmsProp 104 loss=2097.903076 err=1387.517456
I 2015-05-26 23:13:08 theanets.trainer:168 RmsProp 105 loss=2046.548828 err=1336.859253
I 2015-05-26 23:13:45 theanets.trainer:168 RmsProp 106 loss=2013.209473 err=1304.685669
I 2015-05-26 23:14:23 theanets.trainer:168 RmsProp 107 loss=2030.021729 err=1320.560425
I 2015-05-26 23:15:00 theanets.trainer:168 RmsProp 108 loss=2046.037109 err=1333.456299
I 2015-05-26 23:15:37 theanets.trainer:168 RmsProp 109 loss=2027.192261 err=1313.954346
I 2015-05-26 23:16:14 theanets.trainer:168 RmsProp 110 loss=2026.660645 err=1311.594116
I 2015-05-26 23:16:15 theanets.trainer:168 validation 11 loss=2923.721436 err=2208.165283 *
I 2015-05-26 23:16:52 theanets.trainer:168 RmsProp 111 loss=2023.280640 err=1306.884033
I 2015-05-26 23:17:28 theanets.trainer:168 RmsProp 112 loss=2045.835815 err=1326.613281
I 2015-05-26 23:18:04 theanets.trainer:168 RmsProp 113 loss=2056.079590 err=1333.415649
I 2015-05-26 23:18:39 theanets.trainer:168 RmsProp 114 loss=2041.403076 err=1316.619507
I 2015-05-26 23:19:15 theanets.trainer:168 RmsProp 115 loss=2120.997803 err=1392.402588
I 2015-05-26 23:19:50 theanets.trainer:168 RmsProp 116 loss=2119.704834 err=1386.521118
I 2015-05-26 23:20:26 theanets.trainer:168 RmsProp 117 loss=2013.670532 err=1281.803101
I 2015-05-26 23:21:01 theanets.trainer:168 RmsProp 118 loss=1992.989014 err=1262.655518
I 2015-05-26 23:21:37 theanets.trainer:168 RmsProp 119 loss=1980.004150 err=1250.326904
I 2015-05-26 23:22:13 theanets.trainer:168 RmsProp 120 loss=1934.366943 err=1206.619263
I 2015-05-26 23:22:14 theanets.trainer:168 validation 12 loss=3068.927979 err=2341.305176
I 2015-05-26 23:22:50 theanets.trainer:168 RmsProp 121 loss=1926.572510 err=1199.036499
I 2015-05-26 23:23:28 theanets.trainer:168 RmsProp 122 loss=1944.215210 err=1215.866333
I 2015-05-26 23:24:05 theanets.trainer:168 RmsProp 123 loss=1947.687744 err=1217.857300
I 2015-05-26 23:24:42 theanets.trainer:168 RmsProp 124 loss=1902.056519 err=1173.572998
I 2015-05-26 23:25:19 theanets.trainer:168 RmsProp 125 loss=1925.711182 err=1196.627563
I 2015-05-26 23:25:55 theanets.trainer:168 RmsProp 126 loss=1917.455200 err=1187.139526
I 2015-05-26 23:26:32 theanets.trainer:168 RmsProp 127 loss=1933.630615 err=1200.636230
I 2015-05-26 23:27:08 theanets.trainer:168 RmsProp 128 loss=1894.496460 err=1160.760254
I 2015-05-26 23:27:44 theanets.trainer:168 RmsProp 129 loss=1895.172241 err=1161.616577
I 2015-05-26 23:28:21 theanets.trainer:168 RmsProp 130 loss=1881.206787 err=1146.546143
I 2015-05-26 23:28:22 theanets.trainer:168 validation 13 loss=2981.852295 err=2246.912842
I 2015-05-26 23:28:59 theanets.trainer:168 RmsProp 131 loss=1891.433350 err=1156.542236
I 2015-05-26 23:29:36 theanets.trainer:168 RmsProp 132 loss=2001.753540 err=1260.504761
I 2015-05-26 23:30:13 theanets.trainer:168 RmsProp 133 loss=1939.212280 err=1193.173828
I 2015-05-26 23:30:49 theanets.trainer:168 RmsProp 134 loss=1852.555542 err=1111.640625
I 2015-05-26 23:31:26 theanets.trainer:168 RmsProp 135 loss=1817.966064 err=1080.860840
I 2015-05-26 23:32:03 theanets.trainer:168 RmsProp 136 loss=1825.473145 err=1089.683350
I 2015-05-26 23:32:39 theanets.trainer:168 RmsProp 137 loss=1823.272949 err=1087.293213
I 2015-05-26 23:33:15 theanets.trainer:168 RmsProp 138 loss=1813.020874 err=1078.275879
I 2015-05-26 23:33:52 theanets.trainer:168 RmsProp 139 loss=1809.922974 err=1074.834229
I 2015-05-26 23:34:29 theanets.trainer:168 RmsProp 140 loss=1812.834351 err=1077.391235
I 2015-05-26 23:34:29 theanets.trainer:168 validation 14 loss=2801.576416 err=2065.275635 *
I 2015-05-26 23:35:06 theanets.trainer:168 RmsProp 141 loss=1837.996094 err=1099.100342
I 2015-05-26 23:35:42 theanets.trainer:168 RmsProp 142 loss=1789.999756 err=1051.323975
I 2015-05-26 23:36:18 theanets.trainer:168 RmsProp 143 loss=1805.493408 err=1066.090576
I 2015-05-26 23:36:54 theanets.trainer:168 RmsProp 144 loss=1797.503784 err=1057.778931
I 2015-05-26 23:37:31 theanets.trainer:168 RmsProp 145 loss=1742.917725 err=1005.515076
I 2015-05-26 23:38:08 theanets.trainer:168 RmsProp 146 loss=1757.032471 err=1021.836914
I 2015-05-26 23:38:46 theanets.trainer:168 RmsProp 147 loss=1818.557007 err=1079.057373
I 2015-05-26 23:39:22 theanets.trainer:168 RmsProp 148 loss=1797.758423 err=1056.190552
I 2015-05-26 23:39:58 theanets.trainer:168 RmsProp 149 loss=1741.772949 err=1000.756409
I 2015-05-26 23:40:34 theanets.trainer:168 RmsProp 150 loss=1718.847290 err=980.671082
I 2015-05-26 23:40:35 theanets.trainer:168 validation 15 loss=2775.865479 err=2038.476929 *
I 2015-05-26 23:41:12 theanets.trainer:168 RmsProp 151 loss=1693.193481 err=956.774231
I 2015-05-26 23:41:50 theanets.trainer:168 RmsProp 152 loss=1692.257446 err=956.491516
I 2015-05-26 23:42:27 theanets.trainer:168 RmsProp 153 loss=1817.103027 err=1077.007568
I 2015-05-26 23:43:04 theanets.trainer:168 RmsProp 154 loss=1958.848145 err=1207.946655
I 2015-05-26 23:43:41 theanets.trainer:168 RmsProp 155 loss=2016.953491 err=1260.416016
I 2015-05-26 23:44:18 theanets.trainer:168 RmsProp 156 loss=2786.161865 err=2015.784058
I 2015-05-26 23:44:54 theanets.trainer:168 RmsProp 157 loss=3288.968262 err=2489.395752
I 2015-05-26 23:45:31 theanets.trainer:168 RmsProp 158 loss=3069.573730 err=2252.591064
I 2015-05-26 23:46:08 theanets.trainer:168 RmsProp 159 loss=2688.030029 err=1871.497681
I 2015-05-26 23:46:43 theanets.trainer:168 RmsProp 160 loss=2502.963623 err=1694.370728
I 2015-05-26 23:46:44 theanets.trainer:168 validation 16 loss=3542.210938 err=2738.795898
I 2015-05-26 23:47:19 theanets.trainer:168 RmsProp 161 loss=2407.140137 err=1606.663818
I 2015-05-26 23:47:53 theanets.trainer:168 RmsProp 162 loss=2483.190186 err=1680.515869
I 2015-05-26 23:48:27 theanets.trainer:168 RmsProp 163 loss=2377.985596 err=1574.631226
I 2015-05-26 23:49:02 theanets.trainer:168 RmsProp 164 loss=2354.712646 err=1551.669434
I 2015-05-26 23:49:38 theanets.trainer:168 RmsProp 165 loss=2227.595459 err=1428.494019
I 2015-05-26 23:50:14 theanets.trainer:168 RmsProp 166 loss=2221.953369 err=1424.313232
I 2015-05-26 23:50:50 theanets.trainer:168 RmsProp 167 loss=2179.408936 err=1382.425049
I 2015-05-26 23:51:25 theanets.trainer:168 RmsProp 168 loss=2123.712402 err=1329.554321
I 2015-05-26 23:51:59 theanets.trainer:168 RmsProp 169 loss=2254.433838 err=1456.426514
I 2015-05-26 23:52:34 theanets.trainer:168 RmsProp 170 loss=2310.868652 err=1503.554077
I 2015-05-26 23:52:35 theanets.trainer:168 validation 17 loss=3072.593750 err=2263.833496
I 2015-05-26 23:53:10 theanets.trainer:168 RmsProp 171 loss=2255.820068 err=1444.925537
I 2015-05-26 23:53:45 theanets.trainer:168 RmsProp 172 loss=2174.129150 err=1362.395996
I 2015-05-26 23:54:21 theanets.trainer:168 RmsProp 173 loss=2135.383301 err=1325.521118
I 2015-05-26 23:54:56 theanets.trainer:168 RmsProp 174 loss=2128.128418 err=1315.763550
I 2015-05-26 23:55:33 theanets.trainer:168 RmsProp 175 loss=2128.977295 err=1316.667603
I 2015-05-26 23:56:08 theanets.trainer:168 RmsProp 176 loss=2113.358154 err=1299.963379
I 2015-05-26 23:56:44 theanets.trainer:168 RmsProp 177 loss=2092.993896 err=1279.412842
I 2015-05-26 23:57:19 theanets.trainer:168 RmsProp 178 loss=2096.242920 err=1281.334473
I 2015-05-26 23:57:54 theanets.trainer:168 RmsProp 179 loss=2031.157471 err=1214.497314
I 2015-05-26 23:58:29 theanets.trainer:168 RmsProp 180 loss=1998.466309 err=1183.349609
I 2015-05-26 23:58:30 theanets.trainer:168 validation 18 loss=2863.971924 err=2049.021240
I 2015-05-26 23:59:05 theanets.trainer:168 RmsProp 181 loss=2002.845581 err=1187.949463
I 2015-05-26 23:59:42 theanets.trainer:168 RmsProp 182 loss=2056.731934 err=1240.609497
I 2015-05-27 00:00:18 theanets.trainer:168 RmsProp 183 loss=2055.408691 err=1237.488403
I 2015-05-27 00:00:54 theanets.trainer:168 RmsProp 184 loss=2026.884766 err=1206.495483
I 2015-05-27 00:01:30 theanets.trainer:168 RmsProp 185 loss=2079.118896 err=1257.068115
I 2015-05-27 00:02:06 theanets.trainer:168 RmsProp 186 loss=2092.762451 err=1268.744751
I 2015-05-27 00:02:41 theanets.trainer:168 RmsProp 187 loss=2041.653564 err=1217.162842
I 2015-05-27 00:03:17 theanets.trainer:168 RmsProp 188 loss=2039.444458 err=1213.926025
I 2015-05-27 00:03:52 theanets.trainer:168 RmsProp 189 loss=2088.887207 err=1260.770996
I 2015-05-27 00:04:27 theanets.trainer:168 RmsProp 190 loss=2061.316650 err=1232.186401
I 2015-05-27 00:04:28 theanets.trainer:168 validation 19 loss=3053.897705 err=2223.317139
I 2015-05-27 00:05:03 theanets.trainer:168 RmsProp 191 loss=2127.630615 err=1294.259399
I 2015-05-27 00:05:38 theanets.trainer:168 RmsProp 192 loss=2178.548828 err=1340.770996
I 2015-05-27 00:06:13 theanets.trainer:168 RmsProp 193 loss=2120.052734 err=1279.296021
I 2015-05-27 00:06:49 theanets.trainer:168 RmsProp 194 loss=2053.868164 err=1213.933105
I 2015-05-27 00:07:25 theanets.trainer:168 RmsProp 195 loss=2011.732178 err=1170.949585
I 2015-05-27 00:08:01 theanets.trainer:168 RmsProp 196 loss=1966.072754 err=1127.274170
I 2015-05-27 00:08:36 theanets.trainer:168 RmsProp 197 loss=1943.816162 err=1107.310303
I 2015-05-27 00:09:11 theanets.trainer:168 RmsProp 198 loss=1994.687622 err=1155.286621
I 2015-05-27 00:09:47 theanets.trainer:168 RmsProp 199 loss=1980.092041 err=1138.775024
I 2015-05-27 00:10:22 theanets.trainer:168 RmsProp 200 loss=2049.604980 err=1206.818970
I 2015-05-27 00:10:23 theanets.trainer:168 validation 20 loss=2796.235107 err=1949.356079
I 2015-05-27 00:10:23 theanets.trainer:252 patience elapsed!
I 2015-05-27 00:10:23 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 00:10:23 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 00:10:23 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 00:10:23 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 00:10:23 theanets.main:89 --batch_size = 1024
I 2015-05-27 00:10:23 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 00:10:23 theanets.main:89 --hidden_l1 = None
I 2015-05-27 00:10:23 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 00:10:23 theanets.main:89 --train_batches = 10
I 2015-05-27 00:10:23 theanets.main:89 --valid_batches = 2
I 2015-05-27 00:10:23 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 00:10:23 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 00:10:23 theanets.trainer:134 compiling evaluation function
I 2015-05-27 00:10:33 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 00:12:12 theanets.trainer:168 validation 0 loss=3859.998047 err=3122.609619 *
I 2015-05-27 00:12:23 theanets.trainer:168 RmsProp 1 loss=1540.483643 err=806.341431
I 2015-05-27 00:12:33 theanets.trainer:168 RmsProp 2 loss=1384.417114 err=653.506409
I 2015-05-27 00:12:44 theanets.trainer:168 RmsProp 3 loss=1305.107666 err=576.500183
I 2015-05-27 00:12:54 theanets.trainer:168 RmsProp 4 loss=1260.421631 err=533.783936
I 2015-05-27 00:13:05 theanets.trainer:168 RmsProp 5 loss=1216.538818 err=491.765045
I 2015-05-27 00:13:15 theanets.trainer:168 RmsProp 6 loss=1174.477661 err=451.637848
I 2015-05-27 00:13:25 theanets.trainer:168 RmsProp 7 loss=1136.060791 err=415.311859
I 2015-05-27 00:13:36 theanets.trainer:168 RmsProp 8 loss=1088.516113 err=370.023651
I 2015-05-27 00:13:46 theanets.trainer:168 RmsProp 9 loss=1070.279541 err=354.229156
I 2015-05-27 00:13:57 theanets.trainer:168 RmsProp 10 loss=1039.186768 err=325.630127
I 2015-05-27 00:13:57 theanets.trainer:168 validation 1 loss=3236.081299 err=2523.928467 *
I 2015-05-27 00:14:07 theanets.trainer:168 RmsProp 11 loss=1012.623169 err=301.644257
I 2015-05-27 00:14:18 theanets.trainer:168 RmsProp 12 loss=993.642456 err=285.335632
I 2015-05-27 00:14:28 theanets.trainer:168 RmsProp 13 loss=976.596375 err=271.033173
I 2015-05-27 00:14:39 theanets.trainer:168 RmsProp 14 loss=962.347351 err=259.496826
I 2015-05-27 00:14:49 theanets.trainer:168 RmsProp 15 loss=942.086060 err=241.854584
I 2015-05-27 00:14:59 theanets.trainer:168 RmsProp 16 loss=926.531250 err=228.852173
I 2015-05-27 00:15:09 theanets.trainer:168 RmsProp 17 loss=911.038879 err=215.991409
I 2015-05-27 00:15:19 theanets.trainer:168 RmsProp 18 loss=896.141602 err=203.825348
I 2015-05-27 00:15:29 theanets.trainer:168 RmsProp 19 loss=880.184937 err=190.662811
I 2015-05-27 00:15:39 theanets.trainer:168 RmsProp 20 loss=872.490234 err=185.819595
I 2015-05-27 00:15:40 theanets.trainer:168 validation 2 loss=3138.461914 err=2453.397461 *
I 2015-05-27 00:15:50 theanets.trainer:168 RmsProp 21 loss=861.600891 err=177.832672
I 2015-05-27 00:16:00 theanets.trainer:168 RmsProp 22 loss=851.817749 err=170.821899
I 2015-05-27 00:16:10 theanets.trainer:168 RmsProp 23 loss=842.615845 err=164.266342
I 2015-05-27 00:16:20 theanets.trainer:168 RmsProp 24 loss=830.556030 err=154.856842
I 2015-05-27 00:16:30 theanets.trainer:168 RmsProp 25 loss=821.261230 err=148.353104
I 2015-05-27 00:16:41 theanets.trainer:168 RmsProp 26 loss=817.306763 err=147.318268
I 2015-05-27 00:16:51 theanets.trainer:168 RmsProp 27 loss=804.846802 err=137.830902
I 2015-05-27 00:17:01 theanets.trainer:168 RmsProp 28 loss=794.226990 err=130.082825
I 2015-05-27 00:17:11 theanets.trainer:168 RmsProp 29 loss=786.977356 err=125.629845
I 2015-05-27 00:17:22 theanets.trainer:168 RmsProp 30 loss=780.130249 err=121.603859
I 2015-05-27 00:17:22 theanets.trainer:168 validation 3 loss=3100.238770 err=2443.232178 *
I 2015-05-27 00:17:32 theanets.trainer:168 RmsProp 31 loss=771.201782 err=115.452774
I 2015-05-27 00:17:43 theanets.trainer:168 RmsProp 32 loss=767.360718 err=114.378922
I 2015-05-27 00:17:53 theanets.trainer:168 RmsProp 33 loss=761.176392 err=110.950157
I 2015-05-27 00:18:03 theanets.trainer:168 RmsProp 34 loss=753.512085 err=106.018700
I 2015-05-27 00:18:13 theanets.trainer:168 RmsProp 35 loss=749.810181 err=105.012352
I 2015-05-27 00:18:24 theanets.trainer:168 RmsProp 36 loss=744.940308 err=102.904739
I 2015-05-27 00:18:34 theanets.trainer:168 RmsProp 37 loss=736.761353 err=97.451927
I 2015-05-27 00:18:44 theanets.trainer:168 RmsProp 38 loss=732.145203 err=95.500801
I 2015-05-27 00:18:54 theanets.trainer:168 RmsProp 39 loss=726.764160 err=92.835373
I 2015-05-27 00:19:04 theanets.trainer:168 RmsProp 40 loss=720.471130 err=89.249931
I 2015-05-27 00:19:05 theanets.trainer:168 validation 4 loss=3051.511719 err=2421.754639 *
I 2015-05-27 00:19:15 theanets.trainer:168 RmsProp 41 loss=718.574402 err=90.034714
I 2015-05-27 00:19:25 theanets.trainer:168 RmsProp 42 loss=710.081909 err=84.167435
I 2015-05-27 00:19:36 theanets.trainer:168 RmsProp 43 loss=706.632446 err=83.200211
I 2015-05-27 00:19:46 theanets.trainer:168 RmsProp 44 loss=700.155640 err=79.176567
I 2015-05-27 00:19:56 theanets.trainer:168 RmsProp 45 loss=698.262390 err=79.727425
I 2015-05-27 00:20:07 theanets.trainer:168 RmsProp 46 loss=694.671509 err=78.535545
I 2015-05-27 00:20:17 theanets.trainer:168 RmsProp 47 loss=689.013306 err=75.223892
I 2015-05-27 00:20:27 theanets.trainer:168 RmsProp 48 loss=685.783569 err=74.385445
I 2015-05-27 00:20:38 theanets.trainer:168 RmsProp 49 loss=681.368530 err=72.445160
I 2015-05-27 00:20:48 theanets.trainer:168 RmsProp 50 loss=675.028198 err=68.606117
I 2015-05-27 00:20:49 theanets.trainer:168 validation 5 loss=3021.548828 err=2416.503174 *
I 2015-05-27 00:20:59 theanets.trainer:168 RmsProp 51 loss=675.024963 err=71.093880
I 2015-05-27 00:21:10 theanets.trainer:168 RmsProp 52 loss=669.450684 err=68.008247
I 2015-05-27 00:21:20 theanets.trainer:168 RmsProp 53 loss=661.687134 err=62.698524
I 2015-05-27 00:21:30 theanets.trainer:168 RmsProp 54 loss=658.488525 err=61.970245
I 2015-05-27 00:21:41 theanets.trainer:168 RmsProp 55 loss=657.572693 err=63.601398
I 2015-05-27 00:21:51 theanets.trainer:168 RmsProp 56 loss=651.971802 err=60.319683
I 2015-05-27 00:22:02 theanets.trainer:168 RmsProp 57 loss=647.924072 err=58.383881
I 2015-05-27 00:22:12 theanets.trainer:168 RmsProp 58 loss=643.063843 err=55.695148
I 2015-05-27 00:22:23 theanets.trainer:168 RmsProp 59 loss=640.758972 err=55.713879
I 2015-05-27 00:22:33 theanets.trainer:168 RmsProp 60 loss=639.918823 err=57.155750
I 2015-05-27 00:22:33 theanets.trainer:168 validation 6 loss=2995.291504 err=2413.719971 *
I 2015-05-27 00:22:44 theanets.trainer:168 RmsProp 61 loss=636.190430 err=55.605629
I 2015-05-27 00:22:54 theanets.trainer:168 RmsProp 62 loss=628.508179 err=50.110176
I 2015-05-27 00:23:04 theanets.trainer:168 RmsProp 63 loss=627.986450 err=51.859718
I 2015-05-27 00:23:15 theanets.trainer:168 RmsProp 64 loss=625.650818 err=51.824074
I 2015-05-27 00:23:25 theanets.trainer:168 RmsProp 65 loss=621.034485 err=49.469917
I 2015-05-27 00:23:35 theanets.trainer:168 RmsProp 66 loss=614.493591 err=45.137527
I 2015-05-27 00:23:45 theanets.trainer:168 RmsProp 67 loss=615.350098 err=48.256584
I 2015-05-27 00:23:56 theanets.trainer:168 RmsProp 68 loss=610.803833 err=45.963970
I 2015-05-27 00:24:06 theanets.trainer:168 RmsProp 69 loss=608.310059 err=45.641926
I 2015-05-27 00:24:16 theanets.trainer:168 RmsProp 70 loss=602.758057 err=42.168674
I 2015-05-27 00:24:17 theanets.trainer:168 validation 7 loss=2967.373047 err=2407.908203 *
I 2015-05-27 00:24:27 theanets.trainer:168 RmsProp 71 loss=603.033142 err=44.513294
I 2015-05-27 00:24:38 theanets.trainer:168 RmsProp 72 loss=601.155334 err=44.688221
I 2015-05-27 00:24:48 theanets.trainer:168 RmsProp 73 loss=594.893311 err=40.403522
I 2015-05-27 00:24:58 theanets.trainer:168 RmsProp 74 loss=594.653320 err=42.204861
I 2015-05-27 00:25:08 theanets.trainer:168 RmsProp 75 loss=592.767334 err=42.439812
I 2015-05-27 00:25:19 theanets.trainer:168 RmsProp 76 loss=586.366333 err=38.083267
I 2015-05-27 00:25:29 theanets.trainer:168 RmsProp 77 loss=585.403442 err=39.150917
I 2015-05-27 00:25:39 theanets.trainer:168 RmsProp 78 loss=581.675171 err=37.429413
I 2015-05-27 00:25:49 theanets.trainer:168 RmsProp 79 loss=579.785522 err=37.500526
I 2015-05-27 00:25:59 theanets.trainer:168 RmsProp 80 loss=577.292236 err=36.958538
I 2015-05-27 00:26:00 theanets.trainer:168 validation 8 loss=2942.660400 err=2403.395508 *
I 2015-05-27 00:26:10 theanets.trainer:168 RmsProp 81 loss=574.789612 err=36.396881
I 2015-05-27 00:26:20 theanets.trainer:168 RmsProp 82 loss=571.658813 err=35.214230
I 2015-05-27 00:26:31 theanets.trainer:168 RmsProp 83 loss=570.512817 err=36.046207
I 2015-05-27 00:26:41 theanets.trainer:168 RmsProp 84 loss=565.252930 err=32.751884
I 2015-05-27 00:26:51 theanets.trainer:168 RmsProp 85 loss=564.131165 err=33.595692
I 2015-05-27 00:27:00 theanets.trainer:168 RmsProp 86 loss=561.644287 err=33.060333
I 2015-05-27 00:27:10 theanets.trainer:168 RmsProp 87 loss=559.504028 err=32.860847
I 2015-05-27 00:27:20 theanets.trainer:168 RmsProp 88 loss=558.067749 err=33.358063
I 2015-05-27 00:27:29 theanets.trainer:168 RmsProp 89 loss=554.295349 err=31.484592
I 2015-05-27 00:27:39 theanets.trainer:168 RmsProp 90 loss=553.171326 err=32.189377
I 2015-05-27 00:27:40 theanets.trainer:168 validation 9 loss=2921.894531 err=2401.884277 *
I 2015-05-27 00:27:49 theanets.trainer:168 RmsProp 91 loss=549.159180 err=29.944998
I 2015-05-27 00:27:59 theanets.trainer:168 RmsProp 92 loss=549.628418 err=32.229485
I 2015-05-27 00:28:09 theanets.trainer:168 RmsProp 93 loss=543.908691 err=28.349934
I 2015-05-27 00:28:19 theanets.trainer:168 RmsProp 94 loss=544.464417 err=30.720026
I 2015-05-27 00:28:28 theanets.trainer:168 RmsProp 95 loss=541.946106 err=30.007748
I 2015-05-27 00:28:38 theanets.trainer:168 RmsProp 96 loss=538.674255 err=28.548237
I 2015-05-27 00:28:48 theanets.trainer:168 RmsProp 97 loss=537.602966 err=29.299999
I 2015-05-27 00:28:58 theanets.trainer:168 RmsProp 98 loss=533.815308 err=27.323294
I 2015-05-27 00:29:08 theanets.trainer:168 RmsProp 99 loss=535.943237 err=31.255148
I 2015-05-27 00:29:19 theanets.trainer:168 RmsProp 100 loss=531.664490 err=28.583593
I 2015-05-27 00:29:19 theanets.trainer:168 validation 10 loss=2908.536133 err=2406.281250 *
I 2015-05-27 00:29:30 theanets.trainer:168 RmsProp 101 loss=527.798523 err=26.227774
I 2015-05-27 00:29:40 theanets.trainer:168 RmsProp 102 loss=526.742004 err=26.732141
I 2015-05-27 00:29:50 theanets.trainer:168 RmsProp 103 loss=525.244568 err=26.865973
I 2015-05-27 00:30:01 theanets.trainer:168 RmsProp 104 loss=523.618896 err=26.903402
I 2015-05-27 00:30:11 theanets.trainer:168 RmsProp 105 loss=520.152527 err=25.078493
I 2015-05-27 00:30:21 theanets.trainer:168 RmsProp 106 loss=519.677429 err=26.248371
I 2015-05-27 00:30:31 theanets.trainer:168 RmsProp 107 loss=517.238159 err=25.417984
I 2015-05-27 00:30:41 theanets.trainer:168 RmsProp 108 loss=515.501221 err=25.270092
I 2015-05-27 00:30:51 theanets.trainer:168 RmsProp 109 loss=512.913757 err=24.301025
I 2015-05-27 00:31:01 theanets.trainer:168 RmsProp 110 loss=510.875244 err=23.896954
I 2015-05-27 00:31:02 theanets.trainer:168 validation 11 loss=2898.440186 err=2412.352051 *
I 2015-05-27 00:31:12 theanets.trainer:168 RmsProp 111 loss=509.198486 err=23.826893
I 2015-05-27 00:31:22 theanets.trainer:168 RmsProp 112 loss=508.688324 err=24.860947
I 2015-05-27 00:31:32 theanets.trainer:168 RmsProp 113 loss=504.878967 err=22.579998
I 2015-05-27 00:31:43 theanets.trainer:168 RmsProp 114 loss=502.991394 err=22.238640
I 2015-05-27 00:31:53 theanets.trainer:168 RmsProp 115 loss=503.951904 err=24.757542
I 2015-05-27 00:32:03 theanets.trainer:168 RmsProp 116 loss=500.007629 err=22.328320
I 2015-05-27 00:32:13 theanets.trainer:168 RmsProp 117 loss=499.377777 err=23.196014
I 2015-05-27 00:32:23 theanets.trainer:168 RmsProp 118 loss=497.285217 err=22.605078
I 2015-05-27 00:32:34 theanets.trainer:168 RmsProp 119 loss=496.312592 err=23.112669
I 2015-05-27 00:32:44 theanets.trainer:168 RmsProp 120 loss=494.426910 err=22.721426
I 2015-05-27 00:32:45 theanets.trainer:168 validation 12 loss=2878.348145 err=2407.462646 *
I 2015-05-27 00:32:55 theanets.trainer:168 RmsProp 121 loss=491.376648 err=21.156206
I 2015-05-27 00:33:05 theanets.trainer:168 RmsProp 122 loss=489.963226 err=21.195045
I 2015-05-27 00:33:16 theanets.trainer:168 RmsProp 123 loss=488.206787 err=20.885414
I 2015-05-27 00:33:26 theanets.trainer:168 RmsProp 124 loss=487.822418 err=21.944139
I 2015-05-27 00:33:36 theanets.trainer:168 RmsProp 125 loss=485.709534 err=21.262419
I 2015-05-27 00:33:47 theanets.trainer:168 RmsProp 126 loss=483.471863 err=20.455294
I 2015-05-27 00:33:57 theanets.trainer:168 RmsProp 127 loss=481.401031 err=19.832653
I 2015-05-27 00:34:08 theanets.trainer:168 RmsProp 128 loss=480.336914 err=20.177471
I 2015-05-27 00:34:18 theanets.trainer:168 RmsProp 129 loss=478.755554 err=20.000132
I 2015-05-27 00:34:28 theanets.trainer:168 RmsProp 130 loss=478.018250 err=20.691050
I 2015-05-27 00:34:29 theanets.trainer:168 validation 13 loss=2866.775146 err=2410.224609 *
I 2015-05-27 00:34:39 theanets.trainer:168 RmsProp 131 loss=474.268494 err=18.341177
I 2015-05-27 00:34:50 theanets.trainer:168 RmsProp 132 loss=474.033447 err=19.511623
I 2015-05-27 00:35:00 theanets.trainer:168 RmsProp 133 loss=471.756927 err=18.631353
I 2015-05-27 00:35:11 theanets.trainer:168 RmsProp 134 loss=471.254730 err=19.502331
I 2015-05-27 00:35:21 theanets.trainer:168 RmsProp 135 loss=471.215576 err=20.822813
I 2015-05-27 00:35:32 theanets.trainer:168 RmsProp 136 loss=467.721344 err=18.606268
I 2015-05-27 00:35:42 theanets.trainer:168 RmsProp 137 loss=466.659271 err=18.824657
I 2015-05-27 00:35:53 theanets.trainer:168 RmsProp 138 loss=465.378906 err=18.858322
I 2015-05-27 00:36:03 theanets.trainer:168 RmsProp 139 loss=462.841949 err=17.643463
I 2015-05-27 00:36:13 theanets.trainer:168 RmsProp 140 loss=461.977295 err=18.097359
I 2015-05-27 00:36:14 theanets.trainer:168 validation 14 loss=2855.852783 err=2412.680908 *
I 2015-05-27 00:36:24 theanets.trainer:168 RmsProp 141 loss=460.558105 err=17.973200
I 2015-05-27 00:36:34 theanets.trainer:168 RmsProp 142 loss=459.226624 err=17.939814
I 2015-05-27 00:36:44 theanets.trainer:168 RmsProp 143 loss=458.295013 err=18.292912
I 2015-05-27 00:36:54 theanets.trainer:168 RmsProp 144 loss=455.889984 err=17.165480
I 2015-05-27 00:37:04 theanets.trainer:168 RmsProp 145 loss=454.750885 err=17.290480
I 2015-05-27 00:37:15 theanets.trainer:168 RmsProp 146 loss=453.293274 err=17.118013
I 2015-05-27 00:37:25 theanets.trainer:168 RmsProp 147 loss=452.135559 err=17.232878
I 2015-05-27 00:37:35 theanets.trainer:168 RmsProp 148 loss=449.955994 err=16.289797
I 2015-05-27 00:37:46 theanets.trainer:168 RmsProp 149 loss=450.383942 err=17.961706
I 2015-05-27 00:37:56 theanets.trainer:168 RmsProp 150 loss=448.256836 err=17.040041
I 2015-05-27 00:37:57 theanets.trainer:168 validation 15 loss=2842.170410 err=2411.597900 *
I 2015-05-27 00:38:07 theanets.trainer:168 RmsProp 151 loss=446.704010 err=16.654154
I 2015-05-27 00:38:17 theanets.trainer:168 RmsProp 152 loss=445.558929 err=16.660618
I 2015-05-27 00:38:27 theanets.trainer:168 RmsProp 153 loss=444.615540 err=16.881634
I 2015-05-27 00:38:38 theanets.trainer:168 RmsProp 154 loss=442.881927 err=16.315538
I 2015-05-27 00:38:48 theanets.trainer:168 RmsProp 155 loss=440.463959 err=15.076982
I 2015-05-27 00:38:58 theanets.trainer:168 RmsProp 156 loss=444.921539 err=20.750011
I 2015-05-27 00:39:08 theanets.trainer:168 RmsProp 157 loss=440.191803 err=17.107607
I 2015-05-27 00:39:19 theanets.trainer:168 RmsProp 158 loss=438.398438 err=16.285427
I 2015-05-27 00:39:29 theanets.trainer:168 RmsProp 159 loss=436.170898 err=15.049568
I 2015-05-27 00:39:39 theanets.trainer:168 RmsProp 160 loss=436.072754 err=16.042370
I 2015-05-27 00:39:40 theanets.trainer:168 validation 16 loss=2835.478271 err=2416.082031 *
I 2015-05-27 00:39:50 theanets.trainer:168 RmsProp 161 loss=434.694092 err=15.805578
I 2015-05-27 00:40:01 theanets.trainer:168 RmsProp 162 loss=432.975647 err=15.229715
I 2015-05-27 00:40:11 theanets.trainer:168 RmsProp 163 loss=431.536713 err=14.929085
I 2015-05-27 00:40:21 theanets.trainer:168 RmsProp 164 loss=431.234131 err=15.754107
I 2015-05-27 00:40:31 theanets.trainer:168 RmsProp 165 loss=429.553314 err=15.199018
I 2015-05-27 00:40:42 theanets.trainer:168 RmsProp 166 loss=428.987488 err=15.737312
I 2015-05-27 00:40:52 theanets.trainer:168 RmsProp 167 loss=426.725433 err=14.565123
I 2015-05-27 00:41:02 theanets.trainer:168 RmsProp 168 loss=426.023193 err=14.953568
I 2015-05-27 00:41:12 theanets.trainer:168 RmsProp 169 loss=424.950867 err=14.980166
I 2015-05-27 00:41:22 theanets.trainer:168 RmsProp 170 loss=423.719635 err=14.836922
I 2015-05-27 00:41:23 theanets.trainer:168 validation 17 loss=2832.352051 err=2424.060303 *
I 2015-05-27 00:41:33 theanets.trainer:168 RmsProp 171 loss=422.706482 err=14.904051
I 2015-05-27 00:41:43 theanets.trainer:168 RmsProp 172 loss=421.008972 err=14.276217
I 2015-05-27 00:41:54 theanets.trainer:168 RmsProp 173 loss=419.825043 err=14.158365
I 2015-05-27 00:42:04 theanets.trainer:168 RmsProp 174 loss=420.112305 err=15.506262
I 2015-05-27 00:42:14 theanets.trainer:168 RmsProp 175 loss=418.119629 err=14.519237
I 2015-05-27 00:42:24 theanets.trainer:168 RmsProp 176 loss=416.099792 err=13.487982
I 2015-05-27 00:42:35 theanets.trainer:168 RmsProp 177 loss=417.641418 err=16.060390
I 2015-05-27 00:42:45 theanets.trainer:168 RmsProp 178 loss=415.962738 err=15.360022
I 2015-05-27 00:42:55 theanets.trainer:168 RmsProp 179 loss=414.323425 err=14.616916
I 2015-05-27 00:43:06 theanets.trainer:168 RmsProp 180 loss=412.219330 err=13.404414
I 2015-05-27 00:43:06 theanets.trainer:168 validation 18 loss=2824.170898 err=2425.862549 *
I 2015-05-27 00:43:17 theanets.trainer:168 RmsProp 181 loss=411.778076 err=13.913289
I 2015-05-27 00:43:27 theanets.trainer:168 RmsProp 182 loss=410.978271 err=14.089808
I 2015-05-27 00:43:37 theanets.trainer:168 RmsProp 183 loss=409.478119 err=13.559776
I 2015-05-27 00:43:46 theanets.trainer:168 RmsProp 184 loss=409.018951 err=14.069348
I 2015-05-27 00:43:57 theanets.trainer:168 RmsProp 185 loss=408.198181 err=14.204663
I 2015-05-27 00:44:07 theanets.trainer:168 RmsProp 186 loss=406.502991 err=13.462476
I 2015-05-27 00:44:17 theanets.trainer:168 RmsProp 187 loss=405.707703 err=13.616533
I 2015-05-27 00:44:27 theanets.trainer:168 RmsProp 188 loss=404.520813 err=13.362457
I 2015-05-27 00:44:37 theanets.trainer:168 RmsProp 189 loss=404.337830 err=14.103769
I 2015-05-27 00:44:47 theanets.trainer:168 RmsProp 190 loss=402.478516 err=13.167353
I 2015-05-27 00:44:47 theanets.trainer:168 validation 19 loss=2816.426758 err=2427.631592 *
I 2015-05-27 00:44:57 theanets.trainer:168 RmsProp 191 loss=401.692139 err=13.314059
I 2015-05-27 00:45:07 theanets.trainer:168 RmsProp 192 loss=400.934631 err=13.485659
I 2015-05-27 00:45:17 theanets.trainer:168 RmsProp 193 loss=399.667542 err=13.140640
I 2015-05-27 00:45:27 theanets.trainer:168 RmsProp 194 loss=398.723633 err=13.107533
I 2015-05-27 00:45:38 theanets.trainer:168 RmsProp 195 loss=397.956055 err=13.256783
I 2015-05-27 00:45:48 theanets.trainer:168 RmsProp 196 loss=396.789520 err=12.999262
I 2015-05-27 00:45:59 theanets.trainer:168 RmsProp 197 loss=395.574890 err=12.687480
I 2015-05-27 00:46:09 theanets.trainer:168 RmsProp 198 loss=395.377014 err=13.390162
I 2015-05-27 00:46:19 theanets.trainer:168 RmsProp 199 loss=394.454590 err=13.336345
I 2015-05-27 00:46:30 theanets.trainer:168 RmsProp 200 loss=392.594940 err=12.340639
I 2015-05-27 00:46:30 theanets.trainer:168 validation 20 loss=2806.068604 err=2426.294678 *
I 2015-05-27 00:46:41 theanets.trainer:168 RmsProp 201 loss=392.273254 err=12.887781
I 2015-05-27 00:46:51 theanets.trainer:168 RmsProp 202 loss=391.017914 err=12.498880
I 2015-05-27 00:47:02 theanets.trainer:168 RmsProp 203 loss=390.565369 err=12.925685
I 2015-05-27 00:47:13 theanets.trainer:168 RmsProp 204 loss=388.806946 err=12.051806
I 2015-05-27 00:47:23 theanets.trainer:168 RmsProp 205 loss=388.297272 err=12.420795
I 2015-05-27 00:47:34 theanets.trainer:168 RmsProp 206 loss=387.505219 err=12.510226
I 2015-05-27 00:47:44 theanets.trainer:168 RmsProp 207 loss=386.078308 err=11.951922
I 2015-05-27 00:47:55 theanets.trainer:168 RmsProp 208 loss=385.280212 err=12.006825
I 2015-05-27 00:48:05 theanets.trainer:168 RmsProp 209 loss=385.364197 err=12.953868
I 2015-05-27 00:48:16 theanets.trainer:168 RmsProp 210 loss=383.598633 err=12.016939
I 2015-05-27 00:48:17 theanets.trainer:168 validation 21 loss=2802.077637 err=2430.926514 *
I 2015-05-27 00:48:27 theanets.trainer:168 RmsProp 211 loss=382.844269 err=12.062315
I 2015-05-27 00:48:38 theanets.trainer:168 RmsProp 212 loss=382.338226 err=12.371057
I 2015-05-27 00:48:49 theanets.trainer:168 RmsProp 213 loss=381.371155 err=12.225272
I 2015-05-27 00:49:00 theanets.trainer:168 RmsProp 214 loss=380.442566 err=12.115221
I 2015-05-27 00:49:10 theanets.trainer:168 RmsProp 215 loss=378.784119 err=11.279676
I 2015-05-27 00:49:21 theanets.trainer:168 RmsProp 216 loss=379.562805 err=12.876930
I 2015-05-27 00:49:32 theanets.trainer:168 RmsProp 217 loss=377.639313 err=11.737129
I 2015-05-27 00:49:42 theanets.trainer:168 RmsProp 218 loss=376.753601 err=11.611991
I 2015-05-27 00:49:53 theanets.trainer:168 RmsProp 219 loss=376.118469 err=11.744611
I 2015-05-27 00:50:03 theanets.trainer:168 RmsProp 220 loss=374.933044 err=11.336248
I 2015-05-27 00:50:04 theanets.trainer:168 validation 22 loss=2796.898682 err=2433.731689 *
I 2015-05-27 00:50:14 theanets.trainer:168 RmsProp 221 loss=374.533752 err=11.718317
I 2015-05-27 00:50:25 theanets.trainer:168 RmsProp 222 loss=373.295227 err=11.260064
I 2015-05-27 00:50:35 theanets.trainer:168 RmsProp 223 loss=373.225922 err=11.968279
I 2015-05-27 00:50:46 theanets.trainer:168 RmsProp 224 loss=372.705261 err=12.215911
I 2015-05-27 00:50:57 theanets.trainer:168 RmsProp 225 loss=371.289001 err=11.545820
I 2015-05-27 00:51:07 theanets.trainer:168 RmsProp 226 loss=370.482605 err=11.491570
I 2015-05-27 00:51:17 theanets.trainer:168 RmsProp 227 loss=370.343323 err=12.089543
I 2015-05-27 00:51:28 theanets.trainer:168 RmsProp 228 loss=368.723816 err=11.184604
I 2015-05-27 00:51:38 theanets.trainer:168 RmsProp 229 loss=368.302216 err=11.477771
I 2015-05-27 00:51:48 theanets.trainer:168 RmsProp 230 loss=368.325500 err=12.231881
I 2015-05-27 00:51:49 theanets.trainer:168 validation 23 loss=2794.009277 err=2438.321533 *
I 2015-05-27 00:51:59 theanets.trainer:168 RmsProp 231 loss=366.291199 err=10.927855
I 2015-05-27 00:52:10 theanets.trainer:168 RmsProp 232 loss=365.979584 err=11.347653
I 2015-05-27 00:52:20 theanets.trainer:168 RmsProp 233 loss=364.801941 err=10.908700
I 2015-05-27 00:52:30 theanets.trainer:168 RmsProp 234 loss=363.959686 err=10.803542
I 2015-05-27 00:52:41 theanets.trainer:168 RmsProp 235 loss=363.738556 err=11.316415
I 2015-05-27 00:52:52 theanets.trainer:168 RmsProp 236 loss=362.583191 err=10.879091
I 2015-05-27 00:53:02 theanets.trainer:168 RmsProp 237 loss=361.127533 err=10.136900
I 2015-05-27 00:53:12 theanets.trainer:168 RmsProp 238 loss=362.198914 err=11.919958
I 2015-05-27 00:53:23 theanets.trainer:168 RmsProp 239 loss=360.652100 err=11.071733
I 2015-05-27 00:53:33 theanets.trainer:168 RmsProp 240 loss=359.685089 err=10.786466
I 2015-05-27 00:53:34 theanets.trainer:168 validation 24 loss=2788.644287 err=2440.105469 *
I 2015-05-27 00:53:44 theanets.trainer:168 RmsProp 241 loss=359.337311 err=11.117730
I 2015-05-27 00:53:54 theanets.trainer:168 RmsProp 242 loss=358.488434 err=10.957616
I 2015-05-27 00:54:05 theanets.trainer:168 RmsProp 243 loss=358.069550 err=11.211683
I 2015-05-27 00:54:15 theanets.trainer:168 RmsProp 244 loss=356.413116 err=10.228444
I 2015-05-27 00:54:26 theanets.trainer:168 RmsProp 245 loss=356.118652 err=10.620207
I 2015-05-27 00:54:36 theanets.trainer:168 RmsProp 246 loss=355.437378 err=10.631568
I 2015-05-27 00:54:46 theanets.trainer:168 RmsProp 247 loss=354.706726 err=10.580091
I 2015-05-27 00:54:57 theanets.trainer:168 RmsProp 248 loss=354.033661 err=10.585902
I 2015-05-27 00:55:07 theanets.trainer:168 RmsProp 249 loss=352.865051 err=10.091218
I 2015-05-27 00:55:18 theanets.trainer:168 RmsProp 250 loss=352.613281 err=10.508245
I 2015-05-27 00:55:18 theanets.trainer:168 validation 25 loss=2783.920166 err=2442.184814 *
I 2015-05-27 00:55:29 theanets.trainer:168 RmsProp 251 loss=351.922333 err=10.484738
I 2015-05-27 00:55:39 theanets.trainer:168 RmsProp 252 loss=351.661011 err=10.891901
I 2015-05-27 00:55:50 theanets.trainer:168 RmsProp 253 loss=350.147491 err=10.042956
I 2015-05-27 00:56:00 theanets.trainer:168 RmsProp 254 loss=349.753967 err=10.308001
I 2015-05-27 00:56:10 theanets.trainer:168 RmsProp 255 loss=349.195160 err=10.402682
I 2015-05-27 00:56:21 theanets.trainer:168 RmsProp 256 loss=348.565338 err=10.424329
I 2015-05-27 00:56:32 theanets.trainer:168 RmsProp 257 loss=347.837799 err=10.342245
I 2015-05-27 00:56:42 theanets.trainer:168 RmsProp 258 loss=347.763184 err=10.916170
I 2015-05-27 00:56:52 theanets.trainer:168 RmsProp 259 loss=346.483398 err=10.272781
I 2015-05-27 00:57:03 theanets.trainer:168 RmsProp 260 loss=346.219177 err=10.636802
I 2015-05-27 00:57:03 theanets.trainer:168 validation 26 loss=2784.312988 err=2449.075439
I 2015-05-27 00:57:14 theanets.trainer:168 RmsProp 261 loss=344.827240 err=9.870722
I 2015-05-27 00:57:24 theanets.trainer:168 RmsProp 262 loss=345.412262 err=11.068579
I 2015-05-27 00:57:34 theanets.trainer:168 RmsProp 263 loss=343.725220 err=9.989256
I 2015-05-27 00:57:45 theanets.trainer:168 RmsProp 264 loss=343.088013 err=9.950871
I 2015-05-27 00:57:55 theanets.trainer:168 RmsProp 265 loss=342.324280 err=9.794367
I 2015-05-27 00:58:06 theanets.trainer:168 RmsProp 266 loss=342.073639 err=10.159510
I 2015-05-27 00:58:16 theanets.trainer:168 RmsProp 267 loss=341.349792 err=10.041700
I 2015-05-27 00:58:26 theanets.trainer:168 RmsProp 268 loss=340.498505 err=9.785174
I 2015-05-27 00:58:36 theanets.trainer:168 RmsProp 269 loss=340.408936 err=10.290796
I 2015-05-27 00:58:47 theanets.trainer:168 RmsProp 270 loss=338.966553 err=9.453631
I 2015-05-27 00:58:47 theanets.trainer:168 validation 27 loss=2774.449707 err=2445.263916 *
I 2015-05-27 00:58:58 theanets.trainer:168 RmsProp 271 loss=338.837585 err=9.921847
I 2015-05-27 00:59:08 theanets.trainer:168 RmsProp 272 loss=337.937988 err=9.617850
I 2015-05-27 00:59:18 theanets.trainer:168 RmsProp 273 loss=337.134857 err=9.396669
I 2015-05-27 00:59:29 theanets.trainer:168 RmsProp 274 loss=337.884186 err=10.721174
I 2015-05-27 00:59:39 theanets.trainer:168 RmsProp 275 loss=335.876343 err=9.296001
I 2015-05-27 00:59:49 theanets.trainer:168 RmsProp 276 loss=335.890137 err=9.890524
I 2015-05-27 00:59:59 theanets.trainer:168 RmsProp 277 loss=335.961792 err=10.544106
I 2015-05-27 01:00:09 theanets.trainer:168 RmsProp 278 loss=334.506317 err=9.656021
I 2015-05-27 01:00:19 theanets.trainer:168 RmsProp 279 loss=334.454193 err=10.165771
I 2015-05-27 01:00:29 theanets.trainer:168 RmsProp 280 loss=333.235413 err=9.504859
I 2015-05-27 01:00:30 theanets.trainer:168 validation 28 loss=2770.391357 err=2446.966309 *
I 2015-05-27 01:00:40 theanets.trainer:168 RmsProp 281 loss=332.996033 err=9.821190
I 2015-05-27 01:00:49 theanets.trainer:168 RmsProp 282 loss=332.144409 err=9.526487
I 2015-05-27 01:00:59 theanets.trainer:168 RmsProp 283 loss=331.888885 err=9.816924
I 2015-05-27 01:01:09 theanets.trainer:168 RmsProp 284 loss=331.029388 err=9.507002
I 2015-05-27 01:01:19 theanets.trainer:168 RmsProp 285 loss=329.791565 err=8.817030
I 2015-05-27 01:01:29 theanets.trainer:168 RmsProp 286 loss=330.234406 err=9.816744
I 2015-05-27 01:01:39 theanets.trainer:168 RmsProp 287 loss=329.758881 err=9.886442
I 2015-05-27 01:01:48 theanets.trainer:168 RmsProp 288 loss=328.371796 err=9.034575
I 2015-05-27 01:01:59 theanets.trainer:168 RmsProp 289 loss=328.306732 err=9.508352
I 2015-05-27 01:02:09 theanets.trainer:168 RmsProp 290 loss=327.429321 err=9.177870
I 2015-05-27 01:02:10 theanets.trainer:168 validation 29 loss=2766.143555 err=2448.194580 *
I 2015-05-27 01:02:20 theanets.trainer:168 RmsProp 291 loss=326.907288 err=9.200590
I 2015-05-27 01:02:31 theanets.trainer:168 RmsProp 292 loss=326.939392 err=9.775276
I 2015-05-27 01:02:41 theanets.trainer:168 RmsProp 293 loss=325.890198 err=9.274594
I 2015-05-27 01:02:51 theanets.trainer:168 RmsProp 294 loss=325.341858 err=9.270024
I 2015-05-27 01:03:02 theanets.trainer:168 RmsProp 295 loss=324.429810 err=8.900199
I 2015-05-27 01:03:12 theanets.trainer:168 RmsProp 296 loss=325.192780 err=10.195983
I 2015-05-27 01:03:23 theanets.trainer:168 RmsProp 297 loss=323.872803 err=9.394190
I 2015-05-27 01:03:33 theanets.trainer:168 RmsProp 298 loss=323.431427 err=9.457225
I 2015-05-27 01:03:43 theanets.trainer:168 RmsProp 299 loss=322.617889 err=9.152527
I 2015-05-27 01:03:54 theanets.trainer:168 RmsProp 300 loss=322.412415 err=9.457652
I 2015-05-27 01:03:55 theanets.trainer:168 validation 30 loss=2768.439209 err=2455.757080
I 2015-05-27 01:04:05 theanets.trainer:168 RmsProp 301 loss=321.599915 err=9.150493
I 2015-05-27 01:04:16 theanets.trainer:168 RmsProp 302 loss=321.098358 err=9.154223
I 2015-05-27 01:04:27 theanets.trainer:168 RmsProp 303 loss=321.123352 err=9.687088
I 2015-05-27 01:04:38 theanets.trainer:168 RmsProp 304 loss=319.435303 err=8.509432
I 2015-05-27 01:04:48 theanets.trainer:168 RmsProp 305 loss=320.301300 err=9.884755
I 2015-05-27 01:04:59 theanets.trainer:168 RmsProp 306 loss=319.091614 err=9.171737
I 2015-05-27 01:05:10 theanets.trainer:168 RmsProp 307 loss=318.935730 err=9.507759
I 2015-05-27 01:05:21 theanets.trainer:168 RmsProp 308 loss=317.550049 err=8.607828
I 2015-05-27 01:05:32 theanets.trainer:168 RmsProp 309 loss=317.386780 err=8.932157
I 2015-05-27 01:05:42 theanets.trainer:168 RmsProp 310 loss=316.936279 err=8.976983
I 2015-05-27 01:05:43 theanets.trainer:168 validation 31 loss=2764.805176 err=2457.115234 *
I 2015-05-27 01:05:53 theanets.trainer:168 RmsProp 311 loss=317.143005 err=9.675107
I 2015-05-27 01:06:04 theanets.trainer:168 RmsProp 312 loss=315.739563 err=8.758888
I 2015-05-27 01:06:14 theanets.trainer:168 RmsProp 313 loss=314.924255 err=8.426342
I 2015-05-27 01:06:25 theanets.trainer:168 RmsProp 314 loss=314.879211 err=8.874068
I 2015-05-27 01:06:35 theanets.trainer:168 RmsProp 315 loss=314.480408 err=8.972492
I 2015-05-27 01:06:46 theanets.trainer:168 RmsProp 316 loss=314.088165 err=9.069047
I 2015-05-27 01:06:56 theanets.trainer:168 RmsProp 317 loss=313.493225 err=8.953508
I 2015-05-27 01:07:07 theanets.trainer:168 RmsProp 318 loss=313.119537 err=9.048871
I 2015-05-27 01:07:18 theanets.trainer:168 RmsProp 319 loss=312.532532 err=8.929404
I 2015-05-27 01:07:29 theanets.trainer:168 RmsProp 320 loss=311.837433 err=8.702556
I 2015-05-27 01:07:29 theanets.trainer:168 validation 32 loss=2756.044922 err=2453.161865 *
I 2015-05-27 01:07:40 theanets.trainer:168 RmsProp 321 loss=311.711395 err=9.043569
I 2015-05-27 01:07:50 theanets.trainer:168 RmsProp 322 loss=311.105316 err=8.895259
I 2015-05-27 01:08:01 theanets.trainer:168 RmsProp 323 loss=310.722382 err=8.968294
I 2015-05-27 01:08:12 theanets.trainer:168 RmsProp 324 loss=310.296692 err=9.001200
I 2015-05-27 01:08:22 theanets.trainer:168 RmsProp 325 loss=309.242188 err=8.406786
I 2015-05-27 01:08:33 theanets.trainer:168 RmsProp 326 loss=309.277527 err=8.906338
I 2015-05-27 01:08:44 theanets.trainer:168 RmsProp 327 loss=308.507935 err=8.602443
I 2015-05-27 01:08:55 theanets.trainer:168 RmsProp 328 loss=308.207977 err=8.768932
I 2015-05-27 01:09:05 theanets.trainer:168 RmsProp 329 loss=307.636963 err=8.662912
I 2015-05-27 01:09:16 theanets.trainer:168 RmsProp 330 loss=307.230682 err=8.715458
I 2015-05-27 01:09:17 theanets.trainer:168 validation 33 loss=2755.937744 err=2457.667236 *
I 2015-05-27 01:09:28 theanets.trainer:168 RmsProp 331 loss=306.748352 err=8.678824
I 2015-05-27 01:09:39 theanets.trainer:168 RmsProp 332 loss=306.072845 err=8.451881
I 2015-05-27 01:09:49 theanets.trainer:168 RmsProp 333 loss=305.736389 err=8.572256
I 2015-05-27 01:10:00 theanets.trainer:168 RmsProp 334 loss=306.340424 err=9.623846
I 2015-05-27 01:10:11 theanets.trainer:168 RmsProp 335 loss=304.673431 err=8.397860
I 2015-05-27 01:10:21 theanets.trainer:168 RmsProp 336 loss=303.928162 err=8.074163
I 2015-05-27 01:10:32 theanets.trainer:168 RmsProp 337 loss=303.911743 err=8.487284
I 2015-05-27 01:10:43 theanets.trainer:168 RmsProp 338 loss=303.741364 err=8.763268
I 2015-05-27 01:10:54 theanets.trainer:168 RmsProp 339 loss=304.174561 err=9.627612
I 2015-05-27 01:11:05 theanets.trainer:168 RmsProp 340 loss=302.638184 err=8.511444
I 2015-05-27 01:11:05 theanets.trainer:168 validation 34 loss=2757.509521 err=2463.602783
I 2015-05-27 01:11:16 theanets.trainer:168 RmsProp 341 loss=301.546143 err=7.827986
I 2015-05-27 01:11:27 theanets.trainer:168 RmsProp 342 loss=302.398010 err=9.098355
I 2015-05-27 01:11:38 theanets.trainer:168 RmsProp 343 loss=301.643372 err=8.766147
I 2015-05-27 01:11:49 theanets.trainer:168 RmsProp 344 loss=300.322723 err=7.864818
I 2015-05-27 01:12:00 theanets.trainer:168 RmsProp 345 loss=301.326324 err=9.295204
I 2015-05-27 01:12:11 theanets.trainer:168 RmsProp 346 loss=300.234161 err=8.618074
I 2015-05-27 01:12:22 theanets.trainer:168 RmsProp 347 loss=299.482849 err=8.277516
I 2015-05-27 01:12:33 theanets.trainer:168 RmsProp 348 loss=299.102020 err=8.303745
I 2015-05-27 01:12:43 theanets.trainer:168 RmsProp 349 loss=299.050476 err=8.673086
I 2015-05-27 01:12:54 theanets.trainer:168 RmsProp 350 loss=298.969208 err=9.008741
I 2015-05-27 01:12:55 theanets.trainer:168 validation 35 loss=2751.810059 err=2462.076660 *
I 2015-05-27 01:13:05 theanets.trainer:168 RmsProp 351 loss=297.490570 err=7.937956
I 2015-05-27 01:13:16 theanets.trainer:168 RmsProp 352 loss=297.735046 err=8.590717
I 2015-05-27 01:13:27 theanets.trainer:168 RmsProp 353 loss=296.829071 err=8.102765
I 2015-05-27 01:13:37 theanets.trainer:168 RmsProp 354 loss=296.772217 err=8.468042
I 2015-05-27 01:13:48 theanets.trainer:168 RmsProp 355 loss=296.705872 err=8.811003
I 2015-05-27 01:13:58 theanets.trainer:168 RmsProp 356 loss=295.246887 err=7.762414
I 2015-05-27 01:14:09 theanets.trainer:168 RmsProp 357 loss=295.284210 err=8.214880
I 2015-05-27 01:14:19 theanets.trainer:168 RmsProp 358 loss=295.120911 err=8.468209
I 2015-05-27 01:14:29 theanets.trainer:168 RmsProp 359 loss=294.065094 err=7.829803
I 2015-05-27 01:14:40 theanets.trainer:168 RmsProp 360 loss=293.705383 err=7.881906
I 2015-05-27 01:14:40 theanets.trainer:168 validation 36 loss=2754.436768 err=2468.833984
I 2015-05-27 01:14:51 theanets.trainer:168 RmsProp 361 loss=294.057220 err=8.638940
I 2015-05-27 01:15:01 theanets.trainer:168 RmsProp 362 loss=293.449493 err=8.431192
I 2015-05-27 01:15:12 theanets.trainer:168 RmsProp 363 loss=292.583282 err=7.968363
I 2015-05-27 01:15:22 theanets.trainer:168 RmsProp 364 loss=292.068024 err=7.848657
I 2015-05-27 01:15:32 theanets.trainer:168 RmsProp 365 loss=291.899353 err=8.079374
I 2015-05-27 01:15:43 theanets.trainer:168 RmsProp 366 loss=291.519897 err=8.097814
I 2015-05-27 01:15:53 theanets.trainer:168 RmsProp 367 loss=291.398499 err=8.356300
I 2015-05-27 01:16:03 theanets.trainer:168 RmsProp 368 loss=289.915039 err=7.262629
I 2015-05-27 01:16:14 theanets.trainer:168 RmsProp 369 loss=291.855530 err=9.585755
I 2015-05-27 01:16:25 theanets.trainer:168 RmsProp 370 loss=289.951508 err=8.059599
I 2015-05-27 01:16:25 theanets.trainer:168 validation 37 loss=2744.421875 err=2462.738281 *
I 2015-05-27 01:16:36 theanets.trainer:168 RmsProp 371 loss=289.049622 err=7.532586
I 2015-05-27 01:16:46 theanets.trainer:168 RmsProp 372 loss=289.942719 err=8.795752
I 2015-05-27 01:16:57 theanets.trainer:168 RmsProp 373 loss=288.342102 err=7.573328
I 2015-05-27 01:17:08 theanets.trainer:168 RmsProp 374 loss=288.271057 err=7.876878
I 2015-05-27 01:17:18 theanets.trainer:168 RmsProp 375 loss=287.800934 err=7.787032
I 2015-05-27 01:17:28 theanets.trainer:168 RmsProp 376 loss=287.837830 err=8.199628
I 2015-05-27 01:17:39 theanets.trainer:168 RmsProp 377 loss=287.165497 err=7.908459
I 2015-05-27 01:17:50 theanets.trainer:168 RmsProp 378 loss=286.976013 err=8.092688
I 2015-05-27 01:18:01 theanets.trainer:168 RmsProp 379 loss=286.308899 err=7.792880
I 2015-05-27 01:18:12 theanets.trainer:168 RmsProp 380 loss=286.382263 err=8.240595
I 2015-05-27 01:18:12 theanets.trainer:168 validation 38 loss=2743.414795 err=2465.476318 *
I 2015-05-27 01:18:23 theanets.trainer:168 RmsProp 381 loss=286.095886 err=8.319905
I 2015-05-27 01:18:34 theanets.trainer:168 RmsProp 382 loss=285.102142 err=7.689653
I 2015-05-27 01:18:45 theanets.trainer:168 RmsProp 383 loss=284.738037 err=7.682924
I 2015-05-27 01:18:56 theanets.trainer:168 RmsProp 384 loss=284.849823 err=8.166191
I 2015-05-27 01:19:07 theanets.trainer:168 RmsProp 385 loss=284.908813 err=8.590870
I 2015-05-27 01:19:17 theanets.trainer:168 RmsProp 386 loss=283.897034 err=7.937283
I 2015-05-27 01:19:28 theanets.trainer:168 RmsProp 387 loss=283.248474 err=7.639403
I 2015-05-27 01:19:39 theanets.trainer:168 RmsProp 388 loss=282.708557 err=7.454816
I 2015-05-27 01:19:50 theanets.trainer:168 RmsProp 389 loss=282.809875 err=7.918720
I 2015-05-27 01:20:01 theanets.trainer:168 RmsProp 390 loss=282.430145 err=7.902349
I 2015-05-27 01:20:02 theanets.trainer:168 validation 39 loss=2735.141357 err=2460.804199 *
I 2015-05-27 01:20:13 theanets.trainer:168 RmsProp 391 loss=282.301331 err=8.133140
I 2015-05-27 01:20:24 theanets.trainer:168 RmsProp 392 loss=281.503571 err=7.693853
I 2015-05-27 01:20:34 theanets.trainer:168 RmsProp 393 loss=281.448059 err=7.995385
I 2015-05-27 01:20:45 theanets.trainer:168 RmsProp 394 loss=281.328674 err=8.228736
I 2015-05-27 01:20:56 theanets.trainer:168 RmsProp 395 loss=280.924713 err=8.172300
I 2015-05-27 01:21:06 theanets.trainer:168 RmsProp 396 loss=279.974915 err=7.575834
I 2015-05-27 01:21:16 theanets.trainer:168 RmsProp 397 loss=280.212769 err=8.153132
I 2015-05-27 01:21:27 theanets.trainer:168 RmsProp 398 loss=279.168823 err=7.456748
I 2015-05-27 01:21:37 theanets.trainer:168 RmsProp 399 loss=280.128296 err=8.753018
I 2015-05-27 01:21:48 theanets.trainer:168 RmsProp 400 loss=278.321838 err=7.285900
I 2015-05-27 01:21:48 theanets.trainer:168 validation 40 loss=2743.619385 err=2472.773193
I 2015-05-27 01:21:59 theanets.trainer:168 RmsProp 401 loss=278.480591 err=7.783956
I 2015-05-27 01:22:10 theanets.trainer:168 RmsProp 402 loss=278.091400 err=7.731150
I 2015-05-27 01:22:21 theanets.trainer:168 RmsProp 403 loss=277.998657 err=7.980971
I 2015-05-27 01:22:32 theanets.trainer:168 RmsProp 404 loss=277.191162 err=7.516856
I 2015-05-27 01:22:43 theanets.trainer:168 RmsProp 405 loss=276.629120 err=7.305650
I 2015-05-27 01:22:53 theanets.trainer:168 RmsProp 406 loss=277.290955 err=8.312960
I 2015-05-27 01:23:04 theanets.trainer:168 RmsProp 407 loss=276.796234 err=8.165205
I 2015-05-27 01:23:15 theanets.trainer:168 RmsProp 408 loss=275.924988 err=7.637610
I 2015-05-27 01:23:26 theanets.trainer:168 RmsProp 409 loss=275.612701 err=7.664290
I 2015-05-27 01:23:36 theanets.trainer:168 RmsProp 410 loss=275.737854 err=8.126346
I 2015-05-27 01:23:37 theanets.trainer:168 validation 41 loss=2734.940918 err=2467.514404 *
I 2015-05-27 01:23:48 theanets.trainer:168 RmsProp 411 loss=274.757874 err=7.483325
I 2015-05-27 01:23:59 theanets.trainer:168 RmsProp 412 loss=274.228119 err=7.293333
I 2015-05-27 01:24:09 theanets.trainer:168 RmsProp 413 loss=274.479919 err=7.885236
I 2015-05-27 01:24:20 theanets.trainer:168 RmsProp 414 loss=273.605164 err=7.348189
I 2015-05-27 01:24:31 theanets.trainer:168 RmsProp 415 loss=274.069153 err=8.143466
I 2015-05-27 01:24:42 theanets.trainer:168 RmsProp 416 loss=272.626495 err=7.027341
I 2015-05-27 01:24:53 theanets.trainer:168 RmsProp 417 loss=273.174255 err=7.898299
I 2015-05-27 01:25:04 theanets.trainer:168 RmsProp 418 loss=272.514038 err=7.559131
I 2015-05-27 01:25:14 theanets.trainer:168 RmsProp 419 loss=272.227417 err=7.599956
I 2015-05-27 01:25:25 theanets.trainer:168 RmsProp 420 loss=272.016022 err=7.711689
I 2015-05-27 01:25:26 theanets.trainer:168 validation 42 loss=2737.446045 err=2473.309082
I 2015-05-27 01:25:36 theanets.trainer:168 RmsProp 421 loss=270.817993 err=6.839183
I 2015-05-27 01:25:47 theanets.trainer:168 RmsProp 422 loss=271.486023 err=7.824006
I 2015-05-27 01:25:58 theanets.trainer:168 RmsProp 423 loss=271.099762 err=7.758093
I 2015-05-27 01:26:08 theanets.trainer:168 RmsProp 424 loss=270.831635 err=7.803412
I 2015-05-27 01:26:19 theanets.trainer:168 RmsProp 425 loss=270.298767 err=7.583923
I 2015-05-27 01:26:29 theanets.trainer:168 RmsProp 426 loss=270.265381 err=7.863552
I 2015-05-27 01:26:40 theanets.trainer:168 RmsProp 427 loss=269.371796 err=7.272547
I 2015-05-27 01:26:50 theanets.trainer:168 RmsProp 428 loss=269.534546 err=7.744308
I 2015-05-27 01:27:01 theanets.trainer:168 RmsProp 429 loss=269.313995 err=7.833838
I 2015-05-27 01:27:11 theanets.trainer:168 RmsProp 430 loss=268.808624 err=7.633679
I 2015-05-27 01:27:12 theanets.trainer:168 validation 43 loss=2733.112793 err=2472.116943 *
I 2015-05-27 01:27:22 theanets.trainer:168 RmsProp 431 loss=268.798706 err=7.935104
I 2015-05-27 01:27:33 theanets.trainer:168 RmsProp 432 loss=267.661316 err=7.105225
I 2015-05-27 01:27:43 theanets.trainer:168 RmsProp 433 loss=267.893372 err=7.641657
I 2015-05-27 01:27:53 theanets.trainer:168 RmsProp 434 loss=267.445892 err=7.498028
I 2015-05-27 01:28:04 theanets.trainer:168 RmsProp 435 loss=267.070007 err=7.434926
I 2015-05-27 01:28:14 theanets.trainer:168 RmsProp 436 loss=266.874023 err=7.551639
I 2015-05-27 01:28:24 theanets.trainer:168 RmsProp 437 loss=265.715393 err=6.701619
I 2015-05-27 01:28:35 theanets.trainer:168 RmsProp 438 loss=266.407410 err=7.702689
I 2015-05-27 01:28:45 theanets.trainer:168 RmsProp 439 loss=265.180054 err=6.783343
I 2015-05-27 01:28:56 theanets.trainer:168 RmsProp 440 loss=265.018890 err=6.932768
I 2015-05-27 01:28:56 theanets.trainer:168 validation 44 loss=2729.537598 err=2471.619141 *
I 2015-05-27 01:29:07 theanets.trainer:168 RmsProp 441 loss=265.255737 err=7.481374
I 2015-05-27 01:29:17 theanets.trainer:168 RmsProp 442 loss=265.081177 err=7.605090
I 2015-05-27 01:29:27 theanets.trainer:168 RmsProp 443 loss=264.216492 err=7.036132
I 2015-05-27 01:29:38 theanets.trainer:168 RmsProp 444 loss=263.675598 err=6.794829
I 2015-05-27 01:29:48 theanets.trainer:168 RmsProp 445 loss=265.639709 err=9.045349
I 2015-05-27 01:29:59 theanets.trainer:168 RmsProp 446 loss=263.492737 err=7.189066
I 2015-05-27 01:30:10 theanets.trainer:168 RmsProp 447 loss=263.173767 err=7.153162
I 2015-05-27 01:30:20 theanets.trainer:168 RmsProp 448 loss=262.762329 err=7.025899
I 2015-05-27 01:30:30 theanets.trainer:168 RmsProp 449 loss=262.810608 err=7.363789
I 2015-05-27 01:30:41 theanets.trainer:168 RmsProp 450 loss=262.887756 err=7.732100
I 2015-05-27 01:30:42 theanets.trainer:168 validation 45 loss=2731.324951 err=2476.320801
I 2015-05-27 01:30:52 theanets.trainer:168 RmsProp 451 loss=261.999268 err=7.134393
I 2015-05-27 01:31:03 theanets.trainer:168 RmsProp 452 loss=261.785706 err=7.208086
I 2015-05-27 01:31:13 theanets.trainer:168 RmsProp 453 loss=261.477936 err=7.193002
I 2015-05-27 01:31:24 theanets.trainer:168 RmsProp 454 loss=261.489075 err=7.498128
I 2015-05-27 01:31:34 theanets.trainer:168 RmsProp 455 loss=260.492279 err=6.797090
I 2015-05-27 01:31:45 theanets.trainer:168 RmsProp 456 loss=261.035706 err=7.629821
I 2015-05-27 01:31:55 theanets.trainer:168 RmsProp 457 loss=260.470459 err=7.348901
I 2015-05-27 01:32:06 theanets.trainer:168 RmsProp 458 loss=259.614594 err=6.777323
I 2015-05-27 01:32:16 theanets.trainer:168 RmsProp 459 loss=259.864166 err=7.313048
I 2015-05-27 01:32:27 theanets.trainer:168 RmsProp 460 loss=259.412170 err=7.143572
I 2015-05-27 01:32:27 theanets.trainer:168 validation 46 loss=2724.917480 err=2472.798340 *
I 2015-05-27 01:32:38 theanets.trainer:168 RmsProp 461 loss=259.690979 err=7.703539
I 2015-05-27 01:32:48 theanets.trainer:168 RmsProp 462 loss=259.065857 err=7.353374
I 2015-05-27 01:32:59 theanets.trainer:168 RmsProp 463 loss=258.396667 err=6.958026
I 2015-05-27 01:33:09 theanets.trainer:168 RmsProp 464 loss=258.396912 err=7.232540
I 2015-05-27 01:33:20 theanets.trainer:168 RmsProp 465 loss=257.841187 err=6.952708
I 2015-05-27 01:33:31 theanets.trainer:168 RmsProp 466 loss=257.638763 err=7.029469
I 2015-05-27 01:33:41 theanets.trainer:168 RmsProp 467 loss=257.480377 err=7.145749
I 2015-05-27 01:33:52 theanets.trainer:168 RmsProp 468 loss=257.826233 err=7.763303
I 2015-05-27 01:34:03 theanets.trainer:168 RmsProp 469 loss=256.569580 err=6.774157
I 2015-05-27 01:34:13 theanets.trainer:168 RmsProp 470 loss=256.616943 err=7.094061
I 2015-05-27 01:34:14 theanets.trainer:168 validation 47 loss=2721.190430 err=2471.823486 *
I 2015-05-27 01:34:24 theanets.trainer:168 RmsProp 471 loss=255.945953 err=6.698660
I 2015-05-27 01:34:35 theanets.trainer:168 RmsProp 472 loss=256.098755 err=7.125216
I 2015-05-27 01:34:45 theanets.trainer:168 RmsProp 473 loss=255.822098 err=7.121427
I 2015-05-27 01:34:56 theanets.trainer:168 RmsProp 474 loss=254.967804 err=6.544338
I 2015-05-27 01:35:06 theanets.trainer:168 RmsProp 475 loss=255.497040 err=7.350652
I 2015-05-27 01:35:16 theanets.trainer:168 RmsProp 476 loss=255.303879 err=7.430290
I 2015-05-27 01:35:27 theanets.trainer:168 RmsProp 477 loss=254.384033 err=6.775912
I 2015-05-27 01:35:37 theanets.trainer:168 RmsProp 478 loss=254.254425 err=6.911390
I 2015-05-27 01:35:48 theanets.trainer:168 RmsProp 479 loss=254.058151 err=6.980010
I 2015-05-27 01:35:58 theanets.trainer:168 RmsProp 480 loss=254.159622 err=7.346522
I 2015-05-27 01:35:58 theanets.trainer:168 validation 48 loss=2722.313232 err=2475.646240
I 2015-05-27 01:36:09 theanets.trainer:168 RmsProp 481 loss=253.198563 err=6.649686
I 2015-05-27 01:36:19 theanets.trainer:168 RmsProp 482 loss=253.409225 err=7.122488
I 2015-05-27 01:36:30 theanets.trainer:168 RmsProp 483 loss=253.332123 err=7.308577
I 2015-05-27 01:36:41 theanets.trainer:168 RmsProp 484 loss=252.616531 err=6.858140
I 2015-05-27 01:36:52 theanets.trainer:168 RmsProp 485 loss=252.918732 err=7.422811
I 2015-05-27 01:37:02 theanets.trainer:168 RmsProp 486 loss=252.321075 err=7.082616
I 2015-05-27 01:37:13 theanets.trainer:168 RmsProp 487 loss=251.715820 err=6.737573
I 2015-05-27 01:37:24 theanets.trainer:168 RmsProp 488 loss=251.517731 err=6.798303
I 2015-05-27 01:37:35 theanets.trainer:168 RmsProp 489 loss=251.683990 err=7.228114
I 2015-05-27 01:37:45 theanets.trainer:168 RmsProp 490 loss=250.862671 err=6.666394
I 2015-05-27 01:37:46 theanets.trainer:168 validation 49 loss=2724.929199 err=2480.881348
I 2015-05-27 01:37:57 theanets.trainer:168 RmsProp 491 loss=250.335663 err=6.404329
I 2015-05-27 01:38:08 theanets.trainer:168 RmsProp 492 loss=250.717575 err=7.048213
I 2015-05-27 01:38:18 theanets.trainer:168 RmsProp 493 loss=250.663330 err=7.254222
I 2015-05-27 01:38:29 theanets.trainer:168 RmsProp 494 loss=250.280548 err=7.124526
I 2015-05-27 01:38:40 theanets.trainer:168 RmsProp 495 loss=249.676926 err=6.772324
I 2015-05-27 01:38:51 theanets.trainer:168 RmsProp 496 loss=249.481003 err=6.833433
I 2015-05-27 01:39:01 theanets.trainer:168 RmsProp 497 loss=248.988693 err=6.600219
I 2015-05-27 01:39:12 theanets.trainer:168 RmsProp 498 loss=249.239716 err=7.104677
I 2015-05-27 01:39:22 theanets.trainer:168 RmsProp 499 loss=248.721222 err=6.833906
I 2015-05-27 01:39:33 theanets.trainer:168 RmsProp 500 loss=248.163574 err=6.525469
I 2015-05-27 01:39:33 theanets.trainer:168 validation 50 loss=2719.371338 err=2477.876953 *
I 2015-05-27 01:39:44 theanets.trainer:168 RmsProp 501 loss=248.819824 err=7.433958
I 2015-05-27 01:39:54 theanets.trainer:168 RmsProp 502 loss=247.968475 err=6.830756
I 2015-05-27 01:40:05 theanets.trainer:168 RmsProp 503 loss=247.910233 err=7.019385
I 2015-05-27 01:40:16 theanets.trainer:168 RmsProp 504 loss=248.100540 err=7.454849
I 2015-05-27 01:40:27 theanets.trainer:168 RmsProp 505 loss=247.098923 err=6.695905
I 2015-05-27 01:40:38 theanets.trainer:168 RmsProp 506 loss=246.735687 err=6.579348
I 2015-05-27 01:40:49 theanets.trainer:168 RmsProp 507 loss=246.850311 err=6.939888
I 2015-05-27 01:41:00 theanets.trainer:168 RmsProp 508 loss=246.089447 err=6.422933
I 2015-05-27 01:41:10 theanets.trainer:168 RmsProp 509 loss=245.956085 err=6.531806
I 2015-05-27 01:41:20 theanets.trainer:168 RmsProp 510 loss=246.312714 err=7.136424
I 2015-05-27 01:41:21 theanets.trainer:168 validation 51 loss=2720.748535 err=2481.701904
I 2015-05-27 01:41:31 theanets.trainer:168 RmsProp 511 loss=245.091019 err=6.159516
I 2015-05-27 01:41:42 theanets.trainer:168 RmsProp 512 loss=245.963547 err=7.277562
I 2015-05-27 01:41:52 theanets.trainer:168 RmsProp 513 loss=245.145432 err=6.700982
I 2015-05-27 01:42:02 theanets.trainer:168 RmsProp 514 loss=244.795288 err=6.590631
I 2015-05-27 01:42:12 theanets.trainer:168 RmsProp 515 loss=245.599762 err=7.630197
I 2015-05-27 01:42:22 theanets.trainer:168 RmsProp 516 loss=244.457031 err=6.725125
I 2015-05-27 01:42:32 theanets.trainer:168 RmsProp 517 loss=244.721878 err=7.218259
I 2015-05-27 01:42:42 theanets.trainer:168 RmsProp 518 loss=243.193802 err=5.924713
I 2015-05-27 01:42:52 theanets.trainer:168 RmsProp 519 loss=244.767120 err=7.723886
I 2015-05-27 01:43:02 theanets.trainer:168 RmsProp 520 loss=243.055298 err=6.252055
I 2015-05-27 01:43:03 theanets.trainer:168 validation 52 loss=2712.581543 err=2475.907471 *
I 2015-05-27 01:43:13 theanets.trainer:168 RmsProp 521 loss=243.597412 err=7.022784
I 2015-05-27 01:43:23 theanets.trainer:168 RmsProp 522 loss=243.216751 err=6.877015
I 2015-05-27 01:43:33 theanets.trainer:168 RmsProp 523 loss=243.131058 err=7.020794
I 2015-05-27 01:43:43 theanets.trainer:168 RmsProp 524 loss=242.458984 err=6.581899
I 2015-05-27 01:43:53 theanets.trainer:168 RmsProp 525 loss=242.253571 err=6.605336
I 2015-05-27 01:44:03 theanets.trainer:168 RmsProp 526 loss=242.155273 err=6.737149
I 2015-05-27 01:44:13 theanets.trainer:168 RmsProp 527 loss=242.118408 err=6.931433
I 2015-05-27 01:44:23 theanets.trainer:168 RmsProp 528 loss=241.579254 err=6.618211
I 2015-05-27 01:44:34 theanets.trainer:168 RmsProp 529 loss=241.526535 err=6.795180
I 2015-05-27 01:44:44 theanets.trainer:168 RmsProp 530 loss=241.522552 err=7.014858
I 2015-05-27 01:44:44 theanets.trainer:168 validation 53 loss=2717.503418 err=2483.120117
I 2015-05-27 01:44:55 theanets.trainer:168 RmsProp 531 loss=240.808960 err=6.527077
I 2015-05-27 01:45:05 theanets.trainer:168 RmsProp 532 loss=240.697189 err=6.636353
I 2015-05-27 01:45:15 theanets.trainer:168 RmsProp 533 loss=240.453400 err=6.620803
I 2015-05-27 01:45:25 theanets.trainer:168 RmsProp 534 loss=239.977295 err=6.376914
I 2015-05-27 01:45:36 theanets.trainer:168 RmsProp 535 loss=240.243530 err=6.866325
I 2015-05-27 01:45:46 theanets.trainer:168 RmsProp 536 loss=239.809616 err=6.662743
I 2015-05-27 01:45:57 theanets.trainer:168 RmsProp 537 loss=239.468292 err=6.550683
I 2015-05-27 01:46:07 theanets.trainer:168 RmsProp 538 loss=239.669022 err=6.978163
I 2015-05-27 01:46:17 theanets.trainer:168 RmsProp 539 loss=238.837036 err=6.371396
I 2015-05-27 01:46:27 theanets.trainer:168 RmsProp 540 loss=238.738724 err=6.503015
I 2015-05-27 01:46:28 theanets.trainer:168 validation 54 loss=2721.654297 err=2489.536865
I 2015-05-27 01:46:37 theanets.trainer:168 RmsProp 541 loss=238.471405 err=6.460134
I 2015-05-27 01:46:47 theanets.trainer:168 RmsProp 542 loss=238.750656 err=6.960339
I 2015-05-27 01:46:57 theanets.trainer:168 RmsProp 543 loss=238.408524 err=6.844794
I 2015-05-27 01:47:07 theanets.trainer:168 RmsProp 544 loss=237.220261 err=5.878916
I 2015-05-27 01:47:17 theanets.trainer:168 RmsProp 545 loss=238.192505 err=7.072553
I 2015-05-27 01:47:27 theanets.trainer:168 RmsProp 546 loss=237.101974 err=6.208522
I 2015-05-27 01:47:37 theanets.trainer:168 RmsProp 547 loss=237.583572 err=6.909232
I 2015-05-27 01:47:47 theanets.trainer:168 RmsProp 548 loss=237.576324 err=7.116634
I 2015-05-27 01:47:57 theanets.trainer:168 RmsProp 549 loss=236.719818 err=6.480795
I 2015-05-27 01:48:07 theanets.trainer:168 RmsProp 550 loss=236.509720 err=6.487184
I 2015-05-27 01:48:08 theanets.trainer:168 validation 55 loss=2717.125732 err=2487.219971
I 2015-05-27 01:48:18 theanets.trainer:168 RmsProp 551 loss=236.946289 err=7.142326
I 2015-05-27 01:48:28 theanets.trainer:168 RmsProp 552 loss=236.314056 err=6.724428
I 2015-05-27 01:48:39 theanets.trainer:168 RmsProp 553 loss=236.282501 err=6.898820
I 2015-05-27 01:48:49 theanets.trainer:168 RmsProp 554 loss=235.008331 err=5.839214
I 2015-05-27 01:48:59 theanets.trainer:168 RmsProp 555 loss=236.106125 err=7.153336
I 2015-05-27 01:49:09 theanets.trainer:168 RmsProp 556 loss=235.449677 err=6.708687
I 2015-05-27 01:49:19 theanets.trainer:168 RmsProp 557 loss=234.496979 err=5.973697
I 2015-05-27 01:49:29 theanets.trainer:168 RmsProp 558 loss=234.832031 err=6.523189
I 2015-05-27 01:49:39 theanets.trainer:168 RmsProp 559 loss=234.686035 err=6.598385
I 2015-05-27 01:49:49 theanets.trainer:168 RmsProp 560 loss=234.700653 err=6.826761
I 2015-05-27 01:49:50 theanets.trainer:168 validation 56 loss=2708.456055 err=2480.689941 *
I 2015-05-27 01:49:59 theanets.trainer:168 RmsProp 561 loss=234.458344 err=6.793935
I 2015-05-27 01:50:09 theanets.trainer:168 RmsProp 562 loss=233.852493 err=6.398293
I 2015-05-27 01:50:19 theanets.trainer:168 RmsProp 563 loss=233.653351 err=6.404970
I 2015-05-27 01:50:29 theanets.trainer:168 RmsProp 564 loss=233.548370 err=6.513175
I 2015-05-27 01:50:39 theanets.trainer:168 RmsProp 565 loss=233.297928 err=6.472047
I 2015-05-27 01:50:49 theanets.trainer:168 RmsProp 566 loss=233.267334 err=6.652878
I 2015-05-27 01:50:58 theanets.trainer:168 RmsProp 567 loss=232.875687 err=6.469531
I 2015-05-27 01:51:08 theanets.trainer:168 RmsProp 568 loss=232.876999 err=6.681054
I 2015-05-27 01:51:18 theanets.trainer:168 RmsProp 569 loss=232.403778 err=6.415956
I 2015-05-27 01:51:29 theanets.trainer:168 RmsProp 570 loss=231.897949 err=6.118043
I 2015-05-27 01:51:29 theanets.trainer:168 validation 57 loss=2704.797119 err=2479.134033 *
I 2015-05-27 01:51:39 theanets.trainer:168 RmsProp 571 loss=232.551056 err=6.975342
I 2015-05-27 01:51:50 theanets.trainer:168 RmsProp 572 loss=231.825958 err=6.453366
I 2015-05-27 01:52:00 theanets.trainer:168 RmsProp 573 loss=231.515793 err=6.345562
I 2015-05-27 01:52:10 theanets.trainer:168 RmsProp 574 loss=231.288574 err=6.318370
I 2015-05-27 01:52:21 theanets.trainer:168 RmsProp 575 loss=231.248459 err=6.482890
I 2015-05-27 01:52:31 theanets.trainer:168 RmsProp 576 loss=230.961838 err=6.401550
I 2015-05-27 01:52:41 theanets.trainer:168 RmsProp 577 loss=230.841888 err=6.483218
I 2015-05-27 01:52:51 theanets.trainer:168 RmsProp 578 loss=231.058884 err=6.899378
I 2015-05-27 01:53:01 theanets.trainer:168 RmsProp 579 loss=230.414749 err=6.448146
I 2015-05-27 01:53:11 theanets.trainer:168 RmsProp 580 loss=230.544891 err=6.774989
I 2015-05-27 01:53:12 theanets.trainer:168 validation 58 loss=2701.145264 err=2477.480957 *
I 2015-05-27 01:53:22 theanets.trainer:168 RmsProp 581 loss=230.184967 err=6.606486
I 2015-05-27 01:53:32 theanets.trainer:168 RmsProp 582 loss=229.806961 err=6.420559
I 2015-05-27 01:53:42 theanets.trainer:168 RmsProp 583 loss=229.838867 err=6.648341
I 2015-05-27 01:53:52 theanets.trainer:168 RmsProp 584 loss=229.108643 err=6.115072
I 2015-05-27 01:54:02 theanets.trainer:168 RmsProp 585 loss=229.664093 err=6.868382
I 2015-05-27 01:54:12 theanets.trainer:168 RmsProp 586 loss=229.149979 err=6.544547
I 2015-05-27 01:54:22 theanets.trainer:168 RmsProp 587 loss=229.005539 err=6.594485
I 2015-05-27 01:54:32 theanets.trainer:168 RmsProp 588 loss=228.451370 err=6.230006
I 2015-05-27 01:54:42 theanets.trainer:168 RmsProp 589 loss=228.261551 err=6.232852
I 2015-05-27 01:54:52 theanets.trainer:168 RmsProp 590 loss=227.903931 err=6.066583
I 2015-05-27 01:54:52 theanets.trainer:168 validation 59 loss=2702.253418 err=2480.525879
I 2015-05-27 01:55:02 theanets.trainer:168 RmsProp 591 loss=227.450241 err=5.810437
I 2015-05-27 01:55:12 theanets.trainer:168 RmsProp 592 loss=228.548630 err=7.099514
I 2015-05-27 01:55:22 theanets.trainer:168 RmsProp 593 loss=227.134964 err=5.887580
I 2015-05-27 01:55:32 theanets.trainer:168 RmsProp 594 loss=227.816803 err=6.759592
I 2015-05-27 01:55:43 theanets.trainer:168 RmsProp 595 loss=227.167389 err=6.302170
I 2015-05-27 01:55:53 theanets.trainer:168 RmsProp 596 loss=226.768265 err=6.094850
I 2015-05-27 01:56:02 theanets.trainer:168 RmsProp 597 loss=226.787674 err=6.306178
I 2015-05-27 01:56:12 theanets.trainer:168 RmsProp 598 loss=226.506912 err=6.218193
I 2015-05-27 01:56:22 theanets.trainer:168 RmsProp 599 loss=226.400833 err=6.307195
I 2015-05-27 01:56:32 theanets.trainer:168 RmsProp 600 loss=226.008209 err=6.111864
I 2015-05-27 01:56:33 theanets.trainer:168 validation 60 loss=2702.008545 err=2482.210938
I 2015-05-27 01:56:43 theanets.trainer:168 RmsProp 601 loss=226.144043 err=6.442145
I 2015-05-27 01:56:53 theanets.trainer:168 RmsProp 602 loss=225.801666 err=6.293633
I 2015-05-27 01:57:03 theanets.trainer:168 RmsProp 603 loss=225.637497 err=6.323095
I 2015-05-27 01:57:14 theanets.trainer:168 RmsProp 604 loss=225.127289 err=6.006486
I 2015-05-27 01:57:24 theanets.trainer:168 RmsProp 605 loss=224.930450 err=6.001206
I 2015-05-27 01:57:34 theanets.trainer:168 RmsProp 606 loss=225.512939 err=6.770602
I 2015-05-27 01:57:44 theanets.trainer:168 RmsProp 607 loss=224.678558 err=6.123837
I 2015-05-27 01:57:55 theanets.trainer:168 RmsProp 608 loss=225.206543 err=6.832690
I 2015-05-27 01:58:04 theanets.trainer:168 RmsProp 609 loss=224.326935 err=6.133162
I 2015-05-27 01:58:14 theanets.trainer:168 RmsProp 610 loss=224.252762 err=6.241625
I 2015-05-27 01:58:15 theanets.trainer:168 validation 61 loss=2704.132812 err=2486.227051
I 2015-05-27 01:58:25 theanets.trainer:168 RmsProp 611 loss=224.259109 err=6.432767
I 2015-05-27 01:58:36 theanets.trainer:168 RmsProp 612 loss=224.064697 err=6.422480
I 2015-05-27 01:58:46 theanets.trainer:168 RmsProp 613 loss=223.745773 err=6.289115
I 2015-05-27 01:58:56 theanets.trainer:168 RmsProp 614 loss=223.526520 err=6.259148
I 2015-05-27 01:59:07 theanets.trainer:168 RmsProp 615 loss=223.447586 err=6.366083
I 2015-05-27 01:59:17 theanets.trainer:168 RmsProp 616 loss=222.907990 err=6.013761
I 2015-05-27 01:59:27 theanets.trainer:168 RmsProp 617 loss=223.001617 err=6.294808
I 2015-05-27 01:59:38 theanets.trainer:168 RmsProp 618 loss=222.676117 err=6.156396
I 2015-05-27 01:59:47 theanets.trainer:168 RmsProp 619 loss=222.561401 err=6.223047
I 2015-05-27 01:59:57 theanets.trainer:168 RmsProp 620 loss=222.787674 err=6.631864
I 2015-05-27 01:59:58 theanets.trainer:168 validation 62 loss=2699.372314 err=2483.317627 *
I 2015-05-27 02:00:08 theanets.trainer:168 RmsProp 621 loss=222.340729 err=6.363953
I 2015-05-27 02:00:18 theanets.trainer:168 RmsProp 622 loss=221.502151 err=5.708881
I 2015-05-27 02:00:28 theanets.trainer:168 RmsProp 623 loss=222.609741 err=6.987807
I 2015-05-27 02:00:39 theanets.trainer:168 RmsProp 624 loss=221.981735 err=6.539094
I 2015-05-27 02:00:49 theanets.trainer:168 RmsProp 625 loss=221.251389 err=5.989867
I 2015-05-27 02:00:59 theanets.trainer:168 RmsProp 626 loss=221.259232 err=6.178077
I 2015-05-27 02:01:10 theanets.trainer:168 RmsProp 627 loss=220.775589 err=5.876636
I 2015-05-27 02:01:20 theanets.trainer:168 RmsProp 628 loss=220.963470 err=6.240873
I 2015-05-27 02:01:30 theanets.trainer:168 RmsProp 629 loss=220.474640 err=5.936307
I 2015-05-27 02:01:40 theanets.trainer:168 RmsProp 630 loss=220.324310 err=5.969918
I 2015-05-27 02:01:40 theanets.trainer:168 validation 63 loss=2699.534424 err=2485.271973
I 2015-05-27 02:01:50 theanets.trainer:168 RmsProp 631 loss=220.274460 err=6.100598
I 2015-05-27 02:02:00 theanets.trainer:168 RmsProp 632 loss=220.164948 err=6.173220
I 2015-05-27 02:02:10 theanets.trainer:168 RmsProp 633 loss=219.568115 err=5.756091
I 2015-05-27 02:02:20 theanets.trainer:168 RmsProp 634 loss=220.331055 err=6.695196
I 2015-05-27 02:02:31 theanets.trainer:168 RmsProp 635 loss=219.405472 err=5.942989
I 2015-05-27 02:02:41 theanets.trainer:168 RmsProp 636 loss=219.119781 err=5.832297
I 2015-05-27 02:02:51 theanets.trainer:168 RmsProp 637 loss=219.388214 err=6.276120
I 2015-05-27 02:03:02 theanets.trainer:168 RmsProp 638 loss=219.171295 err=6.233417
I 2015-05-27 02:03:12 theanets.trainer:168 RmsProp 639 loss=218.594147 err=5.829275
I 2015-05-27 02:03:22 theanets.trainer:168 RmsProp 640 loss=218.705566 err=6.111209
I 2015-05-27 02:03:23 theanets.trainer:168 validation 64 loss=2697.337646 err=2484.837646 *
I 2015-05-27 02:03:33 theanets.trainer:168 RmsProp 641 loss=218.698776 err=6.279168
I 2015-05-27 02:03:43 theanets.trainer:168 RmsProp 642 loss=218.293182 err=6.050304
I 2015-05-27 02:03:53 theanets.trainer:168 RmsProp 643 loss=218.426758 err=6.351735
I 2015-05-27 02:04:04 theanets.trainer:168 RmsProp 644 loss=218.096634 err=6.192740
I 2015-05-27 02:04:14 theanets.trainer:168 RmsProp 645 loss=218.203568 err=6.466591
I 2015-05-27 02:04:24 theanets.trainer:168 RmsProp 646 loss=217.866669 err=6.295684
I 2015-05-27 02:04:35 theanets.trainer:168 RmsProp 647 loss=217.458374 err=6.050202
I 2015-05-27 02:04:45 theanets.trainer:168 RmsProp 648 loss=217.261475 err=6.025501
I 2015-05-27 02:04:56 theanets.trainer:168 RmsProp 649 loss=217.258698 err=6.193377
I 2015-05-27 02:05:06 theanets.trainer:168 RmsProp 650 loss=216.858765 err=5.967029
I 2015-05-27 02:05:07 theanets.trainer:168 validation 65 loss=2687.409424 err=2476.617920 *
I 2015-05-27 02:05:17 theanets.trainer:168 RmsProp 651 loss=216.676834 err=5.957428
I 2015-05-27 02:05:28 theanets.trainer:168 RmsProp 652 loss=216.674652 err=6.123979
I 2015-05-27 02:05:38 theanets.trainer:168 RmsProp 653 loss=216.952301 err=6.564264
I 2015-05-27 02:05:49 theanets.trainer:168 RmsProp 654 loss=216.340607 err=6.122917
I 2015-05-27 02:05:59 theanets.trainer:168 RmsProp 655 loss=216.098190 err=6.047818
I 2015-05-27 02:06:09 theanets.trainer:168 RmsProp 656 loss=216.233490 err=6.343869
I 2015-05-27 02:06:20 theanets.trainer:168 RmsProp 657 loss=215.839188 err=6.115339
I 2015-05-27 02:06:30 theanets.trainer:168 RmsProp 658 loss=215.466843 err=5.905041
I 2015-05-27 02:06:40 theanets.trainer:168 RmsProp 659 loss=215.601837 err=6.209495
I 2015-05-27 02:06:51 theanets.trainer:168 RmsProp 660 loss=215.357712 err=6.134526
I 2015-05-27 02:06:51 theanets.trainer:168 validation 66 loss=2690.541748 err=2481.411377
I 2015-05-27 02:07:02 theanets.trainer:168 RmsProp 661 loss=215.040482 err=5.989665
I 2015-05-27 02:07:12 theanets.trainer:168 RmsProp 662 loss=215.011566 err=6.127472
I 2015-05-27 02:07:23 theanets.trainer:168 RmsProp 663 loss=214.459320 err=5.744667
I 2015-05-27 02:07:33 theanets.trainer:168 RmsProp 664 loss=214.117477 err=5.570910
I 2015-05-27 02:07:43 theanets.trainer:168 RmsProp 665 loss=214.878265 err=6.494614
I 2015-05-27 02:07:54 theanets.trainer:168 RmsProp 666 loss=214.465210 err=6.247651
I 2015-05-27 02:08:04 theanets.trainer:168 RmsProp 667 loss=213.675140 err=5.625512
I 2015-05-27 02:08:14 theanets.trainer:168 RmsProp 668 loss=213.875122 err=5.989535
I 2015-05-27 02:08:24 theanets.trainer:168 RmsProp 669 loss=214.017853 err=6.294896
I 2015-05-27 02:08:35 theanets.trainer:168 RmsProp 670 loss=213.420258 err=5.856950
I 2015-05-27 02:08:35 theanets.trainer:168 validation 67 loss=2685.081787 err=2477.603760 *
I 2015-05-27 02:08:46 theanets.trainer:168 RmsProp 671 loss=213.671112 err=6.273973
I 2015-05-27 02:08:56 theanets.trainer:168 RmsProp 672 loss=213.363007 err=6.126690
I 2015-05-27 02:09:06 theanets.trainer:168 RmsProp 673 loss=212.754761 err=5.678279
I 2015-05-27 02:09:17 theanets.trainer:168 RmsProp 674 loss=213.191086 err=6.280578
I 2015-05-27 02:09:27 theanets.trainer:168 RmsProp 675 loss=212.473419 err=5.726554
I 2015-05-27 02:09:38 theanets.trainer:168 RmsProp 676 loss=212.455963 err=5.874665
I 2015-05-27 02:09:47 theanets.trainer:168 RmsProp 677 loss=212.265427 err=5.846292
I 2015-05-27 02:09:57 theanets.trainer:168 RmsProp 678 loss=211.887909 err=5.635338
I 2015-05-27 02:10:07 theanets.trainer:168 RmsProp 679 loss=212.295334 err=6.203515
I 2015-05-27 02:10:17 theanets.trainer:168 RmsProp 680 loss=211.956787 err=6.025836
I 2015-05-27 02:10:18 theanets.trainer:168 validation 68 loss=2694.476318 err=2488.633545
I 2015-05-27 02:10:28 theanets.trainer:168 RmsProp 681 loss=211.538452 err=5.767734
I 2015-05-27 02:10:38 theanets.trainer:168 RmsProp 682 loss=211.202271 err=5.590661
I 2015-05-27 02:10:48 theanets.trainer:168 RmsProp 683 loss=211.512131 err=6.063221
I 2015-05-27 02:10:58 theanets.trainer:168 RmsProp 684 loss=211.385376 err=6.097644
I 2015-05-27 02:11:08 theanets.trainer:168 RmsProp 685 loss=211.066772 err=5.937138
I 2015-05-27 02:11:18 theanets.trainer:168 RmsProp 686 loss=211.023163 err=6.046503
I 2015-05-27 02:11:28 theanets.trainer:168 RmsProp 687 loss=210.855392 err=6.036449
I 2015-05-27 02:11:38 theanets.trainer:168 RmsProp 688 loss=210.415695 err=5.755884
I 2015-05-27 02:11:49 theanets.trainer:168 RmsProp 689 loss=210.766815 err=6.262219
I 2015-05-27 02:11:59 theanets.trainer:168 RmsProp 690 loss=210.242752 err=5.894444
I 2015-05-27 02:12:00 theanets.trainer:168 validation 69 loss=2682.743408 err=2478.472412 *
I 2015-05-27 02:12:10 theanets.trainer:168 RmsProp 691 loss=210.159744 err=5.958841
I 2015-05-27 02:12:20 theanets.trainer:168 RmsProp 692 loss=209.736282 err=5.691424
I 2015-05-27 02:12:30 theanets.trainer:168 RmsProp 693 loss=209.789459 err=5.900914
I 2015-05-27 02:12:41 theanets.trainer:168 RmsProp 694 loss=209.657547 err=5.930436
I 2015-05-27 02:12:51 theanets.trainer:168 RmsProp 695 loss=209.741180 err=6.171741
I 2015-05-27 02:13:02 theanets.trainer:168 RmsProp 696 loss=209.275757 err=5.857129
I 2015-05-27 02:13:12 theanets.trainer:168 RmsProp 697 loss=209.105225 err=5.842180
I 2015-05-27 02:13:22 theanets.trainer:168 RmsProp 698 loss=209.427856 err=6.316092
I 2015-05-27 02:13:32 theanets.trainer:168 RmsProp 699 loss=208.371384 err=5.419656
I 2015-05-27 02:13:43 theanets.trainer:168 RmsProp 700 loss=208.440918 err=5.641885
I 2015-05-27 02:13:43 theanets.trainer:168 validation 70 loss=2687.483398 err=2484.758057
I 2015-05-27 02:13:54 theanets.trainer:168 RmsProp 701 loss=208.522797 err=5.880069
I 2015-05-27 02:14:04 theanets.trainer:168 RmsProp 702 loss=208.347260 err=5.862883
I 2015-05-27 02:14:14 theanets.trainer:168 RmsProp 703 loss=208.961456 err=6.622275
I 2015-05-27 02:14:24 theanets.trainer:168 RmsProp 704 loss=207.983887 err=5.798787
I 2015-05-27 02:14:34 theanets.trainer:168 RmsProp 705 loss=207.925812 err=5.891393
I 2015-05-27 02:14:44 theanets.trainer:168 RmsProp 706 loss=207.738556 err=5.852704
I 2015-05-27 02:14:54 theanets.trainer:168 RmsProp 707 loss=207.593460 err=5.853653
I 2015-05-27 02:15:05 theanets.trainer:168 RmsProp 708 loss=207.425385 err=5.837026
I 2015-05-27 02:15:15 theanets.trainer:168 RmsProp 709 loss=207.313232 err=5.875490
I 2015-05-27 02:15:25 theanets.trainer:168 RmsProp 710 loss=206.866379 err=5.579164
I 2015-05-27 02:15:26 theanets.trainer:168 validation 71 loss=2683.342041 err=2482.129639
I 2015-05-27 02:15:36 theanets.trainer:168 RmsProp 711 loss=207.317230 err=6.182041
I 2015-05-27 02:15:46 theanets.trainer:168 RmsProp 712 loss=206.700882 err=5.713813
I 2015-05-27 02:15:55 theanets.trainer:168 RmsProp 713 loss=206.850616 err=6.011552
I 2015-05-27 02:16:04 theanets.trainer:168 RmsProp 714 loss=206.386139 err=5.692457
I 2015-05-27 02:16:12 theanets.trainer:168 RmsProp 715 loss=206.497101 err=5.951342
I 2015-05-27 02:16:21 theanets.trainer:168 RmsProp 716 loss=206.595337 err=6.193439
I 2015-05-27 02:16:28 theanets.trainer:168 RmsProp 717 loss=205.977142 err=5.719314
I 2015-05-27 02:16:36 theanets.trainer:168 RmsProp 718 loss=206.063690 err=5.956748
I 2015-05-27 02:16:44 theanets.trainer:168 RmsProp 719 loss=206.084503 err=6.123121
I 2015-05-27 02:16:52 theanets.trainer:168 RmsProp 720 loss=205.626633 err=5.812643
I 2015-05-27 02:16:52 theanets.trainer:168 validation 72 loss=2670.842285 err=2471.106445 *
I 2015-05-27 02:17:01 theanets.trainer:168 RmsProp 721 loss=205.681061 err=6.009722
I 2015-05-27 02:17:09 theanets.trainer:168 RmsProp 722 loss=204.961258 err=5.434793
I 2015-05-27 02:17:17 theanets.trainer:168 RmsProp 723 loss=205.205612 err=5.824135
I 2015-05-27 02:17:26 theanets.trainer:168 RmsProp 724 loss=205.305664 err=6.066723
I 2015-05-27 02:17:34 theanets.trainer:168 RmsProp 725 loss=204.931732 err=5.837220
I 2015-05-27 02:17:42 theanets.trainer:168 RmsProp 726 loss=204.796631 err=5.845240
I 2015-05-27 02:17:50 theanets.trainer:168 RmsProp 727 loss=204.270782 err=5.462717
I 2015-05-27 02:17:57 theanets.trainer:168 RmsProp 728 loss=204.599579 err=5.932391
I 2015-05-27 02:18:05 theanets.trainer:168 RmsProp 729 loss=204.545334 err=6.025385
I 2015-05-27 02:18:13 theanets.trainer:168 RmsProp 730 loss=204.739914 err=6.358886
I 2015-05-27 02:18:13 theanets.trainer:168 validation 73 loss=2681.280029 err=2482.977295
I 2015-05-27 02:18:20 theanets.trainer:168 RmsProp 731 loss=203.238785 err=5.004001
I 2015-05-27 02:18:27 theanets.trainer:168 RmsProp 732 loss=204.907379 err=6.810964
I 2015-05-27 02:18:35 theanets.trainer:168 RmsProp 733 loss=203.626572 err=5.670149
I 2015-05-27 02:18:42 theanets.trainer:168 RmsProp 734 loss=203.533264 err=5.715434
I 2015-05-27 02:18:49 theanets.trainer:168 RmsProp 735 loss=203.401352 err=5.726316
I 2015-05-27 02:18:58 theanets.trainer:168 RmsProp 736 loss=203.053650 err=5.520770
I 2015-05-27 02:19:05 theanets.trainer:168 RmsProp 737 loss=203.104553 err=5.709987
I 2015-05-27 02:19:13 theanets.trainer:168 RmsProp 738 loss=203.128799 err=5.871619
I 2015-05-27 02:19:20 theanets.trainer:168 RmsProp 739 loss=202.661407 err=5.546138
I 2015-05-27 02:19:28 theanets.trainer:168 RmsProp 740 loss=202.966278 err=5.991341
I 2015-05-27 02:19:29 theanets.trainer:168 validation 74 loss=2674.435303 err=2477.535889
I 2015-05-27 02:19:36 theanets.trainer:168 RmsProp 741 loss=202.291367 err=5.462636
I 2015-05-27 02:19:44 theanets.trainer:168 RmsProp 742 loss=203.301544 err=6.603824
I 2015-05-27 02:19:52 theanets.trainer:168 RmsProp 743 loss=202.405609 err=5.847106
I 2015-05-27 02:20:00 theanets.trainer:168 RmsProp 744 loss=202.127274 err=5.704282
I 2015-05-27 02:20:08 theanets.trainer:168 RmsProp 745 loss=202.179611 err=5.892564
I 2015-05-27 02:20:16 theanets.trainer:168 RmsProp 746 loss=201.836990 err=5.686631
I 2015-05-27 02:20:24 theanets.trainer:168 RmsProp 747 loss=201.733063 err=5.722003
I 2015-05-27 02:20:32 theanets.trainer:168 RmsProp 748 loss=201.522827 err=5.647061
I 2015-05-27 02:20:40 theanets.trainer:168 RmsProp 749 loss=201.472961 err=5.731732
I 2015-05-27 02:20:47 theanets.trainer:168 RmsProp 750 loss=201.440521 err=5.838102
I 2015-05-27 02:20:48 theanets.trainer:168 validation 75 loss=2676.196533 err=2480.671875
I 2015-05-27 02:20:55 theanets.trainer:168 RmsProp 751 loss=201.140656 err=5.675545
I 2015-05-27 02:21:04 theanets.trainer:168 RmsProp 752 loss=201.108170 err=5.779368
I 2015-05-27 02:21:12 theanets.trainer:168 RmsProp 753 loss=200.715485 err=5.523941
I 2015-05-27 02:21:20 theanets.trainer:168 RmsProp 754 loss=201.577469 err=6.517301
I 2015-05-27 02:21:28 theanets.trainer:168 RmsProp 755 loss=200.644043 err=5.716231
I 2015-05-27 02:21:36 theanets.trainer:168 RmsProp 756 loss=200.409271 err=5.618036
I 2015-05-27 02:21:44 theanets.trainer:168 RmsProp 757 loss=200.112869 err=5.458085
I 2015-05-27 02:21:51 theanets.trainer:168 RmsProp 758 loss=200.635040 err=6.114849
I 2015-05-27 02:21:59 theanets.trainer:168 RmsProp 759 loss=200.267365 err=5.880493
I 2015-05-27 02:22:07 theanets.trainer:168 RmsProp 760 loss=199.953568 err=5.704085
I 2015-05-27 02:22:08 theanets.trainer:168 validation 76 loss=2666.919922 err=2472.738037 *
I 2015-05-27 02:22:16 theanets.trainer:168 RmsProp 761 loss=199.741058 err=5.626041
I 2015-05-27 02:22:24 theanets.trainer:168 RmsProp 762 loss=199.679886 err=5.703945
I 2015-05-27 02:22:31 theanets.trainer:168 RmsProp 763 loss=200.266586 err=6.414233
I 2015-05-27 02:22:39 theanets.trainer:168 RmsProp 764 loss=199.171478 err=5.446748
I 2015-05-27 02:22:47 theanets.trainer:168 RmsProp 765 loss=199.906387 err=6.309472
I 2015-05-27 02:22:56 theanets.trainer:168 RmsProp 766 loss=199.053909 err=5.586750
I 2015-05-27 02:23:04 theanets.trainer:168 RmsProp 767 loss=199.015961 err=5.684920
I 2015-05-27 02:23:12 theanets.trainer:168 RmsProp 768 loss=199.127502 err=5.926301
I 2015-05-27 02:23:20 theanets.trainer:168 RmsProp 769 loss=198.364197 err=5.299774
I 2015-05-27 02:23:28 theanets.trainer:168 RmsProp 770 loss=198.629181 err=5.698027
I 2015-05-27 02:23:28 theanets.trainer:168 validation 77 loss=2667.652588 err=2474.797363
I 2015-05-27 02:23:36 theanets.trainer:168 RmsProp 771 loss=198.529984 err=5.735618
I 2015-05-27 02:23:43 theanets.trainer:168 RmsProp 772 loss=198.123764 err=5.460043
I 2015-05-27 02:23:51 theanets.trainer:168 RmsProp 773 loss=197.958496 err=5.426411
I 2015-05-27 02:23:59 theanets.trainer:168 RmsProp 774 loss=198.422363 err=6.024944
I 2015-05-27 02:24:06 theanets.trainer:168 RmsProp 775 loss=198.041397 err=5.771312
I 2015-05-27 02:24:15 theanets.trainer:168 RmsProp 776 loss=197.528290 err=5.388421
I 2015-05-27 02:24:22 theanets.trainer:168 RmsProp 777 loss=197.480789 err=5.477143
I 2015-05-27 02:24:30 theanets.trainer:168 RmsProp 778 loss=197.685669 err=5.816120
I 2015-05-27 02:24:38 theanets.trainer:168 RmsProp 779 loss=197.740265 err=5.998751
I 2015-05-27 02:24:46 theanets.trainer:168 RmsProp 780 loss=197.572372 err=5.954340
I 2015-05-27 02:24:47 theanets.trainer:168 validation 78 loss=2667.458496 err=2475.913086
I 2015-05-27 02:24:55 theanets.trainer:168 RmsProp 781 loss=197.081390 err=5.595676
I 2015-05-27 02:25:03 theanets.trainer:168 RmsProp 782 loss=197.068604 err=5.709732
I 2015-05-27 02:25:11 theanets.trainer:168 RmsProp 783 loss=196.920929 err=5.690017
I 2015-05-27 02:25:18 theanets.trainer:168 RmsProp 784 loss=197.243576 err=6.138453
I 2015-05-27 02:25:25 theanets.trainer:168 RmsProp 785 loss=196.346298 err=5.368018
I 2015-05-27 02:25:32 theanets.trainer:168 RmsProp 786 loss=196.627594 err=5.776252
I 2015-05-27 02:25:39 theanets.trainer:168 RmsProp 787 loss=196.329376 err=5.604239
I 2015-05-27 02:25:46 theanets.trainer:168 RmsProp 788 loss=195.855972 err=5.261106
I 2015-05-27 02:25:53 theanets.trainer:168 RmsProp 789 loss=196.362900 err=5.894330
I 2015-05-27 02:25:59 theanets.trainer:168 RmsProp 790 loss=195.777649 err=5.439224
I 2015-05-27 02:26:00 theanets.trainer:168 validation 79 loss=2662.765137 err=2472.494629 *
I 2015-05-27 02:26:07 theanets.trainer:168 RmsProp 791 loss=196.286530 err=6.074754
I 2015-05-27 02:26:14 theanets.trainer:168 RmsProp 792 loss=195.595367 err=5.512458
I 2015-05-27 02:26:21 theanets.trainer:168 RmsProp 793 loss=195.404694 err=5.448768
I 2015-05-27 02:26:28 theanets.trainer:168 RmsProp 794 loss=195.733307 err=5.905015
I 2015-05-27 02:26:35 theanets.trainer:168 RmsProp 795 loss=195.215607 err=5.515653
I 2015-05-27 02:26:41 theanets.trainer:168 RmsProp 796 loss=194.947128 err=5.372705
I 2015-05-27 02:26:47 theanets.trainer:168 RmsProp 797 loss=195.596527 err=6.147111
I 2015-05-27 02:26:53 theanets.trainer:168 RmsProp 798 loss=194.889618 err=5.565356
I 2015-05-27 02:26:59 theanets.trainer:168 RmsProp 799 loss=194.811829 err=5.611348
I 2015-05-27 02:27:05 theanets.trainer:168 RmsProp 800 loss=194.119202 err=5.045698
I 2015-05-27 02:27:06 theanets.trainer:168 validation 80 loss=2663.633545 err=2474.635498
I 2015-05-27 02:27:12 theanets.trainer:168 RmsProp 801 loss=194.854782 err=5.908998
I 2015-05-27 02:27:19 theanets.trainer:168 RmsProp 802 loss=194.318863 err=5.494730
I 2015-05-27 02:27:25 theanets.trainer:168 RmsProp 803 loss=194.152695 err=5.456014
I 2015-05-27 02:27:32 theanets.trainer:168 RmsProp 804 loss=194.373398 err=5.805669
I 2015-05-27 02:27:38 theanets.trainer:168 RmsProp 805 loss=194.244949 err=5.797820
I 2015-05-27 02:27:45 theanets.trainer:168 RmsProp 806 loss=194.135361 err=5.807994
I 2015-05-27 02:27:51 theanets.trainer:168 RmsProp 807 loss=193.783051 err=5.578207
I 2015-05-27 02:27:57 theanets.trainer:168 RmsProp 808 loss=193.433838 err=5.345832
I 2015-05-27 02:28:04 theanets.trainer:168 RmsProp 809 loss=193.435181 err=5.473784
I 2015-05-27 02:28:10 theanets.trainer:168 RmsProp 810 loss=194.006088 err=6.163561
I 2015-05-27 02:28:10 theanets.trainer:168 validation 81 loss=2661.598877 err=2473.810791 *
I 2015-05-27 02:28:16 theanets.trainer:168 RmsProp 811 loss=193.525787 err=5.802153
I 2015-05-27 02:28:22 theanets.trainer:168 RmsProp 812 loss=193.149017 err=5.549080
I 2015-05-27 02:28:28 theanets.trainer:168 RmsProp 813 loss=193.184280 err=5.702548
I 2015-05-27 02:28:33 theanets.trainer:168 RmsProp 814 loss=192.737747 err=5.379056
I 2015-05-27 02:28:39 theanets.trainer:168 RmsProp 815 loss=192.672028 err=5.431645
I 2015-05-27 02:28:45 theanets.trainer:168 RmsProp 816 loss=192.561462 err=5.439641
I 2015-05-27 02:28:51 theanets.trainer:168 RmsProp 817 loss=193.207977 err=6.202165
I 2015-05-27 02:28:58 theanets.trainer:168 RmsProp 818 loss=192.112091 err=5.235013
I 2015-05-27 02:29:04 theanets.trainer:168 RmsProp 819 loss=192.531982 err=5.774556
I 2015-05-27 02:29:11 theanets.trainer:168 RmsProp 820 loss=192.220016 err=5.583616
I 2015-05-27 02:29:11 theanets.trainer:168 validation 82 loss=2664.396729 err=2477.827881
I 2015-05-27 02:29:17 theanets.trainer:168 RmsProp 821 loss=192.027420 err=5.514535
I 2015-05-27 02:29:23 theanets.trainer:168 RmsProp 822 loss=191.599442 err=5.208529
I 2015-05-27 02:29:29 theanets.trainer:168 RmsProp 823 loss=191.587311 err=5.317773
I 2015-05-27 02:29:35 theanets.trainer:168 RmsProp 824 loss=191.681534 err=5.530486
I 2015-05-27 02:29:42 theanets.trainer:168 RmsProp 825 loss=191.768753 err=5.736545
I 2015-05-27 02:29:48 theanets.trainer:168 RmsProp 826 loss=191.718674 err=5.803050
I 2015-05-27 02:29:54 theanets.trainer:168 RmsProp 827 loss=191.592529 err=5.796237
I 2015-05-27 02:30:00 theanets.trainer:168 RmsProp 828 loss=191.159058 err=5.484714
I 2015-05-27 02:30:05 theanets.trainer:168 RmsProp 829 loss=191.439575 err=5.881648
I 2015-05-27 02:30:12 theanets.trainer:168 RmsProp 830 loss=190.772324 err=5.333227
I 2015-05-27 02:30:12 theanets.trainer:168 validation 83 loss=2659.368408 err=2473.989014 *
I 2015-05-27 02:30:19 theanets.trainer:168 RmsProp 831 loss=190.570480 err=5.246155
I 2015-05-27 02:30:24 theanets.trainer:168 RmsProp 832 loss=190.624054 err=5.417937
I 2015-05-27 02:30:31 theanets.trainer:168 RmsProp 833 loss=190.281769 err=5.196145
I 2015-05-27 02:30:38 theanets.trainer:168 RmsProp 834 loss=190.778854 err=5.810281
I 2015-05-27 02:30:44 theanets.trainer:168 RmsProp 835 loss=190.445099 err=5.592474
I 2015-05-27 02:30:50 theanets.trainer:168 RmsProp 836 loss=189.997787 err=5.260489
I 2015-05-27 02:30:56 theanets.trainer:168 RmsProp 837 loss=190.020538 err=5.404583
I 2015-05-27 02:31:02 theanets.trainer:168 RmsProp 838 loss=190.100128 err=5.599954
I 2015-05-27 02:31:08 theanets.trainer:168 RmsProp 839 loss=189.365845 err=4.988372
I 2015-05-27 02:31:14 theanets.trainer:168 RmsProp 840 loss=189.820831 err=5.559970
I 2015-05-27 02:31:14 theanets.trainer:168 validation 84 loss=2654.199951 err=2469.995361 *
I 2015-05-27 02:31:20 theanets.trainer:168 RmsProp 841 loss=189.539368 err=5.394513
I 2015-05-27 02:31:26 theanets.trainer:168 RmsProp 842 loss=189.392303 err=5.363730
I 2015-05-27 02:31:32 theanets.trainer:168 RmsProp 843 loss=189.601166 err=5.685258
I 2015-05-27 02:31:38 theanets.trainer:168 RmsProp 844 loss=189.314789 err=5.514658
I 2015-05-27 02:31:45 theanets.trainer:168 RmsProp 845 loss=189.137039 err=5.452633
I 2015-05-27 02:31:50 theanets.trainer:168 RmsProp 846 loss=189.203537 err=5.637064
I 2015-05-27 02:31:57 theanets.trainer:168 RmsProp 847 loss=188.850098 err=5.399179
I 2015-05-27 02:32:03 theanets.trainer:168 RmsProp 848 loss=188.755997 err=5.419297
I 2015-05-27 02:32:09 theanets.trainer:168 RmsProp 849 loss=188.879227 err=5.654704
I 2015-05-27 02:32:15 theanets.trainer:168 RmsProp 850 loss=188.618149 err=5.506168
I 2015-05-27 02:32:16 theanets.trainer:168 validation 85 loss=2653.030029 err=2469.981201 *
I 2015-05-27 02:32:22 theanets.trainer:168 RmsProp 851 loss=187.965302 err=4.970873
I 2015-05-27 02:32:28 theanets.trainer:168 RmsProp 852 loss=188.473480 err=5.591610
I 2015-05-27 02:32:35 theanets.trainer:168 RmsProp 853 loss=188.501068 err=5.728988
I 2015-05-27 02:32:41 theanets.trainer:168 RmsProp 854 loss=188.078766 err=5.420892
I 2015-05-27 02:32:48 theanets.trainer:168 RmsProp 855 loss=188.197235 err=5.656223
I 2015-05-27 02:32:54 theanets.trainer:168 RmsProp 856 loss=188.104843 err=5.678758
I 2015-05-27 02:33:00 theanets.trainer:168 RmsProp 857 loss=187.748062 err=5.434409
I 2015-05-27 02:33:06 theanets.trainer:168 RmsProp 858 loss=187.549164 err=5.348269
I 2015-05-27 02:33:12 theanets.trainer:168 RmsProp 859 loss=187.435745 err=5.344154
I 2015-05-27 02:33:18 theanets.trainer:168 RmsProp 860 loss=187.428314 err=5.452374
I 2015-05-27 02:33:18 theanets.trainer:168 validation 86 loss=2662.166260 err=2480.242920
I 2015-05-27 02:33:24 theanets.trainer:168 RmsProp 861 loss=187.253815 err=5.388925
I 2015-05-27 02:33:30 theanets.trainer:168 RmsProp 862 loss=187.365875 err=5.612713
I 2015-05-27 02:33:36 theanets.trainer:168 RmsProp 863 loss=187.353058 err=5.710556
I 2015-05-27 02:33:43 theanets.trainer:168 RmsProp 864 loss=186.625656 err=5.093083
I 2015-05-27 02:33:49 theanets.trainer:168 RmsProp 865 loss=186.982452 err=5.560168
I 2015-05-27 02:33:55 theanets.trainer:168 RmsProp 866 loss=186.733810 err=5.419213
I 2015-05-27 02:34:01 theanets.trainer:168 RmsProp 867 loss=186.836533 err=5.635096
I 2015-05-27 02:34:07 theanets.trainer:168 RmsProp 868 loss=186.516632 err=5.423336
I 2015-05-27 02:34:13 theanets.trainer:168 RmsProp 869 loss=186.278351 err=5.296893
I 2015-05-27 02:34:20 theanets.trainer:168 RmsProp 870 loss=185.951508 err=5.081725
I 2015-05-27 02:34:20 theanets.trainer:168 validation 87 loss=2653.993408 err=2473.174316
I 2015-05-27 02:34:26 theanets.trainer:168 RmsProp 871 loss=186.244308 err=5.483456
I 2015-05-27 02:34:32 theanets.trainer:168 RmsProp 872 loss=186.464508 err=5.815888
I 2015-05-27 02:34:38 theanets.trainer:168 RmsProp 873 loss=185.687866 err=5.151408
I 2015-05-27 02:34:44 theanets.trainer:168 RmsProp 874 loss=186.056976 err=5.631860
I 2015-05-27 02:34:50 theanets.trainer:168 RmsProp 875 loss=185.670746 err=5.354138
I 2015-05-27 02:34:57 theanets.trainer:168 RmsProp 876 loss=185.386368 err=5.178605
I 2015-05-27 02:35:02 theanets.trainer:168 RmsProp 877 loss=185.392059 err=5.295423
I 2015-05-27 02:35:08 theanets.trainer:168 RmsProp 878 loss=185.653152 err=5.665604
I 2015-05-27 02:35:14 theanets.trainer:168 RmsProp 879 loss=185.138763 err=5.256517
I 2015-05-27 02:35:20 theanets.trainer:168 RmsProp 880 loss=185.193726 err=5.417322
I 2015-05-27 02:35:21 theanets.trainer:168 validation 88 loss=2658.231934 err=2478.513428
I 2015-05-27 02:35:27 theanets.trainer:168 RmsProp 881 loss=184.830887 err=5.167670
I 2015-05-27 02:35:33 theanets.trainer:168 RmsProp 882 loss=185.350235 err=5.792872
I 2015-05-27 02:35:40 theanets.trainer:168 RmsProp 883 loss=184.952896 err=5.500389
I 2015-05-27 02:35:46 theanets.trainer:168 RmsProp 884 loss=184.382523 err=5.042249
I 2015-05-27 02:35:52 theanets.trainer:168 RmsProp 885 loss=184.668213 err=5.432852
I 2015-05-27 02:35:58 theanets.trainer:168 RmsProp 886 loss=184.483002 err=5.359338
I 2015-05-27 02:36:04 theanets.trainer:168 RmsProp 887 loss=184.739075 err=5.720708
I 2015-05-27 02:36:10 theanets.trainer:168 RmsProp 888 loss=184.662338 err=5.750798
I 2015-05-27 02:36:16 theanets.trainer:168 RmsProp 889 loss=184.227463 err=5.419856
I 2015-05-27 02:36:23 theanets.trainer:168 RmsProp 890 loss=184.616364 err=5.912491
I 2015-05-27 02:36:23 theanets.trainer:168 validation 89 loss=2646.803955 err=2468.164307 *
I 2015-05-27 02:36:29 theanets.trainer:168 RmsProp 891 loss=183.751266 err=5.153834
I 2015-05-27 02:36:35 theanets.trainer:168 RmsProp 892 loss=183.796494 err=5.299486
I 2015-05-27 02:36:41 theanets.trainer:168 RmsProp 893 loss=183.292892 err=4.911220
I 2015-05-27 02:36:47 theanets.trainer:168 RmsProp 894 loss=184.196426 err=5.911812
I 2015-05-27 02:36:53 theanets.trainer:168 RmsProp 895 loss=183.451874 err=5.279994
I 2015-05-27 02:36:59 theanets.trainer:168 RmsProp 896 loss=183.266388 err=5.196618
I 2015-05-27 02:37:06 theanets.trainer:168 RmsProp 897 loss=183.173065 err=5.209478
I 2015-05-27 02:37:12 theanets.trainer:168 RmsProp 898 loss=183.344330 err=5.491585
I 2015-05-27 02:37:18 theanets.trainer:168 RmsProp 899 loss=183.185944 err=5.438730
I 2015-05-27 02:37:24 theanets.trainer:168 RmsProp 900 loss=183.160416 err=5.516930
I 2015-05-27 02:37:25 theanets.trainer:168 validation 90 loss=2649.761719 err=2472.173340
I 2015-05-27 02:37:31 theanets.trainer:168 RmsProp 901 loss=183.007355 err=5.472026
I 2015-05-27 02:37:38 theanets.trainer:168 RmsProp 902 loss=182.742401 err=5.312985
I 2015-05-27 02:37:45 theanets.trainer:168 RmsProp 903 loss=182.686981 err=5.358695
I 2015-05-27 02:37:51 theanets.trainer:168 RmsProp 904 loss=182.549774 err=5.326344
I 2015-05-27 02:37:58 theanets.trainer:168 RmsProp 905 loss=182.292465 err=5.174421
I 2015-05-27 02:38:04 theanets.trainer:168 RmsProp 906 loss=182.489365 err=5.477948
I 2015-05-27 02:38:10 theanets.trainer:168 RmsProp 907 loss=182.379852 err=5.470220
I 2015-05-27 02:38:16 theanets.trainer:168 RmsProp 908 loss=182.402649 err=5.595711
I 2015-05-27 02:38:22 theanets.trainer:168 RmsProp 909 loss=182.215759 err=5.514653
I 2015-05-27 02:38:28 theanets.trainer:168 RmsProp 910 loss=182.158997 err=5.559052
I 2015-05-27 02:38:29 theanets.trainer:168 validation 91 loss=2640.288330 err=2463.736816 *
I 2015-05-27 02:38:35 theanets.trainer:168 RmsProp 911 loss=181.678619 err=5.175981
I 2015-05-27 02:38:41 theanets.trainer:168 RmsProp 912 loss=181.833130 err=5.437649
I 2015-05-27 02:38:48 theanets.trainer:168 RmsProp 913 loss=181.371979 err=5.081563
I 2015-05-27 02:38:55 theanets.trainer:168 RmsProp 914 loss=181.449463 err=5.267950
I 2015-05-27 02:39:01 theanets.trainer:168 RmsProp 915 loss=181.355576 err=5.273323
I 2015-05-27 02:39:07 theanets.trainer:168 RmsProp 916 loss=181.344147 err=5.361094
I 2015-05-27 02:39:13 theanets.trainer:168 RmsProp 917 loss=181.501038 err=5.620306
I 2015-05-27 02:39:19 theanets.trainer:168 RmsProp 918 loss=181.102005 err=5.323401
I 2015-05-27 02:39:25 theanets.trainer:168 RmsProp 919 loss=180.933075 err=5.259339
I 2015-05-27 02:39:31 theanets.trainer:168 RmsProp 920 loss=181.165680 err=5.589718
I 2015-05-27 02:39:32 theanets.trainer:168 validation 92 loss=2647.138428 err=2471.619141
I 2015-05-27 02:39:37 theanets.trainer:168 RmsProp 921 loss=180.907150 err=5.431154
I 2015-05-27 02:39:44 theanets.trainer:168 RmsProp 922 loss=180.381058 err=5.004430
I 2015-05-27 02:39:50 theanets.trainer:168 RmsProp 923 loss=180.930145 err=5.652359
I 2015-05-27 02:39:57 theanets.trainer:168 RmsProp 924 loss=180.034988 err=4.860648
I 2015-05-27 02:40:03 theanets.trainer:168 RmsProp 925 loss=181.406128 err=6.325212
I 2015-05-27 02:40:10 theanets.trainer:168 RmsProp 926 loss=179.928955 err=4.949533
I 2015-05-27 02:40:16 theanets.trainer:168 RmsProp 927 loss=180.193512 err=5.308784
I 2015-05-27 02:40:22 theanets.trainer:168 RmsProp 928 loss=180.415314 err=5.628987
I 2015-05-27 02:40:28 theanets.trainer:168 RmsProp 929 loss=179.919342 err=5.233908
I 2015-05-27 02:40:35 theanets.trainer:168 RmsProp 930 loss=179.767181 err=5.184611
I 2015-05-27 02:40:35 theanets.trainer:168 validation 93 loss=2640.416016 err=2465.878662
I 2015-05-27 02:40:41 theanets.trainer:168 RmsProp 931 loss=180.233856 err=5.745477
I 2015-05-27 02:40:48 theanets.trainer:168 RmsProp 932 loss=179.815948 err=5.426293
I 2015-05-27 02:40:54 theanets.trainer:168 RmsProp 933 loss=179.306274 err=5.014855
I 2015-05-27 02:41:00 theanets.trainer:168 RmsProp 934 loss=179.126266 err=4.938570
I 2015-05-27 02:41:06 theanets.trainer:168 RmsProp 935 loss=179.494415 err=5.406558
I 2015-05-27 02:41:12 theanets.trainer:168 RmsProp 936 loss=179.332016 err=5.346017
I 2015-05-27 02:41:18 theanets.trainer:168 RmsProp 937 loss=178.915527 err=5.028234
I 2015-05-27 02:41:24 theanets.trainer:168 RmsProp 938 loss=179.399445 err=5.608582
I 2015-05-27 02:41:30 theanets.trainer:168 RmsProp 939 loss=178.904160 err=5.215963
I 2015-05-27 02:41:36 theanets.trainer:168 RmsProp 940 loss=179.020844 err=5.436492
I 2015-05-27 02:41:37 theanets.trainer:168 validation 94 loss=2639.696289 err=2466.165283 *
I 2015-05-27 02:41:43 theanets.trainer:168 RmsProp 941 loss=178.458221 err=4.976849
I 2015-05-27 02:41:49 theanets.trainer:168 RmsProp 942 loss=178.549744 err=5.166991
I 2015-05-27 02:41:56 theanets.trainer:168 RmsProp 943 loss=178.865143 err=5.575761
I 2015-05-27 02:42:02 theanets.trainer:168 RmsProp 944 loss=178.118881 err=4.932594
I 2015-05-27 02:42:08 theanets.trainer:168 RmsProp 945 loss=178.086243 err=4.994679
I 2015-05-27 02:42:14 theanets.trainer:168 RmsProp 946 loss=178.205368 err=5.213435
I 2015-05-27 02:42:20 theanets.trainer:168 RmsProp 947 loss=178.124191 err=5.234485
I 2015-05-27 02:42:27 theanets.trainer:168 RmsProp 948 loss=177.906662 err=5.116621
I 2015-05-27 02:42:33 theanets.trainer:168 RmsProp 949 loss=178.513168 err=5.821078
I 2015-05-27 02:42:39 theanets.trainer:168 RmsProp 950 loss=177.659866 err=5.064647
I 2015-05-27 02:42:39 theanets.trainer:168 validation 95 loss=2638.364502 err=2465.827881 *
I 2015-05-27 02:42:45 theanets.trainer:168 RmsProp 951 loss=177.722382 err=5.231618
I 2015-05-27 02:42:52 theanets.trainer:168 RmsProp 952 loss=177.794281 err=5.396487
I 2015-05-27 02:42:58 theanets.trainer:168 RmsProp 953 loss=177.530151 err=5.229550
I 2015-05-27 02:43:04 theanets.trainer:168 RmsProp 954 loss=177.521683 err=5.316599
I 2015-05-27 02:43:10 theanets.trainer:168 RmsProp 955 loss=177.103821 err=4.992362
I 2015-05-27 02:43:16 theanets.trainer:168 RmsProp 956 loss=177.563202 err=5.553297
I 2015-05-27 02:43:22 theanets.trainer:168 RmsProp 957 loss=177.093231 err=5.177334
I 2015-05-27 02:43:28 theanets.trainer:168 RmsProp 958 loss=177.070389 err=5.251610
I 2015-05-27 02:43:34 theanets.trainer:168 RmsProp 959 loss=177.310516 err=5.590401
I 2015-05-27 02:43:41 theanets.trainer:168 RmsProp 960 loss=176.776596 err=5.149310
I 2015-05-27 02:43:41 theanets.trainer:168 validation 96 loss=2636.387207 err=2464.814209 *
I 2015-05-27 02:43:47 theanets.trainer:168 RmsProp 961 loss=176.537033 err=5.005116
I 2015-05-27 02:43:53 theanets.trainer:168 RmsProp 962 loss=176.909195 err=5.471816
I 2015-05-27 02:43:59 theanets.trainer:168 RmsProp 963 loss=177.082642 err=5.738358
I 2015-05-27 02:44:05 theanets.trainer:168 RmsProp 964 loss=176.475739 err=5.222121
I 2015-05-27 02:44:11 theanets.trainer:168 RmsProp 965 loss=176.519211 err=5.361723
I 2015-05-27 02:44:17 theanets.trainer:168 RmsProp 966 loss=176.137543 err=5.077904
I 2015-05-27 02:44:23 theanets.trainer:168 RmsProp 967 loss=175.953598 err=4.987386
I 2015-05-27 02:44:29 theanets.trainer:168 RmsProp 968 loss=176.141495 err=5.267699
I 2015-05-27 02:44:35 theanets.trainer:168 RmsProp 969 loss=176.038284 err=5.255826
I 2015-05-27 02:44:42 theanets.trainer:168 RmsProp 970 loss=175.902588 err=5.215051
I 2015-05-27 02:44:42 theanets.trainer:168 validation 97 loss=2643.894287 err=2473.260010
I 2015-05-27 02:44:48 theanets.trainer:168 RmsProp 971 loss=175.894623 err=5.299489
I 2015-05-27 02:44:54 theanets.trainer:168 RmsProp 972 loss=175.710815 err=5.211662
I 2015-05-27 02:45:00 theanets.trainer:168 RmsProp 973 loss=175.650665 err=5.243793
I 2015-05-27 02:45:06 theanets.trainer:168 RmsProp 974 loss=175.670135 err=5.353402
I 2015-05-27 02:45:12 theanets.trainer:168 RmsProp 975 loss=175.591309 err=5.368516
I 2015-05-27 02:45:19 theanets.trainer:168 RmsProp 976 loss=174.773407 err=4.646999
I 2015-05-27 02:45:25 theanets.trainer:168 RmsProp 977 loss=175.474731 err=5.442120
I 2015-05-27 02:45:31 theanets.trainer:168 RmsProp 978 loss=175.011536 err=5.077180
I 2015-05-27 02:45:37 theanets.trainer:168 RmsProp 979 loss=174.989777 err=5.150293
I 2015-05-27 02:45:43 theanets.trainer:168 RmsProp 980 loss=175.173309 err=5.426477
I 2015-05-27 02:45:44 theanets.trainer:168 validation 98 loss=2635.328125 err=2465.635742 *
I 2015-05-27 02:45:50 theanets.trainer:168 RmsProp 981 loss=174.782074 err=5.129031
I 2015-05-27 02:45:56 theanets.trainer:168 RmsProp 982 loss=174.765488 err=5.203725
I 2015-05-27 02:46:02 theanets.trainer:168 RmsProp 983 loss=174.754272 err=5.282950
I 2015-05-27 02:46:08 theanets.trainer:168 RmsProp 984 loss=174.735779 err=5.360427
I 2015-05-27 02:46:15 theanets.trainer:168 RmsProp 985 loss=174.454300 err=5.169850
I 2015-05-27 02:46:21 theanets.trainer:168 RmsProp 986 loss=173.920837 err=4.729178
I 2015-05-27 02:46:26 theanets.trainer:168 RmsProp 987 loss=174.566818 err=5.462162
I 2015-05-27 02:46:32 theanets.trainer:168 RmsProp 988 loss=174.353882 err=5.341548
I 2015-05-27 02:46:38 theanets.trainer:168 RmsProp 989 loss=173.995758 err=5.081621
I 2015-05-27 02:46:44 theanets.trainer:168 RmsProp 990 loss=174.057251 err=5.235129
I 2015-05-27 02:46:45 theanets.trainer:168 validation 99 loss=2646.307373 err=2477.533203
I 2015-05-27 02:46:51 theanets.trainer:168 RmsProp 991 loss=173.754349 err=5.027308
I 2015-05-27 02:46:57 theanets.trainer:168 RmsProp 992 loss=173.959625 err=5.320833
I 2015-05-27 02:47:04 theanets.trainer:168 RmsProp 993 loss=174.096344 err=5.546578
I 2015-05-27 02:47:10 theanets.trainer:168 RmsProp 994 loss=173.537308 err=5.076633
I 2015-05-27 02:47:16 theanets.trainer:168 RmsProp 995 loss=173.441010 err=5.076519
I 2015-05-27 02:47:22 theanets.trainer:168 RmsProp 996 loss=172.985779 err=4.716168
I 2015-05-27 02:47:28 theanets.trainer:168 RmsProp 997 loss=174.158783 err=5.971095
I 2015-05-27 02:47:34 theanets.trainer:168 RmsProp 998 loss=172.962006 err=4.868061
I 2015-05-27 02:47:40 theanets.trainer:168 RmsProp 999 loss=173.282059 err=5.275492
I 2015-05-27 02:47:46 theanets.trainer:168 RmsProp 1000 loss=173.024811 err=5.108768
I 2015-05-27 02:47:46 theanets.trainer:168 validation 100 loss=2631.098633 err=2463.228271 *
I 2015-05-27 02:47:52 theanets.trainer:168 RmsProp 1001 loss=172.884995 err=5.055050
I 2015-05-27 02:47:58 theanets.trainer:168 RmsProp 1002 loss=173.291382 err=5.551362
I 2015-05-27 02:48:05 theanets.trainer:168 RmsProp 1003 loss=173.137970 err=5.489810
I 2015-05-27 02:48:11 theanets.trainer:168 RmsProp 1004 loss=172.509613 err=4.954852
I 2015-05-27 02:48:16 theanets.trainer:168 RmsProp 1005 loss=172.821594 err=5.351517
I 2015-05-27 02:48:23 theanets.trainer:168 RmsProp 1006 loss=172.353531 err=4.972436
I 2015-05-27 02:48:29 theanets.trainer:168 RmsProp 1007 loss=172.409225 err=5.116417
I 2015-05-27 02:48:35 theanets.trainer:168 RmsProp 1008 loss=172.417801 err=5.212293
I 2015-05-27 02:48:42 theanets.trainer:168 RmsProp 1009 loss=172.388458 err=5.271828
I 2015-05-27 02:48:49 theanets.trainer:168 RmsProp 1010 loss=172.665497 err=5.635154
I 2015-05-27 02:48:49 theanets.trainer:168 validation 101 loss=2637.785645 err=2470.796875
I 2015-05-27 02:48:55 theanets.trainer:168 RmsProp 1011 loss=172.000305 err=5.055320
I 2015-05-27 02:49:01 theanets.trainer:168 RmsProp 1012 loss=171.810333 err=4.959695
I 2015-05-27 02:49:07 theanets.trainer:168 RmsProp 1013 loss=171.942032 err=5.182504
I 2015-05-27 02:49:13 theanets.trainer:168 RmsProp 1014 loss=171.980560 err=5.312501
I 2015-05-27 02:49:20 theanets.trainer:168 RmsProp 1015 loss=171.795807 err=5.212312
I 2015-05-27 02:49:26 theanets.trainer:168 RmsProp 1016 loss=171.585251 err=5.088803
I 2015-05-27 02:49:32 theanets.trainer:168 RmsProp 1017 loss=171.697662 err=5.288819
I 2015-05-27 02:49:38 theanets.trainer:168 RmsProp 1018 loss=171.300430 err=4.976636
I 2015-05-27 02:49:44 theanets.trainer:168 RmsProp 1019 loss=171.316406 err=5.083508
I 2015-05-27 02:49:50 theanets.trainer:168 RmsProp 1020 loss=171.338715 err=5.191726
I 2015-05-27 02:49:51 theanets.trainer:168 validation 102 loss=2631.865723 err=2465.764404
I 2015-05-27 02:49:57 theanets.trainer:168 RmsProp 1021 loss=171.198044 err=5.136581
I 2015-05-27 02:50:03 theanets.trainer:168 RmsProp 1022 loss=171.187317 err=5.211339
I 2015-05-27 02:50:09 theanets.trainer:168 RmsProp 1023 loss=170.645203 err=4.757289
I 2015-05-27 02:50:15 theanets.trainer:168 RmsProp 1024 loss=171.058807 err=5.256529
I 2015-05-27 02:50:21 theanets.trainer:168 RmsProp 1025 loss=170.768463 err=5.052735
I 2015-05-27 02:50:27 theanets.trainer:168 RmsProp 1026 loss=170.845276 err=5.213829
I 2015-05-27 02:50:34 theanets.trainer:168 RmsProp 1027 loss=170.962631 err=5.411762
I 2015-05-27 02:50:39 theanets.trainer:168 RmsProp 1028 loss=170.195709 err=4.734220
I 2015-05-27 02:50:45 theanets.trainer:168 RmsProp 1029 loss=171.199478 err=5.822693
I 2015-05-27 02:50:51 theanets.trainer:168 RmsProp 1030 loss=170.549301 err=5.259064
I 2015-05-27 02:50:52 theanets.trainer:168 validation 103 loss=2629.789307 err=2464.556641 *
I 2015-05-27 02:50:58 theanets.trainer:168 RmsProp 1031 loss=170.144501 err=4.942093
I 2015-05-27 02:51:04 theanets.trainer:168 RmsProp 1032 loss=170.439972 err=5.321310
I 2015-05-27 02:51:10 theanets.trainer:168 RmsProp 1033 loss=170.174561 err=5.142930
I 2015-05-27 02:51:16 theanets.trainer:168 RmsProp 1034 loss=169.941956 err=4.993836
I 2015-05-27 02:51:22 theanets.trainer:168 RmsProp 1035 loss=170.042679 err=5.174674
I 2015-05-27 02:51:28 theanets.trainer:168 RmsProp 1036 loss=170.322723 err=5.533002
I 2015-05-27 02:51:34 theanets.trainer:168 RmsProp 1037 loss=169.487076 err=4.787255
I 2015-05-27 02:51:40 theanets.trainer:168 RmsProp 1038 loss=169.431290 err=4.822137
I 2015-05-27 02:51:46 theanets.trainer:168 RmsProp 1039 loss=169.635956 err=5.114655
I 2015-05-27 02:51:52 theanets.trainer:168 RmsProp 1040 loss=169.498932 err=5.063369
I 2015-05-27 02:51:53 theanets.trainer:168 validation 104 loss=2633.849854 err=2469.463623
I 2015-05-27 02:51:59 theanets.trainer:168 RmsProp 1041 loss=169.609711 err=5.261178
I 2015-05-27 02:52:06 theanets.trainer:168 RmsProp 1042 loss=169.479126 err=5.214105
I 2015-05-27 02:52:12 theanets.trainer:168 RmsProp 1043 loss=168.935486 err=4.755989
I 2015-05-27 02:52:18 theanets.trainer:168 RmsProp 1044 loss=169.050247 err=4.957509
I 2015-05-27 02:52:24 theanets.trainer:168 RmsProp 1045 loss=169.098083 err=5.095529
I 2015-05-27 02:52:31 theanets.trainer:168 RmsProp 1046 loss=169.010864 err=5.093658
I 2015-05-27 02:52:37 theanets.trainer:168 RmsProp 1047 loss=169.032806 err=5.200574
I 2015-05-27 02:52:43 theanets.trainer:168 RmsProp 1048 loss=168.805023 err=5.051351
I 2015-05-27 02:52:49 theanets.trainer:168 RmsProp 1049 loss=168.728775 err=5.057267
I 2015-05-27 02:52:56 theanets.trainer:168 RmsProp 1050 loss=168.442963 err=4.859800
I 2015-05-27 02:52:56 theanets.trainer:168 validation 105 loss=2636.735352 err=2473.190674
I 2015-05-27 02:53:02 theanets.trainer:168 RmsProp 1051 loss=168.537933 err=5.041450
I 2015-05-27 02:53:09 theanets.trainer:168 RmsProp 1052 loss=168.442337 err=5.028523
I 2015-05-27 02:53:15 theanets.trainer:168 RmsProp 1053 loss=168.630402 err=5.300694
I 2015-05-27 02:53:22 theanets.trainer:168 RmsProp 1054 loss=168.983704 err=5.736687
I 2015-05-27 02:53:28 theanets.trainer:168 RmsProp 1055 loss=168.260910 err=5.093530
I 2015-05-27 02:53:34 theanets.trainer:168 RmsProp 1056 loss=167.835968 err=4.754266
I 2015-05-27 02:53:40 theanets.trainer:168 RmsProp 1057 loss=168.260300 err=5.257772
I 2015-05-27 02:53:46 theanets.trainer:168 RmsProp 1058 loss=167.945282 err=5.024841
I 2015-05-27 02:53:53 theanets.trainer:168 RmsProp 1059 loss=167.824768 err=4.987113
I 2015-05-27 02:54:00 theanets.trainer:168 RmsProp 1060 loss=167.795074 err=5.038220
I 2015-05-27 02:54:00 theanets.trainer:168 validation 106 loss=2620.620117 err=2457.912109 *
I 2015-05-27 02:54:06 theanets.trainer:168 RmsProp 1061 loss=167.690842 err=5.014626
I 2015-05-27 02:54:12 theanets.trainer:168 RmsProp 1062 loss=167.768097 err=5.177438
I 2015-05-27 02:54:18 theanets.trainer:168 RmsProp 1063 loss=167.481537 err=4.976090
I 2015-05-27 02:54:24 theanets.trainer:168 RmsProp 1064 loss=167.615829 err=5.190215
I 2015-05-27 02:54:30 theanets.trainer:168 RmsProp 1065 loss=167.427673 err=5.084151
I 2015-05-27 02:54:37 theanets.trainer:168 RmsProp 1066 loss=167.330704 err=5.070441
I 2015-05-27 02:54:43 theanets.trainer:168 RmsProp 1067 loss=167.595200 err=5.415527
I 2015-05-27 02:54:49 theanets.trainer:168 RmsProp 1068 loss=166.969147 err=4.877021
I 2015-05-27 02:54:55 theanets.trainer:168 RmsProp 1069 loss=167.187988 err=5.173054
I 2015-05-27 02:55:01 theanets.trainer:168 RmsProp 1070 loss=166.951935 err=5.019992
I 2015-05-27 02:55:02 theanets.trainer:168 validation 107 loss=2621.451660 err=2459.568848
I 2015-05-27 02:55:07 theanets.trainer:168 RmsProp 1071 loss=166.971939 err=5.125640
I 2015-05-27 02:55:13 theanets.trainer:168 RmsProp 1072 loss=166.761261 err=4.993142
I 2015-05-27 02:55:20 theanets.trainer:168 RmsProp 1073 loss=166.644287 err=4.961493
I 2015-05-27 02:55:26 theanets.trainer:168 RmsProp 1074 loss=166.785126 err=5.182724
I 2015-05-27 02:55:32 theanets.trainer:168 RmsProp 1075 loss=166.320312 err=4.800285
I 2015-05-27 02:55:38 theanets.trainer:168 RmsProp 1076 loss=166.518677 err=5.076923
I 2015-05-27 02:55:44 theanets.trainer:168 RmsProp 1077 loss=166.405151 err=5.045784
I 2015-05-27 02:55:51 theanets.trainer:168 RmsProp 1078 loss=166.464081 err=5.183216
I 2015-05-27 02:55:57 theanets.trainer:168 RmsProp 1079 loss=166.414062 err=5.214898
I 2015-05-27 02:56:03 theanets.trainer:168 RmsProp 1080 loss=165.816177 err=4.702169
I 2015-05-27 02:56:04 theanets.trainer:168 validation 108 loss=2634.068359 err=2472.984375
I 2015-05-27 02:56:10 theanets.trainer:168 RmsProp 1081 loss=166.109573 err=5.073217
I 2015-05-27 02:56:16 theanets.trainer:168 RmsProp 1082 loss=166.013351 err=5.059015
I 2015-05-27 02:56:23 theanets.trainer:168 RmsProp 1083 loss=166.335373 err=5.452399
I 2015-05-27 02:56:29 theanets.trainer:168 RmsProp 1084 loss=166.099747 err=5.297036
I 2015-05-27 02:56:35 theanets.trainer:168 RmsProp 1085 loss=165.533417 err=4.811851
I 2015-05-27 02:56:41 theanets.trainer:168 RmsProp 1086 loss=165.753326 err=5.116246
I 2015-05-27 02:56:47 theanets.trainer:168 RmsProp 1087 loss=165.655365 err=5.100806
I 2015-05-27 02:56:54 theanets.trainer:168 RmsProp 1088 loss=165.284180 err=4.806132
I 2015-05-27 02:57:00 theanets.trainer:168 RmsProp 1089 loss=165.348541 err=4.949845
I 2015-05-27 02:57:06 theanets.trainer:168 RmsProp 1090 loss=165.422531 err=5.098484
I 2015-05-27 02:57:06 theanets.trainer:168 validation 109 loss=2620.417480 err=2460.130615 *
I 2015-05-27 02:57:12 theanets.trainer:168 RmsProp 1091 loss=165.103271 err=4.858859
I 2015-05-27 02:57:19 theanets.trainer:168 RmsProp 1092 loss=165.179779 err=5.015445
I 2015-05-27 02:57:25 theanets.trainer:168 RmsProp 1093 loss=165.006165 err=4.921891
I 2015-05-27 02:57:31 theanets.trainer:168 RmsProp 1094 loss=165.007919 err=5.006560
I 2015-05-27 02:57:37 theanets.trainer:168 RmsProp 1095 loss=164.857086 err=4.933022
I 2015-05-27 02:57:44 theanets.trainer:168 RmsProp 1096 loss=164.592209 err=4.749697
I 2015-05-27 02:57:50 theanets.trainer:168 RmsProp 1097 loss=164.756088 err=4.995345
I 2015-05-27 02:57:56 theanets.trainer:168 RmsProp 1098 loss=164.511703 err=4.833326
I 2015-05-27 02:58:03 theanets.trainer:168 RmsProp 1099 loss=164.709946 err=5.110092
I 2015-05-27 02:58:09 theanets.trainer:168 RmsProp 1100 loss=164.404999 err=4.889033
I 2015-05-27 02:58:10 theanets.trainer:168 validation 110 loss=2621.695557 err=2462.233887
I 2015-05-27 02:58:16 theanets.trainer:168 RmsProp 1101 loss=164.553665 err=5.118472
I 2015-05-27 02:58:23 theanets.trainer:168 RmsProp 1102 loss=164.034180 err=4.677552
I 2015-05-27 02:58:29 theanets.trainer:168 RmsProp 1103 loss=164.382721 err=5.106385
I 2015-05-27 02:58:35 theanets.trainer:168 RmsProp 1104 loss=163.924881 err=4.724936
I 2015-05-27 02:58:42 theanets.trainer:168 RmsProp 1105 loss=164.274948 err=5.151928
I 2015-05-27 02:58:48 theanets.trainer:168 RmsProp 1106 loss=164.222153 err=5.176875
I 2015-05-27 02:58:55 theanets.trainer:168 RmsProp 1107 loss=164.459381 err=5.487423
I 2015-05-27 02:59:01 theanets.trainer:168 RmsProp 1108 loss=164.026749 err=5.135615
I 2015-05-27 02:59:08 theanets.trainer:168 RmsProp 1109 loss=163.929657 err=5.113652
I 2015-05-27 02:59:14 theanets.trainer:168 RmsProp 1110 loss=163.930145 err=5.191694
I 2015-05-27 02:59:14 theanets.trainer:168 validation 111 loss=2629.392578 err=2470.686768
I 2015-05-27 02:59:20 theanets.trainer:168 RmsProp 1111 loss=163.964569 err=5.299577
I 2015-05-27 02:59:26 theanets.trainer:168 RmsProp 1112 loss=163.528107 err=4.943854
I 2015-05-27 02:59:32 theanets.trainer:168 RmsProp 1113 loss=163.598175 err=5.089256
I 2015-05-27 02:59:39 theanets.trainer:168 RmsProp 1114 loss=163.410645 err=4.979931
I 2015-05-27 02:59:44 theanets.trainer:168 RmsProp 1115 loss=163.494278 err=5.137025
I 2015-05-27 02:59:50 theanets.trainer:168 RmsProp 1116 loss=163.029800 err=4.750381
I 2015-05-27 02:59:56 theanets.trainer:168 RmsProp 1117 loss=163.540817 err=5.334391
I 2015-05-27 03:00:02 theanets.trainer:168 RmsProp 1118 loss=162.695923 err=4.574194
I 2015-05-27 03:00:08 theanets.trainer:168 RmsProp 1119 loss=163.554337 err=5.507457
I 2015-05-27 03:00:13 theanets.trainer:168 RmsProp 1120 loss=162.744156 err=4.775614
I 2015-05-27 03:00:14 theanets.trainer:168 validation 112 loss=2618.663330 err=2460.738770 *
I 2015-05-27 03:00:20 theanets.trainer:168 RmsProp 1121 loss=162.802094 err=4.909785
I 2015-05-27 03:00:26 theanets.trainer:168 RmsProp 1122 loss=162.945908 err=5.130954
I 2015-05-27 03:00:32 theanets.trainer:168 RmsProp 1123 loss=162.414169 err=4.669463
I 2015-05-27 03:00:38 theanets.trainer:168 RmsProp 1124 loss=162.512009 err=4.847093
I 2015-05-27 03:00:44 theanets.trainer:168 RmsProp 1125 loss=162.465347 err=4.878017
I 2015-05-27 03:00:50 theanets.trainer:168 RmsProp 1126 loss=162.152954 err=4.645150
I 2015-05-27 03:00:56 theanets.trainer:168 RmsProp 1127 loss=162.713440 err=5.283484
I 2015-05-27 03:01:02 theanets.trainer:168 RmsProp 1128 loss=162.234711 err=4.879706
I 2015-05-27 03:01:08 theanets.trainer:168 RmsProp 1129 loss=162.155914 err=4.877411
I 2015-05-27 03:01:15 theanets.trainer:168 RmsProp 1130 loss=162.080231 err=4.875301
I 2015-05-27 03:01:15 theanets.trainer:168 validation 113 loss=2613.962402 err=2456.810059 *
I 2015-05-27 03:01:21 theanets.trainer:168 RmsProp 1131 loss=162.309814 err=5.182790
I 2015-05-27 03:01:26 theanets.trainer:168 RmsProp 1132 loss=161.914764 err=4.862860
I 2015-05-27 03:01:32 theanets.trainer:168 RmsProp 1133 loss=161.854858 err=4.879286
I 2015-05-27 03:01:38 theanets.trainer:168 RmsProp 1134 loss=161.888687 err=4.985717
I 2015-05-27 03:01:43 theanets.trainer:168 RmsProp 1135 loss=161.986160 err=5.158614
I 2015-05-27 03:01:49 theanets.trainer:168 RmsProp 1136 loss=161.748077 err=4.996608
I 2015-05-27 03:01:55 theanets.trainer:168 RmsProp 1137 loss=161.744644 err=5.068896
I 2015-05-27 03:02:00 theanets.trainer:168 RmsProp 1138 loss=161.850555 err=5.249743
I 2015-05-27 03:02:06 theanets.trainer:168 RmsProp 1139 loss=161.547714 err=5.018902
I 2015-05-27 03:02:12 theanets.trainer:168 RmsProp 1140 loss=161.000458 err=4.551183
I 2015-05-27 03:02:13 theanets.trainer:168 validation 114 loss=2618.490723 err=2462.073975
I 2015-05-27 03:02:18 theanets.trainer:168 RmsProp 1141 loss=161.434860 err=5.054522
I 2015-05-27 03:02:24 theanets.trainer:168 RmsProp 1142 loss=161.048813 err=4.743102
I 2015-05-27 03:02:30 theanets.trainer:168 RmsProp 1143 loss=161.029327 err=4.802695
I 2015-05-27 03:02:35 theanets.trainer:168 RmsProp 1144 loss=160.795731 err=4.645457
I 2015-05-27 03:02:41 theanets.trainer:168 RmsProp 1145 loss=161.415131 err=5.340254
I 2015-05-27 03:02:46 theanets.trainer:168 RmsProp 1146 loss=161.118958 err=5.117894
I 2015-05-27 03:02:52 theanets.trainer:168 RmsProp 1147 loss=160.773575 err=4.847733
I 2015-05-27 03:02:58 theanets.trainer:168 RmsProp 1148 loss=160.909882 err=5.056171
I 2015-05-27 03:03:03 theanets.trainer:168 RmsProp 1149 loss=160.505219 err=4.723337
I 2015-05-27 03:03:09 theanets.trainer:168 RmsProp 1150 loss=160.517273 err=4.811437
I 2015-05-27 03:03:10 theanets.trainer:168 validation 115 loss=2618.999268 err=2463.337646
I 2015-05-27 03:03:16 theanets.trainer:168 RmsProp 1151 loss=160.539001 err=4.908410
I 2015-05-27 03:03:21 theanets.trainer:168 RmsProp 1152 loss=160.468994 err=4.907293
I 2015-05-27 03:03:28 theanets.trainer:168 RmsProp 1153 loss=160.744141 err=5.251033
I 2015-05-27 03:03:33 theanets.trainer:168 RmsProp 1154 loss=160.800613 err=5.382197
I 2015-05-27 03:03:39 theanets.trainer:168 RmsProp 1155 loss=160.185562 err=4.842454
I 2015-05-27 03:03:45 theanets.trainer:168 RmsProp 1156 loss=159.871384 err=4.604101
I 2015-05-27 03:03:50 theanets.trainer:168 RmsProp 1157 loss=160.069458 err=4.874804
I 2015-05-27 03:03:56 theanets.trainer:168 RmsProp 1158 loss=160.209824 err=5.086569
I 2015-05-27 03:04:02 theanets.trainer:168 RmsProp 1159 loss=159.847351 err=4.794537
I 2015-05-27 03:04:08 theanets.trainer:168 RmsProp 1160 loss=160.006744 err=5.026907
I 2015-05-27 03:04:08 theanets.trainer:168 validation 116 loss=2614.822998 err=2459.877441
I 2015-05-27 03:04:14 theanets.trainer:168 RmsProp 1161 loss=159.853882 err=4.948925
I 2015-05-27 03:04:20 theanets.trainer:168 RmsProp 1162 loss=159.459274 err=4.629649
I 2015-05-27 03:04:26 theanets.trainer:168 RmsProp 1163 loss=159.820053 err=5.057571
I 2015-05-27 03:04:31 theanets.trainer:168 RmsProp 1164 loss=159.553192 err=4.868549
I 2015-05-27 03:04:37 theanets.trainer:168 RmsProp 1165 loss=159.636963 err=5.024635
I 2015-05-27 03:04:44 theanets.trainer:168 RmsProp 1166 loss=159.778854 err=5.237556
I 2015-05-27 03:04:50 theanets.trainer:168 RmsProp 1167 loss=159.615219 err=5.145781
I 2015-05-27 03:04:56 theanets.trainer:168 RmsProp 1168 loss=158.973068 err=4.580625
I 2015-05-27 03:05:02 theanets.trainer:168 RmsProp 1169 loss=159.530884 err=5.206824
I 2015-05-27 03:05:08 theanets.trainer:168 RmsProp 1170 loss=159.284042 err=5.030528
I 2015-05-27 03:05:09 theanets.trainer:168 validation 117 loss=2613.824951 err=2459.614258 *
I 2015-05-27 03:05:13 theanets.trainer:168 RmsProp 1171 loss=158.882782 err=4.702399
I 2015-05-27 03:05:18 theanets.trainer:168 RmsProp 1172 loss=158.767532 err=4.658319
I 2015-05-27 03:05:22 theanets.trainer:168 RmsProp 1173 loss=159.104340 err=5.068629
I 2015-05-27 03:05:27 theanets.trainer:168 RmsProp 1174 loss=158.616867 err=4.649755
I 2015-05-27 03:05:32 theanets.trainer:168 RmsProp 1175 loss=158.985916 err=5.090924
I 2015-05-27 03:05:37 theanets.trainer:168 RmsProp 1176 loss=158.906265 err=5.085372
I 2015-05-27 03:05:42 theanets.trainer:168 RmsProp 1177 loss=158.730774 err=4.979150
I 2015-05-27 03:05:46 theanets.trainer:168 RmsProp 1178 loss=158.607864 err=4.926728
I 2015-05-27 03:05:51 theanets.trainer:168 RmsProp 1179 loss=158.857727 err=5.244659
I 2015-05-27 03:05:56 theanets.trainer:168 RmsProp 1180 loss=158.311508 err=4.768457
I 2015-05-27 03:05:56 theanets.trainer:168 validation 118 loss=2611.102051 err=2457.602295 *
I 2015-05-27 03:06:02 theanets.trainer:168 RmsProp 1181 loss=158.212433 err=4.739857
I 2015-05-27 03:06:07 theanets.trainer:168 RmsProp 1182 loss=158.512573 err=5.111633
I 2015-05-27 03:06:12 theanets.trainer:168 RmsProp 1183 loss=158.104431 err=4.773874
I 2015-05-27 03:06:17 theanets.trainer:168 RmsProp 1184 loss=158.035645 err=4.779895
I 2015-05-27 03:06:22 theanets.trainer:168 RmsProp 1185 loss=157.947998 err=4.765781
I 2015-05-27 03:06:27 theanets.trainer:168 RmsProp 1186 loss=158.209396 err=5.094710
I 2015-05-27 03:06:33 theanets.trainer:168 RmsProp 1187 loss=157.741837 err=4.695697
I 2015-05-27 03:06:39 theanets.trainer:168 RmsProp 1188 loss=157.822479 err=4.844920
I 2015-05-27 03:06:45 theanets.trainer:168 RmsProp 1189 loss=157.946426 err=5.042885
I 2015-05-27 03:06:51 theanets.trainer:168 RmsProp 1190 loss=157.662445 err=4.827785
I 2015-05-27 03:06:51 theanets.trainer:168 validation 119 loss=2611.440674 err=2458.639893
I 2015-05-27 03:06:57 theanets.trainer:168 RmsProp 1191 loss=157.690582 err=4.929325
I 2015-05-27 03:07:03 theanets.trainer:168 RmsProp 1192 loss=157.706894 err=5.016402
I 2015-05-27 03:07:08 theanets.trainer:168 RmsProp 1193 loss=157.606339 err=4.983215
I 2015-05-27 03:07:14 theanets.trainer:168 RmsProp 1194 loss=157.608231 err=5.056271
I 2015-05-27 03:07:19 theanets.trainer:168 RmsProp 1195 loss=157.344818 err=4.860882
I 2015-05-27 03:07:25 theanets.trainer:168 RmsProp 1196 loss=157.090805 err=4.681102
I 2015-05-27 03:07:30 theanets.trainer:168 RmsProp 1197 loss=157.075104 err=4.736053
I 2015-05-27 03:07:36 theanets.trainer:168 RmsProp 1198 loss=157.355881 err=5.084249
I 2015-05-27 03:07:42 theanets.trainer:168 RmsProp 1199 loss=156.879745 err=4.679368
I 2015-05-27 03:07:49 theanets.trainer:168 RmsProp 1200 loss=156.727264 err=4.599751
I 2015-05-27 03:07:49 theanets.trainer:168 validation 120 loss=2612.547119 err=2460.460938
I 2015-05-27 03:07:55 theanets.trainer:168 RmsProp 1201 loss=157.200256 err=5.141170
I 2015-05-27 03:08:00 theanets.trainer:168 RmsProp 1202 loss=156.605225 err=4.612462
I 2015-05-27 03:08:06 theanets.trainer:168 RmsProp 1203 loss=157.040649 err=5.116227
I 2015-05-27 03:08:12 theanets.trainer:168 RmsProp 1204 loss=156.667511 err=4.814514
I 2015-05-27 03:08:18 theanets.trainer:168 RmsProp 1205 loss=156.804840 err=5.020787
I 2015-05-27 03:08:24 theanets.trainer:168 RmsProp 1206 loss=156.489365 err=4.775728
I 2015-05-27 03:08:30 theanets.trainer:168 RmsProp 1207 loss=156.523087 err=4.875309
I 2015-05-27 03:08:36 theanets.trainer:168 RmsProp 1208 loss=156.740692 err=5.156071
I 2015-05-27 03:08:42 theanets.trainer:168 RmsProp 1209 loss=156.311722 err=4.797072
I 2015-05-27 03:08:47 theanets.trainer:168 RmsProp 1210 loss=156.473907 err=5.030011
I 2015-05-27 03:08:48 theanets.trainer:168 validation 121 loss=2617.127197 err=2465.713867
I 2015-05-27 03:08:53 theanets.trainer:168 RmsProp 1211 loss=156.397491 err=5.020154
I 2015-05-27 03:08:59 theanets.trainer:168 RmsProp 1212 loss=155.498566 err=4.192494
I 2015-05-27 03:09:05 theanets.trainer:168 RmsProp 1213 loss=156.112289 err=4.873528
I 2015-05-27 03:09:12 theanets.trainer:168 RmsProp 1214 loss=156.135132 err=4.959980
I 2015-05-27 03:09:18 theanets.trainer:168 RmsProp 1215 loss=156.422333 err=5.314515
I 2015-05-27 03:09:24 theanets.trainer:168 RmsProp 1216 loss=155.996246 err=4.953105
I 2015-05-27 03:09:29 theanets.trainer:168 RmsProp 1217 loss=156.305954 err=5.329093
I 2015-05-27 03:09:35 theanets.trainer:168 RmsProp 1218 loss=155.639328 err=4.732062
I 2015-05-27 03:09:40 theanets.trainer:168 RmsProp 1219 loss=155.727463 err=4.887861
I 2015-05-27 03:09:46 theanets.trainer:168 RmsProp 1220 loss=155.955154 err=5.181899
I 2015-05-27 03:09:46 theanets.trainer:168 validation 122 loss=2612.868896 err=2462.132080
I 2015-05-27 03:09:52 theanets.trainer:168 RmsProp 1221 loss=155.274765 err=4.569777
I 2015-05-27 03:09:57 theanets.trainer:168 RmsProp 1222 loss=155.596649 err=4.958385
I 2015-05-27 03:10:03 theanets.trainer:168 RmsProp 1223 loss=155.519180 err=4.942088
I 2015-05-27 03:10:09 theanets.trainer:168 RmsProp 1224 loss=155.079376 err=4.570469
I 2015-05-27 03:10:14 theanets.trainer:168 RmsProp 1225 loss=155.105103 err=4.667053
I 2015-05-27 03:10:19 theanets.trainer:168 RmsProp 1226 loss=155.327499 err=4.953212
I 2015-05-27 03:10:25 theanets.trainer:168 RmsProp 1227 loss=155.034882 err=4.731015
I 2015-05-27 03:10:31 theanets.trainer:168 RmsProp 1228 loss=155.192352 err=4.952816
I 2015-05-27 03:10:36 theanets.trainer:168 RmsProp 1229 loss=155.041016 err=4.871179
I 2015-05-27 03:10:42 theanets.trainer:168 RmsProp 1230 loss=154.824631 err=4.723808
I 2015-05-27 03:10:42 theanets.trainer:168 validation 123 loss=2605.822754 err=2455.759766 *
I 2015-05-27 03:10:48 theanets.trainer:168 RmsProp 1231 loss=154.863541 err=4.831449
I 2015-05-27 03:10:55 theanets.trainer:168 RmsProp 1232 loss=155.018448 err=5.051156
I 2015-05-27 03:11:01 theanets.trainer:168 RmsProp 1233 loss=154.425766 err=4.524271
I 2015-05-27 03:11:07 theanets.trainer:168 RmsProp 1234 loss=154.718033 err=4.883991
I 2015-05-27 03:11:13 theanets.trainer:168 RmsProp 1235 loss=154.647781 err=4.878032
I 2015-05-27 03:11:19 theanets.trainer:168 RmsProp 1236 loss=154.376129 err=4.676454
I 2015-05-27 03:11:26 theanets.trainer:168 RmsProp 1237 loss=154.983322 err=5.347157
I 2015-05-27 03:11:32 theanets.trainer:168 RmsProp 1238 loss=154.383545 err=4.813895
I 2015-05-27 03:11:37 theanets.trainer:168 RmsProp 1239 loss=154.080124 err=4.576095
I 2015-05-27 03:11:43 theanets.trainer:168 RmsProp 1240 loss=154.192413 err=4.753372
I 2015-05-27 03:11:43 theanets.trainer:168 validation 124 loss=2608.063965 err=2458.655518
I 2015-05-27 03:11:49 theanets.trainer:168 RmsProp 1241 loss=154.260712 err=4.886608
I 2015-05-27 03:11:55 theanets.trainer:168 RmsProp 1242 loss=153.890259 err=4.583941
I 2015-05-27 03:12:01 theanets.trainer:168 RmsProp 1243 loss=154.393341 err=5.152038
I 2015-05-27 03:12:06 theanets.trainer:168 RmsProp 1244 loss=153.421967 err=4.245967
I 2015-05-27 03:12:12 theanets.trainer:168 RmsProp 1245 loss=154.763092 err=5.651424
I 2015-05-27 03:12:18 theanets.trainer:168 RmsProp 1246 loss=154.092255 err=5.043624
I 2015-05-27 03:12:23 theanets.trainer:168 RmsProp 1247 loss=153.694962 err=4.710863
I 2015-05-27 03:12:29 theanets.trainer:168 RmsProp 1248 loss=153.924210 err=5.009484
I 2015-05-27 03:12:34 theanets.trainer:168 RmsProp 1249 loss=153.444061 err=4.592685
I 2015-05-27 03:12:41 theanets.trainer:168 RmsProp 1250 loss=153.765533 err=4.980110
I 2015-05-27 03:12:41 theanets.trainer:168 validation 125 loss=2602.340088 err=2453.587646 *
I 2015-05-27 03:12:47 theanets.trainer:168 RmsProp 1251 loss=153.606491 err=4.884667
I 2015-05-27 03:12:53 theanets.trainer:168 RmsProp 1252 loss=153.278275 err=4.621492
I 2015-05-27 03:12:59 theanets.trainer:168 RmsProp 1253 loss=153.558792 err=4.969693
I 2015-05-27 03:13:06 theanets.trainer:168 RmsProp 1254 loss=153.263458 err=4.741430
I 2015-05-27 03:13:12 theanets.trainer:168 RmsProp 1255 loss=153.393036 err=4.934815
I 2015-05-27 03:13:17 theanets.trainer:168 RmsProp 1256 loss=153.027496 err=4.630464
I 2015-05-27 03:13:23 theanets.trainer:168 RmsProp 1257 loss=152.926620 err=4.596831
I 2015-05-27 03:13:29 theanets.trainer:168 RmsProp 1258 loss=153.013367 err=4.749560
I 2015-05-27 03:13:35 theanets.trainer:168 RmsProp 1259 loss=153.036560 err=4.833545
I 2015-05-27 03:13:41 theanets.trainer:168 RmsProp 1260 loss=152.858826 err=4.719416
I 2015-05-27 03:13:42 theanets.trainer:168 validation 126 loss=2606.007080 err=2457.906006
I 2015-05-27 03:13:47 theanets.trainer:168 RmsProp 1261 loss=152.911209 err=4.838973
I 2015-05-27 03:13:53 theanets.trainer:168 RmsProp 1262 loss=152.762405 err=4.757608
I 2015-05-27 03:13:58 theanets.trainer:168 RmsProp 1263 loss=152.964569 err=5.024227
I 2015-05-27 03:14:04 theanets.trainer:168 RmsProp 1264 loss=152.606720 err=4.729815
I 2015-05-27 03:14:09 theanets.trainer:168 RmsProp 1265 loss=152.920731 err=5.107511
I 2015-05-27 03:14:15 theanets.trainer:168 RmsProp 1266 loss=152.193512 err=4.448575
I 2015-05-27 03:14:20 theanets.trainer:168 RmsProp 1267 loss=152.983337 err=5.291708
I 2015-05-27 03:14:25 theanets.trainer:168 RmsProp 1268 loss=152.311798 err=4.685975
I 2015-05-27 03:14:32 theanets.trainer:168 RmsProp 1269 loss=152.368286 err=4.815033
I 2015-05-27 03:14:38 theanets.trainer:168 RmsProp 1270 loss=152.227005 err=4.734971
I 2015-05-27 03:14:39 theanets.trainer:168 validation 127 loss=2611.772705 err=2464.315674
I 2015-05-27 03:14:44 theanets.trainer:168 RmsProp 1271 loss=151.984650 err=4.554237
I 2015-05-27 03:14:50 theanets.trainer:168 RmsProp 1272 loss=152.167511 err=4.800048
I 2015-05-27 03:14:57 theanets.trainer:168 RmsProp 1273 loss=152.184341 err=4.879629
I 2015-05-27 03:15:03 theanets.trainer:168 RmsProp 1274 loss=152.042755 err=4.800423
I 2015-05-27 03:15:09 theanets.trainer:168 RmsProp 1275 loss=151.901413 err=4.721103
I 2015-05-27 03:15:15 theanets.trainer:168 RmsProp 1276 loss=151.941559 err=4.827416
I 2015-05-27 03:15:21 theanets.trainer:168 RmsProp 1277 loss=151.718781 err=4.667315
I 2015-05-27 03:15:27 theanets.trainer:168 RmsProp 1278 loss=151.842850 err=4.856670
I 2015-05-27 03:15:33 theanets.trainer:168 RmsProp 1279 loss=152.141388 err=5.211783
I 2015-05-27 03:15:39 theanets.trainer:168 RmsProp 1280 loss=151.656128 err=4.786737
I 2015-05-27 03:15:40 theanets.trainer:168 validation 128 loss=2615.786865 err=2468.948975
I 2015-05-27 03:15:46 theanets.trainer:168 RmsProp 1281 loss=151.791443 err=4.989211
I 2015-05-27 03:15:52 theanets.trainer:168 RmsProp 1282 loss=151.187057 err=4.452319
I 2015-05-27 03:15:57 theanets.trainer:168 RmsProp 1283 loss=152.025848 err=5.344583
I 2015-05-27 03:16:03 theanets.trainer:168 RmsProp 1284 loss=151.278900 err=4.660609
I 2015-05-27 03:16:09 theanets.trainer:168 RmsProp 1285 loss=151.324295 err=4.769483
I 2015-05-27 03:16:14 theanets.trainer:168 RmsProp 1286 loss=151.055389 err=4.564359
I 2015-05-27 03:16:20 theanets.trainer:168 RmsProp 1287 loss=151.376755 err=4.946573
I 2015-05-27 03:16:26 theanets.trainer:168 RmsProp 1288 loss=151.101074 err=4.730954
I 2015-05-27 03:16:33 theanets.trainer:168 RmsProp 1289 loss=150.957794 err=4.652083
I 2015-05-27 03:16:39 theanets.trainer:168 RmsProp 1290 loss=151.237579 err=4.998646
I 2015-05-27 03:16:39 theanets.trainer:168 validation 129 loss=2599.082275 err=2452.873047 *
I 2015-05-27 03:16:45 theanets.trainer:168 RmsProp 1291 loss=150.748459 err=4.567039
I 2015-05-27 03:16:51 theanets.trainer:168 RmsProp 1292 loss=150.812302 err=4.694129
I 2015-05-27 03:16:57 theanets.trainer:168 RmsProp 1293 loss=150.765869 err=4.710636
I 2015-05-27 03:17:03 theanets.trainer:168 RmsProp 1294 loss=150.889618 err=4.896754
I 2015-05-27 03:17:10 theanets.trainer:168 RmsProp 1295 loss=150.768433 err=4.838934
I 2015-05-27 03:17:16 theanets.trainer:168 RmsProp 1296 loss=150.617142 err=4.749641
I 2015-05-27 03:17:22 theanets.trainer:168 RmsProp 1297 loss=150.640411 err=4.829508
I 2015-05-27 03:17:28 theanets.trainer:168 RmsProp 1298 loss=150.163162 err=4.415041
I 2015-05-27 03:17:33 theanets.trainer:168 RmsProp 1299 loss=150.505768 err=4.821778
I 2015-05-27 03:17:39 theanets.trainer:168 RmsProp 1300 loss=150.933441 err=5.305653
I 2015-05-27 03:17:39 theanets.trainer:168 validation 130 loss=2599.676514 err=2454.081055
I 2015-05-27 03:17:45 theanets.trainer:168 RmsProp 1301 loss=150.238556 err=4.674078
I 2015-05-27 03:17:50 theanets.trainer:168 RmsProp 1302 loss=150.290985 err=4.790650
I 2015-05-27 03:17:56 theanets.trainer:168 RmsProp 1303 loss=150.429810 err=4.991589
I 2015-05-27 03:18:02 theanets.trainer:168 RmsProp 1304 loss=150.169601 err=4.788981
I 2015-05-27 03:18:09 theanets.trainer:168 RmsProp 1305 loss=149.782990 err=4.462327
I 2015-05-27 03:18:15 theanets.trainer:168 RmsProp 1306 loss=150.039673 err=4.781666
I 2015-05-27 03:18:21 theanets.trainer:168 RmsProp 1307 loss=149.954254 err=4.753720
I 2015-05-27 03:18:27 theanets.trainer:168 RmsProp 1308 loss=150.056580 err=4.914778
I 2015-05-27 03:18:34 theanets.trainer:168 RmsProp 1309 loss=149.731552 err=4.652141
I 2015-05-27 03:18:40 theanets.trainer:168 RmsProp 1310 loss=150.048157 err=5.028900
I 2015-05-27 03:18:41 theanets.trainer:168 validation 131 loss=2614.962402 err=2469.974609
I 2015-05-27 03:18:46 theanets.trainer:168 RmsProp 1311 loss=150.170837 err=5.212451
I 2015-05-27 03:18:52 theanets.trainer:168 RmsProp 1312 loss=149.311752 err=4.412854
I 2015-05-27 03:18:59 theanets.trainer:168 RmsProp 1313 loss=149.570251 err=4.732032
I 2015-05-27 03:19:05 theanets.trainer:168 RmsProp 1314 loss=149.869797 err=5.086074
I 2015-05-27 03:19:11 theanets.trainer:168 RmsProp 1315 loss=149.490799 err=4.766482
I 2015-05-27 03:19:17 theanets.trainer:168 RmsProp 1316 loss=149.091949 err=4.429890
I 2015-05-27 03:19:23 theanets.trainer:168 RmsProp 1317 loss=149.570923 err=4.974051
I 2015-05-27 03:19:30 theanets.trainer:168 RmsProp 1318 loss=149.287567 err=4.749290
I 2015-05-27 03:19:35 theanets.trainer:168 RmsProp 1319 loss=149.326416 err=4.844362
I 2015-05-27 03:19:40 theanets.trainer:168 RmsProp 1320 loss=149.174454 err=4.752074
I 2015-05-27 03:19:41 theanets.trainer:168 validation 132 loss=2600.848877 err=2456.460938
I 2015-05-27 03:19:47 theanets.trainer:168 RmsProp 1321 loss=148.881927 err=4.522103
I 2015-05-27 03:19:53 theanets.trainer:168 RmsProp 1322 loss=148.903442 err=4.602337
I 2015-05-27 03:19:59 theanets.trainer:168 RmsProp 1323 loss=148.956543 err=4.713484
I 2015-05-27 03:20:05 theanets.trainer:168 RmsProp 1324 loss=148.903366 err=4.722932
I 2015-05-27 03:20:10 theanets.trainer:168 RmsProp 1325 loss=148.763229 err=4.641412
I 2015-05-27 03:20:16 theanets.trainer:168 RmsProp 1326 loss=149.087723 err=5.023388
I 2015-05-27 03:20:21 theanets.trainer:168 RmsProp 1327 loss=148.636505 err=4.633582
I 2015-05-27 03:20:27 theanets.trainer:168 RmsProp 1328 loss=148.926834 err=4.983312
I 2015-05-27 03:20:32 theanets.trainer:168 RmsProp 1329 loss=148.505539 err=4.622179
I 2015-05-27 03:20:38 theanets.trainer:168 RmsProp 1330 loss=148.767014 err=4.940701
I 2015-05-27 03:20:38 theanets.trainer:168 validation 133 loss=2601.637695 err=2457.840820
I 2015-05-27 03:20:44 theanets.trainer:168 RmsProp 1331 loss=148.619095 err=4.851979
I 2015-05-27 03:20:51 theanets.trainer:168 RmsProp 1332 loss=148.942688 err=5.233028
I 2015-05-27 03:20:57 theanets.trainer:168 RmsProp 1333 loss=148.131744 err=4.481240
I 2015-05-27 03:21:03 theanets.trainer:168 RmsProp 1334 loss=148.121063 err=4.532205
I 2015-05-27 03:21:08 theanets.trainer:168 RmsProp 1335 loss=148.503815 err=4.973805
I 2015-05-27 03:21:14 theanets.trainer:168 RmsProp 1336 loss=148.184128 err=4.712880
I 2015-05-27 03:21:19 theanets.trainer:168 RmsProp 1337 loss=147.986557 err=4.573498
I 2015-05-27 03:21:25 theanets.trainer:168 RmsProp 1338 loss=147.918030 err=4.566439
I 2015-05-27 03:21:30 theanets.trainer:168 RmsProp 1339 loss=148.207611 err=4.914807
I 2015-05-27 03:21:36 theanets.trainer:168 RmsProp 1340 loss=148.136124 err=4.901509
I 2015-05-27 03:21:36 theanets.trainer:168 validation 134 loss=2610.901367 err=2467.695312
I 2015-05-27 03:21:36 theanets.trainer:252 patience elapsed!
I 2015-05-27 03:21:36 theanets.main:237 models_deep_post_code_sep/95125-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 03:21:36 theanets.graph:477 models_deep_post_code_sep/95125-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
