I 2015-05-26 03:35:25 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 03:35:25 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95126-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl
I 2015-05-26 03:35:25 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 03:35:25 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 03:35:25 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 03:35:25 theanets.main:89 --batch_size = 1024
I 2015-05-26 03:35:25 theanets.main:89 --gradient_clip = 1
I 2015-05-26 03:35:25 theanets.main:89 --hidden_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 03:35:25 theanets.main:89 --train_batches = 30
I 2015-05-26 03:35:25 theanets.main:89 --valid_batches = 3
I 2015-05-26 03:35:25 theanets.main:89 --weight_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --weight_l2 = None
I 2015-05-26 03:35:25 theanets.trainer:134 compiling evaluation function
I 2015-05-26 03:35:41 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 03:38:56 theanets.trainer:168 validation 0 loss=14156.687500 err=14156.687500 *
I 2015-05-26 03:39:54 theanets.trainer:168 RmsProp 1 loss=13183.159180 err=13183.159180
I 2015-05-26 03:40:53 theanets.trainer:168 RmsProp 2 loss=12985.591797 err=12985.591797
I 2015-05-26 03:41:53 theanets.trainer:168 RmsProp 3 loss=12228.187500 err=12228.187500
I 2015-05-26 03:42:52 theanets.trainer:168 RmsProp 4 loss=10973.736328 err=10973.736328
I 2015-05-26 03:43:50 theanets.trainer:168 RmsProp 5 loss=10333.215820 err=10333.215820
I 2015-05-26 03:44:48 theanets.trainer:168 RmsProp 6 loss=9482.223633 err=9482.223633
I 2015-05-26 03:45:47 theanets.trainer:168 RmsProp 7 loss=8597.849609 err=8597.849609
I 2015-05-26 03:46:46 theanets.trainer:168 RmsProp 8 loss=7927.693359 err=7927.693359
I 2015-05-26 03:47:44 theanets.trainer:168 RmsProp 9 loss=8027.772949 err=8027.772949
I 2015-05-26 03:48:43 theanets.trainer:168 RmsProp 10 loss=8770.245117 err=8770.245117
I 2015-05-26 03:48:44 theanets.trainer:168 validation 1 loss=6842.312500 err=6842.312500 *
I 2015-05-26 03:49:43 theanets.trainer:168 RmsProp 11 loss=8095.931152 err=8095.931152
I 2015-05-26 03:50:42 theanets.trainer:168 RmsProp 12 loss=7669.341797 err=7669.341797
I 2015-05-26 03:51:42 theanets.trainer:168 RmsProp 13 loss=6937.437012 err=6937.437012
I 2015-05-26 03:52:42 theanets.trainer:168 RmsProp 14 loss=6139.658691 err=6139.658691
I 2015-05-26 03:53:42 theanets.trainer:168 RmsProp 15 loss=5393.964355 err=5393.964355
I 2015-05-26 03:54:42 theanets.trainer:168 RmsProp 16 loss=4838.440430 err=4838.440430
I 2015-05-26 03:55:41 theanets.trainer:168 RmsProp 17 loss=4388.400391 err=4388.400391
I 2015-05-26 03:56:42 theanets.trainer:168 RmsProp 18 loss=4146.296387 err=4146.296387
I 2015-05-26 03:57:42 theanets.trainer:168 RmsProp 19 loss=3912.117676 err=3912.117676
I 2015-05-26 03:58:41 theanets.trainer:168 RmsProp 20 loss=3622.311035 err=3622.311035
I 2015-05-26 03:58:43 theanets.trainer:168 validation 2 loss=3464.792236 err=3464.792236 *
I 2015-05-26 03:59:41 theanets.trainer:168 RmsProp 21 loss=3465.131592 err=3465.131592
I 2015-05-26 04:00:41 theanets.trainer:168 RmsProp 22 loss=3272.855957 err=3272.855957
I 2015-05-26 04:01:41 theanets.trainer:168 RmsProp 23 loss=3100.380615 err=3100.380615
I 2015-05-26 04:02:41 theanets.trainer:168 RmsProp 24 loss=2943.622070 err=2943.622070
I 2015-05-26 04:03:41 theanets.trainer:168 RmsProp 25 loss=2812.212402 err=2812.212402
I 2015-05-26 04:04:41 theanets.trainer:168 RmsProp 26 loss=2715.566406 err=2715.566406
I 2015-05-26 04:05:40 theanets.trainer:168 RmsProp 27 loss=2587.780518 err=2587.780518
I 2015-05-26 04:06:40 theanets.trainer:168 RmsProp 28 loss=2469.703369 err=2469.703369
I 2015-05-26 04:07:39 theanets.trainer:168 RmsProp 29 loss=2347.327881 err=2347.327881
I 2015-05-26 04:08:39 theanets.trainer:168 RmsProp 30 loss=2288.752441 err=2288.752441
I 2015-05-26 04:08:40 theanets.trainer:168 validation 3 loss=2648.616455 err=2648.616455 *
I 2015-05-26 04:09:40 theanets.trainer:168 RmsProp 31 loss=2167.558350 err=2167.558350
I 2015-05-26 04:10:38 theanets.trainer:168 RmsProp 32 loss=2131.753662 err=2131.753662
I 2015-05-26 04:11:38 theanets.trainer:168 RmsProp 33 loss=2055.040527 err=2055.040527
I 2015-05-26 04:12:35 theanets.trainer:168 RmsProp 34 loss=2007.617554 err=2007.617554
I 2015-05-26 04:13:32 theanets.trainer:168 RmsProp 35 loss=1918.411499 err=1918.411499
I 2015-05-26 04:14:28 theanets.trainer:168 RmsProp 36 loss=1863.919678 err=1863.919678
I 2015-05-26 04:15:23 theanets.trainer:168 RmsProp 37 loss=1797.207031 err=1797.207031
I 2015-05-26 04:16:18 theanets.trainer:168 RmsProp 38 loss=1752.022095 err=1752.022095
I 2015-05-26 04:17:13 theanets.trainer:168 RmsProp 39 loss=1700.528564 err=1700.528564
I 2015-05-26 04:18:08 theanets.trainer:168 RmsProp 40 loss=1657.156738 err=1657.156738
I 2015-05-26 04:18:09 theanets.trainer:168 validation 4 loss=2631.355225 err=2631.355225 *
I 2015-05-26 04:19:05 theanets.trainer:168 RmsProp 41 loss=1627.346802 err=1627.346802
I 2015-05-26 04:20:00 theanets.trainer:168 RmsProp 42 loss=1553.981201 err=1553.981201
I 2015-05-26 04:20:56 theanets.trainer:168 RmsProp 43 loss=1491.195190 err=1491.195190
I 2015-05-26 04:21:53 theanets.trainer:168 RmsProp 44 loss=1450.332642 err=1450.332642
I 2015-05-26 04:22:47 theanets.trainer:168 RmsProp 45 loss=1415.587280 err=1415.587280
I 2015-05-26 04:23:38 theanets.trainer:168 RmsProp 46 loss=1360.105225 err=1360.105225
I 2015-05-26 04:24:30 theanets.trainer:168 RmsProp 47 loss=1348.455200 err=1348.455200
I 2015-05-26 04:25:22 theanets.trainer:168 RmsProp 48 loss=1346.739868 err=1346.739868
I 2015-05-26 04:26:14 theanets.trainer:168 RmsProp 49 loss=1267.346313 err=1267.346313
I 2015-05-26 04:27:07 theanets.trainer:168 RmsProp 50 loss=1267.716553 err=1267.716553
I 2015-05-26 04:27:08 theanets.trainer:168 validation 5 loss=2204.772217 err=2204.772217 *
I 2015-05-26 04:27:59 theanets.trainer:168 RmsProp 51 loss=1203.519409 err=1203.519409
I 2015-05-26 04:28:50 theanets.trainer:168 RmsProp 52 loss=1207.224609 err=1207.224609
I 2015-05-26 04:29:42 theanets.trainer:168 RmsProp 53 loss=1172.912964 err=1172.912964
I 2015-05-26 04:30:33 theanets.trainer:168 RmsProp 54 loss=1157.572998 err=1157.572998
I 2015-05-26 04:31:25 theanets.trainer:168 RmsProp 55 loss=1115.091309 err=1115.091309
I 2015-05-26 04:32:16 theanets.trainer:168 RmsProp 56 loss=1109.626831 err=1109.626831
I 2015-05-26 04:33:07 theanets.trainer:168 RmsProp 57 loss=1061.314453 err=1061.314453
I 2015-05-26 04:33:59 theanets.trainer:168 RmsProp 58 loss=1049.672241 err=1049.672241
I 2015-05-26 04:34:51 theanets.trainer:168 RmsProp 59 loss=1027.715454 err=1027.715454
I 2015-05-26 04:35:43 theanets.trainer:168 RmsProp 60 loss=1032.770630 err=1032.770630
I 2015-05-26 04:35:44 theanets.trainer:168 validation 6 loss=2372.582520 err=2372.582520
I 2015-05-26 04:36:37 theanets.trainer:168 RmsProp 61 loss=985.650940 err=985.650940
I 2015-05-26 04:37:29 theanets.trainer:168 RmsProp 62 loss=961.504089 err=961.504089
I 2015-05-26 04:38:21 theanets.trainer:168 RmsProp 63 loss=928.216736 err=928.216736
I 2015-05-26 04:39:14 theanets.trainer:168 RmsProp 64 loss=937.896423 err=937.896423
I 2015-05-26 04:40:07 theanets.trainer:168 RmsProp 65 loss=956.534851 err=956.534851
I 2015-05-26 04:41:00 theanets.trainer:168 RmsProp 66 loss=949.981689 err=949.981689
I 2015-05-26 04:41:53 theanets.trainer:168 RmsProp 67 loss=962.828369 err=962.828369
I 2015-05-26 04:42:46 theanets.trainer:168 RmsProp 68 loss=908.802979 err=908.802979
I 2015-05-26 04:43:39 theanets.trainer:168 RmsProp 69 loss=904.948669 err=904.948669
I 2015-05-26 04:44:32 theanets.trainer:168 RmsProp 70 loss=852.476135 err=852.476135
I 2015-05-26 04:44:33 theanets.trainer:168 validation 7 loss=2069.363037 err=2069.363037 *
I 2015-05-26 04:45:26 theanets.trainer:168 RmsProp 71 loss=824.012878 err=824.012878
I 2015-05-26 04:46:18 theanets.trainer:168 RmsProp 72 loss=798.547913 err=798.547913
I 2015-05-26 04:47:11 theanets.trainer:168 RmsProp 73 loss=786.074402 err=786.074402
I 2015-05-26 04:48:03 theanets.trainer:168 RmsProp 74 loss=788.682739 err=788.682739
I 2015-05-26 04:48:56 theanets.trainer:168 RmsProp 75 loss=785.819519 err=785.819519
I 2015-05-26 04:49:48 theanets.trainer:168 RmsProp 76 loss=753.109985 err=753.109985
I 2015-05-26 04:50:40 theanets.trainer:168 RmsProp 77 loss=755.911011 err=755.911011
I 2015-05-26 04:51:32 theanets.trainer:168 RmsProp 78 loss=726.785156 err=726.785156
I 2015-05-26 04:52:25 theanets.trainer:168 RmsProp 79 loss=711.404297 err=711.404297
I 2015-05-26 04:53:18 theanets.trainer:168 RmsProp 80 loss=702.879333 err=702.879333
I 2015-05-26 04:53:19 theanets.trainer:168 validation 8 loss=1921.107300 err=1921.107300 *
I 2015-05-26 04:54:11 theanets.trainer:168 RmsProp 81 loss=669.882263 err=669.882263
I 2015-05-26 04:55:03 theanets.trainer:168 RmsProp 82 loss=667.012817 err=667.012817
I 2015-05-26 04:55:53 theanets.trainer:168 RmsProp 83 loss=672.256165 err=672.256165
I 2015-05-26 04:56:44 theanets.trainer:168 RmsProp 84 loss=663.930908 err=663.930908
I 2015-05-26 04:57:34 theanets.trainer:168 RmsProp 85 loss=648.159241 err=648.159241
I 2015-05-26 04:58:25 theanets.trainer:168 RmsProp 86 loss=638.751099 err=638.751099
I 2015-05-26 04:59:16 theanets.trainer:168 RmsProp 87 loss=605.476440 err=605.476440
I 2015-05-26 05:00:07 theanets.trainer:168 RmsProp 88 loss=596.367798 err=596.367798
I 2015-05-26 05:00:58 theanets.trainer:168 RmsProp 89 loss=565.832092 err=565.832092
I 2015-05-26 05:01:49 theanets.trainer:168 RmsProp 90 loss=566.214539 err=566.214539
I 2015-05-26 05:01:50 theanets.trainer:168 validation 9 loss=1854.575806 err=1854.575806 *
I 2015-05-26 05:02:41 theanets.trainer:168 RmsProp 91 loss=573.810303 err=573.810303
I 2015-05-26 05:03:32 theanets.trainer:168 RmsProp 92 loss=568.478149 err=568.478149
I 2015-05-26 05:04:24 theanets.trainer:168 RmsProp 93 loss=544.769409 err=544.769409
I 2015-05-26 05:05:15 theanets.trainer:168 RmsProp 94 loss=522.455627 err=522.455627
I 2015-05-26 05:06:07 theanets.trainer:168 RmsProp 95 loss=512.070251 err=512.070251
I 2015-05-26 05:06:59 theanets.trainer:168 RmsProp 96 loss=508.009857 err=508.009857
I 2015-05-26 05:07:50 theanets.trainer:168 RmsProp 97 loss=499.566193 err=499.566193
I 2015-05-26 05:08:40 theanets.trainer:168 RmsProp 98 loss=493.976624 err=493.976624
I 2015-05-26 05:09:31 theanets.trainer:168 RmsProp 99 loss=481.054108 err=481.054108
I 2015-05-26 05:10:20 theanets.trainer:168 RmsProp 100 loss=473.789551 err=473.789551
I 2015-05-26 05:10:21 theanets.trainer:168 validation 10 loss=1795.392578 err=1795.392578 *
I 2015-05-26 05:11:11 theanets.trainer:168 RmsProp 101 loss=460.604492 err=460.604492
I 2015-05-26 05:11:59 theanets.trainer:168 RmsProp 102 loss=443.186951 err=443.186951
I 2015-05-26 05:12:48 theanets.trainer:168 RmsProp 103 loss=441.664856 err=441.664856
I 2015-05-26 05:13:37 theanets.trainer:168 RmsProp 104 loss=435.816742 err=435.816742
I 2015-05-26 05:14:27 theanets.trainer:168 RmsProp 105 loss=427.404694 err=427.404694
I 2015-05-26 05:15:17 theanets.trainer:168 RmsProp 106 loss=415.386353 err=415.386353
I 2015-05-26 05:16:07 theanets.trainer:168 RmsProp 107 loss=415.048920 err=415.048920
I 2015-05-26 05:16:56 theanets.trainer:168 RmsProp 108 loss=400.882965 err=400.882965
I 2015-05-26 05:17:46 theanets.trainer:168 RmsProp 109 loss=389.389191 err=389.389191
I 2015-05-26 05:18:36 theanets.trainer:168 RmsProp 110 loss=371.903259 err=371.903259
I 2015-05-26 05:18:37 theanets.trainer:168 validation 11 loss=1666.083862 err=1666.083862 *
I 2015-05-26 05:19:26 theanets.trainer:168 RmsProp 111 loss=370.603333 err=370.603333
I 2015-05-26 05:20:15 theanets.trainer:168 RmsProp 112 loss=362.399628 err=362.399628
I 2015-05-26 05:21:05 theanets.trainer:168 RmsProp 113 loss=361.207245 err=361.207245
I 2015-05-26 05:21:55 theanets.trainer:168 RmsProp 114 loss=362.923920 err=362.923920
I 2015-05-26 05:22:45 theanets.trainer:168 RmsProp 115 loss=338.336243 err=338.336243
I 2015-05-26 05:23:35 theanets.trainer:168 RmsProp 116 loss=346.272736 err=346.272736
I 2015-05-26 05:24:25 theanets.trainer:168 RmsProp 117 loss=328.298737 err=328.298737
I 2015-05-26 05:25:14 theanets.trainer:168 RmsProp 118 loss=318.912231 err=318.912231
I 2015-05-26 05:26:04 theanets.trainer:168 RmsProp 119 loss=311.016876 err=311.016876
I 2015-05-26 05:26:53 theanets.trainer:168 RmsProp 120 loss=306.592438 err=306.592438
I 2015-05-26 05:26:54 theanets.trainer:168 validation 12 loss=1586.350464 err=1586.350464 *
I 2015-05-26 05:27:44 theanets.trainer:168 RmsProp 121 loss=300.982788 err=300.982788
I 2015-05-26 05:28:34 theanets.trainer:168 RmsProp 122 loss=299.550293 err=299.550293
I 2015-05-26 05:29:24 theanets.trainer:168 RmsProp 123 loss=290.980408 err=290.980408
I 2015-05-26 05:30:14 theanets.trainer:168 RmsProp 124 loss=284.101959 err=284.101959
I 2015-05-26 05:31:05 theanets.trainer:168 RmsProp 125 loss=276.197327 err=276.197327
I 2015-05-26 05:31:55 theanets.trainer:168 RmsProp 126 loss=269.025360 err=269.025360
I 2015-05-26 05:32:45 theanets.trainer:168 RmsProp 127 loss=263.200409 err=263.200409
I 2015-05-26 05:33:35 theanets.trainer:168 RmsProp 128 loss=257.169037 err=257.169037
I 2015-05-26 05:34:25 theanets.trainer:168 RmsProp 129 loss=251.515732 err=251.515732
I 2015-05-26 05:35:15 theanets.trainer:168 RmsProp 130 loss=246.325363 err=246.325363
I 2015-05-26 05:35:16 theanets.trainer:168 validation 13 loss=1469.425781 err=1469.425781 *
I 2015-05-26 05:36:06 theanets.trainer:168 RmsProp 131 loss=239.385910 err=239.385910
I 2015-05-26 05:36:55 theanets.trainer:168 RmsProp 132 loss=232.551712 err=232.551712
I 2015-05-26 05:37:43 theanets.trainer:168 RmsProp 133 loss=230.465118 err=230.465118
I 2015-05-26 05:38:31 theanets.trainer:168 RmsProp 134 loss=224.791092 err=224.791092
I 2015-05-26 05:39:18 theanets.trainer:168 RmsProp 135 loss=216.693832 err=216.693832
I 2015-05-26 05:40:05 theanets.trainer:168 RmsProp 136 loss=217.599792 err=217.599792
I 2015-05-26 05:40:52 theanets.trainer:168 RmsProp 137 loss=208.322754 err=208.322754
I 2015-05-26 05:41:39 theanets.trainer:168 RmsProp 138 loss=206.478622 err=206.478622
I 2015-05-26 05:42:27 theanets.trainer:168 RmsProp 139 loss=206.093597 err=206.093597
I 2015-05-26 05:43:14 theanets.trainer:168 RmsProp 140 loss=198.459183 err=198.459183
I 2015-05-26 05:43:15 theanets.trainer:168 validation 14 loss=1441.755981 err=1441.755981 *
I 2015-05-26 05:44:02 theanets.trainer:168 RmsProp 141 loss=190.838486 err=190.838486
I 2015-05-26 05:44:50 theanets.trainer:168 RmsProp 142 loss=193.295227 err=193.295227
I 2015-05-26 05:45:37 theanets.trainer:168 RmsProp 143 loss=186.202942 err=186.202942
I 2015-05-26 05:46:25 theanets.trainer:168 RmsProp 144 loss=183.049744 err=183.049744
I 2015-05-26 05:47:13 theanets.trainer:168 RmsProp 145 loss=176.277969 err=176.277969
I 2015-05-26 05:48:01 theanets.trainer:168 RmsProp 146 loss=178.690643 err=178.690643
I 2015-05-26 05:48:48 theanets.trainer:168 RmsProp 147 loss=170.584900 err=170.584900
I 2015-05-26 05:49:36 theanets.trainer:168 RmsProp 148 loss=164.984543 err=164.984543
I 2015-05-26 05:50:24 theanets.trainer:168 RmsProp 149 loss=167.004791 err=167.004791
I 2015-05-26 05:51:12 theanets.trainer:168 RmsProp 150 loss=164.440125 err=164.440125
I 2015-05-26 05:51:13 theanets.trainer:168 validation 15 loss=1368.283691 err=1368.283691 *
I 2015-05-26 05:52:00 theanets.trainer:168 RmsProp 151 loss=155.596252 err=155.596252
I 2015-05-26 05:52:47 theanets.trainer:168 RmsProp 152 loss=153.963074 err=153.963074
I 2015-05-26 05:53:34 theanets.trainer:168 RmsProp 153 loss=148.246826 err=148.246826
I 2015-05-26 05:54:21 theanets.trainer:168 RmsProp 154 loss=145.225891 err=145.225891
I 2015-05-26 05:55:08 theanets.trainer:168 RmsProp 155 loss=143.030716 err=143.030716
I 2015-05-26 05:55:56 theanets.trainer:168 RmsProp 156 loss=142.615997 err=142.615997
I 2015-05-26 05:56:44 theanets.trainer:168 RmsProp 157 loss=133.945801 err=133.945801
I 2015-05-26 05:57:32 theanets.trainer:168 RmsProp 158 loss=135.565491 err=135.565491
I 2015-05-26 05:58:19 theanets.trainer:168 RmsProp 159 loss=129.998108 err=129.998108
I 2015-05-26 05:59:05 theanets.trainer:168 RmsProp 160 loss=126.964134 err=126.964134
I 2015-05-26 05:59:07 theanets.trainer:168 validation 16 loss=1358.951538 err=1358.951538 *
I 2015-05-26 05:59:54 theanets.trainer:168 RmsProp 161 loss=123.447113 err=123.447113
I 2015-05-26 06:00:42 theanets.trainer:168 RmsProp 162 loss=124.008919 err=124.008919
I 2015-05-26 06:01:29 theanets.trainer:168 RmsProp 163 loss=119.831161 err=119.831161
I 2015-05-26 06:02:17 theanets.trainer:168 RmsProp 164 loss=120.638741 err=120.638741
I 2015-05-26 06:03:05 theanets.trainer:168 RmsProp 165 loss=116.512703 err=116.512703
I 2015-05-26 06:03:52 theanets.trainer:168 RmsProp 166 loss=112.032761 err=112.032761
I 2015-05-26 06:04:40 theanets.trainer:168 RmsProp 167 loss=111.999046 err=111.999046
I 2015-05-26 06:05:27 theanets.trainer:168 RmsProp 168 loss=109.354988 err=109.354988
I 2015-05-26 06:06:14 theanets.trainer:168 RmsProp 169 loss=107.501411 err=107.501411
I 2015-05-26 06:07:00 theanets.trainer:168 RmsProp 170 loss=103.951180 err=103.951180
I 2015-05-26 06:07:01 theanets.trainer:168 validation 17 loss=1355.454590 err=1355.454590 *
I 2015-05-26 06:07:48 theanets.trainer:168 RmsProp 171 loss=100.761574 err=100.761574
I 2015-05-26 06:08:34 theanets.trainer:168 RmsProp 172 loss=103.561501 err=103.561501
I 2015-05-26 06:09:22 theanets.trainer:168 RmsProp 173 loss=98.416496 err=98.416496
I 2015-05-26 06:10:09 theanets.trainer:168 RmsProp 174 loss=95.998688 err=95.998688
I 2015-05-26 06:10:56 theanets.trainer:168 RmsProp 175 loss=94.329819 err=94.329819
I 2015-05-26 06:11:44 theanets.trainer:168 RmsProp 176 loss=93.551445 err=93.551445
I 2015-05-26 06:12:32 theanets.trainer:168 RmsProp 177 loss=91.519310 err=91.519310
I 2015-05-26 06:13:20 theanets.trainer:168 RmsProp 178 loss=90.172951 err=90.172951
I 2015-05-26 06:14:08 theanets.trainer:168 RmsProp 179 loss=86.250786 err=86.250786
I 2015-05-26 06:14:55 theanets.trainer:168 RmsProp 180 loss=85.145737 err=85.145737
I 2015-05-26 06:14:56 theanets.trainer:168 validation 18 loss=1307.394165 err=1307.394165 *
I 2015-05-26 06:15:44 theanets.trainer:168 RmsProp 181 loss=85.404228 err=85.404228
I 2015-05-26 06:16:31 theanets.trainer:168 RmsProp 182 loss=84.431984 err=84.431984
I 2015-05-26 06:17:19 theanets.trainer:168 RmsProp 183 loss=82.642128 err=82.642128
I 2015-05-26 06:18:08 theanets.trainer:168 RmsProp 184 loss=79.447189 err=79.447189
I 2015-05-26 06:18:55 theanets.trainer:168 RmsProp 185 loss=78.072243 err=78.072243
I 2015-05-26 06:19:43 theanets.trainer:168 RmsProp 186 loss=78.528267 err=78.528267
I 2015-05-26 06:20:29 theanets.trainer:168 RmsProp 187 loss=77.955475 err=77.955475
I 2015-05-26 06:21:16 theanets.trainer:168 RmsProp 188 loss=75.277817 err=75.277817
I 2015-05-26 06:22:03 theanets.trainer:168 RmsProp 189 loss=75.896820 err=75.896820
I 2015-05-26 06:22:51 theanets.trainer:168 RmsProp 190 loss=72.873268 err=72.873268
I 2015-05-26 06:22:52 theanets.trainer:168 validation 19 loss=1273.751221 err=1273.751221 *
I 2015-05-26 06:23:38 theanets.trainer:168 RmsProp 191 loss=70.785919 err=70.785919
I 2015-05-26 06:24:24 theanets.trainer:168 RmsProp 192 loss=68.324699 err=68.324699
I 2015-05-26 06:25:11 theanets.trainer:168 RmsProp 193 loss=68.465912 err=68.465912
I 2015-05-26 06:25:58 theanets.trainer:168 RmsProp 194 loss=66.272545 err=66.272545
I 2015-05-26 06:26:45 theanets.trainer:168 RmsProp 195 loss=67.145508 err=67.145508
I 2015-05-26 06:27:33 theanets.trainer:168 RmsProp 196 loss=64.420235 err=64.420235
I 2015-05-26 06:28:20 theanets.trainer:168 RmsProp 197 loss=63.665184 err=63.665184
I 2015-05-26 06:29:08 theanets.trainer:168 RmsProp 198 loss=61.617195 err=61.617195
I 2015-05-26 06:29:56 theanets.trainer:168 RmsProp 199 loss=62.659237 err=62.659237
I 2015-05-26 06:30:44 theanets.trainer:168 RmsProp 200 loss=64.148636 err=64.148636
I 2015-05-26 06:30:45 theanets.trainer:168 validation 20 loss=1268.515991 err=1268.515991 *
I 2015-05-26 06:31:32 theanets.trainer:168 RmsProp 201 loss=59.818027 err=59.818027
I 2015-05-26 06:32:20 theanets.trainer:168 RmsProp 202 loss=57.812824 err=57.812824
I 2015-05-26 06:33:08 theanets.trainer:168 RmsProp 203 loss=58.866348 err=58.866348
I 2015-05-26 06:33:56 theanets.trainer:168 RmsProp 204 loss=57.608437 err=57.608437
I 2015-05-26 06:34:42 theanets.trainer:168 RmsProp 205 loss=55.632820 err=55.632820
I 2015-05-26 06:35:27 theanets.trainer:168 RmsProp 206 loss=54.438404 err=54.438404
I 2015-05-26 06:36:13 theanets.trainer:168 RmsProp 207 loss=53.965221 err=53.965221
I 2015-05-26 06:36:59 theanets.trainer:168 RmsProp 208 loss=52.442181 err=52.442181
I 2015-05-26 06:37:44 theanets.trainer:168 RmsProp 209 loss=50.366215 err=50.366215
I 2015-05-26 06:38:30 theanets.trainer:168 RmsProp 210 loss=50.980080 err=50.980080
I 2015-05-26 06:38:31 theanets.trainer:168 validation 21 loss=1249.172729 err=1249.172729 *
I 2015-05-26 06:39:17 theanets.trainer:168 RmsProp 211 loss=50.922112 err=50.922112
I 2015-05-26 06:40:02 theanets.trainer:168 RmsProp 212 loss=50.773865 err=50.773865
I 2015-05-26 06:40:45 theanets.trainer:168 RmsProp 213 loss=49.641945 err=49.641945
I 2015-05-26 06:41:29 theanets.trainer:168 RmsProp 214 loss=48.184349 err=48.184349
I 2015-05-26 06:42:12 theanets.trainer:168 RmsProp 215 loss=46.119041 err=46.119041
I 2015-05-26 06:42:54 theanets.trainer:168 RmsProp 216 loss=46.065819 err=46.065819
I 2015-05-26 06:43:37 theanets.trainer:168 RmsProp 217 loss=45.838326 err=45.838326
I 2015-05-26 06:44:20 theanets.trainer:168 RmsProp 218 loss=44.842495 err=44.842495
I 2015-05-26 06:45:03 theanets.trainer:168 RmsProp 219 loss=44.893433 err=44.893433
I 2015-05-26 06:45:46 theanets.trainer:168 RmsProp 220 loss=44.861370 err=44.861370
I 2015-05-26 06:45:47 theanets.trainer:168 validation 22 loss=1262.765137 err=1262.765137
I 2015-05-26 06:46:30 theanets.trainer:168 RmsProp 221 loss=42.729713 err=42.729713
I 2015-05-26 06:47:12 theanets.trainer:168 RmsProp 222 loss=43.442123 err=43.442123
I 2015-05-26 06:47:54 theanets.trainer:168 RmsProp 223 loss=42.200848 err=42.200848
I 2015-05-26 06:48:36 theanets.trainer:168 RmsProp 224 loss=40.163250 err=40.163250
I 2015-05-26 06:49:19 theanets.trainer:168 RmsProp 225 loss=39.560619 err=39.560619
I 2015-05-26 06:50:02 theanets.trainer:168 RmsProp 226 loss=38.472771 err=38.472771
I 2015-05-26 06:50:45 theanets.trainer:168 RmsProp 227 loss=39.514851 err=39.514851
I 2015-05-26 06:51:28 theanets.trainer:168 RmsProp 228 loss=37.958546 err=37.958546
I 2015-05-26 06:52:11 theanets.trainer:168 RmsProp 229 loss=37.791710 err=37.791710
I 2015-05-26 06:52:53 theanets.trainer:168 RmsProp 230 loss=35.914066 err=35.914066
I 2015-05-26 06:52:54 theanets.trainer:168 validation 23 loss=1228.920532 err=1228.920532 *
I 2015-05-26 06:53:36 theanets.trainer:168 RmsProp 231 loss=34.860821 err=34.860821
I 2015-05-26 06:54:18 theanets.trainer:168 RmsProp 232 loss=36.767826 err=36.767826
I 2015-05-26 06:55:00 theanets.trainer:168 RmsProp 233 loss=35.579174 err=35.579174
I 2015-05-26 06:55:44 theanets.trainer:168 RmsProp 234 loss=34.411064 err=34.411064
I 2015-05-26 06:56:27 theanets.trainer:168 RmsProp 235 loss=32.465504 err=32.465504
I 2015-05-26 06:57:10 theanets.trainer:168 RmsProp 236 loss=34.338257 err=34.338257
I 2015-05-26 06:57:49 theanets.trainer:168 RmsProp 237 loss=32.477806 err=32.477806
I 2015-05-26 06:58:28 theanets.trainer:168 RmsProp 238 loss=33.850143 err=33.850143
I 2015-05-26 06:59:05 theanets.trainer:168 RmsProp 239 loss=32.497494 err=32.497494
I 2015-05-26 06:59:44 theanets.trainer:168 RmsProp 240 loss=32.060619 err=32.060619
I 2015-05-26 06:59:44 theanets.trainer:168 validation 24 loss=1243.606445 err=1243.606445
I 2015-05-26 07:00:22 theanets.trainer:168 RmsProp 241 loss=29.993683 err=29.993683
I 2015-05-26 07:00:59 theanets.trainer:168 RmsProp 242 loss=30.783325 err=30.783325
I 2015-05-26 07:01:36 theanets.trainer:168 RmsProp 243 loss=29.204720 err=29.204720
I 2015-05-26 07:02:15 theanets.trainer:168 RmsProp 244 loss=25.666695 err=25.666695
I 2015-05-26 07:02:54 theanets.trainer:168 RmsProp 245 loss=20.572155 err=20.572155
I 2015-05-26 07:03:33 theanets.trainer:168 RmsProp 246 loss=18.210655 err=18.210655
I 2015-05-26 07:04:11 theanets.trainer:168 RmsProp 247 loss=18.310459 err=18.310459
I 2015-05-26 07:04:50 theanets.trainer:168 RmsProp 248 loss=16.962620 err=16.962620
I 2015-05-26 07:05:27 theanets.trainer:168 RmsProp 249 loss=19.481880 err=19.481880
I 2015-05-26 07:06:05 theanets.trainer:168 RmsProp 250 loss=17.895155 err=17.895155
I 2015-05-26 07:06:06 theanets.trainer:168 validation 25 loss=1188.822876 err=1188.822876 *
I 2015-05-26 07:06:44 theanets.trainer:168 RmsProp 251 loss=16.545088 err=16.545088
I 2015-05-26 07:07:23 theanets.trainer:168 RmsProp 252 loss=16.378958 err=16.378958
I 2015-05-26 07:08:02 theanets.trainer:168 RmsProp 253 loss=18.922178 err=18.922178
I 2015-05-26 07:08:41 theanets.trainer:168 RmsProp 254 loss=21.246622 err=21.246622
I 2015-05-26 07:09:20 theanets.trainer:168 RmsProp 255 loss=23.532225 err=23.532225
I 2015-05-26 07:09:58 theanets.trainer:168 RmsProp 256 loss=33.628162 err=33.628162
I 2015-05-26 07:10:37 theanets.trainer:168 RmsProp 257 loss=28.575733 err=28.575733
I 2015-05-26 07:11:16 theanets.trainer:168 RmsProp 258 loss=24.219898 err=24.219898
I 2015-05-26 07:11:54 theanets.trainer:168 RmsProp 259 loss=24.687021 err=24.687021
I 2015-05-26 07:12:31 theanets.trainer:168 RmsProp 260 loss=25.076849 err=25.076849
I 2015-05-26 07:12:32 theanets.trainer:168 validation 26 loss=1181.563599 err=1181.563599 *
I 2015-05-26 07:13:09 theanets.trainer:168 RmsProp 261 loss=23.067282 err=23.067282
I 2015-05-26 07:13:46 theanets.trainer:168 RmsProp 262 loss=22.461855 err=22.461855
I 2015-05-26 07:14:22 theanets.trainer:168 RmsProp 263 loss=22.674744 err=22.674744
I 2015-05-26 07:15:01 theanets.trainer:168 RmsProp 264 loss=20.626936 err=20.626936
I 2015-05-26 07:15:39 theanets.trainer:168 RmsProp 265 loss=23.114298 err=23.114298
I 2015-05-26 07:16:16 theanets.trainer:168 RmsProp 266 loss=20.597790 err=20.597790
I 2015-05-26 07:16:55 theanets.trainer:168 RmsProp 267 loss=19.432899 err=19.432899
I 2015-05-26 07:17:33 theanets.trainer:168 RmsProp 268 loss=19.091976 err=19.091976
I 2015-05-26 07:18:11 theanets.trainer:168 RmsProp 269 loss=21.311655 err=21.311655
I 2015-05-26 07:18:48 theanets.trainer:168 RmsProp 270 loss=19.797878 err=19.797878
I 2015-05-26 07:18:49 theanets.trainer:168 validation 27 loss=1215.078979 err=1215.078979
I 2015-05-26 07:19:28 theanets.trainer:168 RmsProp 271 loss=18.261274 err=18.261274
I 2015-05-26 07:20:07 theanets.trainer:168 RmsProp 272 loss=22.190121 err=22.190121
I 2015-05-26 07:20:45 theanets.trainer:168 RmsProp 273 loss=20.620821 err=20.620821
I 2015-05-26 07:21:23 theanets.trainer:168 RmsProp 274 loss=18.849846 err=18.849846
I 2015-05-26 07:22:02 theanets.trainer:168 RmsProp 275 loss=18.027861 err=18.027861
I 2015-05-26 07:22:40 theanets.trainer:168 RmsProp 276 loss=15.898677 err=15.898677
I 2015-05-26 07:23:19 theanets.trainer:168 RmsProp 277 loss=13.131079 err=13.131079
I 2015-05-26 07:23:58 theanets.trainer:168 RmsProp 278 loss=12.037617 err=12.037617
I 2015-05-26 07:24:37 theanets.trainer:168 RmsProp 279 loss=13.280272 err=13.280272
I 2015-05-26 07:25:14 theanets.trainer:168 RmsProp 280 loss=10.884639 err=10.884639
I 2015-05-26 07:25:14 theanets.trainer:168 validation 28 loss=1166.076416 err=1166.076416 *
I 2015-05-26 07:25:51 theanets.trainer:168 RmsProp 281 loss=10.460368 err=10.460368
I 2015-05-26 07:26:28 theanets.trainer:168 RmsProp 282 loss=10.982774 err=10.982774
I 2015-05-26 07:27:03 theanets.trainer:168 RmsProp 283 loss=11.970398 err=11.970398
I 2015-05-26 07:27:39 theanets.trainer:168 RmsProp 284 loss=11.290302 err=11.290302
I 2015-05-26 07:28:15 theanets.trainer:168 RmsProp 285 loss=10.830126 err=10.830126
I 2015-05-26 07:28:51 theanets.trainer:168 RmsProp 286 loss=9.391946 err=9.391946
I 2015-05-26 07:29:26 theanets.trainer:168 RmsProp 287 loss=8.827403 err=8.827403
I 2015-05-26 07:30:02 theanets.trainer:168 RmsProp 288 loss=9.535233 err=9.535233
I 2015-05-26 07:30:38 theanets.trainer:168 RmsProp 289 loss=8.919054 err=8.919054
I 2015-05-26 07:31:14 theanets.trainer:168 RmsProp 290 loss=8.661198 err=8.661198
I 2015-05-26 07:31:15 theanets.trainer:168 validation 29 loss=1173.457642 err=1173.457642
I 2015-05-26 07:31:49 theanets.trainer:168 RmsProp 291 loss=7.993110 err=7.993110
I 2015-05-26 07:32:24 theanets.trainer:168 RmsProp 292 loss=8.302211 err=8.302211
I 2015-05-26 07:32:58 theanets.trainer:168 RmsProp 293 loss=8.522161 err=8.522161
I 2015-05-26 07:33:33 theanets.trainer:168 RmsProp 294 loss=8.638284 err=8.638284
I 2015-05-26 07:34:09 theanets.trainer:168 RmsProp 295 loss=9.235347 err=9.235347
I 2015-05-26 07:34:44 theanets.trainer:168 RmsProp 296 loss=7.863590 err=7.863590
I 2015-05-26 07:35:20 theanets.trainer:168 RmsProp 297 loss=7.675247 err=7.675247
I 2015-05-26 07:35:55 theanets.trainer:168 RmsProp 298 loss=9.077466 err=9.077466
I 2015-05-26 07:36:30 theanets.trainer:168 RmsProp 299 loss=8.693100 err=8.693100
I 2015-05-26 07:37:06 theanets.trainer:168 RmsProp 300 loss=7.271163 err=7.271163
I 2015-05-26 07:37:07 theanets.trainer:168 validation 30 loss=1212.429321 err=1212.429321
I 2015-05-26 07:37:42 theanets.trainer:168 RmsProp 301 loss=7.670702 err=7.670702
I 2015-05-26 07:38:19 theanets.trainer:168 RmsProp 302 loss=7.713233 err=7.713233
I 2015-05-26 07:38:54 theanets.trainer:168 RmsProp 303 loss=8.281588 err=8.281588
I 2015-05-26 07:39:30 theanets.trainer:168 RmsProp 304 loss=9.450853 err=9.450853
I 2015-05-26 07:40:07 theanets.trainer:168 RmsProp 305 loss=8.308434 err=8.308434
I 2015-05-26 07:40:44 theanets.trainer:168 RmsProp 306 loss=7.814281 err=7.814281
I 2015-05-26 07:41:21 theanets.trainer:168 RmsProp 307 loss=7.842661 err=7.842661
I 2015-05-26 07:41:58 theanets.trainer:168 RmsProp 308 loss=8.071212 err=8.071212
I 2015-05-26 07:42:34 theanets.trainer:168 RmsProp 309 loss=7.929444 err=7.929444
I 2015-05-26 07:43:09 theanets.trainer:168 RmsProp 310 loss=7.488205 err=7.488205
I 2015-05-26 07:43:10 theanets.trainer:168 validation 31 loss=1215.969604 err=1215.969604
I 2015-05-26 07:43:43 theanets.trainer:168 RmsProp 311 loss=6.880793 err=6.880793
I 2015-05-26 07:44:17 theanets.trainer:168 RmsProp 312 loss=6.529363 err=6.529363
I 2015-05-26 07:44:50 theanets.trainer:168 RmsProp 313 loss=7.245731 err=7.245731
I 2015-05-26 07:45:23 theanets.trainer:168 RmsProp 314 loss=6.272078 err=6.272078
I 2015-05-26 07:45:56 theanets.trainer:168 RmsProp 315 loss=7.018323 err=7.018323
I 2015-05-26 07:46:30 theanets.trainer:168 RmsProp 316 loss=7.575005 err=7.575005
I 2015-05-26 07:47:03 theanets.trainer:168 RmsProp 317 loss=7.516527 err=7.516527
I 2015-05-26 07:47:37 theanets.trainer:168 RmsProp 318 loss=7.810694 err=7.810694
I 2015-05-26 07:48:10 theanets.trainer:168 RmsProp 319 loss=6.655496 err=6.655496
I 2015-05-26 07:48:43 theanets.trainer:168 RmsProp 320 loss=6.184877 err=6.184877
I 2015-05-26 07:48:44 theanets.trainer:168 validation 32 loss=1253.666870 err=1253.666870
I 2015-05-26 07:49:16 theanets.trainer:168 RmsProp 321 loss=6.082703 err=6.082703
I 2015-05-26 07:49:48 theanets.trainer:168 RmsProp 322 loss=5.959163 err=5.959163
I 2015-05-26 07:50:19 theanets.trainer:168 RmsProp 323 loss=5.736757 err=5.736757
I 2015-05-26 07:50:50 theanets.trainer:168 RmsProp 324 loss=6.240115 err=6.240115
I 2015-05-26 07:51:22 theanets.trainer:168 RmsProp 325 loss=5.758462 err=5.758462
I 2015-05-26 07:51:53 theanets.trainer:168 RmsProp 326 loss=6.569739 err=6.569739
I 2015-05-26 07:52:26 theanets.trainer:168 RmsProp 327 loss=6.888240 err=6.888240
I 2015-05-26 07:52:59 theanets.trainer:168 RmsProp 328 loss=6.973504 err=6.973504
I 2015-05-26 07:53:32 theanets.trainer:168 RmsProp 329 loss=7.057636 err=7.057636
I 2015-05-26 07:54:05 theanets.trainer:168 RmsProp 330 loss=6.476120 err=6.476120
I 2015-05-26 07:54:06 theanets.trainer:168 validation 33 loss=1276.521973 err=1276.521973
I 2015-05-26 07:54:06 theanets.trainer:252 patience elapsed!
I 2015-05-26 07:54:06 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 07:54:06 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 07:54:06 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 07:54:06 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 07:54:06 theanets.main:89 --batch_size = 1024
I 2015-05-26 07:54:06 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 07:54:06 theanets.main:89 --hidden_l1 = None
I 2015-05-26 07:54:06 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 07:54:06 theanets.main:89 --train_batches = 10
I 2015-05-26 07:54:06 theanets.main:89 --valid_batches = 2
I 2015-05-26 07:54:06 theanets.main:89 --weight_l1 = None
I 2015-05-26 07:54:06 theanets.main:89 --weight_l2 = None
I 2015-05-26 07:54:06 theanets.trainer:134 compiling evaluation function
I 2015-05-26 07:54:15 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 07:55:56 theanets.trainer:168 validation 0 loss=1529.757080 err=1529.757080 *
I 2015-05-26 07:56:07 theanets.trainer:168 RmsProp 1 loss=6.575693 err=6.575693
I 2015-05-26 07:56:18 theanets.trainer:168 RmsProp 2 loss=4.989275 err=4.989275
I 2015-05-26 07:56:29 theanets.trainer:168 RmsProp 3 loss=4.061354 err=4.061354
I 2015-05-26 07:56:40 theanets.trainer:168 RmsProp 4 loss=3.588823 err=3.588823
I 2015-05-26 07:56:51 theanets.trainer:168 RmsProp 5 loss=3.156675 err=3.156675
I 2015-05-26 07:57:02 theanets.trainer:168 RmsProp 6 loss=2.912704 err=2.912704
I 2015-05-26 07:57:14 theanets.trainer:168 RmsProp 7 loss=2.656360 err=2.656360
I 2015-05-26 07:57:25 theanets.trainer:168 RmsProp 8 loss=2.476960 err=2.476960
I 2015-05-26 07:57:36 theanets.trainer:168 RmsProp 9 loss=2.310440 err=2.310440
I 2015-05-26 07:57:48 theanets.trainer:168 RmsProp 10 loss=2.149224 err=2.149224
I 2015-05-26 07:57:48 theanets.trainer:168 validation 1 loss=1455.703979 err=1455.703979 *
I 2015-05-26 07:58:00 theanets.trainer:168 RmsProp 11 loss=2.026965 err=2.026965
I 2015-05-26 07:58:11 theanets.trainer:168 RmsProp 12 loss=1.963666 err=1.963666
I 2015-05-26 07:58:22 theanets.trainer:168 RmsProp 13 loss=1.834394 err=1.834394
I 2015-05-26 07:58:33 theanets.trainer:168 RmsProp 14 loss=1.730476 err=1.730476
I 2015-05-26 07:58:43 theanets.trainer:168 RmsProp 15 loss=1.685862 err=1.685862
I 2015-05-26 07:58:54 theanets.trainer:168 RmsProp 16 loss=1.654854 err=1.654854
I 2015-05-26 07:59:05 theanets.trainer:168 RmsProp 17 loss=1.601843 err=1.601843
I 2015-05-26 07:59:16 theanets.trainer:168 RmsProp 18 loss=1.511191 err=1.511191
I 2015-05-26 07:59:26 theanets.trainer:168 RmsProp 19 loss=1.465620 err=1.465620
I 2015-05-26 07:59:37 theanets.trainer:168 RmsProp 20 loss=1.402308 err=1.402308
I 2015-05-26 07:59:38 theanets.trainer:168 validation 2 loss=1419.082886 err=1419.082886 *
I 2015-05-26 07:59:48 theanets.trainer:168 RmsProp 21 loss=1.388752 err=1.388752
I 2015-05-26 07:59:59 theanets.trainer:168 RmsProp 22 loss=1.354779 err=1.354779
I 2015-05-26 08:00:11 theanets.trainer:168 RmsProp 23 loss=1.287358 err=1.287358
I 2015-05-26 08:00:22 theanets.trainer:168 RmsProp 24 loss=1.289362 err=1.289362
I 2015-05-26 08:00:33 theanets.trainer:168 RmsProp 25 loss=1.222448 err=1.222448
I 2015-05-26 08:00:44 theanets.trainer:168 RmsProp 26 loss=1.169452 err=1.169452
I 2015-05-26 08:00:56 theanets.trainer:168 RmsProp 27 loss=1.162803 err=1.162803
I 2015-05-26 08:01:07 theanets.trainer:168 RmsProp 28 loss=1.141824 err=1.141824
I 2015-05-26 08:01:19 theanets.trainer:168 RmsProp 29 loss=1.118425 err=1.118425
I 2015-05-26 08:01:30 theanets.trainer:168 RmsProp 30 loss=1.074502 err=1.074502
I 2015-05-26 08:01:30 theanets.trainer:168 validation 3 loss=1393.490234 err=1393.490234 *
I 2015-05-26 08:01:41 theanets.trainer:168 RmsProp 31 loss=1.063365 err=1.063365
I 2015-05-26 08:01:52 theanets.trainer:168 RmsProp 32 loss=1.050965 err=1.050965
I 2015-05-26 08:02:03 theanets.trainer:168 RmsProp 33 loss=1.007595 err=1.007595
I 2015-05-26 08:02:13 theanets.trainer:168 RmsProp 34 loss=0.992367 err=0.992367
I 2015-05-26 08:02:23 theanets.trainer:168 RmsProp 35 loss=0.973125 err=0.973125
I 2015-05-26 08:02:34 theanets.trainer:168 RmsProp 36 loss=0.967493 err=0.967493
I 2015-05-26 08:02:44 theanets.trainer:168 RmsProp 37 loss=0.939532 err=0.939532
I 2015-05-26 08:02:54 theanets.trainer:168 RmsProp 38 loss=0.922925 err=0.922925
I 2015-05-26 08:03:05 theanets.trainer:168 RmsProp 39 loss=0.906616 err=0.906616
I 2015-05-26 08:03:15 theanets.trainer:168 RmsProp 40 loss=0.874748 err=0.874748
I 2015-05-26 08:03:16 theanets.trainer:168 validation 4 loss=1376.030884 err=1376.030884 *
I 2015-05-26 08:03:26 theanets.trainer:168 RmsProp 41 loss=0.873449 err=0.873449
I 2015-05-26 08:03:36 theanets.trainer:168 RmsProp 42 loss=0.865735 err=0.865735
I 2015-05-26 08:03:47 theanets.trainer:168 RmsProp 43 loss=0.851721 err=0.851721
I 2015-05-26 08:03:57 theanets.trainer:168 RmsProp 44 loss=0.837681 err=0.837681
I 2015-05-26 08:04:07 theanets.trainer:168 RmsProp 45 loss=0.838163 err=0.838163
I 2015-05-26 08:04:17 theanets.trainer:168 RmsProp 46 loss=0.805236 err=0.805236
I 2015-05-26 08:04:28 theanets.trainer:168 RmsProp 47 loss=0.821594 err=0.821594
I 2015-05-26 08:04:38 theanets.trainer:168 RmsProp 48 loss=0.779056 err=0.779056
I 2015-05-26 08:04:48 theanets.trainer:168 RmsProp 49 loss=0.769558 err=0.769558
I 2015-05-26 08:04:58 theanets.trainer:168 RmsProp 50 loss=0.750091 err=0.750091
I 2015-05-26 08:04:59 theanets.trainer:168 validation 5 loss=1360.461548 err=1360.461548 *
I 2015-05-26 08:05:09 theanets.trainer:168 RmsProp 51 loss=0.740839 err=0.740839
I 2015-05-26 08:05:20 theanets.trainer:168 RmsProp 52 loss=0.757119 err=0.757119
I 2015-05-26 08:05:30 theanets.trainer:168 RmsProp 53 loss=0.747568 err=0.747568
I 2015-05-26 08:05:40 theanets.trainer:168 RmsProp 54 loss=0.707579 err=0.707579
I 2015-05-26 08:05:50 theanets.trainer:168 RmsProp 55 loss=0.716866 err=0.716866
I 2015-05-26 08:06:01 theanets.trainer:168 RmsProp 56 loss=0.707188 err=0.707188
I 2015-05-26 08:06:11 theanets.trainer:168 RmsProp 57 loss=0.697292 err=0.697292
I 2015-05-26 08:06:21 theanets.trainer:168 RmsProp 58 loss=0.688546 err=0.688546
I 2015-05-26 08:06:31 theanets.trainer:168 RmsProp 59 loss=0.661848 err=0.661848
I 2015-05-26 08:06:42 theanets.trainer:168 RmsProp 60 loss=0.673883 err=0.673883
I 2015-05-26 08:06:42 theanets.trainer:168 validation 6 loss=1347.048096 err=1347.048096 *
I 2015-05-26 08:06:53 theanets.trainer:168 RmsProp 61 loss=0.666719 err=0.666719
I 2015-05-26 08:07:03 theanets.trainer:168 RmsProp 62 loss=0.653678 err=0.653678
I 2015-05-26 08:07:13 theanets.trainer:168 RmsProp 63 loss=0.642234 err=0.642234
I 2015-05-26 08:07:24 theanets.trainer:168 RmsProp 64 loss=0.641495 err=0.641495
I 2015-05-26 08:07:34 theanets.trainer:168 RmsProp 65 loss=0.636486 err=0.636486
I 2015-05-26 08:07:44 theanets.trainer:168 RmsProp 66 loss=0.624750 err=0.624750
I 2015-05-26 08:07:54 theanets.trainer:168 RmsProp 67 loss=0.605542 err=0.605542
I 2015-05-26 08:08:04 theanets.trainer:168 RmsProp 68 loss=0.599811 err=0.599811
I 2015-05-26 08:08:14 theanets.trainer:168 RmsProp 69 loss=0.600483 err=0.600483
I 2015-05-26 08:08:24 theanets.trainer:168 RmsProp 70 loss=0.591901 err=0.591901
I 2015-05-26 08:08:25 theanets.trainer:168 validation 7 loss=1338.257690 err=1338.257690 *
I 2015-05-26 08:08:35 theanets.trainer:168 RmsProp 71 loss=0.586540 err=0.586540
I 2015-05-26 08:08:45 theanets.trainer:168 RmsProp 72 loss=0.592773 err=0.592773
I 2015-05-26 08:08:55 theanets.trainer:168 RmsProp 73 loss=0.580488 err=0.580488
I 2015-05-26 08:09:06 theanets.trainer:168 RmsProp 74 loss=0.557692 err=0.557692
I 2015-05-26 08:09:16 theanets.trainer:168 RmsProp 75 loss=0.570662 err=0.570662
I 2015-05-26 08:09:26 theanets.trainer:168 RmsProp 76 loss=0.556523 err=0.556523
I 2015-05-26 08:09:37 theanets.trainer:168 RmsProp 77 loss=0.554159 err=0.554159
I 2015-05-26 08:09:48 theanets.trainer:168 RmsProp 78 loss=0.554391 err=0.554391
I 2015-05-26 08:09:58 theanets.trainer:168 RmsProp 79 loss=0.537998 err=0.537998
I 2015-05-26 08:10:09 theanets.trainer:168 RmsProp 80 loss=0.531177 err=0.531177
I 2015-05-26 08:10:09 theanets.trainer:168 validation 8 loss=1327.869019 err=1327.869019 *
I 2015-05-26 08:10:19 theanets.trainer:168 RmsProp 81 loss=0.531711 err=0.531711
I 2015-05-26 08:10:30 theanets.trainer:168 RmsProp 82 loss=0.534047 err=0.534047
I 2015-05-26 08:10:41 theanets.trainer:168 RmsProp 83 loss=0.520146 err=0.520146
I 2015-05-26 08:10:51 theanets.trainer:168 RmsProp 84 loss=0.514975 err=0.514975
I 2015-05-26 08:11:02 theanets.trainer:168 RmsProp 85 loss=0.521052 err=0.521052
I 2015-05-26 08:11:12 theanets.trainer:168 RmsProp 86 loss=0.507581 err=0.507581
I 2015-05-26 08:11:22 theanets.trainer:168 RmsProp 87 loss=0.500090 err=0.500090
I 2015-05-26 08:11:33 theanets.trainer:168 RmsProp 88 loss=0.496397 err=0.496397
I 2015-05-26 08:11:43 theanets.trainer:168 RmsProp 89 loss=0.490331 err=0.490331
I 2015-05-26 08:11:53 theanets.trainer:168 RmsProp 90 loss=0.485666 err=0.485666
I 2015-05-26 08:11:53 theanets.trainer:168 validation 9 loss=1321.989502 err=1321.989502 *
I 2015-05-26 08:12:03 theanets.trainer:168 RmsProp 91 loss=0.490526 err=0.490526
I 2015-05-26 08:12:13 theanets.trainer:168 RmsProp 92 loss=0.467760 err=0.467760
I 2015-05-26 08:12:24 theanets.trainer:168 RmsProp 93 loss=0.476247 err=0.476247
I 2015-05-26 08:12:34 theanets.trainer:168 RmsProp 94 loss=0.470157 err=0.470157
I 2015-05-26 08:12:44 theanets.trainer:168 RmsProp 95 loss=0.455576 err=0.455576
I 2015-05-26 08:12:55 theanets.trainer:168 RmsProp 96 loss=0.467199 err=0.467199
I 2015-05-26 08:13:05 theanets.trainer:168 RmsProp 97 loss=0.464333 err=0.464333
I 2015-05-26 08:13:16 theanets.trainer:168 RmsProp 98 loss=0.477246 err=0.477246
I 2015-05-26 08:13:27 theanets.trainer:168 RmsProp 99 loss=0.453250 err=0.453250
I 2015-05-26 08:13:38 theanets.trainer:168 RmsProp 100 loss=0.447691 err=0.447691
I 2015-05-26 08:13:38 theanets.trainer:168 validation 10 loss=1312.144897 err=1312.144897 *
I 2015-05-26 08:13:49 theanets.trainer:168 RmsProp 101 loss=0.450508 err=0.450508
I 2015-05-26 08:13:59 theanets.trainer:168 RmsProp 102 loss=0.453882 err=0.453882
I 2015-05-26 08:14:09 theanets.trainer:168 RmsProp 103 loss=0.438850 err=0.438850
I 2015-05-26 08:14:19 theanets.trainer:168 RmsProp 104 loss=0.429769 err=0.429769
I 2015-05-26 08:14:29 theanets.trainer:168 RmsProp 105 loss=0.431167 err=0.431167
I 2015-05-26 08:14:40 theanets.trainer:168 RmsProp 106 loss=0.425287 err=0.425287
I 2015-05-26 08:14:50 theanets.trainer:168 RmsProp 107 loss=0.423961 err=0.423961
I 2015-05-26 08:15:00 theanets.trainer:168 RmsProp 108 loss=0.425234 err=0.425234
I 2015-05-26 08:15:10 theanets.trainer:168 RmsProp 109 loss=0.418577 err=0.418577
I 2015-05-26 08:15:21 theanets.trainer:168 RmsProp 110 loss=0.413475 err=0.413475
I 2015-05-26 08:15:21 theanets.trainer:168 validation 11 loss=1307.677124 err=1307.677124 *
I 2015-05-26 08:15:32 theanets.trainer:168 RmsProp 111 loss=0.419297 err=0.419297
I 2015-05-26 08:15:42 theanets.trainer:168 RmsProp 112 loss=0.406020 err=0.406020
I 2015-05-26 08:15:52 theanets.trainer:168 RmsProp 113 loss=0.411967 err=0.411967
I 2015-05-26 08:16:03 theanets.trainer:168 RmsProp 114 loss=0.402643 err=0.402643
I 2015-05-26 08:16:13 theanets.trainer:168 RmsProp 115 loss=0.414029 err=0.414029
I 2015-05-26 08:16:23 theanets.trainer:168 RmsProp 116 loss=0.392958 err=0.392958
I 2015-05-26 08:16:33 theanets.trainer:168 RmsProp 117 loss=0.385580 err=0.385580
I 2015-05-26 08:16:44 theanets.trainer:168 RmsProp 118 loss=0.417601 err=0.417601
I 2015-05-26 08:16:54 theanets.trainer:168 RmsProp 119 loss=0.394342 err=0.394342
I 2015-05-26 08:17:04 theanets.trainer:168 RmsProp 120 loss=0.393804 err=0.393804
I 2015-05-26 08:17:05 theanets.trainer:168 validation 12 loss=1300.192993 err=1300.192993 *
I 2015-05-26 08:17:15 theanets.trainer:168 RmsProp 121 loss=0.384144 err=0.384144
I 2015-05-26 08:17:25 theanets.trainer:168 RmsProp 122 loss=0.386049 err=0.386049
I 2015-05-26 08:17:35 theanets.trainer:168 RmsProp 123 loss=0.382294 err=0.382294
I 2015-05-26 08:17:45 theanets.trainer:168 RmsProp 124 loss=0.374790 err=0.374790
I 2015-05-26 08:17:56 theanets.trainer:168 RmsProp 125 loss=0.386977 err=0.386977
I 2015-05-26 08:18:06 theanets.trainer:168 RmsProp 126 loss=0.372152 err=0.372152
I 2015-05-26 08:18:17 theanets.trainer:168 RmsProp 127 loss=0.375142 err=0.375142
I 2015-05-26 08:18:28 theanets.trainer:168 RmsProp 128 loss=0.364994 err=0.364994
I 2015-05-26 08:18:38 theanets.trainer:168 RmsProp 129 loss=0.365641 err=0.365641
I 2015-05-26 08:18:48 theanets.trainer:168 RmsProp 130 loss=0.361621 err=0.361621
I 2015-05-26 08:18:48 theanets.trainer:168 validation 13 loss=1294.274536 err=1294.274536 *
I 2015-05-26 08:18:59 theanets.trainer:168 RmsProp 131 loss=0.364641 err=0.364641
I 2015-05-26 08:19:09 theanets.trainer:168 RmsProp 132 loss=0.365922 err=0.365922
I 2015-05-26 08:19:20 theanets.trainer:168 RmsProp 133 loss=0.358276 err=0.358276
I 2015-05-26 08:19:31 theanets.trainer:168 RmsProp 134 loss=0.356715 err=0.356715
I 2015-05-26 08:19:41 theanets.trainer:168 RmsProp 135 loss=0.353238 err=0.353238
I 2015-05-26 08:19:52 theanets.trainer:168 RmsProp 136 loss=0.366751 err=0.366751
I 2015-05-26 08:20:02 theanets.trainer:168 RmsProp 137 loss=0.342467 err=0.342467
I 2015-05-26 08:20:12 theanets.trainer:168 RmsProp 138 loss=0.350508 err=0.350508
I 2015-05-26 08:20:23 theanets.trainer:168 RmsProp 139 loss=0.347909 err=0.347909
I 2015-05-26 08:20:33 theanets.trainer:168 RmsProp 140 loss=0.340801 err=0.340801
I 2015-05-26 08:20:34 theanets.trainer:168 validation 14 loss=1288.040161 err=1288.040161 *
I 2015-05-26 08:20:44 theanets.trainer:168 RmsProp 141 loss=0.340311 err=0.340311
I 2015-05-26 08:20:54 theanets.trainer:168 RmsProp 142 loss=0.349152 err=0.349152
I 2015-05-26 08:21:05 theanets.trainer:168 RmsProp 143 loss=0.351542 err=0.351542
I 2015-05-26 08:21:15 theanets.trainer:168 RmsProp 144 loss=0.340795 err=0.340795
I 2015-05-26 08:21:25 theanets.trainer:168 RmsProp 145 loss=0.346203 err=0.346203
I 2015-05-26 08:21:36 theanets.trainer:168 RmsProp 146 loss=0.339015 err=0.339015
I 2015-05-26 08:21:46 theanets.trainer:168 RmsProp 147 loss=0.326839 err=0.326839
I 2015-05-26 08:21:57 theanets.trainer:168 RmsProp 148 loss=0.328461 err=0.328461
I 2015-05-26 08:22:07 theanets.trainer:168 RmsProp 149 loss=0.336247 err=0.336247
I 2015-05-26 08:22:17 theanets.trainer:168 RmsProp 150 loss=0.329083 err=0.329083
I 2015-05-26 08:22:18 theanets.trainer:168 validation 15 loss=1285.102783 err=1285.102783 *
I 2015-05-26 08:22:28 theanets.trainer:168 RmsProp 151 loss=0.322061 err=0.322061
I 2015-05-26 08:22:39 theanets.trainer:168 RmsProp 152 loss=0.327124 err=0.327124
I 2015-05-26 08:22:50 theanets.trainer:168 RmsProp 153 loss=0.335552 err=0.335552
I 2015-05-26 08:23:00 theanets.trainer:168 RmsProp 154 loss=0.318479 err=0.318479
I 2015-05-26 08:23:11 theanets.trainer:168 RmsProp 155 loss=0.311846 err=0.311846
I 2015-05-26 08:23:21 theanets.trainer:168 RmsProp 156 loss=0.318100 err=0.318100
I 2015-05-26 08:23:31 theanets.trainer:168 RmsProp 157 loss=0.316772 err=0.316772
I 2015-05-26 08:23:42 theanets.trainer:168 RmsProp 158 loss=0.305150 err=0.305150
I 2015-05-26 08:23:52 theanets.trainer:168 RmsProp 159 loss=0.317854 err=0.317854
I 2015-05-26 08:24:02 theanets.trainer:168 RmsProp 160 loss=0.304797 err=0.304797
I 2015-05-26 08:24:03 theanets.trainer:168 validation 16 loss=1280.835327 err=1280.835327 *
I 2015-05-26 08:24:13 theanets.trainer:168 RmsProp 161 loss=0.309234 err=0.309234
I 2015-05-26 08:24:23 theanets.trainer:168 RmsProp 162 loss=0.323370 err=0.323370
I 2015-05-26 08:24:34 theanets.trainer:168 RmsProp 163 loss=0.312536 err=0.312536
I 2015-05-26 08:24:45 theanets.trainer:168 RmsProp 164 loss=0.291883 err=0.291883
I 2015-05-26 08:24:55 theanets.trainer:168 RmsProp 165 loss=0.303493 err=0.303493
I 2015-05-26 08:25:06 theanets.trainer:168 RmsProp 166 loss=0.307767 err=0.307767
I 2015-05-26 08:25:16 theanets.trainer:168 RmsProp 167 loss=0.300190 err=0.300190
I 2015-05-26 08:25:27 theanets.trainer:168 RmsProp 168 loss=0.304603 err=0.304603
I 2015-05-26 08:25:38 theanets.trainer:168 RmsProp 169 loss=0.287572 err=0.287572
I 2015-05-26 08:25:48 theanets.trainer:168 RmsProp 170 loss=0.294134 err=0.294134
I 2015-05-26 08:25:49 theanets.trainer:168 validation 17 loss=1277.586914 err=1277.586914 *
I 2015-05-26 08:25:59 theanets.trainer:168 RmsProp 171 loss=0.284826 err=0.284826
I 2015-05-26 08:26:09 theanets.trainer:168 RmsProp 172 loss=0.292502 err=0.292502
I 2015-05-26 08:26:20 theanets.trainer:168 RmsProp 173 loss=0.288701 err=0.288701
I 2015-05-26 08:26:31 theanets.trainer:168 RmsProp 174 loss=0.288156 err=0.288156
I 2015-05-26 08:26:41 theanets.trainer:168 RmsProp 175 loss=0.287363 err=0.287363
I 2015-05-26 08:26:52 theanets.trainer:168 RmsProp 176 loss=0.279580 err=0.279580
I 2015-05-26 08:27:03 theanets.trainer:168 RmsProp 177 loss=0.285029 err=0.285029
I 2015-05-26 08:27:13 theanets.trainer:168 RmsProp 178 loss=0.295664 err=0.295664
I 2015-05-26 08:27:24 theanets.trainer:168 RmsProp 179 loss=0.283525 err=0.283525
I 2015-05-26 08:27:35 theanets.trainer:168 RmsProp 180 loss=0.277549 err=0.277549
I 2015-05-26 08:27:36 theanets.trainer:168 validation 18 loss=1274.152222 err=1274.152222 *
I 2015-05-26 08:27:46 theanets.trainer:168 RmsProp 181 loss=0.278280 err=0.278280
I 2015-05-26 08:27:57 theanets.trainer:168 RmsProp 182 loss=0.289185 err=0.289185
I 2015-05-26 08:28:07 theanets.trainer:168 RmsProp 183 loss=0.280466 err=0.280466
I 2015-05-26 08:28:18 theanets.trainer:168 RmsProp 184 loss=0.268940 err=0.268940
I 2015-05-26 08:28:28 theanets.trainer:168 RmsProp 185 loss=0.271647 err=0.271647
I 2015-05-26 08:28:38 theanets.trainer:168 RmsProp 186 loss=0.285771 err=0.285771
I 2015-05-26 08:28:49 theanets.trainer:168 RmsProp 187 loss=0.276093 err=0.276093
I 2015-05-26 08:28:59 theanets.trainer:168 RmsProp 188 loss=0.267141 err=0.267141
I 2015-05-26 08:29:10 theanets.trainer:168 RmsProp 189 loss=0.270339 err=0.270339
I 2015-05-26 08:29:20 theanets.trainer:168 RmsProp 190 loss=0.278374 err=0.278374
I 2015-05-26 08:29:21 theanets.trainer:168 validation 19 loss=1270.565796 err=1270.565796 *
I 2015-05-26 08:29:31 theanets.trainer:168 RmsProp 191 loss=0.272837 err=0.272837
I 2015-05-26 08:29:41 theanets.trainer:168 RmsProp 192 loss=0.258264 err=0.258264
I 2015-05-26 08:29:52 theanets.trainer:168 RmsProp 193 loss=0.280308 err=0.280308
I 2015-05-26 08:30:02 theanets.trainer:168 RmsProp 194 loss=0.264622 err=0.264622
I 2015-05-26 08:30:13 theanets.trainer:168 RmsProp 195 loss=0.259383 err=0.259383
I 2015-05-26 08:30:24 theanets.trainer:168 RmsProp 196 loss=0.258886 err=0.258886
I 2015-05-26 08:30:35 theanets.trainer:168 RmsProp 197 loss=0.270952 err=0.270952
I 2015-05-26 08:30:46 theanets.trainer:168 RmsProp 198 loss=0.265879 err=0.265879
I 2015-05-26 08:30:56 theanets.trainer:168 RmsProp 199 loss=0.263503 err=0.263503
I 2015-05-26 08:31:07 theanets.trainer:168 RmsProp 200 loss=0.257716 err=0.257716
I 2015-05-26 08:31:08 theanets.trainer:168 validation 20 loss=1267.068726 err=1267.068726 *
I 2015-05-26 08:31:19 theanets.trainer:168 RmsProp 201 loss=0.262758 err=0.262758
I 2015-05-26 08:31:29 theanets.trainer:168 RmsProp 202 loss=0.261076 err=0.261076
I 2015-05-26 08:31:39 theanets.trainer:168 RmsProp 203 loss=0.249163 err=0.249163
I 2015-05-26 08:31:49 theanets.trainer:168 RmsProp 204 loss=0.248519 err=0.248519
I 2015-05-26 08:31:59 theanets.trainer:168 RmsProp 205 loss=0.264024 err=0.264024
I 2015-05-26 08:32:09 theanets.trainer:168 RmsProp 206 loss=0.250169 err=0.250169
I 2015-05-26 08:32:20 theanets.trainer:168 RmsProp 207 loss=0.257849 err=0.257849
I 2015-05-26 08:32:30 theanets.trainer:168 RmsProp 208 loss=0.244213 err=0.244213
I 2015-05-26 08:32:39 theanets.trainer:168 RmsProp 209 loss=0.243986 err=0.243986
I 2015-05-26 08:32:49 theanets.trainer:168 RmsProp 210 loss=0.246703 err=0.246703
I 2015-05-26 08:32:50 theanets.trainer:168 validation 21 loss=1265.015991 err=1265.015991 *
I 2015-05-26 08:33:00 theanets.trainer:168 RmsProp 211 loss=0.251186 err=0.251186
I 2015-05-26 08:33:10 theanets.trainer:168 RmsProp 212 loss=0.247002 err=0.247002
I 2015-05-26 08:33:20 theanets.trainer:168 RmsProp 213 loss=0.245179 err=0.245179
I 2015-05-26 08:33:30 theanets.trainer:168 RmsProp 214 loss=0.246522 err=0.246522
I 2015-05-26 08:33:40 theanets.trainer:168 RmsProp 215 loss=0.241255 err=0.241255
I 2015-05-26 08:33:50 theanets.trainer:168 RmsProp 216 loss=0.245560 err=0.245560
I 2015-05-26 08:33:59 theanets.trainer:168 RmsProp 217 loss=0.246299 err=0.246299
I 2015-05-26 08:34:09 theanets.trainer:168 RmsProp 218 loss=0.238259 err=0.238259
I 2015-05-26 08:34:19 theanets.trainer:168 RmsProp 219 loss=0.232971 err=0.232971
I 2015-05-26 08:34:30 theanets.trainer:168 RmsProp 220 loss=0.231836 err=0.231836
I 2015-05-26 08:34:30 theanets.trainer:168 validation 22 loss=1262.438110 err=1262.438110 *
I 2015-05-26 08:34:40 theanets.trainer:168 RmsProp 221 loss=0.233632 err=0.233632
I 2015-05-26 08:34:50 theanets.trainer:168 RmsProp 222 loss=0.236640 err=0.236640
I 2015-05-26 08:35:00 theanets.trainer:168 RmsProp 223 loss=0.239589 err=0.239589
I 2015-05-26 08:35:11 theanets.trainer:168 RmsProp 224 loss=0.234840 err=0.234840
I 2015-05-26 08:35:21 theanets.trainer:168 RmsProp 225 loss=0.225528 err=0.225528
I 2015-05-26 08:35:31 theanets.trainer:168 RmsProp 226 loss=0.236829 err=0.236829
I 2015-05-26 08:35:42 theanets.trainer:168 RmsProp 227 loss=0.234376 err=0.234376
I 2015-05-26 08:35:51 theanets.trainer:168 RmsProp 228 loss=0.226958 err=0.226958
I 2015-05-26 08:36:01 theanets.trainer:168 RmsProp 229 loss=0.216005 err=0.216005
I 2015-05-26 08:36:11 theanets.trainer:168 RmsProp 230 loss=0.243370 err=0.243370
I 2015-05-26 08:36:12 theanets.trainer:168 validation 23 loss=1257.610962 err=1257.610962 *
I 2015-05-26 08:36:21 theanets.trainer:168 RmsProp 231 loss=0.224631 err=0.224631
I 2015-05-26 08:36:32 theanets.trainer:168 RmsProp 232 loss=0.225720 err=0.225720
I 2015-05-26 08:36:42 theanets.trainer:168 RmsProp 233 loss=0.232026 err=0.232026
I 2015-05-26 08:36:52 theanets.trainer:168 RmsProp 234 loss=0.224341 err=0.224341
I 2015-05-26 08:37:02 theanets.trainer:168 RmsProp 235 loss=0.221671 err=0.221671
I 2015-05-26 08:37:12 theanets.trainer:168 RmsProp 236 loss=0.226951 err=0.226951
I 2015-05-26 08:37:22 theanets.trainer:168 RmsProp 237 loss=0.232334 err=0.232334
I 2015-05-26 08:37:31 theanets.trainer:168 RmsProp 238 loss=0.217360 err=0.217360
I 2015-05-26 08:37:41 theanets.trainer:168 RmsProp 239 loss=0.231591 err=0.231591
I 2015-05-26 08:37:51 theanets.trainer:168 RmsProp 240 loss=0.220615 err=0.220615
I 2015-05-26 08:37:52 theanets.trainer:168 validation 24 loss=1255.377319 err=1255.377319 *
I 2015-05-26 08:38:01 theanets.trainer:168 RmsProp 241 loss=0.217124 err=0.217124
I 2015-05-26 08:38:11 theanets.trainer:168 RmsProp 242 loss=0.219354 err=0.219354
I 2015-05-26 08:38:21 theanets.trainer:168 RmsProp 243 loss=0.216862 err=0.216862
I 2015-05-26 08:38:31 theanets.trainer:168 RmsProp 244 loss=0.231116 err=0.231116
I 2015-05-26 08:38:42 theanets.trainer:168 RmsProp 245 loss=0.215076 err=0.215076
I 2015-05-26 08:38:51 theanets.trainer:168 RmsProp 246 loss=0.226798 err=0.226798
I 2015-05-26 08:39:01 theanets.trainer:168 RmsProp 247 loss=0.218444 err=0.218444
I 2015-05-26 08:39:11 theanets.trainer:168 RmsProp 248 loss=0.214916 err=0.214916
I 2015-05-26 08:39:21 theanets.trainer:168 RmsProp 249 loss=0.216112 err=0.216112
I 2015-05-26 08:39:31 theanets.trainer:168 RmsProp 250 loss=0.208980 err=0.208980
I 2015-05-26 08:39:32 theanets.trainer:168 validation 25 loss=1252.831909 err=1252.831909 *
I 2015-05-26 08:39:41 theanets.trainer:168 RmsProp 251 loss=0.222569 err=0.222569
I 2015-05-26 08:39:51 theanets.trainer:168 RmsProp 252 loss=0.211782 err=0.211782
I 2015-05-26 08:40:01 theanets.trainer:168 RmsProp 253 loss=0.216315 err=0.216315
I 2015-05-26 08:40:11 theanets.trainer:168 RmsProp 254 loss=0.208255 err=0.208255
I 2015-05-26 08:40:21 theanets.trainer:168 RmsProp 255 loss=0.218436 err=0.218436
I 2015-05-26 08:40:31 theanets.trainer:168 RmsProp 256 loss=0.214021 err=0.214021
I 2015-05-26 08:40:41 theanets.trainer:168 RmsProp 257 loss=0.213637 err=0.213637
I 2015-05-26 08:40:51 theanets.trainer:168 RmsProp 258 loss=0.218142 err=0.218142
I 2015-05-26 08:41:01 theanets.trainer:168 RmsProp 259 loss=0.210016 err=0.210016
I 2015-05-26 08:41:10 theanets.trainer:168 RmsProp 260 loss=0.210877 err=0.210877
I 2015-05-26 08:41:11 theanets.trainer:168 validation 26 loss=1249.470947 err=1249.470947 *
I 2015-05-26 08:41:21 theanets.trainer:168 RmsProp 261 loss=0.213847 err=0.213847
I 2015-05-26 08:41:31 theanets.trainer:168 RmsProp 262 loss=0.204497 err=0.204497
I 2015-05-26 08:41:41 theanets.trainer:168 RmsProp 263 loss=0.204604 err=0.204604
I 2015-05-26 08:41:51 theanets.trainer:168 RmsProp 264 loss=0.209016 err=0.209016
I 2015-05-26 08:42:01 theanets.trainer:168 RmsProp 265 loss=0.207477 err=0.207477
I 2015-05-26 08:42:11 theanets.trainer:168 RmsProp 266 loss=0.205056 err=0.205056
I 2015-05-26 08:42:22 theanets.trainer:168 RmsProp 267 loss=0.204768 err=0.204768
I 2015-05-26 08:42:32 theanets.trainer:168 RmsProp 268 loss=0.198459 err=0.198459
I 2015-05-26 08:42:41 theanets.trainer:168 RmsProp 269 loss=0.210464 err=0.210464
I 2015-05-26 08:42:51 theanets.trainer:168 RmsProp 270 loss=0.198897 err=0.198897
I 2015-05-26 08:42:51 theanets.trainer:168 validation 27 loss=1247.463013 err=1247.463013 *
I 2015-05-26 08:43:01 theanets.trainer:168 RmsProp 271 loss=0.198561 err=0.198561
I 2015-05-26 08:43:11 theanets.trainer:168 RmsProp 272 loss=0.207233 err=0.207233
I 2015-05-26 08:43:21 theanets.trainer:168 RmsProp 273 loss=0.196343 err=0.196343
I 2015-05-26 08:43:31 theanets.trainer:168 RmsProp 274 loss=0.202234 err=0.202234
I 2015-05-26 08:43:41 theanets.trainer:168 RmsProp 275 loss=0.199502 err=0.199502
I 2015-05-26 08:43:51 theanets.trainer:168 RmsProp 276 loss=0.203597 err=0.203597
I 2015-05-26 08:44:00 theanets.trainer:168 RmsProp 277 loss=0.195803 err=0.195803
I 2015-05-26 08:44:10 theanets.trainer:168 RmsProp 278 loss=0.199120 err=0.199120
I 2015-05-26 08:44:20 theanets.trainer:168 RmsProp 279 loss=0.196551 err=0.196551
I 2015-05-26 08:44:30 theanets.trainer:168 RmsProp 280 loss=0.192962 err=0.192962
I 2015-05-26 08:44:30 theanets.trainer:168 validation 28 loss=1245.434448 err=1245.434448 *
I 2015-05-26 08:44:40 theanets.trainer:168 RmsProp 281 loss=0.202725 err=0.202725
I 2015-05-26 08:44:50 theanets.trainer:168 RmsProp 282 loss=0.196234 err=0.196234
I 2015-05-26 08:44:59 theanets.trainer:168 RmsProp 283 loss=0.189613 err=0.189613
I 2015-05-26 08:45:09 theanets.trainer:168 RmsProp 284 loss=0.191754 err=0.191754
I 2015-05-26 08:45:19 theanets.trainer:168 RmsProp 285 loss=0.196399 err=0.196399
I 2015-05-26 08:45:29 theanets.trainer:168 RmsProp 286 loss=0.194788 err=0.194788
I 2015-05-26 08:45:39 theanets.trainer:168 RmsProp 287 loss=0.192217 err=0.192217
I 2015-05-26 08:45:49 theanets.trainer:168 RmsProp 288 loss=0.190840 err=0.190840
I 2015-05-26 08:45:58 theanets.trainer:168 RmsProp 289 loss=0.190337 err=0.190337
I 2015-05-26 08:46:07 theanets.trainer:168 RmsProp 290 loss=0.187932 err=0.187932
I 2015-05-26 08:46:08 theanets.trainer:168 validation 29 loss=1243.475586 err=1243.475586 *
I 2015-05-26 08:46:17 theanets.trainer:168 RmsProp 291 loss=0.188496 err=0.188496
I 2015-05-26 08:46:26 theanets.trainer:168 RmsProp 292 loss=0.194977 err=0.194977
I 2015-05-26 08:46:35 theanets.trainer:168 RmsProp 293 loss=0.192264 err=0.192264
I 2015-05-26 08:46:43 theanets.trainer:168 RmsProp 294 loss=0.189457 err=0.189457
I 2015-05-26 08:46:52 theanets.trainer:168 RmsProp 295 loss=0.187076 err=0.187076
I 2015-05-26 08:47:01 theanets.trainer:168 RmsProp 296 loss=0.177718 err=0.177718
I 2015-05-26 08:47:09 theanets.trainer:168 RmsProp 297 loss=0.201471 err=0.201471
I 2015-05-26 08:47:18 theanets.trainer:168 RmsProp 298 loss=0.185598 err=0.185598
I 2015-05-26 08:47:27 theanets.trainer:168 RmsProp 299 loss=0.188257 err=0.188257
I 2015-05-26 08:47:35 theanets.trainer:168 RmsProp 300 loss=0.187114 err=0.187114
I 2015-05-26 08:47:36 theanets.trainer:168 validation 30 loss=1242.499878 err=1242.499878 *
I 2015-05-26 08:47:44 theanets.trainer:168 RmsProp 301 loss=0.185416 err=0.185416
I 2015-05-26 08:47:53 theanets.trainer:168 RmsProp 302 loss=0.182407 err=0.182407
I 2015-05-26 08:48:02 theanets.trainer:168 RmsProp 303 loss=0.189639 err=0.189639
I 2015-05-26 08:48:11 theanets.trainer:168 RmsProp 304 loss=0.187989 err=0.187989
I 2015-05-26 08:48:19 theanets.trainer:168 RmsProp 305 loss=0.181812 err=0.181812
I 2015-05-26 08:48:28 theanets.trainer:168 RmsProp 306 loss=0.178669 err=0.178669
I 2015-05-26 08:48:37 theanets.trainer:168 RmsProp 307 loss=0.184780 err=0.184780
I 2015-05-26 08:48:46 theanets.trainer:168 RmsProp 308 loss=0.180830 err=0.180830
I 2015-05-26 08:48:55 theanets.trainer:168 RmsProp 309 loss=0.186574 err=0.186574
I 2015-05-26 08:49:04 theanets.trainer:168 RmsProp 310 loss=0.178825 err=0.178825
I 2015-05-26 08:49:04 theanets.trainer:168 validation 31 loss=1239.462524 err=1239.462524 *
I 2015-05-26 08:49:13 theanets.trainer:168 RmsProp 311 loss=0.176740 err=0.176740
I 2015-05-26 08:49:22 theanets.trainer:168 RmsProp 312 loss=0.184717 err=0.184717
I 2015-05-26 08:49:30 theanets.trainer:168 RmsProp 313 loss=0.181354 err=0.181354
I 2015-05-26 08:49:39 theanets.trainer:168 RmsProp 314 loss=0.170805 err=0.170805
I 2015-05-26 08:49:48 theanets.trainer:168 RmsProp 315 loss=0.188951 err=0.188951
I 2015-05-26 08:49:57 theanets.trainer:168 RmsProp 316 loss=0.170485 err=0.170485
I 2015-05-26 08:50:06 theanets.trainer:168 RmsProp 317 loss=0.177150 err=0.177150
I 2015-05-26 08:50:14 theanets.trainer:168 RmsProp 318 loss=0.172040 err=0.172040
I 2015-05-26 08:50:23 theanets.trainer:168 RmsProp 319 loss=0.181043 err=0.181043
I 2015-05-26 08:50:31 theanets.trainer:168 RmsProp 320 loss=0.169962 err=0.169962
I 2015-05-26 08:50:32 theanets.trainer:168 validation 32 loss=1237.509033 err=1237.509033 *
I 2015-05-26 08:50:40 theanets.trainer:168 RmsProp 321 loss=0.178479 err=0.178479
I 2015-05-26 08:50:49 theanets.trainer:168 RmsProp 322 loss=0.169786 err=0.169786
I 2015-05-26 08:50:57 theanets.trainer:168 RmsProp 323 loss=0.175985 err=0.175985
I 2015-05-26 08:51:04 theanets.trainer:168 RmsProp 324 loss=0.172291 err=0.172291
I 2015-05-26 08:51:13 theanets.trainer:168 RmsProp 325 loss=0.177953 err=0.177953
I 2015-05-26 08:51:21 theanets.trainer:168 RmsProp 326 loss=0.165238 err=0.165238
I 2015-05-26 08:51:30 theanets.trainer:168 RmsProp 327 loss=0.171815 err=0.171815
I 2015-05-26 08:51:38 theanets.trainer:168 RmsProp 328 loss=0.174942 err=0.174942
I 2015-05-26 08:51:47 theanets.trainer:168 RmsProp 329 loss=0.168959 err=0.168959
I 2015-05-26 08:51:55 theanets.trainer:168 RmsProp 330 loss=0.170668 err=0.170668
I 2015-05-26 08:51:55 theanets.trainer:168 validation 33 loss=1234.896729 err=1234.896729 *
I 2015-05-26 08:52:03 theanets.trainer:168 RmsProp 331 loss=0.173460 err=0.173460
I 2015-05-26 08:52:11 theanets.trainer:168 RmsProp 332 loss=0.171569 err=0.171569
I 2015-05-26 08:52:19 theanets.trainer:168 RmsProp 333 loss=0.165958 err=0.165958
I 2015-05-26 08:52:27 theanets.trainer:168 RmsProp 334 loss=0.165134 err=0.165134
I 2015-05-26 08:52:35 theanets.trainer:168 RmsProp 335 loss=0.177328 err=0.177328
I 2015-05-26 08:52:43 theanets.trainer:168 RmsProp 336 loss=0.165244 err=0.165244
I 2015-05-26 08:52:51 theanets.trainer:168 RmsProp 337 loss=0.163164 err=0.163164
I 2015-05-26 08:52:59 theanets.trainer:168 RmsProp 338 loss=0.170882 err=0.170882
I 2015-05-26 08:53:07 theanets.trainer:168 RmsProp 339 loss=0.163489 err=0.163489
I 2015-05-26 08:53:15 theanets.trainer:168 RmsProp 340 loss=0.173935 err=0.173935
I 2015-05-26 08:53:16 theanets.trainer:168 validation 34 loss=1234.052124 err=1234.052124 *
I 2015-05-26 08:53:23 theanets.trainer:168 RmsProp 341 loss=0.165290 err=0.165290
I 2015-05-26 08:53:31 theanets.trainer:168 RmsProp 342 loss=0.160377 err=0.160377
I 2015-05-26 08:53:39 theanets.trainer:168 RmsProp 343 loss=0.166721 err=0.166721
I 2015-05-26 08:53:47 theanets.trainer:168 RmsProp 344 loss=0.157135 err=0.157135
I 2015-05-26 08:53:55 theanets.trainer:168 RmsProp 345 loss=0.163048 err=0.163048
I 2015-05-26 08:54:03 theanets.trainer:168 RmsProp 346 loss=0.158272 err=0.158272
I 2015-05-26 08:54:11 theanets.trainer:168 RmsProp 347 loss=0.163318 err=0.163318
I 2015-05-26 08:54:19 theanets.trainer:168 RmsProp 348 loss=0.184452 err=0.184452
I 2015-05-26 08:54:27 theanets.trainer:168 RmsProp 349 loss=0.162190 err=0.162190
I 2015-05-26 08:54:33 theanets.trainer:168 RmsProp 350 loss=0.151182 err=0.151182
I 2015-05-26 08:54:34 theanets.trainer:168 validation 35 loss=1230.310425 err=1230.310425 *
I 2015-05-26 08:54:41 theanets.trainer:168 RmsProp 351 loss=0.172681 err=0.172681
I 2015-05-26 08:54:49 theanets.trainer:168 RmsProp 352 loss=0.162864 err=0.162864
I 2015-05-26 08:54:56 theanets.trainer:168 RmsProp 353 loss=0.155376 err=0.155376
I 2015-05-26 08:55:04 theanets.trainer:168 RmsProp 354 loss=0.173573 err=0.173573
I 2015-05-26 08:55:11 theanets.trainer:168 RmsProp 355 loss=0.160287 err=0.160287
I 2015-05-26 08:55:18 theanets.trainer:168 RmsProp 356 loss=0.154147 err=0.154147
I 2015-05-26 08:55:25 theanets.trainer:168 RmsProp 357 loss=0.153617 err=0.153617
I 2015-05-26 08:55:33 theanets.trainer:168 RmsProp 358 loss=0.163971 err=0.163971
I 2015-05-26 08:55:41 theanets.trainer:168 RmsProp 359 loss=0.160813 err=0.160813
I 2015-05-26 08:55:48 theanets.trainer:168 RmsProp 360 loss=0.163018 err=0.163018
I 2015-05-26 08:55:49 theanets.trainer:168 validation 36 loss=1231.324707 err=1231.324707
I 2015-05-26 08:55:56 theanets.trainer:168 RmsProp 361 loss=0.160854 err=0.160854
I 2015-05-26 08:56:04 theanets.trainer:168 RmsProp 362 loss=0.157068 err=0.157068
I 2015-05-26 08:56:11 theanets.trainer:168 RmsProp 363 loss=0.150427 err=0.150427
I 2015-05-26 08:56:19 theanets.trainer:168 RmsProp 364 loss=0.163130 err=0.163130
I 2015-05-26 08:56:27 theanets.trainer:168 RmsProp 365 loss=0.153192 err=0.153192
I 2015-05-26 08:56:35 theanets.trainer:168 RmsProp 366 loss=0.163185 err=0.163185
I 2015-05-26 08:56:43 theanets.trainer:168 RmsProp 367 loss=0.152833 err=0.152833
I 2015-05-26 08:56:51 theanets.trainer:168 RmsProp 368 loss=0.158980 err=0.158980
I 2015-05-26 08:56:58 theanets.trainer:168 RmsProp 369 loss=0.157730 err=0.157730
I 2015-05-26 08:57:05 theanets.trainer:168 RmsProp 370 loss=0.156531 err=0.156531
I 2015-05-26 08:57:06 theanets.trainer:168 validation 37 loss=1228.117065 err=1228.117065 *
I 2015-05-26 08:57:13 theanets.trainer:168 RmsProp 371 loss=0.154522 err=0.154522
I 2015-05-26 08:57:22 theanets.trainer:168 RmsProp 372 loss=0.148438 err=0.148438
I 2015-05-26 08:57:29 theanets.trainer:168 RmsProp 373 loss=0.157161 err=0.157161
I 2015-05-26 08:57:37 theanets.trainer:168 RmsProp 374 loss=0.150622 err=0.150622
I 2015-05-26 08:57:44 theanets.trainer:168 RmsProp 375 loss=0.158624 err=0.158624
I 2015-05-26 08:57:51 theanets.trainer:168 RmsProp 376 loss=0.146785 err=0.146785
I 2015-05-26 08:57:59 theanets.trainer:168 RmsProp 377 loss=0.150192 err=0.150192
I 2015-05-26 08:58:07 theanets.trainer:168 RmsProp 378 loss=0.156623 err=0.156623
I 2015-05-26 08:58:14 theanets.trainer:168 RmsProp 379 loss=0.157516 err=0.157516
I 2015-05-26 08:58:21 theanets.trainer:168 RmsProp 380 loss=0.145393 err=0.145393
I 2015-05-26 08:58:21 theanets.trainer:168 validation 38 loss=1226.091187 err=1226.091187 *
I 2015-05-26 08:58:29 theanets.trainer:168 RmsProp 381 loss=0.161172 err=0.161172
I 2015-05-26 08:58:37 theanets.trainer:168 RmsProp 382 loss=0.146108 err=0.146108
I 2015-05-26 08:58:45 theanets.trainer:168 RmsProp 383 loss=0.156658 err=0.156658
I 2015-05-26 08:58:52 theanets.trainer:168 RmsProp 384 loss=0.154501 err=0.154501
I 2015-05-26 08:59:00 theanets.trainer:168 RmsProp 385 loss=0.148005 err=0.148005
I 2015-05-26 08:59:07 theanets.trainer:168 RmsProp 386 loss=0.151759 err=0.151759
I 2015-05-26 08:59:15 theanets.trainer:168 RmsProp 387 loss=0.142770 err=0.142770
I 2015-05-26 08:59:22 theanets.trainer:168 RmsProp 388 loss=0.160063 err=0.160063
I 2015-05-26 08:59:30 theanets.trainer:168 RmsProp 389 loss=0.143506 err=0.143506
I 2015-05-26 08:59:37 theanets.trainer:168 RmsProp 390 loss=0.148456 err=0.148456
I 2015-05-26 08:59:38 theanets.trainer:168 validation 39 loss=1222.683472 err=1222.683472 *
I 2015-05-26 08:59:45 theanets.trainer:168 RmsProp 391 loss=0.152025 err=0.152025
I 2015-05-26 08:59:52 theanets.trainer:168 RmsProp 392 loss=0.148288 err=0.148288
I 2015-05-26 08:59:59 theanets.trainer:168 RmsProp 393 loss=0.152140 err=0.152140
I 2015-05-26 09:00:07 theanets.trainer:168 RmsProp 394 loss=0.147808 err=0.147808
I 2015-05-26 09:00:15 theanets.trainer:168 RmsProp 395 loss=0.138768 err=0.138768
I 2015-05-26 09:00:23 theanets.trainer:168 RmsProp 396 loss=0.155106 err=0.155106
I 2015-05-26 09:00:31 theanets.trainer:168 RmsProp 397 loss=0.149636 err=0.149636
I 2015-05-26 09:00:39 theanets.trainer:168 RmsProp 398 loss=0.142151 err=0.142151
I 2015-05-26 09:00:46 theanets.trainer:168 RmsProp 399 loss=0.142352 err=0.142352
I 2015-05-26 09:00:54 theanets.trainer:168 RmsProp 400 loss=0.141038 err=0.141038
I 2015-05-26 09:00:55 theanets.trainer:168 validation 40 loss=1220.627930 err=1220.627930 *
I 2015-05-26 09:01:02 theanets.trainer:168 RmsProp 401 loss=0.149792 err=0.149792
I 2015-05-26 09:01:09 theanets.trainer:168 RmsProp 402 loss=0.144090 err=0.144090
I 2015-05-26 09:01:17 theanets.trainer:168 RmsProp 403 loss=0.144600 err=0.144600
I 2015-05-26 09:01:25 theanets.trainer:168 RmsProp 404 loss=0.144454 err=0.144454
I 2015-05-26 09:01:32 theanets.trainer:168 RmsProp 405 loss=0.138508 err=0.138508
I 2015-05-26 09:01:40 theanets.trainer:168 RmsProp 406 loss=0.148659 err=0.148659
I 2015-05-26 09:01:48 theanets.trainer:168 RmsProp 407 loss=0.139694 err=0.139694
I 2015-05-26 09:01:56 theanets.trainer:168 RmsProp 408 loss=0.138470 err=0.138470
I 2015-05-26 09:02:03 theanets.trainer:168 RmsProp 409 loss=0.147025 err=0.147025
I 2015-05-26 09:02:11 theanets.trainer:168 RmsProp 410 loss=0.139713 err=0.139713
I 2015-05-26 09:02:11 theanets.trainer:168 validation 41 loss=1220.930542 err=1220.930542
I 2015-05-26 09:02:18 theanets.trainer:168 RmsProp 411 loss=0.139427 err=0.139427
I 2015-05-26 09:02:25 theanets.trainer:168 RmsProp 412 loss=0.139462 err=0.139462
I 2015-05-26 09:02:33 theanets.trainer:168 RmsProp 413 loss=0.144761 err=0.144761
I 2015-05-26 09:02:40 theanets.trainer:168 RmsProp 414 loss=0.141649 err=0.141649
I 2015-05-26 09:02:49 theanets.trainer:168 RmsProp 415 loss=0.133889 err=0.133889
I 2015-05-26 09:02:56 theanets.trainer:168 RmsProp 416 loss=0.139423 err=0.139423
I 2015-05-26 09:03:03 theanets.trainer:168 RmsProp 417 loss=0.140101 err=0.140101
I 2015-05-26 09:03:12 theanets.trainer:168 RmsProp 418 loss=0.134795 err=0.134795
I 2015-05-26 09:03:19 theanets.trainer:168 RmsProp 419 loss=0.141407 err=0.141407
I 2015-05-26 09:03:27 theanets.trainer:168 RmsProp 420 loss=0.140144 err=0.140144
I 2015-05-26 09:03:27 theanets.trainer:168 validation 42 loss=1218.119019 err=1218.119019 *
I 2015-05-26 09:03:35 theanets.trainer:168 RmsProp 421 loss=0.150500 err=0.150500
I 2015-05-26 09:03:44 theanets.trainer:168 RmsProp 422 loss=0.141772 err=0.141772
I 2015-05-26 09:03:52 theanets.trainer:168 RmsProp 423 loss=0.134375 err=0.134375
I 2015-05-26 09:03:59 theanets.trainer:168 RmsProp 424 loss=0.140678 err=0.140678
I 2015-05-26 09:04:07 theanets.trainer:168 RmsProp 425 loss=0.139916 err=0.139916
I 2015-05-26 09:04:15 theanets.trainer:168 RmsProp 426 loss=0.138360 err=0.138360
I 2015-05-26 09:04:22 theanets.trainer:168 RmsProp 427 loss=0.136951 err=0.136951
I 2015-05-26 09:04:29 theanets.trainer:168 RmsProp 428 loss=0.136119 err=0.136119
I 2015-05-26 09:04:37 theanets.trainer:168 RmsProp 429 loss=0.136462 err=0.136462
I 2015-05-26 09:04:44 theanets.trainer:168 RmsProp 430 loss=0.132288 err=0.132288
I 2015-05-26 09:04:45 theanets.trainer:168 validation 43 loss=1219.041016 err=1219.041016
I 2015-05-26 09:04:53 theanets.trainer:168 RmsProp 431 loss=0.143555 err=0.143555
I 2015-05-26 09:05:01 theanets.trainer:168 RmsProp 432 loss=0.136422 err=0.136422
I 2015-05-26 09:05:08 theanets.trainer:168 RmsProp 433 loss=0.132698 err=0.132698
I 2015-05-26 09:05:16 theanets.trainer:168 RmsProp 434 loss=0.133884 err=0.133884
I 2015-05-26 09:05:24 theanets.trainer:168 RmsProp 435 loss=0.140339 err=0.140339
I 2015-05-26 09:05:32 theanets.trainer:168 RmsProp 436 loss=0.133678 err=0.133678
I 2015-05-26 09:05:40 theanets.trainer:168 RmsProp 437 loss=0.131748 err=0.131748
I 2015-05-26 09:05:47 theanets.trainer:168 RmsProp 438 loss=0.131509 err=0.131509
I 2015-05-26 09:05:55 theanets.trainer:168 RmsProp 439 loss=0.135526 err=0.135526
I 2015-05-26 09:06:03 theanets.trainer:168 RmsProp 440 loss=0.132767 err=0.132767
I 2015-05-26 09:06:04 theanets.trainer:168 validation 44 loss=1215.607056 err=1215.607056 *
I 2015-05-26 09:06:11 theanets.trainer:168 RmsProp 441 loss=0.134525 err=0.134525
I 2015-05-26 09:06:18 theanets.trainer:168 RmsProp 442 loss=0.127075 err=0.127075
I 2015-05-26 09:06:26 theanets.trainer:168 RmsProp 443 loss=0.134837 err=0.134837
I 2015-05-26 09:06:34 theanets.trainer:168 RmsProp 444 loss=0.130702 err=0.130702
I 2015-05-26 09:06:42 theanets.trainer:168 RmsProp 445 loss=0.136937 err=0.136937
I 2015-05-26 09:06:49 theanets.trainer:168 RmsProp 446 loss=0.128298 err=0.128298
I 2015-05-26 09:06:57 theanets.trainer:168 RmsProp 447 loss=0.141637 err=0.141637
I 2015-05-26 09:07:05 theanets.trainer:168 RmsProp 448 loss=0.127890 err=0.127890
I 2015-05-26 09:07:12 theanets.trainer:168 RmsProp 449 loss=0.139598 err=0.139598
I 2015-05-26 09:07:20 theanets.trainer:168 RmsProp 450 loss=0.128465 err=0.128465
I 2015-05-26 09:07:20 theanets.trainer:168 validation 45 loss=1215.158691 err=1215.158691 *
I 2015-05-26 09:07:28 theanets.trainer:168 RmsProp 451 loss=0.138031 err=0.138031
I 2015-05-26 09:07:35 theanets.trainer:168 RmsProp 452 loss=0.139969 err=0.139969
I 2015-05-26 09:07:43 theanets.trainer:168 RmsProp 453 loss=0.125675 err=0.125675
I 2015-05-26 09:07:51 theanets.trainer:168 RmsProp 454 loss=0.126741 err=0.126741
I 2015-05-26 09:07:59 theanets.trainer:168 RmsProp 455 loss=0.131783 err=0.131783
I 2015-05-26 09:08:07 theanets.trainer:168 RmsProp 456 loss=0.128062 err=0.128062
I 2015-05-26 09:08:15 theanets.trainer:168 RmsProp 457 loss=0.126923 err=0.126923
I 2015-05-26 09:08:22 theanets.trainer:168 RmsProp 458 loss=0.127243 err=0.127243
I 2015-05-26 09:08:30 theanets.trainer:168 RmsProp 459 loss=0.135304 err=0.135304
I 2015-05-26 09:08:37 theanets.trainer:168 RmsProp 460 loss=0.129934 err=0.129934
I 2015-05-26 09:08:38 theanets.trainer:168 validation 46 loss=1213.110962 err=1213.110962 *
I 2015-05-26 09:08:44 theanets.trainer:168 RmsProp 461 loss=0.123310 err=0.123310
I 2015-05-26 09:08:51 theanets.trainer:168 RmsProp 462 loss=0.128823 err=0.128823
I 2015-05-26 09:08:59 theanets.trainer:168 RmsProp 463 loss=0.123509 err=0.123509
I 2015-05-26 09:09:07 theanets.trainer:168 RmsProp 464 loss=0.128735 err=0.128735
I 2015-05-26 09:09:15 theanets.trainer:168 RmsProp 465 loss=0.130060 err=0.130060
I 2015-05-26 09:09:22 theanets.trainer:168 RmsProp 466 loss=0.127241 err=0.127241
I 2015-05-26 09:09:30 theanets.trainer:168 RmsProp 467 loss=0.129787 err=0.129787
I 2015-05-26 09:09:38 theanets.trainer:168 RmsProp 468 loss=0.122792 err=0.122792
I 2015-05-26 09:09:46 theanets.trainer:168 RmsProp 469 loss=0.127369 err=0.127369
I 2015-05-26 09:09:54 theanets.trainer:168 RmsProp 470 loss=0.123094 err=0.123094
I 2015-05-26 09:09:54 theanets.trainer:168 validation 47 loss=1213.338257 err=1213.338257
I 2015-05-26 09:10:02 theanets.trainer:168 RmsProp 471 loss=0.129450 err=0.129450
I 2015-05-26 09:10:09 theanets.trainer:168 RmsProp 472 loss=0.129192 err=0.129192
I 2015-05-26 09:10:17 theanets.trainer:168 RmsProp 473 loss=0.119702 err=0.119702
I 2015-05-26 09:10:25 theanets.trainer:168 RmsProp 474 loss=0.128817 err=0.128817
I 2015-05-26 09:10:33 theanets.trainer:168 RmsProp 475 loss=0.121668 err=0.121668
I 2015-05-26 09:10:40 theanets.trainer:168 RmsProp 476 loss=0.128980 err=0.128980
I 2015-05-26 09:10:48 theanets.trainer:168 RmsProp 477 loss=0.125505 err=0.125505
I 2015-05-26 09:10:55 theanets.trainer:168 RmsProp 478 loss=0.123848 err=0.123848
I 2015-05-26 09:11:02 theanets.trainer:168 RmsProp 479 loss=0.123664 err=0.123664
I 2015-05-26 09:11:09 theanets.trainer:168 RmsProp 480 loss=0.128514 err=0.128514
I 2015-05-26 09:11:09 theanets.trainer:168 validation 48 loss=1211.407104 err=1211.407104 *
I 2015-05-26 09:11:17 theanets.trainer:168 RmsProp 481 loss=0.125539 err=0.125539
I 2015-05-26 09:11:24 theanets.trainer:168 RmsProp 482 loss=0.122276 err=0.122276
I 2015-05-26 09:11:31 theanets.trainer:168 RmsProp 483 loss=0.122263 err=0.122263
I 2015-05-26 09:11:38 theanets.trainer:168 RmsProp 484 loss=0.123633 err=0.123633
I 2015-05-26 09:11:44 theanets.trainer:168 RmsProp 485 loss=0.118209 err=0.118209
I 2015-05-26 09:11:52 theanets.trainer:168 RmsProp 486 loss=0.123600 err=0.123600
I 2015-05-26 09:12:00 theanets.trainer:168 RmsProp 487 loss=0.124158 err=0.124158
I 2015-05-26 09:12:07 theanets.trainer:168 RmsProp 488 loss=0.121333 err=0.121333
I 2015-05-26 09:12:15 theanets.trainer:168 RmsProp 489 loss=0.118094 err=0.118094
I 2015-05-26 09:12:22 theanets.trainer:168 RmsProp 490 loss=0.122607 err=0.122607
I 2015-05-26 09:12:23 theanets.trainer:168 validation 49 loss=1210.817505 err=1210.817505 *
I 2015-05-26 09:12:30 theanets.trainer:168 RmsProp 491 loss=0.125189 err=0.125189
I 2015-05-26 09:12:38 theanets.trainer:168 RmsProp 492 loss=0.128721 err=0.128721
I 2015-05-26 09:12:45 theanets.trainer:168 RmsProp 493 loss=0.122955 err=0.122955
I 2015-05-26 09:12:52 theanets.trainer:168 RmsProp 494 loss=0.115200 err=0.115200
I 2015-05-26 09:12:59 theanets.trainer:168 RmsProp 495 loss=0.126251 err=0.126251
I 2015-05-26 09:13:06 theanets.trainer:168 RmsProp 496 loss=0.119814 err=0.119814
I 2015-05-26 09:13:14 theanets.trainer:168 RmsProp 497 loss=0.123942 err=0.123942
I 2015-05-26 09:13:22 theanets.trainer:168 RmsProp 498 loss=0.125377 err=0.125377
I 2015-05-26 09:13:30 theanets.trainer:168 RmsProp 499 loss=0.121976 err=0.121976
I 2015-05-26 09:13:37 theanets.trainer:168 RmsProp 500 loss=0.117870 err=0.117870
I 2015-05-26 09:13:37 theanets.trainer:168 validation 50 loss=1208.675903 err=1208.675903 *
I 2015-05-26 09:13:44 theanets.trainer:168 RmsProp 501 loss=0.118778 err=0.118778
I 2015-05-26 09:13:51 theanets.trainer:168 RmsProp 502 loss=0.120192 err=0.120192
I 2015-05-26 09:13:58 theanets.trainer:168 RmsProp 503 loss=0.125689 err=0.125689
I 2015-05-26 09:14:05 theanets.trainer:168 RmsProp 504 loss=0.123583 err=0.123583
I 2015-05-26 09:14:12 theanets.trainer:168 RmsProp 505 loss=0.120844 err=0.120844
I 2015-05-26 09:14:19 theanets.trainer:168 RmsProp 506 loss=0.117749 err=0.117749
I 2015-05-26 09:14:26 theanets.trainer:168 RmsProp 507 loss=0.114809 err=0.114809
I 2015-05-26 09:14:33 theanets.trainer:168 RmsProp 508 loss=0.120852 err=0.120852
I 2015-05-26 09:14:41 theanets.trainer:168 RmsProp 509 loss=0.117481 err=0.117481
I 2015-05-26 09:14:48 theanets.trainer:168 RmsProp 510 loss=0.114637 err=0.114637
I 2015-05-26 09:14:49 theanets.trainer:168 validation 51 loss=1208.151123 err=1208.151123 *
I 2015-05-26 09:14:56 theanets.trainer:168 RmsProp 511 loss=0.124309 err=0.124309
I 2015-05-26 09:15:04 theanets.trainer:168 RmsProp 512 loss=0.119122 err=0.119122
I 2015-05-26 09:15:12 theanets.trainer:168 RmsProp 513 loss=0.120062 err=0.120062
I 2015-05-26 09:15:20 theanets.trainer:168 RmsProp 514 loss=0.120905 err=0.120905
I 2015-05-26 09:15:27 theanets.trainer:168 RmsProp 515 loss=0.120800 err=0.120800
I 2015-05-26 09:15:35 theanets.trainer:168 RmsProp 516 loss=0.108985 err=0.108985
I 2015-05-26 09:15:42 theanets.trainer:168 RmsProp 517 loss=0.116379 err=0.116379
I 2015-05-26 09:15:49 theanets.trainer:168 RmsProp 518 loss=0.114939 err=0.114939
I 2015-05-26 09:15:55 theanets.trainer:168 RmsProp 519 loss=0.115839 err=0.115839
I 2015-05-26 09:16:02 theanets.trainer:168 RmsProp 520 loss=0.114861 err=0.114861
I 2015-05-26 09:16:03 theanets.trainer:168 validation 52 loss=1206.172119 err=1206.172119 *
I 2015-05-26 09:16:10 theanets.trainer:168 RmsProp 521 loss=0.117546 err=0.117546
I 2015-05-26 09:16:17 theanets.trainer:168 RmsProp 522 loss=0.122629 err=0.122629
I 2015-05-26 09:16:24 theanets.trainer:168 RmsProp 523 loss=0.116286 err=0.116286
I 2015-05-26 09:16:32 theanets.trainer:168 RmsProp 524 loss=0.114805 err=0.114805
I 2015-05-26 09:16:39 theanets.trainer:168 RmsProp 525 loss=0.111717 err=0.111717
I 2015-05-26 09:16:47 theanets.trainer:168 RmsProp 526 loss=0.111853 err=0.111853
I 2015-05-26 09:16:53 theanets.trainer:168 RmsProp 527 loss=0.114429 err=0.114429
I 2015-05-26 09:17:01 theanets.trainer:168 RmsProp 528 loss=0.119705 err=0.119705
I 2015-05-26 09:17:09 theanets.trainer:168 RmsProp 529 loss=0.112943 err=0.112943
I 2015-05-26 09:17:16 theanets.trainer:168 RmsProp 530 loss=0.116984 err=0.116984
I 2015-05-26 09:17:17 theanets.trainer:168 validation 53 loss=1205.837524 err=1205.837524 *
I 2015-05-26 09:17:24 theanets.trainer:168 RmsProp 531 loss=0.118568 err=0.118568
I 2015-05-26 09:17:32 theanets.trainer:168 RmsProp 532 loss=0.119798 err=0.119798
I 2015-05-26 09:17:39 theanets.trainer:168 RmsProp 533 loss=0.115679 err=0.115679
I 2015-05-26 09:17:46 theanets.trainer:168 RmsProp 534 loss=0.114216 err=0.114216
I 2015-05-26 09:17:53 theanets.trainer:168 RmsProp 535 loss=0.108500 err=0.108500
I 2015-05-26 09:18:00 theanets.trainer:168 RmsProp 536 loss=0.117431 err=0.117431
I 2015-05-26 09:18:08 theanets.trainer:168 RmsProp 537 loss=0.112949 err=0.112949
I 2015-05-26 09:18:16 theanets.trainer:168 RmsProp 538 loss=0.115670 err=0.115670
I 2015-05-26 09:18:24 theanets.trainer:168 RmsProp 539 loss=0.115611 err=0.115611
I 2015-05-26 09:18:31 theanets.trainer:168 RmsProp 540 loss=0.113981 err=0.113981
I 2015-05-26 09:18:32 theanets.trainer:168 validation 54 loss=1203.590942 err=1203.590942 *
I 2015-05-26 09:18:39 theanets.trainer:168 RmsProp 541 loss=0.115807 err=0.115807
I 2015-05-26 09:18:47 theanets.trainer:168 RmsProp 542 loss=0.112399 err=0.112399
I 2015-05-26 09:18:55 theanets.trainer:168 RmsProp 543 loss=0.104005 err=0.104005
I 2015-05-26 09:19:01 theanets.trainer:168 RmsProp 544 loss=0.124518 err=0.124518
I 2015-05-26 09:19:09 theanets.trainer:168 RmsProp 545 loss=0.111620 err=0.111620
I 2015-05-26 09:19:16 theanets.trainer:168 RmsProp 546 loss=0.109260 err=0.109260
I 2015-05-26 09:19:23 theanets.trainer:168 RmsProp 547 loss=0.107300 err=0.107300
I 2015-05-26 09:19:30 theanets.trainer:168 RmsProp 548 loss=0.111442 err=0.111442
I 2015-05-26 09:19:37 theanets.trainer:168 RmsProp 549 loss=0.107846 err=0.107846
I 2015-05-26 09:19:44 theanets.trainer:168 RmsProp 550 loss=0.113887 err=0.113887
I 2015-05-26 09:19:44 theanets.trainer:168 validation 55 loss=1201.333984 err=1201.333984 *
I 2015-05-26 09:19:51 theanets.trainer:168 RmsProp 551 loss=0.112474 err=0.112474
I 2015-05-26 09:19:59 theanets.trainer:168 RmsProp 552 loss=0.107302 err=0.107302
I 2015-05-26 09:20:07 theanets.trainer:168 RmsProp 553 loss=0.107720 err=0.107720
I 2015-05-26 09:20:14 theanets.trainer:168 RmsProp 554 loss=0.112730 err=0.112730
I 2015-05-26 09:20:22 theanets.trainer:168 RmsProp 555 loss=0.107992 err=0.107992
I 2015-05-26 09:20:30 theanets.trainer:168 RmsProp 556 loss=0.104389 err=0.104389
I 2015-05-26 09:20:38 theanets.trainer:168 RmsProp 557 loss=0.112553 err=0.112553
I 2015-05-26 09:20:45 theanets.trainer:168 RmsProp 558 loss=0.108178 err=0.108178
I 2015-05-26 09:20:52 theanets.trainer:168 RmsProp 559 loss=0.109360 err=0.109360
I 2015-05-26 09:20:59 theanets.trainer:168 RmsProp 560 loss=0.106016 err=0.106016
I 2015-05-26 09:21:00 theanets.trainer:168 validation 56 loss=1199.841797 err=1199.841797 *
I 2015-05-26 09:21:07 theanets.trainer:168 RmsProp 561 loss=0.105046 err=0.105046
I 2015-05-26 09:21:14 theanets.trainer:168 RmsProp 562 loss=0.106375 err=0.106375
I 2015-05-26 09:21:21 theanets.trainer:168 RmsProp 563 loss=0.111464 err=0.111464
I 2015-05-26 09:21:28 theanets.trainer:168 RmsProp 564 loss=0.113056 err=0.113056
I 2015-05-26 09:21:36 theanets.trainer:168 RmsProp 565 loss=0.109981 err=0.109981
I 2015-05-26 09:21:43 theanets.trainer:168 RmsProp 566 loss=0.108852 err=0.108852
I 2015-05-26 09:21:51 theanets.trainer:168 RmsProp 567 loss=0.108458 err=0.108458
I 2015-05-26 09:21:58 theanets.trainer:168 RmsProp 568 loss=0.104321 err=0.104321
I 2015-05-26 09:22:04 theanets.trainer:168 RmsProp 569 loss=0.101395 err=0.101395
I 2015-05-26 09:22:11 theanets.trainer:168 RmsProp 570 loss=0.113072 err=0.113072
I 2015-05-26 09:22:12 theanets.trainer:168 validation 57 loss=1198.898193 err=1198.898193 *
I 2015-05-26 09:22:18 theanets.trainer:168 RmsProp 571 loss=0.108016 err=0.108016
I 2015-05-26 09:22:25 theanets.trainer:168 RmsProp 572 loss=0.097731 err=0.097731
I 2015-05-26 09:22:32 theanets.trainer:168 RmsProp 573 loss=0.115352 err=0.115352
I 2015-05-26 09:22:38 theanets.trainer:168 RmsProp 574 loss=0.103123 err=0.103123
I 2015-05-26 09:22:46 theanets.trainer:168 RmsProp 575 loss=0.109971 err=0.109971
I 2015-05-26 09:22:52 theanets.trainer:168 RmsProp 576 loss=0.097779 err=0.097779
I 2015-05-26 09:22:59 theanets.trainer:168 RmsProp 577 loss=0.112354 err=0.112354
I 2015-05-26 09:23:06 theanets.trainer:168 RmsProp 578 loss=0.103798 err=0.103798
I 2015-05-26 09:23:13 theanets.trainer:168 RmsProp 579 loss=0.107966 err=0.107966
I 2015-05-26 09:23:19 theanets.trainer:168 RmsProp 580 loss=0.107268 err=0.107268
I 2015-05-26 09:23:20 theanets.trainer:168 validation 58 loss=1200.019165 err=1200.019165
I 2015-05-26 09:23:26 theanets.trainer:168 RmsProp 581 loss=0.104557 err=0.104557
I 2015-05-26 09:23:33 theanets.trainer:168 RmsProp 582 loss=0.108674 err=0.108674
I 2015-05-26 09:23:40 theanets.trainer:168 RmsProp 583 loss=0.102277 err=0.102277
I 2015-05-26 09:23:46 theanets.trainer:168 RmsProp 584 loss=0.111011 err=0.111011
I 2015-05-26 09:23:53 theanets.trainer:168 RmsProp 585 loss=0.109710 err=0.109710
I 2015-05-26 09:23:59 theanets.trainer:168 RmsProp 586 loss=0.101515 err=0.101515
I 2015-05-26 09:24:06 theanets.trainer:168 RmsProp 587 loss=0.107817 err=0.107817
I 2015-05-26 09:24:13 theanets.trainer:168 RmsProp 588 loss=0.104527 err=0.104527
I 2015-05-26 09:24:20 theanets.trainer:168 RmsProp 589 loss=0.110934 err=0.110934
I 2015-05-26 09:24:27 theanets.trainer:168 RmsProp 590 loss=0.104091 err=0.104091
I 2015-05-26 09:24:27 theanets.trainer:168 validation 59 loss=1200.657837 err=1200.657837
I 2015-05-26 09:24:34 theanets.trainer:168 RmsProp 591 loss=0.106500 err=0.106500
I 2015-05-26 09:24:42 theanets.trainer:168 RmsProp 592 loss=0.099562 err=0.099562
I 2015-05-26 09:24:49 theanets.trainer:168 RmsProp 593 loss=0.101005 err=0.101005
I 2015-05-26 09:24:55 theanets.trainer:168 RmsProp 594 loss=0.105078 err=0.105078
I 2015-05-26 09:25:02 theanets.trainer:168 RmsProp 595 loss=0.100797 err=0.100797
I 2015-05-26 09:25:09 theanets.trainer:168 RmsProp 596 loss=0.105982 err=0.105982
I 2015-05-26 09:25:16 theanets.trainer:168 RmsProp 597 loss=0.102141 err=0.102141
I 2015-05-26 09:25:23 theanets.trainer:168 RmsProp 598 loss=0.106126 err=0.106126
I 2015-05-26 09:25:30 theanets.trainer:168 RmsProp 599 loss=0.100366 err=0.100366
I 2015-05-26 09:25:36 theanets.trainer:168 RmsProp 600 loss=0.108950 err=0.108950
I 2015-05-26 09:25:37 theanets.trainer:168 validation 60 loss=1200.055298 err=1200.055298
I 2015-05-26 09:25:43 theanets.trainer:168 RmsProp 601 loss=0.101213 err=0.101213
I 2015-05-26 09:25:50 theanets.trainer:168 RmsProp 602 loss=0.100758 err=0.100758
I 2015-05-26 09:25:57 theanets.trainer:168 RmsProp 603 loss=0.106339 err=0.106339
I 2015-05-26 09:26:04 theanets.trainer:168 RmsProp 604 loss=0.104141 err=0.104141
I 2015-05-26 09:26:11 theanets.trainer:168 RmsProp 605 loss=0.100771 err=0.100771
I 2015-05-26 09:26:18 theanets.trainer:168 RmsProp 606 loss=0.102186 err=0.102186
I 2015-05-26 09:26:25 theanets.trainer:168 RmsProp 607 loss=0.105499 err=0.105499
I 2015-05-26 09:26:32 theanets.trainer:168 RmsProp 608 loss=0.100733 err=0.100733
I 2015-05-26 09:26:39 theanets.trainer:168 RmsProp 609 loss=0.104244 err=0.104244
I 2015-05-26 09:26:46 theanets.trainer:168 RmsProp 610 loss=0.098416 err=0.098416
I 2015-05-26 09:26:46 theanets.trainer:168 validation 61 loss=1199.766479 err=1199.766479
I 2015-05-26 09:26:53 theanets.trainer:168 RmsProp 611 loss=0.104014 err=0.104014
I 2015-05-26 09:27:00 theanets.trainer:168 RmsProp 612 loss=0.109521 err=0.109521
I 2015-05-26 09:27:06 theanets.trainer:168 RmsProp 613 loss=0.101319 err=0.101319
I 2015-05-26 09:27:14 theanets.trainer:168 RmsProp 614 loss=0.099645 err=0.099645
I 2015-05-26 09:27:20 theanets.trainer:168 RmsProp 615 loss=0.097300 err=0.097300
I 2015-05-26 09:27:27 theanets.trainer:168 RmsProp 616 loss=0.098984 err=0.098984
I 2015-05-26 09:27:33 theanets.trainer:168 RmsProp 617 loss=0.096113 err=0.096113
I 2015-05-26 09:27:40 theanets.trainer:168 RmsProp 618 loss=0.108808 err=0.108808
I 2015-05-26 09:27:47 theanets.trainer:168 RmsProp 619 loss=0.094075 err=0.094075
I 2015-05-26 09:27:54 theanets.trainer:168 RmsProp 620 loss=0.118361 err=0.118361
I 2015-05-26 09:27:54 theanets.trainer:168 validation 62 loss=1197.431274 err=1197.431274 *
I 2015-05-26 09:28:01 theanets.trainer:168 RmsProp 621 loss=0.102817 err=0.102817
I 2015-05-26 09:28:08 theanets.trainer:168 RmsProp 622 loss=0.100055 err=0.100055
I 2015-05-26 09:28:15 theanets.trainer:168 RmsProp 623 loss=0.096976 err=0.096976
I 2015-05-26 09:28:22 theanets.trainer:168 RmsProp 624 loss=0.104683 err=0.104683
I 2015-05-26 09:28:29 theanets.trainer:168 RmsProp 625 loss=0.098649 err=0.098649
I 2015-05-26 09:28:36 theanets.trainer:168 RmsProp 626 loss=0.094570 err=0.094570
I 2015-05-26 09:28:43 theanets.trainer:168 RmsProp 627 loss=0.099205 err=0.099205
I 2015-05-26 09:28:50 theanets.trainer:168 RmsProp 628 loss=0.103673 err=0.103673
I 2015-05-26 09:28:57 theanets.trainer:168 RmsProp 629 loss=0.101862 err=0.101862
I 2015-05-26 09:29:03 theanets.trainer:168 RmsProp 630 loss=0.091739 err=0.091739
I 2015-05-26 09:29:03 theanets.trainer:168 validation 63 loss=1197.168335 err=1197.168335 *
I 2015-05-26 09:29:10 theanets.trainer:168 RmsProp 631 loss=0.106063 err=0.106063
I 2015-05-26 09:29:17 theanets.trainer:168 RmsProp 632 loss=0.096705 err=0.096705
I 2015-05-26 09:29:24 theanets.trainer:168 RmsProp 633 loss=0.109188 err=0.109188
I 2015-05-26 09:29:31 theanets.trainer:168 RmsProp 634 loss=0.095905 err=0.095905
I 2015-05-26 09:29:38 theanets.trainer:168 RmsProp 635 loss=0.094584 err=0.094584
I 2015-05-26 09:29:45 theanets.trainer:168 RmsProp 636 loss=0.098928 err=0.098928
I 2015-05-26 09:29:51 theanets.trainer:168 RmsProp 637 loss=0.098111 err=0.098111
I 2015-05-26 09:29:58 theanets.trainer:168 RmsProp 638 loss=0.097095 err=0.097095
I 2015-05-26 09:30:05 theanets.trainer:168 RmsProp 639 loss=0.091610 err=0.091610
I 2015-05-26 09:30:12 theanets.trainer:168 RmsProp 640 loss=0.102102 err=0.102102
I 2015-05-26 09:30:12 theanets.trainer:168 validation 64 loss=1197.103027 err=1197.103027 *
I 2015-05-26 09:30:19 theanets.trainer:168 RmsProp 641 loss=0.096789 err=0.096789
I 2015-05-26 09:30:25 theanets.trainer:168 RmsProp 642 loss=0.100918 err=0.100918
I 2015-05-26 09:30:33 theanets.trainer:168 RmsProp 643 loss=0.094609 err=0.094609
I 2015-05-26 09:30:39 theanets.trainer:168 RmsProp 644 loss=0.096931 err=0.096931
I 2015-05-26 09:30:46 theanets.trainer:168 RmsProp 645 loss=0.093013 err=0.093013
I 2015-05-26 09:30:53 theanets.trainer:168 RmsProp 646 loss=0.090924 err=0.090924
I 2015-05-26 09:30:59 theanets.trainer:168 RmsProp 647 loss=0.101459 err=0.101459
I 2015-05-26 09:31:06 theanets.trainer:168 RmsProp 648 loss=0.088231 err=0.088231
I 2015-05-26 09:31:13 theanets.trainer:168 RmsProp 649 loss=0.108622 err=0.108622
I 2015-05-26 09:31:20 theanets.trainer:168 RmsProp 650 loss=0.091027 err=0.091027
I 2015-05-26 09:31:21 theanets.trainer:168 validation 65 loss=1196.158081 err=1196.158081 *
I 2015-05-26 09:31:28 theanets.trainer:168 RmsProp 651 loss=0.097649 err=0.097649
I 2015-05-26 09:31:35 theanets.trainer:168 RmsProp 652 loss=0.090637 err=0.090637
I 2015-05-26 09:31:41 theanets.trainer:168 RmsProp 653 loss=0.100366 err=0.100366
I 2015-05-26 09:31:48 theanets.trainer:168 RmsProp 654 loss=0.098834 err=0.098834
I 2015-05-26 09:31:55 theanets.trainer:168 RmsProp 655 loss=0.095207 err=0.095207
I 2015-05-26 09:32:01 theanets.trainer:168 RmsProp 656 loss=0.086914 err=0.086914
I 2015-05-26 09:32:08 theanets.trainer:168 RmsProp 657 loss=0.108999 err=0.108999
I 2015-05-26 09:32:15 theanets.trainer:168 RmsProp 658 loss=0.092171 err=0.092171
I 2015-05-26 09:32:22 theanets.trainer:168 RmsProp 659 loss=0.106984 err=0.106984
I 2015-05-26 09:32:29 theanets.trainer:168 RmsProp 660 loss=0.093121 err=0.093121
I 2015-05-26 09:32:29 theanets.trainer:168 validation 66 loss=1194.795532 err=1194.795532 *
I 2015-05-26 09:32:36 theanets.trainer:168 RmsProp 661 loss=0.096979 err=0.096979
I 2015-05-26 09:32:42 theanets.trainer:168 RmsProp 662 loss=0.092403 err=0.092403
I 2015-05-26 09:32:49 theanets.trainer:168 RmsProp 663 loss=0.094882 err=0.094882
I 2015-05-26 09:32:55 theanets.trainer:168 RmsProp 664 loss=0.091669 err=0.091669
I 2015-05-26 09:33:02 theanets.trainer:168 RmsProp 665 loss=0.096660 err=0.096660
I 2015-05-26 09:33:09 theanets.trainer:168 RmsProp 666 loss=0.089546 err=0.089546
I 2015-05-26 09:33:15 theanets.trainer:168 RmsProp 667 loss=0.093621 err=0.093621
I 2015-05-26 09:33:21 theanets.trainer:168 RmsProp 668 loss=0.096227 err=0.096227
I 2015-05-26 09:33:28 theanets.trainer:168 RmsProp 669 loss=0.102709 err=0.102709
I 2015-05-26 09:33:35 theanets.trainer:168 RmsProp 670 loss=0.090718 err=0.090718
I 2015-05-26 09:33:35 theanets.trainer:168 validation 67 loss=1194.049561 err=1194.049561 *
I 2015-05-26 09:33:42 theanets.trainer:168 RmsProp 671 loss=0.101127 err=0.101127
I 2015-05-26 09:33:48 theanets.trainer:168 RmsProp 672 loss=0.090718 err=0.090718
I 2015-05-26 09:33:54 theanets.trainer:168 RmsProp 673 loss=0.092888 err=0.092888
I 2015-05-26 09:34:01 theanets.trainer:168 RmsProp 674 loss=0.094970 err=0.094970
I 2015-05-26 09:34:07 theanets.trainer:168 RmsProp 675 loss=0.095341 err=0.095341
I 2015-05-26 09:34:13 theanets.trainer:168 RmsProp 676 loss=0.096912 err=0.096912
I 2015-05-26 09:34:20 theanets.trainer:168 RmsProp 677 loss=0.094030 err=0.094030
I 2015-05-26 09:34:26 theanets.trainer:168 RmsProp 678 loss=0.086252 err=0.086252
I 2015-05-26 09:34:32 theanets.trainer:168 RmsProp 679 loss=0.101157 err=0.101157
I 2015-05-26 09:34:39 theanets.trainer:168 RmsProp 680 loss=0.096124 err=0.096124
I 2015-05-26 09:34:40 theanets.trainer:168 validation 68 loss=1192.192383 err=1192.192383 *
I 2015-05-26 09:34:46 theanets.trainer:168 RmsProp 681 loss=0.095310 err=0.095310
I 2015-05-26 09:34:53 theanets.trainer:168 RmsProp 682 loss=0.090071 err=0.090071
I 2015-05-26 09:34:59 theanets.trainer:168 RmsProp 683 loss=0.095972 err=0.095972
I 2015-05-26 09:35:06 theanets.trainer:168 RmsProp 684 loss=0.092692 err=0.092692
I 2015-05-26 09:35:13 theanets.trainer:168 RmsProp 685 loss=0.096960 err=0.096960
I 2015-05-26 09:35:20 theanets.trainer:168 RmsProp 686 loss=0.095061 err=0.095061
I 2015-05-26 09:35:26 theanets.trainer:168 RmsProp 687 loss=0.092065 err=0.092065
I 2015-05-26 09:35:33 theanets.trainer:168 RmsProp 688 loss=0.089897 err=0.089897
I 2015-05-26 09:35:40 theanets.trainer:168 RmsProp 689 loss=0.093604 err=0.093604
I 2015-05-26 09:35:47 theanets.trainer:168 RmsProp 690 loss=0.089604 err=0.089604
I 2015-05-26 09:35:47 theanets.trainer:168 validation 69 loss=1191.461548 err=1191.461548 *
I 2015-05-26 09:35:54 theanets.trainer:168 RmsProp 691 loss=0.095856 err=0.095856
I 2015-05-26 09:36:01 theanets.trainer:168 RmsProp 692 loss=0.087784 err=0.087784
I 2015-05-26 09:36:08 theanets.trainer:168 RmsProp 693 loss=0.093176 err=0.093176
I 2015-05-26 09:36:15 theanets.trainer:168 RmsProp 694 loss=0.104110 err=0.104110
I 2015-05-26 09:36:21 theanets.trainer:168 RmsProp 695 loss=0.088158 err=0.088158
I 2015-05-26 09:36:28 theanets.trainer:168 RmsProp 696 loss=0.093045 err=0.093045
I 2015-05-26 09:36:34 theanets.trainer:168 RmsProp 697 loss=0.090087 err=0.090087
I 2015-05-26 09:36:41 theanets.trainer:168 RmsProp 698 loss=0.095193 err=0.095193
I 2015-05-26 09:36:48 theanets.trainer:168 RmsProp 699 loss=0.088232 err=0.088232
I 2015-05-26 09:36:55 theanets.trainer:168 RmsProp 700 loss=0.087560 err=0.087560
I 2015-05-26 09:36:55 theanets.trainer:168 validation 70 loss=1190.950928 err=1190.950928 *
I 2015-05-26 09:37:02 theanets.trainer:168 RmsProp 701 loss=0.087668 err=0.087668
I 2015-05-26 09:37:09 theanets.trainer:168 RmsProp 702 loss=0.092301 err=0.092301
I 2015-05-26 09:37:15 theanets.trainer:168 RmsProp 703 loss=0.092425 err=0.092425
I 2015-05-26 09:37:22 theanets.trainer:168 RmsProp 704 loss=0.087687 err=0.087687
I 2015-05-26 09:37:28 theanets.trainer:168 RmsProp 705 loss=0.091781 err=0.091781
I 2015-05-26 09:37:34 theanets.trainer:168 RmsProp 706 loss=0.090164 err=0.090164
I 2015-05-26 09:37:41 theanets.trainer:168 RmsProp 707 loss=0.088522 err=0.088522
I 2015-05-26 09:37:47 theanets.trainer:168 RmsProp 708 loss=0.089813 err=0.089813
I 2015-05-26 09:37:54 theanets.trainer:168 RmsProp 709 loss=0.093651 err=0.093651
I 2015-05-26 09:38:01 theanets.trainer:168 RmsProp 710 loss=0.087733 err=0.087733
I 2015-05-26 09:38:01 theanets.trainer:168 validation 71 loss=1189.996948 err=1189.996948 *
I 2015-05-26 09:38:08 theanets.trainer:168 RmsProp 711 loss=0.091436 err=0.091436
I 2015-05-26 09:38:14 theanets.trainer:168 RmsProp 712 loss=0.099113 err=0.099113
I 2015-05-26 09:38:21 theanets.trainer:168 RmsProp 713 loss=0.088423 err=0.088423
I 2015-05-26 09:38:28 theanets.trainer:168 RmsProp 714 loss=0.089103 err=0.089103
I 2015-05-26 09:38:35 theanets.trainer:168 RmsProp 715 loss=0.086996 err=0.086996
I 2015-05-26 09:38:41 theanets.trainer:168 RmsProp 716 loss=0.081759 err=0.081759
I 2015-05-26 09:38:48 theanets.trainer:168 RmsProp 717 loss=0.088940 err=0.088940
I 2015-05-26 09:38:54 theanets.trainer:168 RmsProp 718 loss=0.093741 err=0.093741
I 2015-05-26 09:39:01 theanets.trainer:168 RmsProp 719 loss=0.087467 err=0.087467
I 2015-05-26 09:39:07 theanets.trainer:168 RmsProp 720 loss=0.089152 err=0.089152
I 2015-05-26 09:39:07 theanets.trainer:168 validation 72 loss=1188.141479 err=1188.141479 *
I 2015-05-26 09:39:14 theanets.trainer:168 RmsProp 721 loss=0.089908 err=0.089908
I 2015-05-26 09:39:21 theanets.trainer:168 RmsProp 722 loss=0.082863 err=0.082863
I 2015-05-26 09:39:27 theanets.trainer:168 RmsProp 723 loss=0.089550 err=0.089550
I 2015-05-26 09:39:34 theanets.trainer:168 RmsProp 724 loss=0.090236 err=0.090236
I 2015-05-26 09:39:41 theanets.trainer:168 RmsProp 725 loss=0.087723 err=0.087723
I 2015-05-26 09:39:48 theanets.trainer:168 RmsProp 726 loss=0.085207 err=0.085207
I 2015-05-26 09:39:55 theanets.trainer:168 RmsProp 727 loss=0.092713 err=0.092713
I 2015-05-26 09:40:03 theanets.trainer:168 RmsProp 728 loss=0.090709 err=0.090709
I 2015-05-26 09:40:10 theanets.trainer:168 RmsProp 729 loss=0.085786 err=0.085786
I 2015-05-26 09:40:17 theanets.trainer:168 RmsProp 730 loss=0.083617 err=0.083617
I 2015-05-26 09:40:17 theanets.trainer:168 validation 73 loss=1188.707397 err=1188.707397
I 2015-05-26 09:40:23 theanets.trainer:168 RmsProp 731 loss=0.090996 err=0.090996
I 2015-05-26 09:40:31 theanets.trainer:168 RmsProp 732 loss=0.090123 err=0.090123
I 2015-05-26 09:40:38 theanets.trainer:168 RmsProp 733 loss=0.088449 err=0.088449
I 2015-05-26 09:40:44 theanets.trainer:168 RmsProp 734 loss=0.086817 err=0.086817
I 2015-05-26 09:40:51 theanets.trainer:168 RmsProp 735 loss=0.088371 err=0.088371
I 2015-05-26 09:40:57 theanets.trainer:168 RmsProp 736 loss=0.088505 err=0.088505
I 2015-05-26 09:41:04 theanets.trainer:168 RmsProp 737 loss=0.080541 err=0.080541
I 2015-05-26 09:41:11 theanets.trainer:168 RmsProp 738 loss=0.093515 err=0.093515
I 2015-05-26 09:41:18 theanets.trainer:168 RmsProp 739 loss=0.086938 err=0.086938
I 2015-05-26 09:41:24 theanets.trainer:168 RmsProp 740 loss=0.084120 err=0.084120
I 2015-05-26 09:41:25 theanets.trainer:168 validation 74 loss=1188.506592 err=1188.506592
I 2015-05-26 09:41:31 theanets.trainer:168 RmsProp 741 loss=0.086797 err=0.086797
I 2015-05-26 09:41:38 theanets.trainer:168 RmsProp 742 loss=0.083579 err=0.083579
I 2015-05-26 09:41:45 theanets.trainer:168 RmsProp 743 loss=0.081915 err=0.081915
I 2015-05-26 09:41:51 theanets.trainer:168 RmsProp 744 loss=0.102710 err=0.102710
I 2015-05-26 09:41:58 theanets.trainer:168 RmsProp 745 loss=0.086106 err=0.086106
I 2015-05-26 09:42:05 theanets.trainer:168 RmsProp 746 loss=0.082325 err=0.082325
I 2015-05-26 09:42:11 theanets.trainer:168 RmsProp 747 loss=0.080386 err=0.080386
I 2015-05-26 09:42:18 theanets.trainer:168 RmsProp 748 loss=0.090664 err=0.090664
I 2015-05-26 09:42:24 theanets.trainer:168 RmsProp 749 loss=0.078324 err=0.078324
I 2015-05-26 09:42:31 theanets.trainer:168 RmsProp 750 loss=0.097871 err=0.097871
I 2015-05-26 09:42:31 theanets.trainer:168 validation 75 loss=1187.304688 err=1187.304688 *
I 2015-05-26 09:42:38 theanets.trainer:168 RmsProp 751 loss=0.082282 err=0.082282
I 2015-05-26 09:42:45 theanets.trainer:168 RmsProp 752 loss=0.086303 err=0.086303
I 2015-05-26 09:42:51 theanets.trainer:168 RmsProp 753 loss=0.086358 err=0.086358
I 2015-05-26 09:42:58 theanets.trainer:168 RmsProp 754 loss=0.088674 err=0.088674
I 2015-05-26 09:43:06 theanets.trainer:168 RmsProp 755 loss=0.079331 err=0.079331
I 2015-05-26 09:43:12 theanets.trainer:168 RmsProp 756 loss=0.093300 err=0.093300
I 2015-05-26 09:43:18 theanets.trainer:168 RmsProp 757 loss=0.093063 err=0.093063
I 2015-05-26 09:43:25 theanets.trainer:168 RmsProp 758 loss=0.084169 err=0.084169
I 2015-05-26 09:43:31 theanets.trainer:168 RmsProp 759 loss=0.078876 err=0.078876
I 2015-05-26 09:43:38 theanets.trainer:168 RmsProp 760 loss=0.089368 err=0.089368
I 2015-05-26 09:43:38 theanets.trainer:168 validation 76 loss=1188.284424 err=1188.284424
I 2015-05-26 09:43:45 theanets.trainer:168 RmsProp 761 loss=0.085475 err=0.085475
I 2015-05-26 09:43:51 theanets.trainer:168 RmsProp 762 loss=0.081417 err=0.081417
I 2015-05-26 09:43:57 theanets.trainer:168 RmsProp 763 loss=0.083447 err=0.083447
I 2015-05-26 09:44:03 theanets.trainer:168 RmsProp 764 loss=0.082218 err=0.082218
I 2015-05-26 09:44:10 theanets.trainer:168 RmsProp 765 loss=0.081651 err=0.081651
I 2015-05-26 09:44:18 theanets.trainer:168 RmsProp 766 loss=0.083391 err=0.083391
I 2015-05-26 09:44:24 theanets.trainer:168 RmsProp 767 loss=0.080978 err=0.080978
I 2015-05-26 09:44:32 theanets.trainer:168 RmsProp 768 loss=0.080821 err=0.080821
I 2015-05-26 09:44:39 theanets.trainer:168 RmsProp 769 loss=0.085296 err=0.085296
I 2015-05-26 09:44:45 theanets.trainer:168 RmsProp 770 loss=0.084426 err=0.084426
I 2015-05-26 09:44:46 theanets.trainer:168 validation 77 loss=1184.956787 err=1184.956787 *
I 2015-05-26 09:44:53 theanets.trainer:168 RmsProp 771 loss=0.079933 err=0.079933
I 2015-05-26 09:44:59 theanets.trainer:168 RmsProp 772 loss=0.087314 err=0.087314
I 2015-05-26 09:45:06 theanets.trainer:168 RmsProp 773 loss=0.080474 err=0.080474
I 2015-05-26 09:45:13 theanets.trainer:168 RmsProp 774 loss=0.079696 err=0.079696
I 2015-05-26 09:45:20 theanets.trainer:168 RmsProp 775 loss=0.084126 err=0.084126
I 2015-05-26 09:45:27 theanets.trainer:168 RmsProp 776 loss=0.079278 err=0.079278
I 2015-05-26 09:45:34 theanets.trainer:168 RmsProp 777 loss=0.089275 err=0.089275
I 2015-05-26 09:45:41 theanets.trainer:168 RmsProp 778 loss=0.084406 err=0.084406
I 2015-05-26 09:45:47 theanets.trainer:168 RmsProp 779 loss=0.081631 err=0.081631
I 2015-05-26 09:45:54 theanets.trainer:168 RmsProp 780 loss=0.079358 err=0.079358
I 2015-05-26 09:45:55 theanets.trainer:168 validation 78 loss=1184.513428 err=1184.513428 *
I 2015-05-26 09:46:01 theanets.trainer:168 RmsProp 781 loss=0.085585 err=0.085585
I 2015-05-26 09:46:08 theanets.trainer:168 RmsProp 782 loss=0.080715 err=0.080715
I 2015-05-26 09:46:15 theanets.trainer:168 RmsProp 783 loss=0.089184 err=0.089184
I 2015-05-26 09:46:22 theanets.trainer:168 RmsProp 784 loss=0.080384 err=0.080384
I 2015-05-26 09:46:29 theanets.trainer:168 RmsProp 785 loss=0.078445 err=0.078445
I 2015-05-26 09:46:36 theanets.trainer:168 RmsProp 786 loss=0.082011 err=0.082011
I 2015-05-26 09:46:43 theanets.trainer:168 RmsProp 787 loss=0.079862 err=0.079862
I 2015-05-26 09:46:49 theanets.trainer:168 RmsProp 788 loss=0.078693 err=0.078693
I 2015-05-26 09:46:56 theanets.trainer:168 RmsProp 789 loss=0.080356 err=0.080356
I 2015-05-26 09:47:03 theanets.trainer:168 RmsProp 790 loss=0.082936 err=0.082936
I 2015-05-26 09:47:04 theanets.trainer:168 validation 79 loss=1183.614380 err=1183.614380 *
I 2015-05-26 09:47:11 theanets.trainer:168 RmsProp 791 loss=0.087154 err=0.087154
I 2015-05-26 09:47:17 theanets.trainer:168 RmsProp 792 loss=0.077882 err=0.077882
I 2015-05-26 09:47:23 theanets.trainer:168 RmsProp 793 loss=0.084733 err=0.084733
I 2015-05-26 09:47:30 theanets.trainer:168 RmsProp 794 loss=0.077257 err=0.077257
I 2015-05-26 09:47:37 theanets.trainer:168 RmsProp 795 loss=0.083622 err=0.083622
I 2015-05-26 09:47:45 theanets.trainer:168 RmsProp 796 loss=0.081206 err=0.081206
I 2015-05-26 09:47:51 theanets.trainer:168 RmsProp 797 loss=0.082557 err=0.082557
I 2015-05-26 09:47:57 theanets.trainer:168 RmsProp 798 loss=0.075017 err=0.075017
I 2015-05-26 09:48:04 theanets.trainer:168 RmsProp 799 loss=0.083854 err=0.083854
I 2015-05-26 09:48:11 theanets.trainer:168 RmsProp 800 loss=0.072552 err=0.072552
I 2015-05-26 09:48:11 theanets.trainer:168 validation 80 loss=1181.758179 err=1181.758179 *
I 2015-05-26 09:48:18 theanets.trainer:168 RmsProp 801 loss=0.092538 err=0.092538
I 2015-05-26 09:48:25 theanets.trainer:168 RmsProp 802 loss=0.075545 err=0.075545
I 2015-05-26 09:48:32 theanets.trainer:168 RmsProp 803 loss=0.083733 err=0.083733
I 2015-05-26 09:48:38 theanets.trainer:168 RmsProp 804 loss=0.078967 err=0.078967
I 2015-05-26 09:48:45 theanets.trainer:168 RmsProp 805 loss=0.078132 err=0.078132
I 2015-05-26 09:48:52 theanets.trainer:168 RmsProp 806 loss=0.080027 err=0.080027
I 2015-05-26 09:48:59 theanets.trainer:168 RmsProp 807 loss=0.081971 err=0.081971
I 2015-05-26 09:49:06 theanets.trainer:168 RmsProp 808 loss=0.081375 err=0.081375
I 2015-05-26 09:49:12 theanets.trainer:168 RmsProp 809 loss=0.070438 err=0.070438
I 2015-05-26 09:49:19 theanets.trainer:168 RmsProp 810 loss=0.088738 err=0.088738
I 2015-05-26 09:49:20 theanets.trainer:168 validation 81 loss=1182.288696 err=1182.288696
I 2015-05-26 09:49:26 theanets.trainer:168 RmsProp 811 loss=0.076363 err=0.076363
I 2015-05-26 09:49:32 theanets.trainer:168 RmsProp 812 loss=0.081214 err=0.081214
I 2015-05-26 09:49:39 theanets.trainer:168 RmsProp 813 loss=0.085371 err=0.085371
I 2015-05-26 09:49:45 theanets.trainer:168 RmsProp 814 loss=0.081575 err=0.081575
I 2015-05-26 09:49:52 theanets.trainer:168 RmsProp 815 loss=0.078728 err=0.078728
I 2015-05-26 09:49:58 theanets.trainer:168 RmsProp 816 loss=0.077155 err=0.077155
I 2015-05-26 09:50:05 theanets.trainer:168 RmsProp 817 loss=0.077951 err=0.077951
I 2015-05-26 09:50:11 theanets.trainer:168 RmsProp 818 loss=0.082538 err=0.082538
I 2015-05-26 09:50:18 theanets.trainer:168 RmsProp 819 loss=0.084709 err=0.084709
I 2015-05-26 09:50:25 theanets.trainer:168 RmsProp 820 loss=0.081610 err=0.081610
I 2015-05-26 09:50:25 theanets.trainer:168 validation 82 loss=1180.393799 err=1180.393799 *
I 2015-05-26 09:50:32 theanets.trainer:168 RmsProp 821 loss=0.078060 err=0.078060
I 2015-05-26 09:50:38 theanets.trainer:168 RmsProp 822 loss=0.078814 err=0.078814
I 2015-05-26 09:50:46 theanets.trainer:168 RmsProp 823 loss=0.078480 err=0.078480
I 2015-05-26 09:50:52 theanets.trainer:168 RmsProp 824 loss=0.078554 err=0.078554
I 2015-05-26 09:50:59 theanets.trainer:168 RmsProp 825 loss=0.076434 err=0.076434
I 2015-05-26 09:51:05 theanets.trainer:168 RmsProp 826 loss=0.080840 err=0.080840
I 2015-05-26 09:51:12 theanets.trainer:168 RmsProp 827 loss=0.076816 err=0.076816
I 2015-05-26 09:51:18 theanets.trainer:168 RmsProp 828 loss=0.083843 err=0.083843
I 2015-05-26 09:51:25 theanets.trainer:168 RmsProp 829 loss=0.076567 err=0.076567
I 2015-05-26 09:51:32 theanets.trainer:168 RmsProp 830 loss=0.079275 err=0.079275
I 2015-05-26 09:51:32 theanets.trainer:168 validation 83 loss=1180.708984 err=1180.708984
I 2015-05-26 09:51:39 theanets.trainer:168 RmsProp 831 loss=0.076643 err=0.076643
I 2015-05-26 09:51:46 theanets.trainer:168 RmsProp 832 loss=0.077539 err=0.077539
I 2015-05-26 09:51:52 theanets.trainer:168 RmsProp 833 loss=0.073933 err=0.073933
I 2015-05-26 09:51:59 theanets.trainer:168 RmsProp 834 loss=0.081105 err=0.081105
I 2015-05-26 09:52:06 theanets.trainer:168 RmsProp 835 loss=0.077186 err=0.077186
I 2015-05-26 09:52:13 theanets.trainer:168 RmsProp 836 loss=0.076609 err=0.076609
I 2015-05-26 09:52:19 theanets.trainer:168 RmsProp 837 loss=0.079453 err=0.079453
I 2015-05-26 09:52:26 theanets.trainer:168 RmsProp 838 loss=0.081084 err=0.081084
I 2015-05-26 09:52:33 theanets.trainer:168 RmsProp 839 loss=0.080692 err=0.080692
I 2015-05-26 09:52:40 theanets.trainer:168 RmsProp 840 loss=0.079091 err=0.079091
I 2015-05-26 09:52:40 theanets.trainer:168 validation 84 loss=1178.714111 err=1178.714111 *
I 2015-05-26 09:52:47 theanets.trainer:168 RmsProp 841 loss=0.074601 err=0.074601
I 2015-05-26 09:52:54 theanets.trainer:168 RmsProp 842 loss=0.078762 err=0.078762
I 2015-05-26 09:53:01 theanets.trainer:168 RmsProp 843 loss=0.076854 err=0.076854
I 2015-05-26 09:53:07 theanets.trainer:168 RmsProp 844 loss=0.081356 err=0.081356
I 2015-05-26 09:53:14 theanets.trainer:168 RmsProp 845 loss=0.071933 err=0.071933
I 2015-05-26 09:53:20 theanets.trainer:168 RmsProp 846 loss=0.081271 err=0.081271
I 2015-05-26 09:53:27 theanets.trainer:168 RmsProp 847 loss=0.074665 err=0.074665
I 2015-05-26 09:53:33 theanets.trainer:168 RmsProp 848 loss=0.073026 err=0.073026
I 2015-05-26 09:53:40 theanets.trainer:168 RmsProp 849 loss=0.082222 err=0.082222
I 2015-05-26 09:53:47 theanets.trainer:168 RmsProp 850 loss=0.075715 err=0.075715
I 2015-05-26 09:53:47 theanets.trainer:168 validation 85 loss=1179.102539 err=1179.102539
I 2015-05-26 09:53:54 theanets.trainer:168 RmsProp 851 loss=0.077319 err=0.077319
I 2015-05-26 09:54:00 theanets.trainer:168 RmsProp 852 loss=0.076172 err=0.076172
I 2015-05-26 09:54:07 theanets.trainer:168 RmsProp 853 loss=0.076216 err=0.076216
I 2015-05-26 09:54:14 theanets.trainer:168 RmsProp 854 loss=0.073868 err=0.073868
I 2015-05-26 09:54:22 theanets.trainer:168 RmsProp 855 loss=0.083701 err=0.083701
I 2015-05-26 09:54:29 theanets.trainer:168 RmsProp 856 loss=0.078252 err=0.078252
I 2015-05-26 09:54:36 theanets.trainer:168 RmsProp 857 loss=0.079424 err=0.079424
I 2015-05-26 09:54:44 theanets.trainer:168 RmsProp 858 loss=0.075553 err=0.075553
I 2015-05-26 09:54:50 theanets.trainer:168 RmsProp 859 loss=0.075936 err=0.075936
I 2015-05-26 09:54:57 theanets.trainer:168 RmsProp 860 loss=0.075477 err=0.075477
I 2015-05-26 09:54:58 theanets.trainer:168 validation 86 loss=1177.538452 err=1177.538452 *
I 2015-05-26 09:55:04 theanets.trainer:168 RmsProp 861 loss=0.076160 err=0.076160
I 2015-05-26 09:55:12 theanets.trainer:168 RmsProp 862 loss=0.076054 err=0.076054
I 2015-05-26 09:55:18 theanets.trainer:168 RmsProp 863 loss=0.073854 err=0.073854
I 2015-05-26 09:55:25 theanets.trainer:168 RmsProp 864 loss=0.079444 err=0.079444
I 2015-05-26 09:55:31 theanets.trainer:168 RmsProp 865 loss=0.075872 err=0.075872
I 2015-05-26 09:55:38 theanets.trainer:168 RmsProp 866 loss=0.073820 err=0.073820
I 2015-05-26 09:55:45 theanets.trainer:168 RmsProp 867 loss=0.078802 err=0.078802
I 2015-05-26 09:55:52 theanets.trainer:168 RmsProp 868 loss=0.075189 err=0.075189
I 2015-05-26 09:55:59 theanets.trainer:168 RmsProp 869 loss=0.074319 err=0.074319
I 2015-05-26 09:56:06 theanets.trainer:168 RmsProp 870 loss=0.082072 err=0.082072
I 2015-05-26 09:56:07 theanets.trainer:168 validation 87 loss=1178.149780 err=1178.149780
I 2015-05-26 09:56:13 theanets.trainer:168 RmsProp 871 loss=0.073067 err=0.073067
I 2015-05-26 09:56:20 theanets.trainer:168 RmsProp 872 loss=0.074967 err=0.074967
I 2015-05-26 09:56:26 theanets.trainer:168 RmsProp 873 loss=0.073907 err=0.073907
I 2015-05-26 09:56:33 theanets.trainer:168 RmsProp 874 loss=0.075668 err=0.075668
I 2015-05-26 09:56:40 theanets.trainer:168 RmsProp 875 loss=0.073721 err=0.073721
I 2015-05-26 09:56:47 theanets.trainer:168 RmsProp 876 loss=0.078962 err=0.078962
I 2015-05-26 09:56:55 theanets.trainer:168 RmsProp 877 loss=0.074554 err=0.074554
I 2015-05-26 09:57:01 theanets.trainer:168 RmsProp 878 loss=0.071575 err=0.071575
I 2015-05-26 09:57:08 theanets.trainer:168 RmsProp 879 loss=0.074643 err=0.074643
I 2015-05-26 09:57:14 theanets.trainer:168 RmsProp 880 loss=0.073885 err=0.073885
I 2015-05-26 09:57:14 theanets.trainer:168 validation 88 loss=1176.824585 err=1176.824585 *
I 2015-05-26 09:57:21 theanets.trainer:168 RmsProp 881 loss=0.073476 err=0.073476
I 2015-05-26 09:57:28 theanets.trainer:168 RmsProp 882 loss=0.073638 err=0.073638
I 2015-05-26 09:57:35 theanets.trainer:168 RmsProp 883 loss=0.076894 err=0.076894
I 2015-05-26 09:57:42 theanets.trainer:168 RmsProp 884 loss=0.070612 err=0.070612
I 2015-05-26 09:57:49 theanets.trainer:168 RmsProp 885 loss=0.076505 err=0.076505
I 2015-05-26 09:57:56 theanets.trainer:168 RmsProp 886 loss=0.071295 err=0.071295
I 2015-05-26 09:58:03 theanets.trainer:168 RmsProp 887 loss=0.072238 err=0.072238
I 2015-05-26 09:58:10 theanets.trainer:168 RmsProp 888 loss=0.081983 err=0.081983
I 2015-05-26 09:58:18 theanets.trainer:168 RmsProp 889 loss=0.071208 err=0.071208
I 2015-05-26 09:58:24 theanets.trainer:168 RmsProp 890 loss=0.068592 err=0.068592
I 2015-05-26 09:58:25 theanets.trainer:168 validation 89 loss=1176.751343 err=1176.751343 *
I 2015-05-26 09:58:31 theanets.trainer:168 RmsProp 891 loss=0.075890 err=0.075890
I 2015-05-26 09:58:39 theanets.trainer:168 RmsProp 892 loss=0.076276 err=0.076276
I 2015-05-26 09:58:45 theanets.trainer:168 RmsProp 893 loss=0.073129 err=0.073129
I 2015-05-26 09:58:52 theanets.trainer:168 RmsProp 894 loss=0.073877 err=0.073877
I 2015-05-26 09:58:58 theanets.trainer:168 RmsProp 895 loss=0.075590 err=0.075590
I 2015-05-26 09:59:06 theanets.trainer:168 RmsProp 896 loss=0.073495 err=0.073495
I 2015-05-26 09:59:12 theanets.trainer:168 RmsProp 897 loss=0.070244 err=0.070244
I 2015-05-26 09:59:19 theanets.trainer:168 RmsProp 898 loss=0.075225 err=0.075225
I 2015-05-26 09:59:26 theanets.trainer:168 RmsProp 899 loss=0.071319 err=0.071319
I 2015-05-26 09:59:33 theanets.trainer:168 RmsProp 900 loss=0.077502 err=0.077502
I 2015-05-26 09:59:33 theanets.trainer:168 validation 90 loss=1173.859863 err=1173.859863 *
I 2015-05-26 09:59:40 theanets.trainer:168 RmsProp 901 loss=0.074183 err=0.074183
I 2015-05-26 09:59:47 theanets.trainer:168 RmsProp 902 loss=0.075643 err=0.075643
I 2015-05-26 09:59:54 theanets.trainer:168 RmsProp 903 loss=0.067757 err=0.067757
I 2015-05-26 10:00:02 theanets.trainer:168 RmsProp 904 loss=0.079556 err=0.079556
I 2015-05-26 10:00:08 theanets.trainer:168 RmsProp 905 loss=0.076350 err=0.076350
I 2015-05-26 10:00:15 theanets.trainer:168 RmsProp 906 loss=0.072798 err=0.072798
I 2015-05-26 10:00:22 theanets.trainer:168 RmsProp 907 loss=0.071192 err=0.071192
I 2015-05-26 10:00:28 theanets.trainer:168 RmsProp 908 loss=0.069854 err=0.069854
I 2015-05-26 10:00:34 theanets.trainer:168 RmsProp 909 loss=0.083404 err=0.083404
I 2015-05-26 10:00:41 theanets.trainer:168 RmsProp 910 loss=0.070110 err=0.070110
I 2015-05-26 10:00:41 theanets.trainer:168 validation 91 loss=1174.133179 err=1174.133179
I 2015-05-26 10:00:48 theanets.trainer:168 RmsProp 911 loss=0.067558 err=0.067558
I 2015-05-26 10:00:55 theanets.trainer:168 RmsProp 912 loss=0.071864 err=0.071864
I 2015-05-26 10:01:01 theanets.trainer:168 RmsProp 913 loss=0.071380 err=0.071380
I 2015-05-26 10:01:08 theanets.trainer:168 RmsProp 914 loss=0.070507 err=0.070507
I 2015-05-26 10:01:16 theanets.trainer:168 RmsProp 915 loss=0.075506 err=0.075506
I 2015-05-26 10:01:22 theanets.trainer:168 RmsProp 916 loss=0.073005 err=0.073005
I 2015-05-26 10:01:29 theanets.trainer:168 RmsProp 917 loss=0.074643 err=0.074643
I 2015-05-26 10:01:36 theanets.trainer:168 RmsProp 918 loss=0.072026 err=0.072026
I 2015-05-26 10:01:43 theanets.trainer:168 RmsProp 919 loss=0.073039 err=0.073039
I 2015-05-26 10:01:50 theanets.trainer:168 RmsProp 920 loss=0.067115 err=0.067115
I 2015-05-26 10:01:50 theanets.trainer:168 validation 92 loss=1174.021362 err=1174.021362
I 2015-05-26 10:01:57 theanets.trainer:168 RmsProp 921 loss=0.081283 err=0.081283
I 2015-05-26 10:02:04 theanets.trainer:168 RmsProp 922 loss=0.067330 err=0.067330
I 2015-05-26 10:02:11 theanets.trainer:168 RmsProp 923 loss=0.079981 err=0.079981
I 2015-05-26 10:02:18 theanets.trainer:168 RmsProp 924 loss=0.071394 err=0.071394
I 2015-05-26 10:02:25 theanets.trainer:168 RmsProp 925 loss=0.069144 err=0.069144
I 2015-05-26 10:02:32 theanets.trainer:168 RmsProp 926 loss=0.070801 err=0.070801
I 2015-05-26 10:02:40 theanets.trainer:168 RmsProp 927 loss=0.071192 err=0.071192
I 2015-05-26 10:02:47 theanets.trainer:168 RmsProp 928 loss=0.069523 err=0.069523
I 2015-05-26 10:02:53 theanets.trainer:168 RmsProp 929 loss=0.077721 err=0.077721
I 2015-05-26 10:03:00 theanets.trainer:168 RmsProp 930 loss=0.072819 err=0.072819
I 2015-05-26 10:03:01 theanets.trainer:168 validation 93 loss=1172.786133 err=1172.786133 *
I 2015-05-26 10:03:07 theanets.trainer:168 RmsProp 931 loss=0.070299 err=0.070299
I 2015-05-26 10:03:14 theanets.trainer:168 RmsProp 932 loss=0.066923 err=0.066923
I 2015-05-26 10:03:21 theanets.trainer:168 RmsProp 933 loss=0.077044 err=0.077044
I 2015-05-26 10:03:27 theanets.trainer:168 RmsProp 934 loss=0.074136 err=0.074136
I 2015-05-26 10:03:34 theanets.trainer:168 RmsProp 935 loss=0.067834 err=0.067834
I 2015-05-26 10:03:41 theanets.trainer:168 RmsProp 936 loss=0.061261 err=0.061261
I 2015-05-26 10:03:48 theanets.trainer:168 RmsProp 937 loss=0.085150 err=0.085150
I 2015-05-26 10:03:54 theanets.trainer:168 RmsProp 938 loss=0.070266 err=0.070266
I 2015-05-26 10:04:01 theanets.trainer:168 RmsProp 939 loss=0.065164 err=0.065164
I 2015-05-26 10:04:07 theanets.trainer:168 RmsProp 940 loss=0.078480 err=0.078480
I 2015-05-26 10:04:08 theanets.trainer:168 validation 94 loss=1171.706421 err=1171.706421 *
I 2015-05-26 10:04:14 theanets.trainer:168 RmsProp 941 loss=0.064062 err=0.064062
I 2015-05-26 10:04:20 theanets.trainer:168 RmsProp 942 loss=0.070114 err=0.070114
I 2015-05-26 10:04:26 theanets.trainer:168 RmsProp 943 loss=0.068119 err=0.068119
I 2015-05-26 10:04:32 theanets.trainer:168 RmsProp 944 loss=0.072840 err=0.072840
I 2015-05-26 10:04:38 theanets.trainer:168 RmsProp 945 loss=0.067880 err=0.067880
I 2015-05-26 10:04:44 theanets.trainer:168 RmsProp 946 loss=0.069688 err=0.069688
I 2015-05-26 10:04:50 theanets.trainer:168 RmsProp 947 loss=0.068008 err=0.068008
I 2015-05-26 10:04:56 theanets.trainer:168 RmsProp 948 loss=0.069471 err=0.069471
I 2015-05-26 10:05:02 theanets.trainer:168 RmsProp 949 loss=0.073938 err=0.073938
I 2015-05-26 10:05:08 theanets.trainer:168 RmsProp 950 loss=0.063856 err=0.063856
I 2015-05-26 10:05:08 theanets.trainer:168 validation 95 loss=1172.026001 err=1172.026001
I 2015-05-26 10:05:14 theanets.trainer:168 RmsProp 951 loss=0.071822 err=0.071822
I 2015-05-26 10:05:20 theanets.trainer:168 RmsProp 952 loss=0.070732 err=0.070732
I 2015-05-26 10:05:26 theanets.trainer:168 RmsProp 953 loss=0.073877 err=0.073877
I 2015-05-26 10:05:33 theanets.trainer:168 RmsProp 954 loss=0.067155 err=0.067155
I 2015-05-26 10:05:39 theanets.trainer:168 RmsProp 955 loss=0.066152 err=0.066152
I 2015-05-26 10:05:45 theanets.trainer:168 RmsProp 956 loss=0.072718 err=0.072718
I 2015-05-26 10:05:51 theanets.trainer:168 RmsProp 957 loss=0.069152 err=0.069152
I 2015-05-26 10:05:57 theanets.trainer:168 RmsProp 958 loss=0.066679 err=0.066679
I 2015-05-26 10:06:03 theanets.trainer:168 RmsProp 959 loss=0.071536 err=0.071536
I 2015-05-26 10:06:09 theanets.trainer:168 RmsProp 960 loss=0.064322 err=0.064322
I 2015-05-26 10:06:10 theanets.trainer:168 validation 96 loss=1172.628296 err=1172.628296
I 2015-05-26 10:06:15 theanets.trainer:168 RmsProp 961 loss=0.069721 err=0.069721
I 2015-05-26 10:06:22 theanets.trainer:168 RmsProp 962 loss=0.071236 err=0.071236
I 2015-05-26 10:06:28 theanets.trainer:168 RmsProp 963 loss=0.070231 err=0.070231
I 2015-05-26 10:06:34 theanets.trainer:168 RmsProp 964 loss=0.068669 err=0.068669
I 2015-05-26 10:06:40 theanets.trainer:168 RmsProp 965 loss=0.066338 err=0.066338
I 2015-05-26 10:06:46 theanets.trainer:168 RmsProp 966 loss=0.075450 err=0.075450
I 2015-05-26 10:06:52 theanets.trainer:168 RmsProp 967 loss=0.066589 err=0.066589
I 2015-05-26 10:06:58 theanets.trainer:168 RmsProp 968 loss=0.069540 err=0.069540
I 2015-05-26 10:07:04 theanets.trainer:168 RmsProp 969 loss=0.067699 err=0.067699
I 2015-05-26 10:07:11 theanets.trainer:168 RmsProp 970 loss=0.069393 err=0.069393
I 2015-05-26 10:07:11 theanets.trainer:168 validation 97 loss=1171.432739 err=1171.432739 *
I 2015-05-26 10:07:16 theanets.trainer:168 RmsProp 971 loss=0.069339 err=0.069339
I 2015-05-26 10:07:22 theanets.trainer:168 RmsProp 972 loss=0.066883 err=0.066883
I 2015-05-26 10:07:27 theanets.trainer:168 RmsProp 973 loss=0.072457 err=0.072457
I 2015-05-26 10:07:33 theanets.trainer:168 RmsProp 974 loss=0.069613 err=0.069613
I 2015-05-26 10:07:39 theanets.trainer:168 RmsProp 975 loss=0.066060 err=0.066060
I 2015-05-26 10:07:44 theanets.trainer:168 RmsProp 976 loss=0.063610 err=0.063610
I 2015-05-26 10:07:50 theanets.trainer:168 RmsProp 977 loss=0.074152 err=0.074152
I 2015-05-26 10:07:56 theanets.trainer:168 RmsProp 978 loss=0.068246 err=0.068246
I 2015-05-26 10:08:02 theanets.trainer:168 RmsProp 979 loss=0.069580 err=0.069580
I 2015-05-26 10:08:09 theanets.trainer:168 RmsProp 980 loss=0.066203 err=0.066203
I 2015-05-26 10:08:09 theanets.trainer:168 validation 98 loss=1171.090698 err=1171.090698 *
I 2015-05-26 10:08:15 theanets.trainer:168 RmsProp 981 loss=0.071101 err=0.071101
I 2015-05-26 10:08:21 theanets.trainer:168 RmsProp 982 loss=0.067280 err=0.067280
I 2015-05-26 10:08:27 theanets.trainer:168 RmsProp 983 loss=0.066614 err=0.066614
I 2015-05-26 10:08:34 theanets.trainer:168 RmsProp 984 loss=0.065332 err=0.065332
I 2015-05-26 10:08:40 theanets.trainer:168 RmsProp 985 loss=0.075144 err=0.075144
I 2015-05-26 10:08:45 theanets.trainer:168 RmsProp 986 loss=0.067240 err=0.067240
I 2015-05-26 10:08:52 theanets.trainer:168 RmsProp 987 loss=0.068227 err=0.068227
I 2015-05-26 10:08:58 theanets.trainer:168 RmsProp 988 loss=0.066252 err=0.066252
I 2015-05-26 10:09:04 theanets.trainer:168 RmsProp 989 loss=0.066324 err=0.066324
I 2015-05-26 10:09:10 theanets.trainer:168 RmsProp 990 loss=0.069348 err=0.069348
I 2015-05-26 10:09:10 theanets.trainer:168 validation 99 loss=1169.856567 err=1169.856567 *
I 2015-05-26 10:09:16 theanets.trainer:168 RmsProp 991 loss=0.067170 err=0.067170
I 2015-05-26 10:09:22 theanets.trainer:168 RmsProp 992 loss=0.064552 err=0.064552
I 2015-05-26 10:09:28 theanets.trainer:168 RmsProp 993 loss=0.077790 err=0.077790
I 2015-05-26 10:09:34 theanets.trainer:168 RmsProp 994 loss=0.067222 err=0.067222
I 2015-05-26 10:09:40 theanets.trainer:168 RmsProp 995 loss=0.058909 err=0.058909
I 2015-05-26 10:09:47 theanets.trainer:168 RmsProp 996 loss=0.081841 err=0.081841
I 2015-05-26 10:09:53 theanets.trainer:168 RmsProp 997 loss=0.070110 err=0.070110
I 2015-05-26 10:09:59 theanets.trainer:168 RmsProp 998 loss=0.065908 err=0.065908
I 2015-05-26 10:10:05 theanets.trainer:168 RmsProp 999 loss=0.063413 err=0.063413
I 2015-05-26 10:10:11 theanets.trainer:168 RmsProp 1000 loss=0.068377 err=0.068377
I 2015-05-26 10:10:12 theanets.trainer:168 validation 100 loss=1169.068604 err=1169.068604 *
I 2015-05-26 10:10:17 theanets.trainer:168 RmsProp 1001 loss=0.061935 err=0.061935
I 2015-05-26 10:10:24 theanets.trainer:168 RmsProp 1002 loss=0.069489 err=0.069489
I 2015-05-26 10:10:30 theanets.trainer:168 RmsProp 1003 loss=0.068590 err=0.068590
I 2015-05-26 10:10:36 theanets.trainer:168 RmsProp 1004 loss=0.065768 err=0.065768
I 2015-05-26 10:10:42 theanets.trainer:168 RmsProp 1005 loss=0.068657 err=0.068657
I 2015-05-26 10:10:48 theanets.trainer:168 RmsProp 1006 loss=0.062659 err=0.062659
I 2015-05-26 10:10:54 theanets.trainer:168 RmsProp 1007 loss=0.064992 err=0.064992
I 2015-05-26 10:11:00 theanets.trainer:168 RmsProp 1008 loss=0.066969 err=0.066969
I 2015-05-26 10:11:06 theanets.trainer:168 RmsProp 1009 loss=0.066242 err=0.066242
I 2015-05-26 10:11:11 theanets.trainer:168 RmsProp 1010 loss=0.065027 err=0.065027
I 2015-05-26 10:11:12 theanets.trainer:168 validation 101 loss=1168.765625 err=1168.765625 *
I 2015-05-26 10:11:17 theanets.trainer:168 RmsProp 1011 loss=0.074261 err=0.074261
I 2015-05-26 10:11:22 theanets.trainer:168 RmsProp 1012 loss=0.065442 err=0.065442
I 2015-05-26 10:11:28 theanets.trainer:168 RmsProp 1013 loss=0.065008 err=0.065008
I 2015-05-26 10:11:33 theanets.trainer:168 RmsProp 1014 loss=0.069629 err=0.069629
I 2015-05-26 10:11:39 theanets.trainer:168 RmsProp 1015 loss=0.067669 err=0.067669
I 2015-05-26 10:11:44 theanets.trainer:168 RmsProp 1016 loss=0.064254 err=0.064254
I 2015-05-26 10:11:50 theanets.trainer:168 RmsProp 1017 loss=0.065888 err=0.065888
I 2015-05-26 10:11:55 theanets.trainer:168 RmsProp 1018 loss=0.065040 err=0.065040
I 2015-05-26 10:12:01 theanets.trainer:168 RmsProp 1019 loss=0.075214 err=0.075214
I 2015-05-26 10:12:07 theanets.trainer:168 RmsProp 1020 loss=0.062445 err=0.062445
I 2015-05-26 10:12:08 theanets.trainer:168 validation 102 loss=1168.226196 err=1168.226196 *
I 2015-05-26 10:12:13 theanets.trainer:168 RmsProp 1021 loss=0.067139 err=0.067139
I 2015-05-26 10:12:19 theanets.trainer:168 RmsProp 1022 loss=0.064540 err=0.064540
I 2015-05-26 10:12:26 theanets.trainer:168 RmsProp 1023 loss=0.071882 err=0.071882
I 2015-05-26 10:12:32 theanets.trainer:168 RmsProp 1024 loss=0.061921 err=0.061921
I 2015-05-26 10:12:38 theanets.trainer:168 RmsProp 1025 loss=0.061676 err=0.061676
I 2015-05-26 10:12:44 theanets.trainer:168 RmsProp 1026 loss=0.072241 err=0.072241
I 2015-05-26 10:12:51 theanets.trainer:168 RmsProp 1027 loss=0.064206 err=0.064206
I 2015-05-26 10:12:57 theanets.trainer:168 RmsProp 1028 loss=0.072999 err=0.072999
I 2015-05-26 10:13:03 theanets.trainer:168 RmsProp 1029 loss=0.067596 err=0.067596
I 2015-05-26 10:13:09 theanets.trainer:168 RmsProp 1030 loss=0.066987 err=0.066987
I 2015-05-26 10:13:10 theanets.trainer:168 validation 103 loss=1167.297241 err=1167.297241 *
I 2015-05-26 10:13:15 theanets.trainer:168 RmsProp 1031 loss=0.065460 err=0.065460
I 2015-05-26 10:13:22 theanets.trainer:168 RmsProp 1032 loss=0.066913 err=0.066913
I 2015-05-26 10:13:27 theanets.trainer:168 RmsProp 1033 loss=0.067237 err=0.067237
I 2015-05-26 10:13:33 theanets.trainer:168 RmsProp 1034 loss=0.063081 err=0.063081
I 2015-05-26 10:13:39 theanets.trainer:168 RmsProp 1035 loss=0.066325 err=0.066325
I 2015-05-26 10:13:45 theanets.trainer:168 RmsProp 1036 loss=0.066135 err=0.066135
I 2015-05-26 10:13:51 theanets.trainer:168 RmsProp 1037 loss=0.074028 err=0.074028
I 2015-05-26 10:13:57 theanets.trainer:168 RmsProp 1038 loss=0.067893 err=0.067893
I 2015-05-26 10:14:03 theanets.trainer:168 RmsProp 1039 loss=0.063435 err=0.063435
I 2015-05-26 10:14:09 theanets.trainer:168 RmsProp 1040 loss=0.063378 err=0.063378
I 2015-05-26 10:14:09 theanets.trainer:168 validation 104 loss=1166.692871 err=1166.692871 *
I 2015-05-26 10:14:15 theanets.trainer:168 RmsProp 1041 loss=0.065908 err=0.065908
I 2015-05-26 10:14:21 theanets.trainer:168 RmsProp 1042 loss=0.067561 err=0.067561
I 2015-05-26 10:14:27 theanets.trainer:168 RmsProp 1043 loss=0.061044 err=0.061044
I 2015-05-26 10:14:34 theanets.trainer:168 RmsProp 1044 loss=0.065268 err=0.065268
I 2015-05-26 10:14:40 theanets.trainer:168 RmsProp 1045 loss=0.063636 err=0.063636
I 2015-05-26 10:14:46 theanets.trainer:168 RmsProp 1046 loss=0.061718 err=0.061718
I 2015-05-26 10:14:52 theanets.trainer:168 RmsProp 1047 loss=0.071251 err=0.071251
I 2015-05-26 10:14:59 theanets.trainer:168 RmsProp 1048 loss=0.064931 err=0.064931
I 2015-05-26 10:15:04 theanets.trainer:168 RmsProp 1049 loss=0.059950 err=0.059950
I 2015-05-26 10:15:11 theanets.trainer:168 RmsProp 1050 loss=0.069738 err=0.069738
I 2015-05-26 10:15:11 theanets.trainer:168 validation 105 loss=1166.973511 err=1166.973511
I 2015-05-26 10:15:16 theanets.trainer:168 RmsProp 1051 loss=0.063710 err=0.063710
I 2015-05-26 10:15:22 theanets.trainer:168 RmsProp 1052 loss=0.062818 err=0.062818
I 2015-05-26 10:15:27 theanets.trainer:168 RmsProp 1053 loss=0.064845 err=0.064845
I 2015-05-26 10:15:32 theanets.trainer:168 RmsProp 1054 loss=0.060737 err=0.060737
I 2015-05-26 10:15:39 theanets.trainer:168 RmsProp 1055 loss=0.059513 err=0.059513
I 2015-05-26 10:15:44 theanets.trainer:168 RmsProp 1056 loss=0.066087 err=0.066087
I 2015-05-26 10:15:50 theanets.trainer:168 RmsProp 1057 loss=0.066773 err=0.066773
I 2015-05-26 10:15:57 theanets.trainer:168 RmsProp 1058 loss=0.061008 err=0.061008
I 2015-05-26 10:16:02 theanets.trainer:168 RmsProp 1059 loss=0.063031 err=0.063031
I 2015-05-26 10:16:08 theanets.trainer:168 RmsProp 1060 loss=0.061538 err=0.061538
I 2015-05-26 10:16:09 theanets.trainer:168 validation 106 loss=1165.081665 err=1165.081665 *
I 2015-05-26 10:16:14 theanets.trainer:168 RmsProp 1061 loss=0.069507 err=0.069507
I 2015-05-26 10:16:20 theanets.trainer:168 RmsProp 1062 loss=0.062143 err=0.062143
I 2015-05-26 10:16:26 theanets.trainer:168 RmsProp 1063 loss=0.060968 err=0.060968
I 2015-05-26 10:16:32 theanets.trainer:168 RmsProp 1064 loss=0.063270 err=0.063270
I 2015-05-26 10:16:38 theanets.trainer:168 RmsProp 1065 loss=0.060741 err=0.060741
I 2015-05-26 10:16:45 theanets.trainer:168 RmsProp 1066 loss=0.064613 err=0.064613
I 2015-05-26 10:16:51 theanets.trainer:168 RmsProp 1067 loss=0.066251 err=0.066251
I 2015-05-26 10:16:57 theanets.trainer:168 RmsProp 1068 loss=0.059919 err=0.059919
I 2015-05-26 10:17:03 theanets.trainer:168 RmsProp 1069 loss=0.062472 err=0.062472
I 2015-05-26 10:17:09 theanets.trainer:168 RmsProp 1070 loss=0.061224 err=0.061224
I 2015-05-26 10:17:10 theanets.trainer:168 validation 107 loss=1164.044800 err=1164.044800 *
I 2015-05-26 10:17:15 theanets.trainer:168 RmsProp 1071 loss=0.067932 err=0.067932
I 2015-05-26 10:17:21 theanets.trainer:168 RmsProp 1072 loss=0.059521 err=0.059521
I 2015-05-26 10:17:27 theanets.trainer:168 RmsProp 1073 loss=0.061514 err=0.061514
I 2015-05-26 10:17:33 theanets.trainer:168 RmsProp 1074 loss=0.064240 err=0.064240
I 2015-05-26 10:17:39 theanets.trainer:168 RmsProp 1075 loss=0.059470 err=0.059470
I 2015-05-26 10:17:45 theanets.trainer:168 RmsProp 1076 loss=0.069939 err=0.069939
I 2015-05-26 10:17:52 theanets.trainer:168 RmsProp 1077 loss=0.059389 err=0.059389
I 2015-05-26 10:17:58 theanets.trainer:168 RmsProp 1078 loss=0.063511 err=0.063511
I 2015-05-26 10:18:04 theanets.trainer:168 RmsProp 1079 loss=0.059422 err=0.059422
I 2015-05-26 10:18:09 theanets.trainer:168 RmsProp 1080 loss=0.062477 err=0.062477
I 2015-05-26 10:18:10 theanets.trainer:168 validation 108 loss=1164.877197 err=1164.877197
I 2015-05-26 10:18:15 theanets.trainer:168 RmsProp 1081 loss=0.066628 err=0.066628
I 2015-05-26 10:18:21 theanets.trainer:168 RmsProp 1082 loss=0.061710 err=0.061710
I 2015-05-26 10:18:28 theanets.trainer:168 RmsProp 1083 loss=0.063213 err=0.063213
I 2015-05-26 10:18:33 theanets.trainer:168 RmsProp 1084 loss=0.061739 err=0.061739
I 2015-05-26 10:18:39 theanets.trainer:168 RmsProp 1085 loss=0.063358 err=0.063358
I 2015-05-26 10:18:46 theanets.trainer:168 RmsProp 1086 loss=0.062710 err=0.062710
I 2015-05-26 10:18:52 theanets.trainer:168 RmsProp 1087 loss=0.060279 err=0.060279
I 2015-05-26 10:18:58 theanets.trainer:168 RmsProp 1088 loss=0.066350 err=0.066350
I 2015-05-26 10:19:04 theanets.trainer:168 RmsProp 1089 loss=0.060469 err=0.060469
I 2015-05-26 10:19:10 theanets.trainer:168 RmsProp 1090 loss=0.063090 err=0.063090
I 2015-05-26 10:19:11 theanets.trainer:168 validation 109 loss=1164.247681 err=1164.247681
I 2015-05-26 10:19:16 theanets.trainer:168 RmsProp 1091 loss=0.061387 err=0.061387
I 2015-05-26 10:19:22 theanets.trainer:168 RmsProp 1092 loss=0.068552 err=0.068552
I 2015-05-26 10:19:29 theanets.trainer:168 RmsProp 1093 loss=0.060003 err=0.060003
I 2015-05-26 10:19:35 theanets.trainer:168 RmsProp 1094 loss=0.060806 err=0.060806
I 2015-05-26 10:19:41 theanets.trainer:168 RmsProp 1095 loss=0.058019 err=0.058019
I 2015-05-26 10:19:47 theanets.trainer:168 RmsProp 1096 loss=0.065374 err=0.065374
I 2015-05-26 10:19:53 theanets.trainer:168 RmsProp 1097 loss=0.062411 err=0.062411
I 2015-05-26 10:20:00 theanets.trainer:168 RmsProp 1098 loss=0.059280 err=0.059280
I 2015-05-26 10:20:06 theanets.trainer:168 RmsProp 1099 loss=0.069270 err=0.069270
I 2015-05-26 10:20:12 theanets.trainer:168 RmsProp 1100 loss=0.064804 err=0.064804
I 2015-05-26 10:20:12 theanets.trainer:168 validation 110 loss=1162.626099 err=1162.626099 *
I 2015-05-26 10:20:17 theanets.trainer:168 RmsProp 1101 loss=0.062707 err=0.062707
I 2015-05-26 10:20:23 theanets.trainer:168 RmsProp 1102 loss=0.058496 err=0.058496
I 2015-05-26 10:20:29 theanets.trainer:168 RmsProp 1103 loss=0.077165 err=0.077165
I 2015-05-26 10:20:35 theanets.trainer:168 RmsProp 1104 loss=0.058138 err=0.058138
I 2015-05-26 10:20:41 theanets.trainer:168 RmsProp 1105 loss=0.061276 err=0.061276
I 2015-05-26 10:20:47 theanets.trainer:168 RmsProp 1106 loss=0.069765 err=0.069765
I 2015-05-26 10:20:52 theanets.trainer:168 RmsProp 1107 loss=0.063974 err=0.063974
I 2015-05-26 10:20:57 theanets.trainer:168 RmsProp 1108 loss=0.060227 err=0.060227
I 2015-05-26 10:21:03 theanets.trainer:168 RmsProp 1109 loss=0.060101 err=0.060101
I 2015-05-26 10:21:08 theanets.trainer:168 RmsProp 1110 loss=0.061110 err=0.061110
I 2015-05-26 10:21:09 theanets.trainer:168 validation 111 loss=1162.015259 err=1162.015259 *
I 2015-05-26 10:21:15 theanets.trainer:168 RmsProp 1111 loss=0.057588 err=0.057588
I 2015-05-26 10:21:21 theanets.trainer:168 RmsProp 1112 loss=0.059731 err=0.059731
I 2015-05-26 10:21:27 theanets.trainer:168 RmsProp 1113 loss=0.062424 err=0.062424
I 2015-05-26 10:21:34 theanets.trainer:168 RmsProp 1114 loss=0.066248 err=0.066248
I 2015-05-26 10:21:40 theanets.trainer:168 RmsProp 1115 loss=0.062203 err=0.062203
I 2015-05-26 10:21:45 theanets.trainer:168 RmsProp 1116 loss=0.060243 err=0.060243
I 2015-05-26 10:21:51 theanets.trainer:168 RmsProp 1117 loss=0.059781 err=0.059781
I 2015-05-26 10:21:57 theanets.trainer:168 RmsProp 1118 loss=0.062749 err=0.062749
I 2015-05-26 10:22:04 theanets.trainer:168 RmsProp 1119 loss=0.060316 err=0.060316
I 2015-05-26 10:22:10 theanets.trainer:168 RmsProp 1120 loss=0.057962 err=0.057962
I 2015-05-26 10:22:10 theanets.trainer:168 validation 112 loss=1160.984253 err=1160.984253 *
I 2015-05-26 10:22:16 theanets.trainer:168 RmsProp 1121 loss=0.065439 err=0.065439
I 2015-05-26 10:22:22 theanets.trainer:168 RmsProp 1122 loss=0.062737 err=0.062737
I 2015-05-26 10:22:28 theanets.trainer:168 RmsProp 1123 loss=0.062903 err=0.062903
I 2015-05-26 10:22:35 theanets.trainer:168 RmsProp 1124 loss=0.060023 err=0.060023
I 2015-05-26 10:22:41 theanets.trainer:168 RmsProp 1125 loss=0.060081 err=0.060081
I 2015-05-26 10:22:47 theanets.trainer:168 RmsProp 1126 loss=0.057576 err=0.057576
I 2015-05-26 10:22:53 theanets.trainer:168 RmsProp 1127 loss=0.062339 err=0.062339
I 2015-05-26 10:23:00 theanets.trainer:168 RmsProp 1128 loss=0.055035 err=0.055035
I 2015-05-26 10:23:05 theanets.trainer:168 RmsProp 1129 loss=0.067531 err=0.067531
I 2015-05-26 10:23:12 theanets.trainer:168 RmsProp 1130 loss=0.060815 err=0.060815
I 2015-05-26 10:23:12 theanets.trainer:168 validation 113 loss=1161.220581 err=1161.220581
I 2015-05-26 10:23:17 theanets.trainer:168 RmsProp 1131 loss=0.058032 err=0.058032
I 2015-05-26 10:23:23 theanets.trainer:168 RmsProp 1132 loss=0.061342 err=0.061342
I 2015-05-26 10:23:30 theanets.trainer:168 RmsProp 1133 loss=0.056886 err=0.056886
I 2015-05-26 10:23:35 theanets.trainer:168 RmsProp 1134 loss=0.066691 err=0.066691
I 2015-05-26 10:23:41 theanets.trainer:168 RmsProp 1135 loss=0.065101 err=0.065101
I 2015-05-26 10:23:47 theanets.trainer:168 RmsProp 1136 loss=0.056176 err=0.056176
I 2015-05-26 10:23:53 theanets.trainer:168 RmsProp 1137 loss=0.055168 err=0.055168
I 2015-05-26 10:23:59 theanets.trainer:168 RmsProp 1138 loss=0.068213 err=0.068213
I 2015-05-26 10:24:06 theanets.trainer:168 RmsProp 1139 loss=0.062094 err=0.062094
I 2015-05-26 10:24:12 theanets.trainer:168 RmsProp 1140 loss=0.059895 err=0.059895
I 2015-05-26 10:24:12 theanets.trainer:168 validation 114 loss=1161.486572 err=1161.486572
I 2015-05-26 10:24:18 theanets.trainer:168 RmsProp 1141 loss=0.061496 err=0.061496
I 2015-05-26 10:24:24 theanets.trainer:168 RmsProp 1142 loss=0.073387 err=0.073387
I 2015-05-26 10:24:30 theanets.trainer:168 RmsProp 1143 loss=0.059470 err=0.059470
I 2015-05-26 10:24:36 theanets.trainer:168 RmsProp 1144 loss=0.061760 err=0.061760
I 2015-05-26 10:24:43 theanets.trainer:168 RmsProp 1145 loss=0.057761 err=0.057761
I 2015-05-26 10:24:49 theanets.trainer:168 RmsProp 1146 loss=0.062596 err=0.062596
I 2015-05-26 10:24:55 theanets.trainer:168 RmsProp 1147 loss=0.058803 err=0.058803
I 2015-05-26 10:25:02 theanets.trainer:168 RmsProp 1148 loss=0.060931 err=0.060931
I 2015-05-26 10:25:07 theanets.trainer:168 RmsProp 1149 loss=0.061056 err=0.061056
I 2015-05-26 10:25:13 theanets.trainer:168 RmsProp 1150 loss=0.062324 err=0.062324
I 2015-05-26 10:25:14 theanets.trainer:168 validation 115 loss=1159.353882 err=1159.353882 *
I 2015-05-26 10:25:19 theanets.trainer:168 RmsProp 1151 loss=0.057171 err=0.057171
I 2015-05-26 10:25:26 theanets.trainer:168 RmsProp 1152 loss=0.063944 err=0.063944
I 2015-05-26 10:25:32 theanets.trainer:168 RmsProp 1153 loss=0.062805 err=0.062805
I 2015-05-26 10:25:38 theanets.trainer:168 RmsProp 1154 loss=0.057268 err=0.057268
I 2015-05-26 10:25:44 theanets.trainer:168 RmsProp 1155 loss=0.060836 err=0.060836
I 2015-05-26 10:25:50 theanets.trainer:168 RmsProp 1156 loss=0.058052 err=0.058052
I 2015-05-26 10:25:56 theanets.trainer:168 RmsProp 1157 loss=0.060128 err=0.060128
I 2015-05-26 10:26:02 theanets.trainer:168 RmsProp 1158 loss=0.061131 err=0.061131
I 2015-05-26 10:26:08 theanets.trainer:168 RmsProp 1159 loss=0.057400 err=0.057400
I 2015-05-26 10:26:14 theanets.trainer:168 RmsProp 1160 loss=0.057392 err=0.057392
I 2015-05-26 10:26:14 theanets.trainer:168 validation 116 loss=1159.552979 err=1159.552979
I 2015-05-26 10:26:20 theanets.trainer:168 RmsProp 1161 loss=0.058636 err=0.058636
I 2015-05-26 10:26:26 theanets.trainer:168 RmsProp 1162 loss=0.062160 err=0.062160
I 2015-05-26 10:26:32 theanets.trainer:168 RmsProp 1163 loss=0.057549 err=0.057549
I 2015-05-26 10:26:39 theanets.trainer:168 RmsProp 1164 loss=0.062819 err=0.062819
I 2015-05-26 10:26:45 theanets.trainer:168 RmsProp 1165 loss=0.059134 err=0.059134
I 2015-05-26 10:26:51 theanets.trainer:168 RmsProp 1166 loss=0.057841 err=0.057841
I 2015-05-26 10:26:57 theanets.trainer:168 RmsProp 1167 loss=0.061120 err=0.061120
I 2015-05-26 10:27:03 theanets.trainer:168 RmsProp 1168 loss=0.062389 err=0.062389
I 2015-05-26 10:27:09 theanets.trainer:168 RmsProp 1169 loss=0.056636 err=0.056636
I 2015-05-26 10:27:15 theanets.trainer:168 RmsProp 1170 loss=0.059114 err=0.059114
I 2015-05-26 10:27:16 theanets.trainer:168 validation 117 loss=1158.608398 err=1158.608398 *
I 2015-05-26 10:27:22 theanets.trainer:168 RmsProp 1171 loss=0.061215 err=0.061215
I 2015-05-26 10:27:28 theanets.trainer:168 RmsProp 1172 loss=0.056089 err=0.056089
I 2015-05-26 10:27:34 theanets.trainer:168 RmsProp 1173 loss=0.060095 err=0.060095
I 2015-05-26 10:27:41 theanets.trainer:168 RmsProp 1174 loss=0.061712 err=0.061712
I 2015-05-26 10:27:47 theanets.trainer:168 RmsProp 1175 loss=0.054517 err=0.054517
I 2015-05-26 10:27:53 theanets.trainer:168 RmsProp 1176 loss=0.060588 err=0.060588
I 2015-05-26 10:27:59 theanets.trainer:168 RmsProp 1177 loss=0.056645 err=0.056645
I 2015-05-26 10:28:05 theanets.trainer:168 RmsProp 1178 loss=0.062067 err=0.062067
I 2015-05-26 10:28:11 theanets.trainer:168 RmsProp 1179 loss=0.058288 err=0.058288
I 2015-05-26 10:28:17 theanets.trainer:168 RmsProp 1180 loss=0.059278 err=0.059278
I 2015-05-26 10:28:18 theanets.trainer:168 validation 118 loss=1156.675293 err=1156.675293 *
I 2015-05-26 10:28:23 theanets.trainer:168 RmsProp 1181 loss=0.050950 err=0.050950
I 2015-05-26 10:28:30 theanets.trainer:168 RmsProp 1182 loss=0.069001 err=0.069001
I 2015-05-26 10:28:36 theanets.trainer:168 RmsProp 1183 loss=0.058333 err=0.058333
I 2015-05-26 10:28:42 theanets.trainer:168 RmsProp 1184 loss=0.055764 err=0.055764
I 2015-05-26 10:28:48 theanets.trainer:168 RmsProp 1185 loss=0.055696 err=0.055696
I 2015-05-26 10:28:55 theanets.trainer:168 RmsProp 1186 loss=0.057283 err=0.057283
I 2015-05-26 10:29:01 theanets.trainer:168 RmsProp 1187 loss=0.057297 err=0.057297
I 2015-05-26 10:29:07 theanets.trainer:168 RmsProp 1188 loss=0.056945 err=0.056945
I 2015-05-26 10:29:13 theanets.trainer:168 RmsProp 1189 loss=0.057156 err=0.057156
I 2015-05-26 10:29:19 theanets.trainer:168 RmsProp 1190 loss=0.061949 err=0.061949
I 2015-05-26 10:29:20 theanets.trainer:168 validation 119 loss=1157.074341 err=1157.074341
I 2015-05-26 10:29:26 theanets.trainer:168 RmsProp 1191 loss=0.053237 err=0.053237
I 2015-05-26 10:29:31 theanets.trainer:168 RmsProp 1192 loss=0.062552 err=0.062552
I 2015-05-26 10:29:37 theanets.trainer:168 RmsProp 1193 loss=0.053722 err=0.053722
I 2015-05-26 10:29:44 theanets.trainer:168 RmsProp 1194 loss=0.058866 err=0.058866
I 2015-05-26 10:29:50 theanets.trainer:168 RmsProp 1195 loss=0.053833 err=0.053833
I 2015-05-26 10:29:56 theanets.trainer:168 RmsProp 1196 loss=0.069115 err=0.069115
I 2015-05-26 10:30:03 theanets.trainer:168 RmsProp 1197 loss=0.055575 err=0.055575
I 2015-05-26 10:30:09 theanets.trainer:168 RmsProp 1198 loss=0.060039 err=0.060039
I 2015-05-26 10:30:14 theanets.trainer:168 RmsProp 1199 loss=0.055284 err=0.055284
I 2015-05-26 10:30:21 theanets.trainer:168 RmsProp 1200 loss=0.065729 err=0.065729
I 2015-05-26 10:30:21 theanets.trainer:168 validation 120 loss=1156.788940 err=1156.788940
I 2015-05-26 10:30:27 theanets.trainer:168 RmsProp 1201 loss=0.058168 err=0.058168
I 2015-05-26 10:30:33 theanets.trainer:168 RmsProp 1202 loss=0.058854 err=0.058854
I 2015-05-26 10:30:39 theanets.trainer:168 RmsProp 1203 loss=0.053363 err=0.053363
I 2015-05-26 10:30:46 theanets.trainer:168 RmsProp 1204 loss=0.060297 err=0.060297
I 2015-05-26 10:30:51 theanets.trainer:168 RmsProp 1205 loss=0.064561 err=0.064561
I 2015-05-26 10:30:57 theanets.trainer:168 RmsProp 1206 loss=0.056533 err=0.056533
I 2015-05-26 10:31:04 theanets.trainer:168 RmsProp 1207 loss=0.055026 err=0.055026
I 2015-05-26 10:31:10 theanets.trainer:168 RmsProp 1208 loss=0.055494 err=0.055494
I 2015-05-26 10:31:15 theanets.trainer:168 RmsProp 1209 loss=0.057431 err=0.057431
I 2015-05-26 10:31:20 theanets.trainer:168 RmsProp 1210 loss=0.057159 err=0.057159
I 2015-05-26 10:31:21 theanets.trainer:168 validation 121 loss=1154.944214 err=1154.944214 *
I 2015-05-26 10:31:26 theanets.trainer:168 RmsProp 1211 loss=0.058360 err=0.058360
I 2015-05-26 10:31:32 theanets.trainer:168 RmsProp 1212 loss=0.058877 err=0.058877
I 2015-05-26 10:31:37 theanets.trainer:168 RmsProp 1213 loss=0.053046 err=0.053046
I 2015-05-26 10:31:43 theanets.trainer:168 RmsProp 1214 loss=0.056528 err=0.056528
I 2015-05-26 10:31:50 theanets.trainer:168 RmsProp 1215 loss=0.059350 err=0.059350
I 2015-05-26 10:31:56 theanets.trainer:168 RmsProp 1216 loss=0.058736 err=0.058736
I 2015-05-26 10:32:02 theanets.trainer:168 RmsProp 1217 loss=0.053405 err=0.053405
I 2015-05-26 10:32:08 theanets.trainer:168 RmsProp 1218 loss=0.066876 err=0.066876
I 2015-05-26 10:32:14 theanets.trainer:168 RmsProp 1219 loss=0.055295 err=0.055295
I 2015-05-26 10:32:21 theanets.trainer:168 RmsProp 1220 loss=0.056453 err=0.056453
I 2015-05-26 10:32:21 theanets.trainer:168 validation 122 loss=1155.583374 err=1155.583374
I 2015-05-26 10:32:27 theanets.trainer:168 RmsProp 1221 loss=0.062886 err=0.062886
I 2015-05-26 10:32:33 theanets.trainer:168 RmsProp 1222 loss=0.056347 err=0.056347
I 2015-05-26 10:32:39 theanets.trainer:168 RmsProp 1223 loss=0.054454 err=0.054454
I 2015-05-26 10:32:45 theanets.trainer:168 RmsProp 1224 loss=0.054960 err=0.054960
I 2015-05-26 10:32:52 theanets.trainer:168 RmsProp 1225 loss=0.055219 err=0.055219
I 2015-05-26 10:32:58 theanets.trainer:168 RmsProp 1226 loss=0.056376 err=0.056376
I 2015-05-26 10:33:04 theanets.trainer:168 RmsProp 1227 loss=0.054650 err=0.054650
I 2015-05-26 10:33:10 theanets.trainer:168 RmsProp 1228 loss=0.062640 err=0.062640
I 2015-05-26 10:33:17 theanets.trainer:168 RmsProp 1229 loss=0.056951 err=0.056951
I 2015-05-26 10:33:23 theanets.trainer:168 RmsProp 1230 loss=0.053637 err=0.053637
I 2015-05-26 10:33:23 theanets.trainer:168 validation 123 loss=1153.910889 err=1153.910889 *
I 2015-05-26 10:33:29 theanets.trainer:168 RmsProp 1231 loss=0.057411 err=0.057411
I 2015-05-26 10:33:35 theanets.trainer:168 RmsProp 1232 loss=0.053606 err=0.053606
I 2015-05-26 10:33:42 theanets.trainer:168 RmsProp 1233 loss=0.062238 err=0.062238
I 2015-05-26 10:33:48 theanets.trainer:168 RmsProp 1234 loss=0.063561 err=0.063561
I 2015-05-26 10:33:54 theanets.trainer:168 RmsProp 1235 loss=0.055197 err=0.055197
I 2015-05-26 10:34:00 theanets.trainer:168 RmsProp 1236 loss=0.062810 err=0.062810
I 2015-05-26 10:34:06 theanets.trainer:168 RmsProp 1237 loss=0.057917 err=0.057917
I 2015-05-26 10:34:13 theanets.trainer:168 RmsProp 1238 loss=0.054789 err=0.054789
I 2015-05-26 10:34:19 theanets.trainer:168 RmsProp 1239 loss=0.053731 err=0.053731
I 2015-05-26 10:34:25 theanets.trainer:168 RmsProp 1240 loss=0.052097 err=0.052097
I 2015-05-26 10:34:26 theanets.trainer:168 validation 124 loss=1153.085449 err=1153.085449 *
I 2015-05-26 10:34:31 theanets.trainer:168 RmsProp 1241 loss=0.061571 err=0.061571
I 2015-05-26 10:34:38 theanets.trainer:168 RmsProp 1242 loss=0.058254 err=0.058254
I 2015-05-26 10:34:44 theanets.trainer:168 RmsProp 1243 loss=0.055794 err=0.055794
I 2015-05-26 10:34:50 theanets.trainer:168 RmsProp 1244 loss=0.058811 err=0.058811
I 2015-05-26 10:34:56 theanets.trainer:168 RmsProp 1245 loss=0.057656 err=0.057656
I 2015-05-26 10:35:03 theanets.trainer:168 RmsProp 1246 loss=0.053326 err=0.053326
I 2015-05-26 10:35:08 theanets.trainer:168 RmsProp 1247 loss=0.059557 err=0.059557
I 2015-05-26 10:35:14 theanets.trainer:168 RmsProp 1248 loss=0.056689 err=0.056689
I 2015-05-26 10:35:21 theanets.trainer:168 RmsProp 1249 loss=0.053755 err=0.053755
I 2015-05-26 10:35:27 theanets.trainer:168 RmsProp 1250 loss=0.055862 err=0.055862
I 2015-05-26 10:35:27 theanets.trainer:168 validation 125 loss=1153.261108 err=1153.261108
I 2015-05-26 10:35:33 theanets.trainer:168 RmsProp 1251 loss=0.053550 err=0.053550
I 2015-05-26 10:35:39 theanets.trainer:168 RmsProp 1252 loss=0.055204 err=0.055204
I 2015-05-26 10:35:46 theanets.trainer:168 RmsProp 1253 loss=0.049423 err=0.049423
I 2015-05-26 10:35:52 theanets.trainer:168 RmsProp 1254 loss=0.066256 err=0.066256
I 2015-05-26 10:35:58 theanets.trainer:168 RmsProp 1255 loss=0.056819 err=0.056819
I 2015-05-26 10:36:04 theanets.trainer:168 RmsProp 1256 loss=0.054650 err=0.054650
I 2015-05-26 10:36:11 theanets.trainer:168 RmsProp 1257 loss=0.052227 err=0.052227
I 2015-05-26 10:36:17 theanets.trainer:168 RmsProp 1258 loss=0.056322 err=0.056322
I 2015-05-26 10:36:23 theanets.trainer:168 RmsProp 1259 loss=0.053438 err=0.053438
I 2015-05-26 10:36:29 theanets.trainer:168 RmsProp 1260 loss=0.052864 err=0.052864
I 2015-05-26 10:36:30 theanets.trainer:168 validation 126 loss=1152.380249 err=1152.380249 *
I 2015-05-26 10:36:36 theanets.trainer:168 RmsProp 1261 loss=0.057702 err=0.057702
I 2015-05-26 10:36:42 theanets.trainer:168 RmsProp 1262 loss=0.057181 err=0.057181
I 2015-05-26 10:36:48 theanets.trainer:168 RmsProp 1263 loss=0.061252 err=0.061252
I 2015-05-26 10:36:54 theanets.trainer:168 RmsProp 1264 loss=0.051004 err=0.051004
I 2015-05-26 10:36:59 theanets.trainer:168 RmsProp 1265 loss=0.051959 err=0.051959
I 2015-05-26 10:37:04 theanets.trainer:168 RmsProp 1266 loss=0.058466 err=0.058466
I 2015-05-26 10:37:10 theanets.trainer:168 RmsProp 1267 loss=0.054932 err=0.054932
I 2015-05-26 10:37:16 theanets.trainer:168 RmsProp 1268 loss=0.050906 err=0.050906
I 2015-05-26 10:37:23 theanets.trainer:168 RmsProp 1269 loss=0.063074 err=0.063074
I 2015-05-26 10:37:28 theanets.trainer:168 RmsProp 1270 loss=0.050929 err=0.050929
I 2015-05-26 10:37:29 theanets.trainer:168 validation 127 loss=1151.411499 err=1151.411499 *
I 2015-05-26 10:37:34 theanets.trainer:168 RmsProp 1271 loss=0.064388 err=0.064388
I 2015-05-26 10:37:41 theanets.trainer:168 RmsProp 1272 loss=0.050674 err=0.050674
I 2015-05-26 10:37:47 theanets.trainer:168 RmsProp 1273 loss=0.063043 err=0.063043
I 2015-05-26 10:37:53 theanets.trainer:168 RmsProp 1274 loss=0.051571 err=0.051571
I 2015-05-26 10:37:59 theanets.trainer:168 RmsProp 1275 loss=0.061971 err=0.061971
I 2015-05-26 10:38:06 theanets.trainer:168 RmsProp 1276 loss=0.050853 err=0.050853
I 2015-05-26 10:38:12 theanets.trainer:168 RmsProp 1277 loss=0.053269 err=0.053269
I 2015-05-26 10:38:18 theanets.trainer:168 RmsProp 1278 loss=0.051601 err=0.051601
I 2015-05-26 10:38:24 theanets.trainer:168 RmsProp 1279 loss=0.054037 err=0.054037
I 2015-05-26 10:38:30 theanets.trainer:168 RmsProp 1280 loss=0.053679 err=0.053679
I 2015-05-26 10:38:31 theanets.trainer:168 validation 128 loss=1150.088745 err=1150.088745 *
I 2015-05-26 10:38:37 theanets.trainer:168 RmsProp 1281 loss=0.055273 err=0.055273
I 2015-05-26 10:38:43 theanets.trainer:168 RmsProp 1282 loss=0.053607 err=0.053607
I 2015-05-26 10:38:49 theanets.trainer:168 RmsProp 1283 loss=0.053326 err=0.053326
I 2015-05-26 10:38:55 theanets.trainer:168 RmsProp 1284 loss=0.053175 err=0.053175
I 2015-05-26 10:39:00 theanets.trainer:168 RmsProp 1285 loss=0.054605 err=0.054605
I 2015-05-26 10:39:06 theanets.trainer:168 RmsProp 1286 loss=0.057401 err=0.057401
I 2015-05-26 10:39:11 theanets.trainer:168 RmsProp 1287 loss=0.052909 err=0.052909
I 2015-05-26 10:39:18 theanets.trainer:168 RmsProp 1288 loss=0.049403 err=0.049403
I 2015-05-26 10:39:24 theanets.trainer:168 RmsProp 1289 loss=0.062593 err=0.062593
I 2015-05-26 10:39:30 theanets.trainer:168 RmsProp 1290 loss=0.054216 err=0.054216
I 2015-05-26 10:39:30 theanets.trainer:168 validation 129 loss=1150.541504 err=1150.541504
I 2015-05-26 10:39:36 theanets.trainer:168 RmsProp 1291 loss=0.054860 err=0.054860
I 2015-05-26 10:39:42 theanets.trainer:168 RmsProp 1292 loss=0.053398 err=0.053398
I 2015-05-26 10:39:48 theanets.trainer:168 RmsProp 1293 loss=0.055349 err=0.055349
I 2015-05-26 10:39:55 theanets.trainer:168 RmsProp 1294 loss=0.058994 err=0.058994
I 2015-05-26 10:40:01 theanets.trainer:168 RmsProp 1295 loss=0.048424 err=0.048424
I 2015-05-26 10:40:07 theanets.trainer:168 RmsProp 1296 loss=0.054262 err=0.054262
I 2015-05-26 10:40:13 theanets.trainer:168 RmsProp 1297 loss=0.052491 err=0.052491
I 2015-05-26 10:40:20 theanets.trainer:168 RmsProp 1298 loss=0.053501 err=0.053501
I 2015-05-26 10:40:26 theanets.trainer:168 RmsProp 1299 loss=0.055153 err=0.055153
I 2015-05-26 10:40:32 theanets.trainer:168 RmsProp 1300 loss=0.053189 err=0.053189
I 2015-05-26 10:40:33 theanets.trainer:168 validation 130 loss=1150.491455 err=1150.491455
I 2015-05-26 10:40:38 theanets.trainer:168 RmsProp 1301 loss=0.050799 err=0.050799
I 2015-05-26 10:40:44 theanets.trainer:168 RmsProp 1302 loss=0.060725 err=0.060725
I 2015-05-26 10:40:50 theanets.trainer:168 RmsProp 1303 loss=0.052998 err=0.052998
I 2015-05-26 10:40:56 theanets.trainer:168 RmsProp 1304 loss=0.051492 err=0.051492
I 2015-05-26 10:41:02 theanets.trainer:168 RmsProp 1305 loss=0.053569 err=0.053569
I 2015-05-26 10:41:08 theanets.trainer:168 RmsProp 1306 loss=0.048544 err=0.048544
I 2015-05-26 10:41:15 theanets.trainer:168 RmsProp 1307 loss=0.060733 err=0.060733
I 2015-05-26 10:41:21 theanets.trainer:168 RmsProp 1308 loss=0.052772 err=0.052772
I 2015-05-26 10:41:27 theanets.trainer:168 RmsProp 1309 loss=0.051340 err=0.051340
I 2015-05-26 10:41:33 theanets.trainer:168 RmsProp 1310 loss=0.056065 err=0.056065
I 2015-05-26 10:41:33 theanets.trainer:168 validation 131 loss=1150.369751 err=1150.369751
I 2015-05-26 10:41:39 theanets.trainer:168 RmsProp 1311 loss=0.050807 err=0.050807
I 2015-05-26 10:41:45 theanets.trainer:168 RmsProp 1312 loss=0.053671 err=0.053671
I 2015-05-26 10:41:51 theanets.trainer:168 RmsProp 1313 loss=0.052256 err=0.052256
I 2015-05-26 10:41:57 theanets.trainer:168 RmsProp 1314 loss=0.052318 err=0.052318
I 2015-05-26 10:42:03 theanets.trainer:168 RmsProp 1315 loss=0.055518 err=0.055518
I 2015-05-26 10:42:09 theanets.trainer:168 RmsProp 1316 loss=0.048721 err=0.048721
I 2015-05-26 10:42:16 theanets.trainer:168 RmsProp 1317 loss=0.061252 err=0.061252
I 2015-05-26 10:42:22 theanets.trainer:168 RmsProp 1318 loss=0.055632 err=0.055632
I 2015-05-26 10:42:28 theanets.trainer:168 RmsProp 1319 loss=0.051262 err=0.051262
I 2015-05-26 10:42:34 theanets.trainer:168 RmsProp 1320 loss=0.057881 err=0.057881
I 2015-05-26 10:42:35 theanets.trainer:168 validation 132 loss=1149.853516 err=1149.853516 *
I 2015-05-26 10:42:41 theanets.trainer:168 RmsProp 1321 loss=0.048190 err=0.048190
I 2015-05-26 10:42:47 theanets.trainer:168 RmsProp 1322 loss=0.055904 err=0.055904
I 2015-05-26 10:42:53 theanets.trainer:168 RmsProp 1323 loss=0.049684 err=0.049684
I 2015-05-26 10:42:59 theanets.trainer:168 RmsProp 1324 loss=0.049326 err=0.049326
I 2015-05-26 10:43:05 theanets.trainer:168 RmsProp 1325 loss=0.055392 err=0.055392
I 2015-05-26 10:43:11 theanets.trainer:168 RmsProp 1326 loss=0.050222 err=0.050222
I 2015-05-26 10:43:17 theanets.trainer:168 RmsProp 1327 loss=0.054479 err=0.054479
I 2015-05-26 10:43:24 theanets.trainer:168 RmsProp 1328 loss=0.053915 err=0.053915
I 2015-05-26 10:43:30 theanets.trainer:168 RmsProp 1329 loss=0.055643 err=0.055643
I 2015-05-26 10:43:36 theanets.trainer:168 RmsProp 1330 loss=0.051771 err=0.051771
I 2015-05-26 10:43:37 theanets.trainer:168 validation 133 loss=1149.804688 err=1149.804688 *
I 2015-05-26 10:43:42 theanets.trainer:168 RmsProp 1331 loss=0.057149 err=0.057149
I 2015-05-26 10:43:48 theanets.trainer:168 RmsProp 1332 loss=0.056120 err=0.056120
I 2015-05-26 10:43:54 theanets.trainer:168 RmsProp 1333 loss=0.053781 err=0.053781
I 2015-05-26 10:43:59 theanets.trainer:168 RmsProp 1334 loss=0.056041 err=0.056041
I 2015-05-26 10:44:05 theanets.trainer:168 RmsProp 1335 loss=0.048070 err=0.048070
I 2015-05-26 10:44:10 theanets.trainer:168 RmsProp 1336 loss=0.057470 err=0.057470
I 2015-05-26 10:44:17 theanets.trainer:168 RmsProp 1337 loss=0.049793 err=0.049793
I 2015-05-26 10:44:23 theanets.trainer:168 RmsProp 1338 loss=0.051870 err=0.051870
I 2015-05-26 10:44:29 theanets.trainer:168 RmsProp 1339 loss=0.055070 err=0.055070
I 2015-05-26 10:44:35 theanets.trainer:168 RmsProp 1340 loss=0.051725 err=0.051725
I 2015-05-26 10:44:36 theanets.trainer:168 validation 134 loss=1147.522827 err=1147.522827 *
I 2015-05-26 10:44:41 theanets.trainer:168 RmsProp 1341 loss=0.052606 err=0.052606
I 2015-05-26 10:44:48 theanets.trainer:168 RmsProp 1342 loss=0.053541 err=0.053541
I 2015-05-26 10:44:54 theanets.trainer:168 RmsProp 1343 loss=0.052243 err=0.052243
I 2015-05-26 10:45:00 theanets.trainer:168 RmsProp 1344 loss=0.053737 err=0.053737
I 2015-05-26 10:45:06 theanets.trainer:168 RmsProp 1345 loss=0.055768 err=0.055768
I 2015-05-26 10:45:11 theanets.trainer:168 RmsProp 1346 loss=0.049379 err=0.049379
I 2015-05-26 10:45:17 theanets.trainer:168 RmsProp 1347 loss=0.053360 err=0.053360
I 2015-05-26 10:45:24 theanets.trainer:168 RmsProp 1348 loss=0.053454 err=0.053454
I 2015-05-26 10:45:29 theanets.trainer:168 RmsProp 1349 loss=0.059152 err=0.059152
I 2015-05-26 10:45:35 theanets.trainer:168 RmsProp 1350 loss=0.048944 err=0.048944
I 2015-05-26 10:45:35 theanets.trainer:168 validation 135 loss=1146.701660 err=1146.701660 *
I 2015-05-26 10:45:41 theanets.trainer:168 RmsProp 1351 loss=0.053719 err=0.053719
I 2015-05-26 10:45:47 theanets.trainer:168 RmsProp 1352 loss=0.053470 err=0.053470
I 2015-05-26 10:45:53 theanets.trainer:168 RmsProp 1353 loss=0.054530 err=0.054530
I 2015-05-26 10:46:00 theanets.trainer:168 RmsProp 1354 loss=0.050184 err=0.050184
I 2015-05-26 10:46:06 theanets.trainer:168 RmsProp 1355 loss=0.048703 err=0.048703
I 2015-05-26 10:46:12 theanets.trainer:168 RmsProp 1356 loss=0.049015 err=0.049015
I 2015-05-26 10:46:18 theanets.trainer:168 RmsProp 1357 loss=0.058025 err=0.058025
I 2015-05-26 10:46:25 theanets.trainer:168 RmsProp 1358 loss=0.048846 err=0.048846
I 2015-05-26 10:46:30 theanets.trainer:168 RmsProp 1359 loss=0.051372 err=0.051372
I 2015-05-26 10:46:37 theanets.trainer:168 RmsProp 1360 loss=0.049876 err=0.049876
I 2015-05-26 10:46:37 theanets.trainer:168 validation 136 loss=1146.587891 err=1146.587891 *
I 2015-05-26 10:46:43 theanets.trainer:168 RmsProp 1361 loss=0.064210 err=0.064210
I 2015-05-26 10:46:49 theanets.trainer:168 RmsProp 1362 loss=0.054051 err=0.054051
I 2015-05-26 10:46:55 theanets.trainer:168 RmsProp 1363 loss=0.045536 err=0.045536
I 2015-05-26 10:47:01 theanets.trainer:168 RmsProp 1364 loss=0.066383 err=0.066383
I 2015-05-26 10:47:07 theanets.trainer:168 RmsProp 1365 loss=0.052898 err=0.052898
I 2015-05-26 10:47:14 theanets.trainer:168 RmsProp 1366 loss=0.052188 err=0.052188
I 2015-05-26 10:47:20 theanets.trainer:168 RmsProp 1367 loss=0.050992 err=0.050992
I 2015-05-26 10:47:26 theanets.trainer:168 RmsProp 1368 loss=0.049509 err=0.049509
I 2015-05-26 10:47:33 theanets.trainer:168 RmsProp 1369 loss=0.056325 err=0.056325
I 2015-05-26 10:47:39 theanets.trainer:168 RmsProp 1370 loss=0.055306 err=0.055306
I 2015-05-26 10:47:39 theanets.trainer:168 validation 137 loss=1144.995972 err=1144.995972 *
I 2015-05-26 10:47:45 theanets.trainer:168 RmsProp 1371 loss=0.051423 err=0.051423
I 2015-05-26 10:47:51 theanets.trainer:168 RmsProp 1372 loss=0.053059 err=0.053059
I 2015-05-26 10:47:57 theanets.trainer:168 RmsProp 1373 loss=0.052158 err=0.052158
I 2015-05-26 10:48:04 theanets.trainer:168 RmsProp 1374 loss=0.050326 err=0.050326
I 2015-05-26 10:48:09 theanets.trainer:168 RmsProp 1375 loss=0.051142 err=0.051142
I 2015-05-26 10:48:15 theanets.trainer:168 RmsProp 1376 loss=0.052753 err=0.052753
I 2015-05-26 10:48:22 theanets.trainer:168 RmsProp 1377 loss=0.050089 err=0.050089
I 2015-05-26 10:48:28 theanets.trainer:168 RmsProp 1378 loss=0.048456 err=0.048456
I 2015-05-26 10:48:34 theanets.trainer:168 RmsProp 1379 loss=0.050937 err=0.050937
I 2015-05-26 10:48:40 theanets.trainer:168 RmsProp 1380 loss=0.047155 err=0.047155
I 2015-05-26 10:48:41 theanets.trainer:168 validation 138 loss=1145.897095 err=1145.897095
I 2015-05-26 10:48:47 theanets.trainer:168 RmsProp 1381 loss=0.061773 err=0.061773
I 2015-05-26 10:48:53 theanets.trainer:168 RmsProp 1382 loss=0.047425 err=0.047425
I 2015-05-26 10:48:59 theanets.trainer:168 RmsProp 1383 loss=0.053387 err=0.053387
I 2015-05-26 10:49:05 theanets.trainer:168 RmsProp 1384 loss=0.049297 err=0.049297
I 2015-05-26 10:49:11 theanets.trainer:168 RmsProp 1385 loss=0.051165 err=0.051165
I 2015-05-26 10:49:18 theanets.trainer:168 RmsProp 1386 loss=0.048174 err=0.048174
I 2015-05-26 10:49:24 theanets.trainer:168 RmsProp 1387 loss=0.055281 err=0.055281
I 2015-05-26 10:49:30 theanets.trainer:168 RmsProp 1388 loss=0.052351 err=0.052351
I 2015-05-26 10:49:36 theanets.trainer:168 RmsProp 1389 loss=0.052543 err=0.052543
I 2015-05-26 10:49:42 theanets.trainer:168 RmsProp 1390 loss=0.045901 err=0.045901
I 2015-05-26 10:49:42 theanets.trainer:168 validation 139 loss=1146.513306 err=1146.513306
I 2015-05-26 10:49:48 theanets.trainer:168 RmsProp 1391 loss=0.059182 err=0.059182
I 2015-05-26 10:49:54 theanets.trainer:168 RmsProp 1392 loss=0.047185 err=0.047185
I 2015-05-26 10:50:01 theanets.trainer:168 RmsProp 1393 loss=0.050975 err=0.050975
I 2015-05-26 10:50:07 theanets.trainer:168 RmsProp 1394 loss=0.056237 err=0.056237
I 2015-05-26 10:50:13 theanets.trainer:168 RmsProp 1395 loss=0.046590 err=0.046590
I 2015-05-26 10:50:19 theanets.trainer:168 RmsProp 1396 loss=0.056563 err=0.056563
I 2015-05-26 10:50:25 theanets.trainer:168 RmsProp 1397 loss=0.052158 err=0.052158
I 2015-05-26 10:50:31 theanets.trainer:168 RmsProp 1398 loss=0.048099 err=0.048099
I 2015-05-26 10:50:37 theanets.trainer:168 RmsProp 1399 loss=0.051004 err=0.051004
I 2015-05-26 10:50:43 theanets.trainer:168 RmsProp 1400 loss=0.052477 err=0.052477
I 2015-05-26 10:50:43 theanets.trainer:168 validation 140 loss=1145.101929 err=1145.101929
I 2015-05-26 10:50:49 theanets.trainer:168 RmsProp 1401 loss=0.049113 err=0.049113
I 2015-05-26 10:50:55 theanets.trainer:168 RmsProp 1402 loss=0.051434 err=0.051434
I 2015-05-26 10:51:01 theanets.trainer:168 RmsProp 1403 loss=0.051071 err=0.051071
I 2015-05-26 10:51:07 theanets.trainer:168 RmsProp 1404 loss=0.045365 err=0.045365
I 2015-05-26 10:51:13 theanets.trainer:168 RmsProp 1405 loss=0.051369 err=0.051369
I 2015-05-26 10:51:19 theanets.trainer:168 RmsProp 1406 loss=0.054274 err=0.054274
I 2015-05-26 10:51:26 theanets.trainer:168 RmsProp 1407 loss=0.051464 err=0.051464
I 2015-05-26 10:51:32 theanets.trainer:168 RmsProp 1408 loss=0.046529 err=0.046529
I 2015-05-26 10:51:38 theanets.trainer:168 RmsProp 1409 loss=0.051856 err=0.051856
I 2015-05-26 10:51:43 theanets.trainer:168 RmsProp 1410 loss=0.055613 err=0.055613
I 2015-05-26 10:51:44 theanets.trainer:168 validation 141 loss=1144.696777 err=1144.696777 *
I 2015-05-26 10:51:49 theanets.trainer:168 RmsProp 1411 loss=0.050741 err=0.050741
I 2015-05-26 10:51:55 theanets.trainer:168 RmsProp 1412 loss=0.042542 err=0.042542
I 2015-05-26 10:52:01 theanets.trainer:168 RmsProp 1413 loss=0.054048 err=0.054048
I 2015-05-26 10:52:07 theanets.trainer:168 RmsProp 1414 loss=0.053058 err=0.053058
I 2015-05-26 10:52:13 theanets.trainer:168 RmsProp 1415 loss=0.051542 err=0.051542
I 2015-05-26 10:52:20 theanets.trainer:168 RmsProp 1416 loss=0.050519 err=0.050519
I 2015-05-26 10:52:26 theanets.trainer:168 RmsProp 1417 loss=0.049008 err=0.049008
I 2015-05-26 10:52:32 theanets.trainer:168 RmsProp 1418 loss=0.050346 err=0.050346
I 2015-05-26 10:52:38 theanets.trainer:168 RmsProp 1419 loss=0.049190 err=0.049190
I 2015-05-26 10:52:44 theanets.trainer:168 RmsProp 1420 loss=0.052488 err=0.052488
I 2015-05-26 10:52:44 theanets.trainer:168 validation 142 loss=1144.303467 err=1144.303467 *
I 2015-05-26 10:52:50 theanets.trainer:168 RmsProp 1421 loss=0.052761 err=0.052761
I 2015-05-26 10:52:56 theanets.trainer:168 RmsProp 1422 loss=0.052007 err=0.052007
I 2015-05-26 10:53:01 theanets.trainer:168 RmsProp 1423 loss=0.051084 err=0.051084
I 2015-05-26 10:53:08 theanets.trainer:168 RmsProp 1424 loss=0.052148 err=0.052148
I 2015-05-26 10:53:14 theanets.trainer:168 RmsProp 1425 loss=0.049096 err=0.049096
I 2015-05-26 10:53:20 theanets.trainer:168 RmsProp 1426 loss=0.050056 err=0.050056
I 2015-05-26 10:53:26 theanets.trainer:168 RmsProp 1427 loss=0.050035 err=0.050035
I 2015-05-26 10:53:32 theanets.trainer:168 RmsProp 1428 loss=0.047904 err=0.047904
I 2015-05-26 10:53:39 theanets.trainer:168 RmsProp 1429 loss=0.049932 err=0.049932
I 2015-05-26 10:53:45 theanets.trainer:168 RmsProp 1430 loss=0.046479 err=0.046479
I 2015-05-26 10:53:45 theanets.trainer:168 validation 143 loss=1143.844604 err=1143.844604 *
I 2015-05-26 10:53:51 theanets.trainer:168 RmsProp 1431 loss=0.060766 err=0.060766
I 2015-05-26 10:53:57 theanets.trainer:168 RmsProp 1432 loss=0.047338 err=0.047338
I 2015-05-26 10:54:03 theanets.trainer:168 RmsProp 1433 loss=0.049847 err=0.049847
I 2015-05-26 10:54:09 theanets.trainer:168 RmsProp 1434 loss=0.047410 err=0.047410
I 2015-05-26 10:54:14 theanets.trainer:168 RmsProp 1435 loss=0.047503 err=0.047503
I 2015-05-26 10:54:20 theanets.trainer:168 RmsProp 1436 loss=0.054261 err=0.054261
I 2015-05-26 10:54:26 theanets.trainer:168 RmsProp 1437 loss=0.045098 err=0.045098
I 2015-05-26 10:54:32 theanets.trainer:168 RmsProp 1438 loss=0.057390 err=0.057390
I 2015-05-26 10:54:38 theanets.trainer:168 RmsProp 1439 loss=0.048154 err=0.048154
I 2015-05-26 10:54:44 theanets.trainer:168 RmsProp 1440 loss=0.050058 err=0.050058
I 2015-05-26 10:54:44 theanets.trainer:168 validation 144 loss=1144.178711 err=1144.178711
I 2015-05-26 10:54:50 theanets.trainer:168 RmsProp 1441 loss=0.047317 err=0.047317
I 2015-05-26 10:54:56 theanets.trainer:168 RmsProp 1442 loss=0.045817 err=0.045817
I 2015-05-26 10:55:02 theanets.trainer:168 RmsProp 1443 loss=0.054683 err=0.054683
I 2015-05-26 10:55:09 theanets.trainer:168 RmsProp 1444 loss=0.054234 err=0.054234
I 2015-05-26 10:55:14 theanets.trainer:168 RmsProp 1445 loss=0.047118 err=0.047118
I 2015-05-26 10:55:20 theanets.trainer:168 RmsProp 1446 loss=0.045920 err=0.045920
I 2015-05-26 10:55:26 theanets.trainer:168 RmsProp 1447 loss=0.050892 err=0.050892
I 2015-05-26 10:55:32 theanets.trainer:168 RmsProp 1448 loss=0.051393 err=0.051393
I 2015-05-26 10:55:37 theanets.trainer:168 RmsProp 1449 loss=0.048185 err=0.048185
I 2015-05-26 10:55:43 theanets.trainer:168 RmsProp 1450 loss=0.048478 err=0.048478
I 2015-05-26 10:55:43 theanets.trainer:168 validation 145 loss=1144.763062 err=1144.763062
I 2015-05-26 10:55:49 theanets.trainer:168 RmsProp 1451 loss=0.051426 err=0.051426
I 2015-05-26 10:55:54 theanets.trainer:168 RmsProp 1452 loss=0.046299 err=0.046299
I 2015-05-26 10:56:00 theanets.trainer:168 RmsProp 1453 loss=0.049123 err=0.049123
I 2015-05-26 10:56:07 theanets.trainer:168 RmsProp 1454 loss=0.054798 err=0.054798
I 2015-05-26 10:56:13 theanets.trainer:168 RmsProp 1455 loss=0.047223 err=0.047223
I 2015-05-26 10:56:19 theanets.trainer:168 RmsProp 1456 loss=0.044476 err=0.044476
I 2015-05-26 10:56:25 theanets.trainer:168 RmsProp 1457 loss=0.054624 err=0.054624
I 2015-05-26 10:56:31 theanets.trainer:168 RmsProp 1458 loss=0.051072 err=0.051072
I 2015-05-26 10:56:38 theanets.trainer:168 RmsProp 1459 loss=0.052927 err=0.052927
I 2015-05-26 10:56:44 theanets.trainer:168 RmsProp 1460 loss=0.044159 err=0.044159
I 2015-05-26 10:56:44 theanets.trainer:168 validation 146 loss=1145.227905 err=1145.227905
I 2015-05-26 10:56:50 theanets.trainer:168 RmsProp 1461 loss=0.050042 err=0.050042
I 2015-05-26 10:56:56 theanets.trainer:168 RmsProp 1462 loss=0.049337 err=0.049337
I 2015-05-26 10:57:02 theanets.trainer:168 RmsProp 1463 loss=0.049277 err=0.049277
I 2015-05-26 10:57:08 theanets.trainer:168 RmsProp 1464 loss=0.049985 err=0.049985
I 2015-05-26 10:57:14 theanets.trainer:168 RmsProp 1465 loss=0.049388 err=0.049388
I 2015-05-26 10:57:20 theanets.trainer:168 RmsProp 1466 loss=0.046511 err=0.046511
I 2015-05-26 10:57:27 theanets.trainer:168 RmsProp 1467 loss=0.050102 err=0.050102
I 2015-05-26 10:57:32 theanets.trainer:168 RmsProp 1468 loss=0.053130 err=0.053130
I 2015-05-26 10:57:38 theanets.trainer:168 RmsProp 1469 loss=0.047167 err=0.047167
I 2015-05-26 10:57:44 theanets.trainer:168 RmsProp 1470 loss=0.048618 err=0.048618
I 2015-05-26 10:57:45 theanets.trainer:168 validation 147 loss=1143.532593 err=1143.532593 *
I 2015-05-26 10:57:51 theanets.trainer:168 RmsProp 1471 loss=0.046741 err=0.046741
I 2015-05-26 10:57:57 theanets.trainer:168 RmsProp 1472 loss=0.046597 err=0.046597
I 2015-05-26 10:58:03 theanets.trainer:168 RmsProp 1473 loss=0.043745 err=0.043745
I 2015-05-26 10:58:09 theanets.trainer:168 RmsProp 1474 loss=0.050525 err=0.050525
I 2015-05-26 10:58:15 theanets.trainer:168 RmsProp 1475 loss=0.047235 err=0.047235
I 2015-05-26 10:58:20 theanets.trainer:168 RmsProp 1476 loss=0.053289 err=0.053289
I 2015-05-26 10:58:26 theanets.trainer:168 RmsProp 1477 loss=0.046895 err=0.046895
I 2015-05-26 10:58:32 theanets.trainer:168 RmsProp 1478 loss=0.045095 err=0.045095
I 2015-05-26 10:58:39 theanets.trainer:168 RmsProp 1479 loss=0.050065 err=0.050065
I 2015-05-26 10:58:45 theanets.trainer:168 RmsProp 1480 loss=0.050025 err=0.050025
I 2015-05-26 10:58:45 theanets.trainer:168 validation 148 loss=1143.652588 err=1143.652588
I 2015-05-26 10:58:51 theanets.trainer:168 RmsProp 1481 loss=0.047642 err=0.047642
I 2015-05-26 10:58:57 theanets.trainer:168 RmsProp 1482 loss=0.052124 err=0.052124
I 2015-05-26 10:59:03 theanets.trainer:168 RmsProp 1483 loss=0.044654 err=0.044654
I 2015-05-26 10:59:09 theanets.trainer:168 RmsProp 1484 loss=0.048447 err=0.048447
I 2015-05-26 10:59:15 theanets.trainer:168 RmsProp 1485 loss=0.042817 err=0.042817
I 2015-05-26 10:59:21 theanets.trainer:168 RmsProp 1486 loss=0.060662 err=0.060662
I 2015-05-26 10:59:28 theanets.trainer:168 RmsProp 1487 loss=0.046143 err=0.046143
I 2015-05-26 10:59:34 theanets.trainer:168 RmsProp 1488 loss=0.050897 err=0.050897
I 2015-05-26 10:59:40 theanets.trainer:168 RmsProp 1489 loss=0.045046 err=0.045046
I 2015-05-26 10:59:46 theanets.trainer:168 RmsProp 1490 loss=0.049911 err=0.049911
I 2015-05-26 10:59:47 theanets.trainer:168 validation 149 loss=1142.963501 err=1142.963501 *
I 2015-05-26 10:59:53 theanets.trainer:168 RmsProp 1491 loss=0.050683 err=0.050683
I 2015-05-26 10:59:59 theanets.trainer:168 RmsProp 1492 loss=0.048388 err=0.048388
I 2015-05-26 11:00:05 theanets.trainer:168 RmsProp 1493 loss=0.047299 err=0.047299
I 2015-05-26 11:00:11 theanets.trainer:168 RmsProp 1494 loss=0.047308 err=0.047308
I 2015-05-26 11:00:17 theanets.trainer:168 RmsProp 1495 loss=0.050288 err=0.050288
I 2015-05-26 11:00:24 theanets.trainer:168 RmsProp 1496 loss=0.047613 err=0.047613
I 2015-05-26 11:00:30 theanets.trainer:168 RmsProp 1497 loss=0.045533 err=0.045533
I 2015-05-26 11:00:36 theanets.trainer:168 RmsProp 1498 loss=0.047931 err=0.047931
I 2015-05-26 11:00:42 theanets.trainer:168 RmsProp 1499 loss=0.048378 err=0.048378
I 2015-05-26 11:00:49 theanets.trainer:168 RmsProp 1500 loss=0.048852 err=0.048852
I 2015-05-26 11:00:49 theanets.trainer:168 validation 150 loss=1142.652222 err=1142.652222 *
I 2015-05-26 11:00:55 theanets.trainer:168 RmsProp 1501 loss=0.048066 err=0.048066
I 2015-05-26 11:01:01 theanets.trainer:168 RmsProp 1502 loss=0.048813 err=0.048813
I 2015-05-26 11:01:07 theanets.trainer:168 RmsProp 1503 loss=0.047129 err=0.047129
I 2015-05-26 11:01:13 theanets.trainer:168 RmsProp 1504 loss=0.048943 err=0.048943
I 2015-05-26 11:01:19 theanets.trainer:168 RmsProp 1505 loss=0.049143 err=0.049143
I 2015-05-26 11:01:25 theanets.trainer:168 RmsProp 1506 loss=0.046080 err=0.046080
I 2015-05-26 11:01:31 theanets.trainer:168 RmsProp 1507 loss=0.048669 err=0.048669
I 2015-05-26 11:01:38 theanets.trainer:168 RmsProp 1508 loss=0.049905 err=0.049905
I 2015-05-26 11:01:44 theanets.trainer:168 RmsProp 1509 loss=0.048099 err=0.048099
I 2015-05-26 11:01:50 theanets.trainer:168 RmsProp 1510 loss=0.048798 err=0.048798
I 2015-05-26 11:01:51 theanets.trainer:168 validation 151 loss=1142.197632 err=1142.197632 *
I 2015-05-26 11:01:56 theanets.trainer:168 RmsProp 1511 loss=0.046915 err=0.046915
I 2015-05-26 11:02:03 theanets.trainer:168 RmsProp 1512 loss=0.042701 err=0.042701
I 2015-05-26 11:02:08 theanets.trainer:168 RmsProp 1513 loss=0.046018 err=0.046018
I 2015-05-26 11:02:14 theanets.trainer:168 RmsProp 1514 loss=0.055055 err=0.055055
I 2015-05-26 11:02:20 theanets.trainer:168 RmsProp 1515 loss=0.045382 err=0.045382
I 2015-05-26 11:02:25 theanets.trainer:168 RmsProp 1516 loss=0.046697 err=0.046697
I 2015-05-26 11:02:31 theanets.trainer:168 RmsProp 1517 loss=0.046974 err=0.046974
I 2015-05-26 11:02:36 theanets.trainer:168 RmsProp 1518 loss=0.044741 err=0.044741
I 2015-05-26 11:02:41 theanets.trainer:168 RmsProp 1519 loss=0.053146 err=0.053146
I 2015-05-26 11:02:47 theanets.trainer:168 RmsProp 1520 loss=0.046166 err=0.046166
I 2015-05-26 11:02:47 theanets.trainer:168 validation 152 loss=1140.468750 err=1140.468750 *
I 2015-05-26 11:02:52 theanets.trainer:168 RmsProp 1521 loss=0.050614 err=0.050614
I 2015-05-26 11:02:57 theanets.trainer:168 RmsProp 1522 loss=0.046293 err=0.046293
I 2015-05-26 11:03:02 theanets.trainer:168 RmsProp 1523 loss=0.048731 err=0.048731
I 2015-05-26 11:03:07 theanets.trainer:168 RmsProp 1524 loss=0.049956 err=0.049956
I 2015-05-26 11:03:12 theanets.trainer:168 RmsProp 1525 loss=0.045414 err=0.045414
I 2015-05-26 11:03:17 theanets.trainer:168 RmsProp 1526 loss=0.046930 err=0.046930
I 2015-05-26 11:03:23 theanets.trainer:168 RmsProp 1527 loss=0.048355 err=0.048355
I 2015-05-26 11:03:28 theanets.trainer:168 RmsProp 1528 loss=0.046565 err=0.046565
I 2015-05-26 11:03:33 theanets.trainer:168 RmsProp 1529 loss=0.044296 err=0.044296
I 2015-05-26 11:03:38 theanets.trainer:168 RmsProp 1530 loss=0.046060 err=0.046060
I 2015-05-26 11:03:39 theanets.trainer:168 validation 153 loss=1139.502808 err=1139.502808 *
I 2015-05-26 11:03:43 theanets.trainer:168 RmsProp 1531 loss=0.045225 err=0.045225
I 2015-05-26 11:03:48 theanets.trainer:168 RmsProp 1532 loss=0.048454 err=0.048454
I 2015-05-26 11:03:54 theanets.trainer:168 RmsProp 1533 loss=0.048097 err=0.048097
I 2015-05-26 11:03:59 theanets.trainer:168 RmsProp 1534 loss=0.046056 err=0.046056
I 2015-05-26 11:04:04 theanets.trainer:168 RmsProp 1535 loss=0.044642 err=0.044642
I 2015-05-26 11:04:09 theanets.trainer:168 RmsProp 1536 loss=0.047863 err=0.047863
I 2015-05-26 11:04:14 theanets.trainer:168 RmsProp 1537 loss=0.047682 err=0.047682
I 2015-05-26 11:04:20 theanets.trainer:168 RmsProp 1538 loss=0.047572 err=0.047572
I 2015-05-26 11:04:25 theanets.trainer:168 RmsProp 1539 loss=0.047585 err=0.047585
I 2015-05-26 11:04:30 theanets.trainer:168 RmsProp 1540 loss=0.045946 err=0.045946
I 2015-05-26 11:04:30 theanets.trainer:168 validation 154 loss=1139.980957 err=1139.980957
I 2015-05-26 11:04:35 theanets.trainer:168 RmsProp 1541 loss=0.047602 err=0.047602
I 2015-05-26 11:04:40 theanets.trainer:168 RmsProp 1542 loss=0.048186 err=0.048186
I 2015-05-26 11:04:45 theanets.trainer:168 RmsProp 1543 loss=0.046026 err=0.046026
I 2015-05-26 11:04:50 theanets.trainer:168 RmsProp 1544 loss=0.045849 err=0.045849
I 2015-05-26 11:04:54 theanets.trainer:168 RmsProp 1545 loss=0.045976 err=0.045976
I 2015-05-26 11:04:58 theanets.trainer:168 RmsProp 1546 loss=0.047486 err=0.047486
I 2015-05-26 11:05:02 theanets.trainer:168 RmsProp 1547 loss=0.042541 err=0.042541
I 2015-05-26 11:05:06 theanets.trainer:168 RmsProp 1548 loss=0.049572 err=0.049572
I 2015-05-26 11:05:10 theanets.trainer:168 RmsProp 1549 loss=0.051304 err=0.051304
I 2015-05-26 11:05:14 theanets.trainer:168 RmsProp 1550 loss=0.043044 err=0.043044
I 2015-05-26 11:05:15 theanets.trainer:168 validation 155 loss=1139.713501 err=1139.713501
I 2015-05-26 11:05:18 theanets.trainer:168 RmsProp 1551 loss=0.052404 err=0.052404
I 2015-05-26 11:05:22 theanets.trainer:168 RmsProp 1552 loss=0.049299 err=0.049299
I 2015-05-26 11:05:26 theanets.trainer:168 RmsProp 1553 loss=0.048098 err=0.048098
I 2015-05-26 11:05:30 theanets.trainer:168 RmsProp 1554 loss=0.043939 err=0.043939
I 2015-05-26 11:05:34 theanets.trainer:168 RmsProp 1555 loss=0.042890 err=0.042890
I 2015-05-26 11:05:38 theanets.trainer:168 RmsProp 1556 loss=0.046017 err=0.046017
I 2015-05-26 11:05:42 theanets.trainer:168 RmsProp 1557 loss=0.048324 err=0.048324
I 2015-05-26 11:05:46 theanets.trainer:168 RmsProp 1558 loss=0.047883 err=0.047883
I 2015-05-26 11:05:50 theanets.trainer:168 RmsProp 1559 loss=0.044838 err=0.044838
I 2015-05-26 11:05:54 theanets.trainer:168 RmsProp 1560 loss=0.045724 err=0.045724
I 2015-05-26 11:05:55 theanets.trainer:168 validation 156 loss=1139.689575 err=1139.689575
I 2015-05-26 11:05:58 theanets.trainer:168 RmsProp 1561 loss=0.043341 err=0.043341
I 2015-05-26 11:06:02 theanets.trainer:168 RmsProp 1562 loss=0.050963 err=0.050963
I 2015-05-26 11:06:06 theanets.trainer:168 RmsProp 1563 loss=0.043543 err=0.043543
I 2015-05-26 11:06:10 theanets.trainer:168 RmsProp 1564 loss=0.051712 err=0.051712
I 2015-05-26 11:06:14 theanets.trainer:168 RmsProp 1565 loss=0.046125 err=0.046125
I 2015-05-26 11:06:18 theanets.trainer:168 RmsProp 1566 loss=0.048365 err=0.048365
I 2015-05-26 11:06:22 theanets.trainer:168 RmsProp 1567 loss=0.044482 err=0.044482
I 2015-05-26 11:06:26 theanets.trainer:168 RmsProp 1568 loss=0.042842 err=0.042842
I 2015-05-26 11:06:30 theanets.trainer:168 RmsProp 1569 loss=0.050371 err=0.050371
I 2015-05-26 11:06:34 theanets.trainer:168 RmsProp 1570 loss=0.047860 err=0.047860
I 2015-05-26 11:06:35 theanets.trainer:168 validation 157 loss=1139.089478 err=1139.089478 *
I 2015-05-26 11:06:38 theanets.trainer:168 RmsProp 1571 loss=0.044519 err=0.044519
I 2015-05-26 11:06:42 theanets.trainer:168 RmsProp 1572 loss=0.045016 err=0.045016
I 2015-05-26 11:06:46 theanets.trainer:168 RmsProp 1573 loss=0.043855 err=0.043855
I 2015-05-26 11:06:50 theanets.trainer:168 RmsProp 1574 loss=0.047772 err=0.047772
I 2015-05-26 11:06:54 theanets.trainer:168 RmsProp 1575 loss=0.046503 err=0.046503
I 2015-05-26 11:06:58 theanets.trainer:168 RmsProp 1576 loss=0.044433 err=0.044433
I 2015-05-26 11:07:02 theanets.trainer:168 RmsProp 1577 loss=0.048105 err=0.048105
I 2015-05-26 11:07:06 theanets.trainer:168 RmsProp 1578 loss=0.045500 err=0.045500
I 2015-05-26 11:07:10 theanets.trainer:168 RmsProp 1579 loss=0.047980 err=0.047980
I 2015-05-26 11:07:14 theanets.trainer:168 RmsProp 1580 loss=0.044296 err=0.044296
I 2015-05-26 11:07:14 theanets.trainer:168 validation 158 loss=1138.265991 err=1138.265991 *
I 2015-05-26 11:07:18 theanets.trainer:168 RmsProp 1581 loss=0.042913 err=0.042913
I 2015-05-26 11:07:22 theanets.trainer:168 RmsProp 1582 loss=0.043613 err=0.043613
I 2015-05-26 11:07:26 theanets.trainer:168 RmsProp 1583 loss=0.052629 err=0.052629
I 2015-05-26 11:07:30 theanets.trainer:168 RmsProp 1584 loss=0.045953 err=0.045953
I 2015-05-26 11:07:34 theanets.trainer:168 RmsProp 1585 loss=0.047384 err=0.047384
I 2015-05-26 11:07:38 theanets.trainer:168 RmsProp 1586 loss=0.041214 err=0.041214
I 2015-05-26 11:07:42 theanets.trainer:168 RmsProp 1587 loss=0.047246 err=0.047246
I 2015-05-26 11:07:46 theanets.trainer:168 RmsProp 1588 loss=0.044308 err=0.044308
I 2015-05-26 11:07:50 theanets.trainer:168 RmsProp 1589 loss=0.047392 err=0.047392
I 2015-05-26 11:07:54 theanets.trainer:168 RmsProp 1590 loss=0.043501 err=0.043501
I 2015-05-26 11:07:54 theanets.trainer:168 validation 159 loss=1138.358521 err=1138.358521
I 2015-05-26 11:07:58 theanets.trainer:168 RmsProp 1591 loss=0.047578 err=0.047578
I 2015-05-26 11:08:02 theanets.trainer:168 RmsProp 1592 loss=0.045261 err=0.045261
I 2015-05-26 11:08:06 theanets.trainer:168 RmsProp 1593 loss=0.046744 err=0.046744
I 2015-05-26 11:08:10 theanets.trainer:168 RmsProp 1594 loss=0.044562 err=0.044562
I 2015-05-26 11:08:14 theanets.trainer:168 RmsProp 1595 loss=0.045858 err=0.045858
I 2015-05-26 11:08:18 theanets.trainer:168 RmsProp 1596 loss=0.055645 err=0.055645
I 2015-05-26 11:08:22 theanets.trainer:168 RmsProp 1597 loss=0.046908 err=0.046908
I 2015-05-26 11:08:26 theanets.trainer:168 RmsProp 1598 loss=0.041061 err=0.041061
I 2015-05-26 11:08:30 theanets.trainer:168 RmsProp 1599 loss=0.050251 err=0.050251
I 2015-05-26 11:08:34 theanets.trainer:168 RmsProp 1600 loss=0.041254 err=0.041254
I 2015-05-26 11:08:34 theanets.trainer:168 validation 160 loss=1136.146362 err=1136.146362 *
I 2015-05-26 11:08:38 theanets.trainer:168 RmsProp 1601 loss=0.045804 err=0.045804
I 2015-05-26 11:08:42 theanets.trainer:168 RmsProp 1602 loss=0.046970 err=0.046970
I 2015-05-26 11:08:46 theanets.trainer:168 RmsProp 1603 loss=0.042011 err=0.042011
I 2015-05-26 11:08:50 theanets.trainer:168 RmsProp 1604 loss=0.047104 err=0.047104
I 2015-05-26 11:08:54 theanets.trainer:168 RmsProp 1605 loss=0.043636 err=0.043636
I 2015-05-26 11:08:58 theanets.trainer:168 RmsProp 1606 loss=0.044072 err=0.044072
I 2015-05-26 11:09:02 theanets.trainer:168 RmsProp 1607 loss=0.044621 err=0.044621
I 2015-05-26 11:09:06 theanets.trainer:168 RmsProp 1608 loss=0.045597 err=0.045597
I 2015-05-26 11:09:11 theanets.trainer:168 RmsProp 1609 loss=0.043567 err=0.043567
I 2015-05-26 11:09:15 theanets.trainer:168 RmsProp 1610 loss=0.042763 err=0.042763
I 2015-05-26 11:09:15 theanets.trainer:168 validation 161 loss=1136.619507 err=1136.619507
I 2015-05-26 11:09:18 theanets.trainer:168 RmsProp 1611 loss=0.046837 err=0.046837
I 2015-05-26 11:09:22 theanets.trainer:168 RmsProp 1612 loss=0.039427 err=0.039427
I 2015-05-26 11:09:26 theanets.trainer:168 RmsProp 1613 loss=0.058456 err=0.058456
I 2015-05-26 11:09:30 theanets.trainer:168 RmsProp 1614 loss=0.047021 err=0.047021
I 2015-05-26 11:09:34 theanets.trainer:168 RmsProp 1615 loss=0.045932 err=0.045932
I 2015-05-26 11:09:38 theanets.trainer:168 RmsProp 1616 loss=0.046799 err=0.046799
I 2015-05-26 11:09:43 theanets.trainer:168 RmsProp 1617 loss=0.045014 err=0.045014
I 2015-05-26 11:09:47 theanets.trainer:168 RmsProp 1618 loss=0.039990 err=0.039990
I 2015-05-26 11:09:51 theanets.trainer:168 RmsProp 1619 loss=0.047563 err=0.047563
I 2015-05-26 11:09:55 theanets.trainer:168 RmsProp 1620 loss=0.042595 err=0.042595
I 2015-05-26 11:09:55 theanets.trainer:168 validation 162 loss=1135.008667 err=1135.008667 *
I 2015-05-26 11:09:59 theanets.trainer:168 RmsProp 1621 loss=0.040402 err=0.040402
I 2015-05-26 11:10:02 theanets.trainer:168 RmsProp 1622 loss=0.055574 err=0.055574
I 2015-05-26 11:10:06 theanets.trainer:168 RmsProp 1623 loss=0.044243 err=0.044243
I 2015-05-26 11:10:10 theanets.trainer:168 RmsProp 1624 loss=0.040719 err=0.040719
I 2015-05-26 11:10:14 theanets.trainer:168 RmsProp 1625 loss=0.046660 err=0.046660
I 2015-05-26 11:10:19 theanets.trainer:168 RmsProp 1626 loss=0.045313 err=0.045313
I 2015-05-26 11:10:23 theanets.trainer:168 RmsProp 1627 loss=0.046321 err=0.046321
I 2015-05-26 11:10:27 theanets.trainer:168 RmsProp 1628 loss=0.039844 err=0.039844
I 2015-05-26 11:10:31 theanets.trainer:168 RmsProp 1629 loss=0.050174 err=0.050174
I 2015-05-26 11:10:35 theanets.trainer:168 RmsProp 1630 loss=0.039191 err=0.039191
I 2015-05-26 11:10:35 theanets.trainer:168 validation 163 loss=1134.849609 err=1134.849609 *
I 2015-05-26 11:10:39 theanets.trainer:168 RmsProp 1631 loss=0.046774 err=0.046774
I 2015-05-26 11:10:43 theanets.trainer:168 RmsProp 1632 loss=0.046298 err=0.046298
I 2015-05-26 11:10:47 theanets.trainer:168 RmsProp 1633 loss=0.043601 err=0.043601
I 2015-05-26 11:10:51 theanets.trainer:168 RmsProp 1634 loss=0.044713 err=0.044713
I 2015-05-26 11:10:54 theanets.trainer:168 RmsProp 1635 loss=0.044975 err=0.044975
I 2015-05-26 11:10:58 theanets.trainer:168 RmsProp 1636 loss=0.047455 err=0.047455
I 2015-05-26 11:11:02 theanets.trainer:168 RmsProp 1637 loss=0.046125 err=0.046125
I 2015-05-26 11:11:06 theanets.trainer:168 RmsProp 1638 loss=0.043739 err=0.043739
I 2015-05-26 11:11:10 theanets.trainer:168 RmsProp 1639 loss=0.040513 err=0.040513
I 2015-05-26 11:11:14 theanets.trainer:168 RmsProp 1640 loss=0.045317 err=0.045317
I 2015-05-26 11:11:15 theanets.trainer:168 validation 164 loss=1134.923218 err=1134.923218
I 2015-05-26 11:11:18 theanets.trainer:168 RmsProp 1641 loss=0.042579 err=0.042579
I 2015-05-26 11:11:22 theanets.trainer:168 RmsProp 1642 loss=0.043007 err=0.043007
I 2015-05-26 11:11:26 theanets.trainer:168 RmsProp 1643 loss=0.043832 err=0.043832
I 2015-05-26 11:11:30 theanets.trainer:168 RmsProp 1644 loss=0.045767 err=0.045767
I 2015-05-26 11:11:34 theanets.trainer:168 RmsProp 1645 loss=0.046865 err=0.046865
I 2015-05-26 11:11:38 theanets.trainer:168 RmsProp 1646 loss=0.043991 err=0.043991
I 2015-05-26 11:11:42 theanets.trainer:168 RmsProp 1647 loss=0.046584 err=0.046584
I 2015-05-26 11:11:46 theanets.trainer:168 RmsProp 1648 loss=0.043178 err=0.043178
I 2015-05-26 11:11:50 theanets.trainer:168 RmsProp 1649 loss=0.048118 err=0.048118
I 2015-05-26 11:11:54 theanets.trainer:168 RmsProp 1650 loss=0.045881 err=0.045881
I 2015-05-26 11:11:55 theanets.trainer:168 validation 165 loss=1133.478394 err=1133.478394 *
I 2015-05-26 11:11:58 theanets.trainer:168 RmsProp 1651 loss=0.042744 err=0.042744
I 2015-05-26 11:12:02 theanets.trainer:168 RmsProp 1652 loss=0.050795 err=0.050795
I 2015-05-26 11:12:06 theanets.trainer:168 RmsProp 1653 loss=0.041639 err=0.041639
I 2015-05-26 11:12:10 theanets.trainer:168 RmsProp 1654 loss=0.045539 err=0.045539
I 2015-05-26 11:12:14 theanets.trainer:168 RmsProp 1655 loss=0.044233 err=0.044233
I 2015-05-26 11:12:18 theanets.trainer:168 RmsProp 1656 loss=0.040655 err=0.040655
I 2015-05-26 11:12:22 theanets.trainer:168 RmsProp 1657 loss=0.050533 err=0.050533
I 2015-05-26 11:12:26 theanets.trainer:168 RmsProp 1658 loss=0.043616 err=0.043616
I 2015-05-26 11:12:30 theanets.trainer:168 RmsProp 1659 loss=0.042390 err=0.042390
I 2015-05-26 11:12:34 theanets.trainer:168 RmsProp 1660 loss=0.041357 err=0.041357
I 2015-05-26 11:12:35 theanets.trainer:168 validation 166 loss=1133.061401 err=1133.061401 *
I 2015-05-26 11:12:38 theanets.trainer:168 RmsProp 1661 loss=0.045196 err=0.045196
I 2015-05-26 11:12:42 theanets.trainer:168 RmsProp 1662 loss=0.044674 err=0.044674
I 2015-05-26 11:12:46 theanets.trainer:168 RmsProp 1663 loss=0.045766 err=0.045766
I 2015-05-26 11:12:50 theanets.trainer:168 RmsProp 1664 loss=0.043402 err=0.043402
I 2015-05-26 11:12:54 theanets.trainer:168 RmsProp 1665 loss=0.043109 err=0.043109
I 2015-05-26 11:12:58 theanets.trainer:168 RmsProp 1666 loss=0.043296 err=0.043296
I 2015-05-26 11:13:02 theanets.trainer:168 RmsProp 1667 loss=0.043724 err=0.043724
I 2015-05-26 11:13:06 theanets.trainer:168 RmsProp 1668 loss=0.040503 err=0.040503
I 2015-05-26 11:13:10 theanets.trainer:168 RmsProp 1669 loss=0.049340 err=0.049340
I 2015-05-26 11:13:14 theanets.trainer:168 RmsProp 1670 loss=0.040370 err=0.040370
I 2015-05-26 11:13:14 theanets.trainer:168 validation 167 loss=1132.605835 err=1132.605835 *
I 2015-05-26 11:13:18 theanets.trainer:168 RmsProp 1671 loss=0.042555 err=0.042555
I 2015-05-26 11:13:21 theanets.trainer:168 RmsProp 1672 loss=0.038504 err=0.038504
I 2015-05-26 11:13:26 theanets.trainer:168 RmsProp 1673 loss=0.058847 err=0.058847
I 2015-05-26 11:13:29 theanets.trainer:168 RmsProp 1674 loss=0.047847 err=0.047847
I 2015-05-26 11:13:33 theanets.trainer:168 RmsProp 1675 loss=0.043293 err=0.043293
I 2015-05-26 11:13:37 theanets.trainer:168 RmsProp 1676 loss=0.040128 err=0.040128
I 2015-05-26 11:13:41 theanets.trainer:168 RmsProp 1677 loss=0.044640 err=0.044640
I 2015-05-26 11:13:46 theanets.trainer:168 RmsProp 1678 loss=0.043223 err=0.043223
I 2015-05-26 11:13:50 theanets.trainer:168 RmsProp 1679 loss=0.042548 err=0.042548
I 2015-05-26 11:13:54 theanets.trainer:168 RmsProp 1680 loss=0.043067 err=0.043067
I 2015-05-26 11:13:54 theanets.trainer:168 validation 168 loss=1132.589111 err=1132.589111 *
I 2015-05-26 11:13:58 theanets.trainer:168 RmsProp 1681 loss=0.041906 err=0.041906
I 2015-05-26 11:14:01 theanets.trainer:168 RmsProp 1682 loss=0.046302 err=0.046302
I 2015-05-26 11:14:05 theanets.trainer:168 RmsProp 1683 loss=0.042183 err=0.042183
I 2015-05-26 11:14:09 theanets.trainer:168 RmsProp 1684 loss=0.040039 err=0.040039
I 2015-05-26 11:14:12 theanets.trainer:168 RmsProp 1685 loss=0.047861 err=0.047861
I 2015-05-26 11:14:15 theanets.trainer:168 RmsProp 1686 loss=0.040444 err=0.040444
I 2015-05-26 11:14:18 theanets.trainer:168 RmsProp 1687 loss=0.041294 err=0.041294
I 2015-05-26 11:14:21 theanets.trainer:168 RmsProp 1688 loss=0.042966 err=0.042966
I 2015-05-26 11:14:24 theanets.trainer:168 RmsProp 1689 loss=0.042886 err=0.042886
I 2015-05-26 11:14:27 theanets.trainer:168 RmsProp 1690 loss=0.046476 err=0.046476
I 2015-05-26 11:14:27 theanets.trainer:168 validation 169 loss=1131.623535 err=1131.623535 *
I 2015-05-26 11:14:30 theanets.trainer:168 RmsProp 1691 loss=0.040749 err=0.040749
I 2015-05-26 11:14:33 theanets.trainer:168 RmsProp 1692 loss=0.046981 err=0.046981
I 2015-05-26 11:14:36 theanets.trainer:168 RmsProp 1693 loss=0.042097 err=0.042097
I 2015-05-26 11:14:39 theanets.trainer:168 RmsProp 1694 loss=0.047431 err=0.047431
I 2015-05-26 11:14:42 theanets.trainer:168 RmsProp 1695 loss=0.042442 err=0.042442
I 2015-05-26 11:14:45 theanets.trainer:168 RmsProp 1696 loss=0.047306 err=0.047306
I 2015-05-26 11:14:48 theanets.trainer:168 RmsProp 1697 loss=0.039763 err=0.039763
I 2015-05-26 11:14:51 theanets.trainer:168 RmsProp 1698 loss=0.042315 err=0.042315
I 2015-05-26 11:14:54 theanets.trainer:168 RmsProp 1699 loss=0.050899 err=0.050899
I 2015-05-26 11:14:57 theanets.trainer:168 RmsProp 1700 loss=0.037889 err=0.037889
I 2015-05-26 11:14:57 theanets.trainer:168 validation 170 loss=1131.794922 err=1131.794922
I 2015-05-26 11:14:59 theanets.trainer:168 RmsProp 1701 loss=0.052523 err=0.052523
I 2015-05-26 11:15:02 theanets.trainer:168 RmsProp 1702 loss=0.044610 err=0.044610
I 2015-05-26 11:15:04 theanets.trainer:168 RmsProp 1703 loss=0.043366 err=0.043366
I 2015-05-26 11:15:07 theanets.trainer:168 RmsProp 1704 loss=0.037525 err=0.037525
I 2015-05-26 11:15:10 theanets.trainer:168 RmsProp 1705 loss=0.047821 err=0.047821
I 2015-05-26 11:15:12 theanets.trainer:168 RmsProp 1706 loss=0.042550 err=0.042550
I 2015-05-26 11:15:15 theanets.trainer:168 RmsProp 1707 loss=0.042041 err=0.042041
I 2015-05-26 11:15:17 theanets.trainer:168 RmsProp 1708 loss=0.046006 err=0.046006
I 2015-05-26 11:15:20 theanets.trainer:168 RmsProp 1709 loss=0.040295 err=0.040295
I 2015-05-26 11:15:22 theanets.trainer:168 RmsProp 1710 loss=0.043219 err=0.043219
I 2015-05-26 11:15:23 theanets.trainer:168 validation 171 loss=1132.386597 err=1132.386597
I 2015-05-26 11:15:25 theanets.trainer:168 RmsProp 1711 loss=0.046044 err=0.046044
I 2015-05-26 11:15:28 theanets.trainer:168 RmsProp 1712 loss=0.037695 err=0.037695
I 2015-05-26 11:15:30 theanets.trainer:168 RmsProp 1713 loss=0.052079 err=0.052079
I 2015-05-26 11:15:33 theanets.trainer:168 RmsProp 1714 loss=0.041083 err=0.041083
I 2015-05-26 11:15:35 theanets.trainer:168 RmsProp 1715 loss=0.041391 err=0.041391
I 2015-05-26 11:15:38 theanets.trainer:168 RmsProp 1716 loss=0.039149 err=0.039149
I 2015-05-26 11:15:40 theanets.trainer:168 RmsProp 1717 loss=0.047454 err=0.047454
I 2015-05-26 11:15:43 theanets.trainer:168 RmsProp 1718 loss=0.041296 err=0.041296
I 2015-05-26 11:15:45 theanets.trainer:168 RmsProp 1719 loss=0.037749 err=0.037749
I 2015-05-26 11:15:48 theanets.trainer:168 RmsProp 1720 loss=0.042458 err=0.042458
I 2015-05-26 11:15:48 theanets.trainer:168 validation 172 loss=1131.218140 err=1131.218140 *
I 2015-05-26 11:15:51 theanets.trainer:168 RmsProp 1721 loss=0.040301 err=0.040301
I 2015-05-26 11:15:53 theanets.trainer:168 RmsProp 1722 loss=0.042787 err=0.042787
I 2015-05-26 11:15:56 theanets.trainer:168 RmsProp 1723 loss=0.044868 err=0.044868
I 2015-05-26 11:15:58 theanets.trainer:168 RmsProp 1724 loss=0.042390 err=0.042390
I 2015-05-26 11:16:01 theanets.trainer:168 RmsProp 1725 loss=0.038323 err=0.038323
I 2015-05-26 11:16:03 theanets.trainer:168 RmsProp 1726 loss=0.044968 err=0.044968
I 2015-05-26 11:16:06 theanets.trainer:168 RmsProp 1727 loss=0.044720 err=0.044720
I 2015-05-26 11:16:08 theanets.trainer:168 RmsProp 1728 loss=0.039479 err=0.039479
I 2015-05-26 11:16:11 theanets.trainer:168 RmsProp 1729 loss=0.045322 err=0.045322
I 2015-05-26 11:16:14 theanets.trainer:168 RmsProp 1730 loss=0.039962 err=0.039962
I 2015-05-26 11:16:14 theanets.trainer:168 validation 173 loss=1130.883667 err=1130.883667 *
I 2015-05-26 11:16:16 theanets.trainer:168 RmsProp 1731 loss=0.051052 err=0.051052
I 2015-05-26 11:16:19 theanets.trainer:168 RmsProp 1732 loss=0.042045 err=0.042045
I 2015-05-26 11:16:21 theanets.trainer:168 RmsProp 1733 loss=0.041309 err=0.041309
I 2015-05-26 11:16:24 theanets.trainer:168 RmsProp 1734 loss=0.041884 err=0.041884
I 2015-05-26 11:16:26 theanets.trainer:168 RmsProp 1735 loss=0.042153 err=0.042153
I 2015-05-26 11:16:29 theanets.trainer:168 RmsProp 1736 loss=0.039706 err=0.039706
I 2015-05-26 11:16:32 theanets.trainer:168 RmsProp 1737 loss=0.039484 err=0.039484
I 2015-05-26 11:16:34 theanets.trainer:168 RmsProp 1738 loss=0.048005 err=0.048005
I 2015-05-26 11:16:37 theanets.trainer:168 RmsProp 1739 loss=0.036647 err=0.036647
I 2015-05-26 11:16:39 theanets.trainer:168 RmsProp 1740 loss=0.046607 err=0.046607
I 2015-05-26 11:16:39 theanets.trainer:168 validation 174 loss=1129.447632 err=1129.447632 *
I 2015-05-26 11:16:42 theanets.trainer:168 RmsProp 1741 loss=0.041118 err=0.041118
I 2015-05-26 11:16:45 theanets.trainer:168 RmsProp 1742 loss=0.040010 err=0.040010
I 2015-05-26 11:16:48 theanets.trainer:168 RmsProp 1743 loss=0.042601 err=0.042601
I 2015-05-26 11:16:51 theanets.trainer:168 RmsProp 1744 loss=0.039460 err=0.039460
I 2015-05-26 11:16:54 theanets.trainer:168 RmsProp 1745 loss=0.040911 err=0.040911
I 2015-05-26 11:16:57 theanets.trainer:168 RmsProp 1746 loss=0.046465 err=0.046465
I 2015-05-26 11:17:00 theanets.trainer:168 RmsProp 1747 loss=0.038214 err=0.038214
I 2015-05-26 11:17:02 theanets.trainer:168 RmsProp 1748 loss=0.049414 err=0.049414
I 2015-05-26 11:17:05 theanets.trainer:168 RmsProp 1749 loss=0.040850 err=0.040850
I 2015-05-26 11:17:08 theanets.trainer:168 RmsProp 1750 loss=0.044310 err=0.044310
I 2015-05-26 11:17:09 theanets.trainer:168 validation 175 loss=1129.268066 err=1129.268066 *
I 2015-05-26 11:17:12 theanets.trainer:168 RmsProp 1751 loss=0.041677 err=0.041677
I 2015-05-26 11:17:14 theanets.trainer:168 RmsProp 1752 loss=0.043126 err=0.043126
I 2015-05-26 11:17:17 theanets.trainer:168 RmsProp 1753 loss=0.040586 err=0.040586
I 2015-05-26 11:17:20 theanets.trainer:168 RmsProp 1754 loss=0.044597 err=0.044597
I 2015-05-26 11:17:23 theanets.trainer:168 RmsProp 1755 loss=0.039666 err=0.039666
I 2015-05-26 11:17:26 theanets.trainer:168 RmsProp 1756 loss=0.039697 err=0.039697
I 2015-05-26 11:17:29 theanets.trainer:168 RmsProp 1757 loss=0.043516 err=0.043516
I 2015-05-26 11:17:32 theanets.trainer:168 RmsProp 1758 loss=0.042758 err=0.042758
I 2015-05-26 11:17:35 theanets.trainer:168 RmsProp 1759 loss=0.044174 err=0.044174
I 2015-05-26 11:17:38 theanets.trainer:168 RmsProp 1760 loss=0.039091 err=0.039091
I 2015-05-26 11:17:38 theanets.trainer:168 validation 176 loss=1128.823364 err=1128.823364 *
I 2015-05-26 11:17:41 theanets.trainer:168 RmsProp 1761 loss=0.039457 err=0.039457
I 2015-05-26 11:17:44 theanets.trainer:168 RmsProp 1762 loss=0.045319 err=0.045319
I 2015-05-26 11:17:47 theanets.trainer:168 RmsProp 1763 loss=0.052478 err=0.052478
I 2015-05-26 11:17:50 theanets.trainer:168 RmsProp 1764 loss=0.043314 err=0.043314
I 2015-05-26 11:17:53 theanets.trainer:168 RmsProp 1765 loss=0.043619 err=0.043619
I 2015-05-26 11:17:56 theanets.trainer:168 RmsProp 1766 loss=0.036371 err=0.036371
I 2015-05-26 11:17:59 theanets.trainer:168 RmsProp 1767 loss=0.048972 err=0.048972
I 2015-05-26 11:18:02 theanets.trainer:168 RmsProp 1768 loss=0.041595 err=0.041595
I 2015-05-26 11:18:04 theanets.trainer:168 RmsProp 1769 loss=0.041731 err=0.041731
I 2015-05-26 11:18:07 theanets.trainer:168 RmsProp 1770 loss=0.040318 err=0.040318
I 2015-05-26 11:18:07 theanets.trainer:168 validation 177 loss=1128.229858 err=1128.229858 *
I 2015-05-26 11:18:09 theanets.trainer:168 RmsProp 1771 loss=0.041133 err=0.041133
I 2015-05-26 11:18:12 theanets.trainer:168 RmsProp 1772 loss=0.043018 err=0.043018
I 2015-05-26 11:18:14 theanets.trainer:168 RmsProp 1773 loss=0.044562 err=0.044562
I 2015-05-26 11:18:16 theanets.trainer:168 RmsProp 1774 loss=0.040147 err=0.040147
I 2015-05-26 11:18:19 theanets.trainer:168 RmsProp 1775 loss=0.038755 err=0.038755
I 2015-05-26 11:18:21 theanets.trainer:168 RmsProp 1776 loss=0.045464 err=0.045464
I 2015-05-26 11:18:24 theanets.trainer:168 RmsProp 1777 loss=0.037079 err=0.037079
I 2015-05-26 11:18:26 theanets.trainer:168 RmsProp 1778 loss=0.046123 err=0.046123
I 2015-05-26 11:18:28 theanets.trainer:168 RmsProp 1779 loss=0.041686 err=0.041686
I 2015-05-26 11:18:31 theanets.trainer:168 RmsProp 1780 loss=0.042685 err=0.042685
I 2015-05-26 11:18:31 theanets.trainer:168 validation 178 loss=1127.570312 err=1127.570312 *
I 2015-05-26 11:18:33 theanets.trainer:168 RmsProp 1781 loss=0.042454 err=0.042454
I 2015-05-26 11:18:36 theanets.trainer:168 RmsProp 1782 loss=0.040235 err=0.040235
I 2015-05-26 11:18:38 theanets.trainer:168 RmsProp 1783 loss=0.041291 err=0.041291
I 2015-05-26 11:18:40 theanets.trainer:168 RmsProp 1784 loss=0.043105 err=0.043105
I 2015-05-26 11:18:43 theanets.trainer:168 RmsProp 1785 loss=0.042951 err=0.042951
I 2015-05-26 11:18:45 theanets.trainer:168 RmsProp 1786 loss=0.043524 err=0.043524
I 2015-05-26 11:18:48 theanets.trainer:168 RmsProp 1787 loss=0.043617 err=0.043617
I 2015-05-26 11:18:50 theanets.trainer:168 RmsProp 1788 loss=0.040495 err=0.040495
I 2015-05-26 11:18:52 theanets.trainer:168 RmsProp 1789 loss=0.042424 err=0.042424
I 2015-05-26 11:18:55 theanets.trainer:168 RmsProp 1790 loss=0.036266 err=0.036266
I 2015-05-26 11:18:55 theanets.trainer:168 validation 179 loss=1127.866455 err=1127.866455
I 2015-05-26 11:18:57 theanets.trainer:168 RmsProp 1791 loss=0.050155 err=0.050155
I 2015-05-26 11:19:00 theanets.trainer:168 RmsProp 1792 loss=0.037083 err=0.037083
I 2015-05-26 11:19:02 theanets.trainer:168 RmsProp 1793 loss=0.042790 err=0.042790
I 2015-05-26 11:19:04 theanets.trainer:168 RmsProp 1794 loss=0.040683 err=0.040683
I 2015-05-26 11:19:07 theanets.trainer:168 RmsProp 1795 loss=0.040822 err=0.040822
I 2015-05-26 11:19:09 theanets.trainer:168 RmsProp 1796 loss=0.044333 err=0.044333
I 2015-05-26 11:19:12 theanets.trainer:168 RmsProp 1797 loss=0.039574 err=0.039574
I 2015-05-26 11:19:14 theanets.trainer:168 RmsProp 1798 loss=0.039750 err=0.039750
I 2015-05-26 11:19:16 theanets.trainer:168 RmsProp 1799 loss=0.042287 err=0.042287
I 2015-05-26 11:19:19 theanets.trainer:168 RmsProp 1800 loss=0.039895 err=0.039895
I 2015-05-26 11:19:19 theanets.trainer:168 validation 180 loss=1127.741211 err=1127.741211
I 2015-05-26 11:19:21 theanets.trainer:168 RmsProp 1801 loss=0.040186 err=0.040186
I 2015-05-26 11:19:24 theanets.trainer:168 RmsProp 1802 loss=0.043245 err=0.043245
I 2015-05-26 11:19:26 theanets.trainer:168 RmsProp 1803 loss=0.044341 err=0.044341
I 2015-05-26 11:19:28 theanets.trainer:168 RmsProp 1804 loss=0.036507 err=0.036507
I 2015-05-26 11:19:31 theanets.trainer:168 RmsProp 1805 loss=0.038876 err=0.038876
I 2015-05-26 11:19:33 theanets.trainer:168 RmsProp 1806 loss=0.044592 err=0.044592
I 2015-05-26 11:19:36 theanets.trainer:168 RmsProp 1807 loss=0.042298 err=0.042298
I 2015-05-26 11:19:38 theanets.trainer:168 RmsProp 1808 loss=0.043170 err=0.043170
I 2015-05-26 11:19:40 theanets.trainer:168 RmsProp 1809 loss=0.040989 err=0.040989
I 2015-05-26 11:19:43 theanets.trainer:168 RmsProp 1810 loss=0.039370 err=0.039370
I 2015-05-26 11:19:43 theanets.trainer:168 validation 181 loss=1127.796265 err=1127.796265
I 2015-05-26 11:19:45 theanets.trainer:168 RmsProp 1811 loss=0.041292 err=0.041292
I 2015-05-26 11:19:48 theanets.trainer:168 RmsProp 1812 loss=0.041726 err=0.041726
I 2015-05-26 11:19:50 theanets.trainer:168 RmsProp 1813 loss=0.039711 err=0.039711
I 2015-05-26 11:19:52 theanets.trainer:168 RmsProp 1814 loss=0.042402 err=0.042402
I 2015-05-26 11:19:55 theanets.trainer:168 RmsProp 1815 loss=0.041528 err=0.041528
I 2015-05-26 11:19:57 theanets.trainer:168 RmsProp 1816 loss=0.039299 err=0.039299
I 2015-05-26 11:20:00 theanets.trainer:168 RmsProp 1817 loss=0.046414 err=0.046414
I 2015-05-26 11:20:02 theanets.trainer:168 RmsProp 1818 loss=0.035773 err=0.035773
I 2015-05-26 11:20:04 theanets.trainer:168 RmsProp 1819 loss=0.052263 err=0.052263
I 2015-05-26 11:20:07 theanets.trainer:168 RmsProp 1820 loss=0.039314 err=0.039314
I 2015-05-26 11:20:07 theanets.trainer:168 validation 182 loss=1125.711182 err=1125.711182 *
I 2015-05-26 11:20:09 theanets.trainer:168 RmsProp 1821 loss=0.043753 err=0.043753
I 2015-05-26 11:20:12 theanets.trainer:168 RmsProp 1822 loss=0.038871 err=0.038871
I 2015-05-26 11:20:14 theanets.trainer:168 RmsProp 1823 loss=0.035792 err=0.035792
I 2015-05-26 11:20:16 theanets.trainer:168 RmsProp 1824 loss=0.051561 err=0.051561
I 2015-05-26 11:20:19 theanets.trainer:168 RmsProp 1825 loss=0.041008 err=0.041008
I 2015-05-26 11:20:21 theanets.trainer:168 RmsProp 1826 loss=0.036239 err=0.036239
I 2015-05-26 11:20:23 theanets.trainer:168 RmsProp 1827 loss=0.041759 err=0.041759
I 2015-05-26 11:20:26 theanets.trainer:168 RmsProp 1828 loss=0.040316 err=0.040316
I 2015-05-26 11:20:28 theanets.trainer:168 RmsProp 1829 loss=0.045494 err=0.045494
I 2015-05-26 11:20:31 theanets.trainer:168 RmsProp 1830 loss=0.040196 err=0.040196
I 2015-05-26 11:20:31 theanets.trainer:168 validation 183 loss=1126.452515 err=1126.452515
I 2015-05-26 11:20:33 theanets.trainer:168 RmsProp 1831 loss=0.045783 err=0.045783
I 2015-05-26 11:20:36 theanets.trainer:168 RmsProp 1832 loss=0.038708 err=0.038708
I 2015-05-26 11:20:38 theanets.trainer:168 RmsProp 1833 loss=0.036044 err=0.036044
I 2015-05-26 11:20:40 theanets.trainer:168 RmsProp 1834 loss=0.049035 err=0.049035
I 2015-05-26 11:20:43 theanets.trainer:168 RmsProp 1835 loss=0.038345 err=0.038345
I 2015-05-26 11:20:45 theanets.trainer:168 RmsProp 1836 loss=0.042929 err=0.042929
I 2015-05-26 11:20:47 theanets.trainer:168 RmsProp 1837 loss=0.039152 err=0.039152
I 2015-05-26 11:20:50 theanets.trainer:168 RmsProp 1838 loss=0.038544 err=0.038544
I 2015-05-26 11:20:52 theanets.trainer:168 RmsProp 1839 loss=0.040456 err=0.040456
I 2015-05-26 11:20:55 theanets.trainer:168 RmsProp 1840 loss=0.042259 err=0.042259
I 2015-05-26 11:20:55 theanets.trainer:168 validation 184 loss=1125.956055 err=1125.956055
I 2015-05-26 11:20:57 theanets.trainer:168 RmsProp 1841 loss=0.039623 err=0.039623
I 2015-05-26 11:21:00 theanets.trainer:168 RmsProp 1842 loss=0.042581 err=0.042581
I 2015-05-26 11:21:02 theanets.trainer:168 RmsProp 1843 loss=0.037627 err=0.037627
I 2015-05-26 11:21:04 theanets.trainer:168 RmsProp 1844 loss=0.049711 err=0.049711
I 2015-05-26 11:21:07 theanets.trainer:168 RmsProp 1845 loss=0.037320 err=0.037320
I 2015-05-26 11:21:09 theanets.trainer:168 RmsProp 1846 loss=0.041736 err=0.041736
I 2015-05-26 11:21:11 theanets.trainer:168 RmsProp 1847 loss=0.040869 err=0.040869
I 2015-05-26 11:21:14 theanets.trainer:168 RmsProp 1848 loss=0.043350 err=0.043350
I 2015-05-26 11:21:16 theanets.trainer:168 RmsProp 1849 loss=0.038199 err=0.038199
I 2015-05-26 11:21:19 theanets.trainer:168 RmsProp 1850 loss=0.042058 err=0.042058
I 2015-05-26 11:21:19 theanets.trainer:168 validation 185 loss=1126.089233 err=1126.089233
I 2015-05-26 11:21:21 theanets.trainer:168 RmsProp 1851 loss=0.038943 err=0.038943
I 2015-05-26 11:21:24 theanets.trainer:168 RmsProp 1852 loss=0.045452 err=0.045452
I 2015-05-26 11:21:26 theanets.trainer:168 RmsProp 1853 loss=0.035703 err=0.035703
I 2015-05-26 11:21:28 theanets.trainer:168 RmsProp 1854 loss=0.042364 err=0.042364
I 2015-05-26 11:21:31 theanets.trainer:168 RmsProp 1855 loss=0.041272 err=0.041272
I 2015-05-26 11:21:33 theanets.trainer:168 RmsProp 1856 loss=0.038041 err=0.038041
I 2015-05-26 11:21:35 theanets.trainer:168 RmsProp 1857 loss=0.038341 err=0.038341
I 2015-05-26 11:21:38 theanets.trainer:168 RmsProp 1858 loss=0.047733 err=0.047733
I 2015-05-26 11:21:40 theanets.trainer:168 RmsProp 1859 loss=0.037299 err=0.037299
I 2015-05-26 11:21:43 theanets.trainer:168 RmsProp 1860 loss=0.050628 err=0.050628
I 2015-05-26 11:21:43 theanets.trainer:168 validation 186 loss=1124.190674 err=1124.190674 *
I 2015-05-26 11:21:45 theanets.trainer:168 RmsProp 1861 loss=0.039912 err=0.039912
I 2015-05-26 11:21:48 theanets.trainer:168 RmsProp 1862 loss=0.037762 err=0.037762
I 2015-05-26 11:21:50 theanets.trainer:168 RmsProp 1863 loss=0.042691 err=0.042691
I 2015-05-26 11:21:52 theanets.trainer:168 RmsProp 1864 loss=0.038985 err=0.038985
I 2015-05-26 11:21:55 theanets.trainer:168 RmsProp 1865 loss=0.038018 err=0.038018
I 2015-05-26 11:21:57 theanets.trainer:168 RmsProp 1866 loss=0.039778 err=0.039778
I 2015-05-26 11:21:59 theanets.trainer:168 RmsProp 1867 loss=0.041222 err=0.041222
I 2015-05-26 11:22:02 theanets.trainer:168 RmsProp 1868 loss=0.041618 err=0.041618
I 2015-05-26 11:22:04 theanets.trainer:168 RmsProp 1869 loss=0.037180 err=0.037180
I 2015-05-26 11:22:07 theanets.trainer:168 RmsProp 1870 loss=0.041175 err=0.041175
I 2015-05-26 11:22:07 theanets.trainer:168 validation 187 loss=1124.859497 err=1124.859497
I 2015-05-26 11:22:09 theanets.trainer:168 RmsProp 1871 loss=0.039084 err=0.039084
I 2015-05-26 11:22:12 theanets.trainer:168 RmsProp 1872 loss=0.038222 err=0.038222
I 2015-05-26 11:22:14 theanets.trainer:168 RmsProp 1873 loss=0.044506 err=0.044506
I 2015-05-26 11:22:16 theanets.trainer:168 RmsProp 1874 loss=0.040191 err=0.040191
I 2015-05-26 11:22:19 theanets.trainer:168 RmsProp 1875 loss=0.040669 err=0.040669
I 2015-05-26 11:22:21 theanets.trainer:168 RmsProp 1876 loss=0.037951 err=0.037951
I 2015-05-26 11:22:23 theanets.trainer:168 RmsProp 1877 loss=0.040623 err=0.040623
I 2015-05-26 11:22:26 theanets.trainer:168 RmsProp 1878 loss=0.037936 err=0.037936
I 2015-05-26 11:22:28 theanets.trainer:168 RmsProp 1879 loss=0.039881 err=0.039881
I 2015-05-26 11:22:31 theanets.trainer:168 RmsProp 1880 loss=0.037081 err=0.037081
I 2015-05-26 11:22:31 theanets.trainer:168 validation 188 loss=1124.034546 err=1124.034546 *
I 2015-05-26 11:22:33 theanets.trainer:168 RmsProp 1881 loss=0.046650 err=0.046650
I 2015-05-26 11:22:35 theanets.trainer:168 RmsProp 1882 loss=0.041834 err=0.041834
I 2015-05-26 11:22:38 theanets.trainer:168 RmsProp 1883 loss=0.035591 err=0.035591
I 2015-05-26 11:22:40 theanets.trainer:168 RmsProp 1884 loss=0.039851 err=0.039851
I 2015-05-26 11:22:43 theanets.trainer:168 RmsProp 1885 loss=0.039946 err=0.039946
I 2015-05-26 11:22:45 theanets.trainer:168 RmsProp 1886 loss=0.038821 err=0.038821
I 2015-05-26 11:22:47 theanets.trainer:168 RmsProp 1887 loss=0.040476 err=0.040476
I 2015-05-26 11:22:50 theanets.trainer:168 RmsProp 1888 loss=0.033375 err=0.033375
I 2015-05-26 11:22:52 theanets.trainer:168 RmsProp 1889 loss=0.046787 err=0.046787
I 2015-05-26 11:22:55 theanets.trainer:168 RmsProp 1890 loss=0.038167 err=0.038167
I 2015-05-26 11:22:55 theanets.trainer:168 validation 189 loss=1124.138062 err=1124.138062
I 2015-05-26 11:22:57 theanets.trainer:168 RmsProp 1891 loss=0.041375 err=0.041375
I 2015-05-26 11:22:59 theanets.trainer:168 RmsProp 1892 loss=0.034421 err=0.034421
I 2015-05-26 11:23:02 theanets.trainer:168 RmsProp 1893 loss=0.047230 err=0.047230
I 2015-05-26 11:23:04 theanets.trainer:168 RmsProp 1894 loss=0.040518 err=0.040518
I 2015-05-26 11:23:07 theanets.trainer:168 RmsProp 1895 loss=0.038050 err=0.038050
I 2015-05-26 11:23:09 theanets.trainer:168 RmsProp 1896 loss=0.038974 err=0.038974
I 2015-05-26 11:23:11 theanets.trainer:168 RmsProp 1897 loss=0.038528 err=0.038528
I 2015-05-26 11:23:14 theanets.trainer:168 RmsProp 1898 loss=0.046046 err=0.046046
I 2015-05-26 11:23:16 theanets.trainer:168 RmsProp 1899 loss=0.042276 err=0.042276
I 2015-05-26 11:23:18 theanets.trainer:168 RmsProp 1900 loss=0.035658 err=0.035658
I 2015-05-26 11:23:19 theanets.trainer:168 validation 190 loss=1123.723267 err=1123.723267 *
I 2015-05-26 11:23:21 theanets.trainer:168 RmsProp 1901 loss=0.037905 err=0.037905
I 2015-05-26 11:23:23 theanets.trainer:168 RmsProp 1902 loss=0.040330 err=0.040330
I 2015-05-26 11:23:26 theanets.trainer:168 RmsProp 1903 loss=0.042757 err=0.042757
I 2015-05-26 11:23:28 theanets.trainer:168 RmsProp 1904 loss=0.041500 err=0.041500
I 2015-05-26 11:23:31 theanets.trainer:168 RmsProp 1905 loss=0.041460 err=0.041460
I 2015-05-26 11:23:33 theanets.trainer:168 RmsProp 1906 loss=0.038808 err=0.038808
I 2015-05-26 11:23:35 theanets.trainer:168 RmsProp 1907 loss=0.036861 err=0.036861
I 2015-05-26 11:23:38 theanets.trainer:168 RmsProp 1908 loss=0.040037 err=0.040037
I 2015-05-26 11:23:40 theanets.trainer:168 RmsProp 1909 loss=0.042110 err=0.042110
I 2015-05-26 11:23:42 theanets.trainer:168 RmsProp 1910 loss=0.040820 err=0.040820
I 2015-05-26 11:23:43 theanets.trainer:168 validation 191 loss=1122.608765 err=1122.608765 *
I 2015-05-26 11:23:45 theanets.trainer:168 RmsProp 1911 loss=0.039047 err=0.039047
I 2015-05-26 11:23:47 theanets.trainer:168 RmsProp 1912 loss=0.034904 err=0.034904
I 2015-05-26 11:23:50 theanets.trainer:168 RmsProp 1913 loss=0.046574 err=0.046574
I 2015-05-26 11:23:52 theanets.trainer:168 RmsProp 1914 loss=0.037093 err=0.037093
I 2015-05-26 11:23:54 theanets.trainer:168 RmsProp 1915 loss=0.038851 err=0.038851
I 2015-05-26 11:23:57 theanets.trainer:168 RmsProp 1916 loss=0.038448 err=0.038448
I 2015-05-26 11:23:59 theanets.trainer:168 RmsProp 1917 loss=0.038456 err=0.038456
I 2015-05-26 11:24:02 theanets.trainer:168 RmsProp 1918 loss=0.036310 err=0.036310
I 2015-05-26 11:24:04 theanets.trainer:168 RmsProp 1919 loss=0.041207 err=0.041207
I 2015-05-26 11:24:06 theanets.trainer:168 RmsProp 1920 loss=0.038679 err=0.038679
I 2015-05-26 11:24:07 theanets.trainer:168 validation 192 loss=1122.628174 err=1122.628174
I 2015-05-26 11:24:09 theanets.trainer:168 RmsProp 1921 loss=0.041689 err=0.041689
I 2015-05-26 11:24:11 theanets.trainer:168 RmsProp 1922 loss=0.039909 err=0.039909
I 2015-05-26 11:24:14 theanets.trainer:168 RmsProp 1923 loss=0.038930 err=0.038930
I 2015-05-26 11:24:16 theanets.trainer:168 RmsProp 1924 loss=0.038709 err=0.038709
I 2015-05-26 11:24:18 theanets.trainer:168 RmsProp 1925 loss=0.036473 err=0.036473
I 2015-05-26 11:24:21 theanets.trainer:168 RmsProp 1926 loss=0.041192 err=0.041192
I 2015-05-26 11:24:23 theanets.trainer:168 RmsProp 1927 loss=0.037189 err=0.037189
I 2015-05-26 11:24:26 theanets.trainer:168 RmsProp 1928 loss=0.042449 err=0.042449
I 2015-05-26 11:24:28 theanets.trainer:168 RmsProp 1929 loss=0.043046 err=0.043046
I 2015-05-26 11:24:30 theanets.trainer:168 RmsProp 1930 loss=0.038924 err=0.038924
I 2015-05-26 11:24:31 theanets.trainer:168 validation 193 loss=1122.162231 err=1122.162231 *
I 2015-05-26 11:24:33 theanets.trainer:168 RmsProp 1931 loss=0.038597 err=0.038597
I 2015-05-26 11:24:35 theanets.trainer:168 RmsProp 1932 loss=0.035904 err=0.035904
I 2015-05-26 11:24:38 theanets.trainer:168 RmsProp 1933 loss=0.038830 err=0.038830
I 2015-05-26 11:24:40 theanets.trainer:168 RmsProp 1934 loss=0.037316 err=0.037316
I 2015-05-26 11:24:42 theanets.trainer:168 RmsProp 1935 loss=0.041538 err=0.041538
I 2015-05-26 11:24:45 theanets.trainer:168 RmsProp 1936 loss=0.043843 err=0.043843
I 2015-05-26 11:24:47 theanets.trainer:168 RmsProp 1937 loss=0.037738 err=0.037738
I 2015-05-26 11:24:50 theanets.trainer:168 RmsProp 1938 loss=0.043455 err=0.043455
I 2015-05-26 11:24:52 theanets.trainer:168 RmsProp 1939 loss=0.032687 err=0.032687
I 2015-05-26 11:24:54 theanets.trainer:168 RmsProp 1940 loss=0.045799 err=0.045799
I 2015-05-26 11:24:55 theanets.trainer:168 validation 194 loss=1122.038452 err=1122.038452 *
I 2015-05-26 11:24:57 theanets.trainer:168 RmsProp 1941 loss=0.035503 err=0.035503
I 2015-05-26 11:24:59 theanets.trainer:168 RmsProp 1942 loss=0.038790 err=0.038790
I 2015-05-26 11:25:02 theanets.trainer:168 RmsProp 1943 loss=0.034641 err=0.034641
I 2015-05-26 11:25:04 theanets.trainer:168 RmsProp 1944 loss=0.055431 err=0.055431
I 2015-05-26 11:25:06 theanets.trainer:168 RmsProp 1945 loss=0.038529 err=0.038529
I 2015-05-26 11:25:09 theanets.trainer:168 RmsProp 1946 loss=0.035612 err=0.035612
I 2015-05-26 11:25:11 theanets.trainer:168 RmsProp 1947 loss=0.036846 err=0.036846
I 2015-05-26 11:25:14 theanets.trainer:168 RmsProp 1948 loss=0.041639 err=0.041639
I 2015-05-26 11:25:16 theanets.trainer:168 RmsProp 1949 loss=0.036005 err=0.036005
I 2015-05-26 11:25:18 theanets.trainer:168 RmsProp 1950 loss=0.040944 err=0.040944
I 2015-05-26 11:25:19 theanets.trainer:168 validation 195 loss=1119.783813 err=1119.783813 *
I 2015-05-26 11:25:21 theanets.trainer:168 RmsProp 1951 loss=0.040246 err=0.040246
I 2015-05-26 11:25:23 theanets.trainer:168 RmsProp 1952 loss=0.037084 err=0.037084
I 2015-05-26 11:25:26 theanets.trainer:168 RmsProp 1953 loss=0.038197 err=0.038197
I 2015-05-26 11:25:28 theanets.trainer:168 RmsProp 1954 loss=0.041252 err=0.041252
I 2015-05-26 11:25:30 theanets.trainer:168 RmsProp 1955 loss=0.039409 err=0.039409
I 2015-05-26 11:25:33 theanets.trainer:168 RmsProp 1956 loss=0.037401 err=0.037401
I 2015-05-26 11:25:35 theanets.trainer:168 RmsProp 1957 loss=0.034520 err=0.034520
I 2015-05-26 11:25:38 theanets.trainer:168 RmsProp 1958 loss=0.046824 err=0.046824
I 2015-05-26 11:25:40 theanets.trainer:168 RmsProp 1959 loss=0.039541 err=0.039541
I 2015-05-26 11:25:42 theanets.trainer:168 RmsProp 1960 loss=0.033481 err=0.033481
I 2015-05-26 11:25:42 theanets.trainer:168 validation 196 loss=1120.263672 err=1120.263672
I 2015-05-26 11:25:45 theanets.trainer:168 RmsProp 1961 loss=0.050423 err=0.050423
I 2015-05-26 11:25:47 theanets.trainer:168 RmsProp 1962 loss=0.039391 err=0.039391
I 2015-05-26 11:25:50 theanets.trainer:168 RmsProp 1963 loss=0.034994 err=0.034994
I 2015-05-26 11:25:52 theanets.trainer:168 RmsProp 1964 loss=0.037677 err=0.037677
I 2015-05-26 11:25:54 theanets.trainer:168 RmsProp 1965 loss=0.041673 err=0.041673
I 2015-05-26 11:25:57 theanets.trainer:168 RmsProp 1966 loss=0.036727 err=0.036727
I 2015-05-26 11:25:59 theanets.trainer:168 RmsProp 1967 loss=0.039012 err=0.039012
I 2015-05-26 11:26:01 theanets.trainer:168 RmsProp 1968 loss=0.035290 err=0.035290
I 2015-05-26 11:26:04 theanets.trainer:168 RmsProp 1969 loss=0.039419 err=0.039419
I 2015-05-26 11:26:06 theanets.trainer:168 RmsProp 1970 loss=0.034739 err=0.034739
I 2015-05-26 11:26:06 theanets.trainer:168 validation 197 loss=1119.065796 err=1119.065796 *
I 2015-05-26 11:26:09 theanets.trainer:168 RmsProp 1971 loss=0.042261 err=0.042261
I 2015-05-26 11:26:11 theanets.trainer:168 RmsProp 1972 loss=0.040324 err=0.040324
I 2015-05-26 11:26:14 theanets.trainer:168 RmsProp 1973 loss=0.036640 err=0.036640
I 2015-05-26 11:26:16 theanets.trainer:168 RmsProp 1974 loss=0.042760 err=0.042760
I 2015-05-26 11:26:18 theanets.trainer:168 RmsProp 1975 loss=0.038760 err=0.038760
I 2015-05-26 11:26:21 theanets.trainer:168 RmsProp 1976 loss=0.037790 err=0.037790
I 2015-05-26 11:26:23 theanets.trainer:168 RmsProp 1977 loss=0.037102 err=0.037102
I 2015-05-26 11:26:25 theanets.trainer:168 RmsProp 1978 loss=0.041705 err=0.041705
I 2015-05-26 11:26:28 theanets.trainer:168 RmsProp 1979 loss=0.035164 err=0.035164
I 2015-05-26 11:26:30 theanets.trainer:168 RmsProp 1980 loss=0.038363 err=0.038363
I 2015-05-26 11:26:30 theanets.trainer:168 validation 198 loss=1119.813232 err=1119.813232
I 2015-05-26 11:26:33 theanets.trainer:168 RmsProp 1981 loss=0.038973 err=0.038973
I 2015-05-26 11:26:35 theanets.trainer:168 RmsProp 1982 loss=0.035939 err=0.035939
I 2015-05-26 11:26:38 theanets.trainer:168 RmsProp 1983 loss=0.042429 err=0.042429
I 2015-05-26 11:26:40 theanets.trainer:168 RmsProp 1984 loss=0.037611 err=0.037611
I 2015-05-26 11:26:42 theanets.trainer:168 RmsProp 1985 loss=0.040658 err=0.040658
I 2015-05-26 11:26:45 theanets.trainer:168 RmsProp 1986 loss=0.033832 err=0.033832
I 2015-05-26 11:26:47 theanets.trainer:168 RmsProp 1987 loss=0.041316 err=0.041316
I 2015-05-26 11:26:49 theanets.trainer:168 RmsProp 1988 loss=0.036306 err=0.036306
I 2015-05-26 11:26:52 theanets.trainer:168 RmsProp 1989 loss=0.039226 err=0.039226
I 2015-05-26 11:26:54 theanets.trainer:168 RmsProp 1990 loss=0.035608 err=0.035608
I 2015-05-26 11:26:54 theanets.trainer:168 validation 199 loss=1118.803101 err=1118.803101 *
I 2015-05-26 11:26:57 theanets.trainer:168 RmsProp 1991 loss=0.043330 err=0.043330
I 2015-05-26 11:26:59 theanets.trainer:168 RmsProp 1992 loss=0.032546 err=0.032546
I 2015-05-26 11:27:02 theanets.trainer:168 RmsProp 1993 loss=0.044561 err=0.044561
I 2015-05-26 11:27:04 theanets.trainer:168 RmsProp 1994 loss=0.043866 err=0.043866
I 2015-05-26 11:27:06 theanets.trainer:168 RmsProp 1995 loss=0.037260 err=0.037260
I 2015-05-26 11:27:09 theanets.trainer:168 RmsProp 1996 loss=0.035267 err=0.035267
I 2015-05-26 11:27:11 theanets.trainer:168 RmsProp 1997 loss=0.039535 err=0.039535
I 2015-05-26 11:27:13 theanets.trainer:168 RmsProp 1998 loss=0.033453 err=0.033453
I 2015-05-26 11:27:16 theanets.trainer:168 RmsProp 1999 loss=0.047892 err=0.047892
I 2015-05-26 11:27:18 theanets.trainer:168 RmsProp 2000 loss=0.035680 err=0.035680
I 2015-05-26 11:27:18 theanets.trainer:168 validation 200 loss=1118.266479 err=1118.266479 *
I 2015-05-26 11:27:21 theanets.trainer:168 RmsProp 2001 loss=0.035230 err=0.035230
I 2015-05-26 11:27:23 theanets.trainer:168 RmsProp 2002 loss=0.037817 err=0.037817
I 2015-05-26 11:27:26 theanets.trainer:168 RmsProp 2003 loss=0.039874 err=0.039874
I 2015-05-26 11:27:28 theanets.trainer:168 RmsProp 2004 loss=0.036711 err=0.036711
I 2015-05-26 11:27:30 theanets.trainer:168 RmsProp 2005 loss=0.037899 err=0.037899
I 2015-05-26 11:27:33 theanets.trainer:168 RmsProp 2006 loss=0.037143 err=0.037143
I 2015-05-26 11:27:35 theanets.trainer:168 RmsProp 2007 loss=0.037669 err=0.037669
I 2015-05-26 11:27:37 theanets.trainer:168 RmsProp 2008 loss=0.042468 err=0.042468
I 2015-05-26 11:27:40 theanets.trainer:168 RmsProp 2009 loss=0.040157 err=0.040157
I 2015-05-26 11:27:42 theanets.trainer:168 RmsProp 2010 loss=0.034776 err=0.034776
I 2015-05-26 11:27:42 theanets.trainer:168 validation 201 loss=1116.824707 err=1116.824707 *
I 2015-05-26 11:27:45 theanets.trainer:168 RmsProp 2011 loss=0.032958 err=0.032958
I 2015-05-26 11:27:47 theanets.trainer:168 RmsProp 2012 loss=0.040551 err=0.040551
I 2015-05-26 11:27:50 theanets.trainer:168 RmsProp 2013 loss=0.044375 err=0.044375
I 2015-05-26 11:27:52 theanets.trainer:168 RmsProp 2014 loss=0.037067 err=0.037067
I 2015-05-26 11:27:54 theanets.trainer:168 RmsProp 2015 loss=0.036400 err=0.036400
I 2015-05-26 11:27:57 theanets.trainer:168 RmsProp 2016 loss=0.035625 err=0.035625
I 2015-05-26 11:27:59 theanets.trainer:168 RmsProp 2017 loss=0.037086 err=0.037086
I 2015-05-26 11:28:01 theanets.trainer:168 RmsProp 2018 loss=0.036939 err=0.036939
I 2015-05-26 11:28:04 theanets.trainer:168 RmsProp 2019 loss=0.041505 err=0.041505
I 2015-05-26 11:28:06 theanets.trainer:168 RmsProp 2020 loss=0.037734 err=0.037734
I 2015-05-26 11:28:06 theanets.trainer:168 validation 202 loss=1118.140503 err=1118.140503
I 2015-05-26 11:28:09 theanets.trainer:168 RmsProp 2021 loss=0.038687 err=0.038687
I 2015-05-26 11:28:11 theanets.trainer:168 RmsProp 2022 loss=0.034044 err=0.034044
I 2015-05-26 11:28:14 theanets.trainer:168 RmsProp 2023 loss=0.046168 err=0.046168
I 2015-05-26 11:28:16 theanets.trainer:168 RmsProp 2024 loss=0.043370 err=0.043370
I 2015-05-26 11:28:18 theanets.trainer:168 RmsProp 2025 loss=0.034835 err=0.034835
I 2015-05-26 11:28:21 theanets.trainer:168 RmsProp 2026 loss=0.037804 err=0.037804
I 2015-05-26 11:28:23 theanets.trainer:168 RmsProp 2027 loss=0.034556 err=0.034556
I 2015-05-26 11:28:25 theanets.trainer:168 RmsProp 2028 loss=0.037348 err=0.037348
I 2015-05-26 11:28:28 theanets.trainer:168 RmsProp 2029 loss=0.037390 err=0.037390
I 2015-05-26 11:28:30 theanets.trainer:168 RmsProp 2030 loss=0.037849 err=0.037849
I 2015-05-26 11:28:30 theanets.trainer:168 validation 203 loss=1117.055542 err=1117.055542
I 2015-05-26 11:28:33 theanets.trainer:168 RmsProp 2031 loss=0.038319 err=0.038319
I 2015-05-26 11:28:35 theanets.trainer:168 RmsProp 2032 loss=0.041924 err=0.041924
I 2015-05-26 11:28:37 theanets.trainer:168 RmsProp 2033 loss=0.035227 err=0.035227
I 2015-05-26 11:28:40 theanets.trainer:168 RmsProp 2034 loss=0.039048 err=0.039048
I 2015-05-26 11:28:42 theanets.trainer:168 RmsProp 2035 loss=0.035108 err=0.035108
I 2015-05-26 11:28:45 theanets.trainer:168 RmsProp 2036 loss=0.043692 err=0.043692
I 2015-05-26 11:28:47 theanets.trainer:168 RmsProp 2037 loss=0.034647 err=0.034647
I 2015-05-26 11:28:49 theanets.trainer:168 RmsProp 2038 loss=0.043380 err=0.043380
I 2015-05-26 11:28:52 theanets.trainer:168 RmsProp 2039 loss=0.037089 err=0.037089
I 2015-05-26 11:28:54 theanets.trainer:168 RmsProp 2040 loss=0.035571 err=0.035571
I 2015-05-26 11:28:54 theanets.trainer:168 validation 204 loss=1116.955933 err=1116.955933
I 2015-05-26 11:28:57 theanets.trainer:168 RmsProp 2041 loss=0.033286 err=0.033286
I 2015-05-26 11:28:59 theanets.trainer:168 RmsProp 2042 loss=0.040874 err=0.040874
I 2015-05-26 11:29:01 theanets.trainer:168 RmsProp 2043 loss=0.035301 err=0.035301
I 2015-05-26 11:29:04 theanets.trainer:168 RmsProp 2044 loss=0.039384 err=0.039384
I 2015-05-26 11:29:06 theanets.trainer:168 RmsProp 2045 loss=0.040092 err=0.040092
I 2015-05-26 11:29:09 theanets.trainer:168 RmsProp 2046 loss=0.043907 err=0.043907
I 2015-05-26 11:29:11 theanets.trainer:168 RmsProp 2047 loss=0.038475 err=0.038475
I 2015-05-26 11:29:13 theanets.trainer:168 RmsProp 2048 loss=0.038805 err=0.038805
I 2015-05-26 11:29:16 theanets.trainer:168 RmsProp 2049 loss=0.035410 err=0.035410
I 2015-05-26 11:29:18 theanets.trainer:168 RmsProp 2050 loss=0.037772 err=0.037772
I 2015-05-26 11:29:18 theanets.trainer:168 validation 205 loss=1116.248047 err=1116.248047 *
I 2015-05-26 11:29:21 theanets.trainer:168 RmsProp 2051 loss=0.036332 err=0.036332
I 2015-05-26 11:29:23 theanets.trainer:168 RmsProp 2052 loss=0.040072 err=0.040072
I 2015-05-26 11:29:25 theanets.trainer:168 RmsProp 2053 loss=0.036135 err=0.036135
I 2015-05-26 11:29:28 theanets.trainer:168 RmsProp 2054 loss=0.037562 err=0.037562
I 2015-05-26 11:29:30 theanets.trainer:168 RmsProp 2055 loss=0.040479 err=0.040479
I 2015-05-26 11:29:33 theanets.trainer:168 RmsProp 2056 loss=0.040860 err=0.040860
I 2015-05-26 11:29:35 theanets.trainer:168 RmsProp 2057 loss=0.037786 err=0.037786
I 2015-05-26 11:29:37 theanets.trainer:168 RmsProp 2058 loss=0.038508 err=0.038508
I 2015-05-26 11:29:40 theanets.trainer:168 RmsProp 2059 loss=0.034792 err=0.034792
I 2015-05-26 11:29:42 theanets.trainer:168 RmsProp 2060 loss=0.041753 err=0.041753
I 2015-05-26 11:29:42 theanets.trainer:168 validation 206 loss=1116.474365 err=1116.474365
I 2015-05-26 11:29:45 theanets.trainer:168 RmsProp 2061 loss=0.037722 err=0.037722
I 2015-05-26 11:29:47 theanets.trainer:168 RmsProp 2062 loss=0.036941 err=0.036941
I 2015-05-26 11:29:49 theanets.trainer:168 RmsProp 2063 loss=0.040321 err=0.040321
I 2015-05-26 11:29:52 theanets.trainer:168 RmsProp 2064 loss=0.033588 err=0.033588
I 2015-05-26 11:29:54 theanets.trainer:168 RmsProp 2065 loss=0.038709 err=0.038709
I 2015-05-26 11:29:57 theanets.trainer:168 RmsProp 2066 loss=0.038476 err=0.038476
I 2015-05-26 11:29:59 theanets.trainer:168 RmsProp 2067 loss=0.039087 err=0.039087
I 2015-05-26 11:30:01 theanets.trainer:168 RmsProp 2068 loss=0.042691 err=0.042691
I 2015-05-26 11:30:04 theanets.trainer:168 RmsProp 2069 loss=0.035937 err=0.035937
I 2015-05-26 11:30:06 theanets.trainer:168 RmsProp 2070 loss=0.036290 err=0.036290
I 2015-05-26 11:30:06 theanets.trainer:168 validation 207 loss=1115.089111 err=1115.089111 *
I 2015-05-26 11:30:09 theanets.trainer:168 RmsProp 2071 loss=0.035287 err=0.035287
I 2015-05-26 11:30:11 theanets.trainer:168 RmsProp 2072 loss=0.040013 err=0.040013
I 2015-05-26 11:30:13 theanets.trainer:168 RmsProp 2073 loss=0.041954 err=0.041954
I 2015-05-26 11:30:16 theanets.trainer:168 RmsProp 2074 loss=0.032879 err=0.032879
I 2015-05-26 11:30:18 theanets.trainer:168 RmsProp 2075 loss=0.035433 err=0.035433
I 2015-05-26 11:30:21 theanets.trainer:168 RmsProp 2076 loss=0.039107 err=0.039107
I 2015-05-26 11:30:23 theanets.trainer:168 RmsProp 2077 loss=0.036899 err=0.036899
I 2015-05-26 11:30:25 theanets.trainer:168 RmsProp 2078 loss=0.036277 err=0.036277
I 2015-05-26 11:30:28 theanets.trainer:168 RmsProp 2079 loss=0.036142 err=0.036142
I 2015-05-26 11:30:30 theanets.trainer:168 RmsProp 2080 loss=0.036146 err=0.036146
I 2015-05-26 11:30:30 theanets.trainer:168 validation 208 loss=1115.370483 err=1115.370483
I 2015-05-26 11:30:33 theanets.trainer:168 RmsProp 2081 loss=0.034381 err=0.034381
I 2015-05-26 11:30:35 theanets.trainer:168 RmsProp 2082 loss=0.032318 err=0.032318
I 2015-05-26 11:30:37 theanets.trainer:168 RmsProp 2083 loss=0.045150 err=0.045150
I 2015-05-26 11:30:40 theanets.trainer:168 RmsProp 2084 loss=0.034613 err=0.034613
I 2015-05-26 11:30:42 theanets.trainer:168 RmsProp 2085 loss=0.038777 err=0.038777
I 2015-05-26 11:30:45 theanets.trainer:168 RmsProp 2086 loss=0.035223 err=0.035223
I 2015-05-26 11:30:47 theanets.trainer:168 RmsProp 2087 loss=0.035680 err=0.035680
I 2015-05-26 11:30:49 theanets.trainer:168 RmsProp 2088 loss=0.032986 err=0.032986
I 2015-05-26 11:30:52 theanets.trainer:168 RmsProp 2089 loss=0.046677 err=0.046677
I 2015-05-26 11:30:54 theanets.trainer:168 RmsProp 2090 loss=0.037094 err=0.037094
I 2015-05-26 11:30:54 theanets.trainer:168 validation 209 loss=1114.793335 err=1114.793335 *
I 2015-05-26 11:30:57 theanets.trainer:168 RmsProp 2091 loss=0.035376 err=0.035376
I 2015-05-26 11:30:59 theanets.trainer:168 RmsProp 2092 loss=0.035811 err=0.035811
I 2015-05-26 11:31:01 theanets.trainer:168 RmsProp 2093 loss=0.036365 err=0.036365
I 2015-05-26 11:31:04 theanets.trainer:168 RmsProp 2094 loss=0.038879 err=0.038879
I 2015-05-26 11:31:06 theanets.trainer:168 RmsProp 2095 loss=0.035746 err=0.035746
I 2015-05-26 11:31:09 theanets.trainer:168 RmsProp 2096 loss=0.040894 err=0.040894
I 2015-05-26 11:31:11 theanets.trainer:168 RmsProp 2097 loss=0.033480 err=0.033480
I 2015-05-26 11:31:13 theanets.trainer:168 RmsProp 2098 loss=0.041856 err=0.041856
I 2015-05-26 11:31:16 theanets.trainer:168 RmsProp 2099 loss=0.032735 err=0.032735
I 2015-05-26 11:31:18 theanets.trainer:168 RmsProp 2100 loss=0.035002 err=0.035002
I 2015-05-26 11:31:18 theanets.trainer:168 validation 210 loss=1115.223389 err=1115.223389
I 2015-05-26 11:31:21 theanets.trainer:168 RmsProp 2101 loss=0.035301 err=0.035301
I 2015-05-26 11:31:23 theanets.trainer:168 RmsProp 2102 loss=0.035940 err=0.035940
I 2015-05-26 11:31:25 theanets.trainer:168 RmsProp 2103 loss=0.038349 err=0.038349
I 2015-05-26 11:31:28 theanets.trainer:168 RmsProp 2104 loss=0.035181 err=0.035181
I 2015-05-26 11:31:30 theanets.trainer:168 RmsProp 2105 loss=0.040031 err=0.040031
I 2015-05-26 11:31:33 theanets.trainer:168 RmsProp 2106 loss=0.033791 err=0.033791
I 2015-05-26 11:31:35 theanets.trainer:168 RmsProp 2107 loss=0.037228 err=0.037228
I 2015-05-26 11:31:37 theanets.trainer:168 RmsProp 2108 loss=0.037690 err=0.037690
I 2015-05-26 11:31:40 theanets.trainer:168 RmsProp 2109 loss=0.034003 err=0.034003
I 2015-05-26 11:31:42 theanets.trainer:168 RmsProp 2110 loss=0.036937 err=0.036937
I 2015-05-26 11:31:42 theanets.trainer:168 validation 211 loss=1113.509766 err=1113.509766 *
I 2015-05-26 11:31:45 theanets.trainer:168 RmsProp 2111 loss=0.037169 err=0.037169
I 2015-05-26 11:31:47 theanets.trainer:168 RmsProp 2112 loss=0.036378 err=0.036378
I 2015-05-26 11:31:49 theanets.trainer:168 RmsProp 2113 loss=0.038322 err=0.038322
I 2015-05-26 11:31:52 theanets.trainer:168 RmsProp 2114 loss=0.034391 err=0.034391
I 2015-05-26 11:31:54 theanets.trainer:168 RmsProp 2115 loss=0.043297 err=0.043297
I 2015-05-26 11:31:57 theanets.trainer:168 RmsProp 2116 loss=0.036235 err=0.036235
I 2015-05-26 11:31:59 theanets.trainer:168 RmsProp 2117 loss=0.032041 err=0.032041
I 2015-05-26 11:32:01 theanets.trainer:168 RmsProp 2118 loss=0.046913 err=0.046913
I 2015-05-26 11:32:04 theanets.trainer:168 RmsProp 2119 loss=0.037907 err=0.037907
I 2015-05-26 11:32:06 theanets.trainer:168 RmsProp 2120 loss=0.035491 err=0.035491
I 2015-05-26 11:32:06 theanets.trainer:168 validation 212 loss=1112.609863 err=1112.609863 *
I 2015-05-26 11:32:09 theanets.trainer:168 RmsProp 2121 loss=0.034305 err=0.034305
I 2015-05-26 11:32:11 theanets.trainer:168 RmsProp 2122 loss=0.034954 err=0.034954
I 2015-05-26 11:32:13 theanets.trainer:168 RmsProp 2123 loss=0.038800 err=0.038800
I 2015-05-26 11:32:16 theanets.trainer:168 RmsProp 2124 loss=0.036235 err=0.036235
I 2015-05-26 11:32:18 theanets.trainer:168 RmsProp 2125 loss=0.032715 err=0.032715
I 2015-05-26 11:32:21 theanets.trainer:168 RmsProp 2126 loss=0.043431 err=0.043431
I 2015-05-26 11:32:23 theanets.trainer:168 RmsProp 2127 loss=0.033824 err=0.033824
I 2015-05-26 11:32:25 theanets.trainer:168 RmsProp 2128 loss=0.034736 err=0.034736
I 2015-05-26 11:32:28 theanets.trainer:168 RmsProp 2129 loss=0.033885 err=0.033885
I 2015-05-26 11:32:30 theanets.trainer:168 RmsProp 2130 loss=0.037393 err=0.037393
I 2015-05-26 11:32:30 theanets.trainer:168 validation 213 loss=1113.163208 err=1113.163208
I 2015-05-26 11:32:33 theanets.trainer:168 RmsProp 2131 loss=0.040059 err=0.040059
I 2015-05-26 11:32:35 theanets.trainer:168 RmsProp 2132 loss=0.040531 err=0.040531
I 2015-05-26 11:32:37 theanets.trainer:168 RmsProp 2133 loss=0.033831 err=0.033831
I 2015-05-26 11:32:40 theanets.trainer:168 RmsProp 2134 loss=0.032745 err=0.032745
I 2015-05-26 11:32:42 theanets.trainer:168 RmsProp 2135 loss=0.038378 err=0.038378
I 2015-05-26 11:32:45 theanets.trainer:168 RmsProp 2136 loss=0.033760 err=0.033760
I 2015-05-26 11:32:47 theanets.trainer:168 RmsProp 2137 loss=0.039250 err=0.039250
I 2015-05-26 11:32:49 theanets.trainer:168 RmsProp 2138 loss=0.035349 err=0.035349
I 2015-05-26 11:32:52 theanets.trainer:168 RmsProp 2139 loss=0.034421 err=0.034421
I 2015-05-26 11:32:54 theanets.trainer:168 RmsProp 2140 loss=0.036550 err=0.036550
I 2015-05-26 11:32:54 theanets.trainer:168 validation 214 loss=1113.385742 err=1113.385742
I 2015-05-26 11:32:57 theanets.trainer:168 RmsProp 2141 loss=0.034862 err=0.034862
I 2015-05-26 11:32:59 theanets.trainer:168 RmsProp 2142 loss=0.037478 err=0.037478
I 2015-05-26 11:33:01 theanets.trainer:168 RmsProp 2143 loss=0.036619 err=0.036619
I 2015-05-26 11:33:04 theanets.trainer:168 RmsProp 2144 loss=0.033798 err=0.033798
I 2015-05-26 11:33:06 theanets.trainer:168 RmsProp 2145 loss=0.036811 err=0.036811
I 2015-05-26 11:33:09 theanets.trainer:168 RmsProp 2146 loss=0.038278 err=0.038278
I 2015-05-26 11:33:11 theanets.trainer:168 RmsProp 2147 loss=0.042932 err=0.042932
I 2015-05-26 11:33:13 theanets.trainer:168 RmsProp 2148 loss=0.034820 err=0.034820
I 2015-05-26 11:33:16 theanets.trainer:168 RmsProp 2149 loss=0.034809 err=0.034809
I 2015-05-26 11:33:18 theanets.trainer:168 RmsProp 2150 loss=0.033268 err=0.033268
I 2015-05-26 11:33:18 theanets.trainer:168 validation 215 loss=1112.355591 err=1112.355591 *
I 2015-05-26 11:33:21 theanets.trainer:168 RmsProp 2151 loss=0.034991 err=0.034991
I 2015-05-26 11:33:23 theanets.trainer:168 RmsProp 2152 loss=0.032061 err=0.032061
I 2015-05-26 11:33:25 theanets.trainer:168 RmsProp 2153 loss=0.046337 err=0.046337
I 2015-05-26 11:33:28 theanets.trainer:168 RmsProp 2154 loss=0.037494 err=0.037494
I 2015-05-26 11:33:30 theanets.trainer:168 RmsProp 2155 loss=0.037805 err=0.037805
I 2015-05-26 11:33:32 theanets.trainer:168 RmsProp 2156 loss=0.037954 err=0.037954
I 2015-05-26 11:33:35 theanets.trainer:168 RmsProp 2157 loss=0.031536 err=0.031536
I 2015-05-26 11:33:37 theanets.trainer:168 RmsProp 2158 loss=0.034491 err=0.034491
I 2015-05-26 11:33:40 theanets.trainer:168 RmsProp 2159 loss=0.035129 err=0.035129
I 2015-05-26 11:33:42 theanets.trainer:168 RmsProp 2160 loss=0.037724 err=0.037724
I 2015-05-26 11:33:42 theanets.trainer:168 validation 216 loss=1112.168335 err=1112.168335 *
I 2015-05-26 11:33:45 theanets.trainer:168 RmsProp 2161 loss=0.032551 err=0.032551
I 2015-05-26 11:33:47 theanets.trainer:168 RmsProp 2162 loss=0.038895 err=0.038895
I 2015-05-26 11:33:49 theanets.trainer:168 RmsProp 2163 loss=0.033525 err=0.033525
I 2015-05-26 11:33:52 theanets.trainer:168 RmsProp 2164 loss=0.039226 err=0.039226
I 2015-05-26 11:33:54 theanets.trainer:168 RmsProp 2165 loss=0.034712 err=0.034712
I 2015-05-26 11:33:56 theanets.trainer:168 RmsProp 2166 loss=0.034253 err=0.034253
I 2015-05-26 11:33:59 theanets.trainer:168 RmsProp 2167 loss=0.034150 err=0.034150
I 2015-05-26 11:34:01 theanets.trainer:168 RmsProp 2168 loss=0.037842 err=0.037842
I 2015-05-26 11:34:04 theanets.trainer:168 RmsProp 2169 loss=0.035907 err=0.035907
I 2015-05-26 11:34:06 theanets.trainer:168 RmsProp 2170 loss=0.034817 err=0.034817
I 2015-05-26 11:34:06 theanets.trainer:168 validation 217 loss=1111.128296 err=1111.128296 *
I 2015-05-26 11:34:09 theanets.trainer:168 RmsProp 2171 loss=0.038451 err=0.038451
I 2015-05-26 11:34:11 theanets.trainer:168 RmsProp 2172 loss=0.033305 err=0.033305
I 2015-05-26 11:34:13 theanets.trainer:168 RmsProp 2173 loss=0.033921 err=0.033921
I 2015-05-26 11:34:16 theanets.trainer:168 RmsProp 2174 loss=0.032854 err=0.032854
I 2015-05-26 11:34:18 theanets.trainer:168 RmsProp 2175 loss=0.039524 err=0.039524
I 2015-05-26 11:34:20 theanets.trainer:168 RmsProp 2176 loss=0.035018 err=0.035018
I 2015-05-26 11:34:23 theanets.trainer:168 RmsProp 2177 loss=0.036989 err=0.036989
I 2015-05-26 11:34:25 theanets.trainer:168 RmsProp 2178 loss=0.032898 err=0.032898
I 2015-05-26 11:34:28 theanets.trainer:168 RmsProp 2179 loss=0.034969 err=0.034969
I 2015-05-26 11:34:30 theanets.trainer:168 RmsProp 2180 loss=0.036654 err=0.036654
I 2015-05-26 11:34:30 theanets.trainer:168 validation 218 loss=1111.268555 err=1111.268555
I 2015-05-26 11:34:33 theanets.trainer:168 RmsProp 2181 loss=0.032257 err=0.032257
I 2015-05-26 11:34:35 theanets.trainer:168 RmsProp 2182 loss=0.042921 err=0.042921
I 2015-05-26 11:34:37 theanets.trainer:168 RmsProp 2183 loss=0.038076 err=0.038076
I 2015-05-26 11:34:40 theanets.trainer:168 RmsProp 2184 loss=0.034619 err=0.034619
I 2015-05-26 11:34:42 theanets.trainer:168 RmsProp 2185 loss=0.031296 err=0.031296
I 2015-05-26 11:34:44 theanets.trainer:168 RmsProp 2186 loss=0.037584 err=0.037584
I 2015-05-26 11:34:47 theanets.trainer:168 RmsProp 2187 loss=0.034485 err=0.034485
I 2015-05-26 11:34:49 theanets.trainer:168 RmsProp 2188 loss=0.033543 err=0.033543
I 2015-05-26 11:34:52 theanets.trainer:168 RmsProp 2189 loss=0.041735 err=0.041735
I 2015-05-26 11:34:54 theanets.trainer:168 RmsProp 2190 loss=0.037436 err=0.037436
I 2015-05-26 11:34:54 theanets.trainer:168 validation 219 loss=1110.490845 err=1110.490845 *
I 2015-05-26 11:34:57 theanets.trainer:168 RmsProp 2191 loss=0.033622 err=0.033622
I 2015-05-26 11:34:59 theanets.trainer:168 RmsProp 2192 loss=0.031967 err=0.031967
I 2015-05-26 11:35:01 theanets.trainer:168 RmsProp 2193 loss=0.033915 err=0.033915
I 2015-05-26 11:35:04 theanets.trainer:168 RmsProp 2194 loss=0.033208 err=0.033208
I 2015-05-26 11:35:06 theanets.trainer:168 RmsProp 2195 loss=0.041342 err=0.041342
I 2015-05-26 11:35:08 theanets.trainer:168 RmsProp 2196 loss=0.037182 err=0.037182
I 2015-05-26 11:35:11 theanets.trainer:168 RmsProp 2197 loss=0.035058 err=0.035058
I 2015-05-26 11:35:13 theanets.trainer:168 RmsProp 2198 loss=0.034664 err=0.034664
I 2015-05-26 11:35:16 theanets.trainer:168 RmsProp 2199 loss=0.031509 err=0.031509
I 2015-05-26 11:35:18 theanets.trainer:168 RmsProp 2200 loss=0.043097 err=0.043097
I 2015-05-26 11:35:18 theanets.trainer:168 validation 220 loss=1110.445923 err=1110.445923 *
I 2015-05-26 11:35:20 theanets.trainer:168 RmsProp 2201 loss=0.035892 err=0.035892
I 2015-05-26 11:35:23 theanets.trainer:168 RmsProp 2202 loss=0.032427 err=0.032427
I 2015-05-26 11:35:25 theanets.trainer:168 RmsProp 2203 loss=0.035249 err=0.035249
I 2015-05-26 11:35:28 theanets.trainer:168 RmsProp 2204 loss=0.035087 err=0.035087
I 2015-05-26 11:35:30 theanets.trainer:168 RmsProp 2205 loss=0.033736 err=0.033736
I 2015-05-26 11:35:32 theanets.trainer:168 RmsProp 2206 loss=0.037086 err=0.037086
I 2015-05-26 11:35:35 theanets.trainer:168 RmsProp 2207 loss=0.033603 err=0.033603
I 2015-05-26 11:35:37 theanets.trainer:168 RmsProp 2208 loss=0.034552 err=0.034552
I 2015-05-26 11:35:39 theanets.trainer:168 RmsProp 2209 loss=0.033068 err=0.033068
I 2015-05-26 11:35:42 theanets.trainer:168 RmsProp 2210 loss=0.035491 err=0.035491
I 2015-05-26 11:35:42 theanets.trainer:168 validation 221 loss=1109.520996 err=1109.520996 *
I 2015-05-26 11:35:44 theanets.trainer:168 RmsProp 2211 loss=0.034641 err=0.034641
I 2015-05-26 11:35:47 theanets.trainer:168 RmsProp 2212 loss=0.033149 err=0.033149
I 2015-05-26 11:35:49 theanets.trainer:168 RmsProp 2213 loss=0.042978 err=0.042978
I 2015-05-26 11:35:52 theanets.trainer:168 RmsProp 2214 loss=0.034598 err=0.034598
I 2015-05-26 11:35:54 theanets.trainer:168 RmsProp 2215 loss=0.030405 err=0.030405
I 2015-05-26 11:35:56 theanets.trainer:168 RmsProp 2216 loss=0.043659 err=0.043659
I 2015-05-26 11:35:59 theanets.trainer:168 RmsProp 2217 loss=0.033804 err=0.033804
I 2015-05-26 11:36:01 theanets.trainer:168 RmsProp 2218 loss=0.036588 err=0.036588
I 2015-05-26 11:36:03 theanets.trainer:168 RmsProp 2219 loss=0.036537 err=0.036537
I 2015-05-26 11:36:06 theanets.trainer:168 RmsProp 2220 loss=0.035852 err=0.035852
I 2015-05-26 11:36:06 theanets.trainer:168 validation 222 loss=1109.775269 err=1109.775269
I 2015-05-26 11:36:08 theanets.trainer:168 RmsProp 2221 loss=0.033386 err=0.033386
I 2015-05-26 11:36:11 theanets.trainer:168 RmsProp 2222 loss=0.034293 err=0.034293
I 2015-05-26 11:36:13 theanets.trainer:168 RmsProp 2223 loss=0.032628 err=0.032628
I 2015-05-26 11:36:16 theanets.trainer:168 RmsProp 2224 loss=0.035145 err=0.035145
I 2015-05-26 11:36:18 theanets.trainer:168 RmsProp 2225 loss=0.036079 err=0.036079
I 2015-05-26 11:36:20 theanets.trainer:168 RmsProp 2226 loss=0.034439 err=0.034439
I 2015-05-26 11:36:23 theanets.trainer:168 RmsProp 2227 loss=0.038205 err=0.038205
I 2015-05-26 11:36:25 theanets.trainer:168 RmsProp 2228 loss=0.033436 err=0.033436
I 2015-05-26 11:36:27 theanets.trainer:168 RmsProp 2229 loss=0.030785 err=0.030785
I 2015-05-26 11:36:30 theanets.trainer:168 RmsProp 2230 loss=0.032388 err=0.032388
I 2015-05-26 11:36:30 theanets.trainer:168 validation 223 loss=1109.090332 err=1109.090332 *
I 2015-05-26 11:36:32 theanets.trainer:168 RmsProp 2231 loss=0.036237 err=0.036237
I 2015-05-26 11:36:35 theanets.trainer:168 RmsProp 2232 loss=0.032492 err=0.032492
I 2015-05-26 11:36:37 theanets.trainer:168 RmsProp 2233 loss=0.036049 err=0.036049
I 2015-05-26 11:36:40 theanets.trainer:168 RmsProp 2234 loss=0.032025 err=0.032025
I 2015-05-26 11:36:42 theanets.trainer:168 RmsProp 2235 loss=0.032945 err=0.032945
I 2015-05-26 11:36:44 theanets.trainer:168 RmsProp 2236 loss=0.036407 err=0.036407
I 2015-05-26 11:36:47 theanets.trainer:168 RmsProp 2237 loss=0.032638 err=0.032638
I 2015-05-26 11:36:49 theanets.trainer:168 RmsProp 2238 loss=0.033583 err=0.033583
I 2015-05-26 11:36:51 theanets.trainer:168 RmsProp 2239 loss=0.037205 err=0.037205
I 2015-05-26 11:36:54 theanets.trainer:168 RmsProp 2240 loss=0.033253 err=0.033253
I 2015-05-26 11:36:54 theanets.trainer:168 validation 224 loss=1108.549927 err=1108.549927 *
I 2015-05-26 11:36:56 theanets.trainer:168 RmsProp 2241 loss=0.037821 err=0.037821
I 2015-05-26 11:36:59 theanets.trainer:168 RmsProp 2242 loss=0.031890 err=0.031890
I 2015-05-26 11:37:01 theanets.trainer:168 RmsProp 2243 loss=0.041581 err=0.041581
I 2015-05-26 11:37:04 theanets.trainer:168 RmsProp 2244 loss=0.029732 err=0.029732
I 2015-05-26 11:37:06 theanets.trainer:168 RmsProp 2245 loss=0.033373 err=0.033373
I 2015-05-26 11:37:08 theanets.trainer:168 RmsProp 2246 loss=0.034946 err=0.034946
I 2015-05-26 11:37:11 theanets.trainer:168 RmsProp 2247 loss=0.036958 err=0.036958
I 2015-05-26 11:37:13 theanets.trainer:168 RmsProp 2248 loss=0.029754 err=0.029754
I 2015-05-26 11:37:15 theanets.trainer:168 RmsProp 2249 loss=0.036106 err=0.036106
I 2015-05-26 11:37:18 theanets.trainer:168 RmsProp 2250 loss=0.033119 err=0.033119
I 2015-05-26 11:37:18 theanets.trainer:168 validation 225 loss=1109.601440 err=1109.601440
I 2015-05-26 11:37:20 theanets.trainer:168 RmsProp 2251 loss=0.037763 err=0.037763
I 2015-05-26 11:37:23 theanets.trainer:168 RmsProp 2252 loss=0.033385 err=0.033385
I 2015-05-26 11:37:25 theanets.trainer:168 RmsProp 2253 loss=0.036898 err=0.036898
I 2015-05-26 11:37:28 theanets.trainer:168 RmsProp 2254 loss=0.034712 err=0.034712
I 2015-05-26 11:37:30 theanets.trainer:168 RmsProp 2255 loss=0.033495 err=0.033495
I 2015-05-26 11:37:32 theanets.trainer:168 RmsProp 2256 loss=0.032857 err=0.032857
I 2015-05-26 11:37:35 theanets.trainer:168 RmsProp 2257 loss=0.035128 err=0.035128
I 2015-05-26 11:37:37 theanets.trainer:168 RmsProp 2258 loss=0.034789 err=0.034789
I 2015-05-26 11:37:39 theanets.trainer:168 RmsProp 2259 loss=0.033114 err=0.033114
I 2015-05-26 11:37:42 theanets.trainer:168 RmsProp 2260 loss=0.035851 err=0.035851
I 2015-05-26 11:37:42 theanets.trainer:168 validation 226 loss=1108.551758 err=1108.551758
I 2015-05-26 11:37:44 theanets.trainer:168 RmsProp 2261 loss=0.036489 err=0.036489
I 2015-05-26 11:37:47 theanets.trainer:168 RmsProp 2262 loss=0.030178 err=0.030178
I 2015-05-26 11:37:49 theanets.trainer:168 RmsProp 2263 loss=0.041149 err=0.041149
I 2015-05-26 11:37:52 theanets.trainer:168 RmsProp 2264 loss=0.034700 err=0.034700
I 2015-05-26 11:37:54 theanets.trainer:168 RmsProp 2265 loss=0.036216 err=0.036216
I 2015-05-26 11:37:56 theanets.trainer:168 RmsProp 2266 loss=0.032915 err=0.032915
I 2015-05-26 11:37:59 theanets.trainer:168 RmsProp 2267 loss=0.032120 err=0.032120
I 2015-05-26 11:38:01 theanets.trainer:168 RmsProp 2268 loss=0.036031 err=0.036031
I 2015-05-26 11:38:03 theanets.trainer:168 RmsProp 2269 loss=0.032956 err=0.032956
I 2015-05-26 11:38:06 theanets.trainer:168 RmsProp 2270 loss=0.036737 err=0.036737
I 2015-05-26 11:38:06 theanets.trainer:168 validation 227 loss=1108.237793 err=1108.237793 *
I 2015-05-26 11:38:08 theanets.trainer:168 RmsProp 2271 loss=0.034591 err=0.034591
I 2015-05-26 11:38:11 theanets.trainer:168 RmsProp 2272 loss=0.031253 err=0.031253
I 2015-05-26 11:38:13 theanets.trainer:168 RmsProp 2273 loss=0.038261 err=0.038261
I 2015-05-26 11:38:16 theanets.trainer:168 RmsProp 2274 loss=0.032040 err=0.032040
I 2015-05-26 11:38:18 theanets.trainer:168 RmsProp 2275 loss=0.035015 err=0.035015
I 2015-05-26 11:38:20 theanets.trainer:168 RmsProp 2276 loss=0.028642 err=0.028642
I 2015-05-26 11:38:23 theanets.trainer:168 RmsProp 2277 loss=0.045287 err=0.045287
I 2015-05-26 11:38:25 theanets.trainer:168 RmsProp 2278 loss=0.034899 err=0.034899
I 2015-05-26 11:38:27 theanets.trainer:168 RmsProp 2279 loss=0.028647 err=0.028647
I 2015-05-26 11:38:30 theanets.trainer:168 RmsProp 2280 loss=0.045362 err=0.045362
I 2015-05-26 11:38:30 theanets.trainer:168 validation 228 loss=1108.029419 err=1108.029419 *
I 2015-05-26 11:38:32 theanets.trainer:168 RmsProp 2281 loss=0.034752 err=0.034752
I 2015-05-26 11:38:35 theanets.trainer:168 RmsProp 2282 loss=0.036399 err=0.036399
I 2015-05-26 11:38:36 theanets.trainer:168 RmsProp 2283 loss=0.030762 err=0.030762
I 2015-05-26 11:38:38 theanets.trainer:168 RmsProp 2284 loss=0.034853 err=0.034853
I 2015-05-26 11:38:40 theanets.trainer:168 RmsProp 2285 loss=0.035963 err=0.035963
I 2015-05-26 11:38:42 theanets.trainer:168 RmsProp 2286 loss=0.036453 err=0.036453
I 2015-05-26 11:38:44 theanets.trainer:168 RmsProp 2287 loss=0.033758 err=0.033758
I 2015-05-26 11:38:46 theanets.trainer:168 RmsProp 2288 loss=0.038118 err=0.038118
I 2015-05-26 11:38:48 theanets.trainer:168 RmsProp 2289 loss=0.031799 err=0.031799
I 2015-05-26 11:38:50 theanets.trainer:168 RmsProp 2290 loss=0.034559 err=0.034559
I 2015-05-26 11:38:50 theanets.trainer:168 validation 229 loss=1108.434937 err=1108.434937
I 2015-05-26 11:38:52 theanets.trainer:168 RmsProp 2291 loss=0.032752 err=0.032752
I 2015-05-26 11:38:53 theanets.trainer:168 RmsProp 2292 loss=0.034477 err=0.034477
I 2015-05-26 11:38:55 theanets.trainer:168 RmsProp 2293 loss=0.033086 err=0.033086
I 2015-05-26 11:38:57 theanets.trainer:168 RmsProp 2294 loss=0.033247 err=0.033247
I 2015-05-26 11:38:59 theanets.trainer:168 RmsProp 2295 loss=0.037410 err=0.037410
I 2015-05-26 11:39:01 theanets.trainer:168 RmsProp 2296 loss=0.031998 err=0.031998
I 2015-05-26 11:39:03 theanets.trainer:168 RmsProp 2297 loss=0.032163 err=0.032163
I 2015-05-26 11:39:05 theanets.trainer:168 RmsProp 2298 loss=0.032469 err=0.032469
I 2015-05-26 11:39:07 theanets.trainer:168 RmsProp 2299 loss=0.028388 err=0.028388
I 2015-05-26 11:39:08 theanets.trainer:168 RmsProp 2300 loss=0.038011 err=0.038011
I 2015-05-26 11:39:09 theanets.trainer:168 validation 230 loss=1107.843140 err=1107.843140 *
I 2015-05-26 11:39:11 theanets.trainer:168 RmsProp 2301 loss=0.032777 err=0.032777
I 2015-05-26 11:39:12 theanets.trainer:168 RmsProp 2302 loss=0.033683 err=0.033683
I 2015-05-26 11:39:14 theanets.trainer:168 RmsProp 2303 loss=0.034224 err=0.034224
I 2015-05-26 11:39:16 theanets.trainer:168 RmsProp 2304 loss=0.038119 err=0.038119
I 2015-05-26 11:39:18 theanets.trainer:168 RmsProp 2305 loss=0.032580 err=0.032580
I 2015-05-26 11:39:20 theanets.trainer:168 RmsProp 2306 loss=0.033517 err=0.033517
I 2015-05-26 11:39:22 theanets.trainer:168 RmsProp 2307 loss=0.030538 err=0.030538
I 2015-05-26 11:39:24 theanets.trainer:168 RmsProp 2308 loss=0.040041 err=0.040041
I 2015-05-26 11:39:26 theanets.trainer:168 RmsProp 2309 loss=0.035694 err=0.035694
I 2015-05-26 11:39:27 theanets.trainer:168 RmsProp 2310 loss=0.031908 err=0.031908
I 2015-05-26 11:39:28 theanets.trainer:168 validation 231 loss=1107.758789 err=1107.758789 *
I 2015-05-26 11:39:30 theanets.trainer:168 RmsProp 2311 loss=0.032776 err=0.032776
I 2015-05-26 11:39:31 theanets.trainer:168 RmsProp 2312 loss=0.031741 err=0.031741
I 2015-05-26 11:39:33 theanets.trainer:168 RmsProp 2313 loss=0.039956 err=0.039956
I 2015-05-26 11:39:35 theanets.trainer:168 RmsProp 2314 loss=0.032318 err=0.032318
I 2015-05-26 11:39:37 theanets.trainer:168 RmsProp 2315 loss=0.035196 err=0.035196
I 2015-05-26 11:39:39 theanets.trainer:168 RmsProp 2316 loss=0.030782 err=0.030782
I 2015-05-26 11:39:41 theanets.trainer:168 RmsProp 2317 loss=0.040428 err=0.040428
I 2015-05-26 11:39:43 theanets.trainer:168 RmsProp 2318 loss=0.031276 err=0.031276
I 2015-05-26 11:39:45 theanets.trainer:168 RmsProp 2319 loss=0.033355 err=0.033355
I 2015-05-26 11:39:46 theanets.trainer:168 RmsProp 2320 loss=0.032831 err=0.032831
I 2015-05-26 11:39:47 theanets.trainer:168 validation 232 loss=1106.784058 err=1106.784058 *
I 2015-05-26 11:39:48 theanets.trainer:168 RmsProp 2321 loss=0.032620 err=0.032620
I 2015-05-26 11:39:50 theanets.trainer:168 RmsProp 2322 loss=0.036336 err=0.036336
I 2015-05-26 11:39:52 theanets.trainer:168 RmsProp 2323 loss=0.033165 err=0.033165
I 2015-05-26 11:39:54 theanets.trainer:168 RmsProp 2324 loss=0.033336 err=0.033336
I 2015-05-26 11:39:56 theanets.trainer:168 RmsProp 2325 loss=0.030972 err=0.030972
I 2015-05-26 11:39:58 theanets.trainer:168 RmsProp 2326 loss=0.037793 err=0.037793
I 2015-05-26 11:40:00 theanets.trainer:168 RmsProp 2327 loss=0.031859 err=0.031859
I 2015-05-26 11:40:02 theanets.trainer:168 RmsProp 2328 loss=0.033460 err=0.033460
I 2015-05-26 11:40:03 theanets.trainer:168 RmsProp 2329 loss=0.028896 err=0.028896
I 2015-05-26 11:40:05 theanets.trainer:168 RmsProp 2330 loss=0.039372 err=0.039372
I 2015-05-26 11:40:06 theanets.trainer:168 validation 233 loss=1107.554199 err=1107.554199
I 2015-05-26 11:40:07 theanets.trainer:168 RmsProp 2331 loss=0.031439 err=0.031439
I 2015-05-26 11:40:09 theanets.trainer:168 RmsProp 2332 loss=0.032676 err=0.032676
I 2015-05-26 11:40:11 theanets.trainer:168 RmsProp 2333 loss=0.031799 err=0.031799
I 2015-05-26 11:40:13 theanets.trainer:168 RmsProp 2334 loss=0.036606 err=0.036606
I 2015-05-26 11:40:15 theanets.trainer:168 RmsProp 2335 loss=0.031703 err=0.031703
I 2015-05-26 11:40:17 theanets.trainer:168 RmsProp 2336 loss=0.031447 err=0.031447
I 2015-05-26 11:40:19 theanets.trainer:168 RmsProp 2337 loss=0.033456 err=0.033456
I 2015-05-26 11:40:20 theanets.trainer:168 RmsProp 2338 loss=0.030086 err=0.030086
I 2015-05-26 11:40:22 theanets.trainer:168 RmsProp 2339 loss=0.041346 err=0.041346
I 2015-05-26 11:40:24 theanets.trainer:168 RmsProp 2340 loss=0.033002 err=0.033002
I 2015-05-26 11:40:24 theanets.trainer:168 validation 234 loss=1107.988647 err=1107.988647
I 2015-05-26 11:40:26 theanets.trainer:168 RmsProp 2341 loss=0.028493 err=0.028493
I 2015-05-26 11:40:28 theanets.trainer:168 RmsProp 2342 loss=0.043255 err=0.043255
I 2015-05-26 11:40:30 theanets.trainer:168 RmsProp 2343 loss=0.030342 err=0.030342
I 2015-05-26 11:40:32 theanets.trainer:168 RmsProp 2344 loss=0.029716 err=0.029716
I 2015-05-26 11:40:34 theanets.trainer:168 RmsProp 2345 loss=0.037604 err=0.037604
I 2015-05-26 11:40:36 theanets.trainer:168 RmsProp 2346 loss=0.033272 err=0.033272
I 2015-05-26 11:40:37 theanets.trainer:168 RmsProp 2347 loss=0.029785 err=0.029785
I 2015-05-26 11:40:39 theanets.trainer:168 RmsProp 2348 loss=0.035642 err=0.035642
I 2015-05-26 11:40:41 theanets.trainer:168 RmsProp 2349 loss=0.035634 err=0.035634
I 2015-05-26 11:40:43 theanets.trainer:168 RmsProp 2350 loss=0.030071 err=0.030071
I 2015-05-26 11:40:43 theanets.trainer:168 validation 235 loss=1106.625854 err=1106.625854 *
I 2015-05-26 11:40:45 theanets.trainer:168 RmsProp 2351 loss=0.026365 err=0.026365
I 2015-05-26 11:40:47 theanets.trainer:168 RmsProp 2352 loss=0.048810 err=0.048810
I 2015-05-26 11:40:49 theanets.trainer:168 RmsProp 2353 loss=0.032737 err=0.032737
I 2015-05-26 11:40:51 theanets.trainer:168 RmsProp 2354 loss=0.032234 err=0.032234
I 2015-05-26 11:40:53 theanets.trainer:168 RmsProp 2355 loss=0.031832 err=0.031832
I 2015-05-26 11:40:54 theanets.trainer:168 RmsProp 2356 loss=0.034582 err=0.034582
I 2015-05-26 11:40:56 theanets.trainer:168 RmsProp 2357 loss=0.034781 err=0.034781
I 2015-05-26 11:40:58 theanets.trainer:168 RmsProp 2358 loss=0.033411 err=0.033411
I 2015-05-26 11:41:00 theanets.trainer:168 RmsProp 2359 loss=0.033674 err=0.033674
I 2015-05-26 11:41:02 theanets.trainer:168 RmsProp 2360 loss=0.031389 err=0.031389
I 2015-05-26 11:41:02 theanets.trainer:168 validation 236 loss=1106.199829 err=1106.199829 *
I 2015-05-26 11:41:04 theanets.trainer:168 RmsProp 2361 loss=0.035595 err=0.035595
I 2015-05-26 11:41:06 theanets.trainer:168 RmsProp 2362 loss=0.033353 err=0.033353
I 2015-05-26 11:41:08 theanets.trainer:168 RmsProp 2363 loss=0.035156 err=0.035156
I 2015-05-26 11:41:10 theanets.trainer:168 RmsProp 2364 loss=0.031481 err=0.031481
I 2015-05-26 11:41:12 theanets.trainer:168 RmsProp 2365 loss=0.031967 err=0.031967
I 2015-05-26 11:41:13 theanets.trainer:168 RmsProp 2366 loss=0.042749 err=0.042749
I 2015-05-26 11:41:15 theanets.trainer:168 RmsProp 2367 loss=0.033138 err=0.033138
I 2015-05-26 11:41:17 theanets.trainer:168 RmsProp 2368 loss=0.032295 err=0.032295
I 2015-05-26 11:41:19 theanets.trainer:168 RmsProp 2369 loss=0.032634 err=0.032634
I 2015-05-26 11:41:21 theanets.trainer:168 RmsProp 2370 loss=0.034006 err=0.034006
I 2015-05-26 11:41:21 theanets.trainer:168 validation 237 loss=1106.536011 err=1106.536011
I 2015-05-26 11:41:23 theanets.trainer:168 RmsProp 2371 loss=0.033298 err=0.033298
I 2015-05-26 11:41:25 theanets.trainer:168 RmsProp 2372 loss=0.033080 err=0.033080
I 2015-05-26 11:41:27 theanets.trainer:168 RmsProp 2373 loss=0.029768 err=0.029768
I 2015-05-26 11:41:29 theanets.trainer:168 RmsProp 2374 loss=0.037975 err=0.037975
I 2015-05-26 11:41:31 theanets.trainer:168 RmsProp 2375 loss=0.032039 err=0.032039
I 2015-05-26 11:41:32 theanets.trainer:168 RmsProp 2376 loss=0.039070 err=0.039070
I 2015-05-26 11:41:34 theanets.trainer:168 RmsProp 2377 loss=0.033571 err=0.033571
I 2015-05-26 11:41:36 theanets.trainer:168 RmsProp 2378 loss=0.030184 err=0.030184
I 2015-05-26 11:41:38 theanets.trainer:168 RmsProp 2379 loss=0.035659 err=0.035659
I 2015-05-26 11:41:40 theanets.trainer:168 RmsProp 2380 loss=0.030366 err=0.030366
I 2015-05-26 11:41:40 theanets.trainer:168 validation 238 loss=1106.096313 err=1106.096313 *
I 2015-05-26 11:41:42 theanets.trainer:168 RmsProp 2381 loss=0.037757 err=0.037757
I 2015-05-26 11:41:44 theanets.trainer:168 RmsProp 2382 loss=0.030181 err=0.030181
I 2015-05-26 11:41:46 theanets.trainer:168 RmsProp 2383 loss=0.036794 err=0.036794
I 2015-05-26 11:41:48 theanets.trainer:168 RmsProp 2384 loss=0.029025 err=0.029025
I 2015-05-26 11:41:50 theanets.trainer:168 RmsProp 2385 loss=0.034161 err=0.034161
I 2015-05-26 11:41:51 theanets.trainer:168 RmsProp 2386 loss=0.032251 err=0.032251
I 2015-05-26 11:41:53 theanets.trainer:168 RmsProp 2387 loss=0.033847 err=0.033847
I 2015-05-26 11:41:55 theanets.trainer:168 RmsProp 2388 loss=0.031139 err=0.031139
I 2015-05-26 11:41:57 theanets.trainer:168 RmsProp 2389 loss=0.038106 err=0.038106
I 2015-05-26 11:41:59 theanets.trainer:168 RmsProp 2390 loss=0.036346 err=0.036346
I 2015-05-26 11:41:59 theanets.trainer:168 validation 239 loss=1105.241821 err=1105.241821 *
I 2015-05-26 11:42:01 theanets.trainer:168 RmsProp 2391 loss=0.031945 err=0.031945
I 2015-05-26 11:42:03 theanets.trainer:168 RmsProp 2392 loss=0.036237 err=0.036237
I 2015-05-26 11:42:05 theanets.trainer:168 RmsProp 2393 loss=0.031016 err=0.031016
I 2015-05-26 11:42:07 theanets.trainer:168 RmsProp 2394 loss=0.032609 err=0.032609
I 2015-05-26 11:42:08 theanets.trainer:168 RmsProp 2395 loss=0.032097 err=0.032097
I 2015-05-26 11:42:10 theanets.trainer:168 RmsProp 2396 loss=0.036468 err=0.036468
I 2015-05-26 11:42:12 theanets.trainer:168 RmsProp 2397 loss=0.034941 err=0.034941
I 2015-05-26 11:42:14 theanets.trainer:168 RmsProp 2398 loss=0.030354 err=0.030354
I 2015-05-26 11:42:16 theanets.trainer:168 RmsProp 2399 loss=0.036688 err=0.036688
I 2015-05-26 11:42:18 theanets.trainer:168 RmsProp 2400 loss=0.030039 err=0.030039
I 2015-05-26 11:42:18 theanets.trainer:168 validation 240 loss=1104.252441 err=1104.252441 *
I 2015-05-26 11:42:20 theanets.trainer:168 RmsProp 2401 loss=0.040251 err=0.040251
I 2015-05-26 11:42:22 theanets.trainer:168 RmsProp 2402 loss=0.031120 err=0.031120
I 2015-05-26 11:42:24 theanets.trainer:168 RmsProp 2403 loss=0.028612 err=0.028612
I 2015-05-26 11:42:25 theanets.trainer:168 RmsProp 2404 loss=0.033017 err=0.033017
I 2015-05-26 11:42:27 theanets.trainer:168 RmsProp 2405 loss=0.036462 err=0.036462
I 2015-05-26 11:42:29 theanets.trainer:168 RmsProp 2406 loss=0.032844 err=0.032844
I 2015-05-26 11:42:31 theanets.trainer:168 RmsProp 2407 loss=0.032311 err=0.032311
I 2015-05-26 11:42:33 theanets.trainer:168 RmsProp 2408 loss=0.033202 err=0.033202
I 2015-05-26 11:42:35 theanets.trainer:168 RmsProp 2409 loss=0.032530 err=0.032530
I 2015-05-26 11:42:37 theanets.trainer:168 RmsProp 2410 loss=0.031917 err=0.031917
I 2015-05-26 11:42:37 theanets.trainer:168 validation 241 loss=1104.440796 err=1104.440796
I 2015-05-26 11:42:39 theanets.trainer:168 RmsProp 2411 loss=0.032026 err=0.032026
I 2015-05-26 11:42:41 theanets.trainer:168 RmsProp 2412 loss=0.031999 err=0.031999
I 2015-05-26 11:42:42 theanets.trainer:168 RmsProp 2413 loss=0.035087 err=0.035087
I 2015-05-26 11:42:44 theanets.trainer:168 RmsProp 2414 loss=0.032230 err=0.032230
I 2015-05-26 11:42:46 theanets.trainer:168 RmsProp 2415 loss=0.030851 err=0.030851
I 2015-05-26 11:42:48 theanets.trainer:168 RmsProp 2416 loss=0.031385 err=0.031385
I 2015-05-26 11:42:50 theanets.trainer:168 RmsProp 2417 loss=0.029501 err=0.029501
I 2015-05-26 11:42:52 theanets.trainer:168 RmsProp 2418 loss=0.039679 err=0.039679
I 2015-05-26 11:42:54 theanets.trainer:168 RmsProp 2419 loss=0.030952 err=0.030952
I 2015-05-26 11:42:56 theanets.trainer:168 RmsProp 2420 loss=0.032544 err=0.032544
I 2015-05-26 11:42:56 theanets.trainer:168 validation 242 loss=1104.844971 err=1104.844971
I 2015-05-26 11:42:58 theanets.trainer:168 RmsProp 2421 loss=0.031680 err=0.031680
I 2015-05-26 11:42:59 theanets.trainer:168 RmsProp 2422 loss=0.036553 err=0.036553
I 2015-05-26 11:43:01 theanets.trainer:168 RmsProp 2423 loss=0.032775 err=0.032775
I 2015-05-26 11:43:03 theanets.trainer:168 RmsProp 2424 loss=0.036724 err=0.036724
I 2015-05-26 11:43:05 theanets.trainer:168 RmsProp 2425 loss=0.031075 err=0.031075
I 2015-05-26 11:43:07 theanets.trainer:168 RmsProp 2426 loss=0.039815 err=0.039815
I 2015-05-26 11:43:09 theanets.trainer:168 RmsProp 2427 loss=0.028619 err=0.028619
I 2015-05-26 11:43:11 theanets.trainer:168 RmsProp 2428 loss=0.036735 err=0.036735
I 2015-05-26 11:43:13 theanets.trainer:168 RmsProp 2429 loss=0.029883 err=0.029883
I 2015-05-26 11:43:14 theanets.trainer:168 RmsProp 2430 loss=0.028129 err=0.028129
I 2015-05-26 11:43:15 theanets.trainer:168 validation 243 loss=1104.252808 err=1104.252808
I 2015-05-26 11:43:16 theanets.trainer:168 RmsProp 2431 loss=0.034275 err=0.034275
I 2015-05-26 11:43:18 theanets.trainer:168 RmsProp 2432 loss=0.032583 err=0.032583
I 2015-05-26 11:43:20 theanets.trainer:168 RmsProp 2433 loss=0.036969 err=0.036969
I 2015-05-26 11:43:22 theanets.trainer:168 RmsProp 2434 loss=0.027018 err=0.027018
I 2015-05-26 11:43:24 theanets.trainer:168 RmsProp 2435 loss=0.038231 err=0.038231
I 2015-05-26 11:43:26 theanets.trainer:168 RmsProp 2436 loss=0.027346 err=0.027346
I 2015-05-26 11:43:28 theanets.trainer:168 RmsProp 2437 loss=0.034836 err=0.034836
I 2015-05-26 11:43:30 theanets.trainer:168 RmsProp 2438 loss=0.029076 err=0.029076
I 2015-05-26 11:43:32 theanets.trainer:168 RmsProp 2439 loss=0.033857 err=0.033857
I 2015-05-26 11:43:34 theanets.trainer:168 RmsProp 2440 loss=0.029433 err=0.029433
I 2015-05-26 11:43:34 theanets.trainer:168 validation 244 loss=1104.840454 err=1104.840454
I 2015-05-26 11:43:36 theanets.trainer:168 RmsProp 2441 loss=0.032102 err=0.032102
I 2015-05-26 11:43:37 theanets.trainer:168 RmsProp 2442 loss=0.033276 err=0.033276
I 2015-05-26 11:43:39 theanets.trainer:168 RmsProp 2443 loss=0.033040 err=0.033040
I 2015-05-26 11:43:41 theanets.trainer:168 RmsProp 2444 loss=0.029611 err=0.029611
I 2015-05-26 11:43:43 theanets.trainer:168 RmsProp 2445 loss=0.031736 err=0.031736
I 2015-05-26 11:43:45 theanets.trainer:168 RmsProp 2446 loss=0.030070 err=0.030070
I 2015-05-26 11:43:47 theanets.trainer:168 RmsProp 2447 loss=0.032484 err=0.032484
I 2015-05-26 11:43:49 theanets.trainer:168 RmsProp 2448 loss=0.027188 err=0.027188
I 2015-05-26 11:43:51 theanets.trainer:168 RmsProp 2449 loss=0.042208 err=0.042208
I 2015-05-26 11:43:52 theanets.trainer:168 RmsProp 2450 loss=0.030873 err=0.030873
I 2015-05-26 11:43:53 theanets.trainer:168 validation 245 loss=1104.366821 err=1104.366821
I 2015-05-26 11:43:53 theanets.trainer:252 patience elapsed!
I 2015-05-26 11:43:53 theanets.main:237 models_deep_post_code_sep/95126-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saving model
I 2015-05-26 11:43:53 theanets.graph:477 models_deep_post_code_sep/95126-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saved model parameters
