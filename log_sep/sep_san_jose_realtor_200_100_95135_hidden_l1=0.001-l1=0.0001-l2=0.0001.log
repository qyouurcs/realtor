I 2015-05-26 03:35:25 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 03:35:25 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95135-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl
I 2015-05-26 03:35:25 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 03:35:25 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 03:35:25 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 03:35:25 theanets.main:89 --batch_size = 1024
I 2015-05-26 03:35:25 theanets.main:89 --gradient_clip = 1
I 2015-05-26 03:35:25 theanets.main:89 --hidden_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 03:35:25 theanets.main:89 --train_batches = 30
I 2015-05-26 03:35:25 theanets.main:89 --valid_batches = 3
I 2015-05-26 03:35:25 theanets.main:89 --weight_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --weight_l2 = None
I 2015-05-26 03:35:26 theanets.trainer:134 compiling evaluation function
I 2015-05-26 03:35:41 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 03:38:58 theanets.trainer:168 validation 0 loss=14159.065430 err=14159.065430 *
I 2015-05-26 03:39:56 theanets.trainer:168 RmsProp 1 loss=13227.260742 err=13227.260742
I 2015-05-26 03:40:55 theanets.trainer:168 RmsProp 2 loss=13177.884766 err=13177.884766
I 2015-05-26 03:41:55 theanets.trainer:168 RmsProp 3 loss=12695.797852 err=12695.797852
I 2015-05-26 03:42:54 theanets.trainer:168 RmsProp 4 loss=11100.846680 err=11100.846680
I 2015-05-26 03:43:52 theanets.trainer:168 RmsProp 5 loss=10226.661133 err=10226.661133
I 2015-05-26 03:44:50 theanets.trainer:168 RmsProp 6 loss=9844.987305 err=9844.987305
I 2015-05-26 03:45:49 theanets.trainer:168 RmsProp 7 loss=9310.055664 err=9310.055664
I 2015-05-26 03:46:48 theanets.trainer:168 RmsProp 8 loss=8942.467773 err=8942.467773
I 2015-05-26 03:47:46 theanets.trainer:168 RmsProp 9 loss=8356.304688 err=8356.304688
I 2015-05-26 03:48:45 theanets.trainer:168 RmsProp 10 loss=7767.001953 err=7767.001953
I 2015-05-26 03:48:46 theanets.trainer:168 validation 1 loss=7293.620605 err=7293.620605 *
I 2015-05-26 03:49:45 theanets.trainer:168 RmsProp 11 loss=7131.604980 err=7131.604980
I 2015-05-26 03:50:44 theanets.trainer:168 RmsProp 12 loss=6773.898926 err=6773.898926
I 2015-05-26 03:51:44 theanets.trainer:168 RmsProp 13 loss=6468.107422 err=6468.107422
I 2015-05-26 03:52:44 theanets.trainer:168 RmsProp 14 loss=6037.028320 err=6037.028320
I 2015-05-26 03:53:44 theanets.trainer:168 RmsProp 15 loss=5719.567383 err=5719.567383
I 2015-05-26 03:54:44 theanets.trainer:168 RmsProp 16 loss=5478.849609 err=5478.849609
I 2015-05-26 03:55:44 theanets.trainer:168 RmsProp 17 loss=5120.880859 err=5120.880859
I 2015-05-26 03:56:44 theanets.trainer:168 RmsProp 18 loss=4911.634277 err=4911.634277
I 2015-05-26 03:57:44 theanets.trainer:168 RmsProp 19 loss=4680.954590 err=4680.954590
I 2015-05-26 03:58:43 theanets.trainer:168 RmsProp 20 loss=4522.798340 err=4522.798340
I 2015-05-26 03:58:45 theanets.trainer:168 validation 2 loss=4193.700684 err=4193.700684 *
I 2015-05-26 03:59:43 theanets.trainer:168 RmsProp 21 loss=4402.064941 err=4402.064941
I 2015-05-26 04:00:43 theanets.trainer:168 RmsProp 22 loss=4040.052490 err=4040.052490
I 2015-05-26 04:01:43 theanets.trainer:168 RmsProp 23 loss=3802.562012 err=3802.562012
I 2015-05-26 04:02:43 theanets.trainer:168 RmsProp 24 loss=3361.508057 err=3361.508057
I 2015-05-26 04:03:43 theanets.trainer:168 RmsProp 25 loss=3008.513428 err=3008.513428
I 2015-05-26 04:04:43 theanets.trainer:168 RmsProp 26 loss=2858.557373 err=2858.557373
I 2015-05-26 04:05:42 theanets.trainer:168 RmsProp 27 loss=2650.038086 err=2650.038086
I 2015-05-26 04:06:42 theanets.trainer:168 RmsProp 28 loss=2575.347900 err=2575.347900
I 2015-05-26 04:07:41 theanets.trainer:168 RmsProp 29 loss=2412.233398 err=2412.233398
I 2015-05-26 04:08:41 theanets.trainer:168 RmsProp 30 loss=2303.469727 err=2303.469727
I 2015-05-26 04:08:42 theanets.trainer:168 validation 3 loss=2908.151123 err=2908.151123 *
I 2015-05-26 04:09:41 theanets.trainer:168 RmsProp 31 loss=2265.670654 err=2265.670654
I 2015-05-26 04:10:40 theanets.trainer:168 RmsProp 32 loss=2141.287598 err=2141.287598
I 2015-05-26 04:11:40 theanets.trainer:168 RmsProp 33 loss=2019.187134 err=2019.187134
I 2015-05-26 04:12:37 theanets.trainer:168 RmsProp 34 loss=1933.511108 err=1933.511108
I 2015-05-26 04:13:34 theanets.trainer:168 RmsProp 35 loss=1831.410156 err=1831.410156
I 2015-05-26 04:14:29 theanets.trainer:168 RmsProp 36 loss=1769.933228 err=1769.933228
I 2015-05-26 04:15:25 theanets.trainer:168 RmsProp 37 loss=1675.874634 err=1675.874634
I 2015-05-26 04:16:20 theanets.trainer:168 RmsProp 38 loss=1639.049927 err=1639.049927
I 2015-05-26 04:17:15 theanets.trainer:168 RmsProp 39 loss=1574.284912 err=1574.284912
I 2015-05-26 04:18:10 theanets.trainer:168 RmsProp 40 loss=1475.808838 err=1475.808838
I 2015-05-26 04:18:11 theanets.trainer:168 validation 4 loss=2496.245850 err=2496.245850 *
I 2015-05-26 04:19:06 theanets.trainer:168 RmsProp 41 loss=1459.681763 err=1459.681763
I 2015-05-26 04:20:02 theanets.trainer:168 RmsProp 42 loss=1365.974121 err=1365.974121
I 2015-05-26 04:20:58 theanets.trainer:168 RmsProp 43 loss=1291.839233 err=1291.839233
I 2015-05-26 04:21:54 theanets.trainer:168 RmsProp 44 loss=1280.799438 err=1280.799438
I 2015-05-26 04:22:48 theanets.trainer:168 RmsProp 45 loss=1232.637329 err=1232.637329
I 2015-05-26 04:23:40 theanets.trainer:168 RmsProp 46 loss=1181.491821 err=1181.491821
I 2015-05-26 04:24:32 theanets.trainer:168 RmsProp 47 loss=1106.384155 err=1106.384155
I 2015-05-26 04:25:23 theanets.trainer:168 RmsProp 48 loss=1126.584106 err=1126.584106
I 2015-05-26 04:26:16 theanets.trainer:168 RmsProp 49 loss=1079.042603 err=1079.042603
I 2015-05-26 04:27:08 theanets.trainer:168 RmsProp 50 loss=1018.607178 err=1018.607178
I 2015-05-26 04:27:10 theanets.trainer:168 validation 5 loss=2190.244873 err=2190.244873 *
I 2015-05-26 04:28:01 theanets.trainer:168 RmsProp 51 loss=995.946106 err=995.946106
I 2015-05-26 04:28:52 theanets.trainer:168 RmsProp 52 loss=1009.957581 err=1009.957581
I 2015-05-26 04:29:43 theanets.trainer:168 RmsProp 53 loss=950.636658 err=950.636658
I 2015-05-26 04:30:35 theanets.trainer:168 RmsProp 54 loss=932.039490 err=932.039490
I 2015-05-26 04:31:27 theanets.trainer:168 RmsProp 55 loss=904.745300 err=904.745300
I 2015-05-26 04:32:18 theanets.trainer:168 RmsProp 56 loss=869.991211 err=869.991211
I 2015-05-26 04:33:09 theanets.trainer:168 RmsProp 57 loss=829.223267 err=829.223267
I 2015-05-26 04:34:01 theanets.trainer:168 RmsProp 58 loss=804.652283 err=804.652283
I 2015-05-26 04:34:53 theanets.trainer:168 RmsProp 59 loss=781.791443 err=781.791443
I 2015-05-26 04:35:45 theanets.trainer:168 RmsProp 60 loss=795.663086 err=795.663086
I 2015-05-26 04:35:46 theanets.trainer:168 validation 6 loss=2113.935547 err=2113.935547 *
I 2015-05-26 04:36:38 theanets.trainer:168 RmsProp 61 loss=796.710876 err=796.710876
I 2015-05-26 04:37:31 theanets.trainer:168 RmsProp 62 loss=754.339539 err=754.339539
I 2015-05-26 04:38:23 theanets.trainer:168 RmsProp 63 loss=780.928528 err=780.928528
I 2015-05-26 04:39:15 theanets.trainer:168 RmsProp 64 loss=730.905029 err=730.905029
I 2015-05-26 04:40:09 theanets.trainer:168 RmsProp 65 loss=695.781006 err=695.781006
I 2015-05-26 04:41:02 theanets.trainer:168 RmsProp 66 loss=677.891479 err=677.891479
I 2015-05-26 04:41:55 theanets.trainer:168 RmsProp 67 loss=664.404541 err=664.404541
I 2015-05-26 04:42:48 theanets.trainer:168 RmsProp 68 loss=687.264954 err=687.264954
I 2015-05-26 04:43:41 theanets.trainer:168 RmsProp 69 loss=641.959229 err=641.959229
I 2015-05-26 04:44:34 theanets.trainer:168 RmsProp 70 loss=668.927490 err=668.927490
I 2015-05-26 04:44:35 theanets.trainer:168 validation 7 loss=1961.198608 err=1961.198608 *
I 2015-05-26 04:45:27 theanets.trainer:168 RmsProp 71 loss=642.268677 err=642.268677
I 2015-05-26 04:46:20 theanets.trainer:168 RmsProp 72 loss=592.475342 err=592.475342
I 2015-05-26 04:47:12 theanets.trainer:168 RmsProp 73 loss=565.606567 err=565.606567
I 2015-05-26 04:48:05 theanets.trainer:168 RmsProp 74 loss=556.226929 err=556.226929
I 2015-05-26 04:48:57 theanets.trainer:168 RmsProp 75 loss=586.750610 err=586.750610
I 2015-05-26 04:49:50 theanets.trainer:168 RmsProp 76 loss=610.420349 err=610.420349
I 2015-05-26 04:50:43 theanets.trainer:168 RmsProp 77 loss=552.075867 err=552.075867
I 2015-05-26 04:51:34 theanets.trainer:168 RmsProp 78 loss=519.988647 err=519.988647
I 2015-05-26 04:52:27 theanets.trainer:168 RmsProp 79 loss=515.985840 err=515.985840
I 2015-05-26 04:53:20 theanets.trainer:168 RmsProp 80 loss=494.428833 err=494.428833
I 2015-05-26 04:53:21 theanets.trainer:168 validation 8 loss=1787.150024 err=1787.150024 *
I 2015-05-26 04:54:13 theanets.trainer:168 RmsProp 81 loss=461.117676 err=461.117676
I 2015-05-26 04:55:04 theanets.trainer:168 RmsProp 82 loss=443.392059 err=443.392059
I 2015-05-26 04:55:55 theanets.trainer:168 RmsProp 83 loss=436.936554 err=436.936554
I 2015-05-26 04:56:46 theanets.trainer:168 RmsProp 84 loss=423.056580 err=423.056580
I 2015-05-26 04:57:36 theanets.trainer:168 RmsProp 85 loss=415.390472 err=415.390472
I 2015-05-26 04:58:27 theanets.trainer:168 RmsProp 86 loss=398.600677 err=398.600677
I 2015-05-26 04:59:18 theanets.trainer:168 RmsProp 87 loss=385.826569 err=385.826569
I 2015-05-26 05:00:09 theanets.trainer:168 RmsProp 88 loss=385.066925 err=385.066925
I 2015-05-26 05:01:00 theanets.trainer:168 RmsProp 89 loss=358.416046 err=358.416046
I 2015-05-26 05:01:51 theanets.trainer:168 RmsProp 90 loss=352.245575 err=352.245575
I 2015-05-26 05:01:52 theanets.trainer:168 validation 9 loss=1581.076172 err=1581.076172 *
I 2015-05-26 05:02:43 theanets.trainer:168 RmsProp 91 loss=337.191376 err=337.191376
I 2015-05-26 05:03:34 theanets.trainer:168 RmsProp 92 loss=327.978058 err=327.978058
I 2015-05-26 05:04:26 theanets.trainer:168 RmsProp 93 loss=329.623016 err=329.623016
I 2015-05-26 05:05:17 theanets.trainer:168 RmsProp 94 loss=312.969177 err=312.969177
I 2015-05-26 05:06:09 theanets.trainer:168 RmsProp 95 loss=315.135834 err=315.135834
I 2015-05-26 05:07:01 theanets.trainer:168 RmsProp 96 loss=309.654816 err=309.654816
I 2015-05-26 05:07:52 theanets.trainer:168 RmsProp 97 loss=295.574066 err=295.574066
I 2015-05-26 05:08:42 theanets.trainer:168 RmsProp 98 loss=282.765350 err=282.765350
I 2015-05-26 05:09:32 theanets.trainer:168 RmsProp 99 loss=276.205780 err=276.205780
I 2015-05-26 05:10:22 theanets.trainer:168 RmsProp 100 loss=267.772614 err=267.772614
I 2015-05-26 05:10:23 theanets.trainer:168 validation 10 loss=1533.645386 err=1533.645386 *
I 2015-05-26 05:11:12 theanets.trainer:168 RmsProp 101 loss=261.171570 err=261.171570
I 2015-05-26 05:12:00 theanets.trainer:168 RmsProp 102 loss=255.256531 err=255.256531
I 2015-05-26 05:12:49 theanets.trainer:168 RmsProp 103 loss=247.833969 err=247.833969
I 2015-05-26 05:13:38 theanets.trainer:168 RmsProp 104 loss=241.023392 err=241.023392
I 2015-05-26 05:14:28 theanets.trainer:168 RmsProp 105 loss=235.760315 err=235.760315
I 2015-05-26 05:15:18 theanets.trainer:168 RmsProp 106 loss=225.159149 err=225.159149
I 2015-05-26 05:16:08 theanets.trainer:168 RmsProp 107 loss=220.069839 err=220.069839
I 2015-05-26 05:16:58 theanets.trainer:168 RmsProp 108 loss=216.085342 err=216.085342
I 2015-05-26 05:17:47 theanets.trainer:168 RmsProp 109 loss=210.069427 err=210.069427
I 2015-05-26 05:18:37 theanets.trainer:168 RmsProp 110 loss=202.678925 err=202.678925
I 2015-05-26 05:18:38 theanets.trainer:168 validation 11 loss=1408.234741 err=1408.234741 *
I 2015-05-26 05:19:27 theanets.trainer:168 RmsProp 111 loss=200.430267 err=200.430267
I 2015-05-26 05:20:16 theanets.trainer:168 RmsProp 112 loss=195.219482 err=195.219482
I 2015-05-26 05:21:06 theanets.trainer:168 RmsProp 113 loss=187.447601 err=187.447601
I 2015-05-26 05:21:56 theanets.trainer:168 RmsProp 114 loss=189.303024 err=189.303024
I 2015-05-26 05:22:46 theanets.trainer:168 RmsProp 115 loss=185.260391 err=185.260391
I 2015-05-26 05:23:36 theanets.trainer:168 RmsProp 116 loss=178.092316 err=178.092316
I 2015-05-26 05:24:26 theanets.trainer:168 RmsProp 117 loss=171.159729 err=171.159729
I 2015-05-26 05:25:16 theanets.trainer:168 RmsProp 118 loss=175.072403 err=175.072403
I 2015-05-26 05:26:05 theanets.trainer:168 RmsProp 119 loss=166.545868 err=166.545868
I 2015-05-26 05:26:55 theanets.trainer:168 RmsProp 120 loss=160.674850 err=160.674850
I 2015-05-26 05:26:55 theanets.trainer:168 validation 12 loss=1301.974487 err=1301.974487 *
I 2015-05-26 05:27:46 theanets.trainer:168 RmsProp 121 loss=153.416351 err=153.416351
I 2015-05-26 05:28:36 theanets.trainer:168 RmsProp 122 loss=151.843353 err=151.843353
I 2015-05-26 05:29:26 theanets.trainer:168 RmsProp 123 loss=148.684387 err=148.684387
I 2015-05-26 05:30:16 theanets.trainer:168 RmsProp 124 loss=143.572357 err=143.572357
I 2015-05-26 05:31:06 theanets.trainer:168 RmsProp 125 loss=138.528000 err=138.528000
I 2015-05-26 05:31:56 theanets.trainer:168 RmsProp 126 loss=138.343399 err=138.343399
I 2015-05-26 05:32:46 theanets.trainer:168 RmsProp 127 loss=133.077744 err=133.077744
I 2015-05-26 05:33:36 theanets.trainer:168 RmsProp 128 loss=129.753220 err=129.753220
I 2015-05-26 05:34:26 theanets.trainer:168 RmsProp 129 loss=127.238724 err=127.238724
I 2015-05-26 05:35:16 theanets.trainer:168 RmsProp 130 loss=125.265343 err=125.265343
I 2015-05-26 05:35:17 theanets.trainer:168 validation 13 loss=1286.718262 err=1286.718262 *
I 2015-05-26 05:36:08 theanets.trainer:168 RmsProp 131 loss=121.471855 err=121.471855
I 2015-05-26 05:36:57 theanets.trainer:168 RmsProp 132 loss=115.878540 err=115.878540
I 2015-05-26 05:37:44 theanets.trainer:168 RmsProp 133 loss=115.101776 err=115.101776
I 2015-05-26 05:38:32 theanets.trainer:168 RmsProp 134 loss=109.916756 err=109.916756
I 2015-05-26 05:39:20 theanets.trainer:168 RmsProp 135 loss=107.938225 err=107.938225
I 2015-05-26 05:40:07 theanets.trainer:168 RmsProp 136 loss=101.469864 err=101.469864
I 2015-05-26 05:40:54 theanets.trainer:168 RmsProp 137 loss=101.185921 err=101.185921
I 2015-05-26 05:41:41 theanets.trainer:168 RmsProp 138 loss=102.611130 err=102.611130
I 2015-05-26 05:42:28 theanets.trainer:168 RmsProp 139 loss=98.864044 err=98.864044
I 2015-05-26 05:43:15 theanets.trainer:168 RmsProp 140 loss=95.223473 err=95.223473
I 2015-05-26 05:43:16 theanets.trainer:168 validation 14 loss=1241.298218 err=1241.298218 *
I 2015-05-26 05:44:04 theanets.trainer:168 RmsProp 141 loss=92.726532 err=92.726532
I 2015-05-26 05:44:51 theanets.trainer:168 RmsProp 142 loss=92.724335 err=92.724335
I 2015-05-26 05:45:39 theanets.trainer:168 RmsProp 143 loss=88.911240 err=88.911240
I 2015-05-26 05:46:26 theanets.trainer:168 RmsProp 144 loss=83.985107 err=83.985107
I 2015-05-26 05:47:14 theanets.trainer:168 RmsProp 145 loss=82.836227 err=82.836227
I 2015-05-26 05:48:02 theanets.trainer:168 RmsProp 146 loss=81.542877 err=81.542877
I 2015-05-26 05:48:50 theanets.trainer:168 RmsProp 147 loss=81.220932 err=81.220932
I 2015-05-26 05:49:38 theanets.trainer:168 RmsProp 148 loss=79.047295 err=79.047295
I 2015-05-26 05:50:26 theanets.trainer:168 RmsProp 149 loss=75.799698 err=75.799698
I 2015-05-26 05:51:14 theanets.trainer:168 RmsProp 150 loss=75.596237 err=75.596237
I 2015-05-26 05:51:15 theanets.trainer:168 validation 15 loss=1182.208618 err=1182.208618 *
I 2015-05-26 05:52:01 theanets.trainer:168 RmsProp 151 loss=74.473061 err=74.473061
I 2015-05-26 05:52:48 theanets.trainer:168 RmsProp 152 loss=71.878044 err=71.878044
I 2015-05-26 05:53:35 theanets.trainer:168 RmsProp 153 loss=70.199547 err=70.199547
I 2015-05-26 05:54:23 theanets.trainer:168 RmsProp 154 loss=69.573021 err=69.573021
I 2015-05-26 05:55:09 theanets.trainer:168 RmsProp 155 loss=67.013420 err=67.013420
I 2015-05-26 05:55:57 theanets.trainer:168 RmsProp 156 loss=66.313202 err=66.313202
I 2015-05-26 05:56:45 theanets.trainer:168 RmsProp 157 loss=63.345100 err=63.345100
I 2015-05-26 05:57:33 theanets.trainer:168 RmsProp 158 loss=62.531261 err=62.531261
I 2015-05-26 05:58:20 theanets.trainer:168 RmsProp 159 loss=61.282288 err=61.282288
I 2015-05-26 05:59:07 theanets.trainer:168 RmsProp 160 loss=61.197136 err=61.197136
I 2015-05-26 05:59:08 theanets.trainer:168 validation 16 loss=1199.853394 err=1199.853394
I 2015-05-26 05:59:56 theanets.trainer:168 RmsProp 161 loss=56.964176 err=56.964176
I 2015-05-26 06:00:43 theanets.trainer:168 RmsProp 162 loss=57.246567 err=57.246567
I 2015-05-26 06:01:31 theanets.trainer:168 RmsProp 163 loss=56.296154 err=56.296154
I 2015-05-26 06:02:18 theanets.trainer:168 RmsProp 164 loss=56.924618 err=56.924618
I 2015-05-26 06:03:06 theanets.trainer:168 RmsProp 165 loss=52.296177 err=52.296177
I 2015-05-26 06:03:53 theanets.trainer:168 RmsProp 166 loss=52.345737 err=52.345737
I 2015-05-26 06:04:41 theanets.trainer:168 RmsProp 167 loss=49.974854 err=49.974854
I 2015-05-26 06:05:28 theanets.trainer:168 RmsProp 168 loss=51.079521 err=51.079521
I 2015-05-26 06:06:15 theanets.trainer:168 RmsProp 169 loss=49.293560 err=49.293560
I 2015-05-26 06:07:02 theanets.trainer:168 RmsProp 170 loss=48.121227 err=48.121227
I 2015-05-26 06:07:03 theanets.trainer:168 validation 17 loss=1142.051636 err=1142.051636 *
I 2015-05-26 06:07:49 theanets.trainer:168 RmsProp 171 loss=46.345470 err=46.345470
I 2015-05-26 06:08:35 theanets.trainer:168 RmsProp 172 loss=45.190716 err=45.190716
I 2015-05-26 06:09:23 theanets.trainer:168 RmsProp 173 loss=43.351128 err=43.351128
I 2015-05-26 06:10:10 theanets.trainer:168 RmsProp 174 loss=45.046684 err=45.046684
I 2015-05-26 06:10:58 theanets.trainer:168 RmsProp 175 loss=41.798611 err=41.798611
I 2015-05-26 06:11:45 theanets.trainer:168 RmsProp 176 loss=41.409084 err=41.409084
I 2015-05-26 06:12:33 theanets.trainer:168 RmsProp 177 loss=40.771412 err=40.771412
I 2015-05-26 06:13:21 theanets.trainer:168 RmsProp 178 loss=39.728161 err=39.728161
I 2015-05-26 06:14:09 theanets.trainer:168 RmsProp 179 loss=39.942463 err=39.942463
I 2015-05-26 06:14:57 theanets.trainer:168 RmsProp 180 loss=40.397415 err=40.397415
I 2015-05-26 06:14:58 theanets.trainer:168 validation 18 loss=1149.115723 err=1149.115723
I 2015-05-26 06:15:45 theanets.trainer:168 RmsProp 181 loss=37.400497 err=37.400497
I 2015-05-26 06:16:33 theanets.trainer:168 RmsProp 182 loss=36.612694 err=36.612694
I 2015-05-26 06:17:21 theanets.trainer:168 RmsProp 183 loss=37.448631 err=37.448631
I 2015-05-26 06:18:09 theanets.trainer:168 RmsProp 184 loss=34.984890 err=34.984890
I 2015-05-26 06:18:57 theanets.trainer:168 RmsProp 185 loss=35.752880 err=35.752880
I 2015-05-26 06:19:44 theanets.trainer:168 RmsProp 186 loss=35.489929 err=35.489929
I 2015-05-26 06:20:30 theanets.trainer:168 RmsProp 187 loss=33.626354 err=33.626354
I 2015-05-26 06:21:17 theanets.trainer:168 RmsProp 188 loss=32.359085 err=32.359085
I 2015-05-26 06:22:05 theanets.trainer:168 RmsProp 189 loss=30.640734 err=30.640734
I 2015-05-26 06:22:52 theanets.trainer:168 RmsProp 190 loss=31.174322 err=31.174322
I 2015-05-26 06:22:53 theanets.trainer:168 validation 19 loss=1171.861572 err=1171.861572
I 2015-05-26 06:23:39 theanets.trainer:168 RmsProp 191 loss=31.447239 err=31.447239
I 2015-05-26 06:24:25 theanets.trainer:168 RmsProp 192 loss=31.470133 err=31.470133
I 2015-05-26 06:25:12 theanets.trainer:168 RmsProp 193 loss=30.060926 err=30.060926
I 2015-05-26 06:26:00 theanets.trainer:168 RmsProp 194 loss=28.857248 err=28.857248
I 2015-05-26 06:26:47 theanets.trainer:168 RmsProp 195 loss=29.340498 err=29.340498
I 2015-05-26 06:27:34 theanets.trainer:168 RmsProp 196 loss=27.820047 err=27.820047
I 2015-05-26 06:28:22 theanets.trainer:168 RmsProp 197 loss=27.088354 err=27.088354
I 2015-05-26 06:29:10 theanets.trainer:168 RmsProp 198 loss=26.698919 err=26.698919
I 2015-05-26 06:29:58 theanets.trainer:168 RmsProp 199 loss=24.892164 err=24.892164
I 2015-05-26 06:30:45 theanets.trainer:168 RmsProp 200 loss=25.567799 err=25.567799
I 2015-05-26 06:30:46 theanets.trainer:168 validation 20 loss=1221.411499 err=1221.411499
I 2015-05-26 06:31:34 theanets.trainer:168 RmsProp 201 loss=30.019514 err=30.019514
I 2015-05-26 06:32:22 theanets.trainer:168 RmsProp 202 loss=24.940590 err=24.940590
I 2015-05-26 06:33:10 theanets.trainer:168 RmsProp 203 loss=24.070253 err=24.070253
I 2015-05-26 06:33:58 theanets.trainer:168 RmsProp 204 loss=24.558960 err=24.558960
I 2015-05-26 06:34:44 theanets.trainer:168 RmsProp 205 loss=23.170065 err=23.170065
I 2015-05-26 06:35:29 theanets.trainer:168 RmsProp 206 loss=21.627359 err=21.627359
I 2015-05-26 06:36:15 theanets.trainer:168 RmsProp 207 loss=21.032421 err=21.032421
I 2015-05-26 06:37:00 theanets.trainer:168 RmsProp 208 loss=24.599070 err=24.599070
I 2015-05-26 06:37:46 theanets.trainer:168 RmsProp 209 loss=21.954014 err=21.954014
I 2015-05-26 06:38:31 theanets.trainer:168 RmsProp 210 loss=21.823835 err=21.823835
I 2015-05-26 06:38:32 theanets.trainer:168 validation 21 loss=1144.454102 err=1144.454102
I 2015-05-26 06:39:18 theanets.trainer:168 RmsProp 211 loss=19.488895 err=19.488895
I 2015-05-26 06:40:04 theanets.trainer:168 RmsProp 212 loss=22.793453 err=22.793453
I 2015-05-26 06:40:47 theanets.trainer:168 RmsProp 213 loss=19.710995 err=19.710995
I 2015-05-26 06:41:31 theanets.trainer:168 RmsProp 214 loss=18.951281 err=18.951281
I 2015-05-26 06:42:13 theanets.trainer:168 RmsProp 215 loss=18.807564 err=18.807564
I 2015-05-26 06:42:56 theanets.trainer:168 RmsProp 216 loss=18.807062 err=18.807062
I 2015-05-26 06:43:38 theanets.trainer:168 RmsProp 217 loss=18.430225 err=18.430225
I 2015-05-26 06:44:21 theanets.trainer:168 RmsProp 218 loss=18.265093 err=18.265093
I 2015-05-26 06:45:04 theanets.trainer:168 RmsProp 219 loss=17.698977 err=17.698977
I 2015-05-26 06:45:47 theanets.trainer:168 RmsProp 220 loss=17.018522 err=17.018522
I 2015-05-26 06:45:48 theanets.trainer:168 validation 22 loss=1187.520508 err=1187.520508
I 2015-05-26 06:45:48 theanets.trainer:252 patience elapsed!
I 2015-05-26 06:45:48 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 06:45:48 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 06:45:48 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 06:45:48 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 06:45:48 theanets.main:89 --batch_size = 1024
I 2015-05-26 06:45:48 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 06:45:48 theanets.main:89 --hidden_l1 = None
I 2015-05-26 06:45:48 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 06:45:48 theanets.main:89 --train_batches = 10
I 2015-05-26 06:45:48 theanets.main:89 --valid_batches = 2
I 2015-05-26 06:45:48 theanets.main:89 --weight_l1 = None
I 2015-05-26 06:45:48 theanets.main:89 --weight_l2 = None
I 2015-05-26 06:45:48 theanets.trainer:134 compiling evaluation function
I 2015-05-26 06:45:58 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 06:47:39 theanets.trainer:168 validation 0 loss=2198.166016 err=2198.166016 *
I 2015-05-26 06:47:54 theanets.trainer:168 RmsProp 1 loss=40.505196 err=40.505196
I 2015-05-26 06:48:08 theanets.trainer:168 RmsProp 2 loss=28.182709 err=28.182709
I 2015-05-26 06:48:22 theanets.trainer:168 RmsProp 3 loss=21.461891 err=21.461891
I 2015-05-26 06:48:36 theanets.trainer:168 RmsProp 4 loss=17.881279 err=17.881279
I 2015-05-26 06:48:50 theanets.trainer:168 RmsProp 5 loss=14.955297 err=14.955297
I 2015-05-26 06:49:04 theanets.trainer:168 RmsProp 6 loss=13.020940 err=13.020940
I 2015-05-26 06:49:19 theanets.trainer:168 RmsProp 7 loss=10.770987 err=10.770987
I 2015-05-26 06:49:33 theanets.trainer:168 RmsProp 8 loss=9.371181 err=9.371181
I 2015-05-26 06:49:47 theanets.trainer:168 RmsProp 9 loss=7.950418 err=7.950418
I 2015-05-26 06:50:01 theanets.trainer:168 RmsProp 10 loss=6.923681 err=6.923681
I 2015-05-26 06:50:02 theanets.trainer:168 validation 1 loss=1938.258789 err=1938.258789 *
I 2015-05-26 06:50:16 theanets.trainer:168 RmsProp 11 loss=6.252093 err=6.252093
I 2015-05-26 06:50:30 theanets.trainer:168 RmsProp 12 loss=5.899580 err=5.899580
I 2015-05-26 06:50:45 theanets.trainer:168 RmsProp 13 loss=5.286700 err=5.286700
I 2015-05-26 06:50:59 theanets.trainer:168 RmsProp 14 loss=4.985001 err=4.985001
I 2015-05-26 06:51:14 theanets.trainer:168 RmsProp 15 loss=4.618487 err=4.618487
I 2015-05-26 06:51:28 theanets.trainer:168 RmsProp 16 loss=4.257805 err=4.257805
I 2015-05-26 06:51:42 theanets.trainer:168 RmsProp 17 loss=4.072179 err=4.072179
I 2015-05-26 06:51:57 theanets.trainer:168 RmsProp 18 loss=3.862983 err=3.862983
I 2015-05-26 06:52:11 theanets.trainer:168 RmsProp 19 loss=3.628295 err=3.628295
I 2015-05-26 06:52:25 theanets.trainer:168 RmsProp 20 loss=3.441550 err=3.441550
I 2015-05-26 06:52:26 theanets.trainer:168 validation 2 loss=1871.077148 err=1871.077148 *
I 2015-05-26 06:52:40 theanets.trainer:168 RmsProp 21 loss=3.245517 err=3.245517
I 2015-05-26 06:52:54 theanets.trainer:168 RmsProp 22 loss=3.107913 err=3.107913
I 2015-05-26 06:53:08 theanets.trainer:168 RmsProp 23 loss=3.049037 err=3.049037
I 2015-05-26 06:53:22 theanets.trainer:168 RmsProp 24 loss=2.888137 err=2.888137
I 2015-05-26 06:53:36 theanets.trainer:168 RmsProp 25 loss=2.800113 err=2.800113
I 2015-05-26 06:53:50 theanets.trainer:168 RmsProp 26 loss=2.663844 err=2.663844
I 2015-05-26 06:54:04 theanets.trainer:168 RmsProp 27 loss=2.576182 err=2.576182
I 2015-05-26 06:54:18 theanets.trainer:168 RmsProp 28 loss=2.486432 err=2.486432
I 2015-05-26 06:54:32 theanets.trainer:168 RmsProp 29 loss=2.336337 err=2.336337
I 2015-05-26 06:54:46 theanets.trainer:168 RmsProp 30 loss=2.326634 err=2.326634
I 2015-05-26 06:54:47 theanets.trainer:168 validation 3 loss=1838.563843 err=1838.563843 *
I 2015-05-26 06:55:01 theanets.trainer:168 RmsProp 31 loss=2.224390 err=2.224390
I 2015-05-26 06:55:15 theanets.trainer:168 RmsProp 32 loss=2.196976 err=2.196976
I 2015-05-26 06:55:29 theanets.trainer:168 RmsProp 33 loss=2.094538 err=2.094538
I 2015-05-26 06:55:44 theanets.trainer:168 RmsProp 34 loss=2.077385 err=2.077385
I 2015-05-26 06:55:58 theanets.trainer:168 RmsProp 35 loss=2.063955 err=2.063955
I 2015-05-26 06:56:13 theanets.trainer:168 RmsProp 36 loss=1.971484 err=1.971484
I 2015-05-26 06:56:27 theanets.trainer:168 RmsProp 37 loss=1.911795 err=1.911795
I 2015-05-26 06:56:42 theanets.trainer:168 RmsProp 38 loss=1.866628 err=1.866628
I 2015-05-26 06:56:56 theanets.trainer:168 RmsProp 39 loss=1.836754 err=1.836754
I 2015-05-26 06:57:10 theanets.trainer:168 RmsProp 40 loss=1.763496 err=1.763496
I 2015-05-26 06:57:11 theanets.trainer:168 validation 4 loss=1806.363281 err=1806.363281 *
I 2015-05-26 06:57:24 theanets.trainer:168 RmsProp 41 loss=1.747378 err=1.747378
I 2015-05-26 06:57:37 theanets.trainer:168 RmsProp 42 loss=1.681977 err=1.681977
I 2015-05-26 06:57:50 theanets.trainer:168 RmsProp 43 loss=1.662075 err=1.662075
I 2015-05-26 06:58:03 theanets.trainer:168 RmsProp 44 loss=1.615767 err=1.615767
I 2015-05-26 06:58:16 theanets.trainer:168 RmsProp 45 loss=1.603514 err=1.603514
I 2015-05-26 06:58:29 theanets.trainer:168 RmsProp 46 loss=1.547416 err=1.547416
I 2015-05-26 06:58:41 theanets.trainer:168 RmsProp 47 loss=1.537992 err=1.537992
I 2015-05-26 06:58:54 theanets.trainer:168 RmsProp 48 loss=1.496328 err=1.496328
I 2015-05-26 06:59:07 theanets.trainer:168 RmsProp 49 loss=1.447247 err=1.447247
I 2015-05-26 06:59:19 theanets.trainer:168 RmsProp 50 loss=1.452171 err=1.452171
I 2015-05-26 06:59:20 theanets.trainer:168 validation 5 loss=1794.787476 err=1794.787476 *
I 2015-05-26 06:59:33 theanets.trainer:168 RmsProp 51 loss=1.405374 err=1.405374
I 2015-05-26 06:59:45 theanets.trainer:168 RmsProp 52 loss=1.468314 err=1.468314
I 2015-05-26 06:59:58 theanets.trainer:168 RmsProp 53 loss=1.314987 err=1.314987
I 2015-05-26 07:00:10 theanets.trainer:168 RmsProp 54 loss=1.363939 err=1.363939
I 2015-05-26 07:00:23 theanets.trainer:168 RmsProp 55 loss=1.344899 err=1.344899
I 2015-05-26 07:00:35 theanets.trainer:168 RmsProp 56 loss=1.321746 err=1.321746
I 2015-05-26 07:00:47 theanets.trainer:168 RmsProp 57 loss=1.302296 err=1.302296
I 2015-05-26 07:01:00 theanets.trainer:168 RmsProp 58 loss=1.249775 err=1.249775
I 2015-05-26 07:01:12 theanets.trainer:168 RmsProp 59 loss=1.259481 err=1.259481
I 2015-05-26 07:01:24 theanets.trainer:168 RmsProp 60 loss=1.276112 err=1.276112
I 2015-05-26 07:01:25 theanets.trainer:168 validation 6 loss=1778.517944 err=1778.517944 *
I 2015-05-26 07:01:37 theanets.trainer:168 RmsProp 61 loss=1.189584 err=1.189584
I 2015-05-26 07:01:50 theanets.trainer:168 RmsProp 62 loss=1.199368 err=1.199368
I 2015-05-26 07:02:03 theanets.trainer:168 RmsProp 63 loss=1.189644 err=1.189644
I 2015-05-26 07:02:16 theanets.trainer:168 RmsProp 64 loss=1.158800 err=1.158800
I 2015-05-26 07:02:30 theanets.trainer:168 RmsProp 65 loss=1.122478 err=1.122478
I 2015-05-26 07:02:43 theanets.trainer:168 RmsProp 66 loss=1.123298 err=1.123298
I 2015-05-26 07:02:56 theanets.trainer:168 RmsProp 67 loss=1.151898 err=1.151898
I 2015-05-26 07:03:08 theanets.trainer:168 RmsProp 68 loss=1.091153 err=1.091153
I 2015-05-26 07:03:21 theanets.trainer:168 RmsProp 69 loss=1.091449 err=1.091449
I 2015-05-26 07:03:34 theanets.trainer:168 RmsProp 70 loss=1.054366 err=1.054366
I 2015-05-26 07:03:35 theanets.trainer:168 validation 7 loss=1772.624878 err=1772.624878 *
I 2015-05-26 07:03:48 theanets.trainer:168 RmsProp 71 loss=1.053323 err=1.053323
I 2015-05-26 07:04:01 theanets.trainer:168 RmsProp 72 loss=1.020284 err=1.020284
I 2015-05-26 07:04:14 theanets.trainer:168 RmsProp 73 loss=1.040946 err=1.040946
I 2015-05-26 07:04:27 theanets.trainer:168 RmsProp 74 loss=0.991474 err=0.991474
I 2015-05-26 07:04:39 theanets.trainer:168 RmsProp 75 loss=1.046837 err=1.046837
I 2015-05-26 07:04:52 theanets.trainer:168 RmsProp 76 loss=1.022522 err=1.022522
I 2015-05-26 07:05:05 theanets.trainer:168 RmsProp 77 loss=1.001638 err=1.001638
I 2015-05-26 07:05:17 theanets.trainer:168 RmsProp 78 loss=0.933091 err=0.933091
I 2015-05-26 07:05:30 theanets.trainer:168 RmsProp 79 loss=0.937806 err=0.937806
I 2015-05-26 07:05:43 theanets.trainer:168 RmsProp 80 loss=0.966791 err=0.966791
I 2015-05-26 07:05:43 theanets.trainer:168 validation 8 loss=1756.334595 err=1756.334595 *
I 2015-05-26 07:05:56 theanets.trainer:168 RmsProp 81 loss=0.950964 err=0.950964
I 2015-05-26 07:06:08 theanets.trainer:168 RmsProp 82 loss=0.921149 err=0.921149
I 2015-05-26 07:06:21 theanets.trainer:168 RmsProp 83 loss=0.923315 err=0.923315
I 2015-05-26 07:06:33 theanets.trainer:168 RmsProp 84 loss=0.910363 err=0.910363
I 2015-05-26 07:06:46 theanets.trainer:168 RmsProp 85 loss=0.909583 err=0.909583
I 2015-05-26 07:06:59 theanets.trainer:168 RmsProp 86 loss=0.893696 err=0.893696
I 2015-05-26 07:07:12 theanets.trainer:168 RmsProp 87 loss=0.860534 err=0.860534
I 2015-05-26 07:07:25 theanets.trainer:168 RmsProp 88 loss=0.877355 err=0.877355
I 2015-05-26 07:07:39 theanets.trainer:168 RmsProp 89 loss=0.858760 err=0.858760
I 2015-05-26 07:07:52 theanets.trainer:168 RmsProp 90 loss=0.840515 err=0.840515
I 2015-05-26 07:07:52 theanets.trainer:168 validation 9 loss=1751.096558 err=1751.096558 *
I 2015-05-26 07:08:05 theanets.trainer:168 RmsProp 91 loss=0.825890 err=0.825890
I 2015-05-26 07:08:18 theanets.trainer:168 RmsProp 92 loss=0.821276 err=0.821276
I 2015-05-26 07:08:31 theanets.trainer:168 RmsProp 93 loss=0.805535 err=0.805535
I 2015-05-26 07:08:44 theanets.trainer:168 RmsProp 94 loss=0.831697 err=0.831697
I 2015-05-26 07:08:57 theanets.trainer:168 RmsProp 95 loss=0.825282 err=0.825282
I 2015-05-26 07:09:10 theanets.trainer:168 RmsProp 96 loss=0.789142 err=0.789142
I 2015-05-26 07:09:22 theanets.trainer:168 RmsProp 97 loss=0.782765 err=0.782765
I 2015-05-26 07:09:35 theanets.trainer:168 RmsProp 98 loss=0.786450 err=0.786450
I 2015-05-26 07:09:48 theanets.trainer:168 RmsProp 99 loss=0.749691 err=0.749691
I 2015-05-26 07:10:01 theanets.trainer:168 RmsProp 100 loss=0.809467 err=0.809467
I 2015-05-26 07:10:02 theanets.trainer:168 validation 10 loss=1749.662354 err=1749.662354 *
I 2015-05-26 07:10:14 theanets.trainer:168 RmsProp 101 loss=0.760786 err=0.760786
I 2015-05-26 07:10:27 theanets.trainer:168 RmsProp 102 loss=0.755843 err=0.755843
I 2015-05-26 07:10:40 theanets.trainer:168 RmsProp 103 loss=0.749343 err=0.749343
I 2015-05-26 07:10:53 theanets.trainer:168 RmsProp 104 loss=0.726766 err=0.726766
I 2015-05-26 07:11:06 theanets.trainer:168 RmsProp 105 loss=0.720275 err=0.720275
I 2015-05-26 07:11:19 theanets.trainer:168 RmsProp 106 loss=0.738460 err=0.738460
I 2015-05-26 07:11:32 theanets.trainer:168 RmsProp 107 loss=0.682140 err=0.682140
I 2015-05-26 07:11:45 theanets.trainer:168 RmsProp 108 loss=0.710253 err=0.710253
I 2015-05-26 07:11:58 theanets.trainer:168 RmsProp 109 loss=0.711329 err=0.711329
I 2015-05-26 07:12:10 theanets.trainer:168 RmsProp 110 loss=0.707151 err=0.707151
I 2015-05-26 07:12:10 theanets.trainer:168 validation 11 loss=1741.329956 err=1741.329956 *
I 2015-05-26 07:12:23 theanets.trainer:168 RmsProp 111 loss=0.692338 err=0.692338
I 2015-05-26 07:12:35 theanets.trainer:168 RmsProp 112 loss=0.711129 err=0.711129
I 2015-05-26 07:12:48 theanets.trainer:168 RmsProp 113 loss=0.676503 err=0.676503
I 2015-05-26 07:13:00 theanets.trainer:168 RmsProp 114 loss=0.674027 err=0.674027
I 2015-05-26 07:13:12 theanets.trainer:168 RmsProp 115 loss=0.642527 err=0.642527
I 2015-05-26 07:13:24 theanets.trainer:168 RmsProp 116 loss=0.685379 err=0.685379
I 2015-05-26 07:13:36 theanets.trainer:168 RmsProp 117 loss=0.642457 err=0.642457
I 2015-05-26 07:13:49 theanets.trainer:168 RmsProp 118 loss=0.669242 err=0.669242
I 2015-05-26 07:14:01 theanets.trainer:168 RmsProp 119 loss=0.661677 err=0.661677
I 2015-05-26 07:14:13 theanets.trainer:168 RmsProp 120 loss=0.666406 err=0.666406
I 2015-05-26 07:14:14 theanets.trainer:168 validation 12 loss=1736.838745 err=1736.838745 *
I 2015-05-26 07:14:26 theanets.trainer:168 RmsProp 121 loss=0.643579 err=0.643579
I 2015-05-26 07:14:39 theanets.trainer:168 RmsProp 122 loss=0.645437 err=0.645437
I 2015-05-26 07:14:52 theanets.trainer:168 RmsProp 123 loss=0.625777 err=0.625777
I 2015-05-26 07:15:04 theanets.trainer:168 RmsProp 124 loss=0.625943 err=0.625943
I 2015-05-26 07:15:17 theanets.trainer:168 RmsProp 125 loss=0.627896 err=0.627896
I 2015-05-26 07:15:30 theanets.trainer:168 RmsProp 126 loss=0.605804 err=0.605804
I 2015-05-26 07:15:43 theanets.trainer:168 RmsProp 127 loss=0.624958 err=0.624958
I 2015-05-26 07:15:55 theanets.trainer:168 RmsProp 128 loss=0.632732 err=0.632732
I 2015-05-26 07:16:07 theanets.trainer:168 RmsProp 129 loss=0.613633 err=0.613633
I 2015-05-26 07:16:20 theanets.trainer:168 RmsProp 130 loss=0.603685 err=0.603685
I 2015-05-26 07:16:21 theanets.trainer:168 validation 13 loss=1729.263672 err=1729.263672 *
I 2015-05-26 07:16:34 theanets.trainer:168 RmsProp 131 loss=0.592935 err=0.592935
I 2015-05-26 07:16:47 theanets.trainer:168 RmsProp 132 loss=0.591074 err=0.591074
I 2015-05-26 07:16:59 theanets.trainer:168 RmsProp 133 loss=0.590375 err=0.590375
I 2015-05-26 07:17:12 theanets.trainer:168 RmsProp 134 loss=0.582364 err=0.582364
I 2015-05-26 07:17:25 theanets.trainer:168 RmsProp 135 loss=0.582246 err=0.582246
I 2015-05-26 07:17:37 theanets.trainer:168 RmsProp 136 loss=0.593359 err=0.593359
I 2015-05-26 07:17:50 theanets.trainer:168 RmsProp 137 loss=0.546231 err=0.546231
I 2015-05-26 07:18:02 theanets.trainer:168 RmsProp 138 loss=0.573895 err=0.573895
I 2015-05-26 07:18:15 theanets.trainer:168 RmsProp 139 loss=0.566499 err=0.566499
I 2015-05-26 07:18:27 theanets.trainer:168 RmsProp 140 loss=0.588080 err=0.588080
I 2015-05-26 07:18:28 theanets.trainer:168 validation 14 loss=1727.382080 err=1727.382080 *
I 2015-05-26 07:18:40 theanets.trainer:168 RmsProp 141 loss=0.563915 err=0.563915
I 2015-05-26 07:18:53 theanets.trainer:168 RmsProp 142 loss=0.555060 err=0.555060
I 2015-05-26 07:19:06 theanets.trainer:168 RmsProp 143 loss=0.535865 err=0.535865
I 2015-05-26 07:19:19 theanets.trainer:168 RmsProp 144 loss=0.533610 err=0.533610
I 2015-05-26 07:19:32 theanets.trainer:168 RmsProp 145 loss=0.539079 err=0.539079
I 2015-05-26 07:19:45 theanets.trainer:168 RmsProp 146 loss=0.559650 err=0.559650
I 2015-05-26 07:19:58 theanets.trainer:168 RmsProp 147 loss=0.544417 err=0.544417
I 2015-05-26 07:20:11 theanets.trainer:168 RmsProp 148 loss=0.529274 err=0.529274
I 2015-05-26 07:20:24 theanets.trainer:168 RmsProp 149 loss=0.546488 err=0.546488
I 2015-05-26 07:20:36 theanets.trainer:168 RmsProp 150 loss=0.527901 err=0.527901
I 2015-05-26 07:20:37 theanets.trainer:168 validation 15 loss=1720.856689 err=1720.856689 *
I 2015-05-26 07:20:49 theanets.trainer:168 RmsProp 151 loss=0.499403 err=0.499403
I 2015-05-26 07:21:02 theanets.trainer:168 RmsProp 152 loss=0.520095 err=0.520095
I 2015-05-26 07:21:15 theanets.trainer:168 RmsProp 153 loss=0.524436 err=0.524436
I 2015-05-26 07:21:28 theanets.trainer:168 RmsProp 154 loss=0.508478 err=0.508478
I 2015-05-26 07:21:41 theanets.trainer:168 RmsProp 155 loss=0.529675 err=0.529675
I 2015-05-26 07:21:54 theanets.trainer:168 RmsProp 156 loss=0.531514 err=0.531514
I 2015-05-26 07:22:06 theanets.trainer:168 RmsProp 157 loss=0.489300 err=0.489300
I 2015-05-26 07:22:19 theanets.trainer:168 RmsProp 158 loss=0.508053 err=0.508053
I 2015-05-26 07:22:32 theanets.trainer:168 RmsProp 159 loss=0.484075 err=0.484075
I 2015-05-26 07:22:45 theanets.trainer:168 RmsProp 160 loss=0.494730 err=0.494730
I 2015-05-26 07:22:45 theanets.trainer:168 validation 16 loss=1713.538330 err=1713.538330 *
I 2015-05-26 07:22:58 theanets.trainer:168 RmsProp 161 loss=0.503655 err=0.503655
I 2015-05-26 07:23:11 theanets.trainer:168 RmsProp 162 loss=0.478501 err=0.478501
I 2015-05-26 07:23:24 theanets.trainer:168 RmsProp 163 loss=0.480001 err=0.480001
I 2015-05-26 07:23:37 theanets.trainer:168 RmsProp 164 loss=0.495238 err=0.495238
I 2015-05-26 07:23:50 theanets.trainer:168 RmsProp 165 loss=0.477219 err=0.477219
I 2015-05-26 07:24:03 theanets.trainer:168 RmsProp 166 loss=0.481878 err=0.481878
I 2015-05-26 07:24:16 theanets.trainer:168 RmsProp 167 loss=0.469279 err=0.469279
I 2015-05-26 07:24:29 theanets.trainer:168 RmsProp 168 loss=0.476566 err=0.476566
I 2015-05-26 07:24:42 theanets.trainer:168 RmsProp 169 loss=0.479610 err=0.479610
I 2015-05-26 07:24:54 theanets.trainer:168 RmsProp 170 loss=0.472477 err=0.472477
I 2015-05-26 07:24:54 theanets.trainer:168 validation 17 loss=1711.855469 err=1711.855469 *
I 2015-05-26 07:25:07 theanets.trainer:168 RmsProp 171 loss=0.457194 err=0.457194
I 2015-05-26 07:25:19 theanets.trainer:168 RmsProp 172 loss=0.472205 err=0.472205
I 2015-05-26 07:25:31 theanets.trainer:168 RmsProp 173 loss=0.465228 err=0.465228
I 2015-05-26 07:25:43 theanets.trainer:168 RmsProp 174 loss=0.489812 err=0.489812
I 2015-05-26 07:25:56 theanets.trainer:168 RmsProp 175 loss=0.445251 err=0.445251
I 2015-05-26 07:26:08 theanets.trainer:168 RmsProp 176 loss=0.441201 err=0.441201
I 2015-05-26 07:26:20 theanets.trainer:168 RmsProp 177 loss=0.481689 err=0.481689
I 2015-05-26 07:26:32 theanets.trainer:168 RmsProp 178 loss=0.470179 err=0.470179
I 2015-05-26 07:26:44 theanets.trainer:168 RmsProp 179 loss=0.450761 err=0.450761
I 2015-05-26 07:26:56 theanets.trainer:168 RmsProp 180 loss=0.431116 err=0.431116
I 2015-05-26 07:26:56 theanets.trainer:168 validation 18 loss=1708.526978 err=1708.526978 *
I 2015-05-26 07:27:08 theanets.trainer:168 RmsProp 181 loss=0.440010 err=0.440010
I 2015-05-26 07:27:20 theanets.trainer:168 RmsProp 182 loss=0.452891 err=0.452891
I 2015-05-26 07:27:32 theanets.trainer:168 RmsProp 183 loss=0.432356 err=0.432356
I 2015-05-26 07:27:44 theanets.trainer:168 RmsProp 184 loss=0.431761 err=0.431761
I 2015-05-26 07:27:56 theanets.trainer:168 RmsProp 185 loss=0.428251 err=0.428251
I 2015-05-26 07:28:08 theanets.trainer:168 RmsProp 186 loss=0.444634 err=0.444634
I 2015-05-26 07:28:20 theanets.trainer:168 RmsProp 187 loss=0.436960 err=0.436960
I 2015-05-26 07:28:32 theanets.trainer:168 RmsProp 188 loss=0.433107 err=0.433107
I 2015-05-26 07:28:44 theanets.trainer:168 RmsProp 189 loss=0.431196 err=0.431196
I 2015-05-26 07:28:56 theanets.trainer:168 RmsProp 190 loss=0.405799 err=0.405799
I 2015-05-26 07:28:57 theanets.trainer:168 validation 19 loss=1704.930664 err=1704.930664 *
I 2015-05-26 07:29:08 theanets.trainer:168 RmsProp 191 loss=0.429470 err=0.429470
I 2015-05-26 07:29:20 theanets.trainer:168 RmsProp 192 loss=0.427983 err=0.427983
I 2015-05-26 07:29:32 theanets.trainer:168 RmsProp 193 loss=0.414583 err=0.414583
I 2015-05-26 07:29:44 theanets.trainer:168 RmsProp 194 loss=0.409180 err=0.409180
I 2015-05-26 07:29:57 theanets.trainer:168 RmsProp 195 loss=0.436877 err=0.436877
I 2015-05-26 07:30:09 theanets.trainer:168 RmsProp 196 loss=0.409616 err=0.409616
I 2015-05-26 07:30:21 theanets.trainer:168 RmsProp 197 loss=0.404740 err=0.404740
I 2015-05-26 07:30:33 theanets.trainer:168 RmsProp 198 loss=0.409152 err=0.409152
I 2015-05-26 07:30:45 theanets.trainer:168 RmsProp 199 loss=0.385701 err=0.385701
I 2015-05-26 07:30:57 theanets.trainer:168 RmsProp 200 loss=0.384493 err=0.384493
I 2015-05-26 07:30:57 theanets.trainer:168 validation 20 loss=1707.003174 err=1707.003174
I 2015-05-26 07:31:09 theanets.trainer:168 RmsProp 201 loss=0.430296 err=0.430296
I 2015-05-26 07:31:21 theanets.trainer:168 RmsProp 202 loss=0.394416 err=0.394416
I 2015-05-26 07:31:33 theanets.trainer:168 RmsProp 203 loss=0.404498 err=0.404498
I 2015-05-26 07:31:44 theanets.trainer:168 RmsProp 204 loss=0.389179 err=0.389179
I 2015-05-26 07:31:56 theanets.trainer:168 RmsProp 205 loss=0.383729 err=0.383729
I 2015-05-26 07:32:08 theanets.trainer:168 RmsProp 206 loss=0.426650 err=0.426650
I 2015-05-26 07:32:19 theanets.trainer:168 RmsProp 207 loss=0.383857 err=0.383857
I 2015-05-26 07:32:31 theanets.trainer:168 RmsProp 208 loss=0.389436 err=0.389436
I 2015-05-26 07:32:42 theanets.trainer:168 RmsProp 209 loss=0.378189 err=0.378189
I 2015-05-26 07:32:53 theanets.trainer:168 RmsProp 210 loss=0.367912 err=0.367912
I 2015-05-26 07:32:54 theanets.trainer:168 validation 21 loss=1704.679932 err=1704.679932 *
I 2015-05-26 07:33:05 theanets.trainer:168 RmsProp 211 loss=0.409463 err=0.409463
I 2015-05-26 07:33:17 theanets.trainer:168 RmsProp 212 loss=0.381237 err=0.381237
I 2015-05-26 07:33:29 theanets.trainer:168 RmsProp 213 loss=0.361976 err=0.361976
I 2015-05-26 07:33:41 theanets.trainer:168 RmsProp 214 loss=0.392439 err=0.392439
I 2015-05-26 07:33:53 theanets.trainer:168 RmsProp 215 loss=0.376271 err=0.376271
I 2015-05-26 07:34:05 theanets.trainer:168 RmsProp 216 loss=0.375843 err=0.375843
I 2015-05-26 07:34:16 theanets.trainer:168 RmsProp 217 loss=0.350052 err=0.350052
I 2015-05-26 07:34:28 theanets.trainer:168 RmsProp 218 loss=0.439199 err=0.439199
I 2015-05-26 07:34:40 theanets.trainer:168 RmsProp 219 loss=0.376224 err=0.376224
I 2015-05-26 07:34:52 theanets.trainer:168 RmsProp 220 loss=0.360647 err=0.360647
I 2015-05-26 07:34:52 theanets.trainer:168 validation 22 loss=1695.706299 err=1695.706299 *
I 2015-05-26 07:35:04 theanets.trainer:168 RmsProp 221 loss=0.365622 err=0.365622
I 2015-05-26 07:35:16 theanets.trainer:168 RmsProp 222 loss=0.383965 err=0.383965
I 2015-05-26 07:35:28 theanets.trainer:168 RmsProp 223 loss=0.348500 err=0.348500
I 2015-05-26 07:35:39 theanets.trainer:168 RmsProp 224 loss=0.360285 err=0.360285
I 2015-05-26 07:35:51 theanets.trainer:168 RmsProp 225 loss=0.362169 err=0.362169
I 2015-05-26 07:36:03 theanets.trainer:168 RmsProp 226 loss=0.364359 err=0.364359
I 2015-05-26 07:36:15 theanets.trainer:168 RmsProp 227 loss=0.356276 err=0.356276
I 2015-05-26 07:36:26 theanets.trainer:168 RmsProp 228 loss=0.358045 err=0.358045
I 2015-05-26 07:36:38 theanets.trainer:168 RmsProp 229 loss=0.339365 err=0.339365
I 2015-05-26 07:36:50 theanets.trainer:168 RmsProp 230 loss=0.364328 err=0.364328
I 2015-05-26 07:36:51 theanets.trainer:168 validation 23 loss=1695.060547 err=1695.060547 *
I 2015-05-26 07:37:02 theanets.trainer:168 RmsProp 231 loss=0.343969 err=0.343969
I 2015-05-26 07:37:14 theanets.trainer:168 RmsProp 232 loss=0.363319 err=0.363319
I 2015-05-26 07:37:26 theanets.trainer:168 RmsProp 233 loss=0.346154 err=0.346154
I 2015-05-26 07:37:38 theanets.trainer:168 RmsProp 234 loss=0.350390 err=0.350390
I 2015-05-26 07:37:50 theanets.trainer:168 RmsProp 235 loss=0.357166 err=0.357166
I 2015-05-26 07:38:02 theanets.trainer:168 RmsProp 236 loss=0.345906 err=0.345906
I 2015-05-26 07:38:14 theanets.trainer:168 RmsProp 237 loss=0.347850 err=0.347850
I 2015-05-26 07:38:26 theanets.trainer:168 RmsProp 238 loss=0.339920 err=0.339920
I 2015-05-26 07:38:38 theanets.trainer:168 RmsProp 239 loss=0.333919 err=0.333919
I 2015-05-26 07:38:50 theanets.trainer:168 RmsProp 240 loss=0.347574 err=0.347574
I 2015-05-26 07:38:50 theanets.trainer:168 validation 24 loss=1691.254761 err=1691.254761 *
I 2015-05-26 07:39:02 theanets.trainer:168 RmsProp 241 loss=0.332372 err=0.332372
I 2015-05-26 07:39:14 theanets.trainer:168 RmsProp 242 loss=0.336357 err=0.336357
I 2015-05-26 07:39:26 theanets.trainer:168 RmsProp 243 loss=0.326649 err=0.326649
I 2015-05-26 07:39:38 theanets.trainer:168 RmsProp 244 loss=0.333330 err=0.333330
I 2015-05-26 07:39:50 theanets.trainer:168 RmsProp 245 loss=0.325048 err=0.325048
I 2015-05-26 07:40:03 theanets.trainer:168 RmsProp 246 loss=0.386603 err=0.386603
I 2015-05-26 07:40:15 theanets.trainer:168 RmsProp 247 loss=0.346675 err=0.346675
I 2015-05-26 07:40:28 theanets.trainer:168 RmsProp 248 loss=0.321591 err=0.321591
I 2015-05-26 07:40:40 theanets.trainer:168 RmsProp 249 loss=0.322543 err=0.322543
I 2015-05-26 07:40:53 theanets.trainer:168 RmsProp 250 loss=0.327125 err=0.327125
I 2015-05-26 07:40:53 theanets.trainer:168 validation 25 loss=1691.592407 err=1691.592407
I 2015-05-26 07:41:06 theanets.trainer:168 RmsProp 251 loss=0.327864 err=0.327864
I 2015-05-26 07:41:18 theanets.trainer:168 RmsProp 252 loss=0.333618 err=0.333618
I 2015-05-26 07:41:30 theanets.trainer:168 RmsProp 253 loss=0.332575 err=0.332575
I 2015-05-26 07:41:42 theanets.trainer:168 RmsProp 254 loss=0.312941 err=0.312941
I 2015-05-26 07:41:55 theanets.trainer:168 RmsProp 255 loss=0.332697 err=0.332697
I 2015-05-26 07:42:07 theanets.trainer:168 RmsProp 256 loss=0.325034 err=0.325034
I 2015-05-26 07:42:19 theanets.trainer:168 RmsProp 257 loss=0.311801 err=0.311801
I 2015-05-26 07:42:31 theanets.trainer:168 RmsProp 258 loss=0.318434 err=0.318434
I 2015-05-26 07:42:43 theanets.trainer:168 RmsProp 259 loss=0.315104 err=0.315104
I 2015-05-26 07:42:55 theanets.trainer:168 RmsProp 260 loss=0.304740 err=0.304740
I 2015-05-26 07:42:55 theanets.trainer:168 validation 26 loss=1691.904297 err=1691.904297
I 2015-05-26 07:43:07 theanets.trainer:168 RmsProp 261 loss=0.319811 err=0.319811
I 2015-05-26 07:43:18 theanets.trainer:168 RmsProp 262 loss=0.304771 err=0.304771
I 2015-05-26 07:43:29 theanets.trainer:168 RmsProp 263 loss=0.311606 err=0.311606
I 2015-05-26 07:43:40 theanets.trainer:168 RmsProp 264 loss=0.311824 err=0.311824
I 2015-05-26 07:43:52 theanets.trainer:168 RmsProp 265 loss=0.307198 err=0.307198
I 2015-05-26 07:44:03 theanets.trainer:168 RmsProp 266 loss=0.312212 err=0.312212
I 2015-05-26 07:44:14 theanets.trainer:168 RmsProp 267 loss=0.302645 err=0.302645
I 2015-05-26 07:44:25 theanets.trainer:168 RmsProp 268 loss=0.313979 err=0.313979
I 2015-05-26 07:44:36 theanets.trainer:168 RmsProp 269 loss=0.321330 err=0.321330
I 2015-05-26 07:44:47 theanets.trainer:168 RmsProp 270 loss=0.303487 err=0.303487
I 2015-05-26 07:44:48 theanets.trainer:168 validation 27 loss=1684.926147 err=1684.926147 *
I 2015-05-26 07:44:58 theanets.trainer:168 RmsProp 271 loss=0.298503 err=0.298503
I 2015-05-26 07:45:09 theanets.trainer:168 RmsProp 272 loss=0.289132 err=0.289132
I 2015-05-26 07:45:21 theanets.trainer:168 RmsProp 273 loss=0.356501 err=0.356501
I 2015-05-26 07:45:32 theanets.trainer:168 RmsProp 274 loss=0.308610 err=0.308610
I 2015-05-26 07:45:43 theanets.trainer:168 RmsProp 275 loss=0.297673 err=0.297673
I 2015-05-26 07:45:54 theanets.trainer:168 RmsProp 276 loss=0.289105 err=0.289105
I 2015-05-26 07:46:06 theanets.trainer:168 RmsProp 277 loss=0.285474 err=0.285474
I 2015-05-26 07:46:16 theanets.trainer:168 RmsProp 278 loss=0.300169 err=0.300169
I 2015-05-26 07:46:28 theanets.trainer:168 RmsProp 279 loss=0.276506 err=0.276506
I 2015-05-26 07:46:39 theanets.trainer:168 RmsProp 280 loss=0.307575 err=0.307575
I 2015-05-26 07:46:39 theanets.trainer:168 validation 28 loss=1688.279297 err=1688.279297
I 2015-05-26 07:46:50 theanets.trainer:168 RmsProp 281 loss=0.294148 err=0.294148
I 2015-05-26 07:47:01 theanets.trainer:168 RmsProp 282 loss=0.288726 err=0.288726
I 2015-05-26 07:47:12 theanets.trainer:168 RmsProp 283 loss=0.287826 err=0.287826
I 2015-05-26 07:47:24 theanets.trainer:168 RmsProp 284 loss=0.301275 err=0.301275
I 2015-05-26 07:47:35 theanets.trainer:168 RmsProp 285 loss=0.290635 err=0.290635
I 2015-05-26 07:47:46 theanets.trainer:168 RmsProp 286 loss=0.289012 err=0.289012
I 2015-05-26 07:47:58 theanets.trainer:168 RmsProp 287 loss=0.282827 err=0.282827
I 2015-05-26 07:48:09 theanets.trainer:168 RmsProp 288 loss=0.296804 err=0.296804
I 2015-05-26 07:48:20 theanets.trainer:168 RmsProp 289 loss=0.296096 err=0.296096
I 2015-05-26 07:48:31 theanets.trainer:168 RmsProp 290 loss=0.287481 err=0.287481
I 2015-05-26 07:48:31 theanets.trainer:168 validation 29 loss=1680.916260 err=1680.916260 *
I 2015-05-26 07:48:42 theanets.trainer:168 RmsProp 291 loss=0.283383 err=0.283383
I 2015-05-26 07:48:53 theanets.trainer:168 RmsProp 292 loss=0.284100 err=0.284100
I 2015-05-26 07:49:03 theanets.trainer:168 RmsProp 293 loss=0.286612 err=0.286612
I 2015-05-26 07:49:14 theanets.trainer:168 RmsProp 294 loss=0.291304 err=0.291304
I 2015-05-26 07:49:25 theanets.trainer:168 RmsProp 295 loss=0.276079 err=0.276079
I 2015-05-26 07:49:35 theanets.trainer:168 RmsProp 296 loss=0.281093 err=0.281093
I 2015-05-26 07:49:46 theanets.trainer:168 RmsProp 297 loss=0.294572 err=0.294572
I 2015-05-26 07:49:56 theanets.trainer:168 RmsProp 298 loss=0.273462 err=0.273462
I 2015-05-26 07:50:07 theanets.trainer:168 RmsProp 299 loss=0.282504 err=0.282504
I 2015-05-26 07:50:17 theanets.trainer:168 RmsProp 300 loss=0.274110 err=0.274110
I 2015-05-26 07:50:17 theanets.trainer:168 validation 30 loss=1680.607422 err=1680.607422 *
I 2015-05-26 07:50:27 theanets.trainer:168 RmsProp 301 loss=0.274197 err=0.274197
I 2015-05-26 07:50:38 theanets.trainer:168 RmsProp 302 loss=0.272183 err=0.272183
I 2015-05-26 07:50:49 theanets.trainer:168 RmsProp 303 loss=0.280407 err=0.280407
I 2015-05-26 07:51:00 theanets.trainer:168 RmsProp 304 loss=0.269347 err=0.269347
I 2015-05-26 07:51:10 theanets.trainer:168 RmsProp 305 loss=0.270262 err=0.270262
I 2015-05-26 07:51:21 theanets.trainer:168 RmsProp 306 loss=0.269108 err=0.269108
I 2015-05-26 07:51:32 theanets.trainer:168 RmsProp 307 loss=0.273548 err=0.273548
I 2015-05-26 07:51:42 theanets.trainer:168 RmsProp 308 loss=0.272066 err=0.272066
I 2015-05-26 07:51:52 theanets.trainer:168 RmsProp 309 loss=0.287711 err=0.287711
I 2015-05-26 07:52:03 theanets.trainer:168 RmsProp 310 loss=0.271942 err=0.271942
I 2015-05-26 07:52:04 theanets.trainer:168 validation 31 loss=1678.873413 err=1678.873413 *
I 2015-05-26 07:52:15 theanets.trainer:168 RmsProp 311 loss=0.267077 err=0.267077
I 2015-05-26 07:52:25 theanets.trainer:168 RmsProp 312 loss=0.261448 err=0.261448
I 2015-05-26 07:52:36 theanets.trainer:168 RmsProp 313 loss=0.259033 err=0.259033
I 2015-05-26 07:52:47 theanets.trainer:168 RmsProp 314 loss=0.274503 err=0.274503
I 2015-05-26 07:52:58 theanets.trainer:168 RmsProp 315 loss=0.255611 err=0.255611
I 2015-05-26 07:53:09 theanets.trainer:168 RmsProp 316 loss=0.281989 err=0.281989
I 2015-05-26 07:53:20 theanets.trainer:168 RmsProp 317 loss=0.266434 err=0.266434
I 2015-05-26 07:53:32 theanets.trainer:168 RmsProp 318 loss=0.255253 err=0.255253
I 2015-05-26 07:53:42 theanets.trainer:168 RmsProp 319 loss=0.270644 err=0.270644
I 2015-05-26 07:53:54 theanets.trainer:168 RmsProp 320 loss=0.248482 err=0.248482
I 2015-05-26 07:53:54 theanets.trainer:168 validation 32 loss=1678.054688 err=1678.054688 *
I 2015-05-26 07:54:05 theanets.trainer:168 RmsProp 321 loss=0.267140 err=0.267140
I 2015-05-26 07:54:16 theanets.trainer:168 RmsProp 322 loss=0.248957 err=0.248957
I 2015-05-26 07:54:27 theanets.trainer:168 RmsProp 323 loss=0.265825 err=0.265825
I 2015-05-26 07:54:38 theanets.trainer:168 RmsProp 324 loss=0.258810 err=0.258810
I 2015-05-26 07:54:48 theanets.trainer:168 RmsProp 325 loss=0.263255 err=0.263255
I 2015-05-26 07:54:59 theanets.trainer:168 RmsProp 326 loss=0.250305 err=0.250305
I 2015-05-26 07:55:10 theanets.trainer:168 RmsProp 327 loss=0.262127 err=0.262127
I 2015-05-26 07:55:21 theanets.trainer:168 RmsProp 328 loss=0.253683 err=0.253683
I 2015-05-26 07:55:32 theanets.trainer:168 RmsProp 329 loss=0.245021 err=0.245021
I 2015-05-26 07:55:43 theanets.trainer:168 RmsProp 330 loss=0.262907 err=0.262907
I 2015-05-26 07:55:43 theanets.trainer:168 validation 33 loss=1674.149292 err=1674.149292 *
I 2015-05-26 07:55:54 theanets.trainer:168 RmsProp 331 loss=0.247009 err=0.247009
I 2015-05-26 07:56:05 theanets.trainer:168 RmsProp 332 loss=0.251200 err=0.251200
I 2015-05-26 07:56:16 theanets.trainer:168 RmsProp 333 loss=0.249634 err=0.249634
I 2015-05-26 07:56:27 theanets.trainer:168 RmsProp 334 loss=0.245997 err=0.245997
I 2015-05-26 07:56:38 theanets.trainer:168 RmsProp 335 loss=0.265864 err=0.265864
I 2015-05-26 07:56:49 theanets.trainer:168 RmsProp 336 loss=0.250596 err=0.250596
I 2015-05-26 07:57:00 theanets.trainer:168 RmsProp 337 loss=0.251910 err=0.251910
I 2015-05-26 07:57:11 theanets.trainer:168 RmsProp 338 loss=0.246886 err=0.246886
I 2015-05-26 07:57:22 theanets.trainer:168 RmsProp 339 loss=0.249394 err=0.249394
I 2015-05-26 07:57:34 theanets.trainer:168 RmsProp 340 loss=0.255978 err=0.255978
I 2015-05-26 07:57:34 theanets.trainer:168 validation 34 loss=1669.800781 err=1669.800781 *
I 2015-05-26 07:57:45 theanets.trainer:168 RmsProp 341 loss=0.241652 err=0.241652
I 2015-05-26 07:57:57 theanets.trainer:168 RmsProp 342 loss=0.251748 err=0.251748
I 2015-05-26 07:58:08 theanets.trainer:168 RmsProp 343 loss=0.240668 err=0.240668
I 2015-05-26 07:58:19 theanets.trainer:168 RmsProp 344 loss=0.243623 err=0.243623
I 2015-05-26 07:58:30 theanets.trainer:168 RmsProp 345 loss=0.245326 err=0.245326
I 2015-05-26 07:58:41 theanets.trainer:168 RmsProp 346 loss=0.247174 err=0.247174
I 2015-05-26 07:58:51 theanets.trainer:168 RmsProp 347 loss=0.243389 err=0.243389
I 2015-05-26 07:59:02 theanets.trainer:168 RmsProp 348 loss=0.239529 err=0.239529
I 2015-05-26 07:59:13 theanets.trainer:168 RmsProp 349 loss=0.248618 err=0.248618
I 2015-05-26 07:59:24 theanets.trainer:168 RmsProp 350 loss=0.242512 err=0.242512
I 2015-05-26 07:59:24 theanets.trainer:168 validation 35 loss=1669.789062 err=1669.789062 *
I 2015-05-26 07:59:35 theanets.trainer:168 RmsProp 351 loss=0.234759 err=0.234759
I 2015-05-26 07:59:46 theanets.trainer:168 RmsProp 352 loss=0.243965 err=0.243965
I 2015-05-26 07:59:57 theanets.trainer:168 RmsProp 353 loss=0.242480 err=0.242480
I 2015-05-26 08:00:08 theanets.trainer:168 RmsProp 354 loss=0.225746 err=0.225746
I 2015-05-26 08:00:19 theanets.trainer:168 RmsProp 355 loss=0.260482 err=0.260482
I 2015-05-26 08:00:30 theanets.trainer:168 RmsProp 356 loss=0.235266 err=0.235266
I 2015-05-26 08:00:42 theanets.trainer:168 RmsProp 357 loss=0.230785 err=0.230785
I 2015-05-26 08:00:53 theanets.trainer:168 RmsProp 358 loss=0.236377 err=0.236377
I 2015-05-26 08:01:05 theanets.trainer:168 RmsProp 359 loss=0.245057 err=0.245057
I 2015-05-26 08:01:16 theanets.trainer:168 RmsProp 360 loss=0.230178 err=0.230178
I 2015-05-26 08:01:17 theanets.trainer:168 validation 36 loss=1665.943359 err=1665.943359 *
I 2015-05-26 08:01:28 theanets.trainer:168 RmsProp 361 loss=0.234173 err=0.234173
I 2015-05-26 08:01:39 theanets.trainer:168 RmsProp 362 loss=0.227593 err=0.227593
I 2015-05-26 08:01:50 theanets.trainer:168 RmsProp 363 loss=0.230938 err=0.230938
I 2015-05-26 08:02:01 theanets.trainer:168 RmsProp 364 loss=0.224831 err=0.224831
I 2015-05-26 08:02:11 theanets.trainer:168 RmsProp 365 loss=0.236764 err=0.236764
I 2015-05-26 08:02:21 theanets.trainer:168 RmsProp 366 loss=0.223336 err=0.223336
I 2015-05-26 08:02:32 theanets.trainer:168 RmsProp 367 loss=0.227834 err=0.227834
I 2015-05-26 08:02:42 theanets.trainer:168 RmsProp 368 loss=0.249104 err=0.249104
I 2015-05-26 08:02:52 theanets.trainer:168 RmsProp 369 loss=0.227068 err=0.227068
I 2015-05-26 08:03:03 theanets.trainer:168 RmsProp 370 loss=0.226216 err=0.226216
I 2015-05-26 08:03:03 theanets.trainer:168 validation 37 loss=1664.619385 err=1664.619385 *
I 2015-05-26 08:03:14 theanets.trainer:168 RmsProp 371 loss=0.221815 err=0.221815
I 2015-05-26 08:03:24 theanets.trainer:168 RmsProp 372 loss=0.219901 err=0.219901
I 2015-05-26 08:03:34 theanets.trainer:168 RmsProp 373 loss=0.252830 err=0.252830
I 2015-05-26 08:03:44 theanets.trainer:168 RmsProp 374 loss=0.224400 err=0.224400
I 2015-05-26 08:03:55 theanets.trainer:168 RmsProp 375 loss=0.222428 err=0.222428
I 2015-05-26 08:04:05 theanets.trainer:168 RmsProp 376 loss=0.230050 err=0.230050
I 2015-05-26 08:04:15 theanets.trainer:168 RmsProp 377 loss=0.218407 err=0.218407
I 2015-05-26 08:04:25 theanets.trainer:168 RmsProp 378 loss=0.222005 err=0.222005
I 2015-05-26 08:04:35 theanets.trainer:168 RmsProp 379 loss=0.224408 err=0.224408
I 2015-05-26 08:04:46 theanets.trainer:168 RmsProp 380 loss=0.220277 err=0.220277
I 2015-05-26 08:04:46 theanets.trainer:168 validation 38 loss=1663.444580 err=1663.444580 *
I 2015-05-26 08:04:57 theanets.trainer:168 RmsProp 381 loss=0.229133 err=0.229133
I 2015-05-26 08:05:07 theanets.trainer:168 RmsProp 382 loss=0.221799 err=0.221799
I 2015-05-26 08:05:18 theanets.trainer:168 RmsProp 383 loss=0.211972 err=0.211972
I 2015-05-26 08:05:28 theanets.trainer:168 RmsProp 384 loss=0.221452 err=0.221452
I 2015-05-26 08:05:38 theanets.trainer:168 RmsProp 385 loss=0.227232 err=0.227232
I 2015-05-26 08:05:49 theanets.trainer:168 RmsProp 386 loss=0.218490 err=0.218490
I 2015-05-26 08:05:59 theanets.trainer:168 RmsProp 387 loss=0.219736 err=0.219736
I 2015-05-26 08:06:09 theanets.trainer:168 RmsProp 388 loss=0.224914 err=0.224914
I 2015-05-26 08:06:19 theanets.trainer:168 RmsProp 389 loss=0.214458 err=0.214458
I 2015-05-26 08:06:30 theanets.trainer:168 RmsProp 390 loss=0.221547 err=0.221547
I 2015-05-26 08:06:30 theanets.trainer:168 validation 39 loss=1658.979370 err=1658.979370 *
I 2015-05-26 08:06:40 theanets.trainer:168 RmsProp 391 loss=0.213740 err=0.213740
I 2015-05-26 08:06:51 theanets.trainer:168 RmsProp 392 loss=0.214736 err=0.214736
I 2015-05-26 08:07:02 theanets.trainer:168 RmsProp 393 loss=0.207014 err=0.207014
I 2015-05-26 08:07:12 theanets.trainer:168 RmsProp 394 loss=0.236234 err=0.236234
I 2015-05-26 08:07:22 theanets.trainer:168 RmsProp 395 loss=0.219599 err=0.219599
I 2015-05-26 08:07:33 theanets.trainer:168 RmsProp 396 loss=0.210451 err=0.210451
I 2015-05-26 08:07:43 theanets.trainer:168 RmsProp 397 loss=0.211436 err=0.211436
I 2015-05-26 08:07:53 theanets.trainer:168 RmsProp 398 loss=0.213524 err=0.213524
I 2015-05-26 08:08:03 theanets.trainer:168 RmsProp 399 loss=0.210196 err=0.210196
I 2015-05-26 08:08:13 theanets.trainer:168 RmsProp 400 loss=0.224348 err=0.224348
I 2015-05-26 08:08:14 theanets.trainer:168 validation 40 loss=1662.700073 err=1662.700073
I 2015-05-26 08:08:24 theanets.trainer:168 RmsProp 401 loss=0.210053 err=0.210053
I 2015-05-26 08:08:34 theanets.trainer:168 RmsProp 402 loss=0.199805 err=0.199805
I 2015-05-26 08:08:44 theanets.trainer:168 RmsProp 403 loss=0.226425 err=0.226425
I 2015-05-26 08:08:54 theanets.trainer:168 RmsProp 404 loss=0.212078 err=0.212078
I 2015-05-26 08:09:04 theanets.trainer:168 RmsProp 405 loss=0.204686 err=0.204686
I 2015-05-26 08:09:15 theanets.trainer:168 RmsProp 406 loss=0.232435 err=0.232435
I 2015-05-26 08:09:25 theanets.trainer:168 RmsProp 407 loss=0.257450 err=0.257450
I 2015-05-26 08:09:36 theanets.trainer:168 RmsProp 408 loss=0.209854 err=0.209854
I 2015-05-26 08:09:47 theanets.trainer:168 RmsProp 409 loss=0.194136 err=0.194136
I 2015-05-26 08:09:57 theanets.trainer:168 RmsProp 410 loss=0.212949 err=0.212949
I 2015-05-26 08:09:58 theanets.trainer:168 validation 41 loss=1659.101562 err=1659.101562
I 2015-05-26 08:10:08 theanets.trainer:168 RmsProp 411 loss=0.206551 err=0.206551
I 2015-05-26 08:10:18 theanets.trainer:168 RmsProp 412 loss=0.205112 err=0.205112
I 2015-05-26 08:10:29 theanets.trainer:168 RmsProp 413 loss=0.203293 err=0.203293
I 2015-05-26 08:10:40 theanets.trainer:168 RmsProp 414 loss=0.205546 err=0.205546
I 2015-05-26 08:10:50 theanets.trainer:168 RmsProp 415 loss=0.203485 err=0.203485
I 2015-05-26 08:11:01 theanets.trainer:168 RmsProp 416 loss=0.222744 err=0.222744
I 2015-05-26 08:11:11 theanets.trainer:168 RmsProp 417 loss=0.197183 err=0.197183
I 2015-05-26 08:11:21 theanets.trainer:168 RmsProp 418 loss=0.203889 err=0.203889
I 2015-05-26 08:11:32 theanets.trainer:168 RmsProp 419 loss=0.202875 err=0.202875
I 2015-05-26 08:11:42 theanets.trainer:168 RmsProp 420 loss=0.203173 err=0.203173
I 2015-05-26 08:11:42 theanets.trainer:168 validation 42 loss=1659.310547 err=1659.310547
I 2015-05-26 08:11:52 theanets.trainer:168 RmsProp 421 loss=0.208943 err=0.208943
I 2015-05-26 08:12:02 theanets.trainer:168 RmsProp 422 loss=0.214631 err=0.214631
I 2015-05-26 08:12:12 theanets.trainer:168 RmsProp 423 loss=0.200699 err=0.200699
I 2015-05-26 08:12:23 theanets.trainer:168 RmsProp 424 loss=0.196808 err=0.196808
I 2015-05-26 08:12:33 theanets.trainer:168 RmsProp 425 loss=0.200341 err=0.200341
I 2015-05-26 08:12:43 theanets.trainer:168 RmsProp 426 loss=0.198203 err=0.198203
I 2015-05-26 08:12:53 theanets.trainer:168 RmsProp 427 loss=0.206961 err=0.206961
I 2015-05-26 08:13:04 theanets.trainer:168 RmsProp 428 loss=0.196224 err=0.196224
I 2015-05-26 08:13:15 theanets.trainer:168 RmsProp 429 loss=0.188306 err=0.188306
I 2015-05-26 08:13:25 theanets.trainer:168 RmsProp 430 loss=0.211837 err=0.211837
I 2015-05-26 08:13:26 theanets.trainer:168 validation 43 loss=1655.625366 err=1655.625366 *
I 2015-05-26 08:13:37 theanets.trainer:168 RmsProp 431 loss=0.198562 err=0.198562
I 2015-05-26 08:13:47 theanets.trainer:168 RmsProp 432 loss=0.197074 err=0.197074
I 2015-05-26 08:13:57 theanets.trainer:168 RmsProp 433 loss=0.205191 err=0.205191
I 2015-05-26 08:14:07 theanets.trainer:168 RmsProp 434 loss=0.193154 err=0.193154
I 2015-05-26 08:14:18 theanets.trainer:168 RmsProp 435 loss=0.213269 err=0.213269
I 2015-05-26 08:14:28 theanets.trainer:168 RmsProp 436 loss=0.207375 err=0.207375
I 2015-05-26 08:14:38 theanets.trainer:168 RmsProp 437 loss=0.195960 err=0.195960
I 2015-05-26 08:14:48 theanets.trainer:168 RmsProp 438 loss=0.195628 err=0.195628
I 2015-05-26 08:14:59 theanets.trainer:168 RmsProp 439 loss=0.194322 err=0.194322
I 2015-05-26 08:15:09 theanets.trainer:168 RmsProp 440 loss=0.180348 err=0.180348
I 2015-05-26 08:15:09 theanets.trainer:168 validation 44 loss=1657.547241 err=1657.547241
I 2015-05-26 08:15:20 theanets.trainer:168 RmsProp 441 loss=0.223452 err=0.223452
I 2015-05-26 08:15:30 theanets.trainer:168 RmsProp 442 loss=0.196446 err=0.196446
I 2015-05-26 08:15:40 theanets.trainer:168 RmsProp 443 loss=0.186478 err=0.186478
I 2015-05-26 08:15:50 theanets.trainer:168 RmsProp 444 loss=0.192088 err=0.192088
I 2015-05-26 08:16:01 theanets.trainer:168 RmsProp 445 loss=0.192627 err=0.192627
I 2015-05-26 08:16:11 theanets.trainer:168 RmsProp 446 loss=0.186485 err=0.186485
I 2015-05-26 08:16:21 theanets.trainer:168 RmsProp 447 loss=0.191802 err=0.191802
I 2015-05-26 08:16:32 theanets.trainer:168 RmsProp 448 loss=0.201779 err=0.201779
I 2015-05-26 08:16:42 theanets.trainer:168 RmsProp 449 loss=0.190497 err=0.190497
I 2015-05-26 08:16:52 theanets.trainer:168 RmsProp 450 loss=0.194026 err=0.194026
I 2015-05-26 08:16:53 theanets.trainer:168 validation 45 loss=1653.496460 err=1653.496460 *
I 2015-05-26 08:17:03 theanets.trainer:168 RmsProp 451 loss=0.188154 err=0.188154
I 2015-05-26 08:17:13 theanets.trainer:168 RmsProp 452 loss=0.184100 err=0.184100
I 2015-05-26 08:17:24 theanets.trainer:168 RmsProp 453 loss=0.191698 err=0.191698
I 2015-05-26 08:17:34 theanets.trainer:168 RmsProp 454 loss=0.187313 err=0.187313
I 2015-05-26 08:17:44 theanets.trainer:168 RmsProp 455 loss=0.190998 err=0.190998
I 2015-05-26 08:17:54 theanets.trainer:168 RmsProp 456 loss=0.196717 err=0.196717
I 2015-05-26 08:18:05 theanets.trainer:168 RmsProp 457 loss=0.181208 err=0.181208
I 2015-05-26 08:18:15 theanets.trainer:168 RmsProp 458 loss=0.190977 err=0.190977
I 2015-05-26 08:18:26 theanets.trainer:168 RmsProp 459 loss=0.186648 err=0.186648
I 2015-05-26 08:18:36 theanets.trainer:168 RmsProp 460 loss=0.174489 err=0.174489
I 2015-05-26 08:18:36 theanets.trainer:168 validation 46 loss=1654.422852 err=1654.422852
I 2015-05-26 08:18:46 theanets.trainer:168 RmsProp 461 loss=0.192714 err=0.192714
I 2015-05-26 08:18:57 theanets.trainer:168 RmsProp 462 loss=0.187940 err=0.187940
I 2015-05-26 08:19:08 theanets.trainer:168 RmsProp 463 loss=0.184759 err=0.184759
I 2015-05-26 08:19:18 theanets.trainer:168 RmsProp 464 loss=0.180249 err=0.180249
I 2015-05-26 08:19:29 theanets.trainer:168 RmsProp 465 loss=0.190418 err=0.190418
I 2015-05-26 08:19:39 theanets.trainer:168 RmsProp 466 loss=0.187653 err=0.187653
I 2015-05-26 08:19:50 theanets.trainer:168 RmsProp 467 loss=0.179791 err=0.179791
I 2015-05-26 08:20:00 theanets.trainer:168 RmsProp 468 loss=0.192842 err=0.192842
I 2015-05-26 08:20:11 theanets.trainer:168 RmsProp 469 loss=0.167273 err=0.167273
I 2015-05-26 08:20:21 theanets.trainer:168 RmsProp 470 loss=0.223594 err=0.223594
I 2015-05-26 08:20:21 theanets.trainer:168 validation 47 loss=1648.268555 err=1648.268555 *
I 2015-05-26 08:20:32 theanets.trainer:168 RmsProp 471 loss=0.189757 err=0.189757
I 2015-05-26 08:20:43 theanets.trainer:168 RmsProp 472 loss=0.170705 err=0.170705
I 2015-05-26 08:20:53 theanets.trainer:168 RmsProp 473 loss=0.193061 err=0.193061
I 2015-05-26 08:21:03 theanets.trainer:168 RmsProp 474 loss=0.190056 err=0.190056
I 2015-05-26 08:21:14 theanets.trainer:168 RmsProp 475 loss=0.176151 err=0.176151
I 2015-05-26 08:21:24 theanets.trainer:168 RmsProp 476 loss=0.180297 err=0.180297
I 2015-05-26 08:21:34 theanets.trainer:168 RmsProp 477 loss=0.187133 err=0.187133
I 2015-05-26 08:21:45 theanets.trainer:168 RmsProp 478 loss=0.178290 err=0.178290
I 2015-05-26 08:21:55 theanets.trainer:168 RmsProp 479 loss=0.179878 err=0.179878
I 2015-05-26 08:22:06 theanets.trainer:168 RmsProp 480 loss=0.176069 err=0.176069
I 2015-05-26 08:22:06 theanets.trainer:168 validation 48 loss=1647.918213 err=1647.918213 *
I 2015-05-26 08:22:17 theanets.trainer:168 RmsProp 481 loss=0.184154 err=0.184154
I 2015-05-26 08:22:27 theanets.trainer:168 RmsProp 482 loss=0.171814 err=0.171814
I 2015-05-26 08:22:37 theanets.trainer:168 RmsProp 483 loss=0.183413 err=0.183413
I 2015-05-26 08:22:48 theanets.trainer:168 RmsProp 484 loss=0.181244 err=0.181244
I 2015-05-26 08:22:59 theanets.trainer:168 RmsProp 485 loss=0.177494 err=0.177494
I 2015-05-26 08:23:09 theanets.trainer:168 RmsProp 486 loss=0.182250 err=0.182250
I 2015-05-26 08:23:20 theanets.trainer:168 RmsProp 487 loss=0.167190 err=0.167190
I 2015-05-26 08:23:30 theanets.trainer:168 RmsProp 488 loss=0.181429 err=0.181429
I 2015-05-26 08:23:40 theanets.trainer:168 RmsProp 489 loss=0.180431 err=0.180431
I 2015-05-26 08:23:51 theanets.trainer:168 RmsProp 490 loss=0.170966 err=0.170966
I 2015-05-26 08:23:51 theanets.trainer:168 validation 49 loss=1646.245361 err=1646.245361 *
I 2015-05-26 08:24:01 theanets.trainer:168 RmsProp 491 loss=0.192920 err=0.192920
I 2015-05-26 08:24:12 theanets.trainer:168 RmsProp 492 loss=0.187911 err=0.187911
I 2015-05-26 08:24:22 theanets.trainer:168 RmsProp 493 loss=0.180556 err=0.180556
I 2015-05-26 08:24:33 theanets.trainer:168 RmsProp 494 loss=0.166439 err=0.166439
I 2015-05-26 08:24:44 theanets.trainer:168 RmsProp 495 loss=0.164945 err=0.164945
I 2015-05-26 08:24:54 theanets.trainer:168 RmsProp 496 loss=0.206122 err=0.206122
I 2015-05-26 08:25:04 theanets.trainer:168 RmsProp 497 loss=0.171573 err=0.171573
I 2015-05-26 08:25:15 theanets.trainer:168 RmsProp 498 loss=0.171691 err=0.171691
I 2015-05-26 08:25:26 theanets.trainer:168 RmsProp 499 loss=0.168967 err=0.168967
I 2015-05-26 08:25:36 theanets.trainer:168 RmsProp 500 loss=0.169381 err=0.169381
I 2015-05-26 08:25:37 theanets.trainer:168 validation 50 loss=1645.690308 err=1645.690308 *
I 2015-05-26 08:25:47 theanets.trainer:168 RmsProp 501 loss=0.171241 err=0.171241
I 2015-05-26 08:25:57 theanets.trainer:168 RmsProp 502 loss=0.177031 err=0.177031
I 2015-05-26 08:26:08 theanets.trainer:168 RmsProp 503 loss=0.183320 err=0.183320
I 2015-05-26 08:26:18 theanets.trainer:168 RmsProp 504 loss=0.161608 err=0.161608
I 2015-05-26 08:26:29 theanets.trainer:168 RmsProp 505 loss=0.192538 err=0.192538
I 2015-05-26 08:26:40 theanets.trainer:168 RmsProp 506 loss=0.164840 err=0.164840
I 2015-05-26 08:26:50 theanets.trainer:168 RmsProp 507 loss=0.166045 err=0.166045
I 2015-05-26 08:27:01 theanets.trainer:168 RmsProp 508 loss=0.170388 err=0.170388
I 2015-05-26 08:27:12 theanets.trainer:168 RmsProp 509 loss=0.164369 err=0.164369
I 2015-05-26 08:27:23 theanets.trainer:168 RmsProp 510 loss=0.160895 err=0.160895
I 2015-05-26 08:27:23 theanets.trainer:168 validation 51 loss=1646.535522 err=1646.535522
I 2015-05-26 08:27:34 theanets.trainer:168 RmsProp 511 loss=0.185703 err=0.185703
I 2015-05-26 08:27:45 theanets.trainer:168 RmsProp 512 loss=0.169777 err=0.169777
I 2015-05-26 08:27:55 theanets.trainer:168 RmsProp 513 loss=0.155344 err=0.155344
I 2015-05-26 08:28:06 theanets.trainer:168 RmsProp 514 loss=0.178801 err=0.178801
I 2015-05-26 08:28:16 theanets.trainer:168 RmsProp 515 loss=0.177142 err=0.177142
I 2015-05-26 08:28:26 theanets.trainer:168 RmsProp 516 loss=0.160393 err=0.160393
I 2015-05-26 08:28:37 theanets.trainer:168 RmsProp 517 loss=0.183580 err=0.183580
I 2015-05-26 08:28:47 theanets.trainer:168 RmsProp 518 loss=0.160189 err=0.160189
I 2015-05-26 08:28:58 theanets.trainer:168 RmsProp 519 loss=0.170205 err=0.170205
I 2015-05-26 08:29:08 theanets.trainer:168 RmsProp 520 loss=0.187604 err=0.187604
I 2015-05-26 08:29:09 theanets.trainer:168 validation 52 loss=1643.157593 err=1643.157593 *
I 2015-05-26 08:29:19 theanets.trainer:168 RmsProp 521 loss=0.164762 err=0.164762
I 2015-05-26 08:29:30 theanets.trainer:168 RmsProp 522 loss=0.160978 err=0.160978
I 2015-05-26 08:29:40 theanets.trainer:168 RmsProp 523 loss=0.171043 err=0.171043
I 2015-05-26 08:29:50 theanets.trainer:168 RmsProp 524 loss=0.168828 err=0.168828
I 2015-05-26 08:30:01 theanets.trainer:168 RmsProp 525 loss=0.153439 err=0.153439
I 2015-05-26 08:30:12 theanets.trainer:168 RmsProp 526 loss=0.183456 err=0.183456
I 2015-05-26 08:30:23 theanets.trainer:168 RmsProp 527 loss=0.165387 err=0.165387
I 2015-05-26 08:30:34 theanets.trainer:168 RmsProp 528 loss=0.150785 err=0.150785
I 2015-05-26 08:30:45 theanets.trainer:168 RmsProp 529 loss=0.187330 err=0.187330
I 2015-05-26 08:30:55 theanets.trainer:168 RmsProp 530 loss=0.160022 err=0.160022
I 2015-05-26 08:30:56 theanets.trainer:168 validation 53 loss=1639.129272 err=1639.129272 *
I 2015-05-26 08:31:06 theanets.trainer:168 RmsProp 531 loss=0.159727 err=0.159727
I 2015-05-26 08:31:17 theanets.trainer:168 RmsProp 532 loss=0.159642 err=0.159642
I 2015-05-26 08:31:28 theanets.trainer:168 RmsProp 533 loss=0.167432 err=0.167432
I 2015-05-26 08:31:38 theanets.trainer:168 RmsProp 534 loss=0.162355 err=0.162355
I 2015-05-26 08:31:48 theanets.trainer:168 RmsProp 535 loss=0.165128 err=0.165128
I 2015-05-26 08:31:58 theanets.trainer:168 RmsProp 536 loss=0.163066 err=0.163066
I 2015-05-26 08:32:08 theanets.trainer:168 RmsProp 537 loss=0.166004 err=0.166004
I 2015-05-26 08:32:18 theanets.trainer:168 RmsProp 538 loss=0.159533 err=0.159533
I 2015-05-26 08:32:28 theanets.trainer:168 RmsProp 539 loss=0.166033 err=0.166033
I 2015-05-26 08:32:38 theanets.trainer:168 RmsProp 540 loss=0.167383 err=0.167383
I 2015-05-26 08:32:38 theanets.trainer:168 validation 54 loss=1638.247925 err=1638.247925 *
I 2015-05-26 08:32:48 theanets.trainer:168 RmsProp 541 loss=0.160797 err=0.160797
I 2015-05-26 08:32:58 theanets.trainer:168 RmsProp 542 loss=0.155301 err=0.155301
I 2015-05-26 08:33:08 theanets.trainer:168 RmsProp 543 loss=0.151381 err=0.151381
I 2015-05-26 08:33:18 theanets.trainer:168 RmsProp 544 loss=0.186196 err=0.186196
I 2015-05-26 08:33:28 theanets.trainer:168 RmsProp 545 loss=0.160086 err=0.160086
I 2015-05-26 08:33:38 theanets.trainer:168 RmsProp 546 loss=0.144784 err=0.144784
I 2015-05-26 08:33:48 theanets.trainer:168 RmsProp 547 loss=0.182557 err=0.182557
I 2015-05-26 08:33:58 theanets.trainer:168 RmsProp 548 loss=0.151254 err=0.151254
I 2015-05-26 08:34:08 theanets.trainer:168 RmsProp 549 loss=0.173472 err=0.173472
I 2015-05-26 08:34:18 theanets.trainer:168 RmsProp 550 loss=0.150693 err=0.150693
I 2015-05-26 08:34:18 theanets.trainer:168 validation 55 loss=1640.197632 err=1640.197632
I 2015-05-26 08:34:29 theanets.trainer:168 RmsProp 551 loss=0.161974 err=0.161974
I 2015-05-26 08:34:39 theanets.trainer:168 RmsProp 552 loss=0.154704 err=0.154704
I 2015-05-26 08:34:49 theanets.trainer:168 RmsProp 553 loss=0.155992 err=0.155992
I 2015-05-26 08:34:59 theanets.trainer:168 RmsProp 554 loss=0.161386 err=0.161386
I 2015-05-26 08:35:09 theanets.trainer:168 RmsProp 555 loss=0.153712 err=0.153712
I 2015-05-26 08:35:19 theanets.trainer:168 RmsProp 556 loss=0.156738 err=0.156738
I 2015-05-26 08:35:30 theanets.trainer:168 RmsProp 557 loss=0.180017 err=0.180017
I 2015-05-26 08:35:40 theanets.trainer:168 RmsProp 558 loss=0.155142 err=0.155142
I 2015-05-26 08:35:50 theanets.trainer:168 RmsProp 559 loss=0.148834 err=0.148834
I 2015-05-26 08:36:00 theanets.trainer:168 RmsProp 560 loss=0.170389 err=0.170389
I 2015-05-26 08:36:00 theanets.trainer:168 validation 56 loss=1635.459473 err=1635.459473 *
I 2015-05-26 08:36:10 theanets.trainer:168 RmsProp 561 loss=0.162532 err=0.162532
I 2015-05-26 08:36:20 theanets.trainer:168 RmsProp 562 loss=0.136109 err=0.136109
I 2015-05-26 08:36:30 theanets.trainer:168 RmsProp 563 loss=0.200892 err=0.200892
I 2015-05-26 08:36:40 theanets.trainer:168 RmsProp 564 loss=0.164004 err=0.164004
I 2015-05-26 08:36:50 theanets.trainer:168 RmsProp 565 loss=0.148375 err=0.148375
I 2015-05-26 08:37:00 theanets.trainer:168 RmsProp 566 loss=0.150439 err=0.150439
I 2015-05-26 08:37:10 theanets.trainer:168 RmsProp 567 loss=0.130876 err=0.130876
I 2015-05-26 08:37:20 theanets.trainer:168 RmsProp 568 loss=0.262053 err=0.262053
I 2015-05-26 08:37:29 theanets.trainer:168 RmsProp 569 loss=0.177257 err=0.177257
I 2015-05-26 08:37:39 theanets.trainer:168 RmsProp 570 loss=0.152603 err=0.152603
I 2015-05-26 08:37:40 theanets.trainer:168 validation 57 loss=1635.195679 err=1635.195679 *
I 2015-05-26 08:37:50 theanets.trainer:168 RmsProp 571 loss=0.138129 err=0.138129
I 2015-05-26 08:37:59 theanets.trainer:168 RmsProp 572 loss=0.165228 err=0.165228
I 2015-05-26 08:38:09 theanets.trainer:168 RmsProp 573 loss=0.145145 err=0.145145
I 2015-05-26 08:38:19 theanets.trainer:168 RmsProp 574 loss=0.172707 err=0.172707
I 2015-05-26 08:38:29 theanets.trainer:168 RmsProp 575 loss=0.152231 err=0.152231
I 2015-05-26 08:38:39 theanets.trainer:168 RmsProp 576 loss=0.141863 err=0.141863
I 2015-05-26 08:38:49 theanets.trainer:168 RmsProp 577 loss=0.157725 err=0.157725
I 2015-05-26 08:38:59 theanets.trainer:168 RmsProp 578 loss=0.152999 err=0.152999
I 2015-05-26 08:39:09 theanets.trainer:168 RmsProp 579 loss=0.148739 err=0.148739
I 2015-05-26 08:39:18 theanets.trainer:168 RmsProp 580 loss=0.141701 err=0.141701
I 2015-05-26 08:39:19 theanets.trainer:168 validation 58 loss=1640.417236 err=1640.417236
I 2015-05-26 08:39:29 theanets.trainer:168 RmsProp 581 loss=0.200100 err=0.200100
I 2015-05-26 08:39:38 theanets.trainer:168 RmsProp 582 loss=0.156261 err=0.156261
I 2015-05-26 08:39:48 theanets.trainer:168 RmsProp 583 loss=0.140244 err=0.140244
I 2015-05-26 08:39:58 theanets.trainer:168 RmsProp 584 loss=0.160142 err=0.160142
I 2015-05-26 08:40:08 theanets.trainer:168 RmsProp 585 loss=0.145165 err=0.145165
I 2015-05-26 08:40:18 theanets.trainer:168 RmsProp 586 loss=0.157779 err=0.157779
I 2015-05-26 08:40:28 theanets.trainer:168 RmsProp 587 loss=0.161244 err=0.161244
I 2015-05-26 08:40:38 theanets.trainer:168 RmsProp 588 loss=0.152759 err=0.152759
I 2015-05-26 08:40:48 theanets.trainer:168 RmsProp 589 loss=0.148060 err=0.148060
I 2015-05-26 08:40:57 theanets.trainer:168 RmsProp 590 loss=0.153558 err=0.153558
I 2015-05-26 08:40:58 theanets.trainer:168 validation 59 loss=1630.554810 err=1630.554810 *
I 2015-05-26 08:41:07 theanets.trainer:168 RmsProp 591 loss=0.178131 err=0.178131
I 2015-05-26 08:41:17 theanets.trainer:168 RmsProp 592 loss=0.154520 err=0.154520
I 2015-05-26 08:41:27 theanets.trainer:168 RmsProp 593 loss=0.140079 err=0.140079
I 2015-05-26 08:41:37 theanets.trainer:168 RmsProp 594 loss=0.154680 err=0.154680
I 2015-05-26 08:41:47 theanets.trainer:168 RmsProp 595 loss=0.150715 err=0.150715
I 2015-05-26 08:41:57 theanets.trainer:168 RmsProp 596 loss=0.141742 err=0.141742
I 2015-05-26 08:42:07 theanets.trainer:168 RmsProp 597 loss=0.160671 err=0.160671
I 2015-05-26 08:42:17 theanets.trainer:168 RmsProp 598 loss=0.155168 err=0.155168
I 2015-05-26 08:42:27 theanets.trainer:168 RmsProp 599 loss=0.148151 err=0.148151
I 2015-05-26 08:42:37 theanets.trainer:168 RmsProp 600 loss=0.138939 err=0.138939
I 2015-05-26 08:42:37 theanets.trainer:168 validation 60 loss=1632.808594 err=1632.808594
I 2015-05-26 08:42:47 theanets.trainer:168 RmsProp 601 loss=0.138305 err=0.138305
I 2015-05-26 08:42:57 theanets.trainer:168 RmsProp 602 loss=0.154410 err=0.154410
I 2015-05-26 08:43:07 theanets.trainer:168 RmsProp 603 loss=0.148837 err=0.148837
I 2015-05-26 08:43:17 theanets.trainer:168 RmsProp 604 loss=0.155452 err=0.155452
I 2015-05-26 08:43:27 theanets.trainer:168 RmsProp 605 loss=0.150473 err=0.150473
I 2015-05-26 08:43:37 theanets.trainer:168 RmsProp 606 loss=0.145402 err=0.145402
I 2015-05-26 08:43:47 theanets.trainer:168 RmsProp 607 loss=0.133975 err=0.133975
I 2015-05-26 08:43:56 theanets.trainer:168 RmsProp 608 loss=0.174680 err=0.174680
I 2015-05-26 08:44:06 theanets.trainer:168 RmsProp 609 loss=0.141915 err=0.141915
I 2015-05-26 08:44:16 theanets.trainer:168 RmsProp 610 loss=0.146309 err=0.146309
I 2015-05-26 08:44:16 theanets.trainer:168 validation 61 loss=1633.297729 err=1633.297729
I 2015-05-26 08:44:26 theanets.trainer:168 RmsProp 611 loss=0.145364 err=0.145364
I 2015-05-26 08:44:36 theanets.trainer:168 RmsProp 612 loss=0.144852 err=0.144852
I 2015-05-26 08:44:46 theanets.trainer:168 RmsProp 613 loss=0.142381 err=0.142381
I 2015-05-26 08:44:55 theanets.trainer:168 RmsProp 614 loss=0.145943 err=0.145943
I 2015-05-26 08:45:05 theanets.trainer:168 RmsProp 615 loss=0.146336 err=0.146336
I 2015-05-26 08:45:15 theanets.trainer:168 RmsProp 616 loss=0.145989 err=0.145989
I 2015-05-26 08:45:25 theanets.trainer:168 RmsProp 617 loss=0.144157 err=0.144157
I 2015-05-26 08:45:35 theanets.trainer:168 RmsProp 618 loss=0.140528 err=0.140528
I 2015-05-26 08:45:44 theanets.trainer:168 RmsProp 619 loss=0.142337 err=0.142337
I 2015-05-26 08:45:54 theanets.trainer:168 RmsProp 620 loss=0.143897 err=0.143897
I 2015-05-26 08:45:55 theanets.trainer:168 validation 62 loss=1628.668823 err=1628.668823 *
I 2015-05-26 08:46:04 theanets.trainer:168 RmsProp 621 loss=0.136464 err=0.136464
I 2015-05-26 08:46:13 theanets.trainer:168 RmsProp 622 loss=0.145997 err=0.145997
I 2015-05-26 08:46:22 theanets.trainer:168 RmsProp 623 loss=0.145878 err=0.145878
I 2015-05-26 08:46:30 theanets.trainer:168 RmsProp 624 loss=0.141480 err=0.141480
I 2015-05-26 08:46:39 theanets.trainer:168 RmsProp 625 loss=0.138271 err=0.138271
I 2015-05-26 08:46:48 theanets.trainer:168 RmsProp 626 loss=0.151902 err=0.151902
I 2015-05-26 08:46:56 theanets.trainer:168 RmsProp 627 loss=0.133409 err=0.133409
I 2015-05-26 08:47:05 theanets.trainer:168 RmsProp 628 loss=0.144194 err=0.144194
I 2015-05-26 08:47:14 theanets.trainer:168 RmsProp 629 loss=0.142849 err=0.142849
I 2015-05-26 08:47:23 theanets.trainer:168 RmsProp 630 loss=0.137579 err=0.137579
I 2015-05-26 08:47:23 theanets.trainer:168 validation 63 loss=1627.411011 err=1627.411011 *
I 2015-05-26 08:47:32 theanets.trainer:168 RmsProp 631 loss=0.138194 err=0.138194
I 2015-05-26 08:47:40 theanets.trainer:168 RmsProp 632 loss=0.145714 err=0.145714
I 2015-05-26 08:47:49 theanets.trainer:168 RmsProp 633 loss=0.136639 err=0.136639
I 2015-05-26 08:47:58 theanets.trainer:168 RmsProp 634 loss=0.144512 err=0.144512
I 2015-05-26 08:48:07 theanets.trainer:168 RmsProp 635 loss=0.139807 err=0.139807
I 2015-05-26 08:48:15 theanets.trainer:168 RmsProp 636 loss=0.141857 err=0.141857
I 2015-05-26 08:48:24 theanets.trainer:168 RmsProp 637 loss=0.138449 err=0.138449
I 2015-05-26 08:48:33 theanets.trainer:168 RmsProp 638 loss=0.136921 err=0.136921
I 2015-05-26 08:48:42 theanets.trainer:168 RmsProp 639 loss=0.137198 err=0.137198
I 2015-05-26 08:48:51 theanets.trainer:168 RmsProp 640 loss=0.136918 err=0.136918
I 2015-05-26 08:48:51 theanets.trainer:168 validation 64 loss=1629.801147 err=1629.801147
I 2015-05-26 08:49:00 theanets.trainer:168 RmsProp 641 loss=0.142774 err=0.142774
I 2015-05-26 08:49:09 theanets.trainer:168 RmsProp 642 loss=0.137381 err=0.137381
I 2015-05-26 08:49:17 theanets.trainer:168 RmsProp 643 loss=0.138003 err=0.138003
I 2015-05-26 08:49:26 theanets.trainer:168 RmsProp 644 loss=0.132378 err=0.132378
I 2015-05-26 08:49:35 theanets.trainer:168 RmsProp 645 loss=0.145137 err=0.145137
I 2015-05-26 08:49:43 theanets.trainer:168 RmsProp 646 loss=0.136742 err=0.136742
I 2015-05-26 08:49:53 theanets.trainer:168 RmsProp 647 loss=0.138395 err=0.138395
I 2015-05-26 08:50:01 theanets.trainer:168 RmsProp 648 loss=0.138837 err=0.138837
I 2015-05-26 08:50:10 theanets.trainer:168 RmsProp 649 loss=0.139270 err=0.139270
I 2015-05-26 08:50:19 theanets.trainer:168 RmsProp 650 loss=0.138663 err=0.138663
I 2015-05-26 08:50:19 theanets.trainer:168 validation 65 loss=1627.637939 err=1627.637939
I 2015-05-26 08:50:27 theanets.trainer:168 RmsProp 651 loss=0.138503 err=0.138503
I 2015-05-26 08:50:36 theanets.trainer:168 RmsProp 652 loss=0.134290 err=0.134290
I 2015-05-26 08:50:45 theanets.trainer:168 RmsProp 653 loss=0.140987 err=0.140987
I 2015-05-26 08:50:53 theanets.trainer:168 RmsProp 654 loss=0.150866 err=0.150866
I 2015-05-26 08:51:01 theanets.trainer:168 RmsProp 655 loss=0.132197 err=0.132197
I 2015-05-26 08:51:09 theanets.trainer:168 RmsProp 656 loss=0.134270 err=0.134270
I 2015-05-26 08:51:18 theanets.trainer:168 RmsProp 657 loss=0.135537 err=0.135537
I 2015-05-26 08:51:26 theanets.trainer:168 RmsProp 658 loss=0.133601 err=0.133601
I 2015-05-26 08:51:34 theanets.trainer:168 RmsProp 659 loss=0.128689 err=0.128689
I 2015-05-26 08:51:43 theanets.trainer:168 RmsProp 660 loss=0.143923 err=0.143923
I 2015-05-26 08:51:43 theanets.trainer:168 validation 66 loss=1625.166626 err=1625.166626 *
I 2015-05-26 08:51:51 theanets.trainer:168 RmsProp 661 loss=0.131495 err=0.131495
I 2015-05-26 08:51:59 theanets.trainer:168 RmsProp 662 loss=0.140078 err=0.140078
I 2015-05-26 08:52:07 theanets.trainer:168 RmsProp 663 loss=0.132110 err=0.132110
I 2015-05-26 08:52:15 theanets.trainer:168 RmsProp 664 loss=0.138843 err=0.138843
I 2015-05-26 08:52:23 theanets.trainer:168 RmsProp 665 loss=0.129519 err=0.129519
I 2015-05-26 08:52:31 theanets.trainer:168 RmsProp 666 loss=0.138960 err=0.138960
I 2015-05-26 08:52:39 theanets.trainer:168 RmsProp 667 loss=0.129301 err=0.129301
I 2015-05-26 08:52:47 theanets.trainer:168 RmsProp 668 loss=0.136988 err=0.136988
I 2015-05-26 08:52:55 theanets.trainer:168 RmsProp 669 loss=0.146731 err=0.146731
I 2015-05-26 08:53:03 theanets.trainer:168 RmsProp 670 loss=0.129368 err=0.129368
I 2015-05-26 08:53:03 theanets.trainer:168 validation 67 loss=1624.423462 err=1624.423462 *
I 2015-05-26 08:53:11 theanets.trainer:168 RmsProp 671 loss=0.119920 err=0.119920
I 2015-05-26 08:53:19 theanets.trainer:168 RmsProp 672 loss=0.152363 err=0.152363
I 2015-05-26 08:53:26 theanets.trainer:168 RmsProp 673 loss=0.125545 err=0.125545
I 2015-05-26 08:53:35 theanets.trainer:168 RmsProp 674 loss=0.129909 err=0.129909
I 2015-05-26 08:53:43 theanets.trainer:168 RmsProp 675 loss=0.136935 err=0.136935
I 2015-05-26 08:53:51 theanets.trainer:168 RmsProp 676 loss=0.136232 err=0.136232
I 2015-05-26 08:54:00 theanets.trainer:168 RmsProp 677 loss=0.134342 err=0.134342
I 2015-05-26 08:54:07 theanets.trainer:168 RmsProp 678 loss=0.129554 err=0.129554
I 2015-05-26 08:54:15 theanets.trainer:168 RmsProp 679 loss=0.133517 err=0.133517
I 2015-05-26 08:54:23 theanets.trainer:168 RmsProp 680 loss=0.130109 err=0.130109
I 2015-05-26 08:54:23 theanets.trainer:168 validation 68 loss=1626.072510 err=1626.072510
I 2015-05-26 08:54:31 theanets.trainer:168 RmsProp 681 loss=0.133966 err=0.133966
I 2015-05-26 08:54:39 theanets.trainer:168 RmsProp 682 loss=0.162100 err=0.162100
I 2015-05-26 08:54:47 theanets.trainer:168 RmsProp 683 loss=0.128945 err=0.128945
I 2015-05-26 08:54:55 theanets.trainer:168 RmsProp 684 loss=0.113072 err=0.113072
I 2015-05-26 08:55:01 theanets.trainer:168 RmsProp 685 loss=0.158542 err=0.158542
I 2015-05-26 08:55:09 theanets.trainer:168 RmsProp 686 loss=0.134079 err=0.134079
I 2015-05-26 08:55:16 theanets.trainer:168 RmsProp 687 loss=0.125923 err=0.125923
I 2015-05-26 08:55:24 theanets.trainer:168 RmsProp 688 loss=0.125736 err=0.125736
I 2015-05-26 08:55:32 theanets.trainer:168 RmsProp 689 loss=0.135079 err=0.135079
I 2015-05-26 08:55:39 theanets.trainer:168 RmsProp 690 loss=0.130390 err=0.130390
I 2015-05-26 08:55:40 theanets.trainer:168 validation 69 loss=1624.683472 err=1624.683472
I 2015-05-26 08:55:46 theanets.trainer:168 RmsProp 691 loss=0.127750 err=0.127750
I 2015-05-26 08:55:54 theanets.trainer:168 RmsProp 692 loss=0.125066 err=0.125066
I 2015-05-26 08:56:01 theanets.trainer:168 RmsProp 693 loss=0.127903 err=0.127903
I 2015-05-26 08:56:08 theanets.trainer:168 RmsProp 694 loss=0.137081 err=0.137081
I 2015-05-26 08:56:16 theanets.trainer:168 RmsProp 695 loss=0.149090 err=0.149090
I 2015-05-26 08:56:23 theanets.trainer:168 RmsProp 696 loss=0.122832 err=0.122832
I 2015-05-26 08:56:31 theanets.trainer:168 RmsProp 697 loss=0.128744 err=0.128744
I 2015-05-26 08:56:39 theanets.trainer:168 RmsProp 698 loss=0.130311 err=0.130311
I 2015-05-26 08:56:47 theanets.trainer:168 RmsProp 699 loss=0.129751 err=0.129751
I 2015-05-26 08:56:54 theanets.trainer:168 RmsProp 700 loss=0.128023 err=0.128023
I 2015-05-26 08:56:55 theanets.trainer:168 validation 70 loss=1619.265503 err=1619.265503 *
I 2015-05-26 08:57:02 theanets.trainer:168 RmsProp 701 loss=0.124412 err=0.124412
I 2015-05-26 08:57:10 theanets.trainer:168 RmsProp 702 loss=0.135986 err=0.135986
I 2015-05-26 08:57:18 theanets.trainer:168 RmsProp 703 loss=0.124228 err=0.124228
I 2015-05-26 08:57:25 theanets.trainer:168 RmsProp 704 loss=0.118965 err=0.118965
I 2015-05-26 08:57:32 theanets.trainer:168 RmsProp 705 loss=0.126559 err=0.126559
I 2015-05-26 08:57:40 theanets.trainer:168 RmsProp 706 loss=0.127168 err=0.127168
I 2015-05-26 08:57:48 theanets.trainer:168 RmsProp 707 loss=0.126919 err=0.126919
I 2015-05-26 08:57:56 theanets.trainer:168 RmsProp 708 loss=0.119585 err=0.119585
I 2015-05-26 08:58:04 theanets.trainer:168 RmsProp 709 loss=0.139927 err=0.139927
I 2015-05-26 08:58:11 theanets.trainer:168 RmsProp 710 loss=0.124586 err=0.124586
I 2015-05-26 08:58:11 theanets.trainer:168 validation 71 loss=1621.629761 err=1621.629761
I 2015-05-26 08:58:18 theanets.trainer:168 RmsProp 711 loss=0.130516 err=0.130516
I 2015-05-26 08:58:26 theanets.trainer:168 RmsProp 712 loss=0.136900 err=0.136900
I 2015-05-26 08:58:34 theanets.trainer:168 RmsProp 713 loss=0.123110 err=0.123110
I 2015-05-26 08:58:41 theanets.trainer:168 RmsProp 714 loss=0.122659 err=0.122659
I 2015-05-26 08:58:49 theanets.trainer:168 RmsProp 715 loss=0.122221 err=0.122221
I 2015-05-26 08:58:56 theanets.trainer:168 RmsProp 716 loss=0.126472 err=0.126472
I 2015-05-26 08:59:04 theanets.trainer:168 RmsProp 717 loss=0.128204 err=0.128204
I 2015-05-26 08:59:12 theanets.trainer:168 RmsProp 718 loss=0.122891 err=0.122891
I 2015-05-26 08:59:20 theanets.trainer:168 RmsProp 719 loss=0.129595 err=0.129595
I 2015-05-26 08:59:28 theanets.trainer:168 RmsProp 720 loss=0.131214 err=0.131214
I 2015-05-26 08:59:29 theanets.trainer:168 validation 72 loss=1620.824097 err=1620.824097
I 2015-05-26 08:59:36 theanets.trainer:168 RmsProp 721 loss=0.123632 err=0.123632
I 2015-05-26 08:59:43 theanets.trainer:168 RmsProp 722 loss=0.128284 err=0.128284
I 2015-05-26 08:59:51 theanets.trainer:168 RmsProp 723 loss=0.119336 err=0.119336
I 2015-05-26 08:59:58 theanets.trainer:168 RmsProp 724 loss=0.121655 err=0.121655
I 2015-05-26 09:00:06 theanets.trainer:168 RmsProp 725 loss=0.115798 err=0.115798
I 2015-05-26 09:00:13 theanets.trainer:168 RmsProp 726 loss=0.142963 err=0.142963
I 2015-05-26 09:00:21 theanets.trainer:168 RmsProp 727 loss=0.123609 err=0.123609
I 2015-05-26 09:00:29 theanets.trainer:168 RmsProp 728 loss=0.119344 err=0.119344
I 2015-05-26 09:00:37 theanets.trainer:168 RmsProp 729 loss=0.121773 err=0.121773
I 2015-05-26 09:00:44 theanets.trainer:168 RmsProp 730 loss=0.122057 err=0.122057
I 2015-05-26 09:00:45 theanets.trainer:168 validation 73 loss=1615.820068 err=1615.820068 *
I 2015-05-26 09:00:52 theanets.trainer:168 RmsProp 731 loss=0.109618 err=0.109618
I 2015-05-26 09:00:59 theanets.trainer:168 RmsProp 732 loss=0.148880 err=0.148880
I 2015-05-26 09:01:08 theanets.trainer:168 RmsProp 733 loss=0.126536 err=0.126536
I 2015-05-26 09:01:16 theanets.trainer:168 RmsProp 734 loss=0.121754 err=0.121754
I 2015-05-26 09:01:24 theanets.trainer:168 RmsProp 735 loss=0.123094 err=0.123094
I 2015-05-26 09:01:31 theanets.trainer:168 RmsProp 736 loss=0.126871 err=0.126871
I 2015-05-26 09:01:39 theanets.trainer:168 RmsProp 737 loss=0.121255 err=0.121255
I 2015-05-26 09:01:47 theanets.trainer:168 RmsProp 738 loss=0.117954 err=0.117954
I 2015-05-26 09:01:55 theanets.trainer:168 RmsProp 739 loss=0.125799 err=0.125799
I 2015-05-26 09:02:02 theanets.trainer:168 RmsProp 740 loss=0.119392 err=0.119392
I 2015-05-26 09:02:02 theanets.trainer:168 validation 74 loss=1616.491577 err=1616.491577
I 2015-05-26 09:02:10 theanets.trainer:168 RmsProp 741 loss=0.123245 err=0.123245
I 2015-05-26 09:02:17 theanets.trainer:168 RmsProp 742 loss=0.121547 err=0.121547
I 2015-05-26 09:02:24 theanets.trainer:168 RmsProp 743 loss=0.118182 err=0.118182
I 2015-05-26 09:02:32 theanets.trainer:168 RmsProp 744 loss=0.124124 err=0.124124
I 2015-05-26 09:02:39 theanets.trainer:168 RmsProp 745 loss=0.120371 err=0.120371
I 2015-05-26 09:02:48 theanets.trainer:168 RmsProp 746 loss=0.120764 err=0.120764
I 2015-05-26 09:02:56 theanets.trainer:168 RmsProp 747 loss=0.124210 err=0.124210
I 2015-05-26 09:03:04 theanets.trainer:168 RmsProp 748 loss=0.122000 err=0.122000
I 2015-05-26 09:03:12 theanets.trainer:168 RmsProp 749 loss=0.124746 err=0.124746
I 2015-05-26 09:03:19 theanets.trainer:168 RmsProp 750 loss=0.119594 err=0.119594
I 2015-05-26 09:03:19 theanets.trainer:168 validation 75 loss=1615.463257 err=1615.463257 *
I 2015-05-26 09:03:27 theanets.trainer:168 RmsProp 751 loss=0.111785 err=0.111785
I 2015-05-26 09:03:35 theanets.trainer:168 RmsProp 752 loss=0.139509 err=0.139509
I 2015-05-26 09:03:43 theanets.trainer:168 RmsProp 753 loss=0.114844 err=0.114844
I 2015-05-26 09:03:51 theanets.trainer:168 RmsProp 754 loss=0.117523 err=0.117523
I 2015-05-26 09:03:59 theanets.trainer:168 RmsProp 755 loss=0.118391 err=0.118391
I 2015-05-26 09:04:07 theanets.trainer:168 RmsProp 756 loss=0.119455 err=0.119455
I 2015-05-26 09:04:15 theanets.trainer:168 RmsProp 757 loss=0.121851 err=0.121851
I 2015-05-26 09:04:22 theanets.trainer:168 RmsProp 758 loss=0.115622 err=0.115622
I 2015-05-26 09:04:29 theanets.trainer:168 RmsProp 759 loss=0.117741 err=0.117741
I 2015-05-26 09:04:37 theanets.trainer:168 RmsProp 760 loss=0.122827 err=0.122827
I 2015-05-26 09:04:38 theanets.trainer:168 validation 76 loss=1614.315308 err=1614.315308 *
I 2015-05-26 09:04:46 theanets.trainer:168 RmsProp 761 loss=0.112539 err=0.112539
I 2015-05-26 09:04:53 theanets.trainer:168 RmsProp 762 loss=0.128785 err=0.128785
I 2015-05-26 09:05:01 theanets.trainer:168 RmsProp 763 loss=0.108252 err=0.108252
I 2015-05-26 09:05:08 theanets.trainer:168 RmsProp 764 loss=0.140240 err=0.140240
I 2015-05-26 09:05:16 theanets.trainer:168 RmsProp 765 loss=0.124176 err=0.124176
I 2015-05-26 09:05:23 theanets.trainer:168 RmsProp 766 loss=0.114441 err=0.114441
I 2015-05-26 09:05:31 theanets.trainer:168 RmsProp 767 loss=0.118526 err=0.118526
I 2015-05-26 09:05:39 theanets.trainer:168 RmsProp 768 loss=0.126684 err=0.126684
I 2015-05-26 09:05:46 theanets.trainer:168 RmsProp 769 loss=0.121168 err=0.121168
I 2015-05-26 09:05:54 theanets.trainer:168 RmsProp 770 loss=0.122984 err=0.122984
I 2015-05-26 09:05:55 theanets.trainer:168 validation 77 loss=1610.313721 err=1610.313721 *
I 2015-05-26 09:06:02 theanets.trainer:168 RmsProp 771 loss=0.110370 err=0.110370
I 2015-05-26 09:06:09 theanets.trainer:168 RmsProp 772 loss=0.104261 err=0.104261
I 2015-05-26 09:06:17 theanets.trainer:168 RmsProp 773 loss=0.164734 err=0.164734
I 2015-05-26 09:06:24 theanets.trainer:168 RmsProp 774 loss=0.129054 err=0.129054
I 2015-05-26 09:06:33 theanets.trainer:168 RmsProp 775 loss=0.107069 err=0.107069
I 2015-05-26 09:06:41 theanets.trainer:168 RmsProp 776 loss=0.123460 err=0.123460
I 2015-05-26 09:06:49 theanets.trainer:168 RmsProp 777 loss=0.122070 err=0.122070
I 2015-05-26 09:06:58 theanets.trainer:168 RmsProp 778 loss=0.113933 err=0.113933
I 2015-05-26 09:07:05 theanets.trainer:168 RmsProp 779 loss=0.116818 err=0.116818
I 2015-05-26 09:07:13 theanets.trainer:168 RmsProp 780 loss=0.114451 err=0.114451
I 2015-05-26 09:07:14 theanets.trainer:168 validation 78 loss=1611.354736 err=1611.354736
I 2015-05-26 09:07:20 theanets.trainer:168 RmsProp 781 loss=0.113339 err=0.113339
I 2015-05-26 09:07:28 theanets.trainer:168 RmsProp 782 loss=0.116416 err=0.116416
I 2015-05-26 09:07:36 theanets.trainer:168 RmsProp 783 loss=0.121245 err=0.121245
I 2015-05-26 09:07:44 theanets.trainer:168 RmsProp 784 loss=0.117914 err=0.117914
I 2015-05-26 09:07:52 theanets.trainer:168 RmsProp 785 loss=0.114932 err=0.114932
I 2015-05-26 09:08:00 theanets.trainer:168 RmsProp 786 loss=0.112131 err=0.112131
I 2015-05-26 09:08:08 theanets.trainer:168 RmsProp 787 loss=0.115278 err=0.115278
I 2015-05-26 09:08:15 theanets.trainer:168 RmsProp 788 loss=0.116116 err=0.116116
I 2015-05-26 09:08:23 theanets.trainer:168 RmsProp 789 loss=0.118972 err=0.118972
I 2015-05-26 09:08:30 theanets.trainer:168 RmsProp 790 loss=0.113625 err=0.113625
I 2015-05-26 09:08:31 theanets.trainer:168 validation 79 loss=1610.936401 err=1610.936401
I 2015-05-26 09:08:38 theanets.trainer:168 RmsProp 791 loss=0.121769 err=0.121769
I 2015-05-26 09:08:45 theanets.trainer:168 RmsProp 792 loss=0.113514 err=0.113514
I 2015-05-26 09:08:53 theanets.trainer:168 RmsProp 793 loss=0.114879 err=0.114879
I 2015-05-26 09:09:00 theanets.trainer:168 RmsProp 794 loss=0.114623 err=0.114623
I 2015-05-26 09:09:08 theanets.trainer:168 RmsProp 795 loss=0.113906 err=0.113906
I 2015-05-26 09:09:16 theanets.trainer:168 RmsProp 796 loss=0.115050 err=0.115050
I 2015-05-26 09:09:25 theanets.trainer:168 RmsProp 797 loss=0.109491 err=0.109491
I 2015-05-26 09:09:33 theanets.trainer:168 RmsProp 798 loss=0.124739 err=0.124739
I 2015-05-26 09:09:41 theanets.trainer:168 RmsProp 799 loss=0.115985 err=0.115985
I 2015-05-26 09:09:49 theanets.trainer:168 RmsProp 800 loss=0.113274 err=0.113274
I 2015-05-26 09:09:49 theanets.trainer:168 validation 80 loss=1608.051147 err=1608.051147 *
I 2015-05-26 09:09:57 theanets.trainer:168 RmsProp 801 loss=0.112862 err=0.112862
I 2015-05-26 09:10:04 theanets.trainer:168 RmsProp 802 loss=0.118718 err=0.118718
I 2015-05-26 09:10:12 theanets.trainer:168 RmsProp 803 loss=0.112838 err=0.112838
I 2015-05-26 09:10:20 theanets.trainer:168 RmsProp 804 loss=0.108562 err=0.108562
I 2015-05-26 09:10:28 theanets.trainer:168 RmsProp 805 loss=0.111598 err=0.111598
I 2015-05-26 09:10:36 theanets.trainer:168 RmsProp 806 loss=0.110365 err=0.110365
I 2015-05-26 09:10:43 theanets.trainer:168 RmsProp 807 loss=0.122818 err=0.122818
I 2015-05-26 09:10:50 theanets.trainer:168 RmsProp 808 loss=0.155591 err=0.155591
I 2015-05-26 09:10:58 theanets.trainer:168 RmsProp 809 loss=0.109488 err=0.109488
I 2015-05-26 09:11:06 theanets.trainer:168 RmsProp 810 loss=0.095532 err=0.095532
I 2015-05-26 09:11:07 theanets.trainer:168 validation 81 loss=1609.399414 err=1609.399414
I 2015-05-26 09:11:14 theanets.trainer:168 RmsProp 811 loss=0.137726 err=0.137726
I 2015-05-26 09:11:21 theanets.trainer:168 RmsProp 812 loss=0.109082 err=0.109082
I 2015-05-26 09:11:28 theanets.trainer:168 RmsProp 813 loss=0.110081 err=0.110081
I 2015-05-26 09:11:35 theanets.trainer:168 RmsProp 814 loss=0.114422 err=0.114422
I 2015-05-26 09:11:43 theanets.trainer:168 RmsProp 815 loss=0.106813 err=0.106813
I 2015-05-26 09:11:50 theanets.trainer:168 RmsProp 816 loss=0.116155 err=0.116155
I 2015-05-26 09:11:57 theanets.trainer:168 RmsProp 817 loss=0.111404 err=0.111404
I 2015-05-26 09:12:05 theanets.trainer:168 RmsProp 818 loss=0.106320 err=0.106320
I 2015-05-26 09:12:11 theanets.trainer:168 RmsProp 819 loss=0.113807 err=0.113807
I 2015-05-26 09:12:19 theanets.trainer:168 RmsProp 820 loss=0.126839 err=0.126839
I 2015-05-26 09:12:19 theanets.trainer:168 validation 82 loss=1609.135376 err=1609.135376
I 2015-05-26 09:12:27 theanets.trainer:168 RmsProp 821 loss=0.107845 err=0.107845
I 2015-05-26 09:12:34 theanets.trainer:168 RmsProp 822 loss=0.109059 err=0.109059
I 2015-05-26 09:12:41 theanets.trainer:168 RmsProp 823 loss=0.109424 err=0.109424
I 2015-05-26 09:12:48 theanets.trainer:168 RmsProp 824 loss=0.116104 err=0.116104
I 2015-05-26 09:12:55 theanets.trainer:168 RmsProp 825 loss=0.125586 err=0.125586
I 2015-05-26 09:13:03 theanets.trainer:168 RmsProp 826 loss=0.106445 err=0.106445
I 2015-05-26 09:13:10 theanets.trainer:168 RmsProp 827 loss=0.102836 err=0.102836
I 2015-05-26 09:13:17 theanets.trainer:168 RmsProp 828 loss=0.122317 err=0.122317
I 2015-05-26 09:13:24 theanets.trainer:168 RmsProp 829 loss=0.099550 err=0.099550
I 2015-05-26 09:13:31 theanets.trainer:168 RmsProp 830 loss=0.113475 err=0.113475
I 2015-05-26 09:13:32 theanets.trainer:168 validation 83 loss=1603.825317 err=1603.825317 *
I 2015-05-26 09:13:39 theanets.trainer:168 RmsProp 831 loss=0.109477 err=0.109477
I 2015-05-26 09:13:46 theanets.trainer:168 RmsProp 832 loss=0.118466 err=0.118466
I 2015-05-26 09:13:53 theanets.trainer:168 RmsProp 833 loss=0.107577 err=0.107577
I 2015-05-26 09:14:00 theanets.trainer:168 RmsProp 834 loss=0.108979 err=0.108979
I 2015-05-26 09:14:06 theanets.trainer:168 RmsProp 835 loss=0.104724 err=0.104724
I 2015-05-26 09:14:13 theanets.trainer:168 RmsProp 836 loss=0.111934 err=0.111934
I 2015-05-26 09:14:20 theanets.trainer:168 RmsProp 837 loss=0.104969 err=0.104969
I 2015-05-26 09:14:28 theanets.trainer:168 RmsProp 838 loss=0.119129 err=0.119129
I 2015-05-26 09:14:34 theanets.trainer:168 RmsProp 839 loss=0.111065 err=0.111065
I 2015-05-26 09:14:42 theanets.trainer:168 RmsProp 840 loss=0.110494 err=0.110494
I 2015-05-26 09:14:43 theanets.trainer:168 validation 84 loss=1605.216797 err=1605.216797
I 2015-05-26 09:14:50 theanets.trainer:168 RmsProp 841 loss=0.106207 err=0.106207
I 2015-05-26 09:14:57 theanets.trainer:168 RmsProp 842 loss=0.113839 err=0.113839
I 2015-05-26 09:15:04 theanets.trainer:168 RmsProp 843 loss=0.114003 err=0.114003
I 2015-05-26 09:15:12 theanets.trainer:168 RmsProp 844 loss=0.111332 err=0.111332
I 2015-05-26 09:15:19 theanets.trainer:168 RmsProp 845 loss=0.101806 err=0.101806
I 2015-05-26 09:15:27 theanets.trainer:168 RmsProp 846 loss=0.130476 err=0.130476
I 2015-05-26 09:15:34 theanets.trainer:168 RmsProp 847 loss=0.113245 err=0.113245
I 2015-05-26 09:15:41 theanets.trainer:168 RmsProp 848 loss=0.097515 err=0.097515
I 2015-05-26 09:15:48 theanets.trainer:168 RmsProp 849 loss=0.121315 err=0.121315
I 2015-05-26 09:15:55 theanets.trainer:168 RmsProp 850 loss=0.105763 err=0.105763
I 2015-05-26 09:15:55 theanets.trainer:168 validation 85 loss=1601.890015 err=1601.890015 *
I 2015-05-26 09:16:02 theanets.trainer:168 RmsProp 851 loss=0.110639 err=0.110639
I 2015-05-26 09:16:09 theanets.trainer:168 RmsProp 852 loss=0.109596 err=0.109596
I 2015-05-26 09:16:16 theanets.trainer:168 RmsProp 853 loss=0.106270 err=0.106270
I 2015-05-26 09:16:23 theanets.trainer:168 RmsProp 854 loss=0.110759 err=0.110759
I 2015-05-26 09:16:30 theanets.trainer:168 RmsProp 855 loss=0.103797 err=0.103797
I 2015-05-26 09:16:38 theanets.trainer:168 RmsProp 856 loss=0.101292 err=0.101292
I 2015-05-26 09:16:45 theanets.trainer:168 RmsProp 857 loss=0.107501 err=0.107501
I 2015-05-26 09:16:52 theanets.trainer:168 RmsProp 858 loss=0.109422 err=0.109422
I 2015-05-26 09:17:00 theanets.trainer:168 RmsProp 859 loss=0.108916 err=0.108916
I 2015-05-26 09:17:08 theanets.trainer:168 RmsProp 860 loss=0.104241 err=0.104241
I 2015-05-26 09:17:08 theanets.trainer:168 validation 86 loss=1600.225586 err=1600.225586 *
I 2015-05-26 09:17:15 theanets.trainer:168 RmsProp 861 loss=0.108205 err=0.108205
I 2015-05-26 09:17:23 theanets.trainer:168 RmsProp 862 loss=0.112539 err=0.112539
I 2015-05-26 09:17:30 theanets.trainer:168 RmsProp 863 loss=0.107037 err=0.107037
I 2015-05-26 09:17:37 theanets.trainer:168 RmsProp 864 loss=0.107221 err=0.107221
I 2015-05-26 09:17:44 theanets.trainer:168 RmsProp 865 loss=0.109433 err=0.109433
I 2015-05-26 09:17:51 theanets.trainer:168 RmsProp 866 loss=0.103887 err=0.103887
I 2015-05-26 09:17:58 theanets.trainer:168 RmsProp 867 loss=0.104765 err=0.104765
I 2015-05-26 09:18:06 theanets.trainer:168 RmsProp 868 loss=0.112509 err=0.112509
I 2015-05-26 09:18:13 theanets.trainer:168 RmsProp 869 loss=0.104763 err=0.104763
I 2015-05-26 09:18:20 theanets.trainer:168 RmsProp 870 loss=0.103753 err=0.103753
I 2015-05-26 09:18:21 theanets.trainer:168 validation 87 loss=1601.779907 err=1601.779907
I 2015-05-26 09:18:28 theanets.trainer:168 RmsProp 871 loss=0.101300 err=0.101300
I 2015-05-26 09:18:36 theanets.trainer:168 RmsProp 872 loss=0.106570 err=0.106570
I 2015-05-26 09:18:43 theanets.trainer:168 RmsProp 873 loss=0.108069 err=0.108069
I 2015-05-26 09:18:50 theanets.trainer:168 RmsProp 874 loss=0.097972 err=0.097972
I 2015-05-26 09:18:57 theanets.trainer:168 RmsProp 875 loss=0.107165 err=0.107165
I 2015-05-26 09:19:04 theanets.trainer:168 RmsProp 876 loss=0.104688 err=0.104688
I 2015-05-26 09:19:11 theanets.trainer:168 RmsProp 877 loss=0.098822 err=0.098822
I 2015-05-26 09:19:18 theanets.trainer:168 RmsProp 878 loss=0.110464 err=0.110464
I 2015-05-26 09:19:25 theanets.trainer:168 RmsProp 879 loss=0.102076 err=0.102076
I 2015-05-26 09:19:33 theanets.trainer:168 RmsProp 880 loss=0.102803 err=0.102803
I 2015-05-26 09:19:33 theanets.trainer:168 validation 88 loss=1605.422241 err=1605.422241
I 2015-05-26 09:19:40 theanets.trainer:168 RmsProp 881 loss=0.108910 err=0.108910
I 2015-05-26 09:19:47 theanets.trainer:168 RmsProp 882 loss=0.099459 err=0.099459
I 2015-05-26 09:19:54 theanets.trainer:168 RmsProp 883 loss=0.104398 err=0.104398
I 2015-05-26 09:20:02 theanets.trainer:168 RmsProp 884 loss=0.116355 err=0.116355
I 2015-05-26 09:20:10 theanets.trainer:168 RmsProp 885 loss=0.100585 err=0.100585
I 2015-05-26 09:20:17 theanets.trainer:168 RmsProp 886 loss=0.101524 err=0.101524
I 2015-05-26 09:20:25 theanets.trainer:168 RmsProp 887 loss=0.110893 err=0.110893
I 2015-05-26 09:20:31 theanets.trainer:168 RmsProp 888 loss=0.121372 err=0.121372
I 2015-05-26 09:20:39 theanets.trainer:168 RmsProp 889 loss=0.103051 err=0.103051
I 2015-05-26 09:20:46 theanets.trainer:168 RmsProp 890 loss=0.097797 err=0.097797
I 2015-05-26 09:20:47 theanets.trainer:168 validation 89 loss=1599.860229 err=1599.860229 *
I 2015-05-26 09:20:54 theanets.trainer:168 RmsProp 891 loss=0.102604 err=0.102604
I 2015-05-26 09:21:00 theanets.trainer:168 RmsProp 892 loss=0.100118 err=0.100118
I 2015-05-26 09:21:07 theanets.trainer:168 RmsProp 893 loss=0.110648 err=0.110648
I 2015-05-26 09:21:14 theanets.trainer:168 RmsProp 894 loss=0.101899 err=0.101899
I 2015-05-26 09:21:21 theanets.trainer:168 RmsProp 895 loss=0.100628 err=0.100628
I 2015-05-26 09:21:29 theanets.trainer:168 RmsProp 896 loss=0.100400 err=0.100400
I 2015-05-26 09:21:37 theanets.trainer:168 RmsProp 897 loss=0.102497 err=0.102497
I 2015-05-26 09:21:44 theanets.trainer:168 RmsProp 898 loss=0.101225 err=0.101225
I 2015-05-26 09:21:51 theanets.trainer:168 RmsProp 899 loss=0.102416 err=0.102416
I 2015-05-26 09:21:58 theanets.trainer:168 RmsProp 900 loss=0.113442 err=0.113442
I 2015-05-26 09:21:59 theanets.trainer:168 validation 90 loss=1602.201538 err=1602.201538
I 2015-05-26 09:22:05 theanets.trainer:168 RmsProp 901 loss=0.097403 err=0.097403
I 2015-05-26 09:22:12 theanets.trainer:168 RmsProp 902 loss=0.109789 err=0.109789
I 2015-05-26 09:22:19 theanets.trainer:168 RmsProp 903 loss=0.095583 err=0.095583
I 2015-05-26 09:22:27 theanets.trainer:168 RmsProp 904 loss=0.102629 err=0.102629
I 2015-05-26 09:22:34 theanets.trainer:168 RmsProp 905 loss=0.104097 err=0.104097
I 2015-05-26 09:22:41 theanets.trainer:168 RmsProp 906 loss=0.101331 err=0.101331
I 2015-05-26 09:22:47 theanets.trainer:168 RmsProp 907 loss=0.105476 err=0.105476
I 2015-05-26 09:22:54 theanets.trainer:168 RmsProp 908 loss=0.103224 err=0.103224
I 2015-05-26 09:23:01 theanets.trainer:168 RmsProp 909 loss=0.099039 err=0.099039
I 2015-05-26 09:23:08 theanets.trainer:168 RmsProp 910 loss=0.102687 err=0.102687
I 2015-05-26 09:23:08 theanets.trainer:168 validation 91 loss=1603.513672 err=1603.513672
I 2015-05-26 09:23:15 theanets.trainer:168 RmsProp 911 loss=0.096537 err=0.096537
I 2015-05-26 09:23:21 theanets.trainer:168 RmsProp 912 loss=0.102764 err=0.102764
I 2015-05-26 09:23:28 theanets.trainer:168 RmsProp 913 loss=0.101555 err=0.101555
I 2015-05-26 09:23:35 theanets.trainer:168 RmsProp 914 loss=0.099022 err=0.099022
I 2015-05-26 09:23:41 theanets.trainer:168 RmsProp 915 loss=0.106584 err=0.106584
I 2015-05-26 09:23:48 theanets.trainer:168 RmsProp 916 loss=0.098550 err=0.098550
I 2015-05-26 09:23:55 theanets.trainer:168 RmsProp 917 loss=0.090945 err=0.090945
I 2015-05-26 09:24:02 theanets.trainer:168 RmsProp 918 loss=0.119659 err=0.119659
I 2015-05-26 09:24:09 theanets.trainer:168 RmsProp 919 loss=0.093765 err=0.093765
I 2015-05-26 09:24:15 theanets.trainer:168 RmsProp 920 loss=0.087162 err=0.087162
I 2015-05-26 09:24:16 theanets.trainer:168 validation 92 loss=1605.688232 err=1605.688232
I 2015-05-26 09:24:23 theanets.trainer:168 RmsProp 921 loss=0.156053 err=0.156053
I 2015-05-26 09:24:29 theanets.trainer:168 RmsProp 922 loss=0.109256 err=0.109256
I 2015-05-26 09:24:37 theanets.trainer:168 RmsProp 923 loss=0.091721 err=0.091721
I 2015-05-26 09:24:43 theanets.trainer:168 RmsProp 924 loss=0.100829 err=0.100829
I 2015-05-26 09:24:49 theanets.trainer:168 RmsProp 925 loss=0.097660 err=0.097660
I 2015-05-26 09:24:57 theanets.trainer:168 RmsProp 926 loss=0.096878 err=0.096878
I 2015-05-26 09:25:04 theanets.trainer:168 RmsProp 927 loss=0.109638 err=0.109638
I 2015-05-26 09:25:10 theanets.trainer:168 RmsProp 928 loss=0.095961 err=0.095961
I 2015-05-26 09:25:16 theanets.trainer:168 RmsProp 929 loss=0.101742 err=0.101742
I 2015-05-26 09:25:23 theanets.trainer:168 RmsProp 930 loss=0.098854 err=0.098854
I 2015-05-26 09:25:23 theanets.trainer:168 validation 93 loss=1600.115356 err=1600.115356
I 2015-05-26 09:25:30 theanets.trainer:168 RmsProp 931 loss=0.102655 err=0.102655
I 2015-05-26 09:25:37 theanets.trainer:168 RmsProp 932 loss=0.098159 err=0.098159
I 2015-05-26 09:25:44 theanets.trainer:168 RmsProp 933 loss=0.097276 err=0.097276
I 2015-05-26 09:25:50 theanets.trainer:168 RmsProp 934 loss=0.100502 err=0.100502
I 2015-05-26 09:25:58 theanets.trainer:168 RmsProp 935 loss=0.104899 err=0.104899
I 2015-05-26 09:26:05 theanets.trainer:168 RmsProp 936 loss=0.096018 err=0.096018
I 2015-05-26 09:26:11 theanets.trainer:168 RmsProp 937 loss=0.090771 err=0.090771
I 2015-05-26 09:26:19 theanets.trainer:168 RmsProp 938 loss=0.103045 err=0.103045
I 2015-05-26 09:26:25 theanets.trainer:168 RmsProp 939 loss=0.098023 err=0.098023
I 2015-05-26 09:26:32 theanets.trainer:168 RmsProp 940 loss=0.099734 err=0.099734
I 2015-05-26 09:26:33 theanets.trainer:168 validation 94 loss=1597.162964 err=1597.162964 *
I 2015-05-26 09:26:40 theanets.trainer:168 RmsProp 941 loss=0.099812 err=0.099812
I 2015-05-26 09:26:46 theanets.trainer:168 RmsProp 942 loss=0.097590 err=0.097590
I 2015-05-26 09:26:53 theanets.trainer:168 RmsProp 943 loss=0.094578 err=0.094578
I 2015-05-26 09:27:00 theanets.trainer:168 RmsProp 944 loss=0.103467 err=0.103467
I 2015-05-26 09:27:07 theanets.trainer:168 RmsProp 945 loss=0.094178 err=0.094178
I 2015-05-26 09:27:14 theanets.trainer:168 RmsProp 946 loss=0.103344 err=0.103344
I 2015-05-26 09:27:21 theanets.trainer:168 RmsProp 947 loss=0.099504 err=0.099504
I 2015-05-26 09:27:28 theanets.trainer:168 RmsProp 948 loss=0.097480 err=0.097480
I 2015-05-26 09:27:35 theanets.trainer:168 RmsProp 949 loss=0.098231 err=0.098231
I 2015-05-26 09:27:41 theanets.trainer:168 RmsProp 950 loss=0.097731 err=0.097731
I 2015-05-26 09:27:42 theanets.trainer:168 validation 95 loss=1595.860352 err=1595.860352 *
I 2015-05-26 09:27:49 theanets.trainer:168 RmsProp 951 loss=0.094235 err=0.094235
I 2015-05-26 09:27:55 theanets.trainer:168 RmsProp 952 loss=0.097772 err=0.097772
I 2015-05-26 09:28:02 theanets.trainer:168 RmsProp 953 loss=0.100875 err=0.100875
I 2015-05-26 09:28:09 theanets.trainer:168 RmsProp 954 loss=0.097996 err=0.097996
I 2015-05-26 09:28:15 theanets.trainer:168 RmsProp 955 loss=0.098900 err=0.098900
I 2015-05-26 09:28:22 theanets.trainer:168 RmsProp 956 loss=0.095278 err=0.095278
I 2015-05-26 09:28:29 theanets.trainer:168 RmsProp 957 loss=0.095489 err=0.095489
I 2015-05-26 09:28:36 theanets.trainer:168 RmsProp 958 loss=0.100660 err=0.100660
I 2015-05-26 09:28:43 theanets.trainer:168 RmsProp 959 loss=0.096466 err=0.096466
I 2015-05-26 09:28:50 theanets.trainer:168 RmsProp 960 loss=0.092136 err=0.092136
I 2015-05-26 09:28:51 theanets.trainer:168 validation 96 loss=1596.077393 err=1596.077393
I 2015-05-26 09:28:57 theanets.trainer:168 RmsProp 961 loss=0.088664 err=0.088664
I 2015-05-26 09:29:04 theanets.trainer:168 RmsProp 962 loss=0.116848 err=0.116848
I 2015-05-26 09:29:10 theanets.trainer:168 RmsProp 963 loss=0.087294 err=0.087294
I 2015-05-26 09:29:17 theanets.trainer:168 RmsProp 964 loss=0.108626 err=0.108626
I 2015-05-26 09:29:24 theanets.trainer:168 RmsProp 965 loss=0.096172 err=0.096172
I 2015-05-26 09:29:31 theanets.trainer:168 RmsProp 966 loss=0.086175 err=0.086175
I 2015-05-26 09:29:38 theanets.trainer:168 RmsProp 967 loss=0.109779 err=0.109779
I 2015-05-26 09:29:45 theanets.trainer:168 RmsProp 968 loss=0.099915 err=0.099915
I 2015-05-26 09:29:51 theanets.trainer:168 RmsProp 969 loss=0.091922 err=0.091922
I 2015-05-26 09:29:58 theanets.trainer:168 RmsProp 970 loss=0.101173 err=0.101173
I 2015-05-26 09:29:58 theanets.trainer:168 validation 97 loss=1591.600708 err=1591.600708 *
I 2015-05-26 09:30:05 theanets.trainer:168 RmsProp 971 loss=0.094511 err=0.094511
I 2015-05-26 09:30:12 theanets.trainer:168 RmsProp 972 loss=0.102147 err=0.102147
I 2015-05-26 09:30:18 theanets.trainer:168 RmsProp 973 loss=0.094988 err=0.094988
I 2015-05-26 09:30:25 theanets.trainer:168 RmsProp 974 loss=0.093862 err=0.093862
I 2015-05-26 09:30:32 theanets.trainer:168 RmsProp 975 loss=0.105742 err=0.105742
I 2015-05-26 09:30:39 theanets.trainer:168 RmsProp 976 loss=0.098059 err=0.098059
I 2015-05-26 09:30:46 theanets.trainer:168 RmsProp 977 loss=0.090048 err=0.090048
I 2015-05-26 09:30:53 theanets.trainer:168 RmsProp 978 loss=0.096969 err=0.096969
I 2015-05-26 09:31:00 theanets.trainer:168 RmsProp 979 loss=0.094492 err=0.094492
I 2015-05-26 09:31:07 theanets.trainer:168 RmsProp 980 loss=0.099585 err=0.099585
I 2015-05-26 09:31:07 theanets.trainer:168 validation 98 loss=1592.661743 err=1592.661743
I 2015-05-26 09:31:14 theanets.trainer:168 RmsProp 981 loss=0.099327 err=0.099327
I 2015-05-26 09:31:21 theanets.trainer:168 RmsProp 982 loss=0.093633 err=0.093633
I 2015-05-26 09:31:27 theanets.trainer:168 RmsProp 983 loss=0.093130 err=0.093130
I 2015-05-26 09:31:34 theanets.trainer:168 RmsProp 984 loss=0.089646 err=0.089646
I 2015-05-26 09:31:41 theanets.trainer:168 RmsProp 985 loss=0.102636 err=0.102636
I 2015-05-26 09:31:48 theanets.trainer:168 RmsProp 986 loss=0.085588 err=0.085588
I 2015-05-26 09:31:55 theanets.trainer:168 RmsProp 987 loss=0.103696 err=0.103696
I 2015-05-26 09:32:01 theanets.trainer:168 RmsProp 988 loss=0.090524 err=0.090524
I 2015-05-26 09:32:08 theanets.trainer:168 RmsProp 989 loss=0.102244 err=0.102244
I 2015-05-26 09:32:14 theanets.trainer:168 RmsProp 990 loss=0.093542 err=0.093542
I 2015-05-26 09:32:15 theanets.trainer:168 validation 99 loss=1594.723022 err=1594.723022
I 2015-05-26 09:32:21 theanets.trainer:168 RmsProp 991 loss=0.091830 err=0.091830
I 2015-05-26 09:32:28 theanets.trainer:168 RmsProp 992 loss=0.094831 err=0.094831
I 2015-05-26 09:32:35 theanets.trainer:168 RmsProp 993 loss=0.091943 err=0.091943
I 2015-05-26 09:32:41 theanets.trainer:168 RmsProp 994 loss=0.097807 err=0.097807
I 2015-05-26 09:32:48 theanets.trainer:168 RmsProp 995 loss=0.104528 err=0.104528
I 2015-05-26 09:32:54 theanets.trainer:168 RmsProp 996 loss=0.091394 err=0.091394
I 2015-05-26 09:33:01 theanets.trainer:168 RmsProp 997 loss=0.086810 err=0.086810
I 2015-05-26 09:33:07 theanets.trainer:168 RmsProp 998 loss=0.108033 err=0.108033
I 2015-05-26 09:33:14 theanets.trainer:168 RmsProp 999 loss=0.089733 err=0.089733
I 2015-05-26 09:33:20 theanets.trainer:168 RmsProp 1000 loss=0.085372 err=0.085372
I 2015-05-26 09:33:21 theanets.trainer:168 validation 100 loss=1591.869385 err=1591.869385
I 2015-05-26 09:33:28 theanets.trainer:168 RmsProp 1001 loss=0.129231 err=0.129231
I 2015-05-26 09:33:35 theanets.trainer:168 RmsProp 1002 loss=0.092186 err=0.092186
I 2015-05-26 09:33:42 theanets.trainer:168 RmsProp 1003 loss=0.087022 err=0.087022
I 2015-05-26 09:33:49 theanets.trainer:168 RmsProp 1004 loss=0.094764 err=0.094764
I 2015-05-26 09:33:56 theanets.trainer:168 RmsProp 1005 loss=0.091846 err=0.091846
I 2015-05-26 09:34:03 theanets.trainer:168 RmsProp 1006 loss=0.098087 err=0.098087
I 2015-05-26 09:34:09 theanets.trainer:168 RmsProp 1007 loss=0.106888 err=0.106888
I 2015-05-26 09:34:16 theanets.trainer:168 RmsProp 1008 loss=0.088802 err=0.088802
I 2015-05-26 09:34:23 theanets.trainer:168 RmsProp 1009 loss=0.086504 err=0.086504
I 2015-05-26 09:34:30 theanets.trainer:168 RmsProp 1010 loss=0.096019 err=0.096019
I 2015-05-26 09:34:30 theanets.trainer:168 validation 101 loss=1590.462646 err=1590.462646 *
I 2015-05-26 09:34:36 theanets.trainer:168 RmsProp 1011 loss=0.092504 err=0.092504
I 2015-05-26 09:34:42 theanets.trainer:168 RmsProp 1012 loss=0.087669 err=0.087669
I 2015-05-26 09:34:49 theanets.trainer:168 RmsProp 1013 loss=0.094435 err=0.094435
I 2015-05-26 09:34:56 theanets.trainer:168 RmsProp 1014 loss=0.083261 err=0.083261
I 2015-05-26 09:35:03 theanets.trainer:168 RmsProp 1015 loss=0.106504 err=0.106504
I 2015-05-26 09:35:09 theanets.trainer:168 RmsProp 1016 loss=0.091666 err=0.091666
I 2015-05-26 09:35:15 theanets.trainer:168 RmsProp 1017 loss=0.089080 err=0.089080
I 2015-05-26 09:35:22 theanets.trainer:168 RmsProp 1018 loss=0.088090 err=0.088090
I 2015-05-26 09:35:29 theanets.trainer:168 RmsProp 1019 loss=0.096144 err=0.096144
I 2015-05-26 09:35:35 theanets.trainer:168 RmsProp 1020 loss=0.092475 err=0.092475
I 2015-05-26 09:35:36 theanets.trainer:168 validation 102 loss=1588.749634 err=1588.749634 *
I 2015-05-26 09:35:42 theanets.trainer:168 RmsProp 1021 loss=0.093791 err=0.093791
I 2015-05-26 09:35:48 theanets.trainer:168 RmsProp 1022 loss=0.085852 err=0.085852
I 2015-05-26 09:35:55 theanets.trainer:168 RmsProp 1023 loss=0.096612 err=0.096612
I 2015-05-26 09:36:02 theanets.trainer:168 RmsProp 1024 loss=0.090404 err=0.090404
I 2015-05-26 09:36:09 theanets.trainer:168 RmsProp 1025 loss=0.087150 err=0.087150
I 2015-05-26 09:36:17 theanets.trainer:168 RmsProp 1026 loss=0.090617 err=0.090617
I 2015-05-26 09:36:24 theanets.trainer:168 RmsProp 1027 loss=0.098829 err=0.098829
I 2015-05-26 09:36:30 theanets.trainer:168 RmsProp 1028 loss=0.085507 err=0.085507
I 2015-05-26 09:36:37 theanets.trainer:168 RmsProp 1029 loss=0.094385 err=0.094385
I 2015-05-26 09:36:44 theanets.trainer:168 RmsProp 1030 loss=0.093307 err=0.093307
I 2015-05-26 09:36:44 theanets.trainer:168 validation 103 loss=1588.617432 err=1588.617432 *
I 2015-05-26 09:36:51 theanets.trainer:168 RmsProp 1031 loss=0.094568 err=0.094568
I 2015-05-26 09:36:57 theanets.trainer:168 RmsProp 1032 loss=0.085265 err=0.085265
I 2015-05-26 09:37:04 theanets.trainer:168 RmsProp 1033 loss=0.089223 err=0.089223
I 2015-05-26 09:37:10 theanets.trainer:168 RmsProp 1034 loss=0.091278 err=0.091278
I 2015-05-26 09:37:17 theanets.trainer:168 RmsProp 1035 loss=0.094857 err=0.094857
I 2015-05-26 09:37:23 theanets.trainer:168 RmsProp 1036 loss=0.088123 err=0.088123
I 2015-05-26 09:37:31 theanets.trainer:168 RmsProp 1037 loss=0.096510 err=0.096510
I 2015-05-26 09:37:38 theanets.trainer:168 RmsProp 1038 loss=0.094332 err=0.094332
I 2015-05-26 09:37:45 theanets.trainer:168 RmsProp 1039 loss=0.090047 err=0.090047
I 2015-05-26 09:37:52 theanets.trainer:168 RmsProp 1040 loss=0.092258 err=0.092258
I 2015-05-26 09:37:52 theanets.trainer:168 validation 104 loss=1585.172485 err=1585.172485 *
I 2015-05-26 09:37:59 theanets.trainer:168 RmsProp 1041 loss=0.102404 err=0.102404
I 2015-05-26 09:38:06 theanets.trainer:168 RmsProp 1042 loss=0.089308 err=0.089308
I 2015-05-26 09:38:13 theanets.trainer:168 RmsProp 1043 loss=0.092646 err=0.092646
I 2015-05-26 09:38:20 theanets.trainer:168 RmsProp 1044 loss=0.089377 err=0.089377
I 2015-05-26 09:38:27 theanets.trainer:168 RmsProp 1045 loss=0.093252 err=0.093252
I 2015-05-26 09:38:33 theanets.trainer:168 RmsProp 1046 loss=0.093450 err=0.093450
I 2015-05-26 09:38:40 theanets.trainer:168 RmsProp 1047 loss=0.078936 err=0.078936
I 2015-05-26 09:38:46 theanets.trainer:168 RmsProp 1048 loss=0.111940 err=0.111940
I 2015-05-26 09:38:53 theanets.trainer:168 RmsProp 1049 loss=0.088567 err=0.088567
I 2015-05-26 09:39:00 theanets.trainer:168 RmsProp 1050 loss=0.082008 err=0.082008
I 2015-05-26 09:39:01 theanets.trainer:168 validation 105 loss=1586.360474 err=1586.360474
I 2015-05-26 09:39:07 theanets.trainer:168 RmsProp 1051 loss=0.092332 err=0.092332
I 2015-05-26 09:39:14 theanets.trainer:168 RmsProp 1052 loss=0.092826 err=0.092826
I 2015-05-26 09:39:20 theanets.trainer:168 RmsProp 1053 loss=0.087587 err=0.087587
I 2015-05-26 09:39:27 theanets.trainer:168 RmsProp 1054 loss=0.094392 err=0.094392
I 2015-05-26 09:39:33 theanets.trainer:168 RmsProp 1055 loss=0.089725 err=0.089725
I 2015-05-26 09:39:40 theanets.trainer:168 RmsProp 1056 loss=0.088983 err=0.088983
I 2015-05-26 09:39:47 theanets.trainer:168 RmsProp 1057 loss=0.082792 err=0.082792
I 2015-05-26 09:39:53 theanets.trainer:168 RmsProp 1058 loss=0.095823 err=0.095823
I 2015-05-26 09:40:00 theanets.trainer:168 RmsProp 1059 loss=0.091676 err=0.091676
I 2015-05-26 09:40:06 theanets.trainer:168 RmsProp 1060 loss=0.090643 err=0.090643
I 2015-05-26 09:40:07 theanets.trainer:168 validation 106 loss=1587.776978 err=1587.776978
I 2015-05-26 09:40:13 theanets.trainer:168 RmsProp 1061 loss=0.086106 err=0.086106
I 2015-05-26 09:40:20 theanets.trainer:168 RmsProp 1062 loss=0.088600 err=0.088600
I 2015-05-26 09:40:26 theanets.trainer:168 RmsProp 1063 loss=0.087007 err=0.087007
I 2015-05-26 09:40:33 theanets.trainer:168 RmsProp 1064 loss=0.090265 err=0.090265
I 2015-05-26 09:40:40 theanets.trainer:168 RmsProp 1065 loss=0.087762 err=0.087762
I 2015-05-26 09:40:47 theanets.trainer:168 RmsProp 1066 loss=0.087509 err=0.087509
I 2015-05-26 09:40:54 theanets.trainer:168 RmsProp 1067 loss=0.091426 err=0.091426
I 2015-05-26 09:41:01 theanets.trainer:168 RmsProp 1068 loss=0.080936 err=0.080936
I 2015-05-26 09:41:08 theanets.trainer:168 RmsProp 1069 loss=0.095063 err=0.095063
I 2015-05-26 09:41:15 theanets.trainer:168 RmsProp 1070 loss=0.087536 err=0.087536
I 2015-05-26 09:41:15 theanets.trainer:168 validation 107 loss=1584.317993 err=1584.317993 *
I 2015-05-26 09:41:22 theanets.trainer:168 RmsProp 1071 loss=0.088860 err=0.088860
I 2015-05-26 09:41:29 theanets.trainer:168 RmsProp 1072 loss=0.090792 err=0.090792
I 2015-05-26 09:41:36 theanets.trainer:168 RmsProp 1073 loss=0.086548 err=0.086548
I 2015-05-26 09:41:42 theanets.trainer:168 RmsProp 1074 loss=0.091362 err=0.091362
I 2015-05-26 09:41:49 theanets.trainer:168 RmsProp 1075 loss=0.089099 err=0.089099
I 2015-05-26 09:41:55 theanets.trainer:168 RmsProp 1076 loss=0.086119 err=0.086119
I 2015-05-26 09:42:02 theanets.trainer:168 RmsProp 1077 loss=0.086429 err=0.086429
I 2015-05-26 09:42:09 theanets.trainer:168 RmsProp 1078 loss=0.090944 err=0.090944
I 2015-05-26 09:42:15 theanets.trainer:168 RmsProp 1079 loss=0.084385 err=0.084385
I 2015-05-26 09:42:22 theanets.trainer:168 RmsProp 1080 loss=0.098865 err=0.098865
I 2015-05-26 09:42:22 theanets.trainer:168 validation 108 loss=1586.171753 err=1586.171753
I 2015-05-26 09:42:29 theanets.trainer:168 RmsProp 1081 loss=0.085741 err=0.085741
I 2015-05-26 09:42:36 theanets.trainer:168 RmsProp 1082 loss=0.083159 err=0.083159
I 2015-05-26 09:42:43 theanets.trainer:168 RmsProp 1083 loss=0.090306 err=0.090306
I 2015-05-26 09:42:50 theanets.trainer:168 RmsProp 1084 loss=0.088218 err=0.088218
I 2015-05-26 09:42:57 theanets.trainer:168 RmsProp 1085 loss=0.081926 err=0.081926
I 2015-05-26 09:43:03 theanets.trainer:168 RmsProp 1086 loss=0.093699 err=0.093699
I 2015-05-26 09:43:09 theanets.trainer:168 RmsProp 1087 loss=0.085572 err=0.085572
I 2015-05-26 09:43:16 theanets.trainer:168 RmsProp 1088 loss=0.089115 err=0.089115
I 2015-05-26 09:43:23 theanets.trainer:168 RmsProp 1089 loss=0.082111 err=0.082111
I 2015-05-26 09:43:30 theanets.trainer:168 RmsProp 1090 loss=0.092256 err=0.092256
I 2015-05-26 09:43:30 theanets.trainer:168 validation 109 loss=1582.885376 err=1582.885376 *
I 2015-05-26 09:43:37 theanets.trainer:168 RmsProp 1091 loss=0.085480 err=0.085480
I 2015-05-26 09:43:43 theanets.trainer:168 RmsProp 1092 loss=0.085424 err=0.085424
I 2015-05-26 09:43:50 theanets.trainer:168 RmsProp 1093 loss=0.087709 err=0.087709
I 2015-05-26 09:43:56 theanets.trainer:168 RmsProp 1094 loss=0.087590 err=0.087590
I 2015-05-26 09:44:02 theanets.trainer:168 RmsProp 1095 loss=0.089221 err=0.089221
I 2015-05-26 09:44:08 theanets.trainer:168 RmsProp 1096 loss=0.077987 err=0.077987
I 2015-05-26 09:44:15 theanets.trainer:168 RmsProp 1097 loss=0.098868 err=0.098868
I 2015-05-26 09:44:22 theanets.trainer:168 RmsProp 1098 loss=0.089575 err=0.089575
I 2015-05-26 09:44:30 theanets.trainer:168 RmsProp 1099 loss=0.083680 err=0.083680
I 2015-05-26 09:44:37 theanets.trainer:168 RmsProp 1100 loss=0.081377 err=0.081377
I 2015-05-26 09:44:37 theanets.trainer:168 validation 110 loss=1584.364136 err=1584.364136
I 2015-05-26 09:44:45 theanets.trainer:168 RmsProp 1101 loss=0.090319 err=0.090319
I 2015-05-26 09:44:52 theanets.trainer:168 RmsProp 1102 loss=0.086082 err=0.086082
I 2015-05-26 09:44:59 theanets.trainer:168 RmsProp 1103 loss=0.085361 err=0.085361
I 2015-05-26 09:45:06 theanets.trainer:168 RmsProp 1104 loss=0.084214 err=0.084214
I 2015-05-26 09:45:12 theanets.trainer:168 RmsProp 1105 loss=0.088939 err=0.088939
I 2015-05-26 09:45:20 theanets.trainer:168 RmsProp 1106 loss=0.083583 err=0.083583
I 2015-05-26 09:45:26 theanets.trainer:168 RmsProp 1107 loss=0.085298 err=0.085298
I 2015-05-26 09:45:33 theanets.trainer:168 RmsProp 1108 loss=0.089475 err=0.089475
I 2015-05-26 09:45:40 theanets.trainer:168 RmsProp 1109 loss=0.075369 err=0.075369
I 2015-05-26 09:45:47 theanets.trainer:168 RmsProp 1110 loss=0.101123 err=0.101123
I 2015-05-26 09:45:47 theanets.trainer:168 validation 111 loss=1580.655396 err=1580.655396 *
I 2015-05-26 09:45:54 theanets.trainer:168 RmsProp 1111 loss=0.082788 err=0.082788
I 2015-05-26 09:46:01 theanets.trainer:168 RmsProp 1112 loss=0.083170 err=0.083170
I 2015-05-26 09:46:08 theanets.trainer:168 RmsProp 1113 loss=0.097052 err=0.097052
I 2015-05-26 09:46:15 theanets.trainer:168 RmsProp 1114 loss=0.081870 err=0.081870
I 2015-05-26 09:46:22 theanets.trainer:168 RmsProp 1115 loss=0.088868 err=0.088868
I 2015-05-26 09:46:29 theanets.trainer:168 RmsProp 1116 loss=0.085981 err=0.085981
I 2015-05-26 09:46:35 theanets.trainer:168 RmsProp 1117 loss=0.089653 err=0.089653
I 2015-05-26 09:46:42 theanets.trainer:168 RmsProp 1118 loss=0.080852 err=0.080852
I 2015-05-26 09:46:49 theanets.trainer:168 RmsProp 1119 loss=0.088089 err=0.088089
I 2015-05-26 09:46:55 theanets.trainer:168 RmsProp 1120 loss=0.081434 err=0.081434
I 2015-05-26 09:46:56 theanets.trainer:168 validation 112 loss=1581.457764 err=1581.457764
I 2015-05-26 09:47:02 theanets.trainer:168 RmsProp 1121 loss=0.087734 err=0.087734
I 2015-05-26 09:47:09 theanets.trainer:168 RmsProp 1122 loss=0.087736 err=0.087736
I 2015-05-26 09:47:15 theanets.trainer:168 RmsProp 1123 loss=0.082935 err=0.082935
I 2015-05-26 09:47:22 theanets.trainer:168 RmsProp 1124 loss=0.076960 err=0.076960
I 2015-05-26 09:47:28 theanets.trainer:168 RmsProp 1125 loss=0.097182 err=0.097182
I 2015-05-26 09:47:35 theanets.trainer:168 RmsProp 1126 loss=0.075996 err=0.075996
I 2015-05-26 09:47:42 theanets.trainer:168 RmsProp 1127 loss=0.087083 err=0.087083
I 2015-05-26 09:47:49 theanets.trainer:168 RmsProp 1128 loss=0.086433 err=0.086433
I 2015-05-26 09:47:56 theanets.trainer:168 RmsProp 1129 loss=0.087762 err=0.087762
I 2015-05-26 09:48:02 theanets.trainer:168 RmsProp 1130 loss=0.082324 err=0.082324
I 2015-05-26 09:48:03 theanets.trainer:168 validation 113 loss=1580.973145 err=1580.973145
I 2015-05-26 09:48:10 theanets.trainer:168 RmsProp 1131 loss=0.082584 err=0.082584
I 2015-05-26 09:48:17 theanets.trainer:168 RmsProp 1132 loss=0.082530 err=0.082530
I 2015-05-26 09:48:24 theanets.trainer:168 RmsProp 1133 loss=0.084016 err=0.084016
I 2015-05-26 09:48:31 theanets.trainer:168 RmsProp 1134 loss=0.090587 err=0.090587
I 2015-05-26 09:48:38 theanets.trainer:168 RmsProp 1135 loss=0.082630 err=0.082630
I 2015-05-26 09:48:44 theanets.trainer:168 RmsProp 1136 loss=0.082534 err=0.082534
I 2015-05-26 09:48:51 theanets.trainer:168 RmsProp 1137 loss=0.078178 err=0.078178
I 2015-05-26 09:48:58 theanets.trainer:168 RmsProp 1138 loss=0.097137 err=0.097137
I 2015-05-26 09:49:04 theanets.trainer:168 RmsProp 1139 loss=0.083359 err=0.083359
I 2015-05-26 09:49:10 theanets.trainer:168 RmsProp 1140 loss=0.073525 err=0.073525
I 2015-05-26 09:49:11 theanets.trainer:168 validation 114 loss=1580.345337 err=1580.345337 *
I 2015-05-26 09:49:17 theanets.trainer:168 RmsProp 1141 loss=0.098521 err=0.098521
I 2015-05-26 09:49:23 theanets.trainer:168 RmsProp 1142 loss=0.081035 err=0.081035
I 2015-05-26 09:49:30 theanets.trainer:168 RmsProp 1143 loss=0.083587 err=0.083587
I 2015-05-26 09:49:37 theanets.trainer:168 RmsProp 1144 loss=0.080011 err=0.080011
I 2015-05-26 09:49:43 theanets.trainer:168 RmsProp 1145 loss=0.083246 err=0.083246
I 2015-05-26 09:49:49 theanets.trainer:168 RmsProp 1146 loss=0.080592 err=0.080592
I 2015-05-26 09:49:56 theanets.trainer:168 RmsProp 1147 loss=0.079427 err=0.079427
I 2015-05-26 09:50:03 theanets.trainer:168 RmsProp 1148 loss=0.086415 err=0.086415
I 2015-05-26 09:50:09 theanets.trainer:168 RmsProp 1149 loss=0.085371 err=0.085371
I 2015-05-26 09:50:16 theanets.trainer:168 RmsProp 1150 loss=0.083450 err=0.083450
I 2015-05-26 09:50:17 theanets.trainer:168 validation 115 loss=1576.097412 err=1576.097412 *
I 2015-05-26 09:50:23 theanets.trainer:168 RmsProp 1151 loss=0.083790 err=0.083790
I 2015-05-26 09:50:30 theanets.trainer:168 RmsProp 1152 loss=0.083704 err=0.083704
I 2015-05-26 09:50:36 theanets.trainer:168 RmsProp 1153 loss=0.078533 err=0.078533
I 2015-05-26 09:50:43 theanets.trainer:168 RmsProp 1154 loss=0.086069 err=0.086069
I 2015-05-26 09:50:50 theanets.trainer:168 RmsProp 1155 loss=0.081104 err=0.081104
I 2015-05-26 09:50:57 theanets.trainer:168 RmsProp 1156 loss=0.078420 err=0.078420
I 2015-05-26 09:51:03 theanets.trainer:168 RmsProp 1157 loss=0.081468 err=0.081468
I 2015-05-26 09:51:10 theanets.trainer:168 RmsProp 1158 loss=0.097317 err=0.097317
I 2015-05-26 09:51:17 theanets.trainer:168 RmsProp 1159 loss=0.082391 err=0.082391
I 2015-05-26 09:51:23 theanets.trainer:168 RmsProp 1160 loss=0.071902 err=0.071902
I 2015-05-26 09:51:24 theanets.trainer:168 validation 116 loss=1578.972290 err=1578.972290
I 2015-05-26 09:51:30 theanets.trainer:168 RmsProp 1161 loss=0.102420 err=0.102420
I 2015-05-26 09:51:37 theanets.trainer:168 RmsProp 1162 loss=0.076640 err=0.076640
I 2015-05-26 09:51:44 theanets.trainer:168 RmsProp 1163 loss=0.079330 err=0.079330
I 2015-05-26 09:51:51 theanets.trainer:168 RmsProp 1164 loss=0.091454 err=0.091454
I 2015-05-26 09:51:58 theanets.trainer:168 RmsProp 1165 loss=0.073675 err=0.073675
I 2015-05-26 09:52:05 theanets.trainer:168 RmsProp 1166 loss=0.090228 err=0.090228
I 2015-05-26 09:52:11 theanets.trainer:168 RmsProp 1167 loss=0.077223 err=0.077223
I 2015-05-26 09:52:17 theanets.trainer:168 RmsProp 1168 loss=0.082424 err=0.082424
I 2015-05-26 09:52:24 theanets.trainer:168 RmsProp 1169 loss=0.083018 err=0.083018
I 2015-05-26 09:52:31 theanets.trainer:168 RmsProp 1170 loss=0.080821 err=0.080821
I 2015-05-26 09:52:32 theanets.trainer:168 validation 117 loss=1578.869995 err=1578.869995
I 2015-05-26 09:52:38 theanets.trainer:168 RmsProp 1171 loss=0.080623 err=0.080623
I 2015-05-26 09:52:45 theanets.trainer:168 RmsProp 1172 loss=0.078574 err=0.078574
I 2015-05-26 09:52:53 theanets.trainer:168 RmsProp 1173 loss=0.079687 err=0.079687
I 2015-05-26 09:53:00 theanets.trainer:168 RmsProp 1174 loss=0.085072 err=0.085072
I 2015-05-26 09:53:06 theanets.trainer:168 RmsProp 1175 loss=0.080643 err=0.080643
I 2015-05-26 09:53:14 theanets.trainer:168 RmsProp 1176 loss=0.085299 err=0.085299
I 2015-05-26 09:53:20 theanets.trainer:168 RmsProp 1177 loss=0.084634 err=0.084634
I 2015-05-26 09:53:27 theanets.trainer:168 RmsProp 1178 loss=0.074158 err=0.074158
I 2015-05-26 09:53:35 theanets.trainer:168 RmsProp 1179 loss=0.079634 err=0.079634
I 2015-05-26 09:53:42 theanets.trainer:168 RmsProp 1180 loss=0.084713 err=0.084713
I 2015-05-26 09:53:42 theanets.trainer:168 validation 118 loss=1575.777344 err=1575.777344 *
I 2015-05-26 09:53:49 theanets.trainer:168 RmsProp 1181 loss=0.080172 err=0.080172
I 2015-05-26 09:53:56 theanets.trainer:168 RmsProp 1182 loss=0.081845 err=0.081845
I 2015-05-26 09:54:03 theanets.trainer:168 RmsProp 1183 loss=0.086285 err=0.086285
I 2015-05-26 09:54:10 theanets.trainer:168 RmsProp 1184 loss=0.078100 err=0.078100
I 2015-05-26 09:54:17 theanets.trainer:168 RmsProp 1185 loss=0.073952 err=0.073952
I 2015-05-26 09:54:25 theanets.trainer:168 RmsProp 1186 loss=0.083774 err=0.083774
I 2015-05-26 09:54:32 theanets.trainer:168 RmsProp 1187 loss=0.082776 err=0.082776
I 2015-05-26 09:54:39 theanets.trainer:168 RmsProp 1188 loss=0.078223 err=0.078223
I 2015-05-26 09:54:46 theanets.trainer:168 RmsProp 1189 loss=0.081539 err=0.081539
I 2015-05-26 09:54:53 theanets.trainer:168 RmsProp 1190 loss=0.088730 err=0.088730
I 2015-05-26 09:54:53 theanets.trainer:168 validation 119 loss=1578.359741 err=1578.359741
I 2015-05-26 09:55:00 theanets.trainer:168 RmsProp 1191 loss=0.078249 err=0.078249
I 2015-05-26 09:55:07 theanets.trainer:168 RmsProp 1192 loss=0.079223 err=0.079223
I 2015-05-26 09:55:15 theanets.trainer:168 RmsProp 1193 loss=0.088740 err=0.088740
I 2015-05-26 09:55:22 theanets.trainer:168 RmsProp 1194 loss=0.080726 err=0.080726
I 2015-05-26 09:55:29 theanets.trainer:168 RmsProp 1195 loss=0.079493 err=0.079493
I 2015-05-26 09:55:35 theanets.trainer:168 RmsProp 1196 loss=0.078841 err=0.078841
I 2015-05-26 09:55:43 theanets.trainer:168 RmsProp 1197 loss=0.079831 err=0.079831
I 2015-05-26 09:55:50 theanets.trainer:168 RmsProp 1198 loss=0.079963 err=0.079963
I 2015-05-26 09:55:57 theanets.trainer:168 RmsProp 1199 loss=0.081732 err=0.081732
I 2015-05-26 09:56:05 theanets.trainer:168 RmsProp 1200 loss=0.078797 err=0.078797
I 2015-05-26 09:56:05 theanets.trainer:168 validation 120 loss=1577.686768 err=1577.686768
I 2015-05-26 09:56:12 theanets.trainer:168 RmsProp 1201 loss=0.079545 err=0.079545
I 2015-05-26 09:56:19 theanets.trainer:168 RmsProp 1202 loss=0.082053 err=0.082053
I 2015-05-26 09:56:26 theanets.trainer:168 RmsProp 1203 loss=0.086289 err=0.086289
I 2015-05-26 09:56:33 theanets.trainer:168 RmsProp 1204 loss=0.069601 err=0.069601
I 2015-05-26 09:56:40 theanets.trainer:168 RmsProp 1205 loss=0.090743 err=0.090743
I 2015-05-26 09:56:47 theanets.trainer:168 RmsProp 1206 loss=0.081599 err=0.081599
I 2015-05-26 09:56:54 theanets.trainer:168 RmsProp 1207 loss=0.073112 err=0.073112
I 2015-05-26 09:57:00 theanets.trainer:168 RmsProp 1208 loss=0.086486 err=0.086486
I 2015-05-26 09:57:06 theanets.trainer:168 RmsProp 1209 loss=0.078724 err=0.078724
I 2015-05-26 09:57:13 theanets.trainer:168 RmsProp 1210 loss=0.083150 err=0.083150
I 2015-05-26 09:57:13 theanets.trainer:168 validation 121 loss=1574.476929 err=1574.476929 *
I 2015-05-26 09:57:19 theanets.trainer:168 RmsProp 1211 loss=0.079123 err=0.079123
I 2015-05-26 09:57:26 theanets.trainer:168 RmsProp 1212 loss=0.076553 err=0.076553
I 2015-05-26 09:57:34 theanets.trainer:168 RmsProp 1213 loss=0.085256 err=0.085256
I 2015-05-26 09:57:41 theanets.trainer:168 RmsProp 1214 loss=0.074256 err=0.074256
I 2015-05-26 09:57:48 theanets.trainer:168 RmsProp 1215 loss=0.086795 err=0.086795
I 2015-05-26 09:57:54 theanets.trainer:168 RmsProp 1216 loss=0.078760 err=0.078760
I 2015-05-26 09:58:01 theanets.trainer:168 RmsProp 1217 loss=0.079701 err=0.079701
I 2015-05-26 09:58:08 theanets.trainer:168 RmsProp 1218 loss=0.071899 err=0.071899
I 2015-05-26 09:58:15 theanets.trainer:168 RmsProp 1219 loss=0.087206 err=0.087206
I 2015-05-26 09:58:22 theanets.trainer:168 RmsProp 1220 loss=0.079979 err=0.079979
I 2015-05-26 09:58:23 theanets.trainer:168 validation 122 loss=1574.352173 err=1574.352173 *
I 2015-05-26 09:58:29 theanets.trainer:168 RmsProp 1221 loss=0.069217 err=0.069217
I 2015-05-26 09:58:36 theanets.trainer:168 RmsProp 1222 loss=0.092038 err=0.092038
I 2015-05-26 09:58:43 theanets.trainer:168 RmsProp 1223 loss=0.079114 err=0.079114
I 2015-05-26 09:58:50 theanets.trainer:168 RmsProp 1224 loss=0.076764 err=0.076764
I 2015-05-26 09:58:57 theanets.trainer:168 RmsProp 1225 loss=0.083463 err=0.083463
I 2015-05-26 09:59:04 theanets.trainer:168 RmsProp 1226 loss=0.075142 err=0.075142
I 2015-05-26 09:59:12 theanets.trainer:168 RmsProp 1227 loss=0.081283 err=0.081283
I 2015-05-26 09:59:19 theanets.trainer:168 RmsProp 1228 loss=0.086110 err=0.086110
I 2015-05-26 09:59:26 theanets.trainer:168 RmsProp 1229 loss=0.075306 err=0.075306
I 2015-05-26 09:59:33 theanets.trainer:168 RmsProp 1230 loss=0.076671 err=0.076671
I 2015-05-26 09:59:33 theanets.trainer:168 validation 123 loss=1573.503540 err=1573.503540 *
I 2015-05-26 09:59:40 theanets.trainer:168 RmsProp 1231 loss=0.080496 err=0.080496
I 2015-05-26 09:59:47 theanets.trainer:168 RmsProp 1232 loss=0.076492 err=0.076492
I 2015-05-26 09:59:54 theanets.trainer:168 RmsProp 1233 loss=0.080054 err=0.080054
I 2015-05-26 10:00:02 theanets.trainer:168 RmsProp 1234 loss=0.071392 err=0.071392
I 2015-05-26 10:00:09 theanets.trainer:168 RmsProp 1235 loss=0.080950 err=0.080950
I 2015-05-26 10:00:16 theanets.trainer:168 RmsProp 1236 loss=0.071904 err=0.071904
I 2015-05-26 10:00:22 theanets.trainer:168 RmsProp 1237 loss=0.077499 err=0.077499
I 2015-05-26 10:00:29 theanets.trainer:168 RmsProp 1238 loss=0.082620 err=0.082620
I 2015-05-26 10:00:36 theanets.trainer:168 RmsProp 1239 loss=0.079747 err=0.079747
I 2015-05-26 10:00:43 theanets.trainer:168 RmsProp 1240 loss=0.074816 err=0.074816
I 2015-05-26 10:00:43 theanets.trainer:168 validation 124 loss=1572.217163 err=1572.217163 *
I 2015-05-26 10:00:50 theanets.trainer:168 RmsProp 1241 loss=0.085280 err=0.085280
I 2015-05-26 10:00:56 theanets.trainer:168 RmsProp 1242 loss=0.075927 err=0.075927
I 2015-05-26 10:01:03 theanets.trainer:168 RmsProp 1243 loss=0.073125 err=0.073125
I 2015-05-26 10:01:10 theanets.trainer:168 RmsProp 1244 loss=0.077767 err=0.077767
I 2015-05-26 10:01:16 theanets.trainer:168 RmsProp 1245 loss=0.074788 err=0.074788
I 2015-05-26 10:01:23 theanets.trainer:168 RmsProp 1246 loss=0.081053 err=0.081053
I 2015-05-26 10:01:31 theanets.trainer:168 RmsProp 1247 loss=0.067976 err=0.067976
I 2015-05-26 10:01:38 theanets.trainer:168 RmsProp 1248 loss=0.082003 err=0.082003
I 2015-05-26 10:01:45 theanets.trainer:168 RmsProp 1249 loss=0.075053 err=0.075053
I 2015-05-26 10:01:53 theanets.trainer:168 RmsProp 1250 loss=0.074279 err=0.074279
I 2015-05-26 10:01:53 theanets.trainer:168 validation 125 loss=1575.254517 err=1575.254517
I 2015-05-26 10:02:00 theanets.trainer:168 RmsProp 1251 loss=0.081801 err=0.081801
I 2015-05-26 10:02:07 theanets.trainer:168 RmsProp 1252 loss=0.073058 err=0.073058
I 2015-05-26 10:02:14 theanets.trainer:168 RmsProp 1253 loss=0.070837 err=0.070837
I 2015-05-26 10:02:21 theanets.trainer:168 RmsProp 1254 loss=0.087396 err=0.087396
I 2015-05-26 10:02:28 theanets.trainer:168 RmsProp 1255 loss=0.073290 err=0.073290
I 2015-05-26 10:02:36 theanets.trainer:168 RmsProp 1256 loss=0.078661 err=0.078661
I 2015-05-26 10:02:43 theanets.trainer:168 RmsProp 1257 loss=0.082593 err=0.082593
I 2015-05-26 10:02:49 theanets.trainer:168 RmsProp 1258 loss=0.074587 err=0.074587
I 2015-05-26 10:02:56 theanets.trainer:168 RmsProp 1259 loss=0.074773 err=0.074773
I 2015-05-26 10:03:03 theanets.trainer:168 RmsProp 1260 loss=0.080677 err=0.080677
I 2015-05-26 10:03:04 theanets.trainer:168 validation 126 loss=1574.994141 err=1574.994141
I 2015-05-26 10:03:11 theanets.trainer:168 RmsProp 1261 loss=0.081753 err=0.081753
I 2015-05-26 10:03:18 theanets.trainer:168 RmsProp 1262 loss=0.077061 err=0.077061
I 2015-05-26 10:03:25 theanets.trainer:168 RmsProp 1263 loss=0.074033 err=0.074033
I 2015-05-26 10:03:33 theanets.trainer:168 RmsProp 1264 loss=0.072660 err=0.072660
I 2015-05-26 10:03:40 theanets.trainer:168 RmsProp 1265 loss=0.080702 err=0.080702
I 2015-05-26 10:03:47 theanets.trainer:168 RmsProp 1266 loss=0.073982 err=0.073982
I 2015-05-26 10:03:54 theanets.trainer:168 RmsProp 1267 loss=0.073927 err=0.073927
I 2015-05-26 10:04:00 theanets.trainer:168 RmsProp 1268 loss=0.080129 err=0.080129
I 2015-05-26 10:04:07 theanets.trainer:168 RmsProp 1269 loss=0.073709 err=0.073709
I 2015-05-26 10:04:13 theanets.trainer:168 RmsProp 1270 loss=0.076366 err=0.076366
I 2015-05-26 10:04:13 theanets.trainer:168 validation 127 loss=1572.115234 err=1572.115234 *
I 2015-05-26 10:04:19 theanets.trainer:168 RmsProp 1271 loss=0.079872 err=0.079872
I 2015-05-26 10:04:25 theanets.trainer:168 RmsProp 1272 loss=0.079478 err=0.079478
I 2015-05-26 10:04:31 theanets.trainer:168 RmsProp 1273 loss=0.076120 err=0.076120
I 2015-05-26 10:04:37 theanets.trainer:168 RmsProp 1274 loss=0.074461 err=0.074461
I 2015-05-26 10:04:44 theanets.trainer:168 RmsProp 1275 loss=0.077538 err=0.077538
I 2015-05-26 10:04:49 theanets.trainer:168 RmsProp 1276 loss=0.073117 err=0.073117
I 2015-05-26 10:04:55 theanets.trainer:168 RmsProp 1277 loss=0.078488 err=0.078488
I 2015-05-26 10:05:02 theanets.trainer:168 RmsProp 1278 loss=0.078518 err=0.078518
I 2015-05-26 10:05:08 theanets.trainer:168 RmsProp 1279 loss=0.074350 err=0.074350
I 2015-05-26 10:05:14 theanets.trainer:168 RmsProp 1280 loss=0.073581 err=0.073581
I 2015-05-26 10:05:14 theanets.trainer:168 validation 128 loss=1570.090698 err=1570.090698 *
I 2015-05-26 10:05:20 theanets.trainer:168 RmsProp 1281 loss=0.078695 err=0.078695
I 2015-05-26 10:05:26 theanets.trainer:168 RmsProp 1282 loss=0.078318 err=0.078318
I 2015-05-26 10:05:32 theanets.trainer:168 RmsProp 1283 loss=0.076463 err=0.076463
I 2015-05-26 10:05:38 theanets.trainer:168 RmsProp 1284 loss=0.070774 err=0.070774
I 2015-05-26 10:05:45 theanets.trainer:168 RmsProp 1285 loss=0.079479 err=0.079479
I 2015-05-26 10:05:51 theanets.trainer:168 RmsProp 1286 loss=0.079942 err=0.079942
I 2015-05-26 10:05:57 theanets.trainer:168 RmsProp 1287 loss=0.073317 err=0.073317
I 2015-05-26 10:06:03 theanets.trainer:168 RmsProp 1288 loss=0.073669 err=0.073669
I 2015-05-26 10:06:09 theanets.trainer:168 RmsProp 1289 loss=0.079233 err=0.079233
I 2015-05-26 10:06:15 theanets.trainer:168 RmsProp 1290 loss=0.073341 err=0.073341
I 2015-05-26 10:06:15 theanets.trainer:168 validation 129 loss=1571.744751 err=1571.744751
I 2015-05-26 10:06:21 theanets.trainer:168 RmsProp 1291 loss=0.076210 err=0.076210
I 2015-05-26 10:06:27 theanets.trainer:168 RmsProp 1292 loss=0.065828 err=0.065828
I 2015-05-26 10:06:33 theanets.trainer:168 RmsProp 1293 loss=0.088699 err=0.088699
I 2015-05-26 10:06:38 theanets.trainer:168 RmsProp 1294 loss=0.081258 err=0.081258
I 2015-05-26 10:06:44 theanets.trainer:168 RmsProp 1295 loss=0.072491 err=0.072491
I 2015-05-26 10:06:51 theanets.trainer:168 RmsProp 1296 loss=0.078963 err=0.078963
I 2015-05-26 10:06:57 theanets.trainer:168 RmsProp 1297 loss=0.079924 err=0.079924
I 2015-05-26 10:07:03 theanets.trainer:168 RmsProp 1298 loss=0.073413 err=0.073413
I 2015-05-26 10:07:09 theanets.trainer:168 RmsProp 1299 loss=0.074344 err=0.074344
I 2015-05-26 10:07:15 theanets.trainer:168 RmsProp 1300 loss=0.071477 err=0.071477
I 2015-05-26 10:07:15 theanets.trainer:168 validation 130 loss=1571.052612 err=1571.052612
I 2015-05-26 10:07:21 theanets.trainer:168 RmsProp 1301 loss=0.075927 err=0.075927
I 2015-05-26 10:07:26 theanets.trainer:168 RmsProp 1302 loss=0.075704 err=0.075704
I 2015-05-26 10:07:32 theanets.trainer:168 RmsProp 1303 loss=0.071394 err=0.071394
I 2015-05-26 10:07:38 theanets.trainer:168 RmsProp 1304 loss=0.078532 err=0.078532
I 2015-05-26 10:07:44 theanets.trainer:168 RmsProp 1305 loss=0.069252 err=0.069252
I 2015-05-26 10:07:51 theanets.trainer:168 RmsProp 1306 loss=0.075667 err=0.075667
I 2015-05-26 10:07:56 theanets.trainer:168 RmsProp 1307 loss=0.072453 err=0.072453
I 2015-05-26 10:08:02 theanets.trainer:168 RmsProp 1308 loss=0.072261 err=0.072261
I 2015-05-26 10:08:09 theanets.trainer:168 RmsProp 1309 loss=0.077352 err=0.077352
I 2015-05-26 10:08:15 theanets.trainer:168 RmsProp 1310 loss=0.073044 err=0.073044
I 2015-05-26 10:08:15 theanets.trainer:168 validation 131 loss=1568.215576 err=1568.215576 *
I 2015-05-26 10:08:21 theanets.trainer:168 RmsProp 1311 loss=0.071618 err=0.071618
I 2015-05-26 10:08:27 theanets.trainer:168 RmsProp 1312 loss=0.075996 err=0.075996
I 2015-05-26 10:08:34 theanets.trainer:168 RmsProp 1313 loss=0.075231 err=0.075231
I 2015-05-26 10:08:39 theanets.trainer:168 RmsProp 1314 loss=0.073662 err=0.073662
I 2015-05-26 10:08:45 theanets.trainer:168 RmsProp 1315 loss=0.073775 err=0.073775
I 2015-05-26 10:08:52 theanets.trainer:168 RmsProp 1316 loss=0.079797 err=0.079797
I 2015-05-26 10:08:58 theanets.trainer:168 RmsProp 1317 loss=0.072254 err=0.072254
I 2015-05-26 10:09:03 theanets.trainer:168 RmsProp 1318 loss=0.069942 err=0.069942
I 2015-05-26 10:09:10 theanets.trainer:168 RmsProp 1319 loss=0.070454 err=0.070454
I 2015-05-26 10:09:16 theanets.trainer:168 RmsProp 1320 loss=0.076434 err=0.076434
I 2015-05-26 10:09:16 theanets.trainer:168 validation 132 loss=1565.397339 err=1565.397339 *
I 2015-05-26 10:09:22 theanets.trainer:168 RmsProp 1321 loss=0.072539 err=0.072539
I 2015-05-26 10:09:28 theanets.trainer:168 RmsProp 1322 loss=0.074170 err=0.074170
I 2015-05-26 10:09:34 theanets.trainer:168 RmsProp 1323 loss=0.070025 err=0.070025
I 2015-05-26 10:09:40 theanets.trainer:168 RmsProp 1324 loss=0.074683 err=0.074683
I 2015-05-26 10:09:47 theanets.trainer:168 RmsProp 1325 loss=0.074470 err=0.074470
I 2015-05-26 10:09:53 theanets.trainer:168 RmsProp 1326 loss=0.071004 err=0.071004
I 2015-05-26 10:09:59 theanets.trainer:168 RmsProp 1327 loss=0.078198 err=0.078198
I 2015-05-26 10:10:06 theanets.trainer:168 RmsProp 1328 loss=0.072354 err=0.072354
I 2015-05-26 10:10:11 theanets.trainer:168 RmsProp 1329 loss=0.073471 err=0.073471
I 2015-05-26 10:10:17 theanets.trainer:168 RmsProp 1330 loss=0.074661 err=0.074661
I 2015-05-26 10:10:18 theanets.trainer:168 validation 133 loss=1567.339722 err=1567.339722
I 2015-05-26 10:10:24 theanets.trainer:168 RmsProp 1331 loss=0.070518 err=0.070518
I 2015-05-26 10:10:30 theanets.trainer:168 RmsProp 1332 loss=0.075935 err=0.075935
I 2015-05-26 10:10:36 theanets.trainer:168 RmsProp 1333 loss=0.065736 err=0.065736
I 2015-05-26 10:10:42 theanets.trainer:168 RmsProp 1334 loss=0.078540 err=0.078540
I 2015-05-26 10:10:49 theanets.trainer:168 RmsProp 1335 loss=0.069566 err=0.069566
I 2015-05-26 10:10:55 theanets.trainer:168 RmsProp 1336 loss=0.072983 err=0.072983
I 2015-05-26 10:11:01 theanets.trainer:168 RmsProp 1337 loss=0.074737 err=0.074737
I 2015-05-26 10:11:06 theanets.trainer:168 RmsProp 1338 loss=0.074156 err=0.074156
I 2015-05-26 10:11:11 theanets.trainer:168 RmsProp 1339 loss=0.069345 err=0.069345
I 2015-05-26 10:11:17 theanets.trainer:168 RmsProp 1340 loss=0.075615 err=0.075615
I 2015-05-26 10:11:17 theanets.trainer:168 validation 134 loss=1564.936768 err=1564.936768 *
I 2015-05-26 10:11:23 theanets.trainer:168 RmsProp 1341 loss=0.072989 err=0.072989
I 2015-05-26 10:11:28 theanets.trainer:168 RmsProp 1342 loss=0.070282 err=0.070282
I 2015-05-26 10:11:33 theanets.trainer:168 RmsProp 1343 loss=0.072793 err=0.072793
I 2015-05-26 10:11:39 theanets.trainer:168 RmsProp 1344 loss=0.075301 err=0.075301
I 2015-05-26 10:11:44 theanets.trainer:168 RmsProp 1345 loss=0.072291 err=0.072291
I 2015-05-26 10:11:50 theanets.trainer:168 RmsProp 1346 loss=0.077130 err=0.077130
I 2015-05-26 10:11:55 theanets.trainer:168 RmsProp 1347 loss=0.071365 err=0.071365
I 2015-05-26 10:12:01 theanets.trainer:168 RmsProp 1348 loss=0.071111 err=0.071111
I 2015-05-26 10:12:07 theanets.trainer:168 RmsProp 1349 loss=0.071698 err=0.071698
I 2015-05-26 10:12:12 theanets.trainer:168 RmsProp 1350 loss=0.073276 err=0.073276
I 2015-05-26 10:12:13 theanets.trainer:168 validation 135 loss=1566.506226 err=1566.506226
I 2015-05-26 10:12:19 theanets.trainer:168 RmsProp 1351 loss=0.073861 err=0.073861
I 2015-05-26 10:12:25 theanets.trainer:168 RmsProp 1352 loss=0.070077 err=0.070077
I 2015-05-26 10:12:31 theanets.trainer:168 RmsProp 1353 loss=0.073355 err=0.073355
I 2015-05-26 10:12:37 theanets.trainer:168 RmsProp 1354 loss=0.072607 err=0.072607
I 2015-05-26 10:12:44 theanets.trainer:168 RmsProp 1355 loss=0.071461 err=0.071461
I 2015-05-26 10:12:50 theanets.trainer:168 RmsProp 1356 loss=0.074333 err=0.074333
I 2015-05-26 10:12:56 theanets.trainer:168 RmsProp 1357 loss=0.069827 err=0.069827
I 2015-05-26 10:13:02 theanets.trainer:168 RmsProp 1358 loss=0.077446 err=0.077446
I 2015-05-26 10:13:09 theanets.trainer:168 RmsProp 1359 loss=0.071904 err=0.071904
I 2015-05-26 10:13:15 theanets.trainer:168 RmsProp 1360 loss=0.074042 err=0.074042
I 2015-05-26 10:13:15 theanets.trainer:168 validation 136 loss=1560.640259 err=1560.640259 *
I 2015-05-26 10:13:21 theanets.trainer:168 RmsProp 1361 loss=0.079041 err=0.079041
I 2015-05-26 10:13:27 theanets.trainer:168 RmsProp 1362 loss=0.067385 err=0.067385
I 2015-05-26 10:13:33 theanets.trainer:168 RmsProp 1363 loss=0.073649 err=0.073649
I 2015-05-26 10:13:40 theanets.trainer:168 RmsProp 1364 loss=0.070141 err=0.070141
I 2015-05-26 10:13:46 theanets.trainer:168 RmsProp 1365 loss=0.072794 err=0.072794
I 2015-05-26 10:13:52 theanets.trainer:168 RmsProp 1366 loss=0.071864 err=0.071864
I 2015-05-26 10:13:58 theanets.trainer:168 RmsProp 1367 loss=0.071012 err=0.071012
I 2015-05-26 10:14:04 theanets.trainer:168 RmsProp 1368 loss=0.069738 err=0.069738
I 2015-05-26 10:14:11 theanets.trainer:168 RmsProp 1369 loss=0.071872 err=0.071872
I 2015-05-26 10:14:17 theanets.trainer:168 RmsProp 1370 loss=0.069100 err=0.069100
I 2015-05-26 10:14:17 theanets.trainer:168 validation 137 loss=1562.722412 err=1562.722412
I 2015-05-26 10:14:23 theanets.trainer:168 RmsProp 1371 loss=0.070642 err=0.070642
I 2015-05-26 10:14:29 theanets.trainer:168 RmsProp 1372 loss=0.071565 err=0.071565
I 2015-05-26 10:14:36 theanets.trainer:168 RmsProp 1373 loss=0.068573 err=0.068573
I 2015-05-26 10:14:42 theanets.trainer:168 RmsProp 1374 loss=0.074589 err=0.074589
I 2015-05-26 10:14:48 theanets.trainer:168 RmsProp 1375 loss=0.067015 err=0.067015
I 2015-05-26 10:14:54 theanets.trainer:168 RmsProp 1376 loss=0.070516 err=0.070516
I 2015-05-26 10:15:01 theanets.trainer:168 RmsProp 1377 loss=0.078651 err=0.078651
I 2015-05-26 10:15:07 theanets.trainer:168 RmsProp 1378 loss=0.069014 err=0.069014
I 2015-05-26 10:15:13 theanets.trainer:168 RmsProp 1379 loss=0.074553 err=0.074553
I 2015-05-26 10:15:18 theanets.trainer:168 RmsProp 1380 loss=0.078769 err=0.078769
I 2015-05-26 10:15:19 theanets.trainer:168 validation 138 loss=1563.862915 err=1563.862915
I 2015-05-26 10:15:24 theanets.trainer:168 RmsProp 1381 loss=0.065931 err=0.065931
I 2015-05-26 10:15:29 theanets.trainer:168 RmsProp 1382 loss=0.067949 err=0.067949
I 2015-05-26 10:15:35 theanets.trainer:168 RmsProp 1383 loss=0.072523 err=0.072523
I 2015-05-26 10:15:41 theanets.trainer:168 RmsProp 1384 loss=0.068695 err=0.068695
I 2015-05-26 10:15:47 theanets.trainer:168 RmsProp 1385 loss=0.068741 err=0.068741
I 2015-05-26 10:15:53 theanets.trainer:168 RmsProp 1386 loss=0.070753 err=0.070753
I 2015-05-26 10:16:00 theanets.trainer:168 RmsProp 1387 loss=0.073195 err=0.073195
I 2015-05-26 10:16:06 theanets.trainer:168 RmsProp 1388 loss=0.068657 err=0.068657
I 2015-05-26 10:16:12 theanets.trainer:168 RmsProp 1389 loss=0.064400 err=0.064400
I 2015-05-26 10:16:18 theanets.trainer:168 RmsProp 1390 loss=0.075073 err=0.075073
I 2015-05-26 10:16:18 theanets.trainer:168 validation 139 loss=1562.564331 err=1562.564331
I 2015-05-26 10:16:24 theanets.trainer:168 RmsProp 1391 loss=0.071591 err=0.071591
I 2015-05-26 10:16:30 theanets.trainer:168 RmsProp 1392 loss=0.071134 err=0.071134
I 2015-05-26 10:16:36 theanets.trainer:168 RmsProp 1393 loss=0.071388 err=0.071388
I 2015-05-26 10:16:43 theanets.trainer:168 RmsProp 1394 loss=0.077357 err=0.077357
I 2015-05-26 10:16:49 theanets.trainer:168 RmsProp 1395 loss=0.068100 err=0.068100
I 2015-05-26 10:16:55 theanets.trainer:168 RmsProp 1396 loss=0.071520 err=0.071520
I 2015-05-26 10:17:01 theanets.trainer:168 RmsProp 1397 loss=0.069773 err=0.069773
I 2015-05-26 10:17:08 theanets.trainer:168 RmsProp 1398 loss=0.070271 err=0.070271
I 2015-05-26 10:17:13 theanets.trainer:168 RmsProp 1399 loss=0.067070 err=0.067070
I 2015-05-26 10:17:19 theanets.trainer:168 RmsProp 1400 loss=0.073911 err=0.073911
I 2015-05-26 10:17:20 theanets.trainer:168 validation 140 loss=1560.323486 err=1560.323486 *
I 2015-05-26 10:17:25 theanets.trainer:168 RmsProp 1401 loss=0.069494 err=0.069494
I 2015-05-26 10:17:31 theanets.trainer:168 RmsProp 1402 loss=0.064565 err=0.064565
I 2015-05-26 10:17:37 theanets.trainer:168 RmsProp 1403 loss=0.074136 err=0.074136
I 2015-05-26 10:17:43 theanets.trainer:168 RmsProp 1404 loss=0.066535 err=0.066535
I 2015-05-26 10:17:49 theanets.trainer:168 RmsProp 1405 loss=0.078406 err=0.078406
I 2015-05-26 10:17:55 theanets.trainer:168 RmsProp 1406 loss=0.071792 err=0.071792
I 2015-05-26 10:18:01 theanets.trainer:168 RmsProp 1407 loss=0.064050 err=0.064050
I 2015-05-26 10:18:07 theanets.trainer:168 RmsProp 1408 loss=0.073851 err=0.073851
I 2015-05-26 10:18:12 theanets.trainer:168 RmsProp 1409 loss=0.069822 err=0.069822
I 2015-05-26 10:18:18 theanets.trainer:168 RmsProp 1410 loss=0.068075 err=0.068075
I 2015-05-26 10:18:19 theanets.trainer:168 validation 141 loss=1558.387451 err=1558.387451 *
I 2015-05-26 10:18:24 theanets.trainer:168 RmsProp 1411 loss=0.070111 err=0.070111
I 2015-05-26 10:18:31 theanets.trainer:168 RmsProp 1412 loss=0.070195 err=0.070195
I 2015-05-26 10:18:37 theanets.trainer:168 RmsProp 1413 loss=0.073132 err=0.073132
I 2015-05-26 10:18:42 theanets.trainer:168 RmsProp 1414 loss=0.067542 err=0.067542
I 2015-05-26 10:18:49 theanets.trainer:168 RmsProp 1415 loss=0.071370 err=0.071370
I 2015-05-26 10:18:55 theanets.trainer:168 RmsProp 1416 loss=0.070596 err=0.070596
I 2015-05-26 10:19:01 theanets.trainer:168 RmsProp 1417 loss=0.069858 err=0.069858
I 2015-05-26 10:19:08 theanets.trainer:168 RmsProp 1418 loss=0.060703 err=0.060703
I 2015-05-26 10:19:13 theanets.trainer:168 RmsProp 1419 loss=0.077767 err=0.077767
I 2015-05-26 10:19:19 theanets.trainer:168 RmsProp 1420 loss=0.068745 err=0.068745
I 2015-05-26 10:19:20 theanets.trainer:168 validation 142 loss=1560.390259 err=1560.390259
I 2015-05-26 10:19:25 theanets.trainer:168 RmsProp 1421 loss=0.074414 err=0.074414
I 2015-05-26 10:19:32 theanets.trainer:168 RmsProp 1422 loss=0.081091 err=0.081091
I 2015-05-26 10:19:37 theanets.trainer:168 RmsProp 1423 loss=0.066849 err=0.066849
I 2015-05-26 10:19:43 theanets.trainer:168 RmsProp 1424 loss=0.067605 err=0.067605
I 2015-05-26 10:19:50 theanets.trainer:168 RmsProp 1425 loss=0.069268 err=0.069268
I 2015-05-26 10:19:56 theanets.trainer:168 RmsProp 1426 loss=0.071036 err=0.071036
I 2015-05-26 10:20:02 theanets.trainer:168 RmsProp 1427 loss=0.060879 err=0.060879
I 2015-05-26 10:20:08 theanets.trainer:168 RmsProp 1428 loss=0.088607 err=0.088607
I 2015-05-26 10:20:14 theanets.trainer:168 RmsProp 1429 loss=0.091329 err=0.091329
I 2015-05-26 10:20:20 theanets.trainer:168 RmsProp 1430 loss=0.064283 err=0.064283
I 2015-05-26 10:20:20 theanets.trainer:168 validation 143 loss=1558.503540 err=1558.503540
I 2015-05-26 10:20:26 theanets.trainer:168 RmsProp 1431 loss=0.053596 err=0.053596
I 2015-05-26 10:20:32 theanets.trainer:168 RmsProp 1432 loss=0.098546 err=0.098546
I 2015-05-26 10:20:37 theanets.trainer:168 RmsProp 1433 loss=0.072438 err=0.072438
I 2015-05-26 10:20:43 theanets.trainer:168 RmsProp 1434 loss=0.065299 err=0.065299
I 2015-05-26 10:20:48 theanets.trainer:168 RmsProp 1435 loss=0.064977 err=0.064977
I 2015-05-26 10:20:54 theanets.trainer:168 RmsProp 1436 loss=0.075208 err=0.075208
I 2015-05-26 10:20:59 theanets.trainer:168 RmsProp 1437 loss=0.067620 err=0.067620
I 2015-05-26 10:21:05 theanets.trainer:168 RmsProp 1438 loss=0.062659 err=0.062659
I 2015-05-26 10:21:10 theanets.trainer:168 RmsProp 1439 loss=0.070894 err=0.070894
I 2015-05-26 10:21:16 theanets.trainer:168 RmsProp 1440 loss=0.068268 err=0.068268
I 2015-05-26 10:21:17 theanets.trainer:168 validation 144 loss=1558.662109 err=1558.662109
I 2015-05-26 10:21:22 theanets.trainer:168 RmsProp 1441 loss=0.070522 err=0.070522
I 2015-05-26 10:21:29 theanets.trainer:168 RmsProp 1442 loss=0.068051 err=0.068051
I 2015-05-26 10:21:35 theanets.trainer:168 RmsProp 1443 loss=0.062911 err=0.062911
I 2015-05-26 10:21:41 theanets.trainer:168 RmsProp 1444 loss=0.081824 err=0.081824
I 2015-05-26 10:21:46 theanets.trainer:168 RmsProp 1445 loss=0.063821 err=0.063821
I 2015-05-26 10:21:52 theanets.trainer:168 RmsProp 1446 loss=0.066688 err=0.066688
I 2015-05-26 10:21:58 theanets.trainer:168 RmsProp 1447 loss=0.070556 err=0.070556
I 2015-05-26 10:22:05 theanets.trainer:168 RmsProp 1448 loss=0.074994 err=0.074994
I 2015-05-26 10:22:11 theanets.trainer:168 RmsProp 1449 loss=0.064752 err=0.064752
I 2015-05-26 10:22:17 theanets.trainer:168 RmsProp 1450 loss=0.069822 err=0.069822
I 2015-05-26 10:22:18 theanets.trainer:168 validation 145 loss=1554.320190 err=1554.320190 *
I 2015-05-26 10:22:23 theanets.trainer:168 RmsProp 1451 loss=0.067914 err=0.067914
I 2015-05-26 10:22:29 theanets.trainer:168 RmsProp 1452 loss=0.063646 err=0.063646
I 2015-05-26 10:22:36 theanets.trainer:168 RmsProp 1453 loss=0.068138 err=0.068138
I 2015-05-26 10:22:42 theanets.trainer:168 RmsProp 1454 loss=0.070165 err=0.070165
I 2015-05-26 10:22:48 theanets.trainer:168 RmsProp 1455 loss=0.065468 err=0.065468
I 2015-05-26 10:22:55 theanets.trainer:168 RmsProp 1456 loss=0.064375 err=0.064375
I 2015-05-26 10:23:01 theanets.trainer:168 RmsProp 1457 loss=0.071721 err=0.071721
I 2015-05-26 10:23:07 theanets.trainer:168 RmsProp 1458 loss=0.062162 err=0.062162
I 2015-05-26 10:23:13 theanets.trainer:168 RmsProp 1459 loss=0.067762 err=0.067762
I 2015-05-26 10:23:19 theanets.trainer:168 RmsProp 1460 loss=0.066223 err=0.066223
I 2015-05-26 10:23:20 theanets.trainer:168 validation 146 loss=1557.346680 err=1557.346680
I 2015-05-26 10:23:25 theanets.trainer:168 RmsProp 1461 loss=0.075693 err=0.075693
I 2015-05-26 10:23:31 theanets.trainer:168 RmsProp 1462 loss=0.086723 err=0.086723
I 2015-05-26 10:23:37 theanets.trainer:168 RmsProp 1463 loss=0.064984 err=0.064984
I 2015-05-26 10:23:43 theanets.trainer:168 RmsProp 1464 loss=0.061186 err=0.061186
I 2015-05-26 10:23:49 theanets.trainer:168 RmsProp 1465 loss=0.068224 err=0.068224
I 2015-05-26 10:23:55 theanets.trainer:168 RmsProp 1466 loss=0.058843 err=0.058843
I 2015-05-26 10:24:02 theanets.trainer:168 RmsProp 1467 loss=0.081567 err=0.081567
I 2015-05-26 10:24:08 theanets.trainer:168 RmsProp 1468 loss=0.063829 err=0.063829
I 2015-05-26 10:24:14 theanets.trainer:168 RmsProp 1469 loss=0.065410 err=0.065410
I 2015-05-26 10:24:20 theanets.trainer:168 RmsProp 1470 loss=0.068676 err=0.068676
I 2015-05-26 10:24:21 theanets.trainer:168 validation 147 loss=1554.621826 err=1554.621826
I 2015-05-26 10:24:26 theanets.trainer:168 RmsProp 1471 loss=0.068131 err=0.068131
I 2015-05-26 10:24:32 theanets.trainer:168 RmsProp 1472 loss=0.061463 err=0.061463
I 2015-05-26 10:24:38 theanets.trainer:168 RmsProp 1473 loss=0.076023 err=0.076023
I 2015-05-26 10:24:45 theanets.trainer:168 RmsProp 1474 loss=0.067417 err=0.067417
I 2015-05-26 10:24:51 theanets.trainer:168 RmsProp 1475 loss=0.067337 err=0.067337
I 2015-05-26 10:24:57 theanets.trainer:168 RmsProp 1476 loss=0.062551 err=0.062551
I 2015-05-26 10:25:03 theanets.trainer:168 RmsProp 1477 loss=0.073381 err=0.073381
I 2015-05-26 10:25:10 theanets.trainer:168 RmsProp 1478 loss=0.067905 err=0.067905
I 2015-05-26 10:25:16 theanets.trainer:168 RmsProp 1479 loss=0.071370 err=0.071370
I 2015-05-26 10:25:22 theanets.trainer:168 RmsProp 1480 loss=0.065642 err=0.065642
I 2015-05-26 10:25:22 theanets.trainer:168 validation 148 loss=1553.784790 err=1553.784790 *
I 2015-05-26 10:25:28 theanets.trainer:168 RmsProp 1481 loss=0.058505 err=0.058505
I 2015-05-26 10:25:34 theanets.trainer:168 RmsProp 1482 loss=0.080913 err=0.080913
I 2015-05-26 10:25:41 theanets.trainer:168 RmsProp 1483 loss=0.067285 err=0.067285
I 2015-05-26 10:25:47 theanets.trainer:168 RmsProp 1484 loss=0.059548 err=0.059548
I 2015-05-26 10:25:53 theanets.trainer:168 RmsProp 1485 loss=0.070594 err=0.070594
I 2015-05-26 10:25:59 theanets.trainer:168 RmsProp 1486 loss=0.067677 err=0.067677
I 2015-05-26 10:26:06 theanets.trainer:168 RmsProp 1487 loss=0.064671 err=0.064671
I 2015-05-26 10:26:12 theanets.trainer:168 RmsProp 1488 loss=0.057718 err=0.057718
I 2015-05-26 10:26:18 theanets.trainer:168 RmsProp 1489 loss=0.094023 err=0.094023
I 2015-05-26 10:26:24 theanets.trainer:168 RmsProp 1490 loss=0.059682 err=0.059682
I 2015-05-26 10:26:25 theanets.trainer:168 validation 149 loss=1553.005005 err=1553.005005 *
I 2015-05-26 10:26:30 theanets.trainer:168 RmsProp 1491 loss=0.062890 err=0.062890
I 2015-05-26 10:26:37 theanets.trainer:168 RmsProp 1492 loss=0.065681 err=0.065681
I 2015-05-26 10:26:42 theanets.trainer:168 RmsProp 1493 loss=0.065693 err=0.065693
I 2015-05-26 10:26:49 theanets.trainer:168 RmsProp 1494 loss=0.072793 err=0.072793
I 2015-05-26 10:26:55 theanets.trainer:168 RmsProp 1495 loss=0.076957 err=0.076957
I 2015-05-26 10:27:01 theanets.trainer:168 RmsProp 1496 loss=0.062370 err=0.062370
I 2015-05-26 10:27:07 theanets.trainer:168 RmsProp 1497 loss=0.063084 err=0.063084
I 2015-05-26 10:27:13 theanets.trainer:168 RmsProp 1498 loss=0.067679 err=0.067679
I 2015-05-26 10:27:20 theanets.trainer:168 RmsProp 1499 loss=0.066668 err=0.066668
I 2015-05-26 10:27:26 theanets.trainer:168 RmsProp 1500 loss=0.063029 err=0.063029
I 2015-05-26 10:27:26 theanets.trainer:168 validation 150 loss=1552.598267 err=1552.598267 *
I 2015-05-26 10:27:32 theanets.trainer:168 RmsProp 1501 loss=0.062905 err=0.062905
I 2015-05-26 10:27:38 theanets.trainer:168 RmsProp 1502 loss=0.071173 err=0.071173
I 2015-05-26 10:27:44 theanets.trainer:168 RmsProp 1503 loss=0.068084 err=0.068084
I 2015-05-26 10:27:51 theanets.trainer:168 RmsProp 1504 loss=0.063654 err=0.063654
I 2015-05-26 10:27:57 theanets.trainer:168 RmsProp 1505 loss=0.065245 err=0.065245
I 2015-05-26 10:28:03 theanets.trainer:168 RmsProp 1506 loss=0.059843 err=0.059843
I 2015-05-26 10:28:09 theanets.trainer:168 RmsProp 1507 loss=0.071128 err=0.071128
I 2015-05-26 10:28:15 theanets.trainer:168 RmsProp 1508 loss=0.063429 err=0.063429
I 2015-05-26 10:28:21 theanets.trainer:168 RmsProp 1509 loss=0.065352 err=0.065352
I 2015-05-26 10:28:28 theanets.trainer:168 RmsProp 1510 loss=0.061763 err=0.061763
I 2015-05-26 10:28:28 theanets.trainer:168 validation 151 loss=1550.535522 err=1550.535522 *
I 2015-05-26 10:28:34 theanets.trainer:168 RmsProp 1511 loss=0.067066 err=0.067066
I 2015-05-26 10:28:40 theanets.trainer:168 RmsProp 1512 loss=0.065478 err=0.065478
I 2015-05-26 10:28:47 theanets.trainer:168 RmsProp 1513 loss=0.061850 err=0.061850
I 2015-05-26 10:28:53 theanets.trainer:168 RmsProp 1514 loss=0.069414 err=0.069414
I 2015-05-26 10:28:59 theanets.trainer:168 RmsProp 1515 loss=0.063750 err=0.063750
I 2015-05-26 10:29:05 theanets.trainer:168 RmsProp 1516 loss=0.071334 err=0.071334
I 2015-05-26 10:29:11 theanets.trainer:168 RmsProp 1517 loss=0.068049 err=0.068049
I 2015-05-26 10:29:17 theanets.trainer:168 RmsProp 1518 loss=0.061771 err=0.061771
I 2015-05-26 10:29:24 theanets.trainer:168 RmsProp 1519 loss=0.068620 err=0.068620
I 2015-05-26 10:29:30 theanets.trainer:168 RmsProp 1520 loss=0.061851 err=0.061851
I 2015-05-26 10:29:30 theanets.trainer:168 validation 152 loss=1548.732300 err=1548.732300 *
I 2015-05-26 10:29:36 theanets.trainer:168 RmsProp 1521 loss=0.069004 err=0.069004
I 2015-05-26 10:29:42 theanets.trainer:168 RmsProp 1522 loss=0.062651 err=0.062651
I 2015-05-26 10:29:49 theanets.trainer:168 RmsProp 1523 loss=0.071409 err=0.071409
I 2015-05-26 10:29:55 theanets.trainer:168 RmsProp 1524 loss=0.062285 err=0.062285
I 2015-05-26 10:30:01 theanets.trainer:168 RmsProp 1525 loss=0.072961 err=0.072961
I 2015-05-26 10:30:08 theanets.trainer:168 RmsProp 1526 loss=0.062973 err=0.062973
I 2015-05-26 10:30:14 theanets.trainer:168 RmsProp 1527 loss=0.064742 err=0.064742
I 2015-05-26 10:30:20 theanets.trainer:168 RmsProp 1528 loss=0.065232 err=0.065232
I 2015-05-26 10:30:26 theanets.trainer:168 RmsProp 1529 loss=0.061311 err=0.061311
I 2015-05-26 10:30:32 theanets.trainer:168 RmsProp 1530 loss=0.066514 err=0.066514
I 2015-05-26 10:30:33 theanets.trainer:168 validation 153 loss=1551.659058 err=1551.659058
I 2015-05-26 10:30:39 theanets.trainer:168 RmsProp 1531 loss=0.060129 err=0.060129
I 2015-05-26 10:30:45 theanets.trainer:168 RmsProp 1532 loss=0.068574 err=0.068574
I 2015-05-26 10:30:51 theanets.trainer:168 RmsProp 1533 loss=0.068769 err=0.068769
I 2015-05-26 10:30:57 theanets.trainer:168 RmsProp 1534 loss=0.061106 err=0.061106
I 2015-05-26 10:31:04 theanets.trainer:168 RmsProp 1535 loss=0.064742 err=0.064742
I 2015-05-26 10:31:10 theanets.trainer:168 RmsProp 1536 loss=0.065641 err=0.065641
I 2015-05-26 10:31:15 theanets.trainer:168 RmsProp 1537 loss=0.061685 err=0.061685
I 2015-05-26 10:31:21 theanets.trainer:168 RmsProp 1538 loss=0.065444 err=0.065444
I 2015-05-26 10:31:26 theanets.trainer:168 RmsProp 1539 loss=0.063669 err=0.063669
I 2015-05-26 10:31:31 theanets.trainer:168 RmsProp 1540 loss=0.063782 err=0.063782
I 2015-05-26 10:31:32 theanets.trainer:168 validation 154 loss=1549.555908 err=1549.555908
I 2015-05-26 10:31:37 theanets.trainer:168 RmsProp 1541 loss=0.066446 err=0.066446
I 2015-05-26 10:31:43 theanets.trainer:168 RmsProp 1542 loss=0.062236 err=0.062236
I 2015-05-26 10:31:48 theanets.trainer:168 RmsProp 1543 loss=0.061604 err=0.061604
I 2015-05-26 10:31:55 theanets.trainer:168 RmsProp 1544 loss=0.060644 err=0.060644
I 2015-05-26 10:32:01 theanets.trainer:168 RmsProp 1545 loss=0.069720 err=0.069720
I 2015-05-26 10:32:07 theanets.trainer:168 RmsProp 1546 loss=0.062479 err=0.062479
I 2015-05-26 10:32:12 theanets.trainer:168 RmsProp 1547 loss=0.062913 err=0.062913
I 2015-05-26 10:32:19 theanets.trainer:168 RmsProp 1548 loss=0.064276 err=0.064276
I 2015-05-26 10:32:25 theanets.trainer:168 RmsProp 1549 loss=0.064463 err=0.064463
I 2015-05-26 10:32:31 theanets.trainer:168 RmsProp 1550 loss=0.062691 err=0.062691
I 2015-05-26 10:32:32 theanets.trainer:168 validation 155 loss=1552.611206 err=1552.611206
I 2015-05-26 10:32:37 theanets.trainer:168 RmsProp 1551 loss=0.060311 err=0.060311
I 2015-05-26 10:32:44 theanets.trainer:168 RmsProp 1552 loss=0.066478 err=0.066478
I 2015-05-26 10:32:50 theanets.trainer:168 RmsProp 1553 loss=0.060748 err=0.060748
I 2015-05-26 10:32:56 theanets.trainer:168 RmsProp 1554 loss=0.069966 err=0.069966
I 2015-05-26 10:33:02 theanets.trainer:168 RmsProp 1555 loss=0.064558 err=0.064558
I 2015-05-26 10:33:08 theanets.trainer:168 RmsProp 1556 loss=0.059261 err=0.059261
I 2015-05-26 10:33:14 theanets.trainer:168 RmsProp 1557 loss=0.065330 err=0.065330
I 2015-05-26 10:33:20 theanets.trainer:168 RmsProp 1558 loss=0.064246 err=0.064246
I 2015-05-26 10:33:27 theanets.trainer:168 RmsProp 1559 loss=0.063810 err=0.063810
I 2015-05-26 10:33:33 theanets.trainer:168 RmsProp 1560 loss=0.058862 err=0.058862
I 2015-05-26 10:33:33 theanets.trainer:168 validation 156 loss=1547.109741 err=1547.109741 *
I 2015-05-26 10:33:39 theanets.trainer:168 RmsProp 1561 loss=0.065461 err=0.065461
I 2015-05-26 10:33:45 theanets.trainer:168 RmsProp 1562 loss=0.066925 err=0.066925
I 2015-05-26 10:33:52 theanets.trainer:168 RmsProp 1563 loss=0.063885 err=0.063885
I 2015-05-26 10:33:57 theanets.trainer:168 RmsProp 1564 loss=0.053735 err=0.053735
I 2015-05-26 10:34:03 theanets.trainer:168 RmsProp 1565 loss=0.083281 err=0.083281
I 2015-05-26 10:34:10 theanets.trainer:168 RmsProp 1566 loss=0.063585 err=0.063585
I 2015-05-26 10:34:16 theanets.trainer:168 RmsProp 1567 loss=0.053903 err=0.053903
I 2015-05-26 10:34:22 theanets.trainer:168 RmsProp 1568 loss=0.075314 err=0.075314
I 2015-05-26 10:34:28 theanets.trainer:168 RmsProp 1569 loss=0.061711 err=0.061711
I 2015-05-26 10:34:35 theanets.trainer:168 RmsProp 1570 loss=0.056340 err=0.056340
I 2015-05-26 10:34:35 theanets.trainer:168 validation 157 loss=1551.814331 err=1551.814331
I 2015-05-26 10:34:41 theanets.trainer:168 RmsProp 1571 loss=0.075037 err=0.075037
I 2015-05-26 10:34:47 theanets.trainer:168 RmsProp 1572 loss=0.064277 err=0.064277
I 2015-05-26 10:34:53 theanets.trainer:168 RmsProp 1573 loss=0.061263 err=0.061263
I 2015-05-26 10:34:59 theanets.trainer:168 RmsProp 1574 loss=0.056063 err=0.056063
I 2015-05-26 10:35:06 theanets.trainer:168 RmsProp 1575 loss=0.078143 err=0.078143
I 2015-05-26 10:35:12 theanets.trainer:168 RmsProp 1576 loss=0.058981 err=0.058981
I 2015-05-26 10:35:18 theanets.trainer:168 RmsProp 1577 loss=0.072111 err=0.072111
I 2015-05-26 10:35:24 theanets.trainer:168 RmsProp 1578 loss=0.064065 err=0.064065
I 2015-05-26 10:35:31 theanets.trainer:168 RmsProp 1579 loss=0.054723 err=0.054723
I 2015-05-26 10:35:37 theanets.trainer:168 RmsProp 1580 loss=0.074097 err=0.074097
I 2015-05-26 10:35:37 theanets.trainer:168 validation 158 loss=1551.665649 err=1551.665649
I 2015-05-26 10:35:43 theanets.trainer:168 RmsProp 1581 loss=0.064864 err=0.064864
I 2015-05-26 10:35:49 theanets.trainer:168 RmsProp 1582 loss=0.057646 err=0.057646
I 2015-05-26 10:35:56 theanets.trainer:168 RmsProp 1583 loss=0.072668 err=0.072668
I 2015-05-26 10:36:02 theanets.trainer:168 RmsProp 1584 loss=0.091765 err=0.091765
I 2015-05-26 10:36:08 theanets.trainer:168 RmsProp 1585 loss=0.063640 err=0.063640
I 2015-05-26 10:36:14 theanets.trainer:168 RmsProp 1586 loss=0.056683 err=0.056683
I 2015-05-26 10:36:21 theanets.trainer:168 RmsProp 1587 loss=0.067228 err=0.067228
I 2015-05-26 10:36:27 theanets.trainer:168 RmsProp 1588 loss=0.061598 err=0.061598
I 2015-05-26 10:36:33 theanets.trainer:168 RmsProp 1589 loss=0.063834 err=0.063834
I 2015-05-26 10:36:39 theanets.trainer:168 RmsProp 1590 loss=0.063168 err=0.063168
I 2015-05-26 10:36:40 theanets.trainer:168 validation 159 loss=1548.457886 err=1548.457886
I 2015-05-26 10:36:46 theanets.trainer:168 RmsProp 1591 loss=0.058579 err=0.058579
I 2015-05-26 10:36:52 theanets.trainer:168 RmsProp 1592 loss=0.063254 err=0.063254
I 2015-05-26 10:36:57 theanets.trainer:168 RmsProp 1593 loss=0.063702 err=0.063702
I 2015-05-26 10:37:03 theanets.trainer:168 RmsProp 1594 loss=0.062001 err=0.062001
I 2015-05-26 10:37:08 theanets.trainer:168 RmsProp 1595 loss=0.060598 err=0.060598
I 2015-05-26 10:37:14 theanets.trainer:168 RmsProp 1596 loss=0.060953 err=0.060953
I 2015-05-26 10:37:21 theanets.trainer:168 RmsProp 1597 loss=0.062209 err=0.062209
I 2015-05-26 10:37:27 theanets.trainer:168 RmsProp 1598 loss=0.063285 err=0.063285
I 2015-05-26 10:37:33 theanets.trainer:168 RmsProp 1599 loss=0.062880 err=0.062880
I 2015-05-26 10:37:39 theanets.trainer:168 RmsProp 1600 loss=0.062351 err=0.062351
I 2015-05-26 10:37:40 theanets.trainer:168 validation 160 loss=1549.612915 err=1549.612915
I 2015-05-26 10:37:46 theanets.trainer:168 RmsProp 1601 loss=0.062436 err=0.062436
I 2015-05-26 10:37:52 theanets.trainer:168 RmsProp 1602 loss=0.058989 err=0.058989
I 2015-05-26 10:37:58 theanets.trainer:168 RmsProp 1603 loss=0.066983 err=0.066983
I 2015-05-26 10:38:04 theanets.trainer:168 RmsProp 1604 loss=0.061312 err=0.061312
I 2015-05-26 10:38:10 theanets.trainer:168 RmsProp 1605 loss=0.064790 err=0.064790
I 2015-05-26 10:38:16 theanets.trainer:168 RmsProp 1606 loss=0.060072 err=0.060072
I 2015-05-26 10:38:22 theanets.trainer:168 RmsProp 1607 loss=0.064797 err=0.064797
I 2015-05-26 10:38:29 theanets.trainer:168 RmsProp 1608 loss=0.066952 err=0.066952
I 2015-05-26 10:38:35 theanets.trainer:168 RmsProp 1609 loss=0.058529 err=0.058529
I 2015-05-26 10:38:41 theanets.trainer:168 RmsProp 1610 loss=0.065546 err=0.065546
I 2015-05-26 10:38:41 theanets.trainer:168 validation 161 loss=1546.862061 err=1546.862061 *
I 2015-05-26 10:38:47 theanets.trainer:168 RmsProp 1611 loss=0.058286 err=0.058286
I 2015-05-26 10:38:53 theanets.trainer:168 RmsProp 1612 loss=0.064426 err=0.064426
I 2015-05-26 10:38:59 theanets.trainer:168 RmsProp 1613 loss=0.060037 err=0.060037
I 2015-05-26 10:39:04 theanets.trainer:168 RmsProp 1614 loss=0.063516 err=0.063516
I 2015-05-26 10:39:10 theanets.trainer:168 RmsProp 1615 loss=0.060859 err=0.060859
I 2015-05-26 10:39:16 theanets.trainer:168 RmsProp 1616 loss=0.065597 err=0.065597
I 2015-05-26 10:39:22 theanets.trainer:168 RmsProp 1617 loss=0.071332 err=0.071332
I 2015-05-26 10:39:28 theanets.trainer:168 RmsProp 1618 loss=0.055874 err=0.055874
I 2015-05-26 10:39:34 theanets.trainer:168 RmsProp 1619 loss=0.067339 err=0.067339
I 2015-05-26 10:39:40 theanets.trainer:168 RmsProp 1620 loss=0.057555 err=0.057555
I 2015-05-26 10:39:41 theanets.trainer:168 validation 162 loss=1547.573608 err=1547.573608
I 2015-05-26 10:39:47 theanets.trainer:168 RmsProp 1621 loss=0.061844 err=0.061844
I 2015-05-26 10:39:53 theanets.trainer:168 RmsProp 1622 loss=0.065479 err=0.065479
I 2015-05-26 10:39:59 theanets.trainer:168 RmsProp 1623 loss=0.061904 err=0.061904
I 2015-05-26 10:40:05 theanets.trainer:168 RmsProp 1624 loss=0.055222 err=0.055222
I 2015-05-26 10:40:11 theanets.trainer:168 RmsProp 1625 loss=0.063117 err=0.063117
I 2015-05-26 10:40:17 theanets.trainer:168 RmsProp 1626 loss=0.061239 err=0.061239
I 2015-05-26 10:40:23 theanets.trainer:168 RmsProp 1627 loss=0.059488 err=0.059488
I 2015-05-26 10:40:30 theanets.trainer:168 RmsProp 1628 loss=0.062217 err=0.062217
I 2015-05-26 10:40:36 theanets.trainer:168 RmsProp 1629 loss=0.068401 err=0.068401
I 2015-05-26 10:40:42 theanets.trainer:168 RmsProp 1630 loss=0.074482 err=0.074482
I 2015-05-26 10:40:43 theanets.trainer:168 validation 163 loss=1549.205322 err=1549.205322
I 2015-05-26 10:40:48 theanets.trainer:168 RmsProp 1631 loss=0.058064 err=0.058064
I 2015-05-26 10:40:54 theanets.trainer:168 RmsProp 1632 loss=0.068908 err=0.068908
I 2015-05-26 10:41:00 theanets.trainer:168 RmsProp 1633 loss=0.057802 err=0.057802
I 2015-05-26 10:41:06 theanets.trainer:168 RmsProp 1634 loss=0.063113 err=0.063113
I 2015-05-26 10:41:13 theanets.trainer:168 RmsProp 1635 loss=0.063994 err=0.063994
I 2015-05-26 10:41:19 theanets.trainer:168 RmsProp 1636 loss=0.061996 err=0.061996
I 2015-05-26 10:41:25 theanets.trainer:168 RmsProp 1637 loss=0.056083 err=0.056083
I 2015-05-26 10:41:31 theanets.trainer:168 RmsProp 1638 loss=0.068447 err=0.068447
I 2015-05-26 10:41:38 theanets.trainer:168 RmsProp 1639 loss=0.056493 err=0.056493
I 2015-05-26 10:41:43 theanets.trainer:168 RmsProp 1640 loss=0.071596 err=0.071596
I 2015-05-26 10:41:44 theanets.trainer:168 validation 164 loss=1544.411133 err=1544.411133 *
I 2015-05-26 10:41:50 theanets.trainer:168 RmsProp 1641 loss=0.075069 err=0.075069
I 2015-05-26 10:41:56 theanets.trainer:168 RmsProp 1642 loss=0.056470 err=0.056470
I 2015-05-26 10:42:03 theanets.trainer:168 RmsProp 1643 loss=0.057805 err=0.057805
I 2015-05-26 10:42:09 theanets.trainer:168 RmsProp 1644 loss=0.063785 err=0.063785
I 2015-05-26 10:42:15 theanets.trainer:168 RmsProp 1645 loss=0.057107 err=0.057107
I 2015-05-26 10:42:21 theanets.trainer:168 RmsProp 1646 loss=0.059512 err=0.059512
I 2015-05-26 10:42:27 theanets.trainer:168 RmsProp 1647 loss=0.064789 err=0.064789
I 2015-05-26 10:42:34 theanets.trainer:168 RmsProp 1648 loss=0.056142 err=0.056142
I 2015-05-26 10:42:40 theanets.trainer:168 RmsProp 1649 loss=0.060084 err=0.060084
I 2015-05-26 10:42:46 theanets.trainer:168 RmsProp 1650 loss=0.063977 err=0.063977
I 2015-05-26 10:42:46 theanets.trainer:168 validation 165 loss=1544.501221 err=1544.501221
I 2015-05-26 10:42:52 theanets.trainer:168 RmsProp 1651 loss=0.052202 err=0.052202
I 2015-05-26 10:42:59 theanets.trainer:168 RmsProp 1652 loss=0.082085 err=0.082085
I 2015-05-26 10:43:05 theanets.trainer:168 RmsProp 1653 loss=0.070409 err=0.070409
I 2015-05-26 10:43:11 theanets.trainer:168 RmsProp 1654 loss=0.058544 err=0.058544
I 2015-05-26 10:43:17 theanets.trainer:168 RmsProp 1655 loss=0.058306 err=0.058306
I 2015-05-26 10:43:24 theanets.trainer:168 RmsProp 1656 loss=0.059102 err=0.059102
I 2015-05-26 10:43:30 theanets.trainer:168 RmsProp 1657 loss=0.062927 err=0.062927
I 2015-05-26 10:43:36 theanets.trainer:168 RmsProp 1658 loss=0.063279 err=0.063279
I 2015-05-26 10:43:42 theanets.trainer:168 RmsProp 1659 loss=0.056119 err=0.056119
I 2015-05-26 10:43:48 theanets.trainer:168 RmsProp 1660 loss=0.063910 err=0.063910
I 2015-05-26 10:43:49 theanets.trainer:168 validation 166 loss=1544.412354 err=1544.412354
I 2015-05-26 10:43:54 theanets.trainer:168 RmsProp 1661 loss=0.059808 err=0.059808
I 2015-05-26 10:44:00 theanets.trainer:168 RmsProp 1662 loss=0.054154 err=0.054154
I 2015-05-26 10:44:05 theanets.trainer:168 RmsProp 1663 loss=0.066235 err=0.066235
I 2015-05-26 10:44:11 theanets.trainer:168 RmsProp 1664 loss=0.060585 err=0.060585
I 2015-05-26 10:44:17 theanets.trainer:168 RmsProp 1665 loss=0.050963 err=0.050963
I 2015-05-26 10:44:23 theanets.trainer:168 RmsProp 1666 loss=0.090424 err=0.090424
I 2015-05-26 10:44:30 theanets.trainer:168 RmsProp 1667 loss=0.082962 err=0.082962
I 2015-05-26 10:44:36 theanets.trainer:168 RmsProp 1668 loss=0.055951 err=0.055951
I 2015-05-26 10:44:42 theanets.trainer:168 RmsProp 1669 loss=0.052521 err=0.052521
I 2015-05-26 10:44:48 theanets.trainer:168 RmsProp 1670 loss=0.061862 err=0.061862
I 2015-05-26 10:44:49 theanets.trainer:168 validation 167 loss=1543.708740 err=1543.708740 *
I 2015-05-26 10:44:54 theanets.trainer:168 RmsProp 1671 loss=0.056821 err=0.056821
I 2015-05-26 10:45:00 theanets.trainer:168 RmsProp 1672 loss=0.061458 err=0.061458
I 2015-05-26 10:45:06 theanets.trainer:168 RmsProp 1673 loss=0.058229 err=0.058229
I 2015-05-26 10:45:11 theanets.trainer:168 RmsProp 1674 loss=0.057961 err=0.057961
I 2015-05-26 10:45:17 theanets.trainer:168 RmsProp 1675 loss=0.063822 err=0.063822
I 2015-05-26 10:45:24 theanets.trainer:168 RmsProp 1676 loss=0.062037 err=0.062037
I 2015-05-26 10:45:30 theanets.trainer:168 RmsProp 1677 loss=0.064395 err=0.064395
I 2015-05-26 10:45:36 theanets.trainer:168 RmsProp 1678 loss=0.057746 err=0.057746
I 2015-05-26 10:45:42 theanets.trainer:168 RmsProp 1679 loss=0.060329 err=0.060329
I 2015-05-26 10:45:48 theanets.trainer:168 RmsProp 1680 loss=0.058966 err=0.058966
I 2015-05-26 10:45:48 theanets.trainer:168 validation 168 loss=1546.188599 err=1546.188599
I 2015-05-26 10:45:54 theanets.trainer:168 RmsProp 1681 loss=0.061093 err=0.061093
I 2015-05-26 10:46:00 theanets.trainer:168 RmsProp 1682 loss=0.060445 err=0.060445
I 2015-05-26 10:46:06 theanets.trainer:168 RmsProp 1683 loss=0.059176 err=0.059176
I 2015-05-26 10:46:12 theanets.trainer:168 RmsProp 1684 loss=0.055616 err=0.055616
I 2015-05-26 10:46:18 theanets.trainer:168 RmsProp 1685 loss=0.063726 err=0.063726
I 2015-05-26 10:46:25 theanets.trainer:168 RmsProp 1686 loss=0.062931 err=0.062931
I 2015-05-26 10:46:31 theanets.trainer:168 RmsProp 1687 loss=0.054456 err=0.054456
I 2015-05-26 10:46:37 theanets.trainer:168 RmsProp 1688 loss=0.061417 err=0.061417
I 2015-05-26 10:46:43 theanets.trainer:168 RmsProp 1689 loss=0.058895 err=0.058895
I 2015-05-26 10:46:49 theanets.trainer:168 RmsProp 1690 loss=0.055856 err=0.055856
I 2015-05-26 10:46:49 theanets.trainer:168 validation 169 loss=1545.342773 err=1545.342773
I 2015-05-26 10:46:55 theanets.trainer:168 RmsProp 1691 loss=0.061859 err=0.061859
I 2015-05-26 10:47:01 theanets.trainer:168 RmsProp 1692 loss=0.060360 err=0.060360
I 2015-05-26 10:47:07 theanets.trainer:168 RmsProp 1693 loss=0.061837 err=0.061837
I 2015-05-26 10:47:14 theanets.trainer:168 RmsProp 1694 loss=0.062327 err=0.062327
I 2015-05-26 10:47:20 theanets.trainer:168 RmsProp 1695 loss=0.054520 err=0.054520
I 2015-05-26 10:47:26 theanets.trainer:168 RmsProp 1696 loss=0.058598 err=0.058598
I 2015-05-26 10:47:33 theanets.trainer:168 RmsProp 1697 loss=0.061335 err=0.061335
I 2015-05-26 10:47:39 theanets.trainer:168 RmsProp 1698 loss=0.056595 err=0.056595
I 2015-05-26 10:47:45 theanets.trainer:168 RmsProp 1699 loss=0.060347 err=0.060347
I 2015-05-26 10:47:51 theanets.trainer:168 RmsProp 1700 loss=0.059573 err=0.059573
I 2015-05-26 10:47:52 theanets.trainer:168 validation 170 loss=1544.252319 err=1544.252319
I 2015-05-26 10:47:57 theanets.trainer:168 RmsProp 1701 loss=0.062313 err=0.062313
I 2015-05-26 10:48:04 theanets.trainer:168 RmsProp 1702 loss=0.058836 err=0.058836
I 2015-05-26 10:48:10 theanets.trainer:168 RmsProp 1703 loss=0.061361 err=0.061361
I 2015-05-26 10:48:16 theanets.trainer:168 RmsProp 1704 loss=0.054391 err=0.054391
I 2015-05-26 10:48:22 theanets.trainer:168 RmsProp 1705 loss=0.065751 err=0.065751
I 2015-05-26 10:48:28 theanets.trainer:168 RmsProp 1706 loss=0.054235 err=0.054235
I 2015-05-26 10:48:34 theanets.trainer:168 RmsProp 1707 loss=0.061078 err=0.061078
I 2015-05-26 10:48:40 theanets.trainer:168 RmsProp 1708 loss=0.061783 err=0.061783
I 2015-05-26 10:48:47 theanets.trainer:168 RmsProp 1709 loss=0.058787 err=0.058787
I 2015-05-26 10:48:53 theanets.trainer:168 RmsProp 1710 loss=0.054025 err=0.054025
I 2015-05-26 10:48:53 theanets.trainer:168 validation 171 loss=1541.622925 err=1541.622925 *
I 2015-05-26 10:48:59 theanets.trainer:168 RmsProp 1711 loss=0.062727 err=0.062727
I 2015-05-26 10:49:05 theanets.trainer:168 RmsProp 1712 loss=0.059053 err=0.059053
I 2015-05-26 10:49:11 theanets.trainer:168 RmsProp 1713 loss=0.054928 err=0.054928
I 2015-05-26 10:49:17 theanets.trainer:168 RmsProp 1714 loss=0.060676 err=0.060676
I 2015-05-26 10:49:23 theanets.trainer:168 RmsProp 1715 loss=0.059435 err=0.059435
I 2015-05-26 10:49:29 theanets.trainer:168 RmsProp 1716 loss=0.060282 err=0.060282
I 2015-05-26 10:49:36 theanets.trainer:168 RmsProp 1717 loss=0.057940 err=0.057940
I 2015-05-26 10:49:42 theanets.trainer:168 RmsProp 1718 loss=0.058916 err=0.058916
I 2015-05-26 10:49:48 theanets.trainer:168 RmsProp 1719 loss=0.057975 err=0.057975
I 2015-05-26 10:49:54 theanets.trainer:168 RmsProp 1720 loss=0.054113 err=0.054113
I 2015-05-26 10:49:55 theanets.trainer:168 validation 172 loss=1542.408081 err=1542.408081
I 2015-05-26 10:50:01 theanets.trainer:168 RmsProp 1721 loss=0.067266 err=0.067266
I 2015-05-26 10:50:07 theanets.trainer:168 RmsProp 1722 loss=0.057922 err=0.057922
I 2015-05-26 10:50:13 theanets.trainer:168 RmsProp 1723 loss=0.057521 err=0.057521
I 2015-05-26 10:50:19 theanets.trainer:168 RmsProp 1724 loss=0.061072 err=0.061072
I 2015-05-26 10:50:25 theanets.trainer:168 RmsProp 1725 loss=0.057216 err=0.057216
I 2015-05-26 10:50:32 theanets.trainer:168 RmsProp 1726 loss=0.058090 err=0.058090
I 2015-05-26 10:50:38 theanets.trainer:168 RmsProp 1727 loss=0.054583 err=0.054583
I 2015-05-26 10:50:44 theanets.trainer:168 RmsProp 1728 loss=0.055486 err=0.055486
I 2015-05-26 10:50:50 theanets.trainer:168 RmsProp 1729 loss=0.072038 err=0.072038
I 2015-05-26 10:50:56 theanets.trainer:168 RmsProp 1730 loss=0.058289 err=0.058289
I 2015-05-26 10:50:57 theanets.trainer:168 validation 173 loss=1538.786987 err=1538.786987 *
I 2015-05-26 10:51:03 theanets.trainer:168 RmsProp 1731 loss=0.054930 err=0.054930
I 2015-05-26 10:51:09 theanets.trainer:168 RmsProp 1732 loss=0.064231 err=0.064231
I 2015-05-26 10:51:16 theanets.trainer:168 RmsProp 1733 loss=0.054948 err=0.054948
I 2015-05-26 10:51:22 theanets.trainer:168 RmsProp 1734 loss=0.065187 err=0.065187
I 2015-05-26 10:51:28 theanets.trainer:168 RmsProp 1735 loss=0.057615 err=0.057615
I 2015-05-26 10:51:34 theanets.trainer:168 RmsProp 1736 loss=0.057407 err=0.057407
I 2015-05-26 10:51:40 theanets.trainer:168 RmsProp 1737 loss=0.053218 err=0.053218
I 2015-05-26 10:51:46 theanets.trainer:168 RmsProp 1738 loss=0.061786 err=0.061786
I 2015-05-26 10:51:52 theanets.trainer:168 RmsProp 1739 loss=0.059265 err=0.059265
I 2015-05-26 10:51:57 theanets.trainer:168 RmsProp 1740 loss=0.058425 err=0.058425
I 2015-05-26 10:51:58 theanets.trainer:168 validation 174 loss=1537.558960 err=1537.558960 *
I 2015-05-26 10:52:03 theanets.trainer:168 RmsProp 1741 loss=0.057579 err=0.057579
I 2015-05-26 10:52:10 theanets.trainer:168 RmsProp 1742 loss=0.057121 err=0.057121
I 2015-05-26 10:52:16 theanets.trainer:168 RmsProp 1743 loss=0.059383 err=0.059383
I 2015-05-26 10:52:22 theanets.trainer:168 RmsProp 1744 loss=0.053535 err=0.053535
I 2015-05-26 10:52:28 theanets.trainer:168 RmsProp 1745 loss=0.061885 err=0.061885
I 2015-05-26 10:52:35 theanets.trainer:168 RmsProp 1746 loss=0.054140 err=0.054140
I 2015-05-26 10:52:41 theanets.trainer:168 RmsProp 1747 loss=0.060904 err=0.060904
I 2015-05-26 10:52:47 theanets.trainer:168 RmsProp 1748 loss=0.055559 err=0.055559
I 2015-05-26 10:52:53 theanets.trainer:168 RmsProp 1749 loss=0.060614 err=0.060614
I 2015-05-26 10:52:59 theanets.trainer:168 RmsProp 1750 loss=0.063809 err=0.063809
I 2015-05-26 10:52:59 theanets.trainer:168 validation 175 loss=1540.615234 err=1540.615234
I 2015-05-26 10:53:04 theanets.trainer:168 RmsProp 1751 loss=0.056425 err=0.056425
I 2015-05-26 10:53:11 theanets.trainer:168 RmsProp 1752 loss=0.058688 err=0.058688
I 2015-05-26 10:53:17 theanets.trainer:168 RmsProp 1753 loss=0.059257 err=0.059257
I 2015-05-26 10:53:23 theanets.trainer:168 RmsProp 1754 loss=0.054280 err=0.054280
I 2015-05-26 10:53:29 theanets.trainer:168 RmsProp 1755 loss=0.064531 err=0.064531
I 2015-05-26 10:53:35 theanets.trainer:168 RmsProp 1756 loss=0.056434 err=0.056434
I 2015-05-26 10:53:41 theanets.trainer:168 RmsProp 1757 loss=0.056280 err=0.056280
I 2015-05-26 10:53:47 theanets.trainer:168 RmsProp 1758 loss=0.056809 err=0.056809
I 2015-05-26 10:53:54 theanets.trainer:168 RmsProp 1759 loss=0.059122 err=0.059122
I 2015-05-26 10:54:00 theanets.trainer:168 RmsProp 1760 loss=0.055291 err=0.055291
I 2015-05-26 10:54:00 theanets.trainer:168 validation 176 loss=1541.676025 err=1541.676025
I 2015-05-26 10:54:06 theanets.trainer:168 RmsProp 1761 loss=0.060452 err=0.060452
I 2015-05-26 10:54:12 theanets.trainer:168 RmsProp 1762 loss=0.060308 err=0.060308
I 2015-05-26 10:54:18 theanets.trainer:168 RmsProp 1763 loss=0.054765 err=0.054765
I 2015-05-26 10:54:23 theanets.trainer:168 RmsProp 1764 loss=0.055810 err=0.055810
I 2015-05-26 10:54:29 theanets.trainer:168 RmsProp 1765 loss=0.056536 err=0.056536
I 2015-05-26 10:54:35 theanets.trainer:168 RmsProp 1766 loss=0.063195 err=0.063195
I 2015-05-26 10:54:41 theanets.trainer:168 RmsProp 1767 loss=0.057826 err=0.057826
I 2015-05-26 10:54:47 theanets.trainer:168 RmsProp 1768 loss=0.058820 err=0.058820
I 2015-05-26 10:54:53 theanets.trainer:168 RmsProp 1769 loss=0.050183 err=0.050183
I 2015-05-26 10:54:59 theanets.trainer:168 RmsProp 1770 loss=0.062310 err=0.062310
I 2015-05-26 10:55:00 theanets.trainer:168 validation 177 loss=1539.482666 err=1539.482666
I 2015-05-26 10:55:06 theanets.trainer:168 RmsProp 1771 loss=0.058636 err=0.058636
I 2015-05-26 10:55:12 theanets.trainer:168 RmsProp 1772 loss=0.057454 err=0.057454
I 2015-05-26 10:55:18 theanets.trainer:168 RmsProp 1773 loss=0.057784 err=0.057784
I 2015-05-26 10:55:24 theanets.trainer:168 RmsProp 1774 loss=0.058934 err=0.058934
I 2015-05-26 10:55:30 theanets.trainer:168 RmsProp 1775 loss=0.055369 err=0.055369
I 2015-05-26 10:55:36 theanets.trainer:168 RmsProp 1776 loss=0.056683 err=0.056683
I 2015-05-26 10:55:42 theanets.trainer:168 RmsProp 1777 loss=0.054194 err=0.054194
I 2015-05-26 10:55:47 theanets.trainer:168 RmsProp 1778 loss=0.057384 err=0.057384
I 2015-05-26 10:55:53 theanets.trainer:168 RmsProp 1779 loss=0.056461 err=0.056461
I 2015-05-26 10:55:58 theanets.trainer:168 RmsProp 1780 loss=0.061622 err=0.061622
I 2015-05-26 10:55:59 theanets.trainer:168 validation 178 loss=1536.219360 err=1536.219360 *
I 2015-05-26 10:56:05 theanets.trainer:168 RmsProp 1781 loss=0.053808 err=0.053808
I 2015-05-26 10:56:11 theanets.trainer:168 RmsProp 1782 loss=0.062827 err=0.062827
I 2015-05-26 10:56:17 theanets.trainer:168 RmsProp 1783 loss=0.062207 err=0.062207
I 2015-05-26 10:56:23 theanets.trainer:168 RmsProp 1784 loss=0.052117 err=0.052117
I 2015-05-26 10:56:29 theanets.trainer:168 RmsProp 1785 loss=0.062186 err=0.062186
I 2015-05-26 10:56:36 theanets.trainer:168 RmsProp 1786 loss=0.052316 err=0.052316
I 2015-05-26 10:56:42 theanets.trainer:168 RmsProp 1787 loss=0.058898 err=0.058898
I 2015-05-26 10:56:48 theanets.trainer:168 RmsProp 1788 loss=0.064298 err=0.064298
I 2015-05-26 10:56:54 theanets.trainer:168 RmsProp 1789 loss=0.055383 err=0.055383
I 2015-05-26 10:57:00 theanets.trainer:168 RmsProp 1790 loss=0.059647 err=0.059647
I 2015-05-26 10:57:00 theanets.trainer:168 validation 179 loss=1540.531372 err=1540.531372
I 2015-05-26 10:57:06 theanets.trainer:168 RmsProp 1791 loss=0.062219 err=0.062219
I 2015-05-26 10:57:12 theanets.trainer:168 RmsProp 1792 loss=0.047657 err=0.047657
I 2015-05-26 10:57:19 theanets.trainer:168 RmsProp 1793 loss=0.075673 err=0.075673
I 2015-05-26 10:57:25 theanets.trainer:168 RmsProp 1794 loss=0.084434 err=0.084434
I 2015-05-26 10:57:31 theanets.trainer:168 RmsProp 1795 loss=0.055836 err=0.055836
I 2015-05-26 10:57:37 theanets.trainer:168 RmsProp 1796 loss=0.049529 err=0.049529
I 2015-05-26 10:57:44 theanets.trainer:168 RmsProp 1797 loss=0.060959 err=0.060959
I 2015-05-26 10:57:50 theanets.trainer:168 RmsProp 1798 loss=0.056239 err=0.056239
I 2015-05-26 10:57:56 theanets.trainer:168 RmsProp 1799 loss=0.054637 err=0.054637
I 2015-05-26 10:58:02 theanets.trainer:168 RmsProp 1800 loss=0.061194 err=0.061194
I 2015-05-26 10:58:03 theanets.trainer:168 validation 180 loss=1537.912109 err=1537.912109
I 2015-05-26 10:58:09 theanets.trainer:168 RmsProp 1801 loss=0.052112 err=0.052112
I 2015-05-26 10:58:15 theanets.trainer:168 RmsProp 1802 loss=0.058231 err=0.058231
I 2015-05-26 10:58:20 theanets.trainer:168 RmsProp 1803 loss=0.056080 err=0.056080
I 2015-05-26 10:58:26 theanets.trainer:168 RmsProp 1804 loss=0.055197 err=0.055197
I 2015-05-26 10:58:32 theanets.trainer:168 RmsProp 1805 loss=0.054945 err=0.054945
I 2015-05-26 10:58:39 theanets.trainer:168 RmsProp 1806 loss=0.057378 err=0.057378
I 2015-05-26 10:58:45 theanets.trainer:168 RmsProp 1807 loss=0.056287 err=0.056287
I 2015-05-26 10:58:51 theanets.trainer:168 RmsProp 1808 loss=0.053027 err=0.053027
I 2015-05-26 10:58:57 theanets.trainer:168 RmsProp 1809 loss=0.058495 err=0.058495
I 2015-05-26 10:59:03 theanets.trainer:168 RmsProp 1810 loss=0.055293 err=0.055293
I 2015-05-26 10:59:03 theanets.trainer:168 validation 181 loss=1534.777710 err=1534.777710 *
I 2015-05-26 10:59:09 theanets.trainer:168 RmsProp 1811 loss=0.050568 err=0.050568
I 2015-05-26 10:59:15 theanets.trainer:168 RmsProp 1812 loss=0.064304 err=0.064304
I 2015-05-26 10:59:21 theanets.trainer:168 RmsProp 1813 loss=0.050576 err=0.050576
I 2015-05-26 10:59:28 theanets.trainer:168 RmsProp 1814 loss=0.060784 err=0.060784
I 2015-05-26 10:59:34 theanets.trainer:168 RmsProp 1815 loss=0.048766 err=0.048766
I 2015-05-26 10:59:40 theanets.trainer:168 RmsProp 1816 loss=0.069090 err=0.069090
I 2015-05-26 10:59:46 theanets.trainer:168 RmsProp 1817 loss=0.051421 err=0.051421
I 2015-05-26 10:59:53 theanets.trainer:168 RmsProp 1818 loss=0.058639 err=0.058639
I 2015-05-26 10:59:59 theanets.trainer:168 RmsProp 1819 loss=0.056625 err=0.056625
I 2015-05-26 11:00:05 theanets.trainer:168 RmsProp 1820 loss=0.053781 err=0.053781
I 2015-05-26 11:00:05 theanets.trainer:168 validation 182 loss=1532.947876 err=1532.947876 *
I 2015-05-26 11:00:11 theanets.trainer:168 RmsProp 1821 loss=0.059855 err=0.059855
I 2015-05-26 11:00:17 theanets.trainer:168 RmsProp 1822 loss=0.051066 err=0.051066
I 2015-05-26 11:00:24 theanets.trainer:168 RmsProp 1823 loss=0.055174 err=0.055174
I 2015-05-26 11:00:30 theanets.trainer:168 RmsProp 1824 loss=0.057255 err=0.057255
I 2015-05-26 11:00:36 theanets.trainer:168 RmsProp 1825 loss=0.058317 err=0.058317
I 2015-05-26 11:00:42 theanets.trainer:168 RmsProp 1826 loss=0.053822 err=0.053822
I 2015-05-26 11:00:49 theanets.trainer:168 RmsProp 1827 loss=0.056588 err=0.056588
I 2015-05-26 11:00:55 theanets.trainer:168 RmsProp 1828 loss=0.049208 err=0.049208
I 2015-05-26 11:01:01 theanets.trainer:168 RmsProp 1829 loss=0.061947 err=0.061947
I 2015-05-26 11:01:07 theanets.trainer:168 RmsProp 1830 loss=0.053133 err=0.053133
I 2015-05-26 11:01:07 theanets.trainer:168 validation 183 loss=1535.317993 err=1535.317993
I 2015-05-26 11:01:13 theanets.trainer:168 RmsProp 1831 loss=0.063764 err=0.063764
I 2015-05-26 11:01:19 theanets.trainer:168 RmsProp 1832 loss=0.053328 err=0.053328
I 2015-05-26 11:01:26 theanets.trainer:168 RmsProp 1833 loss=0.059731 err=0.059731
I 2015-05-26 11:01:32 theanets.trainer:168 RmsProp 1834 loss=0.053707 err=0.053707
I 2015-05-26 11:01:38 theanets.trainer:168 RmsProp 1835 loss=0.055011 err=0.055011
I 2015-05-26 11:01:45 theanets.trainer:168 RmsProp 1836 loss=0.055720 err=0.055720
I 2015-05-26 11:01:51 theanets.trainer:168 RmsProp 1837 loss=0.054789 err=0.054789
I 2015-05-26 11:01:57 theanets.trainer:168 RmsProp 1838 loss=0.051779 err=0.051779
I 2015-05-26 11:02:03 theanets.trainer:168 RmsProp 1839 loss=0.054551 err=0.054551
I 2015-05-26 11:02:09 theanets.trainer:168 RmsProp 1840 loss=0.055863 err=0.055863
I 2015-05-26 11:02:10 theanets.trainer:168 validation 184 loss=1537.356079 err=1537.356079
I 2015-05-26 11:02:15 theanets.trainer:168 RmsProp 1841 loss=0.057045 err=0.057045
I 2015-05-26 11:02:22 theanets.trainer:168 RmsProp 1842 loss=0.050789 err=0.050789
I 2015-05-26 11:02:28 theanets.trainer:168 RmsProp 1843 loss=0.061627 err=0.061627
I 2015-05-26 11:02:33 theanets.trainer:168 RmsProp 1844 loss=0.051846 err=0.051846
I 2015-05-26 11:02:38 theanets.trainer:168 RmsProp 1845 loss=0.065559 err=0.065559
I 2015-05-26 11:02:44 theanets.trainer:168 RmsProp 1846 loss=0.058361 err=0.058361
I 2015-05-26 11:02:49 theanets.trainer:168 RmsProp 1847 loss=0.050852 err=0.050852
I 2015-05-26 11:02:54 theanets.trainer:168 RmsProp 1848 loss=0.058278 err=0.058278
I 2015-05-26 11:02:59 theanets.trainer:168 RmsProp 1849 loss=0.053876 err=0.053876
I 2015-05-26 11:03:04 theanets.trainer:168 RmsProp 1850 loss=0.051381 err=0.051381
I 2015-05-26 11:03:05 theanets.trainer:168 validation 185 loss=1536.200073 err=1536.200073
I 2015-05-26 11:03:09 theanets.trainer:168 RmsProp 1851 loss=0.056346 err=0.056346
I 2015-05-26 11:03:14 theanets.trainer:168 RmsProp 1852 loss=0.056232 err=0.056232
I 2015-05-26 11:03:19 theanets.trainer:168 RmsProp 1853 loss=0.059709 err=0.059709
I 2015-05-26 11:03:25 theanets.trainer:168 RmsProp 1854 loss=0.060299 err=0.060299
I 2015-05-26 11:03:30 theanets.trainer:168 RmsProp 1855 loss=0.052145 err=0.052145
I 2015-05-26 11:03:35 theanets.trainer:168 RmsProp 1856 loss=0.056538 err=0.056538
I 2015-05-26 11:03:40 theanets.trainer:168 RmsProp 1857 loss=0.047809 err=0.047809
I 2015-05-26 11:03:45 theanets.trainer:168 RmsProp 1858 loss=0.068221 err=0.068221
I 2015-05-26 11:03:51 theanets.trainer:168 RmsProp 1859 loss=0.055932 err=0.055932
I 2015-05-26 11:03:56 theanets.trainer:168 RmsProp 1860 loss=0.047360 err=0.047360
I 2015-05-26 11:03:56 theanets.trainer:168 validation 186 loss=1535.693970 err=1535.693970
I 2015-05-26 11:04:01 theanets.trainer:168 RmsProp 1861 loss=0.057124 err=0.057124
I 2015-05-26 11:04:06 theanets.trainer:168 RmsProp 1862 loss=0.055492 err=0.055492
I 2015-05-26 11:04:11 theanets.trainer:168 RmsProp 1863 loss=0.054556 err=0.054556
I 2015-05-26 11:04:16 theanets.trainer:168 RmsProp 1864 loss=0.059408 err=0.059408
I 2015-05-26 11:04:22 theanets.trainer:168 RmsProp 1865 loss=0.053298 err=0.053298
I 2015-05-26 11:04:27 theanets.trainer:168 RmsProp 1866 loss=0.053251 err=0.053251
I 2015-05-26 11:04:32 theanets.trainer:168 RmsProp 1867 loss=0.054089 err=0.054089
I 2015-05-26 11:04:37 theanets.trainer:168 RmsProp 1868 loss=0.055129 err=0.055129
I 2015-05-26 11:04:42 theanets.trainer:168 RmsProp 1869 loss=0.054075 err=0.054075
I 2015-05-26 11:04:48 theanets.trainer:168 RmsProp 1870 loss=0.053141 err=0.053141
I 2015-05-26 11:04:48 theanets.trainer:168 validation 187 loss=1534.902588 err=1534.902588
I 2015-05-26 11:04:48 theanets.trainer:252 patience elapsed!
I 2015-05-26 11:04:48 theanets.main:237 models_deep_post_code_sep/95135-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saving model
I 2015-05-26 11:04:48 theanets.graph:477 models_deep_post_code_sep/95135-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saved model parameters
