I 2015-05-26 22:05:11 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:12 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:12 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95128-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:12 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:12 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:12 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:12 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:12 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:12 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:12 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:12 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:12 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:12 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:12 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:29 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:04 theano.gof.compilelock:266 Waiting for existing lock by process '29907' (I am process '29977')
I 2015-05-26 22:08:04 theano.gof.compilelock:268 To manually release the lock, delete /localdisk/qyou/.theano/compiledir_Linux-3.19-fc20.x86_64-x86_64-with-fedora-20-Heisenbug-x86_64-2.7.5-64/lock_dir
I 2015-05-26 22:08:26 theanets.trainer:168 validation 0 loss=14400.250977 err=14157.968750 *
I 2015-05-26 22:09:01 theanets.trainer:168 RmsProp 1 loss=13312.207031 err=13218.238281
I 2015-05-26 22:09:40 theanets.trainer:168 RmsProp 2 loss=13169.278320 err=13150.658203
I 2015-05-26 22:10:18 theanets.trainer:168 RmsProp 3 loss=13056.506836 err=13043.374023
I 2015-05-26 22:10:56 theanets.trainer:168 RmsProp 4 loss=12951.203125 err=12926.643555
I 2015-05-26 22:11:35 theanets.trainer:168 RmsProp 5 loss=11811.508789 err=11760.080078
I 2015-05-26 22:12:12 theanets.trainer:168 RmsProp 6 loss=10725.562500 err=10652.949219
I 2015-05-26 22:12:50 theanets.trainer:168 RmsProp 7 loss=10271.561523 err=10186.645508
I 2015-05-26 22:13:29 theanets.trainer:168 RmsProp 8 loss=9858.594727 err=9757.166016
I 2015-05-26 22:14:09 theanets.trainer:168 RmsProp 9 loss=9530.889648 err=9413.350586
I 2015-05-26 22:14:47 theanets.trainer:168 RmsProp 10 loss=9395.110352 err=9268.830078
I 2015-05-26 22:14:48 theanets.trainer:168 validation 1 loss=9720.200195 err=9593.222656 *
I 2015-05-26 22:15:26 theanets.trainer:168 RmsProp 11 loss=9058.603516 err=8930.939453
I 2015-05-26 22:16:06 theanets.trainer:168 RmsProp 12 loss=8717.000977 err=8582.555664
I 2015-05-26 22:16:45 theanets.trainer:168 RmsProp 13 loss=8496.913086 err=8349.303711
I 2015-05-26 22:17:24 theanets.trainer:168 RmsProp 14 loss=8126.169434 err=7960.343750
I 2015-05-26 22:18:03 theanets.trainer:168 RmsProp 15 loss=7647.523438 err=7460.098633
I 2015-05-26 22:18:41 theanets.trainer:168 RmsProp 16 loss=7199.516113 err=7003.225098
I 2015-05-26 22:19:20 theanets.trainer:168 RmsProp 17 loss=6904.112305 err=6696.582520
I 2015-05-26 22:19:58 theanets.trainer:168 RmsProp 18 loss=6688.728027 err=6465.365723
I 2015-05-26 22:20:36 theanets.trainer:168 RmsProp 19 loss=6526.789062 err=6288.095215
I 2015-05-26 22:21:15 theanets.trainer:168 RmsProp 20 loss=6343.921875 err=6091.981934
I 2015-05-26 22:21:16 theanets.trainer:168 validation 2 loss=5728.138184 err=5472.410645 *
I 2015-05-26 22:21:54 theanets.trainer:168 RmsProp 21 loss=6176.258301 err=5915.965820
I 2015-05-26 22:22:33 theanets.trainer:168 RmsProp 22 loss=5996.979492 err=5726.733398
I 2015-05-26 22:23:11 theanets.trainer:168 RmsProp 23 loss=5742.305176 err=5462.007324
I 2015-05-26 22:23:49 theanets.trainer:168 RmsProp 24 loss=5606.661133 err=5314.952637
I 2015-05-26 22:24:27 theanets.trainer:168 RmsProp 25 loss=5611.365723 err=5298.024414
I 2015-05-26 22:25:06 theanets.trainer:168 RmsProp 26 loss=5438.275879 err=5115.470215
I 2015-05-26 22:25:44 theanets.trainer:168 RmsProp 27 loss=5376.110840 err=5048.312012
I 2015-05-26 22:26:22 theanets.trainer:168 RmsProp 28 loss=5273.720215 err=4936.622070
I 2015-05-26 22:27:01 theanets.trainer:168 RmsProp 29 loss=5148.229004 err=4803.578613
I 2015-05-26 22:27:39 theanets.trainer:168 RmsProp 30 loss=5035.647949 err=4685.369629
I 2015-05-26 22:27:40 theanets.trainer:168 validation 3 loss=4398.129395 err=4043.820312 *
I 2015-05-26 22:28:19 theanets.trainer:168 RmsProp 31 loss=4986.537598 err=4628.278320
I 2015-05-26 22:28:58 theanets.trainer:168 RmsProp 32 loss=4900.994141 err=4534.875000
I 2015-05-26 22:29:37 theanets.trainer:168 RmsProp 33 loss=4840.717773 err=4465.215332
I 2015-05-26 22:30:16 theanets.trainer:168 RmsProp 34 loss=4732.342773 err=4349.673340
I 2015-05-26 22:30:55 theanets.trainer:168 RmsProp 35 loss=4701.880371 err=4310.640625
I 2015-05-26 22:31:34 theanets.trainer:168 RmsProp 36 loss=4564.475586 err=4164.344727
I 2015-05-26 22:32:13 theanets.trainer:168 RmsProp 37 loss=4592.555176 err=4183.745117
I 2015-05-26 22:32:52 theanets.trainer:168 RmsProp 38 loss=4496.364258 err=4079.104980
I 2015-05-26 22:33:30 theanets.trainer:168 RmsProp 39 loss=4463.625488 err=4038.812988
I 2015-05-26 22:34:08 theanets.trainer:168 RmsProp 40 loss=4360.044434 err=3928.441895
I 2015-05-26 22:34:09 theanets.trainer:168 validation 4 loss=3977.903564 err=3543.067139 *
I 2015-05-26 22:34:47 theanets.trainer:168 RmsProp 41 loss=4304.986816 err=3866.539062
I 2015-05-26 22:35:26 theanets.trainer:168 RmsProp 42 loss=4228.348633 err=3782.434570
I 2015-05-26 22:36:04 theanets.trainer:168 RmsProp 43 loss=4160.186035 err=3707.653564
I 2015-05-26 22:36:42 theanets.trainer:168 RmsProp 44 loss=4111.656250 err=3652.397217
I 2015-05-26 22:37:20 theanets.trainer:168 RmsProp 45 loss=4042.988281 err=3576.859131
I 2015-05-26 22:37:58 theanets.trainer:168 RmsProp 46 loss=4017.324707 err=3544.596924
I 2015-05-26 22:38:35 theanets.trainer:168 RmsProp 47 loss=3955.293701 err=3475.558594
I 2015-05-26 22:39:14 theanets.trainer:168 RmsProp 48 loss=3952.753906 err=3465.211182
I 2015-05-26 22:39:52 theanets.trainer:168 RmsProp 49 loss=3837.293945 err=3343.695557
I 2015-05-26 22:40:28 theanets.trainer:168 RmsProp 50 loss=3783.815186 err=3285.224854
I 2015-05-26 22:40:29 theanets.trainer:168 validation 5 loss=3783.522217 err=3281.991943 *
I 2015-05-26 22:41:07 theanets.trainer:168 RmsProp 51 loss=3752.469727 err=3248.001221
I 2015-05-26 22:41:46 theanets.trainer:168 RmsProp 52 loss=3736.493408 err=3224.930664
I 2015-05-26 22:42:23 theanets.trainer:168 RmsProp 53 loss=3702.233154 err=3184.007812
I 2015-05-26 22:43:01 theanets.trainer:168 RmsProp 54 loss=3605.940674 err=3083.953369
I 2015-05-26 22:43:39 theanets.trainer:168 RmsProp 55 loss=3566.816162 err=3040.278076
I 2015-05-26 22:44:18 theanets.trainer:168 RmsProp 56 loss=3530.687500 err=2996.559570
I 2015-05-26 22:44:57 theanets.trainer:168 RmsProp 57 loss=3483.482910 err=2943.237061
I 2015-05-26 22:45:36 theanets.trainer:168 RmsProp 58 loss=3457.515381 err=2910.157227
I 2015-05-26 22:46:14 theanets.trainer:168 RmsProp 59 loss=3401.686523 err=2844.842773
I 2015-05-26 22:46:52 theanets.trainer:168 RmsProp 60 loss=3447.304688 err=2882.416504
I 2015-05-26 22:46:53 theanets.trainer:168 validation 6 loss=3490.547607 err=2922.768311 *
I 2015-05-26 22:47:31 theanets.trainer:168 RmsProp 61 loss=3308.039551 err=2739.223389
I 2015-05-26 22:48:09 theanets.trainer:168 RmsProp 62 loss=3263.302490 err=2691.958252
I 2015-05-26 22:48:46 theanets.trainer:168 RmsProp 63 loss=3240.947998 err=2665.643555
I 2015-05-26 22:49:24 theanets.trainer:168 RmsProp 64 loss=3207.821533 err=2627.613037
I 2015-05-26 22:50:02 theanets.trainer:168 RmsProp 65 loss=3204.457520 err=2617.510254
I 2015-05-26 22:50:40 theanets.trainer:168 RmsProp 66 loss=3167.851807 err=2575.173584
I 2015-05-26 22:51:18 theanets.trainer:168 RmsProp 67 loss=3136.182129 err=2539.745117
I 2015-05-26 22:51:57 theanets.trainer:168 RmsProp 68 loss=3107.926514 err=2507.289307
I 2015-05-26 22:52:35 theanets.trainer:168 RmsProp 69 loss=3031.195068 err=2427.560059
I 2015-05-26 22:53:14 theanets.trainer:168 RmsProp 70 loss=2992.026855 err=2384.469482
I 2015-05-26 22:53:14 theanets.trainer:168 validation 7 loss=3337.015625 err=2727.854004 *
I 2015-05-26 22:53:55 theanets.trainer:168 RmsProp 71 loss=3022.969727 err=2411.469482
I 2015-05-26 22:54:35 theanets.trainer:168 RmsProp 72 loss=3014.090820 err=2396.618408
I 2015-05-26 22:55:14 theanets.trainer:168 RmsProp 73 loss=2977.811279 err=2356.050781
I 2015-05-26 22:55:52 theanets.trainer:168 RmsProp 74 loss=3009.612305 err=2382.357910
I 2015-05-26 22:56:31 theanets.trainer:168 RmsProp 75 loss=2941.717285 err=2308.634277
I 2015-05-26 22:57:10 theanets.trainer:168 RmsProp 76 loss=2886.354004 err=2252.544678
I 2015-05-26 22:57:50 theanets.trainer:168 RmsProp 77 loss=2936.625732 err=2299.261963
I 2015-05-26 22:58:30 theanets.trainer:168 RmsProp 78 loss=2841.886719 err=2201.608398
I 2015-05-26 22:59:09 theanets.trainer:168 RmsProp 79 loss=2810.058838 err=2168.221680
I 2015-05-26 22:59:47 theanets.trainer:168 RmsProp 80 loss=2781.642090 err=2137.447266
I 2015-05-26 22:59:48 theanets.trainer:168 validation 8 loss=3181.395752 err=2537.168701 *
I 2015-05-26 23:00:25 theanets.trainer:168 RmsProp 81 loss=2706.596924 err=2062.125488
I 2015-05-26 23:01:02 theanets.trainer:168 RmsProp 82 loss=2702.642090 err=2055.765869
I 2015-05-26 23:01:42 theanets.trainer:168 RmsProp 83 loss=2658.760254 err=2010.073364
I 2015-05-26 23:02:20 theanets.trainer:168 RmsProp 84 loss=2656.560303 err=2006.082031
I 2015-05-26 23:02:59 theanets.trainer:168 RmsProp 85 loss=2646.083740 err=1992.855347
I 2015-05-26 23:03:38 theanets.trainer:168 RmsProp 86 loss=2754.496338 err=2094.967041
I 2015-05-26 23:04:17 theanets.trainer:168 RmsProp 87 loss=2692.545654 err=2026.721802
I 2015-05-26 23:04:55 theanets.trainer:168 RmsProp 88 loss=2633.009033 err=1965.597046
I 2015-05-26 23:05:33 theanets.trainer:168 RmsProp 89 loss=2594.497803 err=1926.994507
I 2015-05-26 23:06:10 theanets.trainer:168 RmsProp 90 loss=2546.571045 err=1877.983276
I 2015-05-26 23:06:11 theanets.trainer:168 validation 9 loss=3082.578857 err=2413.611328 *
I 2015-05-26 23:06:49 theanets.trainer:168 RmsProp 91 loss=2526.889893 err=1857.441772
I 2015-05-26 23:07:28 theanets.trainer:168 RmsProp 92 loss=2542.831055 err=1871.671875
I 2015-05-26 23:08:06 theanets.trainer:168 RmsProp 93 loss=2581.912842 err=1906.689087
I 2015-05-26 23:08:46 theanets.trainer:168 RmsProp 94 loss=2684.261963 err=2003.582031
I 2015-05-26 23:09:25 theanets.trainer:168 RmsProp 95 loss=2839.949951 err=2143.472168
I 2015-05-26 23:10:04 theanets.trainer:168 RmsProp 96 loss=2708.064941 err=2006.101196
I 2015-05-26 23:10:42 theanets.trainer:168 RmsProp 97 loss=2565.918945 err=1866.264038
I 2015-05-26 23:11:19 theanets.trainer:168 RmsProp 98 loss=2491.258789 err=1795.723145
I 2015-05-26 23:11:57 theanets.trainer:168 RmsProp 99 loss=2458.017334 err=1763.910889
I 2015-05-26 23:12:35 theanets.trainer:168 RmsProp 100 loss=2506.671143 err=1810.149048
I 2015-05-26 23:12:35 theanets.trainer:168 validation 10 loss=3253.435303 err=2553.377441
I 2015-05-26 23:13:13 theanets.trainer:168 RmsProp 101 loss=2533.877441 err=1831.993042
I 2015-05-26 23:13:52 theanets.trainer:168 RmsProp 102 loss=2449.520508 err=1748.966064
I 2015-05-26 23:14:31 theanets.trainer:168 RmsProp 103 loss=2411.644775 err=1711.058594
I 2015-05-26 23:15:09 theanets.trainer:168 RmsProp 104 loss=2382.893066 err=1683.167480
I 2015-05-26 23:15:47 theanets.trainer:168 RmsProp 105 loss=2342.670410 err=1641.458618
I 2015-05-26 23:16:26 theanets.trainer:168 RmsProp 106 loss=2346.604736 err=1643.353149
I 2015-05-26 23:17:05 theanets.trainer:168 RmsProp 107 loss=2353.276123 err=1649.414795
I 2015-05-26 23:17:42 theanets.trainer:168 RmsProp 108 loss=2354.850098 err=1648.770020
I 2015-05-26 23:18:20 theanets.trainer:168 RmsProp 109 loss=2346.670898 err=1639.100952
I 2015-05-26 23:18:57 theanets.trainer:168 RmsProp 110 loss=2330.743652 err=1620.010498
I 2015-05-26 23:18:58 theanets.trainer:168 validation 11 loss=3188.186768 err=2477.097412
I 2015-05-26 23:19:35 theanets.trainer:168 RmsProp 111 loss=2270.691406 err=1560.412354
I 2015-05-26 23:20:12 theanets.trainer:168 RmsProp 112 loss=2273.195801 err=1564.449097
I 2015-05-26 23:20:49 theanets.trainer:168 RmsProp 113 loss=2270.225586 err=1561.091431
I 2015-05-26 23:21:27 theanets.trainer:168 RmsProp 114 loss=2244.428711 err=1534.934692
I 2015-05-26 23:22:06 theanets.trainer:168 RmsProp 115 loss=2228.774170 err=1519.600708
I 2015-05-26 23:22:44 theanets.trainer:168 RmsProp 116 loss=2236.054199 err=1526.401733
I 2015-05-26 23:23:22 theanets.trainer:168 RmsProp 117 loss=2265.298096 err=1553.976074
I 2015-05-26 23:24:01 theanets.trainer:168 RmsProp 118 loss=2269.468018 err=1554.482544
I 2015-05-26 23:24:39 theanets.trainer:168 RmsProp 119 loss=2266.800293 err=1550.333496
I 2015-05-26 23:25:17 theanets.trainer:168 RmsProp 120 loss=2261.975342 err=1541.257812
I 2015-05-26 23:25:18 theanets.trainer:168 validation 12 loss=3196.166748 err=2475.453125
I 2015-05-26 23:25:55 theanets.trainer:168 RmsProp 121 loss=2240.512939 err=1519.645630
I 2015-05-26 23:26:32 theanets.trainer:168 RmsProp 122 loss=2220.223389 err=1498.761841
I 2015-05-26 23:27:10 theanets.trainer:168 RmsProp 123 loss=2236.788330 err=1514.236572
I 2015-05-26 23:27:47 theanets.trainer:168 RmsProp 124 loss=2261.505127 err=1535.081299
I 2015-05-26 23:28:26 theanets.trainer:168 RmsProp 125 loss=2193.960938 err=1467.670410
I 2015-05-26 23:29:05 theanets.trainer:168 RmsProp 126 loss=2169.541504 err=1443.785889
I 2015-05-26 23:29:43 theanets.trainer:168 RmsProp 127 loss=2159.324463 err=1433.666504
I 2015-05-26 23:30:21 theanets.trainer:168 RmsProp 128 loss=2188.288086 err=1460.819458
I 2015-05-26 23:30:59 theanets.trainer:168 RmsProp 129 loss=2190.195068 err=1459.367676
I 2015-05-26 23:31:36 theanets.trainer:168 RmsProp 130 loss=2231.133789 err=1499.122314
I 2015-05-26 23:31:37 theanets.trainer:168 validation 13 loss=3012.682617 err=2277.547363 *
I 2015-05-26 23:32:14 theanets.trainer:168 RmsProp 131 loss=2253.219238 err=1516.534424
I 2015-05-26 23:32:51 theanets.trainer:168 RmsProp 132 loss=2365.741943 err=1623.540283
I 2015-05-26 23:33:28 theanets.trainer:168 RmsProp 133 loss=2346.134521 err=1598.447998
I 2015-05-26 23:34:06 theanets.trainer:168 RmsProp 134 loss=2266.176270 err=1517.941650
I 2015-05-26 23:34:44 theanets.trainer:168 RmsProp 135 loss=2202.762451 err=1458.373901
I 2015-05-26 23:35:21 theanets.trainer:168 RmsProp 136 loss=2237.259277 err=1490.654297
I 2015-05-26 23:35:58 theanets.trainer:168 RmsProp 137 loss=2205.753418 err=1456.664429
I 2015-05-26 23:36:36 theanets.trainer:168 RmsProp 138 loss=2130.973389 err=1384.777344
I 2015-05-26 23:37:14 theanets.trainer:168 RmsProp 139 loss=2136.050049 err=1391.313232
I 2015-05-26 23:37:51 theanets.trainer:168 RmsProp 140 loss=2343.954834 err=1589.407837
I 2015-05-26 23:37:52 theanets.trainer:168 validation 14 loss=3107.575928 err=2348.610107
I 2015-05-26 23:38:30 theanets.trainer:168 RmsProp 141 loss=2307.606201 err=1546.351440
I 2015-05-26 23:39:08 theanets.trainer:168 RmsProp 142 loss=2300.596191 err=1536.594849
I 2015-05-26 23:39:46 theanets.trainer:168 RmsProp 143 loss=2169.431885 err=1403.782349
I 2015-05-26 23:40:24 theanets.trainer:168 RmsProp 144 loss=2093.105225 err=1335.026123
I 2015-05-26 23:41:03 theanets.trainer:168 RmsProp 145 loss=2128.766113 err=1370.832886
I 2015-05-26 23:41:42 theanets.trainer:168 RmsProp 146 loss=2120.211426 err=1358.664673
I 2015-05-26 23:42:20 theanets.trainer:168 RmsProp 147 loss=2145.969238 err=1381.902100
I 2015-05-26 23:42:59 theanets.trainer:168 RmsProp 148 loss=2150.369385 err=1385.005859
I 2015-05-26 23:43:37 theanets.trainer:168 RmsProp 149 loss=2086.662598 err=1321.476562
I 2015-05-26 23:44:15 theanets.trainer:168 RmsProp 150 loss=2016.812012 err=1256.028687
I 2015-05-26 23:44:16 theanets.trainer:168 validation 15 loss=2992.567627 err=2233.684326 *
I 2015-05-26 23:44:54 theanets.trainer:168 RmsProp 151 loss=2001.604980 err=1244.146606
I 2015-05-26 23:45:33 theanets.trainer:168 RmsProp 152 loss=1984.139038 err=1228.203613
I 2015-05-26 23:46:11 theanets.trainer:168 RmsProp 153 loss=2013.724854 err=1257.735596
I 2015-05-26 23:46:48 theanets.trainer:168 RmsProp 154 loss=2096.694580 err=1337.599731
I 2015-05-26 23:47:26 theanets.trainer:168 RmsProp 155 loss=2154.707764 err=1391.984497
I 2015-05-26 23:48:02 theanets.trainer:168 RmsProp 156 loss=2421.321289 err=1651.455200
I 2015-05-26 23:48:39 theanets.trainer:168 RmsProp 157 loss=2369.903564 err=1590.302246
I 2015-05-26 23:49:16 theanets.trainer:168 RmsProp 158 loss=2175.360596 err=1397.693726
I 2015-05-26 23:49:55 theanets.trainer:168 RmsProp 159 loss=2085.866943 err=1314.945068
I 2015-05-26 23:50:32 theanets.trainer:168 RmsProp 160 loss=2059.875977 err=1291.783691
I 2015-05-26 23:50:32 theanets.trainer:168 validation 16 loss=3296.046631 err=2528.118408
I 2015-05-26 23:51:07 theanets.trainer:168 RmsProp 161 loss=2138.489990 err=1366.677612
I 2015-05-26 23:51:42 theanets.trainer:168 RmsProp 162 loss=2071.568848 err=1298.339111
I 2015-05-26 23:52:15 theanets.trainer:168 RmsProp 163 loss=1998.092651 err=1230.525024
I 2015-05-26 23:52:52 theanets.trainer:168 RmsProp 164 loss=1982.138184 err=1217.594971
I 2015-05-26 23:53:29 theanets.trainer:168 RmsProp 165 loss=1988.198730 err=1223.162598
I 2015-05-26 23:54:06 theanets.trainer:168 RmsProp 166 loss=2048.046143 err=1280.542358
I 2015-05-26 23:54:44 theanets.trainer:168 RmsProp 167 loss=2035.134277 err=1264.792725
I 2015-05-26 23:55:22 theanets.trainer:168 RmsProp 168 loss=2104.191162 err=1330.117188
I 2015-05-26 23:56:00 theanets.trainer:168 RmsProp 169 loss=2054.902588 err=1279.088745
I 2015-05-26 23:56:36 theanets.trainer:168 RmsProp 170 loss=1977.068970 err=1203.597656
I 2015-05-26 23:56:37 theanets.trainer:168 validation 17 loss=3187.026123 err=2415.517334
I 2015-05-26 23:57:13 theanets.trainer:168 RmsProp 171 loss=1982.602173 err=1210.988647
I 2015-05-26 23:57:48 theanets.trainer:168 RmsProp 172 loss=2056.356445 err=1280.629639
I 2015-05-26 23:58:23 theanets.trainer:168 RmsProp 173 loss=2105.202637 err=1323.538452
I 2015-05-26 23:59:00 theanets.trainer:168 RmsProp 174 loss=2006.499390 err=1225.759766
I 2015-05-26 23:59:37 theanets.trainer:168 RmsProp 175 loss=1939.866333 err=1164.092896
I 2015-05-27 00:00:15 theanets.trainer:168 RmsProp 176 loss=1935.674438 err=1162.646606
I 2015-05-27 00:00:53 theanets.trainer:168 RmsProp 177 loss=1990.984009 err=1214.734253
I 2015-05-27 00:01:31 theanets.trainer:168 RmsProp 178 loss=2048.511475 err=1268.658081
I 2015-05-27 00:02:08 theanets.trainer:168 RmsProp 179 loss=1963.719482 err=1181.632446
I 2015-05-27 00:02:45 theanets.trainer:168 RmsProp 180 loss=1930.350220 err=1152.325562
I 2015-05-27 00:02:46 theanets.trainer:168 validation 18 loss=3071.323975 err=2295.383545
I 2015-05-27 00:03:23 theanets.trainer:168 RmsProp 181 loss=1879.582764 err=1105.254639
I 2015-05-27 00:04:00 theanets.trainer:168 RmsProp 182 loss=1883.017090 err=1110.076172
I 2015-05-27 00:04:37 theanets.trainer:168 RmsProp 183 loss=1901.690552 err=1128.311401
I 2015-05-27 00:05:14 theanets.trainer:168 RmsProp 184 loss=1918.968140 err=1141.942017
I 2015-05-27 00:05:51 theanets.trainer:168 RmsProp 185 loss=1954.552368 err=1175.864990
I 2015-05-27 00:06:28 theanets.trainer:168 RmsProp 186 loss=2048.576904 err=1266.180908
I 2015-05-27 00:07:05 theanets.trainer:168 RmsProp 187 loss=2037.404907 err=1251.485596
I 2015-05-27 00:07:42 theanets.trainer:168 RmsProp 188 loss=1915.656982 err=1131.994995
I 2015-05-27 00:08:19 theanets.trainer:168 RmsProp 189 loss=1868.706909 err=1089.339844
I 2015-05-27 00:08:55 theanets.trainer:168 RmsProp 190 loss=1845.504517 err=1068.911987
I 2015-05-27 00:08:56 theanets.trainer:168 validation 19 loss=2963.972412 err=2188.682373 *
I 2015-05-27 00:09:33 theanets.trainer:168 RmsProp 191 loss=1834.479248 err=1059.025513
I 2015-05-27 00:10:10 theanets.trainer:168 RmsProp 192 loss=1843.054199 err=1066.818970
I 2015-05-27 00:10:46 theanets.trainer:168 RmsProp 193 loss=1820.784424 err=1045.161499
I 2015-05-27 00:11:23 theanets.trainer:168 RmsProp 194 loss=1817.813354 err=1042.918091
I 2015-05-27 00:11:58 theanets.trainer:168 RmsProp 195 loss=1892.411377 err=1113.922119
I 2015-05-27 00:12:32 theanets.trainer:168 RmsProp 196 loss=1851.099854 err=1070.502075
I 2015-05-27 00:13:06 theanets.trainer:168 RmsProp 197 loss=1795.014771 err=1017.140381
I 2015-05-27 00:13:40 theanets.trainer:168 RmsProp 198 loss=1781.997803 err=1006.356445
I 2015-05-27 00:14:14 theanets.trainer:168 RmsProp 199 loss=1835.927368 err=1059.375854
I 2015-05-27 00:14:47 theanets.trainer:168 RmsProp 200 loss=1840.229614 err=1061.262573
I 2015-05-27 00:14:48 theanets.trainer:168 validation 20 loss=3010.369385 err=2230.102051
I 2015-05-27 00:15:19 theanets.trainer:168 RmsProp 201 loss=1810.686890 err=1031.609497
I 2015-05-27 00:15:51 theanets.trainer:168 RmsProp 202 loss=1775.664917 err=998.938782
I 2015-05-27 00:16:23 theanets.trainer:168 RmsProp 203 loss=1756.052734 err=982.167542
I 2015-05-27 00:16:56 theanets.trainer:168 RmsProp 204 loss=1769.297485 err=996.347961
I 2015-05-27 00:17:30 theanets.trainer:168 RmsProp 205 loss=1767.141968 err=991.785095
I 2015-05-27 00:18:04 theanets.trainer:168 RmsProp 206 loss=1762.727905 err=988.141846
I 2015-05-27 00:18:37 theanets.trainer:168 RmsProp 207 loss=1782.126831 err=1006.791565
I 2015-05-27 00:19:10 theanets.trainer:168 RmsProp 208 loss=1816.879150 err=1039.453491
I 2015-05-27 00:19:44 theanets.trainer:168 RmsProp 209 loss=1876.348755 err=1092.805298
I 2015-05-27 00:20:17 theanets.trainer:168 RmsProp 210 loss=1828.380005 err=1044.394897
I 2015-05-27 00:20:18 theanets.trainer:168 validation 21 loss=2937.043945 err=2155.697754 *
I 2015-05-27 00:20:52 theanets.trainer:168 RmsProp 211 loss=1820.991699 err=1038.137085
I 2015-05-27 00:21:25 theanets.trainer:168 RmsProp 212 loss=1781.821167 err=999.798218
I 2015-05-27 00:22:00 theanets.trainer:168 RmsProp 213 loss=1734.325073 err=955.722229
I 2015-05-27 00:22:33 theanets.trainer:168 RmsProp 214 loss=1721.438232 err=945.390259
I 2015-05-27 00:23:07 theanets.trainer:168 RmsProp 215 loss=1713.728760 err=938.664612
I 2015-05-27 00:23:40 theanets.trainer:168 RmsProp 216 loss=1697.952759 err=924.706055
I 2015-05-27 00:24:14 theanets.trainer:168 RmsProp 217 loss=1690.642090 err=918.460388
I 2015-05-27 00:24:47 theanets.trainer:168 RmsProp 218 loss=1688.158813 err=917.006775
I 2015-05-27 00:25:20 theanets.trainer:168 RmsProp 219 loss=1797.100342 err=1023.052917
I 2015-05-27 00:25:54 theanets.trainer:168 RmsProp 220 loss=1718.821167 err=942.989075
I 2015-05-27 00:25:55 theanets.trainer:168 validation 22 loss=2838.306396 err=2064.722656 *
I 2015-05-27 00:26:28 theanets.trainer:168 RmsProp 221 loss=1694.505615 err=920.667297
I 2015-05-27 00:27:01 theanets.trainer:168 RmsProp 222 loss=1668.570679 err=897.623901
I 2015-05-27 00:27:34 theanets.trainer:168 RmsProp 223 loss=1684.467163 err=915.286133
I 2015-05-27 00:28:06 theanets.trainer:168 RmsProp 224 loss=1689.429688 err=919.212036
I 2015-05-27 00:28:39 theanets.trainer:168 RmsProp 225 loss=1666.087036 err=896.590149
I 2015-05-27 00:29:12 theanets.trainer:168 RmsProp 226 loss=1638.387451 err=871.941406
I 2015-05-27 00:29:46 theanets.trainer:168 RmsProp 227 loss=1636.392944 err=872.323853
I 2015-05-27 00:30:19 theanets.trainer:168 RmsProp 228 loss=1646.867554 err=881.885803
I 2015-05-27 00:30:51 theanets.trainer:168 RmsProp 229 loss=1617.635498 err=855.433472
I 2015-05-27 00:31:24 theanets.trainer:168 RmsProp 230 loss=1603.741943 err=844.115234
I 2015-05-27 00:31:25 theanets.trainer:168 validation 23 loss=2841.551514 err=2082.247803
I 2015-05-27 00:31:58 theanets.trainer:168 RmsProp 231 loss=1641.239014 err=881.205078
I 2015-05-27 00:32:31 theanets.trainer:168 RmsProp 232 loss=1618.135498 err=857.633606
I 2015-05-27 00:33:05 theanets.trainer:168 RmsProp 233 loss=1600.225220 err=842.779663
I 2015-05-27 00:33:38 theanets.trainer:168 RmsProp 234 loss=1602.240356 err=845.675659
I 2015-05-27 00:34:11 theanets.trainer:168 RmsProp 235 loss=1609.030640 err=852.445251
I 2015-05-27 00:34:45 theanets.trainer:168 RmsProp 236 loss=1626.752563 err=870.452026
I 2015-05-27 00:35:20 theanets.trainer:168 RmsProp 237 loss=1633.146118 err=875.833557
I 2015-05-27 00:35:53 theanets.trainer:168 RmsProp 238 loss=1617.093994 err=860.137634
I 2015-05-27 00:36:27 theanets.trainer:168 RmsProp 239 loss=1619.869995 err=861.285828
I 2015-05-27 00:37:00 theanets.trainer:168 RmsProp 240 loss=1597.250366 err=840.860535
I 2015-05-27 00:37:00 theanets.trainer:168 validation 24 loss=2884.485107 err=2129.389404
I 2015-05-27 00:37:34 theanets.trainer:168 RmsProp 241 loss=1584.797485 err=830.432251
I 2015-05-27 00:38:07 theanets.trainer:168 RmsProp 242 loss=1551.871948 err=799.709045
I 2015-05-27 00:38:41 theanets.trainer:168 RmsProp 243 loss=1579.426025 err=828.065979
I 2015-05-27 00:39:13 theanets.trainer:168 RmsProp 244 loss=1636.721313 err=883.080200
I 2015-05-27 00:39:47 theanets.trainer:168 RmsProp 245 loss=1628.615479 err=871.490112
I 2015-05-27 00:40:20 theanets.trainer:168 RmsProp 246 loss=1629.718994 err=873.732300
I 2015-05-27 00:40:53 theanets.trainer:168 RmsProp 247 loss=1707.772949 err=946.816345
I 2015-05-27 00:41:26 theanets.trainer:168 RmsProp 248 loss=1658.374634 err=895.584351
I 2015-05-27 00:41:59 theanets.trainer:168 RmsProp 249 loss=1599.599731 err=841.619446
I 2015-05-27 00:42:32 theanets.trainer:168 RmsProp 250 loss=1589.682373 err=834.723328
I 2015-05-27 00:42:33 theanets.trainer:168 validation 25 loss=2887.255127 err=2133.393311
I 2015-05-27 00:43:07 theanets.trainer:168 RmsProp 251 loss=1584.137573 err=830.782532
I 2015-05-27 00:43:40 theanets.trainer:168 RmsProp 252 loss=1569.222900 err=816.717163
I 2015-05-27 00:44:14 theanets.trainer:168 RmsProp 253 loss=1570.541504 err=818.872620
I 2015-05-27 00:44:47 theanets.trainer:168 RmsProp 254 loss=1544.876221 err=794.750916
I 2015-05-27 00:45:21 theanets.trainer:168 RmsProp 255 loss=1549.798706 err=801.658142
I 2015-05-27 00:45:54 theanets.trainer:168 RmsProp 256 loss=1543.232422 err=795.488220
I 2015-05-27 00:46:28 theanets.trainer:168 RmsProp 257 loss=1546.713379 err=799.679443
I 2015-05-27 00:47:01 theanets.trainer:168 RmsProp 258 loss=1529.938843 err=783.726868
I 2015-05-27 00:47:35 theanets.trainer:168 RmsProp 259 loss=1545.912354 err=800.218933
I 2015-05-27 00:48:09 theanets.trainer:168 RmsProp 260 loss=1554.461670 err=808.539612
I 2015-05-27 00:48:10 theanets.trainer:168 validation 26 loss=2917.196045 err=2169.214844
I 2015-05-27 00:48:44 theanets.trainer:168 RmsProp 261 loss=1583.111938 err=833.767639
I 2015-05-27 00:49:18 theanets.trainer:168 RmsProp 262 loss=1558.838989 err=809.601135
I 2015-05-27 00:49:52 theanets.trainer:168 RmsProp 263 loss=1536.663574 err=790.004028
I 2015-05-27 00:50:26 theanets.trainer:168 RmsProp 264 loss=1537.202759 err=791.797852
I 2015-05-27 00:51:00 theanets.trainer:168 RmsProp 265 loss=1542.575562 err=798.243225
I 2015-05-27 00:51:34 theanets.trainer:168 RmsProp 266 loss=1510.980713 err=767.786011
I 2015-05-27 00:52:08 theanets.trainer:168 RmsProp 267 loss=1510.026611 err=768.457947
I 2015-05-27 00:52:42 theanets.trainer:168 RmsProp 268 loss=1495.067871 err=754.244324
I 2015-05-27 00:53:16 theanets.trainer:168 RmsProp 269 loss=1498.824829 err=758.623291
I 2015-05-27 00:53:49 theanets.trainer:168 RmsProp 270 loss=1492.959595 err=752.713196
I 2015-05-27 00:53:50 theanets.trainer:168 validation 27 loss=2779.416748 err=2039.395874 *
I 2015-05-27 00:54:24 theanets.trainer:168 RmsProp 271 loss=1471.714478 err=732.986755
I 2015-05-27 00:54:58 theanets.trainer:168 RmsProp 272 loss=1487.765991 err=750.400696
I 2015-05-27 00:55:32 theanets.trainer:168 RmsProp 273 loss=1482.272583 err=745.406494
I 2015-05-27 00:56:05 theanets.trainer:168 RmsProp 274 loss=1473.600830 err=737.822205
I 2015-05-27 00:56:39 theanets.trainer:168 RmsProp 275 loss=1484.269531 err=748.968689
I 2015-05-27 00:57:12 theanets.trainer:168 RmsProp 276 loss=1467.012451 err=732.190186
I 2015-05-27 00:57:46 theanets.trainer:168 RmsProp 277 loss=1459.428467 err=725.696960
I 2015-05-27 00:58:19 theanets.trainer:168 RmsProp 278 loss=1465.604004 err=732.636536
I 2015-05-27 00:58:52 theanets.trainer:168 RmsProp 279 loss=1475.416626 err=742.514648
I 2015-05-27 00:59:25 theanets.trainer:168 RmsProp 280 loss=1477.584229 err=744.840088
I 2015-05-27 00:59:26 theanets.trainer:168 validation 28 loss=2820.100586 err=2086.765381
I 2015-05-27 00:59:59 theanets.trainer:168 RmsProp 281 loss=1459.706299 err=726.801025
I 2015-05-27 01:00:32 theanets.trainer:168 RmsProp 282 loss=1453.384766 err=722.213440
I 2015-05-27 01:01:05 theanets.trainer:168 RmsProp 283 loss=1445.474731 err=715.831421
I 2015-05-27 01:01:38 theanets.trainer:168 RmsProp 284 loss=1440.690186 err=712.450989
I 2015-05-27 01:02:10 theanets.trainer:168 RmsProp 285 loss=1447.829834 err=720.392761
I 2015-05-27 01:02:44 theanets.trainer:168 RmsProp 286 loss=1441.671143 err=714.267761
I 2015-05-27 01:03:17 theanets.trainer:168 RmsProp 287 loss=1437.191528 err=710.881042
I 2015-05-27 01:03:51 theanets.trainer:168 RmsProp 288 loss=1446.319824 err=719.865662
I 2015-05-27 01:04:24 theanets.trainer:168 RmsProp 289 loss=1433.070923 err=706.959900
I 2015-05-27 01:04:58 theanets.trainer:168 RmsProp 290 loss=1435.111328 err=709.880127
I 2015-05-27 01:04:59 theanets.trainer:168 validation 29 loss=2808.190186 err=2082.988037
I 2015-05-27 01:05:33 theanets.trainer:168 RmsProp 291 loss=1454.753296 err=728.787781
I 2015-05-27 01:06:06 theanets.trainer:168 RmsProp 292 loss=1452.014282 err=725.711487
I 2015-05-27 01:06:39 theanets.trainer:168 RmsProp 293 loss=1472.051392 err=746.282104
I 2015-05-27 01:07:13 theanets.trainer:168 RmsProp 294 loss=1593.636841 err=861.188538
I 2015-05-27 01:07:46 theanets.trainer:168 RmsProp 295 loss=1603.128540 err=866.312073
I 2015-05-27 01:08:20 theanets.trainer:168 RmsProp 296 loss=1527.737061 err=791.915894
I 2015-05-27 01:08:54 theanets.trainer:168 RmsProp 297 loss=1499.994385 err=764.559204
I 2015-05-27 01:09:28 theanets.trainer:168 RmsProp 298 loss=1468.175903 err=736.430542
I 2015-05-27 01:10:03 theanets.trainer:168 RmsProp 299 loss=1468.984741 err=738.178406
I 2015-05-27 01:10:37 theanets.trainer:168 RmsProp 300 loss=1459.429077 err=729.840515
I 2015-05-27 01:10:38 theanets.trainer:168 validation 30 loss=2819.410889 err=2090.538086
I 2015-05-27 01:11:12 theanets.trainer:168 RmsProp 301 loss=1450.248901 err=721.823792
I 2015-05-27 01:11:47 theanets.trainer:168 RmsProp 302 loss=1451.262817 err=723.194275
I 2015-05-27 01:12:22 theanets.trainer:168 RmsProp 303 loss=1427.196411 err=700.317688
I 2015-05-27 01:12:56 theanets.trainer:168 RmsProp 304 loss=1449.263550 err=722.558472
I 2015-05-27 01:13:29 theanets.trainer:168 RmsProp 305 loss=1446.684937 err=717.938171
I 2015-05-27 01:14:03 theanets.trainer:168 RmsProp 306 loss=1453.871460 err=726.453735
I 2015-05-27 01:14:36 theanets.trainer:168 RmsProp 307 loss=1445.862061 err=718.437927
I 2015-05-27 01:15:10 theanets.trainer:168 RmsProp 308 loss=1422.293823 err=696.169495
I 2015-05-27 01:15:43 theanets.trainer:168 RmsProp 309 loss=1445.393066 err=719.243103
I 2015-05-27 01:16:17 theanets.trainer:168 RmsProp 310 loss=1455.805176 err=726.989014
I 2015-05-27 01:16:18 theanets.trainer:168 validation 31 loss=2651.683594 err=1922.715210 *
I 2015-05-27 01:16:51 theanets.trainer:168 RmsProp 311 loss=1456.424072 err=728.126343
I 2015-05-27 01:17:25 theanets.trainer:168 RmsProp 312 loss=1488.250610 err=757.117004
I 2015-05-27 01:17:59 theanets.trainer:168 RmsProp 313 loss=1458.714355 err=727.921143
I 2015-05-27 01:18:33 theanets.trainer:168 RmsProp 314 loss=1435.837402 err=707.205627
I 2015-05-27 01:19:07 theanets.trainer:168 RmsProp 315 loss=1420.748535 err=694.603088
I 2015-05-27 01:19:40 theanets.trainer:168 RmsProp 316 loss=1458.183594 err=730.782104
I 2015-05-27 01:20:15 theanets.trainer:168 RmsProp 317 loss=1435.118896 err=707.342346
I 2015-05-27 01:20:50 theanets.trainer:168 RmsProp 318 loss=1432.482910 err=704.345459
I 2015-05-27 01:21:23 theanets.trainer:168 RmsProp 319 loss=1404.409790 err=678.198120
I 2015-05-27 01:21:57 theanets.trainer:168 RmsProp 320 loss=1395.036743 err=671.003296
I 2015-05-27 01:21:58 theanets.trainer:168 validation 32 loss=2630.510254 err=1907.613159 *
I 2015-05-27 01:22:32 theanets.trainer:168 RmsProp 321 loss=1394.240601 err=672.035278
I 2015-05-27 01:23:06 theanets.trainer:168 RmsProp 322 loss=1386.633667 err=665.697510
I 2015-05-27 01:23:41 theanets.trainer:168 RmsProp 323 loss=1390.728760 err=670.847717
I 2015-05-27 01:24:15 theanets.trainer:168 RmsProp 324 loss=1384.955566 err=665.122864
I 2015-05-27 01:24:50 theanets.trainer:168 RmsProp 325 loss=1417.178833 err=695.252075
I 2015-05-27 01:25:24 theanets.trainer:168 RmsProp 326 loss=1411.242310 err=689.015991
I 2015-05-27 01:25:58 theanets.trainer:168 RmsProp 327 loss=1418.817505 err=696.787720
I 2015-05-27 01:26:33 theanets.trainer:168 RmsProp 328 loss=1410.433716 err=688.525085
I 2015-05-27 01:27:05 theanets.trainer:168 RmsProp 329 loss=1404.487793 err=683.072083
I 2015-05-27 01:27:38 theanets.trainer:168 RmsProp 330 loss=1389.002197 err=669.427673
I 2015-05-27 01:27:38 theanets.trainer:168 validation 33 loss=2638.062988 err=1918.359985
I 2015-05-27 01:28:10 theanets.trainer:168 RmsProp 331 loss=1380.582886 err=662.380798
I 2015-05-27 01:28:43 theanets.trainer:168 RmsProp 332 loss=1372.303223 err=655.293213
I 2015-05-27 01:29:16 theanets.trainer:168 RmsProp 333 loss=1384.865479 err=668.505615
I 2015-05-27 01:29:50 theanets.trainer:168 RmsProp 334 loss=1392.222900 err=674.089172
I 2015-05-27 01:30:23 theanets.trainer:168 RmsProp 335 loss=1370.941284 err=654.413635
I 2015-05-27 01:30:57 theanets.trainer:168 RmsProp 336 loss=1369.373291 err=654.022705
I 2015-05-27 01:31:30 theanets.trainer:168 RmsProp 337 loss=1370.715088 err=655.927002
I 2015-05-27 01:32:03 theanets.trainer:168 RmsProp 338 loss=1401.677246 err=685.601929
I 2015-05-27 01:32:36 theanets.trainer:168 RmsProp 339 loss=1383.480103 err=667.066162
I 2015-05-27 01:33:09 theanets.trainer:168 RmsProp 340 loss=1424.022095 err=707.550354
I 2015-05-27 01:33:10 theanets.trainer:168 validation 34 loss=2639.629883 err=1918.331909
I 2015-05-27 01:33:44 theanets.trainer:168 RmsProp 341 loss=1410.510254 err=689.624084
I 2015-05-27 01:34:17 theanets.trainer:168 RmsProp 342 loss=1382.213745 err=664.092407
I 2015-05-27 01:34:51 theanets.trainer:168 RmsProp 343 loss=1378.282837 err=661.214233
I 2015-05-27 01:35:23 theanets.trainer:168 RmsProp 344 loss=1367.131592 err=650.639526
I 2015-05-27 01:35:56 theanets.trainer:168 RmsProp 345 loss=1499.062988 err=779.491516
I 2015-05-27 01:36:30 theanets.trainer:168 RmsProp 346 loss=1630.967651 err=899.398376
I 2015-05-27 01:37:04 theanets.trainer:168 RmsProp 347 loss=1561.569946 err=826.747620
I 2015-05-27 01:37:38 theanets.trainer:168 RmsProp 348 loss=1483.646729 err=751.243835
I 2015-05-27 01:38:12 theanets.trainer:168 RmsProp 349 loss=1426.089966 err=697.795532
I 2015-05-27 01:38:46 theanets.trainer:168 RmsProp 350 loss=1393.307129 err=668.987732
I 2015-05-27 01:38:47 theanets.trainer:168 validation 35 loss=2772.350830 err=2049.581787
I 2015-05-27 01:39:20 theanets.trainer:168 RmsProp 351 loss=1385.724854 err=663.910889
I 2015-05-27 01:39:54 theanets.trainer:168 RmsProp 352 loss=1371.993896 err=651.969543
I 2015-05-27 01:40:28 theanets.trainer:168 RmsProp 353 loss=1371.006592 err=653.443359
I 2015-05-27 01:41:02 theanets.trainer:168 RmsProp 354 loss=1353.288452 err=636.684326
I 2015-05-27 01:41:33 theanets.trainer:168 RmsProp 355 loss=1362.057495 err=646.466248
I 2015-05-27 01:42:04 theanets.trainer:168 RmsProp 356 loss=1360.332031 err=645.463196
I 2015-05-27 01:42:34 theanets.trainer:168 RmsProp 357 loss=1381.521484 err=665.885742
I 2015-05-27 01:43:05 theanets.trainer:168 RmsProp 358 loss=1357.516357 err=642.958313
I 2015-05-27 01:43:35 theanets.trainer:168 RmsProp 359 loss=1334.422607 err=622.313477
I 2015-05-27 01:44:05 theanets.trainer:168 RmsProp 360 loss=1381.990601 err=669.406860
I 2015-05-27 01:44:06 theanets.trainer:168 validation 36 loss=2660.995605 err=1946.739868
I 2015-05-27 01:44:36 theanets.trainer:168 RmsProp 361 loss=1388.570435 err=673.937561
I 2015-05-27 01:45:06 theanets.trainer:168 RmsProp 362 loss=1362.901245 err=647.874939
I 2015-05-27 01:45:37 theanets.trainer:168 RmsProp 363 loss=1385.007202 err=668.788025
I 2015-05-27 01:46:08 theanets.trainer:168 RmsProp 364 loss=1380.783203 err=663.501282
I 2015-05-27 01:46:38 theanets.trainer:168 RmsProp 365 loss=1368.269287 err=652.516418
I 2015-05-27 01:47:08 theanets.trainer:168 RmsProp 366 loss=1452.786499 err=733.200623
I 2015-05-27 01:47:38 theanets.trainer:168 RmsProp 367 loss=1460.057861 err=736.010620
I 2015-05-27 01:48:09 theanets.trainer:168 RmsProp 368 loss=1383.508423 err=660.940308
I 2015-05-27 01:48:39 theanets.trainer:168 RmsProp 369 loss=1360.458984 err=641.371948
I 2015-05-27 01:49:10 theanets.trainer:168 RmsProp 370 loss=1345.859375 err=628.782532
I 2015-05-27 01:49:10 theanets.trainer:168 validation 37 loss=2645.781738 err=1929.185913
I 2015-05-27 01:49:10 theanets.trainer:252 patience elapsed!
I 2015-05-27 01:49:10 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 01:49:10 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 01:49:10 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 01:49:10 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 01:49:10 theanets.main:89 --batch_size = 1024
I 2015-05-27 01:49:10 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 01:49:10 theanets.main:89 --hidden_l1 = None
I 2015-05-27 01:49:10 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 01:49:10 theanets.main:89 --train_batches = 10
I 2015-05-27 01:49:10 theanets.main:89 --valid_batches = 2
I 2015-05-27 01:49:10 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 01:49:10 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 01:49:11 theanets.trainer:134 compiling evaluation function
I 2015-05-27 01:49:20 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 01:50:59 theanets.trainer:168 validation 0 loss=3596.657959 err=2873.760986 *
I 2015-05-27 01:51:09 theanets.trainer:168 RmsProp 1 loss=1604.940674 err=885.152832
I 2015-05-27 01:51:18 theanets.trainer:168 RmsProp 2 loss=1340.159790 err=622.320557
I 2015-05-27 01:51:28 theanets.trainer:168 RmsProp 3 loss=1219.485352 err=502.698547
I 2015-05-27 01:51:38 theanets.trainer:168 RmsProp 4 loss=1134.858521 err=419.011078
I 2015-05-27 01:51:48 theanets.trainer:168 RmsProp 5 loss=1069.356201 err=354.566833
I 2015-05-27 01:51:58 theanets.trainer:168 RmsProp 6 loss=1014.968567 err=301.385040
I 2015-05-27 01:52:08 theanets.trainer:168 RmsProp 7 loss=975.342896 err=263.213074
I 2015-05-27 01:52:18 theanets.trainer:168 RmsProp 8 loss=942.236816 err=231.891891
I 2015-05-27 01:52:28 theanets.trainer:168 RmsProp 9 loss=913.947388 err=205.675339
I 2015-05-27 01:52:38 theanets.trainer:168 RmsProp 10 loss=887.038269 err=181.127838
I 2015-05-27 01:52:38 theanets.trainer:168 validation 1 loss=2566.856201 err=1862.302002 *
I 2015-05-27 01:52:48 theanets.trainer:168 RmsProp 11 loss=869.565247 err=166.123993
I 2015-05-27 01:52:57 theanets.trainer:168 RmsProp 12 loss=857.869751 err=156.988983
I 2015-05-27 01:53:07 theanets.trainer:168 RmsProp 13 loss=841.248413 err=143.014313
I 2015-05-27 01:53:17 theanets.trainer:168 RmsProp 14 loss=826.207886 err=130.663788
I 2015-05-27 01:53:26 theanets.trainer:168 RmsProp 15 loss=817.052246 err=124.303429
I 2015-05-27 01:53:36 theanets.trainer:168 RmsProp 16 loss=806.737854 err=116.814529
I 2015-05-27 01:53:45 theanets.trainer:168 RmsProp 17 loss=797.051392 err=109.939293
I 2015-05-27 01:53:55 theanets.trainer:168 RmsProp 18 loss=788.841797 err=104.513039
I 2015-05-27 01:54:05 theanets.trainer:168 RmsProp 19 loss=782.581116 err=101.008026
I 2015-05-27 01:54:15 theanets.trainer:168 RmsProp 20 loss=773.825317 err=95.071304
I 2015-05-27 01:54:15 theanets.trainer:168 validation 2 loss=2323.619385 err=1646.422729 *
I 2015-05-27 01:54:25 theanets.trainer:168 RmsProp 21 loss=766.824280 err=90.862808
I 2015-05-27 01:54:34 theanets.trainer:168 RmsProp 22 loss=761.856140 err=88.671127
I 2015-05-27 01:54:44 theanets.trainer:168 RmsProp 23 loss=755.052673 err=84.738907
I 2015-05-27 01:54:53 theanets.trainer:168 RmsProp 24 loss=749.756714 err=82.312958
I 2015-05-27 01:55:03 theanets.trainer:168 RmsProp 25 loss=742.736450 err=78.024841
I 2015-05-27 01:55:12 theanets.trainer:168 RmsProp 26 loss=739.484375 err=77.506989
I 2015-05-27 01:55:22 theanets.trainer:168 RmsProp 27 loss=733.143921 err=73.906334
I 2015-05-27 01:55:32 theanets.trainer:168 RmsProp 28 loss=729.516541 err=72.899704
I 2015-05-27 01:55:41 theanets.trainer:168 RmsProp 29 loss=721.636841 err=67.654160
I 2015-05-27 01:55:51 theanets.trainer:168 RmsProp 30 loss=717.328369 err=66.032608
I 2015-05-27 01:55:52 theanets.trainer:168 validation 3 loss=2204.913818 err=1555.087036 *
I 2015-05-27 01:56:01 theanets.trainer:168 RmsProp 31 loss=713.681946 err=65.075859
I 2015-05-27 01:56:10 theanets.trainer:168 RmsProp 32 loss=708.611206 err=62.732655
I 2015-05-27 01:56:20 theanets.trainer:168 RmsProp 33 loss=705.200439 err=61.960155
I 2015-05-27 01:56:30 theanets.trainer:168 RmsProp 34 loss=701.670349 err=61.058342
I 2015-05-27 01:56:40 theanets.trainer:168 RmsProp 35 loss=695.070923 err=57.081432
I 2015-05-27 01:56:49 theanets.trainer:168 RmsProp 36 loss=691.108032 err=55.618237
I 2015-05-27 01:56:59 theanets.trainer:168 RmsProp 37 loss=685.755554 err=52.788841
I 2015-05-27 01:57:09 theanets.trainer:168 RmsProp 38 loss=682.971802 err=52.586903
I 2015-05-27 01:57:19 theanets.trainer:168 RmsProp 39 loss=678.797974 err=51.003998
I 2015-05-27 01:57:29 theanets.trainer:168 RmsProp 40 loss=678.339050 err=53.022758
I 2015-05-27 01:57:29 theanets.trainer:168 validation 4 loss=2112.810059 err=1488.840820 *
I 2015-05-27 01:57:39 theanets.trainer:168 RmsProp 41 loss=672.331482 err=49.489601
I 2015-05-27 01:57:49 theanets.trainer:168 RmsProp 42 loss=669.239319 err=48.844368
I 2015-05-27 01:57:58 theanets.trainer:168 RmsProp 43 loss=666.165649 err=48.189682
I 2015-05-27 01:58:08 theanets.trainer:168 RmsProp 44 loss=661.701660 err=46.151207
I 2015-05-27 01:58:18 theanets.trainer:168 RmsProp 45 loss=659.193359 err=46.031708
I 2015-05-27 01:58:27 theanets.trainer:168 RmsProp 46 loss=655.799988 err=45.028103
I 2015-05-27 01:58:37 theanets.trainer:168 RmsProp 47 loss=653.028687 err=44.642250
I 2015-05-27 01:58:47 theanets.trainer:168 RmsProp 48 loss=648.198059 err=42.235447
I 2015-05-27 01:58:57 theanets.trainer:168 RmsProp 49 loss=644.742554 err=41.206551
I 2015-05-27 01:59:07 theanets.trainer:168 RmsProp 50 loss=641.534485 err=40.308586
I 2015-05-27 01:59:07 theanets.trainer:168 validation 5 loss=2037.046021 err=1437.084717 *
I 2015-05-27 01:59:17 theanets.trainer:168 RmsProp 51 loss=639.677185 err=40.752731
I 2015-05-27 01:59:26 theanets.trainer:168 RmsProp 52 loss=635.767517 err=39.134583
I 2015-05-27 01:59:36 theanets.trainer:168 RmsProp 53 loss=632.381836 err=38.050537
I 2015-05-27 01:59:46 theanets.trainer:168 RmsProp 54 loss=630.846802 err=38.814365
I 2015-05-27 01:59:56 theanets.trainer:168 RmsProp 55 loss=627.839661 err=38.055374
I 2015-05-27 02:00:05 theanets.trainer:168 RmsProp 56 loss=624.996826 err=37.444302
I 2015-05-27 02:00:15 theanets.trainer:168 RmsProp 57 loss=620.451782 err=35.155415
I 2015-05-27 02:00:25 theanets.trainer:168 RmsProp 58 loss=619.766479 err=36.725456
I 2015-05-27 02:00:35 theanets.trainer:168 RmsProp 59 loss=616.191467 err=35.335213
I 2015-05-27 02:00:45 theanets.trainer:168 RmsProp 60 loss=611.972534 err=33.268562
I 2015-05-27 02:00:46 theanets.trainer:168 validation 6 loss=1977.270996 err=1399.753906 *
I 2015-05-27 02:00:56 theanets.trainer:168 RmsProp 61 loss=610.951416 err=34.442787
I 2015-05-27 02:01:06 theanets.trainer:168 RmsProp 62 loss=607.933716 err=33.588364
I 2015-05-27 02:01:15 theanets.trainer:168 RmsProp 63 loss=605.546387 err=33.372746
I 2015-05-27 02:01:25 theanets.trainer:168 RmsProp 64 loss=602.277649 err=32.257874
I 2015-05-27 02:01:35 theanets.trainer:168 RmsProp 65 loss=599.559937 err=31.653326
I 2015-05-27 02:01:45 theanets.trainer:168 RmsProp 66 loss=597.125061 err=31.304422
I 2015-05-27 02:01:54 theanets.trainer:168 RmsProp 67 loss=594.597473 err=30.861408
I 2015-05-27 02:02:03 theanets.trainer:168 RmsProp 68 loss=592.164917 err=30.584850
I 2015-05-27 02:02:13 theanets.trainer:168 RmsProp 69 loss=590.261108 err=30.770727
I 2015-05-27 02:02:23 theanets.trainer:168 RmsProp 70 loss=586.720520 err=29.097355
I 2015-05-27 02:02:24 theanets.trainer:168 validation 7 loss=1919.193115 err=1362.551147 *
I 2015-05-27 02:02:33 theanets.trainer:168 RmsProp 71 loss=585.030396 err=29.229471
I 2015-05-27 02:02:44 theanets.trainer:168 RmsProp 72 loss=582.917297 err=29.045023
I 2015-05-27 02:02:54 theanets.trainer:168 RmsProp 73 loss=580.741211 err=28.846813
I 2015-05-27 02:03:03 theanets.trainer:168 RmsProp 74 loss=577.708130 err=27.802288
I 2015-05-27 02:03:13 theanets.trainer:168 RmsProp 75 loss=575.688416 err=27.770294
I 2015-05-27 02:03:22 theanets.trainer:168 RmsProp 76 loss=574.299438 err=28.309748
I 2015-05-27 02:03:32 theanets.trainer:168 RmsProp 77 loss=570.863892 err=26.819620
I 2015-05-27 02:03:42 theanets.trainer:168 RmsProp 78 loss=569.359497 err=27.300297
I 2015-05-27 02:03:51 theanets.trainer:168 RmsProp 79 loss=566.907532 err=26.801609
I 2015-05-27 02:04:01 theanets.trainer:168 RmsProp 80 loss=564.778687 err=26.569565
I 2015-05-27 02:04:02 theanets.trainer:168 validation 8 loss=1866.390625 err=1329.213623 *
I 2015-05-27 02:04:12 theanets.trainer:168 RmsProp 81 loss=562.516724 err=26.199453
I 2015-05-27 02:04:22 theanets.trainer:168 RmsProp 82 loss=560.459351 err=26.010967
I 2015-05-27 02:04:32 theanets.trainer:168 RmsProp 83 loss=558.456299 err=25.796076
I 2015-05-27 02:04:41 theanets.trainer:168 RmsProp 84 loss=555.168579 err=24.346424
I 2015-05-27 02:04:52 theanets.trainer:168 RmsProp 85 loss=553.544250 err=24.612347
I 2015-05-27 02:05:02 theanets.trainer:168 RmsProp 86 loss=551.720703 err=24.626253
I 2015-05-27 02:05:11 theanets.trainer:168 RmsProp 87 loss=550.332275 err=25.071280
I 2015-05-27 02:05:21 theanets.trainer:168 RmsProp 88 loss=548.427307 err=24.972071
I 2015-05-27 02:05:31 theanets.trainer:168 RmsProp 89 loss=545.741821 err=24.122080
I 2015-05-27 02:05:41 theanets.trainer:168 RmsProp 90 loss=543.031372 err=23.213499
I 2015-05-27 02:05:42 theanets.trainer:168 validation 9 loss=1826.190308 err=1307.335815 *
I 2015-05-27 02:05:51 theanets.trainer:168 RmsProp 91 loss=541.638306 err=23.571041
I 2015-05-27 02:06:01 theanets.trainer:168 RmsProp 92 loss=539.425354 err=23.105915
I 2015-05-27 02:06:11 theanets.trainer:168 RmsProp 93 loss=536.780701 err=22.199835
I 2015-05-27 02:06:21 theanets.trainer:168 RmsProp 94 loss=535.080627 err=22.215725
I 2015-05-27 02:06:30 theanets.trainer:168 RmsProp 95 loss=532.803101 err=21.663744
I 2015-05-27 02:06:40 theanets.trainer:168 RmsProp 96 loss=532.535217 err=23.147528
I 2015-05-27 02:06:50 theanets.trainer:168 RmsProp 97 loss=530.085327 err=22.424778
I 2015-05-27 02:07:00 theanets.trainer:168 RmsProp 98 loss=527.703491 err=21.748001
I 2015-05-27 02:07:10 theanets.trainer:168 RmsProp 99 loss=525.437683 err=21.198591
I 2015-05-27 02:07:20 theanets.trainer:168 RmsProp 100 loss=524.001526 err=21.432184
I 2015-05-27 02:07:21 theanets.trainer:168 validation 10 loss=1780.714844 err=1279.052734 *
I 2015-05-27 02:07:30 theanets.trainer:168 RmsProp 101 loss=523.383179 err=22.498400
I 2015-05-27 02:07:40 theanets.trainer:168 RmsProp 102 loss=520.996094 err=21.800217
I 2015-05-27 02:07:50 theanets.trainer:168 RmsProp 103 loss=518.931519 err=21.337849
I 2015-05-27 02:08:00 theanets.trainer:168 RmsProp 104 loss=516.035767 err=20.052979
I 2015-05-27 02:08:10 theanets.trainer:168 RmsProp 105 loss=515.177673 err=20.812626
I 2015-05-27 02:08:19 theanets.trainer:168 RmsProp 106 loss=513.457886 err=20.723272
I 2015-05-27 02:08:29 theanets.trainer:168 RmsProp 107 loss=511.512878 err=20.338144
I 2015-05-27 02:08:39 theanets.trainer:168 RmsProp 108 loss=509.940979 err=20.337814
I 2015-05-27 02:08:49 theanets.trainer:168 RmsProp 109 loss=508.096039 err=20.092201
I 2015-05-27 02:08:59 theanets.trainer:168 RmsProp 110 loss=505.827087 err=19.385454
I 2015-05-27 02:09:00 theanets.trainer:168 validation 11 loss=1755.847656 err=1270.255859 *
I 2015-05-27 02:09:09 theanets.trainer:168 RmsProp 111 loss=504.841400 err=19.948669
I 2015-05-27 02:09:19 theanets.trainer:168 RmsProp 112 loss=502.446198 err=19.056097
I 2015-05-27 02:09:29 theanets.trainer:168 RmsProp 113 loss=501.388855 err=19.520426
I 2015-05-27 02:09:39 theanets.trainer:168 RmsProp 114 loss=500.666107 err=20.326500
I 2015-05-27 02:09:49 theanets.trainer:168 RmsProp 115 loss=498.022797 err=19.175144
I 2015-05-27 02:09:58 theanets.trainer:168 RmsProp 116 loss=496.027496 err=18.650644
I 2015-05-27 02:10:08 theanets.trainer:168 RmsProp 117 loss=494.805176 err=18.899654
I 2015-05-27 02:10:18 theanets.trainer:168 RmsProp 118 loss=492.980133 err=18.581125
I 2015-05-27 02:10:28 theanets.trainer:168 RmsProp 119 loss=492.165833 err=19.206848
I 2015-05-27 02:10:38 theanets.trainer:168 RmsProp 120 loss=490.690979 err=19.165529
I 2015-05-27 02:10:38 theanets.trainer:168 validation 12 loss=1718.007812 err=1247.281738 *
I 2015-05-27 02:10:47 theanets.trainer:168 RmsProp 121 loss=488.847412 err=18.766958
I 2015-05-27 02:10:57 theanets.trainer:168 RmsProp 122 loss=487.252380 err=18.594240
I 2015-05-27 02:11:07 theanets.trainer:168 RmsProp 123 loss=485.279480 err=18.068850
I 2015-05-27 02:11:17 theanets.trainer:168 RmsProp 124 loss=483.519470 err=17.747562
I 2015-05-27 02:11:26 theanets.trainer:168 RmsProp 125 loss=482.468597 err=18.146215
I 2015-05-27 02:11:36 theanets.trainer:168 RmsProp 126 loss=480.785156 err=17.896395
I 2015-05-27 02:11:46 theanets.trainer:168 RmsProp 127 loss=479.331726 err=17.860935
I 2015-05-27 02:11:56 theanets.trainer:168 RmsProp 128 loss=477.340912 err=17.281225
I 2015-05-27 02:12:05 theanets.trainer:168 RmsProp 129 loss=475.638428 err=16.995045
I 2015-05-27 02:12:15 theanets.trainer:168 RmsProp 130 loss=475.462158 err=18.232292
I 2015-05-27 02:12:16 theanets.trainer:168 validation 13 loss=1690.324951 err=1233.813843 *
I 2015-05-27 02:12:25 theanets.trainer:168 RmsProp 131 loss=472.607117 err=16.676800
I 2015-05-27 02:12:35 theanets.trainer:168 RmsProp 132 loss=471.999908 err=17.377764
I 2015-05-27 02:12:45 theanets.trainer:168 RmsProp 133 loss=470.408203 err=17.132130
I 2015-05-27 02:12:55 theanets.trainer:168 RmsProp 134 loss=469.639221 err=17.733131
I 2015-05-27 02:13:05 theanets.trainer:168 RmsProp 135 loss=467.182526 err=16.618958
I 2015-05-27 02:13:14 theanets.trainer:168 RmsProp 136 loss=465.501892 err=16.228668
I 2015-05-27 02:13:24 theanets.trainer:168 RmsProp 137 loss=464.337952 err=16.387802
I 2015-05-27 02:13:34 theanets.trainer:168 RmsProp 138 loss=463.015198 err=16.406786
I 2015-05-27 02:13:44 theanets.trainer:168 RmsProp 139 loss=462.721130 err=17.454309
I 2015-05-27 02:13:54 theanets.trainer:168 RmsProp 140 loss=460.555115 err=16.563816
I 2015-05-27 02:13:54 theanets.trainer:168 validation 14 loss=1652.565430 err=1209.244141 *
I 2015-05-27 02:14:04 theanets.trainer:168 RmsProp 141 loss=458.942963 err=16.189526
I 2015-05-27 02:14:14 theanets.trainer:168 RmsProp 142 loss=457.811584 err=16.329376
I 2015-05-27 02:14:23 theanets.trainer:168 RmsProp 143 loss=455.926849 err=15.708616
I 2015-05-27 02:14:32 theanets.trainer:168 RmsProp 144 loss=454.908539 err=15.954653
I 2015-05-27 02:14:41 theanets.trainer:168 RmsProp 145 loss=452.959534 err=15.281011
I 2015-05-27 02:14:51 theanets.trainer:168 RmsProp 146 loss=452.054504 err=15.643623
I 2015-05-27 02:15:01 theanets.trainer:168 RmsProp 147 loss=451.073730 err=15.933989
I 2015-05-27 02:15:10 theanets.trainer:168 RmsProp 148 loss=449.389069 err=15.522362
I 2015-05-27 02:15:19 theanets.trainer:168 RmsProp 149 loss=447.993225 err=15.408048
I 2015-05-27 02:15:29 theanets.trainer:168 RmsProp 150 loss=446.879089 err=15.536860
I 2015-05-27 02:15:29 theanets.trainer:168 validation 15 loss=1633.515869 err=1202.843384 *
I 2015-05-27 02:15:39 theanets.trainer:168 RmsProp 151 loss=445.511536 err=15.387874
I 2015-05-27 02:15:49 theanets.trainer:168 RmsProp 152 loss=444.309143 err=15.388750
I 2015-05-27 02:15:57 theanets.trainer:168 RmsProp 153 loss=443.137390 err=15.405062
I 2015-05-27 02:16:06 theanets.trainer:168 RmsProp 154 loss=441.478851 err=14.933868
I 2015-05-27 02:16:15 theanets.trainer:168 RmsProp 155 loss=440.661041 err=15.303807
I 2015-05-27 02:16:23 theanets.trainer:168 RmsProp 156 loss=438.883942 err=14.712964
I 2015-05-27 02:16:31 theanets.trainer:168 RmsProp 157 loss=438.233704 err=15.217253
I 2015-05-27 02:16:39 theanets.trainer:168 RmsProp 158 loss=436.563873 err=14.702647
I 2015-05-27 02:16:47 theanets.trainer:168 RmsProp 159 loss=435.721283 err=15.034986
I 2015-05-27 02:16:55 theanets.trainer:168 RmsProp 160 loss=433.902283 err=14.379170
I 2015-05-27 02:16:56 theanets.trainer:168 validation 16 loss=1608.042847 err=1189.154907 *
I 2015-05-27 02:17:04 theanets.trainer:168 RmsProp 161 loss=432.761719 err=14.410794
I 2015-05-27 02:17:13 theanets.trainer:168 RmsProp 162 loss=431.994080 err=14.801445
I 2015-05-27 02:17:22 theanets.trainer:168 RmsProp 163 loss=429.966492 err=13.894913
I 2015-05-27 02:17:30 theanets.trainer:168 RmsProp 164 loss=429.866058 err=14.927233
I 2015-05-27 02:17:38 theanets.trainer:168 RmsProp 165 loss=428.883698 err=15.064142
I 2015-05-27 02:17:46 theanets.trainer:168 RmsProp 166 loss=426.083984 err=13.319777
I 2015-05-27 02:17:55 theanets.trainer:168 RmsProp 167 loss=425.665955 err=13.953535
I 2015-05-27 02:18:03 theanets.trainer:168 RmsProp 168 loss=424.466370 err=13.848763
I 2015-05-27 02:18:10 theanets.trainer:168 RmsProp 169 loss=423.043274 err=13.519127
I 2015-05-27 02:18:19 theanets.trainer:168 RmsProp 170 loss=422.795258 err=14.357704
I 2015-05-27 02:18:19 theanets.trainer:168 validation 17 loss=1580.507324 err=1172.672729 *
I 2015-05-27 02:18:27 theanets.trainer:168 RmsProp 171 loss=421.820953 err=14.474902
I 2015-05-27 02:18:34 theanets.trainer:168 RmsProp 172 loss=419.969147 err=13.677350
I 2015-05-27 02:18:42 theanets.trainer:168 RmsProp 173 loss=419.198395 err=13.974467
I 2015-05-27 02:18:50 theanets.trainer:168 RmsProp 174 loss=417.560364 err=13.403020
I 2015-05-27 02:18:58 theanets.trainer:168 RmsProp 175 loss=416.725403 err=13.615542
I 2015-05-27 02:19:06 theanets.trainer:168 RmsProp 176 loss=416.157959 err=14.093997
I 2015-05-27 02:19:14 theanets.trainer:168 RmsProp 177 loss=414.728943 err=13.690022
I 2015-05-27 02:19:22 theanets.trainer:168 RmsProp 178 loss=413.279114 err=13.269182
I 2015-05-27 02:19:30 theanets.trainer:168 RmsProp 179 loss=412.033386 err=13.038737
I 2015-05-27 02:19:38 theanets.trainer:168 RmsProp 180 loss=411.826080 err=13.846930
I 2015-05-27 02:19:38 theanets.trainer:168 validation 18 loss=1556.167847 err=1158.733276 *
I 2015-05-27 02:19:46 theanets.trainer:168 RmsProp 181 loss=409.972656 err=12.990393
I 2015-05-27 02:19:54 theanets.trainer:168 RmsProp 182 loss=408.918152 err=12.906741
I 2015-05-27 02:20:01 theanets.trainer:168 RmsProp 183 loss=408.883118 err=13.879570
I 2015-05-27 02:20:10 theanets.trainer:168 RmsProp 184 loss=406.934235 err=12.919055
I 2015-05-27 02:20:18 theanets.trainer:168 RmsProp 185 loss=406.430603 err=13.399907
I 2015-05-27 02:20:26 theanets.trainer:168 RmsProp 186 loss=404.576843 err=12.520002
I 2015-05-27 02:20:34 theanets.trainer:168 RmsProp 187 loss=404.326172 err=13.242844
I 2015-05-27 02:20:43 theanets.trainer:168 RmsProp 188 loss=402.878357 err=12.786318
I 2015-05-27 02:20:50 theanets.trainer:168 RmsProp 189 loss=401.615448 err=12.498809
I 2015-05-27 02:20:58 theanets.trainer:168 RmsProp 190 loss=400.663513 err=12.528456
I 2015-05-27 02:20:59 theanets.trainer:168 validation 19 loss=1541.990723 err=1154.398682 *
I 2015-05-27 02:21:06 theanets.trainer:168 RmsProp 191 loss=399.275726 err=12.115934
I 2015-05-27 02:21:13 theanets.trainer:168 RmsProp 192 loss=398.832520 err=12.641470
I 2015-05-27 02:21:21 theanets.trainer:168 RmsProp 193 loss=397.612885 err=12.378165
I 2015-05-27 02:21:28 theanets.trainer:168 RmsProp 194 loss=396.230927 err=11.930985
I 2015-05-27 02:21:35 theanets.trainer:168 RmsProp 195 loss=396.504761 err=13.149584
I 2015-05-27 02:21:44 theanets.trainer:168 RmsProp 196 loss=394.772491 err=12.365630
I 2015-05-27 02:21:51 theanets.trainer:168 RmsProp 197 loss=393.834412 err=12.373877
I 2015-05-27 02:21:59 theanets.trainer:168 RmsProp 198 loss=392.775024 err=12.260418
I 2015-05-27 02:22:08 theanets.trainer:168 RmsProp 199 loss=391.699188 err=12.123528
I 2015-05-27 02:22:16 theanets.trainer:168 RmsProp 200 loss=390.660706 err=12.016515
I 2015-05-27 02:22:17 theanets.trainer:168 validation 20 loss=1519.593262 err=1141.449951 *
I 2015-05-27 02:22:24 theanets.trainer:168 RmsProp 201 loss=389.914734 err=12.181954
I 2015-05-27 02:22:32 theanets.trainer:168 RmsProp 202 loss=389.118683 err=12.284337
I 2015-05-27 02:22:40 theanets.trainer:168 RmsProp 203 loss=388.003448 err=12.065505
I 2015-05-27 02:22:48 theanets.trainer:168 RmsProp 204 loss=387.438080 err=12.386938
I 2015-05-27 02:22:56 theanets.trainer:168 RmsProp 205 loss=386.301453 err=12.118746
I 2015-05-27 02:23:04 theanets.trainer:168 RmsProp 206 loss=385.214996 err=11.896342
I 2015-05-27 02:23:11 theanets.trainer:168 RmsProp 207 loss=384.627869 err=12.192877
I 2015-05-27 02:23:20 theanets.trainer:168 RmsProp 208 loss=384.001862 err=12.436823
I 2015-05-27 02:23:27 theanets.trainer:168 RmsProp 209 loss=381.963989 err=11.282773
I 2015-05-27 02:23:35 theanets.trainer:168 RmsProp 210 loss=381.437103 err=11.633193
I 2015-05-27 02:23:36 theanets.trainer:168 validation 21 loss=1504.958740 err=1135.619995 *
I 2015-05-27 02:23:43 theanets.trainer:168 RmsProp 211 loss=381.215118 err=12.288149
I 2015-05-27 02:23:50 theanets.trainer:168 RmsProp 212 loss=379.899445 err=11.845878
I 2015-05-27 02:23:58 theanets.trainer:168 RmsProp 213 loss=379.111267 err=11.907736
I 2015-05-27 02:24:06 theanets.trainer:168 RmsProp 214 loss=377.703979 err=11.374152
I 2015-05-27 02:24:14 theanets.trainer:168 RmsProp 215 loss=376.757050 err=11.285614
I 2015-05-27 02:24:22 theanets.trainer:168 RmsProp 216 loss=376.230164 err=11.615854
I 2015-05-27 02:24:30 theanets.trainer:168 RmsProp 217 loss=375.218536 err=11.448094
I 2015-05-27 02:24:39 theanets.trainer:168 RmsProp 218 loss=374.787933 err=11.864366
I 2015-05-27 02:24:47 theanets.trainer:168 RmsProp 219 loss=373.395508 err=11.300247
I 2015-05-27 02:24:55 theanets.trainer:168 RmsProp 220 loss=372.745789 err=11.434851
I 2015-05-27 02:24:56 theanets.trainer:168 validation 22 loss=1481.618652 err=1120.740845 *
I 2015-05-27 02:25:03 theanets.trainer:168 RmsProp 221 loss=371.931396 err=11.406272
I 2015-05-27 02:25:10 theanets.trainer:168 RmsProp 222 loss=371.262665 err=11.513830
I 2015-05-27 02:25:16 theanets.trainer:168 RmsProp 223 loss=370.350433 err=11.390647
I 2015-05-27 02:25:24 theanets.trainer:168 RmsProp 224 loss=369.554993 err=11.390819
I 2015-05-27 02:25:30 theanets.trainer:168 RmsProp 225 loss=368.039307 err=10.672201
I 2015-05-27 02:25:36 theanets.trainer:168 RmsProp 226 loss=367.332581 err=10.755315
I 2015-05-27 02:25:43 theanets.trainer:168 RmsProp 227 loss=367.401672 err=11.611060
I 2015-05-27 02:25:49 theanets.trainer:168 RmsProp 228 loss=365.996368 err=10.990515
I 2015-05-27 02:25:56 theanets.trainer:168 RmsProp 229 loss=365.166107 err=10.936566
I 2015-05-27 02:26:03 theanets.trainer:168 RmsProp 230 loss=364.408234 err=10.969508
I 2015-05-27 02:26:03 theanets.trainer:168 validation 23 loss=1467.433716 err=1114.429688 *
I 2015-05-27 02:26:09 theanets.trainer:168 RmsProp 231 loss=363.712982 err=11.051713
I 2015-05-27 02:26:15 theanets.trainer:168 RmsProp 232 loss=362.391266 err=10.501671
I 2015-05-27 02:26:22 theanets.trainer:168 RmsProp 233 loss=362.105530 err=10.995512
I 2015-05-27 02:26:29 theanets.trainer:168 RmsProp 234 loss=361.775757 err=11.447268
I 2015-05-27 02:26:35 theanets.trainer:168 RmsProp 235 loss=361.302063 err=11.728548
I 2015-05-27 02:26:41 theanets.trainer:168 RmsProp 236 loss=359.387482 err=10.552701
I 2015-05-27 02:26:47 theanets.trainer:168 RmsProp 237 loss=358.838318 err=10.741334
I 2015-05-27 02:26:53 theanets.trainer:168 RmsProp 238 loss=358.415344 err=11.067606
I 2015-05-27 02:27:00 theanets.trainer:168 RmsProp 239 loss=357.214355 err=10.617597
I 2015-05-27 02:27:06 theanets.trainer:168 RmsProp 240 loss=357.228577 err=11.388039
I 2015-05-27 02:27:06 theanets.trainer:168 validation 24 loss=1445.012817 err=1099.569336 *
I 2015-05-27 02:27:13 theanets.trainer:168 RmsProp 241 loss=355.790588 err=10.684849
I 2015-05-27 02:27:19 theanets.trainer:168 RmsProp 242 loss=355.201508 err=10.819444
I 2015-05-27 02:27:26 theanets.trainer:168 RmsProp 243 loss=354.061584 err=10.403086
I 2015-05-27 02:27:32 theanets.trainer:168 RmsProp 244 loss=353.723297 err=10.782706
I 2015-05-27 02:27:39 theanets.trainer:168 RmsProp 245 loss=352.857361 err=10.631190
I 2015-05-27 02:27:45 theanets.trainer:168 RmsProp 246 loss=351.731232 err=10.218170
I 2015-05-27 02:27:52 theanets.trainer:168 RmsProp 247 loss=351.440491 err=10.650286
I 2015-05-27 02:27:58 theanets.trainer:168 RmsProp 248 loss=350.520142 err=10.448292
I 2015-05-27 02:28:04 theanets.trainer:168 RmsProp 249 loss=349.322357 err=9.963064
I 2015-05-27 02:28:11 theanets.trainer:168 RmsProp 250 loss=349.143250 err=10.485361
I 2015-05-27 02:28:11 theanets.trainer:168 validation 25 loss=1439.292725 err=1101.023071 *
I 2015-05-27 02:28:17 theanets.trainer:168 RmsProp 251 loss=348.529755 err=10.575288
I 2015-05-27 02:28:23 theanets.trainer:168 RmsProp 252 loss=347.212830 err=9.949052
I 2015-05-27 02:28:30 theanets.trainer:168 RmsProp 253 loss=346.422241 err=9.844928
I 2015-05-27 02:28:37 theanets.trainer:168 RmsProp 254 loss=346.039276 err=10.162911
I 2015-05-27 02:28:43 theanets.trainer:168 RmsProp 255 loss=345.795349 err=10.616891
I 2015-05-27 02:28:49 theanets.trainer:168 RmsProp 256 loss=344.506775 err=10.004395
I 2015-05-27 02:28:55 theanets.trainer:168 RmsProp 257 loss=343.607208 err=9.775436
I 2015-05-27 02:29:01 theanets.trainer:168 RmsProp 258 loss=343.140747 err=9.999071
I 2015-05-27 02:29:08 theanets.trainer:168 RmsProp 259 loss=342.548523 err=10.077584
I 2015-05-27 02:29:14 theanets.trainer:168 RmsProp 260 loss=342.285522 err=10.467744
I 2015-05-27 02:29:14 theanets.trainer:168 validation 26 loss=1424.385742 err=1092.927124 *
I 2015-05-27 02:29:20 theanets.trainer:168 RmsProp 261 loss=340.629822 err=9.470247
I 2015-05-27 02:29:26 theanets.trainer:168 RmsProp 262 loss=340.522461 err=10.030429
I 2015-05-27 02:29:32 theanets.trainer:168 RmsProp 263 loss=339.386475 err=9.555017
I 2015-05-27 02:29:38 theanets.trainer:168 RmsProp 264 loss=339.026123 err=9.843608
I 2015-05-27 02:29:43 theanets.trainer:168 RmsProp 265 loss=339.066925 err=10.539779
I 2015-05-27 02:29:49 theanets.trainer:168 RmsProp 266 loss=337.716339 err=9.832062
I 2015-05-27 02:29:56 theanets.trainer:168 RmsProp 267 loss=337.409363 err=10.165802
I 2015-05-27 02:30:02 theanets.trainer:168 RmsProp 268 loss=336.589264 err=9.986934
I 2015-05-27 02:30:08 theanets.trainer:168 RmsProp 269 loss=335.756073 err=9.793932
I 2015-05-27 02:30:14 theanets.trainer:168 RmsProp 270 loss=335.215057 err=9.902530
I 2015-05-27 02:30:15 theanets.trainer:168 validation 27 loss=1397.137695 err=1072.166504 *
I 2015-05-27 02:30:20 theanets.trainer:168 RmsProp 271 loss=334.416626 err=9.747074
I 2015-05-27 02:30:26 theanets.trainer:168 RmsProp 272 loss=334.080902 err=10.046799
I 2015-05-27 02:30:33 theanets.trainer:168 RmsProp 273 loss=332.965942 err=9.558138
I 2015-05-27 02:30:39 theanets.trainer:168 RmsProp 274 loss=332.497986 err=9.708793
I 2015-05-27 02:30:45 theanets.trainer:168 RmsProp 275 loss=331.664062 err=9.496174
I 2015-05-27 02:30:51 theanets.trainer:168 RmsProp 276 loss=331.199402 err=9.655733
I 2015-05-27 02:30:57 theanets.trainer:168 RmsProp 277 loss=330.699402 err=9.771035
I 2015-05-27 02:31:03 theanets.trainer:168 RmsProp 278 loss=330.214172 err=9.888976
I 2015-05-27 02:31:10 theanets.trainer:168 RmsProp 279 loss=329.016083 err=9.298562
I 2015-05-27 02:31:16 theanets.trainer:168 RmsProp 280 loss=328.844543 err=9.738971
I 2015-05-27 02:31:17 theanets.trainer:168 validation 28 loss=1396.486084 err=1077.706177 *
I 2015-05-27 02:31:23 theanets.trainer:168 RmsProp 281 loss=327.783325 err=9.284638
I 2015-05-27 02:31:30 theanets.trainer:168 RmsProp 282 loss=327.385223 err=9.497038
I 2015-05-27 02:31:36 theanets.trainer:168 RmsProp 283 loss=326.686768 err=9.398268
I 2015-05-27 02:31:41 theanets.trainer:168 RmsProp 284 loss=326.014893 err=9.328644
I 2015-05-27 02:31:47 theanets.trainer:168 RmsProp 285 loss=325.066284 err=8.978229
I 2015-05-27 02:31:53 theanets.trainer:168 RmsProp 286 loss=324.827545 err=9.341365
I 2015-05-27 02:31:59 theanets.trainer:168 RmsProp 287 loss=324.229675 err=9.337843
I 2015-05-27 02:32:05 theanets.trainer:168 RmsProp 288 loss=323.195312 err=8.898477
I 2015-05-27 02:32:11 theanets.trainer:168 RmsProp 289 loss=323.878723 err=10.172627
I 2015-05-27 02:32:17 theanets.trainer:168 RmsProp 290 loss=322.255920 err=9.126151
I 2015-05-27 02:32:18 theanets.trainer:168 validation 29 loss=1381.466309 err=1068.649536 *
I 2015-05-27 02:32:23 theanets.trainer:168 RmsProp 291 loss=321.622650 err=9.064182
I 2015-05-27 02:32:30 theanets.trainer:168 RmsProp 292 loss=321.263550 err=9.284703
I 2015-05-27 02:32:36 theanets.trainer:168 RmsProp 293 loss=320.614624 err=9.228740
I 2015-05-27 02:32:42 theanets.trainer:168 RmsProp 294 loss=319.544952 err=8.748155
I 2015-05-27 02:32:48 theanets.trainer:168 RmsProp 295 loss=319.115631 err=8.904900
I 2015-05-27 02:32:54 theanets.trainer:168 RmsProp 296 loss=318.770813 err=9.136696
I 2015-05-27 02:33:00 theanets.trainer:168 RmsProp 297 loss=318.593567 err=9.534387
I 2015-05-27 02:33:06 theanets.trainer:168 RmsProp 298 loss=317.804749 err=9.307813
I 2015-05-27 02:33:12 theanets.trainer:168 RmsProp 299 loss=316.830902 err=8.882743
I 2015-05-27 02:33:19 theanets.trainer:168 RmsProp 300 loss=316.162170 err=8.766135
I 2015-05-27 02:33:19 theanets.trainer:168 validation 30 loss=1367.261597 err=1060.163208 *
I 2015-05-27 02:33:26 theanets.trainer:168 RmsProp 301 loss=316.138611 err=9.298395
I 2015-05-27 02:33:32 theanets.trainer:168 RmsProp 302 loss=315.541687 err=9.246934
I 2015-05-27 02:33:38 theanets.trainer:168 RmsProp 303 loss=314.536835 err=8.787310
I 2015-05-27 02:33:44 theanets.trainer:168 RmsProp 304 loss=314.052032 err=8.848289
I 2015-05-27 02:33:50 theanets.trainer:168 RmsProp 305 loss=313.598938 err=8.944651
I 2015-05-27 02:33:56 theanets.trainer:168 RmsProp 306 loss=312.662659 err=8.551252
I 2015-05-27 02:34:03 theanets.trainer:168 RmsProp 307 loss=312.283234 err=8.717920
I 2015-05-27 02:34:09 theanets.trainer:168 RmsProp 308 loss=311.625732 err=8.611723
I 2015-05-27 02:34:15 theanets.trainer:168 RmsProp 309 loss=311.688873 err=9.211963
I 2015-05-27 02:34:21 theanets.trainer:168 RmsProp 310 loss=310.639374 err=8.696012
I 2015-05-27 02:34:21 theanets.trainer:168 validation 31 loss=1360.854492 err=1059.200562 *
I 2015-05-27 02:34:28 theanets.trainer:168 RmsProp 311 loss=310.115662 err=8.705337
I 2015-05-27 02:34:34 theanets.trainer:168 RmsProp 312 loss=309.452667 err=8.580486
I 2015-05-27 02:34:41 theanets.trainer:168 RmsProp 313 loss=308.708069 err=8.369354
I 2015-05-27 02:34:47 theanets.trainer:168 RmsProp 314 loss=308.313782 err=8.507242
I 2015-05-27 02:34:53 theanets.trainer:168 RmsProp 315 loss=307.787170 err=8.513907
I 2015-05-27 02:35:00 theanets.trainer:168 RmsProp 316 loss=307.482727 err=8.743204
I 2015-05-27 02:35:07 theanets.trainer:168 RmsProp 317 loss=306.651794 err=8.445564
I 2015-05-27 02:35:13 theanets.trainer:168 RmsProp 318 loss=306.433380 err=8.743683
I 2015-05-27 02:35:20 theanets.trainer:168 RmsProp 319 loss=305.692200 err=8.516440
I 2015-05-27 02:35:26 theanets.trainer:168 RmsProp 320 loss=305.195526 err=8.528365
I 2015-05-27 02:35:26 theanets.trainer:168 validation 32 loss=1356.941772 err=1060.548096 *
I 2015-05-27 02:35:32 theanets.trainer:168 RmsProp 321 loss=304.794250 err=8.633910
I 2015-05-27 02:35:39 theanets.trainer:168 RmsProp 322 loss=304.307251 err=8.647702
I 2015-05-27 02:35:45 theanets.trainer:168 RmsProp 323 loss=303.431213 err=8.274009
I 2015-05-27 02:35:51 theanets.trainer:168 RmsProp 324 loss=303.326691 err=8.681564
I 2015-05-27 02:35:57 theanets.trainer:168 RmsProp 325 loss=302.433258 err=8.299338
I 2015-05-27 02:36:04 theanets.trainer:168 RmsProp 326 loss=301.839752 err=8.221067
I 2015-05-27 02:36:10 theanets.trainer:168 RmsProp 327 loss=301.533844 err=8.415098
I 2015-05-27 02:36:15 theanets.trainer:168 RmsProp 328 loss=301.023376 err=8.396601
I 2015-05-27 02:36:21 theanets.trainer:168 RmsProp 329 loss=300.880035 err=8.741287
I 2015-05-27 02:36:28 theanets.trainer:168 RmsProp 330 loss=299.992126 err=8.344961
I 2015-05-27 02:36:29 theanets.trainer:168 validation 33 loss=1342.552856 err=1051.176758 *
I 2015-05-27 02:36:35 theanets.trainer:168 RmsProp 331 loss=299.924469 err=8.775045
I 2015-05-27 02:36:41 theanets.trainer:168 RmsProp 332 loss=298.932465 err=8.276066
I 2015-05-27 02:36:48 theanets.trainer:168 RmsProp 333 loss=298.417572 err=8.254604
I 2015-05-27 02:36:54 theanets.trainer:168 RmsProp 334 loss=297.880310 err=8.203085
I 2015-05-27 02:37:00 theanets.trainer:168 RmsProp 335 loss=297.709656 err=8.528532
I 2015-05-27 02:37:07 theanets.trainer:168 RmsProp 336 loss=297.740265 err=9.033450
I 2015-05-27 02:37:12 theanets.trainer:168 RmsProp 337 loss=296.664825 err=8.412317
I 2015-05-27 02:37:18 theanets.trainer:168 RmsProp 338 loss=295.729553 err=7.929774
I 2015-05-27 02:37:25 theanets.trainer:168 RmsProp 339 loss=295.266632 err=7.923805
I 2015-05-27 02:37:32 theanets.trainer:168 RmsProp 340 loss=294.982025 err=8.106005
I 2015-05-27 02:37:32 theanets.trainer:168 validation 34 loss=1332.392578 err=1045.771484 *
I 2015-05-27 02:37:38 theanets.trainer:168 RmsProp 341 loss=294.468506 err=8.056124
I 2015-05-27 02:37:44 theanets.trainer:168 RmsProp 342 loss=293.925842 err=7.985480
I 2015-05-27 02:37:50 theanets.trainer:168 RmsProp 343 loss=293.490784 err=8.023568
I 2015-05-27 02:37:56 theanets.trainer:168 RmsProp 344 loss=293.417511 err=8.427788
I 2015-05-27 02:38:02 theanets.trainer:168 RmsProp 345 loss=292.756744 err=8.237962
I 2015-05-27 02:38:09 theanets.trainer:168 RmsProp 346 loss=291.948944 err=7.883593
I 2015-05-27 02:38:15 theanets.trainer:168 RmsProp 347 loss=291.714172 err=8.108310
I 2015-05-27 02:38:21 theanets.trainer:168 RmsProp 348 loss=291.552368 err=8.398558
I 2015-05-27 02:38:27 theanets.trainer:168 RmsProp 349 loss=290.281738 err=7.587512
I 2015-05-27 02:38:33 theanets.trainer:168 RmsProp 350 loss=290.522888 err=8.280978
I 2015-05-27 02:38:33 theanets.trainer:168 validation 35 loss=1321.188843 err=1039.193848 *
I 2015-05-27 02:38:39 theanets.trainer:168 RmsProp 351 loss=290.027283 err=8.238351
I 2015-05-27 02:38:45 theanets.trainer:168 RmsProp 352 loss=289.175476 err=7.830154
I 2015-05-27 02:38:51 theanets.trainer:168 RmsProp 353 loss=288.819031 err=7.920596
I 2015-05-27 02:38:57 theanets.trainer:168 RmsProp 354 loss=288.561035 err=8.117699
I 2015-05-27 02:39:04 theanets.trainer:168 RmsProp 355 loss=287.923920 err=7.921794
I 2015-05-27 02:39:10 theanets.trainer:168 RmsProp 356 loss=287.522369 err=7.963833
I 2015-05-27 02:39:16 theanets.trainer:168 RmsProp 357 loss=287.262787 err=8.143553
I 2015-05-27 02:39:22 theanets.trainer:168 RmsProp 358 loss=285.954651 err=7.271753
I 2015-05-27 02:39:28 theanets.trainer:168 RmsProp 359 loss=286.147461 err=7.899653
I 2015-05-27 02:39:34 theanets.trainer:168 RmsProp 360 loss=285.958069 err=8.148951
I 2015-05-27 02:39:34 theanets.trainer:168 validation 36 loss=1314.631958 err=1037.054688 *
I 2015-05-27 02:39:40 theanets.trainer:168 RmsProp 361 loss=285.591125 err=8.216692
I 2015-05-27 02:39:46 theanets.trainer:168 RmsProp 362 loss=284.985260 err=8.043418
I 2015-05-27 02:39:52 theanets.trainer:168 RmsProp 363 loss=284.180542 err=7.678133
I 2015-05-27 02:39:59 theanets.trainer:168 RmsProp 364 loss=283.840240 err=7.771289
I 2015-05-27 02:40:05 theanets.trainer:168 RmsProp 365 loss=283.442139 err=7.810098
I 2015-05-27 02:40:11 theanets.trainer:168 RmsProp 366 loss=283.237488 err=8.038476
I 2015-05-27 02:40:17 theanets.trainer:168 RmsProp 367 loss=282.370300 err=7.601022
I 2015-05-27 02:40:23 theanets.trainer:168 RmsProp 368 loss=281.816589 err=7.468398
I 2015-05-27 02:40:30 theanets.trainer:168 RmsProp 369 loss=281.836731 err=7.906439
I 2015-05-27 02:40:36 theanets.trainer:168 RmsProp 370 loss=281.606140 err=8.095727
I 2015-05-27 02:40:36 theanets.trainer:168 validation 37 loss=1311.238770 err=1037.959351 *
I 2015-05-27 02:40:43 theanets.trainer:168 RmsProp 371 loss=280.879974 err=7.777215
I 2015-05-27 02:40:49 theanets.trainer:168 RmsProp 372 loss=279.877747 err=7.183291
I 2015-05-27 02:40:55 theanets.trainer:168 RmsProp 373 loss=279.954468 err=7.677706
I 2015-05-27 02:41:01 theanets.trainer:168 RmsProp 374 loss=279.825745 err=7.960795
I 2015-05-27 02:41:07 theanets.trainer:168 RmsProp 375 loss=278.936218 err=7.486547
I 2015-05-27 02:41:14 theanets.trainer:168 RmsProp 376 loss=278.710999 err=7.657281
I 2015-05-27 02:41:20 theanets.trainer:168 RmsProp 377 loss=278.074707 err=7.428022
I 2015-05-27 02:41:26 theanets.trainer:168 RmsProp 378 loss=278.011108 err=7.782548
I 2015-05-27 02:41:32 theanets.trainer:168 RmsProp 379 loss=277.524506 err=7.707149
I 2015-05-27 02:41:39 theanets.trainer:168 RmsProp 380 loss=277.063568 err=7.653886
I 2015-05-27 02:41:39 theanets.trainer:168 validation 38 loss=1306.537964 err=1037.339722 *
I 2015-05-27 02:41:45 theanets.trainer:168 RmsProp 381 loss=276.352722 err=7.343451
I 2015-05-27 02:41:51 theanets.trainer:168 RmsProp 382 loss=276.349792 err=7.745785
I 2015-05-27 02:41:57 theanets.trainer:168 RmsProp 383 loss=275.846588 err=7.636022
I 2015-05-27 02:42:03 theanets.trainer:168 RmsProp 384 loss=275.032104 err=7.216824
I 2015-05-27 02:42:09 theanets.trainer:168 RmsProp 385 loss=274.989716 err=7.564443
I 2015-05-27 02:42:15 theanets.trainer:168 RmsProp 386 loss=274.287170 err=7.255299
I 2015-05-27 02:42:21 theanets.trainer:168 RmsProp 387 loss=274.444153 err=7.808286
I 2015-05-27 02:42:27 theanets.trainer:168 RmsProp 388 loss=273.354095 err=7.104079
I 2015-05-27 02:42:33 theanets.trainer:168 RmsProp 389 loss=273.328857 err=7.469492
I 2015-05-27 02:42:40 theanets.trainer:168 RmsProp 390 loss=272.426453 err=6.955035
I 2015-05-27 02:42:41 theanets.trainer:168 validation 39 loss=1291.582764 err=1026.313721 *
I 2015-05-27 02:42:46 theanets.trainer:168 RmsProp 391 loss=272.508972 err=7.428276
I 2015-05-27 02:42:53 theanets.trainer:168 RmsProp 392 loss=271.945374 err=7.252431
I 2015-05-27 02:42:59 theanets.trainer:168 RmsProp 393 loss=271.907776 err=7.609605
I 2015-05-27 02:43:05 theanets.trainer:168 RmsProp 394 loss=271.686005 err=7.774740
I 2015-05-27 02:43:11 theanets.trainer:168 RmsProp 395 loss=271.216644 err=7.686648
I 2015-05-27 02:43:17 theanets.trainer:168 RmsProp 396 loss=269.955627 err=6.815868
I 2015-05-27 02:43:23 theanets.trainer:168 RmsProp 397 loss=270.164795 err=7.398622
I 2015-05-27 02:43:29 theanets.trainer:168 RmsProp 398 loss=269.676086 err=7.291060
I 2015-05-27 02:43:36 theanets.trainer:168 RmsProp 399 loss=269.238831 err=7.227572
I 2015-05-27 02:43:42 theanets.trainer:168 RmsProp 400 loss=268.810303 err=7.175341
I 2015-05-27 02:43:42 theanets.trainer:168 validation 40 loss=1288.854370 err=1027.431519 *
I 2015-05-27 02:43:48 theanets.trainer:168 RmsProp 401 loss=268.561371 err=7.298814
I 2015-05-27 02:43:55 theanets.trainer:168 RmsProp 402 loss=267.914246 err=7.017203
I 2015-05-27 02:44:01 theanets.trainer:168 RmsProp 403 loss=267.960571 err=7.432532
I 2015-05-27 02:44:07 theanets.trainer:168 RmsProp 404 loss=267.729370 err=7.568002
I 2015-05-27 02:44:13 theanets.trainer:168 RmsProp 405 loss=267.056793 err=7.261862
I 2015-05-27 02:44:20 theanets.trainer:168 RmsProp 406 loss=266.590271 err=7.157464
I 2015-05-27 02:44:26 theanets.trainer:168 RmsProp 407 loss=266.152985 err=7.083549
I 2015-05-27 02:44:32 theanets.trainer:168 RmsProp 408 loss=265.709167 err=7.007761
I 2015-05-27 02:44:38 theanets.trainer:168 RmsProp 409 loss=265.324524 err=6.990592
I 2015-05-27 02:44:45 theanets.trainer:168 RmsProp 410 loss=265.495941 err=7.528220
I 2015-05-27 02:44:45 theanets.trainer:168 validation 41 loss=1280.113403 err=1022.334961 *
I 2015-05-27 02:44:51 theanets.trainer:168 RmsProp 411 loss=264.741364 err=7.135264
I 2015-05-27 02:44:58 theanets.trainer:168 RmsProp 412 loss=264.288879 err=7.048515
I 2015-05-27 02:45:05 theanets.trainer:168 RmsProp 413 loss=264.136536 err=7.257478
I 2015-05-27 02:45:11 theanets.trainer:168 RmsProp 414 loss=263.072571 err=6.560462
I 2015-05-27 02:45:17 theanets.trainer:168 RmsProp 415 loss=263.285492 err=7.135726
I 2015-05-27 02:45:23 theanets.trainer:168 RmsProp 416 loss=262.597961 err=6.804967
I 2015-05-27 02:45:29 theanets.trainer:168 RmsProp 417 loss=262.766357 err=7.338258
I 2015-05-27 02:45:36 theanets.trainer:168 RmsProp 418 loss=261.954559 err=6.887515
I 2015-05-27 02:45:42 theanets.trainer:168 RmsProp 419 loss=261.761200 err=7.054921
I 2015-05-27 02:45:48 theanets.trainer:168 RmsProp 420 loss=261.061371 err=6.707923
I 2015-05-27 02:45:49 theanets.trainer:168 validation 42 loss=1272.309204 err=1018.128113 *
I 2015-05-27 02:45:54 theanets.trainer:168 RmsProp 421 loss=260.910583 err=6.908168
I 2015-05-27 02:46:00 theanets.trainer:168 RmsProp 422 loss=260.799652 err=7.154716
I 2015-05-27 02:46:06 theanets.trainer:168 RmsProp 423 loss=260.604645 err=7.304090
I 2015-05-27 02:46:13 theanets.trainer:168 RmsProp 424 loss=259.835205 err=6.877587
I 2015-05-27 02:46:18 theanets.trainer:168 RmsProp 425 loss=259.478027 err=6.859174
I 2015-05-27 02:46:25 theanets.trainer:168 RmsProp 426 loss=259.177460 err=6.900819
I 2015-05-27 02:46:32 theanets.trainer:168 RmsProp 427 loss=258.986664 err=7.043290
I 2015-05-27 02:46:39 theanets.trainer:168 RmsProp 428 loss=258.785553 err=7.176677
I 2015-05-27 02:46:46 theanets.trainer:168 RmsProp 429 loss=258.150696 err=6.880543
I 2015-05-27 02:46:52 theanets.trainer:168 RmsProp 430 loss=257.898102 err=6.959525
I 2015-05-27 02:46:53 theanets.trainer:168 validation 43 loss=1277.993774 err=1027.244507
I 2015-05-27 02:46:59 theanets.trainer:168 RmsProp 431 loss=257.550995 err=6.953433
I 2015-05-27 02:47:04 theanets.trainer:168 RmsProp 432 loss=257.327332 err=7.060863
I 2015-05-27 02:47:11 theanets.trainer:168 RmsProp 433 loss=256.772186 err=6.834246
I 2015-05-27 02:47:18 theanets.trainer:168 RmsProp 434 loss=256.498962 err=6.879036
I 2015-05-27 02:47:24 theanets.trainer:168 RmsProp 435 loss=256.496521 err=7.202856
I 2015-05-27 02:47:30 theanets.trainer:168 RmsProp 436 loss=255.097046 err=6.131446
I 2015-05-27 02:47:37 theanets.trainer:168 RmsProp 437 loss=255.646484 err=7.002791
I 2015-05-27 02:47:43 theanets.trainer:168 RmsProp 438 loss=255.270462 err=6.953539
I 2015-05-27 02:47:49 theanets.trainer:168 RmsProp 439 loss=254.819870 err=6.821135
I 2015-05-27 02:47:55 theanets.trainer:168 RmsProp 440 loss=254.590012 err=6.906375
I 2015-05-27 02:47:55 theanets.trainer:168 validation 44 loss=1277.800781 err=1030.281616
I 2015-05-27 02:48:02 theanets.trainer:168 RmsProp 441 loss=254.008011 err=6.631057
I 2015-05-27 02:48:08 theanets.trainer:168 RmsProp 442 loss=253.952026 err=6.882389
I 2015-05-27 02:48:14 theanets.trainer:168 RmsProp 443 loss=253.361618 err=6.600217
I 2015-05-27 02:48:20 theanets.trainer:168 RmsProp 444 loss=253.168777 err=6.715973
I 2015-05-27 02:48:26 theanets.trainer:168 RmsProp 445 loss=252.849243 err=6.706424
I 2015-05-27 02:48:32 theanets.trainer:168 RmsProp 446 loss=252.435867 err=6.606256
I 2015-05-27 02:48:39 theanets.trainer:168 RmsProp 447 loss=252.407639 err=6.892698
I 2015-05-27 02:48:45 theanets.trainer:168 RmsProp 448 loss=252.027634 err=6.826037
I 2015-05-27 02:48:51 theanets.trainer:168 RmsProp 449 loss=251.568405 err=6.680557
I 2015-05-27 02:48:57 theanets.trainer:168 RmsProp 450 loss=251.747833 err=7.174376
I 2015-05-27 02:48:58 theanets.trainer:168 validation 45 loss=1272.995361 err=1028.568604
I 2015-05-27 02:49:04 theanets.trainer:168 RmsProp 451 loss=251.081085 err=6.813297
I 2015-05-27 02:49:10 theanets.trainer:168 RmsProp 452 loss=250.503265 err=6.543138
I 2015-05-27 02:49:16 theanets.trainer:168 RmsProp 453 loss=250.388580 err=6.733373
I 2015-05-27 02:49:22 theanets.trainer:168 RmsProp 454 loss=250.308060 err=6.957062
I 2015-05-27 02:49:28 theanets.trainer:168 RmsProp 455 loss=249.317062 err=6.268509
I 2015-05-27 02:49:34 theanets.trainer:168 RmsProp 456 loss=249.479660 err=6.739899
I 2015-05-27 02:49:40 theanets.trainer:168 RmsProp 457 loss=249.049530 err=6.619210
I 2015-05-27 02:49:46 theanets.trainer:168 RmsProp 458 loss=248.670578 err=6.542079
I 2015-05-27 02:49:52 theanets.trainer:168 RmsProp 459 loss=248.438553 err=6.619703
I 2015-05-27 02:49:58 theanets.trainer:168 RmsProp 460 loss=248.097076 err=6.574468
I 2015-05-27 02:49:59 theanets.trainer:168 validation 46 loss=1272.495239 err=1031.133789
I 2015-05-27 02:50:04 theanets.trainer:168 RmsProp 461 loss=247.832245 err=6.614585
I 2015-05-27 02:50:11 theanets.trainer:168 RmsProp 462 loss=247.528763 err=6.616740
I 2015-05-27 02:50:18 theanets.trainer:168 RmsProp 463 loss=247.551605 err=6.939435
I 2015-05-27 02:50:25 theanets.trainer:168 RmsProp 464 loss=247.129242 err=6.816028
I 2015-05-27 02:50:31 theanets.trainer:168 RmsProp 465 loss=247.014313 err=6.994463
I 2015-05-27 02:50:37 theanets.trainer:168 RmsProp 466 loss=245.752151 err=6.030982
I 2015-05-27 02:50:43 theanets.trainer:168 RmsProp 467 loss=246.136185 err=6.707452
I 2015-05-27 02:50:49 theanets.trainer:168 RmsProp 468 loss=245.829193 err=6.695043
I 2015-05-27 02:50:56 theanets.trainer:168 RmsProp 469 loss=245.279007 err=6.434893
I 2015-05-27 02:51:01 theanets.trainer:168 RmsProp 470 loss=245.172852 err=6.630311
I 2015-05-27 02:51:02 theanets.trainer:168 validation 47 loss=1262.218872 err=1023.845886 *
I 2015-05-27 02:51:08 theanets.trainer:168 RmsProp 471 loss=244.990265 err=6.742433
I 2015-05-27 02:51:15 theanets.trainer:168 RmsProp 472 loss=244.398315 err=6.433578
I 2015-05-27 02:51:21 theanets.trainer:168 RmsProp 473 loss=244.333450 err=6.660944
I 2015-05-27 02:51:27 theanets.trainer:168 RmsProp 474 loss=244.031540 err=6.646567
I 2015-05-27 02:51:33 theanets.trainer:168 RmsProp 475 loss=243.787079 err=6.691680
I 2015-05-27 02:51:40 theanets.trainer:168 RmsProp 476 loss=243.140701 err=6.327250
I 2015-05-27 02:51:46 theanets.trainer:168 RmsProp 477 loss=243.059296 err=6.527146
I 2015-05-27 02:51:52 theanets.trainer:168 RmsProp 478 loss=242.715866 err=6.460018
I 2015-05-27 02:51:58 theanets.trainer:168 RmsProp 479 loss=242.328094 err=6.352920
I 2015-05-27 02:52:04 theanets.trainer:168 RmsProp 480 loss=242.242966 err=6.549258
I 2015-05-27 02:52:05 theanets.trainer:168 validation 48 loss=1265.137329 err=1029.585327
I 2015-05-27 02:52:11 theanets.trainer:168 RmsProp 481 loss=241.788864 err=6.371449
I 2015-05-27 02:52:17 theanets.trainer:168 RmsProp 482 loss=241.729767 err=6.589911
I 2015-05-27 02:52:23 theanets.trainer:168 RmsProp 483 loss=241.510529 err=6.642995
I 2015-05-27 02:52:29 theanets.trainer:168 RmsProp 484 loss=240.813354 err=6.221675
I 2015-05-27 02:52:35 theanets.trainer:168 RmsProp 485 loss=240.751129 err=6.435119
I 2015-05-27 02:52:41 theanets.trainer:168 RmsProp 486 loss=240.239868 err=6.200951
I 2015-05-27 02:52:47 theanets.trainer:168 RmsProp 487 loss=240.285568 err=6.519911
I 2015-05-27 02:52:54 theanets.trainer:168 RmsProp 488 loss=239.818695 err=6.324813
I 2015-05-27 02:53:01 theanets.trainer:168 RmsProp 489 loss=239.445877 err=6.230116
I 2015-05-27 02:53:07 theanets.trainer:168 RmsProp 490 loss=239.187775 err=6.244571
I 2015-05-27 02:53:07 theanets.trainer:168 validation 49 loss=1257.525269 err=1024.729980 *
I 2015-05-27 02:53:14 theanets.trainer:168 RmsProp 491 loss=239.157196 err=6.488229
I 2015-05-27 02:53:20 theanets.trainer:168 RmsProp 492 loss=238.816971 err=6.420777
I 2015-05-27 02:53:26 theanets.trainer:168 RmsProp 493 loss=238.550140 err=6.429583
I 2015-05-27 02:53:32 theanets.trainer:168 RmsProp 494 loss=237.820969 err=5.981296
I 2015-05-27 02:53:38 theanets.trainer:168 RmsProp 495 loss=238.034760 err=6.462953
I 2015-05-27 02:53:45 theanets.trainer:168 RmsProp 496 loss=237.574295 err=6.272944
I 2015-05-27 02:53:51 theanets.trainer:168 RmsProp 497 loss=237.739090 err=6.703981
I 2015-05-27 02:53:57 theanets.trainer:168 RmsProp 498 loss=237.126877 err=6.362938
I 2015-05-27 02:54:04 theanets.trainer:168 RmsProp 499 loss=236.972412 err=6.474949
I 2015-05-27 02:54:10 theanets.trainer:168 RmsProp 500 loss=236.327667 err=6.091491
I 2015-05-27 02:54:10 theanets.trainer:168 validation 50 loss=1257.463135 err=1027.370361 *
I 2015-05-27 02:54:16 theanets.trainer:168 RmsProp 501 loss=236.155548 err=6.180759
I 2015-05-27 02:54:22 theanets.trainer:168 RmsProp 502 loss=235.661331 err=5.950457
I 2015-05-27 02:54:29 theanets.trainer:168 RmsProp 503 loss=235.422119 err=5.979986
I 2015-05-27 02:54:35 theanets.trainer:168 RmsProp 504 loss=235.517792 err=6.341139
I 2015-05-27 02:54:41 theanets.trainer:168 RmsProp 505 loss=235.148880 err=6.236380
I 2015-05-27 02:54:48 theanets.trainer:168 RmsProp 506 loss=234.497528 err=5.849573
I 2015-05-27 02:54:54 theanets.trainer:168 RmsProp 507 loss=234.746185 err=6.352861
I 2015-05-27 02:55:00 theanets.trainer:168 RmsProp 508 loss=233.870697 err=5.740679
I 2015-05-27 02:55:07 theanets.trainer:168 RmsProp 509 loss=234.059845 err=6.177880
I 2015-05-27 02:55:13 theanets.trainer:168 RmsProp 510 loss=233.903809 err=6.280284
I 2015-05-27 02:55:14 theanets.trainer:168 validation 51 loss=1256.750610 err=1029.255005 *
I 2015-05-27 02:55:20 theanets.trainer:168 RmsProp 511 loss=233.147827 err=5.778368
I 2015-05-27 02:55:26 theanets.trainer:168 RmsProp 512 loss=233.552902 err=6.438949
I 2015-05-27 02:55:32 theanets.trainer:168 RmsProp 513 loss=232.933136 err=6.075262
I 2015-05-27 02:55:38 theanets.trainer:168 RmsProp 514 loss=232.687469 err=6.083881
I 2015-05-27 02:55:45 theanets.trainer:168 RmsProp 515 loss=232.708374 err=6.365677
I 2015-05-27 02:55:51 theanets.trainer:168 RmsProp 516 loss=232.275391 err=6.182038
I 2015-05-27 02:55:57 theanets.trainer:168 RmsProp 517 loss=232.008514 err=6.166100
I 2015-05-27 02:56:03 theanets.trainer:168 RmsProp 518 loss=231.646088 err=6.049161
I 2015-05-27 02:56:10 theanets.trainer:168 RmsProp 519 loss=231.535522 err=6.189447
I 2015-05-27 02:56:16 theanets.trainer:168 RmsProp 520 loss=230.924973 err=5.827605
I 2015-05-27 02:56:17 theanets.trainer:168 validation 52 loss=1259.456055 err=1034.490601
I 2015-05-27 02:56:23 theanets.trainer:168 RmsProp 521 loss=231.375275 err=6.519355
I 2015-05-27 02:56:30 theanets.trainer:168 RmsProp 522 loss=230.730392 err=6.123110
I 2015-05-27 02:56:37 theanets.trainer:168 RmsProp 523 loss=230.561935 err=6.198129
I 2015-05-27 02:56:43 theanets.trainer:168 RmsProp 524 loss=229.990570 err=5.872128
I 2015-05-27 02:56:49 theanets.trainer:168 RmsProp 525 loss=229.854004 err=5.979882
I 2015-05-27 02:56:55 theanets.trainer:168 RmsProp 526 loss=229.724152 err=6.095511
I 2015-05-27 02:57:02 theanets.trainer:168 RmsProp 527 loss=229.680222 err=6.290374
I 2015-05-27 02:57:08 theanets.trainer:168 RmsProp 528 loss=229.021851 err=5.875404
I 2015-05-27 02:57:15 theanets.trainer:168 RmsProp 529 loss=228.809158 err=5.905114
I 2015-05-27 02:57:22 theanets.trainer:168 RmsProp 530 loss=228.567215 err=5.905515
I 2015-05-27 02:57:22 theanets.trainer:168 validation 53 loss=1263.580322 err=1041.046265
I 2015-05-27 02:57:28 theanets.trainer:168 RmsProp 531 loss=228.335663 err=5.923277
I 2015-05-27 02:57:34 theanets.trainer:168 RmsProp 532 loss=228.051682 err=5.882144
I 2015-05-27 02:57:40 theanets.trainer:168 RmsProp 533 loss=228.227875 err=6.299028
I 2015-05-27 02:57:47 theanets.trainer:168 RmsProp 534 loss=227.476837 err=5.790672
I 2015-05-27 02:57:53 theanets.trainer:168 RmsProp 535 loss=227.400711 err=5.953979
I 2015-05-27 02:57:59 theanets.trainer:168 RmsProp 536 loss=227.367218 err=6.160792
I 2015-05-27 02:58:06 theanets.trainer:168 RmsProp 537 loss=226.862595 err=5.894223
I 2015-05-27 02:58:12 theanets.trainer:168 RmsProp 538 loss=226.725128 err=5.994204
I 2015-05-27 02:58:18 theanets.trainer:168 RmsProp 539 loss=226.476074 err=5.980700
I 2015-05-27 02:58:25 theanets.trainer:168 RmsProp 540 loss=226.100067 err=5.837749
I 2015-05-27 02:58:25 theanets.trainer:168 validation 54 loss=1262.965088 err=1042.822388
I 2015-05-27 02:58:32 theanets.trainer:168 RmsProp 541 loss=226.083542 err=6.050035
I 2015-05-27 02:58:38 theanets.trainer:168 RmsProp 542 loss=225.510376 err=5.707927
I 2015-05-27 02:58:44 theanets.trainer:168 RmsProp 543 loss=225.843292 err=6.270885
I 2015-05-27 02:58:51 theanets.trainer:168 RmsProp 544 loss=224.838577 err=5.494597
I 2015-05-27 02:58:57 theanets.trainer:168 RmsProp 545 loss=225.255829 err=6.138797
I 2015-05-27 02:59:04 theanets.trainer:168 RmsProp 546 loss=224.458282 err=5.569043
I 2015-05-27 02:59:10 theanets.trainer:168 RmsProp 547 loss=224.718964 err=6.061199
I 2015-05-27 02:59:16 theanets.trainer:168 RmsProp 548 loss=224.479706 err=6.056188
I 2015-05-27 02:59:22 theanets.trainer:168 RmsProp 549 loss=223.634613 err=5.445128
I 2015-05-27 02:59:29 theanets.trainer:168 RmsProp 550 loss=224.173172 err=6.207966
I 2015-05-27 02:59:29 theanets.trainer:168 validation 55 loss=1270.661987 err=1052.817993
I 2015-05-27 02:59:36 theanets.trainer:168 RmsProp 551 loss=223.561981 err=5.825475
I 2015-05-27 02:59:42 theanets.trainer:168 RmsProp 552 loss=223.457809 err=5.948777
I 2015-05-27 02:59:48 theanets.trainer:168 RmsProp 553 loss=223.418213 err=6.134406
I 2015-05-27 02:59:54 theanets.trainer:168 RmsProp 554 loss=222.705811 err=5.651088
I 2015-05-27 03:00:01 theanets.trainer:168 RmsProp 555 loss=222.362259 err=5.533497
I 2015-05-27 03:00:07 theanets.trainer:168 RmsProp 556 loss=222.364914 err=5.755544
I 2015-05-27 03:00:13 theanets.trainer:168 RmsProp 557 loss=222.427200 err=6.042816
I 2015-05-27 03:00:20 theanets.trainer:168 RmsProp 558 loss=222.144318 err=5.983610
I 2015-05-27 03:00:26 theanets.trainer:168 RmsProp 559 loss=221.644852 err=5.710063
I 2015-05-27 03:00:32 theanets.trainer:168 RmsProp 560 loss=222.175385 err=6.464810
I 2015-05-27 03:00:33 theanets.trainer:168 validation 56 loss=1265.844360 err=1050.243774
I 2015-05-27 03:00:33 theanets.trainer:252 patience elapsed!
I 2015-05-27 03:00:33 theanets.main:237 models_deep_post_code_sep/95128-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 03:00:33 theanets.graph:477 models_deep_post_code_sep/95128-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
