I 2015-05-26 22:05:11 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:11 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95112-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:11 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:11 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:11 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:11 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:11 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:11 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:11 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:11 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:11 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:11 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:11 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:12 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:30 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:13 theanets.trainer:168 validation 0 loss=14399.372070 err=14157.083008 *
I 2015-05-26 22:08:44 theanets.trainer:168 RmsProp 1 loss=13330.146484 err=13235.520508
I 2015-05-26 22:09:19 theanets.trainer:168 RmsProp 2 loss=13214.315430 err=13194.315430
I 2015-05-26 22:09:57 theanets.trainer:168 RmsProp 3 loss=13194.873047 err=13180.861328
I 2015-05-26 22:10:33 theanets.trainer:168 RmsProp 4 loss=12867.237305 err=12836.306641
I 2015-05-26 22:11:10 theanets.trainer:168 RmsProp 5 loss=11865.810547 err=11808.161133
I 2015-05-26 22:11:47 theanets.trainer:168 RmsProp 6 loss=11132.797852 err=11063.470703
I 2015-05-26 22:12:24 theanets.trainer:168 RmsProp 7 loss=10320.505859 err=10232.673828
I 2015-05-26 22:13:00 theanets.trainer:168 RmsProp 8 loss=9779.686523 err=9668.515625
I 2015-05-26 22:13:37 theanets.trainer:168 RmsProp 9 loss=9246.234375 err=9108.105469
I 2015-05-26 22:14:15 theanets.trainer:168 RmsProp 10 loss=8769.696289 err=8613.477539
I 2015-05-26 22:14:16 theanets.trainer:168 validation 1 loss=8530.691406 err=8365.846680 *
I 2015-05-26 22:14:53 theanets.trainer:168 RmsProp 11 loss=8467.416992 err=8292.300781
I 2015-05-26 22:15:30 theanets.trainer:168 RmsProp 12 loss=8046.606445 err=7847.778809
I 2015-05-26 22:16:09 theanets.trainer:168 RmsProp 13 loss=7394.950195 err=7175.279297
I 2015-05-26 22:16:46 theanets.trainer:168 RmsProp 14 loss=6698.817871 err=6458.042480
I 2015-05-26 22:17:24 theanets.trainer:168 RmsProp 15 loss=6340.511230 err=6081.001465
I 2015-05-26 22:18:01 theanets.trainer:168 RmsProp 16 loss=6127.438965 err=5849.806152
I 2015-05-26 22:18:37 theanets.trainer:168 RmsProp 17 loss=5998.759766 err=5705.655762
I 2015-05-26 22:19:14 theanets.trainer:168 RmsProp 18 loss=5752.255859 err=5446.073242
I 2015-05-26 22:19:51 theanets.trainer:168 RmsProp 19 loss=5479.708008 err=5165.830566
I 2015-05-26 22:20:28 theanets.trainer:168 RmsProp 20 loss=5269.067383 err=4945.988770
I 2015-05-26 22:20:29 theanets.trainer:168 validation 2 loss=4637.688477 err=4308.721191 *
I 2015-05-26 22:21:06 theanets.trainer:168 RmsProp 21 loss=5068.748535 err=4732.522949
I 2015-05-26 22:21:43 theanets.trainer:168 RmsProp 22 loss=4794.492188 err=4441.339355
I 2015-05-26 22:22:20 theanets.trainer:168 RmsProp 23 loss=4592.889160 err=4226.013672
I 2015-05-26 22:22:57 theanets.trainer:168 RmsProp 24 loss=4465.917480 err=4086.613525
I 2015-05-26 22:23:33 theanets.trainer:168 RmsProp 25 loss=4303.250977 err=3912.905762
I 2015-05-26 22:24:10 theanets.trainer:168 RmsProp 26 loss=4222.086914 err=3819.723145
I 2015-05-26 22:24:47 theanets.trainer:168 RmsProp 27 loss=4128.068848 err=3711.093750
I 2015-05-26 22:25:24 theanets.trainer:168 RmsProp 28 loss=3960.905518 err=3533.314697
I 2015-05-26 22:26:01 theanets.trainer:168 RmsProp 29 loss=3932.975830 err=3498.873535
I 2015-05-26 22:26:38 theanets.trainer:168 RmsProp 30 loss=3888.317871 err=3444.642334
I 2015-05-26 22:26:39 theanets.trainer:168 validation 3 loss=3650.703125 err=3201.775391 *
I 2015-05-26 22:27:16 theanets.trainer:168 RmsProp 31 loss=3762.416260 err=3308.635986
I 2015-05-26 22:27:52 theanets.trainer:168 RmsProp 32 loss=3790.495605 err=3327.344727
I 2015-05-26 22:28:31 theanets.trainer:168 RmsProp 33 loss=3694.113770 err=3220.428711
I 2015-05-26 22:29:08 theanets.trainer:168 RmsProp 34 loss=3607.852051 err=3129.688721
I 2015-05-26 22:29:47 theanets.trainer:168 RmsProp 35 loss=3547.973877 err=3062.206543
I 2015-05-26 22:30:24 theanets.trainer:168 RmsProp 36 loss=3494.393311 err=3006.094238
I 2015-05-26 22:31:02 theanets.trainer:168 RmsProp 37 loss=3399.766357 err=2907.634277
I 2015-05-26 22:31:40 theanets.trainer:168 RmsProp 38 loss=3331.601074 err=2833.924072
I 2015-05-26 22:32:17 theanets.trainer:168 RmsProp 39 loss=3276.350830 err=2772.219238
I 2015-05-26 22:32:55 theanets.trainer:168 RmsProp 40 loss=3363.413818 err=2846.127197
I 2015-05-26 22:32:56 theanets.trainer:168 validation 4 loss=3588.233154 err=3065.178955 *
I 2015-05-26 22:33:33 theanets.trainer:168 RmsProp 41 loss=3255.672363 err=2729.660400
I 2015-05-26 22:34:09 theanets.trainer:168 RmsProp 42 loss=3186.779541 err=2657.538086
I 2015-05-26 22:34:46 theanets.trainer:168 RmsProp 43 loss=3072.721680 err=2538.946777
I 2015-05-26 22:35:23 theanets.trainer:168 RmsProp 44 loss=3071.539551 err=2534.778809
I 2015-05-26 22:36:00 theanets.trainer:168 RmsProp 45 loss=2982.075439 err=2441.663330
I 2015-05-26 22:36:36 theanets.trainer:168 RmsProp 46 loss=2961.891113 err=2417.054688
I 2015-05-26 22:37:12 theanets.trainer:168 RmsProp 47 loss=2921.363770 err=2371.763184
I 2015-05-26 22:37:49 theanets.trainer:168 RmsProp 48 loss=2880.969727 err=2328.545654
I 2015-05-26 22:38:26 theanets.trainer:168 RmsProp 49 loss=2841.406250 err=2285.344482
I 2015-05-26 22:39:03 theanets.trainer:168 RmsProp 50 loss=2830.776123 err=2271.170410
I 2015-05-26 22:39:03 theanets.trainer:168 validation 5 loss=3203.117920 err=2642.031982 *
I 2015-05-26 22:39:40 theanets.trainer:168 RmsProp 51 loss=2810.936279 err=2245.981934
I 2015-05-26 22:40:16 theanets.trainer:168 RmsProp 52 loss=2844.607910 err=2273.372803
I 2015-05-26 22:40:53 theanets.trainer:168 RmsProp 53 loss=2784.377197 err=2210.262695
I 2015-05-26 22:41:29 theanets.trainer:168 RmsProp 54 loss=2773.594727 err=2192.767822
I 2015-05-26 22:42:06 theanets.trainer:168 RmsProp 55 loss=2702.580322 err=2118.430664
I 2015-05-26 22:42:43 theanets.trainer:168 RmsProp 56 loss=2658.099854 err=2073.686279
I 2015-05-26 22:43:19 theanets.trainer:168 RmsProp 57 loss=2621.202637 err=2034.465088
I 2015-05-26 22:43:55 theanets.trainer:168 RmsProp 58 loss=2603.735352 err=2015.166138
I 2015-05-26 22:44:32 theanets.trainer:168 RmsProp 59 loss=2581.186523 err=1989.893433
I 2015-05-26 22:45:11 theanets.trainer:168 RmsProp 60 loss=2531.698730 err=1938.566040
I 2015-05-26 22:45:12 theanets.trainer:168 validation 6 loss=3016.782471 err=2423.091064 *
I 2015-05-26 22:45:48 theanets.trainer:168 RmsProp 61 loss=2544.531738 err=1949.711182
I 2015-05-26 22:46:25 theanets.trainer:168 RmsProp 62 loss=2506.895264 err=1910.425415
I 2015-05-26 22:47:00 theanets.trainer:168 RmsProp 63 loss=2507.460938 err=1908.154785
I 2015-05-26 22:47:37 theanets.trainer:168 RmsProp 64 loss=2500.012939 err=1896.582397
I 2015-05-26 22:48:13 theanets.trainer:168 RmsProp 65 loss=2509.653076 err=1901.764038
I 2015-05-26 22:48:50 theanets.trainer:168 RmsProp 66 loss=2565.598389 err=1951.215942
I 2015-05-26 22:49:26 theanets.trainer:168 RmsProp 67 loss=2504.499512 err=1884.563599
I 2015-05-26 22:50:03 theanets.trainer:168 RmsProp 68 loss=2480.339111 err=1859.864746
I 2015-05-26 22:50:40 theanets.trainer:168 RmsProp 69 loss=2556.937256 err=1932.594849
I 2015-05-26 22:51:17 theanets.trainer:168 RmsProp 70 loss=2526.047363 err=1897.623169
I 2015-05-26 22:51:18 theanets.trainer:168 validation 7 loss=3031.250000 err=2402.568115
I 2015-05-26 22:51:55 theanets.trainer:168 RmsProp 71 loss=2408.619629 err=1781.469604
I 2015-05-26 22:52:31 theanets.trainer:168 RmsProp 72 loss=2383.356934 err=1757.359009
I 2015-05-26 22:53:08 theanets.trainer:168 RmsProp 73 loss=2339.578125 err=1713.724365
I 2015-05-26 22:53:47 theanets.trainer:168 RmsProp 74 loss=2305.147461 err=1678.788208
I 2015-05-26 22:54:25 theanets.trainer:168 RmsProp 75 loss=2281.224365 err=1654.063354
I 2015-05-26 22:55:02 theanets.trainer:168 RmsProp 76 loss=2257.912598 err=1629.951660
I 2015-05-26 22:55:39 theanets.trainer:168 RmsProp 77 loss=2276.197021 err=1645.241089
I 2015-05-26 22:56:15 theanets.trainer:168 RmsProp 78 loss=2260.760010 err=1627.211182
I 2015-05-26 22:56:52 theanets.trainer:168 RmsProp 79 loss=2241.856689 err=1606.588745
I 2015-05-26 22:57:30 theanets.trainer:168 RmsProp 80 loss=2218.947754 err=1583.860474
I 2015-05-26 22:57:31 theanets.trainer:168 validation 8 loss=2908.741455 err=2273.665527 *
I 2015-05-26 22:58:09 theanets.trainer:168 RmsProp 81 loss=2223.528809 err=1588.035522
I 2015-05-26 22:58:47 theanets.trainer:168 RmsProp 82 loss=2199.794434 err=1564.375366
I 2015-05-26 22:59:24 theanets.trainer:168 RmsProp 83 loss=2166.793457 err=1531.578247
I 2015-05-26 22:59:59 theanets.trainer:168 RmsProp 84 loss=2146.882324 err=1511.337036
I 2015-05-26 23:00:35 theanets.trainer:168 RmsProp 85 loss=2142.735596 err=1505.361450
I 2015-05-26 23:01:11 theanets.trainer:168 RmsProp 86 loss=2138.693115 err=1500.432007
I 2015-05-26 23:01:49 theanets.trainer:168 RmsProp 87 loss=2130.095703 err=1491.323120
I 2015-05-26 23:02:26 theanets.trainer:168 RmsProp 88 loss=2204.635010 err=1563.321411
I 2015-05-26 23:03:03 theanets.trainer:168 RmsProp 89 loss=2339.934814 err=1689.906738
I 2015-05-26 23:03:41 theanets.trainer:168 RmsProp 90 loss=2220.175537 err=1566.110718
I 2015-05-26 23:03:42 theanets.trainer:168 validation 9 loss=2888.158203 err=2235.455811 *
I 2015-05-26 23:04:19 theanets.trainer:168 RmsProp 91 loss=2169.694092 err=1517.924072
I 2015-05-26 23:04:56 theanets.trainer:168 RmsProp 92 loss=2189.538574 err=1534.881226
I 2015-05-26 23:05:33 theanets.trainer:168 RmsProp 93 loss=2127.915283 err=1472.947144
I 2015-05-26 23:06:08 theanets.trainer:168 RmsProp 94 loss=2148.605957 err=1492.329590
I 2015-05-26 23:06:45 theanets.trainer:168 RmsProp 95 loss=2288.072021 err=1624.413940
I 2015-05-26 23:07:22 theanets.trainer:168 RmsProp 96 loss=2235.273926 err=1566.365479
I 2015-05-26 23:07:59 theanets.trainer:168 RmsProp 97 loss=2158.172852 err=1491.207031
I 2015-05-26 23:08:37 theanets.trainer:168 RmsProp 98 loss=2089.331543 err=1423.796021
I 2015-05-26 23:09:15 theanets.trainer:168 RmsProp 99 loss=2074.863525 err=1411.930786
I 2015-05-26 23:09:52 theanets.trainer:168 RmsProp 100 loss=2068.303467 err=1405.155884
I 2015-05-26 23:09:53 theanets.trainer:168 validation 10 loss=2823.354492 err=2160.578369 *
I 2015-05-26 23:10:29 theanets.trainer:168 RmsProp 101 loss=2069.630127 err=1406.288940
I 2015-05-26 23:11:05 theanets.trainer:168 RmsProp 102 loss=2058.896729 err=1392.536865
I 2015-05-26 23:11:41 theanets.trainer:168 RmsProp 103 loss=1999.028931 err=1335.100464
I 2015-05-26 23:12:17 theanets.trainer:168 RmsProp 104 loss=1975.337158 err=1313.414062
I 2015-05-26 23:12:53 theanets.trainer:168 RmsProp 105 loss=2003.575562 err=1342.101807
I 2015-05-26 23:13:30 theanets.trainer:168 RmsProp 106 loss=1979.149902 err=1317.340088
I 2015-05-26 23:14:07 theanets.trainer:168 RmsProp 107 loss=2002.932251 err=1339.790283
I 2015-05-26 23:14:45 theanets.trainer:168 RmsProp 108 loss=2003.480835 err=1338.251709
I 2015-05-26 23:15:23 theanets.trainer:168 RmsProp 109 loss=1947.766479 err=1284.302368
I 2015-05-26 23:16:00 theanets.trainer:168 RmsProp 110 loss=2018.461060 err=1354.350830
I 2015-05-26 23:16:01 theanets.trainer:168 validation 11 loss=2727.920410 err=2062.011719 *
I 2015-05-26 23:16:38 theanets.trainer:168 RmsProp 111 loss=2032.115356 err=1365.680298
I 2015-05-26 23:17:14 theanets.trainer:168 RmsProp 112 loss=1957.199463 err=1290.517456
I 2015-05-26 23:17:50 theanets.trainer:168 RmsProp 113 loss=1930.502075 err=1265.597168
I 2015-05-26 23:18:26 theanets.trainer:168 RmsProp 114 loss=1895.768799 err=1232.405518
I 2015-05-26 23:19:01 theanets.trainer:168 RmsProp 115 loss=1876.649902 err=1214.263916
I 2015-05-26 23:19:37 theanets.trainer:168 RmsProp 116 loss=1891.288696 err=1228.840332
I 2015-05-26 23:20:12 theanets.trainer:168 RmsProp 117 loss=1869.710449 err=1207.201172
I 2015-05-26 23:20:48 theanets.trainer:168 RmsProp 118 loss=1871.009399 err=1208.588501
I 2015-05-26 23:21:23 theanets.trainer:168 RmsProp 119 loss=1836.365845 err=1174.158936
I 2015-05-26 23:21:59 theanets.trainer:168 RmsProp 120 loss=1840.189209 err=1178.936401
I 2015-05-26 23:22:00 theanets.trainer:168 validation 12 loss=2639.052979 err=1976.938354 *
I 2015-05-26 23:22:35 theanets.trainer:168 RmsProp 121 loss=1892.620361 err=1228.147217
I 2015-05-26 23:23:13 theanets.trainer:168 RmsProp 122 loss=1862.678345 err=1195.843140
I 2015-05-26 23:23:50 theanets.trainer:168 RmsProp 123 loss=1835.330078 err=1169.806641
I 2015-05-26 23:24:27 theanets.trainer:168 RmsProp 124 loss=1844.936890 err=1180.549438
I 2015-05-26 23:25:04 theanets.trainer:168 RmsProp 125 loss=1858.532715 err=1190.545410
I 2015-05-26 23:25:40 theanets.trainer:168 RmsProp 126 loss=1831.896484 err=1164.086182
I 2015-05-26 23:26:17 theanets.trainer:168 RmsProp 127 loss=1827.025757 err=1160.048096
I 2015-05-26 23:26:53 theanets.trainer:168 RmsProp 128 loss=1818.101562 err=1151.521973
I 2015-05-26 23:27:30 theanets.trainer:168 RmsProp 129 loss=1791.041260 err=1124.165527
I 2015-05-26 23:28:06 theanets.trainer:168 RmsProp 130 loss=1818.364380 err=1150.723267
I 2015-05-26 23:28:07 theanets.trainer:168 validation 13 loss=2751.835938 err=2082.705566
I 2015-05-26 23:28:43 theanets.trainer:168 RmsProp 131 loss=1864.918335 err=1194.601685
I 2015-05-26 23:29:20 theanets.trainer:168 RmsProp 132 loss=1852.787964 err=1179.472900
I 2015-05-26 23:29:57 theanets.trainer:168 RmsProp 133 loss=1813.121460 err=1140.510498
I 2015-05-26 23:30:34 theanets.trainer:168 RmsProp 134 loss=1845.236572 err=1172.052002
I 2015-05-26 23:31:11 theanets.trainer:168 RmsProp 135 loss=1836.908203 err=1162.203735
I 2015-05-26 23:31:47 theanets.trainer:168 RmsProp 136 loss=1859.131470 err=1182.599121
I 2015-05-26 23:32:24 theanets.trainer:168 RmsProp 137 loss=1907.956787 err=1227.991821
I 2015-05-26 23:33:00 theanets.trainer:168 RmsProp 138 loss=1893.021851 err=1207.202393
I 2015-05-26 23:33:37 theanets.trainer:168 RmsProp 139 loss=1900.916748 err=1215.678955
I 2015-05-26 23:34:13 theanets.trainer:168 RmsProp 140 loss=1883.109253 err=1194.847168
I 2015-05-26 23:34:14 theanets.trainer:168 validation 14 loss=2632.808105 err=1944.671265 *
I 2015-05-26 23:34:50 theanets.trainer:168 RmsProp 141 loss=1823.873291 err=1137.564087
I 2015-05-26 23:35:27 theanets.trainer:168 RmsProp 142 loss=1782.892456 err=1099.113647
I 2015-05-26 23:36:03 theanets.trainer:168 RmsProp 143 loss=1758.193359 err=1077.611450
I 2015-05-26 23:36:38 theanets.trainer:168 RmsProp 144 loss=1739.079834 err=1060.221191
I 2015-05-26 23:37:15 theanets.trainer:168 RmsProp 145 loss=1747.690674 err=1069.726929
I 2015-05-26 23:37:52 theanets.trainer:168 RmsProp 146 loss=1723.204590 err=1044.788086
I 2015-05-26 23:38:30 theanets.trainer:168 RmsProp 147 loss=1721.792114 err=1044.410522
I 2015-05-26 23:39:07 theanets.trainer:168 RmsProp 148 loss=1700.706421 err=1024.064575
I 2015-05-26 23:39:43 theanets.trainer:168 RmsProp 149 loss=1735.662720 err=1058.007935
I 2015-05-26 23:40:19 theanets.trainer:168 RmsProp 150 loss=1747.868408 err=1067.807739
I 2015-05-26 23:40:20 theanets.trainer:168 validation 15 loss=2648.630371 err=1968.840210
I 2015-05-26 23:40:57 theanets.trainer:168 RmsProp 151 loss=1724.754272 err=1044.818481
I 2015-05-26 23:41:34 theanets.trainer:168 RmsProp 152 loss=1758.822388 err=1077.524048
I 2015-05-26 23:42:11 theanets.trainer:168 RmsProp 153 loss=1723.239380 err=1041.968384
I 2015-05-26 23:42:47 theanets.trainer:168 RmsProp 154 loss=1740.901123 err=1058.343140
I 2015-05-26 23:43:25 theanets.trainer:168 RmsProp 155 loss=1749.374146 err=1064.078857
I 2015-05-26 23:44:02 theanets.trainer:168 RmsProp 156 loss=1735.083862 err=1049.159668
I 2015-05-26 23:44:38 theanets.trainer:168 RmsProp 157 loss=1728.503540 err=1041.972290
I 2015-05-26 23:45:14 theanets.trainer:168 RmsProp 158 loss=1761.351440 err=1073.522095
I 2015-05-26 23:45:51 theanets.trainer:168 RmsProp 159 loss=1737.589355 err=1048.206421
I 2015-05-26 23:46:27 theanets.trainer:168 RmsProp 160 loss=1716.354370 err=1029.465454
I 2015-05-26 23:46:28 theanets.trainer:168 validation 16 loss=2611.081055 err=1925.092651 *
I 2015-05-26 23:47:03 theanets.trainer:168 RmsProp 161 loss=1706.154053 err=1019.904236
I 2015-05-26 23:47:38 theanets.trainer:168 RmsProp 162 loss=1702.168335 err=1015.614502
I 2015-05-26 23:48:12 theanets.trainer:168 RmsProp 163 loss=1715.610962 err=1028.903809
I 2015-05-26 23:48:46 theanets.trainer:168 RmsProp 164 loss=1739.805786 err=1051.344971
I 2015-05-26 23:49:22 theanets.trainer:168 RmsProp 165 loss=1700.199707 err=1011.445007
I 2015-05-26 23:49:58 theanets.trainer:168 RmsProp 166 loss=1689.033447 err=1000.860168
I 2015-05-26 23:50:34 theanets.trainer:168 RmsProp 167 loss=1661.816772 err=975.521484
I 2015-05-26 23:51:09 theanets.trainer:168 RmsProp 168 loss=1655.426880 err=969.502319
I 2015-05-26 23:51:44 theanets.trainer:168 RmsProp 169 loss=1692.253784 err=1005.084839
I 2015-05-26 23:52:19 theanets.trainer:168 RmsProp 170 loss=1667.344116 err=979.514282
I 2015-05-26 23:52:20 theanets.trainer:168 validation 17 loss=2522.180176 err=1834.806030 *
I 2015-05-26 23:52:55 theanets.trainer:168 RmsProp 171 loss=1666.262329 err=978.315735
I 2015-05-26 23:53:30 theanets.trainer:168 RmsProp 172 loss=1658.669922 err=970.026978
I 2015-05-26 23:54:05 theanets.trainer:168 RmsProp 173 loss=1656.141357 err=967.480896
I 2015-05-26 23:54:41 theanets.trainer:168 RmsProp 174 loss=1670.156982 err=980.801208
I 2015-05-26 23:55:17 theanets.trainer:168 RmsProp 175 loss=1656.830933 err=966.474670
I 2015-05-26 23:55:53 theanets.trainer:168 RmsProp 176 loss=1640.468750 err=950.729187
I 2015-05-26 23:56:28 theanets.trainer:168 RmsProp 177 loss=1631.858521 err=941.908386
I 2015-05-26 23:57:03 theanets.trainer:168 RmsProp 178 loss=1637.525879 err=947.823364
I 2015-05-26 23:57:39 theanets.trainer:168 RmsProp 179 loss=1645.328369 err=953.783081
I 2015-05-26 23:58:14 theanets.trainer:168 RmsProp 180 loss=1630.482422 err=939.218201
I 2015-05-26 23:58:15 theanets.trainer:168 validation 18 loss=2486.560059 err=1795.752808 *
I 2015-05-26 23:58:50 theanets.trainer:168 RmsProp 181 loss=1602.523315 err=912.627075
I 2015-05-26 23:59:26 theanets.trainer:168 RmsProp 182 loss=1610.560303 err=920.411438
I 2015-05-27 00:00:02 theanets.trainer:168 RmsProp 183 loss=1613.962891 err=923.019714
I 2015-05-27 00:00:38 theanets.trainer:168 RmsProp 184 loss=1607.195435 err=915.814575
I 2015-05-27 00:01:14 theanets.trainer:168 RmsProp 185 loss=1614.787964 err=922.611877
I 2015-05-27 00:01:50 theanets.trainer:168 RmsProp 186 loss=1615.725098 err=923.002502
I 2015-05-27 00:02:26 theanets.trainer:168 RmsProp 187 loss=1577.608521 err=885.275513
I 2015-05-27 00:03:01 theanets.trainer:168 RmsProp 188 loss=1563.242920 err=872.162476
I 2015-05-27 00:03:36 theanets.trainer:168 RmsProp 189 loss=1554.064453 err=863.909302
I 2015-05-27 00:04:12 theanets.trainer:168 RmsProp 190 loss=1554.216553 err=864.661316
I 2015-05-27 00:04:13 theanets.trainer:168 validation 19 loss=2442.110596 err=1752.973022 *
I 2015-05-27 00:04:48 theanets.trainer:168 RmsProp 191 loss=1564.394653 err=874.662415
I 2015-05-27 00:05:22 theanets.trainer:168 RmsProp 192 loss=1591.085327 err=900.394287
I 2015-05-27 00:05:57 theanets.trainer:168 RmsProp 193 loss=1567.206543 err=876.648804
I 2015-05-27 00:06:33 theanets.trainer:168 RmsProp 194 loss=1532.418091 err=843.809387
I 2015-05-27 00:07:09 theanets.trainer:168 RmsProp 195 loss=1542.832886 err=855.036743
I 2015-05-27 00:07:45 theanets.trainer:168 RmsProp 196 loss=1561.139038 err=873.415771
I 2015-05-27 00:08:21 theanets.trainer:168 RmsProp 197 loss=1549.421143 err=860.800537
I 2015-05-27 00:08:56 theanets.trainer:168 RmsProp 198 loss=1517.149048 err=828.906860
I 2015-05-27 00:09:32 theanets.trainer:168 RmsProp 199 loss=1521.045288 err=834.700989
I 2015-05-27 00:10:07 theanets.trainer:168 RmsProp 200 loss=1519.345215 err=832.903076
I 2015-05-27 00:10:08 theanets.trainer:168 validation 20 loss=2386.411377 err=1699.587280 *
I 2015-05-27 00:10:43 theanets.trainer:168 RmsProp 201 loss=1538.721313 err=851.278748
I 2015-05-27 00:11:17 theanets.trainer:168 RmsProp 202 loss=1529.176147 err=841.243896
I 2015-05-27 00:11:51 theanets.trainer:168 RmsProp 203 loss=1511.101929 err=824.174194
I 2015-05-27 00:12:23 theanets.trainer:168 RmsProp 204 loss=1495.190552 err=809.594604
I 2015-05-27 00:12:57 theanets.trainer:168 RmsProp 205 loss=1489.240479 err=803.931274
I 2015-05-27 00:13:31 theanets.trainer:168 RmsProp 206 loss=1482.561890 err=797.458984
I 2015-05-27 00:14:05 theanets.trainer:168 RmsProp 207 loss=1550.558105 err=863.381226
I 2015-05-27 00:14:38 theanets.trainer:168 RmsProp 208 loss=1522.334106 err=833.578308
I 2015-05-27 00:15:11 theanets.trainer:168 RmsProp 209 loss=1520.392944 err=832.594177
I 2015-05-27 00:15:43 theanets.trainer:168 RmsProp 210 loss=1529.208984 err=841.092041
I 2015-05-27 00:15:44 theanets.trainer:168 validation 21 loss=2366.029785 err=1677.181274 *
I 2015-05-27 00:16:16 theanets.trainer:168 RmsProp 211 loss=1534.166626 err=845.724365
I 2015-05-27 00:16:49 theanets.trainer:168 RmsProp 212 loss=1532.039795 err=843.278687
I 2015-05-27 00:17:23 theanets.trainer:168 RmsProp 213 loss=1495.311279 err=807.336365
I 2015-05-27 00:17:56 theanets.trainer:168 RmsProp 214 loss=1499.186768 err=811.101379
I 2015-05-27 00:18:29 theanets.trainer:168 RmsProp 215 loss=1494.158813 err=805.445679
I 2015-05-27 00:19:02 theanets.trainer:168 RmsProp 216 loss=1504.798706 err=816.110291
I 2015-05-27 00:19:36 theanets.trainer:168 RmsProp 217 loss=1529.320801 err=839.672424
I 2015-05-27 00:20:09 theanets.trainer:168 RmsProp 218 loss=1518.143433 err=827.571594
I 2015-05-27 00:20:43 theanets.trainer:168 RmsProp 219 loss=1528.006592 err=837.415344
I 2015-05-27 00:21:17 theanets.trainer:168 RmsProp 220 loss=1546.796387 err=854.053406
I 2015-05-27 00:21:17 theanets.trainer:168 validation 22 loss=2362.510254 err=1670.090698 *
I 2015-05-27 00:21:51 theanets.trainer:168 RmsProp 221 loss=1499.469849 err=808.014221
I 2015-05-27 00:22:24 theanets.trainer:168 RmsProp 222 loss=1503.592163 err=812.490540
I 2015-05-27 00:22:58 theanets.trainer:168 RmsProp 223 loss=1514.625732 err=822.941284
I 2015-05-27 00:23:32 theanets.trainer:168 RmsProp 224 loss=1499.022095 err=808.006592
I 2015-05-27 00:24:04 theanets.trainer:168 RmsProp 225 loss=1480.121094 err=789.903442
I 2015-05-27 00:24:38 theanets.trainer:168 RmsProp 226 loss=1461.061646 err=771.659485
I 2015-05-27 00:25:11 theanets.trainer:168 RmsProp 227 loss=1499.632446 err=809.798218
I 2015-05-27 00:25:44 theanets.trainer:168 RmsProp 228 loss=1570.738770 err=876.000916
I 2015-05-27 00:26:17 theanets.trainer:168 RmsProp 229 loss=1532.468140 err=835.812317
I 2015-05-27 00:26:50 theanets.trainer:168 RmsProp 230 loss=1499.202026 err=804.943604
I 2015-05-27 00:26:51 theanets.trainer:168 validation 23 loss=2365.695801 err=1672.541016
I 2015-05-27 00:27:22 theanets.trainer:168 RmsProp 231 loss=1509.712036 err=816.205139
I 2015-05-27 00:27:53 theanets.trainer:168 RmsProp 232 loss=1520.435791 err=825.838013
I 2015-05-27 00:28:25 theanets.trainer:168 RmsProp 233 loss=1500.091919 err=806.075317
I 2015-05-27 00:28:57 theanets.trainer:168 RmsProp 234 loss=1510.266357 err=816.455750
I 2015-05-27 00:29:30 theanets.trainer:168 RmsProp 235 loss=1538.920410 err=843.267273
I 2015-05-27 00:30:03 theanets.trainer:168 RmsProp 236 loss=1524.343140 err=827.255127
I 2015-05-27 00:30:36 theanets.trainer:168 RmsProp 237 loss=1508.956299 err=812.536316
I 2015-05-27 00:31:09 theanets.trainer:168 RmsProp 238 loss=1489.577271 err=794.106750
I 2015-05-27 00:31:41 theanets.trainer:168 RmsProp 239 loss=1463.536255 err=769.453491
I 2015-05-27 00:32:14 theanets.trainer:168 RmsProp 240 loss=1494.262085 err=799.722534
I 2015-05-27 00:32:15 theanets.trainer:168 validation 24 loss=2413.348877 err=1717.301147
I 2015-05-27 00:32:48 theanets.trainer:168 RmsProp 241 loss=1497.603027 err=801.547302
I 2015-05-27 00:33:21 theanets.trainer:168 RmsProp 242 loss=1526.902832 err=829.131165
I 2015-05-27 00:33:55 theanets.trainer:168 RmsProp 243 loss=1565.821045 err=864.704529
I 2015-05-27 00:34:28 theanets.trainer:168 RmsProp 244 loss=1583.576416 err=879.159241
I 2015-05-27 00:35:02 theanets.trainer:168 RmsProp 245 loss=1594.273560 err=887.014648
I 2015-05-27 00:35:35 theanets.trainer:168 RmsProp 246 loss=1561.329712 err=853.281372
I 2015-05-27 00:36:08 theanets.trainer:168 RmsProp 247 loss=1558.705078 err=850.863586
I 2015-05-27 00:36:41 theanets.trainer:168 RmsProp 248 loss=1548.911987 err=839.509338
I 2015-05-27 00:37:13 theanets.trainer:168 RmsProp 249 loss=1521.452515 err=813.540161
I 2015-05-27 00:37:47 theanets.trainer:168 RmsProp 250 loss=1508.848877 err=801.932739
I 2015-05-27 00:37:48 theanets.trainer:168 validation 25 loss=2420.032227 err=1712.956909
I 2015-05-27 00:38:21 theanets.trainer:168 RmsProp 251 loss=1498.927979 err=792.584839
I 2015-05-27 00:38:54 theanets.trainer:168 RmsProp 252 loss=1524.430542 err=818.022034
I 2015-05-27 00:39:27 theanets.trainer:168 RmsProp 253 loss=1550.291626 err=841.758545
I 2015-05-27 00:40:00 theanets.trainer:168 RmsProp 254 loss=1513.815308 err=806.262512
I 2015-05-27 00:40:33 theanets.trainer:168 RmsProp 255 loss=1471.705200 err=766.065125
I 2015-05-27 00:41:06 theanets.trainer:168 RmsProp 256 loss=1464.142090 err=760.449402
I 2015-05-27 00:41:39 theanets.trainer:168 RmsProp 257 loss=1454.647949 err=751.340759
I 2015-05-27 00:42:12 theanets.trainer:168 RmsProp 258 loss=1493.340332 err=791.000244
I 2015-05-27 00:42:44 theanets.trainer:168 RmsProp 259 loss=1661.973389 err=951.733582
I 2015-05-27 00:43:17 theanets.trainer:168 RmsProp 260 loss=1589.711304 err=875.081299
I 2015-05-27 00:43:18 theanets.trainer:168 validation 26 loss=2316.494629 err=1601.810669 *
I 2015-05-27 00:43:50 theanets.trainer:168 RmsProp 261 loss=1563.133423 err=849.030151
I 2015-05-27 00:44:22 theanets.trainer:168 RmsProp 262 loss=1843.533203 err=1123.597168
I 2015-05-27 00:44:54 theanets.trainer:168 RmsProp 263 loss=2313.938232 err=1571.534912
I 2015-05-27 00:45:27 theanets.trainer:168 RmsProp 264 loss=2177.606445 err=1424.091431
I 2015-05-27 00:46:00 theanets.trainer:168 RmsProp 265 loss=1941.713989 err=1190.265747
I 2015-05-27 00:46:34 theanets.trainer:168 RmsProp 266 loss=1843.764771 err=1096.012329
I 2015-05-27 00:47:07 theanets.trainer:168 RmsProp 267 loss=1740.156738 err=999.375183
I 2015-05-27 00:47:41 theanets.trainer:168 RmsProp 268 loss=1684.397217 err=948.972656
I 2015-05-27 00:48:14 theanets.trainer:168 RmsProp 269 loss=1649.695557 err=917.201172
I 2015-05-27 00:48:48 theanets.trainer:168 RmsProp 270 loss=1625.795410 err=895.130127
I 2015-05-27 00:48:49 theanets.trainer:168 validation 27 loss=2367.561523 err=1638.897827
I 2015-05-27 00:49:22 theanets.trainer:168 RmsProp 271 loss=1699.373657 err=970.189209
I 2015-05-27 00:49:56 theanets.trainer:168 RmsProp 272 loss=2047.404297 err=1304.764160
I 2015-05-27 00:50:30 theanets.trainer:168 RmsProp 273 loss=1998.810059 err=1248.384155
I 2015-05-27 00:51:03 theanets.trainer:168 RmsProp 274 loss=1976.091675 err=1225.006958
I 2015-05-27 00:51:37 theanets.trainer:168 RmsProp 275 loss=1844.513916 err=1091.673950
I 2015-05-27 00:52:10 theanets.trainer:168 RmsProp 276 loss=1733.501465 err=985.468201
I 2015-05-27 00:52:44 theanets.trainer:168 RmsProp 277 loss=1636.531494 err=895.350952
I 2015-05-27 00:53:16 theanets.trainer:168 RmsProp 278 loss=1645.938965 err=908.144470
I 2015-05-27 00:53:49 theanets.trainer:168 RmsProp 279 loss=1591.849609 err=856.811707
I 2015-05-27 00:54:22 theanets.trainer:168 RmsProp 280 loss=1556.919434 err=825.611145
I 2015-05-27 00:54:23 theanets.trainer:168 validation 28 loss=2331.001221 err=1600.773071
I 2015-05-27 00:54:56 theanets.trainer:168 RmsProp 281 loss=1527.976562 err=799.486633
I 2015-05-27 00:55:29 theanets.trainer:168 RmsProp 282 loss=1520.444824 err=794.492981
I 2015-05-27 00:56:02 theanets.trainer:168 RmsProp 283 loss=1526.979248 err=802.867493
I 2015-05-27 00:56:36 theanets.trainer:168 RmsProp 284 loss=1516.764526 err=793.183533
I 2015-05-27 00:57:09 theanets.trainer:168 RmsProp 285 loss=1524.494019 err=800.783813
I 2015-05-27 00:57:41 theanets.trainer:168 RmsProp 286 loss=1550.355469 err=825.108093
I 2015-05-27 00:58:14 theanets.trainer:168 RmsProp 287 loss=1541.650879 err=814.837585
I 2015-05-27 00:58:47 theanets.trainer:168 RmsProp 288 loss=1526.148560 err=800.348938
I 2015-05-27 00:59:20 theanets.trainer:168 RmsProp 289 loss=1533.417725 err=807.695068
I 2015-05-27 00:59:53 theanets.trainer:168 RmsProp 290 loss=1509.635132 err=784.872681
I 2015-05-27 00:59:53 theanets.trainer:168 validation 29 loss=2323.895264 err=1600.055664
I 2015-05-27 01:00:25 theanets.trainer:168 RmsProp 291 loss=1488.967529 err=764.940674
I 2015-05-27 01:00:57 theanets.trainer:168 RmsProp 292 loss=1478.596558 err=755.561584
I 2015-05-27 01:01:28 theanets.trainer:168 RmsProp 293 loss=1477.322388 err=754.642700
I 2015-05-27 01:02:00 theanets.trainer:168 RmsProp 294 loss=1470.559082 err=748.244202
I 2015-05-27 01:02:33 theanets.trainer:168 RmsProp 295 loss=1450.214111 err=728.384399
I 2015-05-27 01:03:05 theanets.trainer:168 RmsProp 296 loss=1431.732056 err=712.484436
I 2015-05-27 01:03:38 theanets.trainer:168 RmsProp 297 loss=1440.862549 err=722.681885
I 2015-05-27 01:04:12 theanets.trainer:168 RmsProp 298 loss=1434.954834 err=715.758667
I 2015-05-27 01:04:45 theanets.trainer:168 RmsProp 299 loss=1450.063354 err=730.993286
I 2015-05-27 01:05:19 theanets.trainer:168 RmsProp 300 loss=1442.674927 err=723.656189
I 2015-05-27 01:05:20 theanets.trainer:168 validation 30 loss=2247.614990 err=1528.251343 *
I 2015-05-27 01:05:53 theanets.trainer:168 RmsProp 301 loss=1444.964722 err=723.838806
I 2015-05-27 01:06:26 theanets.trainer:168 RmsProp 302 loss=1419.811646 err=702.196716
I 2015-05-27 01:06:59 theanets.trainer:168 RmsProp 303 loss=1418.108276 err=701.551819
I 2015-05-27 01:07:32 theanets.trainer:168 RmsProp 304 loss=1402.973511 err=688.043213
I 2015-05-27 01:08:06 theanets.trainer:168 RmsProp 305 loss=1415.987061 err=701.243469
I 2015-05-27 01:08:39 theanets.trainer:168 RmsProp 306 loss=1426.365112 err=711.296875
I 2015-05-27 01:09:13 theanets.trainer:168 RmsProp 307 loss=1405.569580 err=691.446960
I 2015-05-27 01:09:47 theanets.trainer:168 RmsProp 308 loss=1392.276733 err=679.839417
I 2015-05-27 01:10:20 theanets.trainer:168 RmsProp 309 loss=1391.855103 err=679.754822
I 2015-05-27 01:10:54 theanets.trainer:168 RmsProp 310 loss=1396.468140 err=684.261108
I 2015-05-27 01:10:55 theanets.trainer:168 validation 31 loss=2254.305176 err=1542.429565
I 2015-05-27 01:11:29 theanets.trainer:168 RmsProp 311 loss=1398.187012 err=686.310852
I 2015-05-27 01:12:03 theanets.trainer:168 RmsProp 312 loss=1400.463257 err=687.858093
I 2015-05-27 01:12:37 theanets.trainer:168 RmsProp 313 loss=1393.332031 err=681.312256
I 2015-05-27 01:13:10 theanets.trainer:168 RmsProp 314 loss=1424.927368 err=711.610718
I 2015-05-27 01:13:43 theanets.trainer:168 RmsProp 315 loss=1543.939087 err=824.191345
I 2015-05-27 01:14:16 theanets.trainer:168 RmsProp 316 loss=1689.148193 err=961.616821
I 2015-05-27 01:14:48 theanets.trainer:168 RmsProp 317 loss=1600.207275 err=864.499878
I 2015-05-27 01:15:21 theanets.trainer:168 RmsProp 318 loss=1575.739624 err=846.201782
I 2015-05-27 01:15:54 theanets.trainer:168 RmsProp 319 loss=1810.293823 err=1071.864136
I 2015-05-27 01:16:28 theanets.trainer:168 RmsProp 320 loss=1756.548950 err=1012.018799
I 2015-05-27 01:16:28 theanets.trainer:168 validation 32 loss=2482.062988 err=1737.816040
I 2015-05-27 01:17:02 theanets.trainer:168 RmsProp 321 loss=1675.767578 err=929.933411
I 2015-05-27 01:17:35 theanets.trainer:168 RmsProp 322 loss=1549.983154 err=808.836670
I 2015-05-27 01:18:09 theanets.trainer:168 RmsProp 323 loss=1493.468262 err=758.221130
I 2015-05-27 01:18:43 theanets.trainer:168 RmsProp 324 loss=1464.577759 err=734.179749
I 2015-05-27 01:19:17 theanets.trainer:168 RmsProp 325 loss=1452.220337 err=724.161133
I 2015-05-27 01:19:51 theanets.trainer:168 RmsProp 326 loss=1483.246338 err=754.231140
I 2015-05-27 01:20:25 theanets.trainer:168 RmsProp 327 loss=1454.951172 err=725.748962
I 2015-05-27 01:20:59 theanets.trainer:168 RmsProp 328 loss=1524.768677 err=795.080017
I 2015-05-27 01:21:32 theanets.trainer:168 RmsProp 329 loss=1651.580566 err=913.161072
I 2015-05-27 01:22:06 theanets.trainer:168 RmsProp 330 loss=1815.399780 err=1069.561279
I 2015-05-27 01:22:06 theanets.trainer:168 validation 33 loss=2415.110352 err=1662.199585
I 2015-05-27 01:22:40 theanets.trainer:168 RmsProp 331 loss=1763.522095 err=1009.578369
I 2015-05-27 01:23:14 theanets.trainer:168 RmsProp 332 loss=1602.483032 err=853.256165
I 2015-05-27 01:23:47 theanets.trainer:168 RmsProp 333 loss=1542.386963 err=799.497986
I 2015-05-27 01:24:21 theanets.trainer:168 RmsProp 334 loss=1501.961792 err=763.406860
I 2015-05-27 01:24:55 theanets.trainer:168 RmsProp 335 loss=1506.766968 err=769.625732
I 2015-05-27 01:25:28 theanets.trainer:168 RmsProp 336 loss=1507.451904 err=769.949890
I 2015-05-27 01:26:01 theanets.trainer:168 RmsProp 337 loss=1493.123779 err=755.849976
I 2015-05-27 01:26:35 theanets.trainer:168 RmsProp 338 loss=1454.901611 err=720.459839
I 2015-05-27 01:27:08 theanets.trainer:168 RmsProp 339 loss=1442.506714 err=709.969177
I 2015-05-27 01:27:41 theanets.trainer:168 RmsProp 340 loss=1447.865601 err=715.577881
I 2015-05-27 01:27:42 theanets.trainer:168 validation 34 loss=2209.860596 err=1476.610840 *
I 2015-05-27 01:28:14 theanets.trainer:168 RmsProp 341 loss=1447.599243 err=714.722046
I 2015-05-27 01:28:47 theanets.trainer:168 RmsProp 342 loss=1437.636230 err=706.077393
I 2015-05-27 01:29:20 theanets.trainer:168 RmsProp 343 loss=1472.867798 err=740.439148
I 2015-05-27 01:29:53 theanets.trainer:168 RmsProp 344 loss=1477.344360 err=743.147034
I 2015-05-27 01:30:26 theanets.trainer:168 RmsProp 345 loss=1449.689697 err=714.953796
I 2015-05-27 01:30:59 theanets.trainer:168 RmsProp 346 loss=1493.640381 err=757.903137
I 2015-05-27 01:31:32 theanets.trainer:168 RmsProp 347 loss=1503.349365 err=766.067261
I 2015-05-27 01:32:05 theanets.trainer:168 RmsProp 348 loss=1569.095825 err=828.927673
I 2015-05-27 01:32:38 theanets.trainer:168 RmsProp 349 loss=1597.353516 err=850.198242
I 2015-05-27 01:33:11 theanets.trainer:168 RmsProp 350 loss=1560.020996 err=812.041992
I 2015-05-27 01:33:12 theanets.trainer:168 validation 35 loss=2248.496338 err=1502.040405
I 2015-05-27 01:33:45 theanets.trainer:168 RmsProp 351 loss=1523.978271 err=778.284119
I 2015-05-27 01:34:18 theanets.trainer:168 RmsProp 352 loss=1491.351562 err=748.959351
I 2015-05-27 01:34:51 theanets.trainer:168 RmsProp 353 loss=1469.220947 err=728.725037
I 2015-05-27 01:35:24 theanets.trainer:168 RmsProp 354 loss=1434.139893 err=696.159790
I 2015-05-27 01:35:57 theanets.trainer:168 RmsProp 355 loss=1418.857422 err=683.129517
I 2015-05-27 01:36:29 theanets.trainer:168 RmsProp 356 loss=1417.064087 err=682.946960
I 2015-05-27 01:37:03 theanets.trainer:168 RmsProp 357 loss=1405.656372 err=672.721497
I 2015-05-27 01:37:37 theanets.trainer:168 RmsProp 358 loss=1427.032837 err=693.830444
I 2015-05-27 01:38:11 theanets.trainer:168 RmsProp 359 loss=1426.090210 err=692.687683
I 2015-05-27 01:38:44 theanets.trainer:168 RmsProp 360 loss=1479.537964 err=745.198364
I 2015-05-27 01:38:45 theanets.trainer:168 validation 36 loss=2517.894287 err=1780.642944
I 2015-05-27 01:39:18 theanets.trainer:168 RmsProp 361 loss=1593.201782 err=852.479126
I 2015-05-27 01:39:52 theanets.trainer:168 RmsProp 362 loss=1658.725220 err=912.356567
I 2015-05-27 01:40:26 theanets.trainer:168 RmsProp 363 loss=1687.354980 err=934.852417
I 2015-05-27 01:40:59 theanets.trainer:168 RmsProp 364 loss=1557.288818 err=805.063293
I 2015-05-27 01:41:31 theanets.trainer:168 RmsProp 365 loss=1493.522949 err=746.297668
I 2015-05-27 01:42:03 theanets.trainer:168 RmsProp 366 loss=1465.896729 err=722.022888
I 2015-05-27 01:42:34 theanets.trainer:168 RmsProp 367 loss=1512.471924 err=766.917847
I 2015-05-27 01:43:05 theanets.trainer:168 RmsProp 368 loss=1509.554321 err=761.887024
I 2015-05-27 01:43:36 theanets.trainer:168 RmsProp 369 loss=1495.935547 err=749.082214
I 2015-05-27 01:44:08 theanets.trainer:168 RmsProp 370 loss=1474.010498 err=727.289062
I 2015-05-27 01:44:08 theanets.trainer:168 validation 37 loss=2301.117432 err=1555.131226
I 2015-05-27 01:44:39 theanets.trainer:168 RmsProp 371 loss=1489.958374 err=742.676208
I 2015-05-27 01:45:11 theanets.trainer:168 RmsProp 372 loss=1515.205322 err=765.955505
I 2015-05-27 01:45:43 theanets.trainer:168 RmsProp 373 loss=1537.679199 err=783.206848
I 2015-05-27 01:46:15 theanets.trainer:168 RmsProp 374 loss=1494.348755 err=741.484436
I 2015-05-27 01:46:47 theanets.trainer:168 RmsProp 375 loss=1460.526733 err=710.364685
I 2015-05-27 01:47:18 theanets.trainer:168 RmsProp 376 loss=1457.843628 err=709.854370
I 2015-05-27 01:47:49 theanets.trainer:168 RmsProp 377 loss=1441.519409 err=693.904724
I 2015-05-27 01:48:20 theanets.trainer:168 RmsProp 378 loss=1480.921143 err=731.444153
I 2015-05-27 01:48:51 theanets.trainer:168 RmsProp 379 loss=1475.411011 err=724.198853
I 2015-05-27 01:49:22 theanets.trainer:168 RmsProp 380 loss=1455.118042 err=705.275513
I 2015-05-27 01:49:23 theanets.trainer:168 validation 38 loss=2149.936523 err=1400.481812 *
I 2015-05-27 01:49:55 theanets.trainer:168 RmsProp 381 loss=1470.990967 err=721.074585
I 2015-05-27 01:50:26 theanets.trainer:168 RmsProp 382 loss=1485.076904 err=732.746094
I 2015-05-27 01:50:57 theanets.trainer:168 RmsProp 383 loss=1466.959106 err=714.050903
I 2015-05-27 01:51:28 theanets.trainer:168 RmsProp 384 loss=1440.123901 err=688.903320
I 2015-05-27 01:52:00 theanets.trainer:168 RmsProp 385 loss=1437.283081 err=686.537231
I 2015-05-27 01:52:32 theanets.trainer:168 RmsProp 386 loss=1431.298950 err=680.845886
I 2015-05-27 01:53:03 theanets.trainer:168 RmsProp 387 loss=1434.784912 err=685.122009
I 2015-05-27 01:53:34 theanets.trainer:168 RmsProp 388 loss=1465.194458 err=712.384216
I 2015-05-27 01:54:06 theanets.trainer:168 RmsProp 389 loss=1435.932251 err=682.402466
I 2015-05-27 01:54:37 theanets.trainer:168 RmsProp 390 loss=1414.603394 err=662.767456
I 2015-05-27 01:54:38 theanets.trainer:168 validation 39 loss=2188.000000 err=1437.157349
I 2015-05-27 01:55:10 theanets.trainer:168 RmsProp 391 loss=1414.353027 err=663.767578
I 2015-05-27 01:55:41 theanets.trainer:168 RmsProp 392 loss=1438.210938 err=687.502625
I 2015-05-27 01:56:13 theanets.trainer:168 RmsProp 393 loss=1432.786987 err=680.592896
I 2015-05-27 01:56:45 theanets.trainer:168 RmsProp 394 loss=1411.221802 err=659.969116
I 2015-05-27 01:57:16 theanets.trainer:168 RmsProp 395 loss=1393.944824 err=644.525024
I 2015-05-27 01:57:48 theanets.trainer:168 RmsProp 396 loss=1376.980957 err=629.141541
I 2015-05-27 01:58:19 theanets.trainer:168 RmsProp 397 loss=1369.790283 err=623.569519
I 2015-05-27 01:58:51 theanets.trainer:168 RmsProp 398 loss=1376.782593 err=630.639526
I 2015-05-27 01:59:23 theanets.trainer:168 RmsProp 399 loss=1383.355835 err=637.055115
I 2015-05-27 01:59:54 theanets.trainer:168 RmsProp 400 loss=1364.488525 err=619.207397
I 2015-05-27 01:59:55 theanets.trainer:168 validation 40 loss=2109.335205 err=1364.732666 *
I 2015-05-27 02:00:27 theanets.trainer:168 RmsProp 401 loss=1361.777954 err=617.416321
I 2015-05-27 02:00:59 theanets.trainer:168 RmsProp 402 loss=1363.299683 err=619.893982
I 2015-05-27 02:01:30 theanets.trainer:168 RmsProp 403 loss=1369.172119 err=625.441833
I 2015-05-27 02:02:02 theanets.trainer:168 RmsProp 404 loss=1354.219360 err=610.966064
I 2015-05-27 02:02:33 theanets.trainer:168 RmsProp 405 loss=1361.209839 err=618.179810
I 2015-05-27 02:03:06 theanets.trainer:168 RmsProp 406 loss=1335.784546 err=594.537109
I 2015-05-27 02:03:37 theanets.trainer:168 RmsProp 407 loss=1366.969116 err=625.299011
I 2015-05-27 02:04:09 theanets.trainer:168 RmsProp 408 loss=1375.687744 err=632.761047
I 2015-05-27 02:04:41 theanets.trainer:168 RmsProp 409 loss=1346.658325 err=605.735046
I 2015-05-27 02:05:14 theanets.trainer:168 RmsProp 410 loss=1334.273682 err=595.248840
I 2015-05-27 02:05:14 theanets.trainer:168 validation 41 loss=2056.847168 err=1318.661743 *
I 2015-05-27 02:05:47 theanets.trainer:168 RmsProp 411 loss=1345.412231 err=607.564331
I 2015-05-27 02:06:19 theanets.trainer:168 RmsProp 412 loss=1329.652710 err=593.129272
I 2015-05-27 02:06:51 theanets.trainer:168 RmsProp 413 loss=1332.240112 err=596.076050
I 2015-05-27 02:07:23 theanets.trainer:168 RmsProp 414 loss=1327.560425 err=592.070923
I 2015-05-27 02:07:54 theanets.trainer:168 RmsProp 415 loss=1347.595947 err=610.884949
I 2015-05-27 02:08:26 theanets.trainer:168 RmsProp 416 loss=1359.260498 err=620.688904
I 2015-05-27 02:08:58 theanets.trainer:168 RmsProp 417 loss=1342.735107 err=604.736450
I 2015-05-27 02:09:30 theanets.trainer:168 RmsProp 418 loss=1369.243774 err=630.580139
I 2015-05-27 02:10:01 theanets.trainer:168 RmsProp 419 loss=1351.635498 err=611.971741
I 2015-05-27 02:10:33 theanets.trainer:168 RmsProp 420 loss=1379.209473 err=639.498291
I 2015-05-27 02:10:34 theanets.trainer:168 validation 42 loss=2102.940186 err=1360.965210
I 2015-05-27 02:11:05 theanets.trainer:168 RmsProp 421 loss=1363.087402 err=621.895630
I 2015-05-27 02:11:37 theanets.trainer:168 RmsProp 422 loss=1349.651123 err=610.584717
I 2015-05-27 02:12:08 theanets.trainer:168 RmsProp 423 loss=1352.216919 err=612.939392
I 2015-05-27 02:12:40 theanets.trainer:168 RmsProp 424 loss=1352.610107 err=613.015198
I 2015-05-27 02:13:12 theanets.trainer:168 RmsProp 425 loss=1345.807495 err=606.493469
I 2015-05-27 02:13:43 theanets.trainer:168 RmsProp 426 loss=1341.926025 err=601.681213
I 2015-05-27 02:14:15 theanets.trainer:168 RmsProp 427 loss=1348.717896 err=607.671326
I 2015-05-27 02:14:47 theanets.trainer:168 RmsProp 428 loss=1351.649780 err=610.410889
I 2015-05-27 02:15:19 theanets.trainer:168 RmsProp 429 loss=1345.441284 err=604.147400
I 2015-05-27 02:15:51 theanets.trainer:168 RmsProp 430 loss=1328.588379 err=587.661865
I 2015-05-27 02:15:51 theanets.trainer:168 validation 43 loss=2027.361328 err=1286.473511 *
I 2015-05-27 02:16:18 theanets.trainer:168 RmsProp 431 loss=1337.553467 err=596.682861
I 2015-05-27 02:16:43 theanets.trainer:168 RmsProp 432 loss=1324.542725 err=584.182007
I 2015-05-27 02:17:08 theanets.trainer:168 RmsProp 433 loss=1334.114136 err=593.921509
I 2015-05-27 02:17:33 theanets.trainer:168 RmsProp 434 loss=1350.294922 err=609.206604
I 2015-05-27 02:17:57 theanets.trainer:168 RmsProp 435 loss=1350.633057 err=608.517822
I 2015-05-27 02:18:20 theanets.trainer:168 RmsProp 436 loss=1324.236694 err=583.312134
I 2015-05-27 02:18:42 theanets.trainer:168 RmsProp 437 loss=1315.952759 err=576.319153
I 2015-05-27 02:19:05 theanets.trainer:168 RmsProp 438 loss=1320.116821 err=580.958313
I 2015-05-27 02:19:30 theanets.trainer:168 RmsProp 439 loss=1339.871216 err=599.108459
I 2015-05-27 02:19:54 theanets.trainer:168 RmsProp 440 loss=1318.027588 err=577.672668
I 2015-05-27 02:19:55 theanets.trainer:168 validation 44 loss=2018.586548 err=1278.876343 *
I 2015-05-27 02:20:20 theanets.trainer:168 RmsProp 441 loss=1310.152588 err=570.959778
I 2015-05-27 02:20:45 theanets.trainer:168 RmsProp 442 loss=1318.565796 err=579.443298
I 2015-05-27 02:21:09 theanets.trainer:168 RmsProp 443 loss=1313.623901 err=573.910034
I 2015-05-27 02:21:34 theanets.trainer:168 RmsProp 444 loss=1300.196655 err=561.394409
I 2015-05-27 02:21:58 theanets.trainer:168 RmsProp 445 loss=1303.643921 err=565.112854
I 2015-05-27 02:22:22 theanets.trainer:168 RmsProp 446 loss=1331.317139 err=591.140442
I 2015-05-27 02:22:46 theanets.trainer:168 RmsProp 447 loss=1385.036743 err=641.523682
I 2015-05-27 02:23:11 theanets.trainer:168 RmsProp 448 loss=1369.479004 err=623.235474
I 2015-05-27 02:23:35 theanets.trainer:168 RmsProp 449 loss=1320.639893 err=576.583191
I 2015-05-27 02:23:58 theanets.trainer:168 RmsProp 450 loss=1304.022827 err=562.428711
I 2015-05-27 02:23:59 theanets.trainer:168 validation 45 loss=2068.412842 err=1328.194580
I 2015-05-27 02:24:22 theanets.trainer:168 RmsProp 451 loss=1291.846069 err=552.239807
I 2015-05-27 02:24:47 theanets.trainer:168 RmsProp 452 loss=1289.083130 err=550.501343
I 2015-05-27 02:25:11 theanets.trainer:168 RmsProp 453 loss=1279.826782 err=541.677368
I 2015-05-27 02:25:33 theanets.trainer:168 RmsProp 454 loss=1285.336060 err=547.350159
I 2015-05-27 02:25:55 theanets.trainer:168 RmsProp 455 loss=1302.333618 err=563.856995
I 2015-05-27 02:26:19 theanets.trainer:168 RmsProp 456 loss=1337.812622 err=595.872192
I 2015-05-27 02:26:39 theanets.trainer:168 RmsProp 457 loss=1343.634155 err=598.274231
I 2015-05-27 02:26:58 theanets.trainer:168 RmsProp 458 loss=1316.492676 err=571.861572
I 2015-05-27 02:27:16 theanets.trainer:168 RmsProp 459 loss=1308.675903 err=565.261475
I 2015-05-27 02:27:35 theanets.trainer:168 RmsProp 460 loss=1311.672241 err=568.989380
I 2015-05-27 02:27:35 theanets.trainer:168 validation 46 loss=2102.098877 err=1359.265625
I 2015-05-27 02:27:55 theanets.trainer:168 RmsProp 461 loss=1327.730469 err=583.505127
I 2015-05-27 02:28:13 theanets.trainer:168 RmsProp 462 loss=1315.054443 err=571.270813
I 2015-05-27 02:28:32 theanets.trainer:168 RmsProp 463 loss=1295.439209 err=553.745667
I 2015-05-27 02:28:50 theanets.trainer:168 RmsProp 464 loss=1293.808838 err=552.686707
I 2015-05-27 02:29:10 theanets.trainer:168 RmsProp 465 loss=1288.449463 err=548.522888
I 2015-05-27 02:29:28 theanets.trainer:168 RmsProp 466 loss=1290.247314 err=550.670593
I 2015-05-27 02:29:47 theanets.trainer:168 RmsProp 467 loss=1295.663208 err=556.434265
I 2015-05-27 02:30:05 theanets.trainer:168 RmsProp 468 loss=1278.115601 err=538.844360
I 2015-05-27 02:30:24 theanets.trainer:168 RmsProp 469 loss=1271.932861 err=534.750366
I 2015-05-27 02:30:44 theanets.trainer:168 RmsProp 470 loss=1270.728760 err=533.924988
I 2015-05-27 02:30:44 theanets.trainer:168 validation 47 loss=2023.161133 err=1286.208252
I 2015-05-27 02:31:03 theanets.trainer:168 RmsProp 471 loss=1254.375854 err=517.836670
I 2015-05-27 02:31:22 theanets.trainer:168 RmsProp 472 loss=1262.818726 err=526.755859
I 2015-05-27 02:31:40 theanets.trainer:168 RmsProp 473 loss=1296.830933 err=558.871887
I 2015-05-27 02:31:59 theanets.trainer:168 RmsProp 474 loss=1279.789307 err=542.327698
I 2015-05-27 02:32:17 theanets.trainer:168 RmsProp 475 loss=1271.931030 err=534.684021
I 2015-05-27 02:32:36 theanets.trainer:168 RmsProp 476 loss=1268.017944 err=531.162964
I 2015-05-27 02:32:55 theanets.trainer:168 RmsProp 477 loss=1261.974854 err=525.057800
I 2015-05-27 02:33:13 theanets.trainer:168 RmsProp 478 loss=1260.605957 err=524.967651
I 2015-05-27 02:33:31 theanets.trainer:168 RmsProp 479 loss=1244.792603 err=509.993958
I 2015-05-27 02:33:51 theanets.trainer:168 RmsProp 480 loss=1254.062988 err=519.951477
I 2015-05-27 02:33:51 theanets.trainer:168 validation 48 loss=2057.485840 err=1323.098999
I 2015-05-27 02:34:10 theanets.trainer:168 RmsProp 481 loss=1259.694580 err=525.248291
I 2015-05-27 02:34:28 theanets.trainer:168 RmsProp 482 loss=1254.725708 err=520.507751
I 2015-05-27 02:34:48 theanets.trainer:168 RmsProp 483 loss=1232.009888 err=499.804291
I 2015-05-27 02:35:07 theanets.trainer:168 RmsProp 484 loss=1247.860229 err=516.403931
I 2015-05-27 02:35:26 theanets.trainer:168 RmsProp 485 loss=1246.855835 err=516.087097
I 2015-05-27 02:35:46 theanets.trainer:168 RmsProp 486 loss=1239.303467 err=509.176178
I 2015-05-27 02:36:05 theanets.trainer:168 RmsProp 487 loss=1224.157104 err=494.942444
I 2015-05-27 02:36:25 theanets.trainer:168 RmsProp 488 loss=1224.430420 err=496.684631
I 2015-05-27 02:36:43 theanets.trainer:168 RmsProp 489 loss=1224.813232 err=497.786194
I 2015-05-27 02:37:01 theanets.trainer:168 RmsProp 490 loss=1233.760864 err=506.682129
I 2015-05-27 02:37:02 theanets.trainer:168 validation 49 loss=2006.370117 err=1279.670532 *
I 2015-05-27 02:37:21 theanets.trainer:168 RmsProp 491 loss=1225.428467 err=499.305389
I 2015-05-27 02:37:40 theanets.trainer:168 RmsProp 492 loss=1243.987915 err=517.204895
I 2015-05-27 02:37:59 theanets.trainer:168 RmsProp 493 loss=1240.465088 err=513.233459
I 2015-05-27 02:38:18 theanets.trainer:168 RmsProp 494 loss=1233.865601 err=507.703278
I 2015-05-27 02:38:38 theanets.trainer:168 RmsProp 495 loss=1229.660156 err=503.694733
I 2015-05-27 02:38:58 theanets.trainer:168 RmsProp 496 loss=1223.355347 err=497.584045
I 2015-05-27 02:39:17 theanets.trainer:168 RmsProp 497 loss=1221.674561 err=496.840240
I 2015-05-27 02:39:36 theanets.trainer:168 RmsProp 498 loss=1238.716187 err=513.063049
I 2015-05-27 02:39:56 theanets.trainer:168 RmsProp 499 loss=1236.035522 err=509.039734
I 2015-05-27 02:40:16 theanets.trainer:168 RmsProp 500 loss=1245.270020 err=518.589966
I 2015-05-27 02:40:17 theanets.trainer:168 validation 50 loss=2095.712402 err=1367.689453
I 2015-05-27 02:40:35 theanets.trainer:168 RmsProp 501 loss=1255.212646 err=527.442688
I 2015-05-27 02:40:54 theanets.trainer:168 RmsProp 502 loss=1250.392212 err=523.349548
I 2015-05-27 02:41:12 theanets.trainer:168 RmsProp 503 loss=1271.345337 err=543.633179
I 2015-05-27 02:41:30 theanets.trainer:168 RmsProp 504 loss=1256.869995 err=528.881226
I 2015-05-27 02:41:49 theanets.trainer:168 RmsProp 505 loss=1256.106201 err=527.830688
I 2015-05-27 02:42:08 theanets.trainer:168 RmsProp 506 loss=1241.724854 err=513.935242
I 2015-05-27 02:42:27 theanets.trainer:168 RmsProp 507 loss=1234.708984 err=507.787048
I 2015-05-27 02:42:47 theanets.trainer:168 RmsProp 508 loss=1229.488159 err=503.594452
I 2015-05-27 02:43:06 theanets.trainer:168 RmsProp 509 loss=1230.498779 err=505.213409
I 2015-05-27 02:43:24 theanets.trainer:168 RmsProp 510 loss=1225.578979 err=500.166199
I 2015-05-27 02:43:25 theanets.trainer:168 validation 51 loss=2013.746582 err=1288.662476
I 2015-05-27 02:43:44 theanets.trainer:168 RmsProp 511 loss=1242.164795 err=516.756653
I 2015-05-27 02:44:02 theanets.trainer:168 RmsProp 512 loss=1239.602295 err=514.112122
I 2015-05-27 02:44:20 theanets.trainer:168 RmsProp 513 loss=1254.307129 err=527.174133
I 2015-05-27 02:44:39 theanets.trainer:168 RmsProp 514 loss=1249.033081 err=520.644104
I 2015-05-27 02:44:57 theanets.trainer:168 RmsProp 515 loss=1214.770752 err=487.555328
I 2015-05-27 02:45:15 theanets.trainer:168 RmsProp 516 loss=1225.970581 err=500.474518
I 2015-05-27 02:45:34 theanets.trainer:168 RmsProp 517 loss=1219.608154 err=495.057770
I 2015-05-27 02:45:53 theanets.trainer:168 RmsProp 518 loss=1237.539673 err=513.065063
I 2015-05-27 02:46:13 theanets.trainer:168 RmsProp 519 loss=1224.552002 err=500.367279
I 2015-05-27 02:46:31 theanets.trainer:168 RmsProp 520 loss=1274.971924 err=546.574951
I 2015-05-27 02:46:32 theanets.trainer:168 validation 52 loss=2045.259888 err=1314.725464
I 2015-05-27 02:46:50 theanets.trainer:168 RmsProp 521 loss=1253.124634 err=524.144470
I 2015-05-27 02:47:09 theanets.trainer:168 RmsProp 522 loss=1235.551636 err=508.296692
I 2015-05-27 02:47:27 theanets.trainer:168 RmsProp 523 loss=1235.237427 err=508.643555
I 2015-05-27 02:47:45 theanets.trainer:168 RmsProp 524 loss=1215.489502 err=491.126038
I 2015-05-27 02:48:03 theanets.trainer:168 RmsProp 525 loss=1212.967163 err=489.532379
I 2015-05-27 02:48:22 theanets.trainer:168 RmsProp 526 loss=1199.343506 err=477.569458
I 2015-05-27 02:48:41 theanets.trainer:168 RmsProp 527 loss=1209.704224 err=488.224609
I 2015-05-27 02:49:00 theanets.trainer:168 RmsProp 528 loss=1218.644531 err=497.253784
I 2015-05-27 02:49:19 theanets.trainer:168 RmsProp 529 loss=1213.195923 err=492.098938
I 2015-05-27 02:49:37 theanets.trainer:168 RmsProp 530 loss=1217.463013 err=496.694183
I 2015-05-27 02:49:38 theanets.trainer:168 validation 53 loss=1948.143066 err=1226.603394 *
I 2015-05-27 02:49:57 theanets.trainer:168 RmsProp 531 loss=1200.476318 err=480.401245
I 2015-05-27 02:50:15 theanets.trainer:168 RmsProp 532 loss=1182.839355 err=465.228424
I 2015-05-27 02:50:34 theanets.trainer:168 RmsProp 533 loss=1217.289795 err=499.533905
I 2015-05-27 02:50:52 theanets.trainer:168 RmsProp 534 loss=1228.861206 err=507.706909
I 2015-05-27 02:51:11 theanets.trainer:168 RmsProp 535 loss=1222.111816 err=499.729950
I 2015-05-27 02:51:29 theanets.trainer:168 RmsProp 536 loss=1253.902832 err=528.803894
I 2015-05-27 02:51:48 theanets.trainer:168 RmsProp 537 loss=1239.153564 err=515.479248
I 2015-05-27 02:52:08 theanets.trainer:168 RmsProp 538 loss=1290.348145 err=564.505493
I 2015-05-27 02:52:26 theanets.trainer:168 RmsProp 539 loss=1337.377319 err=603.934631
I 2015-05-27 02:52:45 theanets.trainer:168 RmsProp 540 loss=1272.104248 err=540.301453
I 2015-05-27 02:52:46 theanets.trainer:168 validation 54 loss=1981.516602 err=1252.115479
I 2015-05-27 02:53:05 theanets.trainer:168 RmsProp 541 loss=1249.648804 err=521.429382
I 2015-05-27 02:53:24 theanets.trainer:168 RmsProp 542 loss=1256.561646 err=528.773621
I 2015-05-27 02:53:42 theanets.trainer:168 RmsProp 543 loss=1258.073364 err=528.652893
I 2015-05-27 02:54:02 theanets.trainer:168 RmsProp 544 loss=1252.511963 err=523.661560
I 2015-05-27 02:54:20 theanets.trainer:168 RmsProp 545 loss=1232.333496 err=504.544464
I 2015-05-27 02:54:40 theanets.trainer:168 RmsProp 546 loss=1221.840332 err=496.070404
I 2015-05-27 02:54:59 theanets.trainer:168 RmsProp 547 loss=1216.314575 err=491.925690
I 2015-05-27 02:55:18 theanets.trainer:168 RmsProp 548 loss=1212.333618 err=488.705231
I 2015-05-27 02:55:36 theanets.trainer:168 RmsProp 549 loss=1228.157593 err=505.257141
I 2015-05-27 02:55:55 theanets.trainer:168 RmsProp 550 loss=1225.381348 err=501.847229
I 2015-05-27 02:55:56 theanets.trainer:168 validation 55 loss=2012.264282 err=1289.292358
I 2015-05-27 02:56:15 theanets.trainer:168 RmsProp 551 loss=1219.087158 err=496.518158
I 2015-05-27 02:56:34 theanets.trainer:168 RmsProp 552 loss=1208.589355 err=487.170776
I 2015-05-27 02:56:52 theanets.trainer:168 RmsProp 553 loss=1195.050415 err=475.980621
I 2015-05-27 02:57:11 theanets.trainer:168 RmsProp 554 loss=1203.974609 err=485.589294
I 2015-05-27 02:57:29 theanets.trainer:168 RmsProp 555 loss=1195.486328 err=477.146667
I 2015-05-27 02:57:48 theanets.trainer:168 RmsProp 556 loss=1194.967285 err=477.230011
I 2015-05-27 02:58:09 theanets.trainer:168 RmsProp 557 loss=1195.452393 err=477.155945
I 2015-05-27 02:58:28 theanets.trainer:168 RmsProp 558 loss=1186.606201 err=469.418976
I 2015-05-27 02:58:47 theanets.trainer:168 RmsProp 559 loss=1178.141846 err=462.257202
I 2015-05-27 02:59:07 theanets.trainer:168 RmsProp 560 loss=1181.267822 err=466.575256
I 2015-05-27 02:59:07 theanets.trainer:168 validation 56 loss=2019.470093 err=1305.058105
I 2015-05-27 02:59:26 theanets.trainer:168 RmsProp 561 loss=1182.391724 err=467.450256
I 2015-05-27 02:59:45 theanets.trainer:168 RmsProp 562 loss=1180.455688 err=465.108734
I 2015-05-27 03:00:05 theanets.trainer:168 RmsProp 563 loss=1194.504028 err=478.793121
I 2015-05-27 03:00:24 theanets.trainer:168 RmsProp 564 loss=1187.890503 err=472.977020
I 2015-05-27 03:00:42 theanets.trainer:168 RmsProp 565 loss=1178.929688 err=464.816345
I 2015-05-27 03:01:00 theanets.trainer:168 RmsProp 566 loss=1183.503418 err=469.307617
I 2015-05-27 03:01:19 theanets.trainer:168 RmsProp 567 loss=1174.211548 err=460.684723
I 2015-05-27 03:01:36 theanets.trainer:168 RmsProp 568 loss=1164.498657 err=452.018250
I 2015-05-27 03:01:53 theanets.trainer:168 RmsProp 569 loss=1164.645142 err=452.932251
I 2015-05-27 03:02:11 theanets.trainer:168 RmsProp 570 loss=1180.518311 err=468.187775
I 2015-05-27 03:02:11 theanets.trainer:168 validation 57 loss=2005.141235 err=1291.786499
I 2015-05-27 03:02:29 theanets.trainer:168 RmsProp 571 loss=1174.531250 err=461.626343
I 2015-05-27 03:02:47 theanets.trainer:168 RmsProp 572 loss=1166.226807 err=454.788177
I 2015-05-27 03:03:04 theanets.trainer:168 RmsProp 573 loss=1171.204468 err=459.576996
I 2015-05-27 03:03:21 theanets.trainer:168 RmsProp 574 loss=1198.611084 err=485.939636
I 2015-05-27 03:03:38 theanets.trainer:168 RmsProp 575 loss=1201.116943 err=485.175018
I 2015-05-27 03:03:56 theanets.trainer:168 RmsProp 576 loss=1175.236084 err=460.070923
I 2015-05-27 03:04:13 theanets.trainer:168 RmsProp 577 loss=1168.453369 err=455.460480
I 2015-05-27 03:04:31 theanets.trainer:168 RmsProp 578 loss=1177.107910 err=464.900909
I 2015-05-27 03:04:50 theanets.trainer:168 RmsProp 579 loss=1163.499390 err=451.724945
I 2015-05-27 03:05:09 theanets.trainer:168 RmsProp 580 loss=1168.055542 err=457.263947
I 2015-05-27 03:05:09 theanets.trainer:168 validation 58 loss=2085.237549 err=1374.244507
I 2015-05-27 03:05:09 theanets.trainer:252 patience elapsed!
I 2015-05-27 03:05:09 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-27 03:05:09 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-27 03:05:09 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-27 03:05:09 theanets.main:89 --algorithms = rmsprop
I 2015-05-27 03:05:09 theanets.main:89 --batch_size = 1024
I 2015-05-27 03:05:09 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-27 03:05:09 theanets.main:89 --hidden_l1 = None
I 2015-05-27 03:05:09 theanets.main:89 --learning_rate = 0.0001
I 2015-05-27 03:05:09 theanets.main:89 --train_batches = 10
I 2015-05-27 03:05:09 theanets.main:89 --valid_batches = 2
I 2015-05-27 03:05:09 theanets.main:89 --weight_l1 = 0.01
I 2015-05-27 03:05:09 theanets.main:89 --weight_l2 = 0.001
I 2015-05-27 03:05:09 theanets.trainer:134 compiling evaluation function
I 2015-05-27 03:05:15 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-27 03:06:32 theanets.trainer:168 validation 0 loss=2001.238525 err=1279.698853 *
I 2015-05-27 03:06:37 theanets.trainer:168 RmsProp 1 loss=990.689758 err=272.705872
I 2015-05-27 03:06:43 theanets.trainer:168 RmsProp 2 loss=892.830200 err=178.288284
I 2015-05-27 03:06:49 theanets.trainer:168 RmsProp 3 loss=851.377258 err=139.261810
I 2015-05-27 03:06:55 theanets.trainer:168 RmsProp 4 loss=822.515320 err=112.379639
I 2015-05-27 03:07:00 theanets.trainer:168 RmsProp 5 loss=803.259460 err=95.057327
I 2015-05-27 03:07:06 theanets.trainer:168 RmsProp 6 loss=786.549194 err=80.407104
I 2015-05-27 03:07:12 theanets.trainer:168 RmsProp 7 loss=770.774841 err=66.997772
I 2015-05-27 03:07:17 theanets.trainer:168 RmsProp 8 loss=758.828491 err=57.820976
I 2015-05-27 03:07:23 theanets.trainer:168 RmsProp 9 loss=747.810608 err=49.874428
I 2015-05-27 03:07:28 theanets.trainer:168 RmsProp 10 loss=738.425110 err=43.643791
I 2015-05-27 03:07:29 theanets.trainer:168 validation 1 loss=1595.806641 err=902.760437 *
I 2015-05-27 03:07:34 theanets.trainer:168 RmsProp 11 loss=729.939941 err=38.315269
I 2015-05-27 03:07:40 theanets.trainer:168 RmsProp 12 loss=723.476196 err=35.143360
I 2015-05-27 03:07:46 theanets.trainer:168 RmsProp 13 loss=717.316345 err=32.436398
I 2015-05-27 03:07:52 theanets.trainer:168 RmsProp 14 loss=711.253052 err=29.858526
I 2015-05-27 03:07:58 theanets.trainer:168 RmsProp 15 loss=705.150818 err=27.257721
I 2015-05-27 03:08:03 theanets.trainer:168 RmsProp 16 loss=700.607544 err=26.227182
I 2015-05-27 03:08:09 theanets.trainer:168 RmsProp 17 loss=695.509583 err=24.566992
I 2015-05-27 03:08:14 theanets.trainer:168 RmsProp 18 loss=690.009888 err=22.427267
I 2015-05-27 03:08:20 theanets.trainer:168 RmsProp 19 loss=686.071167 err=21.902237
I 2015-05-27 03:08:27 theanets.trainer:168 RmsProp 20 loss=681.287964 err=20.612377
I 2015-05-27 03:08:27 theanets.trainer:168 validation 2 loss=1507.369141 err=848.614868 *
I 2015-05-27 03:08:32 theanets.trainer:168 RmsProp 21 loss=676.709595 err=19.532803
I 2015-05-27 03:08:38 theanets.trainer:168 RmsProp 22 loss=672.314087 err=18.670292
I 2015-05-27 03:08:44 theanets.trainer:168 RmsProp 23 loss=667.803589 err=17.656092
I 2015-05-27 03:08:49 theanets.trainer:168 RmsProp 24 loss=664.031677 err=17.369066
I 2015-05-27 03:08:55 theanets.trainer:168 RmsProp 25 loss=659.399780 err=16.098804
I 2015-05-27 03:09:00 theanets.trainer:168 RmsProp 26 loss=655.509460 err=15.540133
I 2015-05-27 03:09:06 theanets.trainer:168 RmsProp 27 loss=652.574219 err=16.031477
I 2015-05-27 03:09:12 theanets.trainer:168 RmsProp 28 loss=648.268921 err=14.961499
I 2015-05-27 03:09:18 theanets.trainer:168 RmsProp 29 loss=644.864624 err=14.643822
I 2015-05-27 03:09:25 theanets.trainer:168 RmsProp 30 loss=641.196533 err=14.038442
I 2015-05-27 03:09:25 theanets.trainer:168 validation 3 loss=1453.151855 err=827.671082 *
I 2015-05-27 03:09:31 theanets.trainer:168 RmsProp 31 loss=637.270813 err=13.229258
I 2015-05-27 03:09:36 theanets.trainer:168 RmsProp 32 loss=634.500427 err=13.696451
I 2015-05-27 03:09:42 theanets.trainer:168 RmsProp 33 loss=630.412476 err=12.697107
I 2015-05-27 03:09:47 theanets.trainer:168 RmsProp 34 loss=627.246948 err=12.568819
I 2015-05-27 03:09:53 theanets.trainer:168 RmsProp 35 loss=623.907288 err=12.245745
I 2015-05-27 03:09:59 theanets.trainer:168 RmsProp 36 loss=620.424255 err=11.753047
I 2015-05-27 03:10:05 theanets.trainer:168 RmsProp 37 loss=617.624512 err=11.983474
I 2015-05-27 03:10:10 theanets.trainer:168 RmsProp 38 loss=614.223206 err=11.521424
I 2015-05-27 03:10:16 theanets.trainer:168 RmsProp 39 loss=610.955200 err=11.154418
I 2015-05-27 03:10:22 theanets.trainer:168 RmsProp 40 loss=607.551086 err=10.594482
I 2015-05-27 03:10:22 theanets.trainer:168 validation 4 loss=1410.334595 err=814.981689 *
I 2015-05-27 03:10:28 theanets.trainer:168 RmsProp 41 loss=605.428772 err=11.419714
I 2015-05-27 03:10:34 theanets.trainer:168 RmsProp 42 loss=601.890991 err=10.672594
I 2015-05-27 03:10:39 theanets.trainer:168 RmsProp 43 loss=598.755127 err=10.239622
I 2015-05-27 03:10:45 theanets.trainer:168 RmsProp 44 loss=595.581177 err=9.851800
I 2015-05-27 03:10:52 theanets.trainer:168 RmsProp 45 loss=594.176880 err=11.292950
I 2015-05-27 03:10:58 theanets.trainer:168 RmsProp 46 loss=590.364258 err=10.129644
I 2015-05-27 03:11:04 theanets.trainer:168 RmsProp 47 loss=587.264465 err=9.486998
I 2015-05-27 03:11:10 theanets.trainer:168 RmsProp 48 loss=584.779175 err=9.494147
I 2015-05-27 03:11:16 theanets.trainer:168 RmsProp 49 loss=582.165894 err=9.490442
I 2015-05-27 03:11:23 theanets.trainer:168 RmsProp 50 loss=579.292786 err=9.245788
I 2015-05-27 03:11:23 theanets.trainer:168 validation 5 loss=1374.759399 err=806.160278 *
I 2015-05-27 03:11:29 theanets.trainer:168 RmsProp 51 loss=576.506531 err=9.095887
I 2015-05-27 03:11:35 theanets.trainer:168 RmsProp 52 loss=573.338379 err=8.558809
I 2015-05-27 03:11:41 theanets.trainer:168 RmsProp 53 loss=571.418152 err=9.299956
I 2015-05-27 03:11:47 theanets.trainer:168 RmsProp 54 loss=568.222961 err=8.655002
I 2015-05-27 03:11:53 theanets.trainer:168 RmsProp 55 loss=565.465942 err=8.425287
I 2015-05-27 03:11:58 theanets.trainer:168 RmsProp 56 loss=563.227783 err=8.752412
I 2015-05-27 03:12:04 theanets.trainer:168 RmsProp 57 loss=560.777039 err=8.764817
I 2015-05-27 03:12:09 theanets.trainer:168 RmsProp 58 loss=557.767700 err=8.136273
I 2015-05-27 03:12:15 theanets.trainer:168 RmsProp 59 loss=555.240173 err=7.990465
I 2015-05-27 03:12:21 theanets.trainer:168 RmsProp 60 loss=553.015381 err=8.220590
I 2015-05-27 03:12:21 theanets.trainer:168 validation 6 loss=1336.907349 err=793.465332 *
I 2015-05-27 03:12:27 theanets.trainer:168 RmsProp 61 loss=550.285156 err=7.954700
I 2015-05-27 03:12:32 theanets.trainer:168 RmsProp 62 loss=547.671509 err=7.733551
I 2015-05-27 03:12:38 theanets.trainer:168 RmsProp 63 loss=545.418152 err=7.874162
I 2015-05-27 03:12:44 theanets.trainer:168 RmsProp 64 loss=542.856812 err=7.689725
I 2015-05-27 03:12:51 theanets.trainer:168 RmsProp 65 loss=540.424622 err=7.608840
I 2015-05-27 03:12:57 theanets.trainer:168 RmsProp 66 loss=538.329346 err=7.820930
I 2015-05-27 03:13:03 theanets.trainer:168 RmsProp 67 loss=535.526428 err=7.266306
I 2015-05-27 03:13:09 theanets.trainer:168 RmsProp 68 loss=533.440613 err=7.443923
I 2015-05-27 03:13:15 theanets.trainer:168 RmsProp 69 loss=531.198792 err=7.464122
I 2015-05-27 03:13:21 theanets.trainer:168 RmsProp 70 loss=528.610779 err=7.124706
I 2015-05-27 03:13:22 theanets.trainer:168 validation 7 loss=1307.996338 err=787.740723 *
I 2015-05-27 03:13:27 theanets.trainer:168 RmsProp 71 loss=526.299988 err=7.058703
I 2015-05-27 03:13:33 theanets.trainer:168 RmsProp 72 loss=524.520630 err=7.543988
I 2015-05-27 03:13:40 theanets.trainer:168 RmsProp 73 loss=522.138550 err=7.324206
I 2015-05-27 03:13:45 theanets.trainer:168 RmsProp 74 loss=519.567444 err=6.806089
I 2015-05-27 03:13:51 theanets.trainer:168 RmsProp 75 loss=517.647339 err=6.985558
I 2015-05-27 03:13:56 theanets.trainer:168 RmsProp 76 loss=515.506897 err=6.956803
I 2015-05-27 03:14:01 theanets.trainer:168 RmsProp 77 loss=513.047241 err=6.607408
I 2015-05-27 03:14:07 theanets.trainer:168 RmsProp 78 loss=511.371094 err=7.064912
I 2015-05-27 03:14:12 theanets.trainer:168 RmsProp 79 loss=508.630035 err=6.409833
I 2015-05-27 03:14:18 theanets.trainer:168 RmsProp 80 loss=506.872253 err=6.749393
I 2015-05-27 03:14:18 theanets.trainer:168 validation 8 loss=1278.634521 err=779.666199 *
I 2015-05-27 03:14:24 theanets.trainer:168 RmsProp 81 loss=504.542297 err=6.514678
I 2015-05-27 03:14:30 theanets.trainer:168 RmsProp 82 loss=502.897888 err=6.964994
I 2015-05-27 03:14:36 theanets.trainer:168 RmsProp 83 loss=500.286713 err=6.366524
I 2015-05-27 03:14:42 theanets.trainer:168 RmsProp 84 loss=498.477600 err=6.532107
I 2015-05-27 03:14:49 theanets.trainer:168 RmsProp 85 loss=496.624664 err=6.625452
I 2015-05-27 03:14:55 theanets.trainer:168 RmsProp 86 loss=494.334381 err=6.237842
I 2015-05-27 03:15:01 theanets.trainer:168 RmsProp 87 loss=492.550293 err=6.398852
I 2015-05-27 03:15:07 theanets.trainer:168 RmsProp 88 loss=490.565582 err=6.373632
I 2015-05-27 03:15:13 theanets.trainer:168 RmsProp 89 loss=488.198090 err=5.934586
I 2015-05-27 03:15:19 theanets.trainer:168 RmsProp 90 loss=487.498383 err=7.215917
I 2015-05-27 03:15:19 theanets.trainer:168 validation 9 loss=1257.594727 err=778.361023 *
I 2015-05-27 03:15:26 theanets.trainer:168 RmsProp 91 loss=484.767029 err=6.334920
I 2015-05-27 03:15:32 theanets.trainer:168 RmsProp 92 loss=482.535645 err=5.839274
I 2015-05-27 03:15:38 theanets.trainer:168 RmsProp 93 loss=480.952576 err=6.045197
I 2015-05-27 03:15:44 theanets.trainer:168 RmsProp 94 loss=479.799164 err=6.742034
I 2015-05-27 03:15:50 theanets.trainer:168 RmsProp 95 loss=477.222656 err=5.913019
I 2015-05-27 03:15:57 theanets.trainer:168 RmsProp 96 loss=475.495911 err=5.907228
I 2015-05-27 03:16:02 theanets.trainer:168 RmsProp 97 loss=473.701324 err=5.888616
I 2015-05-27 03:16:08 theanets.trainer:168 RmsProp 98 loss=471.870911 err=5.855006
I 2015-05-27 03:16:13 theanets.trainer:168 RmsProp 99 loss=470.022156 err=5.835028
I 2015-05-27 03:16:20 theanets.trainer:168 RmsProp 100 loss=468.244293 err=5.875527
I 2015-05-27 03:16:20 theanets.trainer:168 validation 10 loss=1235.539551 err=774.155212 *
I 2015-05-27 03:16:26 theanets.trainer:168 RmsProp 101 loss=466.254150 err=5.696725
I 2015-05-27 03:16:32 theanets.trainer:168 RmsProp 102 loss=464.764252 err=6.009656
I 2015-05-27 03:16:38 theanets.trainer:168 RmsProp 103 loss=462.816467 err=5.784125
I 2015-05-27 03:16:44 theanets.trainer:168 RmsProp 104 loss=460.939453 err=5.599689
I 2015-05-27 03:16:50 theanets.trainer:168 RmsProp 105 loss=459.395599 err=5.731723
I 2015-05-27 03:16:57 theanets.trainer:168 RmsProp 106 loss=457.552490 err=5.587964
I 2015-05-27 03:17:03 theanets.trainer:168 RmsProp 107 loss=455.945404 err=5.654909
I 2015-05-27 03:17:09 theanets.trainer:168 RmsProp 108 loss=454.473724 err=5.844424
I 2015-05-27 03:17:15 theanets.trainer:168 RmsProp 109 loss=452.313782 err=5.291995
I 2015-05-27 03:17:22 theanets.trainer:168 RmsProp 110 loss=451.066589 err=5.656387
I 2015-05-27 03:17:22 theanets.trainer:168 validation 11 loss=1218.580444 err=774.065735 *
I 2015-05-27 03:17:28 theanets.trainer:168 RmsProp 111 loss=449.586609 err=5.796956
I 2015-05-27 03:17:33 theanets.trainer:168 RmsProp 112 loss=447.603210 err=5.367117
I 2015-05-27 03:17:39 theanets.trainer:168 RmsProp 113 loss=446.151062 err=5.478621
I 2015-05-27 03:17:45 theanets.trainer:168 RmsProp 114 loss=444.450500 err=5.351986
I 2015-05-27 03:17:50 theanets.trainer:168 RmsProp 115 loss=442.860291 err=5.328894
I 2015-05-27 03:17:56 theanets.trainer:168 RmsProp 116 loss=441.733246 err=5.791030
I 2015-05-27 03:18:02 theanets.trainer:168 RmsProp 117 loss=439.643738 err=5.229864
I 2015-05-27 03:18:09 theanets.trainer:168 RmsProp 118 loss=438.257996 err=5.353782
I 2015-05-27 03:18:15 theanets.trainer:168 RmsProp 119 loss=436.865326 err=5.460445
I 2015-05-27 03:18:21 theanets.trainer:168 RmsProp 120 loss=435.121094 err=5.209881
I 2015-05-27 03:18:22 theanets.trainer:168 validation 12 loss=1198.648193 err=769.562683 *
I 2015-05-27 03:18:27 theanets.trainer:168 RmsProp 121 loss=433.647858 err=5.237815
I 2015-05-27 03:18:34 theanets.trainer:168 RmsProp 122 loss=432.240875 err=5.315298
I 2015-05-27 03:18:40 theanets.trainer:168 RmsProp 123 loss=430.523865 err=5.073431
I 2015-05-27 03:18:46 theanets.trainer:168 RmsProp 124 loss=429.240875 err=5.261590
I 2015-05-27 03:18:52 theanets.trainer:168 RmsProp 125 loss=427.287689 err=4.799254
I 2015-05-27 03:18:59 theanets.trainer:168 RmsProp 126 loss=426.870270 err=5.859841
I 2015-05-27 03:19:05 theanets.trainer:168 RmsProp 127 loss=424.645081 err=5.029177
I 2015-05-27 03:19:11 theanets.trainer:168 RmsProp 128 loss=423.307037 err=5.072916
I 2015-05-27 03:19:17 theanets.trainer:168 RmsProp 129 loss=421.943542 err=5.107783
I 2015-05-27 03:19:23 theanets.trainer:168 RmsProp 130 loss=420.435547 err=5.014565
I 2015-05-27 03:19:24 theanets.trainer:168 validation 13 loss=1180.882080 err=766.225891 *
I 2015-05-27 03:19:30 theanets.trainer:168 RmsProp 131 loss=419.010651 err=4.985469
I 2015-05-27 03:19:35 theanets.trainer:168 RmsProp 132 loss=417.839020 err=5.237854
I 2015-05-27 03:19:41 theanets.trainer:168 RmsProp 133 loss=416.237732 err=5.032056
I 2015-05-27 03:19:47 theanets.trainer:168 RmsProp 134 loss=414.856293 err=4.991818
I 2015-05-27 03:19:53 theanets.trainer:168 RmsProp 135 loss=413.427887 err=4.925238
I 2015-05-27 03:19:59 theanets.trainer:168 RmsProp 136 loss=412.107819 err=4.962514
I 2015-05-27 03:20:04 theanets.trainer:168 RmsProp 137 loss=410.328552 err=4.542694
I 2015-05-27 03:20:10 theanets.trainer:168 RmsProp 138 loss=410.329437 err=5.885045
I 2015-05-27 03:20:15 theanets.trainer:168 RmsProp 139 loss=408.290344 err=5.102769
I 2015-05-27 03:20:21 theanets.trainer:168 RmsProp 140 loss=406.743011 err=4.768517
I 2015-05-27 03:20:22 theanets.trainer:168 validation 14 loss=1167.059937 err=765.744812 *
I 2015-05-27 03:20:27 theanets.trainer:168 RmsProp 141 loss=405.509949 err=4.771328
I 2015-05-27 03:20:33 theanets.trainer:168 RmsProp 142 loss=404.306976 err=4.864959
I 2015-05-27 03:20:38 theanets.trainer:168 RmsProp 143 loss=402.973785 err=4.831979
I 2015-05-27 03:20:44 theanets.trainer:168 RmsProp 144 loss=401.399078 err=4.574343
I 2015-05-27 03:20:51 theanets.trainer:168 RmsProp 145 loss=400.618286 err=5.121809
I 2015-05-27 03:20:57 theanets.trainer:168 RmsProp 146 loss=398.938232 err=4.728112
I 2015-05-27 03:21:03 theanets.trainer:168 RmsProp 147 loss=397.614258 err=4.668272
I 2015-05-27 03:21:08 theanets.trainer:168 RmsProp 148 loss=396.433105 err=4.752007
I 2015-05-27 03:21:14 theanets.trainer:168 RmsProp 149 loss=395.228455 err=4.816071
I 2015-05-27 03:21:19 theanets.trainer:168 RmsProp 150 loss=394.068390 err=4.890944
I 2015-05-27 03:21:20 theanets.trainer:168 validation 15 loss=1150.071899 err=761.560486 *
I 2015-05-27 03:21:25 theanets.trainer:168 RmsProp 151 loss=392.595337 err=4.631335
I 2015-05-27 03:21:30 theanets.trainer:168 RmsProp 152 loss=391.444641 err=4.682759
I 2015-05-27 03:21:36 theanets.trainer:168 RmsProp 153 loss=390.214539 err=4.651590
I 2015-05-27 03:21:41 theanets.trainer:168 RmsProp 154 loss=389.123230 err=4.766225
I 2015-05-27 03:21:46 theanets.trainer:168 RmsProp 155 loss=387.973846 err=4.808230
I 2015-05-27 03:21:51 theanets.trainer:168 RmsProp 156 loss=386.658600 err=4.661490
I 2015-05-27 03:21:55 theanets.trainer:168 RmsProp 157 loss=385.473145 err=4.623309
I 2015-05-27 03:21:59 theanets.trainer:168 RmsProp 158 loss=384.331024 err=4.636407
I 2015-05-27 03:22:04 theanets.trainer:168 RmsProp 159 loss=383.151031 err=4.606292
I 2015-05-27 03:22:08 theanets.trainer:168 RmsProp 160 loss=382.090790 err=4.696639
I 2015-05-27 03:22:08 theanets.trainer:168 validation 16 loss=1135.177856 err=758.410156 *
I 2015-05-27 03:22:12 theanets.trainer:168 RmsProp 161 loss=381.003845 err=4.750388
I 2015-05-27 03:22:17 theanets.trainer:168 RmsProp 162 loss=379.599091 err=4.463597
I 2015-05-27 03:22:21 theanets.trainer:168 RmsProp 163 loss=378.199707 err=4.181137
I 2015-05-27 03:22:26 theanets.trainer:168 RmsProp 164 loss=378.957581 err=6.073540
I 2015-05-27 03:22:31 theanets.trainer:168 RmsProp 165 loss=376.779541 err=4.938040
I 2015-05-27 03:22:36 theanets.trainer:168 RmsProp 166 loss=375.259644 err=4.383150
I 2015-05-27 03:22:41 theanets.trainer:168 RmsProp 167 loss=374.197235 err=4.312115
I 2015-05-27 03:22:46 theanets.trainer:168 RmsProp 168 loss=373.389404 err=4.556319
I 2015-05-27 03:22:51 theanets.trainer:168 RmsProp 169 loss=372.293488 err=4.543037
I 2015-05-27 03:22:56 theanets.trainer:168 RmsProp 170 loss=371.067688 err=4.396959
I 2015-05-27 03:22:56 theanets.trainer:168 validation 17 loss=1128.401123 err=762.328064 *
I 2015-05-27 03:23:01 theanets.trainer:168 RmsProp 171 loss=370.110291 err=4.528862
I 2015-05-27 03:23:06 theanets.trainer:168 RmsProp 172 loss=369.473694 err=4.952551
I 2015-05-27 03:23:12 theanets.trainer:168 RmsProp 173 loss=368.064484 err=4.555641
I 2015-05-27 03:23:17 theanets.trainer:168 RmsProp 174 loss=367.001312 err=4.491225
I 2015-05-27 03:23:22 theanets.trainer:168 RmsProp 175 loss=365.873047 err=4.362939
I 2015-05-27 03:23:27 theanets.trainer:168 RmsProp 176 loss=364.818146 err=4.339814
I 2015-05-27 03:23:32 theanets.trainer:168 RmsProp 177 loss=364.015076 err=4.578019
I 2015-05-27 03:23:37 theanets.trainer:168 RmsProp 178 loss=362.766449 err=4.353610
I 2015-05-27 03:23:42 theanets.trainer:168 RmsProp 179 loss=361.877991 err=4.458650
I 2015-05-27 03:23:48 theanets.trainer:168 RmsProp 180 loss=361.204651 err=4.770486
I 2015-05-27 03:23:48 theanets.trainer:168 validation 18 loss=1117.583008 err=761.672485 *
I 2015-05-27 03:23:52 theanets.trainer:168 RmsProp 181 loss=359.930969 err=4.462164
I 2015-05-27 03:23:57 theanets.trainer:168 RmsProp 182 loss=358.934967 err=4.405450
I 2015-05-27 03:24:02 theanets.trainer:168 RmsProp 183 loss=357.972412 err=4.403121
I 2015-05-27 03:24:08 theanets.trainer:168 RmsProp 184 loss=357.027863 err=4.406819
I 2015-05-27 03:24:13 theanets.trainer:168 RmsProp 185 loss=355.942200 err=4.282436
I 2015-05-27 03:24:18 theanets.trainer:168 RmsProp 186 loss=355.149811 err=4.465326
I 2015-05-27 03:24:22 theanets.trainer:168 RmsProp 187 loss=354.077515 err=4.357348
I 2015-05-27 03:24:27 theanets.trainer:168 RmsProp 188 loss=353.125793 err=4.369236
I 2015-05-27 03:24:33 theanets.trainer:168 RmsProp 189 loss=352.407288 err=4.581688
I 2015-05-27 03:24:38 theanets.trainer:168 RmsProp 190 loss=351.157349 err=4.250388
I 2015-05-27 03:24:38 theanets.trainer:168 validation 19 loss=1103.325073 err=756.932129 *
I 2015-05-27 03:24:43 theanets.trainer:168 RmsProp 191 loss=350.047424 err=4.063370
I 2015-05-27 03:24:48 theanets.trainer:168 RmsProp 192 loss=349.624695 err=4.568647
I 2015-05-27 03:24:53 theanets.trainer:168 RmsProp 193 loss=348.405701 err=4.274030
I 2015-05-27 03:24:58 theanets.trainer:168 RmsProp 194 loss=347.447632 err=4.235452
I 2015-05-27 03:25:03 theanets.trainer:168 RmsProp 195 loss=346.782196 err=4.502149
I 2015-05-27 03:25:09 theanets.trainer:168 RmsProp 196 loss=345.465546 err=4.081346
I 2015-05-27 03:25:14 theanets.trainer:168 RmsProp 197 loss=344.873352 err=4.390017
I 2015-05-27 03:25:19 theanets.trainer:168 RmsProp 198 loss=343.550842 err=3.969910
I 2015-05-27 03:25:24 theanets.trainer:168 RmsProp 199 loss=342.943390 err=4.264506
I 2015-05-27 03:25:29 theanets.trainer:168 RmsProp 200 loss=341.975311 err=4.214792
I 2015-05-27 03:25:30 theanets.trainer:168 validation 20 loss=1102.625977 err=765.356628 *
I 2015-05-27 03:25:34 theanets.trainer:168 RmsProp 201 loss=341.175232 err=4.317815
I 2015-05-27 03:25:39 theanets.trainer:168 RmsProp 202 loss=340.235901 err=4.268789
I 2015-05-27 03:25:45 theanets.trainer:168 RmsProp 203 loss=339.124817 err=4.031903
I 2015-05-27 03:25:50 theanets.trainer:168 RmsProp 204 loss=338.395599 err=4.175279
I 2015-05-27 03:25:55 theanets.trainer:168 RmsProp 205 loss=337.543396 err=4.197990
I 2015-05-27 03:26:00 theanets.trainer:168 RmsProp 206 loss=336.616119 err=4.141527
I 2015-05-27 03:26:05 theanets.trainer:168 RmsProp 207 loss=336.047058 err=4.450952
I 2015-05-27 03:26:10 theanets.trainer:168 RmsProp 208 loss=334.902985 err=4.148387
I 2015-05-27 03:26:16 theanets.trainer:168 RmsProp 209 loss=333.843811 err=3.925316
I 2015-05-27 03:26:21 theanets.trainer:168 RmsProp 210 loss=333.279572 err=4.208812
I 2015-05-27 03:26:21 theanets.trainer:168 validation 21 loss=1087.941406 err=759.321411 *
I 2015-05-27 03:26:26 theanets.trainer:168 RmsProp 211 loss=332.164001 err=3.943587
I 2015-05-27 03:26:31 theanets.trainer:168 RmsProp 212 loss=332.032379 err=4.664003
I 2015-05-27 03:26:36 theanets.trainer:168 RmsProp 213 loss=330.434387 err=3.884474
I 2015-05-27 03:26:41 theanets.trainer:168 RmsProp 214 loss=329.995544 err=4.259043
I 2015-05-27 03:26:46 theanets.trainer:168 RmsProp 215 loss=329.276306 err=4.339769
I 2015-05-27 03:26:52 theanets.trainer:168 RmsProp 216 loss=328.274261 err=4.124056
I 2015-05-27 03:26:57 theanets.trainer:168 RmsProp 217 loss=327.670013 err=4.292395
I 2015-05-27 03:27:02 theanets.trainer:168 RmsProp 218 loss=326.710632 err=4.100207
I 2015-05-27 03:27:07 theanets.trainer:168 RmsProp 219 loss=326.048798 err=4.213591
I 2015-05-27 03:27:12 theanets.trainer:168 RmsProp 220 loss=325.042542 err=3.973373
I 2015-05-27 03:27:13 theanets.trainer:168 validation 22 loss=1088.380859 err=767.742126
I 2015-05-27 03:27:17 theanets.trainer:168 RmsProp 221 loss=324.238556 err=3.962489
I 2015-05-27 03:27:23 theanets.trainer:168 RmsProp 222 loss=323.749176 err=4.272326
I 2015-05-27 03:27:28 theanets.trainer:168 RmsProp 223 loss=322.935150 err=4.249981
I 2015-05-27 03:27:33 theanets.trainer:168 RmsProp 224 loss=322.029633 err=4.104325
I 2015-05-27 03:27:38 theanets.trainer:168 RmsProp 225 loss=321.057953 err=3.882888
I 2015-05-27 03:27:43 theanets.trainer:168 RmsProp 226 loss=320.465820 err=4.051402
I 2015-05-27 03:27:48 theanets.trainer:168 RmsProp 227 loss=319.882477 err=4.229218
I 2015-05-27 03:27:53 theanets.trainer:168 RmsProp 228 loss=319.171692 err=4.271302
I 2015-05-27 03:27:59 theanets.trainer:168 RmsProp 229 loss=318.061584 err=3.888373
I 2015-05-27 03:28:04 theanets.trainer:168 RmsProp 230 loss=317.552460 err=4.118187
I 2015-05-27 03:28:04 theanets.trainer:168 validation 23 loss=1084.154907 err=771.131409 *
I 2015-05-27 03:28:09 theanets.trainer:168 RmsProp 231 loss=316.829041 err=4.139655
I 2015-05-27 03:28:14 theanets.trainer:168 RmsProp 232 loss=315.839111 err=3.884712
I 2015-05-27 03:28:20 theanets.trainer:168 RmsProp 233 loss=315.347595 err=4.135762
I 2015-05-27 03:28:25 theanets.trainer:168 RmsProp 234 loss=314.488831 err=4.009659
I 2015-05-27 03:28:30 theanets.trainer:168 RmsProp 235 loss=313.788757 err=4.029221
I 2015-05-27 03:28:35 theanets.trainer:168 RmsProp 236 loss=312.995544 err=3.953413
I 2015-05-27 03:28:40 theanets.trainer:168 RmsProp 237 loss=312.307465 err=3.994725
I 2015-05-27 03:28:45 theanets.trainer:168 RmsProp 238 loss=311.787689 err=4.198815
I 2015-05-27 03:28:51 theanets.trainer:168 RmsProp 239 loss=311.100433 err=4.216075
I 2015-05-27 03:28:56 theanets.trainer:168 RmsProp 240 loss=310.074646 err=3.882741
I 2015-05-27 03:28:56 theanets.trainer:168 validation 24 loss=1078.946655 err=773.113281 *
I 2015-05-27 03:29:01 theanets.trainer:168 RmsProp 241 loss=309.486755 err=3.977483
I 2015-05-27 03:29:06 theanets.trainer:168 RmsProp 242 loss=308.590942 err=3.784229
I 2015-05-27 03:29:11 theanets.trainer:168 RmsProp 243 loss=308.156250 err=4.063862
I 2015-05-27 03:29:17 theanets.trainer:168 RmsProp 244 loss=307.767517 err=4.380988
I 2015-05-27 03:29:22 theanets.trainer:168 RmsProp 245 loss=306.609436 err=3.901917
I 2015-05-27 03:29:27 theanets.trainer:168 RmsProp 246 loss=305.801910 err=3.764065
I 2015-05-27 03:29:32 theanets.trainer:168 RmsProp 247 loss=305.256622 err=3.901906
I 2015-05-27 03:29:37 theanets.trainer:168 RmsProp 248 loss=304.671295 err=4.012282
I 2015-05-27 03:29:42 theanets.trainer:168 RmsProp 249 loss=303.945129 err=3.977098
I 2015-05-27 03:29:46 theanets.trainer:168 RmsProp 250 loss=302.907043 err=3.614518
I 2015-05-27 03:29:47 theanets.trainer:168 validation 25 loss=1073.269287 err=774.355774 *
I 2015-05-27 03:29:51 theanets.trainer:168 RmsProp 251 loss=302.978607 err=4.367500
I 2015-05-27 03:29:55 theanets.trainer:168 RmsProp 252 loss=301.930328 err=3.986308
I 2015-05-27 03:30:00 theanets.trainer:168 RmsProp 253 loss=301.174744 err=3.880219
I 2015-05-27 03:30:04 theanets.trainer:168 RmsProp 254 loss=300.588654 err=3.952740
I 2015-05-27 03:30:09 theanets.trainer:168 RmsProp 255 loss=299.916687 err=3.942210
I 2015-05-27 03:30:14 theanets.trainer:168 RmsProp 256 loss=299.171814 err=3.849765
I 2015-05-27 03:30:19 theanets.trainer:168 RmsProp 257 loss=298.683289 err=4.000012
I 2015-05-27 03:30:25 theanets.trainer:168 RmsProp 258 loss=298.145508 err=4.099149
I 2015-05-27 03:30:30 theanets.trainer:168 RmsProp 259 loss=297.235901 err=3.815294
I 2015-05-27 03:30:35 theanets.trainer:168 RmsProp 260 loss=296.713043 err=3.930611
I 2015-05-27 03:30:35 theanets.trainer:168 validation 26 loss=1073.011719 err=780.591614 *
I 2015-05-27 03:30:40 theanets.trainer:168 RmsProp 261 loss=296.017883 err=3.874844
I 2015-05-27 03:30:45 theanets.trainer:168 RmsProp 262 loss=295.366760 err=3.848506
I 2015-05-27 03:30:50 theanets.trainer:168 RmsProp 263 loss=294.759216 err=3.868955
I 2015-05-27 03:30:56 theanets.trainer:168 RmsProp 264 loss=294.366547 err=4.098346
I 2015-05-27 03:31:01 theanets.trainer:168 RmsProp 265 loss=293.461792 err=3.815147
I 2015-05-27 03:31:06 theanets.trainer:168 RmsProp 266 loss=293.054169 err=4.027593
I 2015-05-27 03:31:11 theanets.trainer:168 RmsProp 267 loss=292.309418 err=3.895236
I 2015-05-27 03:31:16 theanets.trainer:168 RmsProp 268 loss=291.613190 err=3.795322
I 2015-05-27 03:31:21 theanets.trainer:168 RmsProp 269 loss=291.060028 err=3.838925
I 2015-05-27 03:31:27 theanets.trainer:168 RmsProp 270 loss=290.331909 err=3.728142
I 2015-05-27 03:31:27 theanets.trainer:168 validation 27 loss=1074.267334 err=787.981934
I 2015-05-27 03:31:32 theanets.trainer:168 RmsProp 271 loss=289.702545 err=3.711528
I 2015-05-27 03:31:37 theanets.trainer:168 RmsProp 272 loss=289.339691 err=3.969989
I 2015-05-27 03:31:42 theanets.trainer:168 RmsProp 273 loss=288.523590 err=3.765369
I 2015-05-27 03:31:47 theanets.trainer:168 RmsProp 274 loss=288.166809 err=4.013417
I 2015-05-27 03:31:52 theanets.trainer:168 RmsProp 275 loss=287.270508 err=3.715065
I 2015-05-27 03:31:58 theanets.trainer:168 RmsProp 276 loss=286.867889 err=3.912350
I 2015-05-27 03:32:03 theanets.trainer:168 RmsProp 277 loss=286.627808 err=4.261454
I 2015-05-27 03:32:08 theanets.trainer:168 RmsProp 278 loss=285.523285 err=3.724256
I 2015-05-27 03:32:13 theanets.trainer:168 RmsProp 279 loss=285.141144 err=3.913176
I 2015-05-27 03:32:18 theanets.trainer:168 RmsProp 280 loss=284.455994 err=3.797857
I 2015-05-27 03:32:18 theanets.trainer:168 validation 28 loss=1076.182495 err=795.833496
I 2015-05-27 03:32:23 theanets.trainer:168 RmsProp 281 loss=283.966644 err=3.882476
I 2015-05-27 03:32:28 theanets.trainer:168 RmsProp 282 loss=283.060547 err=3.558367
I 2015-05-27 03:32:34 theanets.trainer:168 RmsProp 283 loss=282.956238 err=4.034733
I 2015-05-27 03:32:39 theanets.trainer:168 RmsProp 284 loss=282.244720 err=3.902353
I 2015-05-27 03:32:44 theanets.trainer:168 RmsProp 285 loss=281.540649 err=3.764893
I 2015-05-27 03:32:48 theanets.trainer:168 RmsProp 286 loss=280.908112 err=3.699574
I 2015-05-27 03:32:53 theanets.trainer:168 RmsProp 287 loss=280.549561 err=3.908282
I 2015-05-27 03:32:58 theanets.trainer:168 RmsProp 288 loss=279.893372 err=3.825901
I 2015-05-27 03:33:03 theanets.trainer:168 RmsProp 289 loss=279.166931 err=3.666259
I 2015-05-27 03:33:09 theanets.trainer:168 RmsProp 290 loss=278.698700 err=3.761872
I 2015-05-27 03:33:09 theanets.trainer:168 validation 29 loss=1074.443726 err=799.816345
I 2015-05-27 03:33:14 theanets.trainer:168 RmsProp 291 loss=278.316650 err=3.945592
I 2015-05-27 03:33:19 theanets.trainer:168 RmsProp 292 loss=277.466309 err=3.645341
I 2015-05-27 03:33:24 theanets.trainer:168 RmsProp 293 loss=277.062439 err=3.791440
I 2015-05-27 03:33:29 theanets.trainer:168 RmsProp 294 loss=276.325226 err=3.605523
I 2015-05-27 03:33:34 theanets.trainer:168 RmsProp 295 loss=276.212830 err=4.037631
I 2015-05-27 03:33:39 theanets.trainer:168 RmsProp 296 loss=275.469208 err=3.833082
I 2015-05-27 03:33:45 theanets.trainer:168 RmsProp 297 loss=274.736328 err=3.623441
I 2015-05-27 03:33:50 theanets.trainer:168 RmsProp 298 loss=274.299713 err=3.721664
I 2015-05-27 03:33:55 theanets.trainer:168 RmsProp 299 loss=273.709412 err=3.669332
I 2015-05-27 03:34:00 theanets.trainer:168 RmsProp 300 loss=273.506744 err=4.008346
I 2015-05-27 03:34:01 theanets.trainer:168 validation 30 loss=1069.452148 err=800.233337 *
I 2015-05-27 03:34:05 theanets.trainer:168 RmsProp 301 loss=272.653503 err=3.688319
I 2015-05-27 03:34:10 theanets.trainer:168 RmsProp 302 loss=271.911316 err=3.479043
I 2015-05-27 03:34:15 theanets.trainer:168 RmsProp 303 loss=271.791199 err=3.900117
I 2015-05-27 03:34:20 theanets.trainer:168 RmsProp 304 loss=271.204010 err=3.844996
I 2015-05-27 03:34:24 theanets.trainer:168 RmsProp 305 loss=270.624603 err=3.788288
I 2015-05-27 03:34:29 theanets.trainer:168 RmsProp 306 loss=270.059357 err=3.735336
I 2015-05-27 03:34:33 theanets.trainer:168 RmsProp 307 loss=269.614777 err=3.803853
I 2015-05-27 03:34:38 theanets.trainer:168 RmsProp 308 loss=268.661682 err=3.357957
I 2015-05-27 03:34:44 theanets.trainer:168 RmsProp 309 loss=268.631439 err=3.845309
I 2015-05-27 03:34:49 theanets.trainer:168 RmsProp 310 loss=267.910095 err=3.645080
I 2015-05-27 03:34:49 theanets.trainer:168 validation 31 loss=1072.708740 err=808.725037
I 2015-05-27 03:34:54 theanets.trainer:168 RmsProp 311 loss=267.533875 err=3.779668
I 2015-05-27 03:34:59 theanets.trainer:168 RmsProp 312 loss=266.835876 err=3.594187
I 2015-05-27 03:35:04 theanets.trainer:168 RmsProp 313 loss=266.692688 err=3.953202
I 2015-05-27 03:35:09 theanets.trainer:168 RmsProp 314 loss=266.134796 err=3.893943
I 2015-05-27 03:35:13 theanets.trainer:168 RmsProp 315 loss=265.260071 err=3.507987
I 2015-05-27 03:35:18 theanets.trainer:168 RmsProp 316 loss=265.219574 err=3.955172
I 2015-05-27 03:35:23 theanets.trainer:168 RmsProp 317 loss=264.617371 err=3.834217
I 2015-05-27 03:35:29 theanets.trainer:168 RmsProp 318 loss=263.919128 err=3.611048
I 2015-05-27 03:35:34 theanets.trainer:168 RmsProp 319 loss=263.646851 err=3.818743
I 2015-05-27 03:35:39 theanets.trainer:168 RmsProp 320 loss=262.920715 err=3.569621
I 2015-05-27 03:35:39 theanets.trainer:168 validation 32 loss=1071.640503 err=812.551208
I 2015-05-27 03:35:44 theanets.trainer:168 RmsProp 321 loss=262.323944 err=3.460360
I 2015-05-27 03:35:49 theanets.trainer:168 RmsProp 322 loss=262.580505 err=4.190928
I 2015-05-27 03:35:54 theanets.trainer:168 RmsProp 323 loss=261.669495 err=3.742564
I 2015-05-27 03:35:59 theanets.trainer:168 RmsProp 324 loss=260.985138 err=3.521096
I 2015-05-27 03:36:04 theanets.trainer:168 RmsProp 325 loss=260.920135 err=3.919951
I 2015-05-27 03:36:09 theanets.trainer:168 RmsProp 326 loss=260.133301 err=3.604907
I 2015-05-27 03:36:14 theanets.trainer:168 RmsProp 327 loss=259.697906 err=3.630640
I 2015-05-27 03:36:20 theanets.trainer:168 RmsProp 328 loss=259.279114 err=3.675609
I 2015-05-27 03:36:25 theanets.trainer:168 RmsProp 329 loss=258.940247 err=3.790594
I 2015-05-27 03:36:30 theanets.trainer:168 RmsProp 330 loss=258.207916 err=3.523980
I 2015-05-27 03:36:30 theanets.trainer:168 validation 33 loss=1073.185791 err=818.759277
I 2015-05-27 03:36:35 theanets.trainer:168 RmsProp 331 loss=258.210785 err=3.990292
I 2015-05-27 03:36:40 theanets.trainer:168 RmsProp 332 loss=257.670807 err=3.903339
I 2015-05-27 03:36:45 theanets.trainer:168 RmsProp 333 loss=256.916382 err=3.597392
I 2015-05-27 03:36:51 theanets.trainer:168 RmsProp 334 loss=256.235657 err=3.353101
I 2015-05-27 03:36:56 theanets.trainer:168 RmsProp 335 loss=256.411072 err=3.981966
I 2015-05-27 03:37:01 theanets.trainer:168 RmsProp 336 loss=255.632126 err=3.651866
I 2015-05-27 03:37:06 theanets.trainer:168 RmsProp 337 loss=255.115280 err=3.582804
I 2015-05-27 03:37:11 theanets.trainer:168 RmsProp 338 loss=254.316254 err=3.245499
I 2015-05-27 03:37:16 theanets.trainer:168 RmsProp 339 loss=254.701691 err=4.088042
I 2015-05-27 03:37:21 theanets.trainer:168 RmsProp 340 loss=253.858521 err=3.694478
I 2015-05-27 03:37:22 theanets.trainer:168 validation 34 loss=1072.629639 err=822.705017
I 2015-05-27 03:37:26 theanets.trainer:168 RmsProp 341 loss=253.449753 err=3.717761
I 2015-05-27 03:37:32 theanets.trainer:168 RmsProp 342 loss=252.701813 err=3.407123
I 2015-05-27 03:37:37 theanets.trainer:168 RmsProp 343 loss=252.693207 err=3.835165
I 2015-05-27 03:37:42 theanets.trainer:168 RmsProp 344 loss=252.253586 err=3.828999
I 2015-05-27 03:37:47 theanets.trainer:168 RmsProp 345 loss=251.682327 err=3.684823
I 2015-05-27 03:37:52 theanets.trainer:168 RmsProp 346 loss=251.116974 err=3.540054
I 2015-05-27 03:37:58 theanets.trainer:168 RmsProp 347 loss=251.083282 err=3.926459
I 2015-05-27 03:38:03 theanets.trainer:168 RmsProp 348 loss=250.163742 err=3.423159
I 2015-05-27 03:38:08 theanets.trainer:168 RmsProp 349 loss=250.044952 err=3.725664
I 2015-05-27 03:38:13 theanets.trainer:168 RmsProp 350 loss=249.465164 err=3.563082
I 2015-05-27 03:38:13 theanets.trainer:168 validation 35 loss=1074.554932 err=828.879578
I 2015-05-27 03:38:13 theanets.trainer:252 patience elapsed!
I 2015-05-27 03:38:13 theanets.main:237 models_deep_post_code_sep/95112-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 03:38:13 theanets.graph:477 models_deep_post_code_sep/95112-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
