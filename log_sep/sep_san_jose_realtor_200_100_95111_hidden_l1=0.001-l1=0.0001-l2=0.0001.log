I 2015-05-26 03:35:24 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 03:35:24 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:24 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:24 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 03:35:24 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:24 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:24 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 03:35:24 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 03:35:24 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95111-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl
I 2015-05-26 03:35:24 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 03:35:24 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 03:35:24 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 03:35:24 theanets.main:89 --batch_size = 1024
I 2015-05-26 03:35:24 theanets.main:89 --gradient_clip = 1
I 2015-05-26 03:35:24 theanets.main:89 --hidden_l1 = None
I 2015-05-26 03:35:24 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 03:35:24 theanets.main:89 --train_batches = 30
I 2015-05-26 03:35:24 theanets.main:89 --valid_batches = 3
I 2015-05-26 03:35:24 theanets.main:89 --weight_l1 = None
I 2015-05-26 03:35:24 theanets.main:89 --weight_l2 = None
I 2015-05-26 03:35:25 theanets.trainer:134 compiling evaluation function
I 2015-05-26 03:35:39 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 03:38:49 theanets.trainer:168 validation 0 loss=14153.301758 err=14153.301758 *
I 2015-05-26 03:39:45 theanets.trainer:168 RmsProp 1 loss=13223.602539 err=13223.602539
I 2015-05-26 03:40:44 theanets.trainer:168 RmsProp 2 loss=13202.089844 err=13202.089844
I 2015-05-26 03:41:43 theanets.trainer:168 RmsProp 3 loss=12661.614258 err=12661.614258
I 2015-05-26 03:42:42 theanets.trainer:168 RmsProp 4 loss=11138.691406 err=11138.691406
I 2015-05-26 03:43:41 theanets.trainer:168 RmsProp 5 loss=10436.281250 err=10436.281250
I 2015-05-26 03:44:39 theanets.trainer:168 RmsProp 6 loss=9708.337891 err=9708.337891
I 2015-05-26 03:45:37 theanets.trainer:168 RmsProp 7 loss=9215.520508 err=9215.520508
I 2015-05-26 03:46:36 theanets.trainer:168 RmsProp 8 loss=8466.460938 err=8466.460938
I 2015-05-26 03:47:35 theanets.trainer:168 RmsProp 9 loss=7859.697754 err=7859.697754
I 2015-05-26 03:48:33 theanets.trainer:168 RmsProp 10 loss=7035.981445 err=7035.981445
I 2015-05-26 03:48:34 theanets.trainer:168 validation 1 loss=6290.747559 err=6290.747559 *
I 2015-05-26 03:49:33 theanets.trainer:168 RmsProp 11 loss=6412.263672 err=6412.263672
I 2015-05-26 03:50:32 theanets.trainer:168 RmsProp 12 loss=5919.625488 err=5919.625488
I 2015-05-26 03:51:32 theanets.trainer:168 RmsProp 13 loss=5535.586426 err=5535.586426
I 2015-05-26 03:52:32 theanets.trainer:168 RmsProp 14 loss=5106.543457 err=5106.543457
I 2015-05-26 03:53:32 theanets.trainer:168 RmsProp 15 loss=4676.668457 err=4676.668457
I 2015-05-26 03:54:32 theanets.trainer:168 RmsProp 16 loss=4290.243652 err=4290.243652
I 2015-05-26 03:55:31 theanets.trainer:168 RmsProp 17 loss=3993.168213 err=3993.168213
I 2015-05-26 03:56:32 theanets.trainer:168 RmsProp 18 loss=3722.516602 err=3722.516602
I 2015-05-26 03:57:32 theanets.trainer:168 RmsProp 19 loss=3462.851562 err=3462.851562
I 2015-05-26 03:58:32 theanets.trainer:168 RmsProp 20 loss=3271.906738 err=3271.906738
I 2015-05-26 03:58:33 theanets.trainer:168 validation 2 loss=3434.210205 err=3434.210205 *
I 2015-05-26 03:59:32 theanets.trainer:168 RmsProp 21 loss=3069.621094 err=3069.621094
I 2015-05-26 04:00:31 theanets.trainer:168 RmsProp 22 loss=2929.562500 err=2929.562500
I 2015-05-26 04:01:31 theanets.trainer:168 RmsProp 23 loss=2718.125000 err=2718.125000
I 2015-05-26 04:02:31 theanets.trainer:168 RmsProp 24 loss=2559.932129 err=2559.932129
I 2015-05-26 04:03:31 theanets.trainer:168 RmsProp 25 loss=2399.585449 err=2399.585449
I 2015-05-26 04:04:31 theanets.trainer:168 RmsProp 26 loss=2307.453613 err=2307.453613
I 2015-05-26 04:05:30 theanets.trainer:168 RmsProp 27 loss=2158.762207 err=2158.762207
I 2015-05-26 04:06:30 theanets.trainer:168 RmsProp 28 loss=2073.514893 err=2073.514893
I 2015-05-26 04:07:29 theanets.trainer:168 RmsProp 29 loss=2046.900269 err=2046.900269
I 2015-05-26 04:08:29 theanets.trainer:168 RmsProp 30 loss=1911.430786 err=1911.430786
I 2015-05-26 04:08:30 theanets.trainer:168 validation 3 loss=2774.691650 err=2774.691650 *
I 2015-05-26 04:09:29 theanets.trainer:168 RmsProp 31 loss=1799.311646 err=1799.311646
I 2015-05-26 04:10:28 theanets.trainer:168 RmsProp 32 loss=1767.933594 err=1767.933594
I 2015-05-26 04:11:27 theanets.trainer:168 RmsProp 33 loss=1683.433838 err=1683.433838
I 2015-05-26 04:12:25 theanets.trainer:168 RmsProp 34 loss=1603.762573 err=1603.762573
I 2015-05-26 04:13:22 theanets.trainer:168 RmsProp 35 loss=1524.694824 err=1524.694824
I 2015-05-26 04:14:18 theanets.trainer:168 RmsProp 36 loss=1450.996338 err=1450.996338
I 2015-05-26 04:15:13 theanets.trainer:168 RmsProp 37 loss=1387.748779 err=1387.748779
I 2015-05-26 04:16:08 theanets.trainer:168 RmsProp 38 loss=1349.555054 err=1349.555054
I 2015-05-26 04:17:03 theanets.trainer:168 RmsProp 39 loss=1260.723877 err=1260.723877
I 2015-05-26 04:17:58 theanets.trainer:168 RmsProp 40 loss=1218.726685 err=1218.726685
I 2015-05-26 04:17:59 theanets.trainer:168 validation 4 loss=2621.651611 err=2621.651611 *
I 2015-05-26 04:18:54 theanets.trainer:168 RmsProp 41 loss=1159.652832 err=1159.652832
I 2015-05-26 04:19:50 theanets.trainer:168 RmsProp 42 loss=1117.175415 err=1117.175415
I 2015-05-26 04:20:46 theanets.trainer:168 RmsProp 43 loss=1069.617310 err=1069.617310
I 2015-05-26 04:21:42 theanets.trainer:168 RmsProp 44 loss=1028.307861 err=1028.307861
I 2015-05-26 04:22:37 theanets.trainer:168 RmsProp 45 loss=999.439514 err=999.439514
I 2015-05-26 04:23:28 theanets.trainer:168 RmsProp 46 loss=961.000549 err=961.000549
I 2015-05-26 04:24:20 theanets.trainer:168 RmsProp 47 loss=915.778198 err=915.778198
I 2015-05-26 04:25:12 theanets.trainer:168 RmsProp 48 loss=883.641296 err=883.641296
I 2015-05-26 04:26:04 theanets.trainer:168 RmsProp 49 loss=844.542297 err=844.542297
I 2015-05-26 04:26:57 theanets.trainer:168 RmsProp 50 loss=830.576782 err=830.576782
I 2015-05-26 04:26:58 theanets.trainer:168 validation 5 loss=2325.084717 err=2325.084717 *
I 2015-05-26 04:27:49 theanets.trainer:168 RmsProp 51 loss=798.720581 err=798.720581
I 2015-05-26 04:28:40 theanets.trainer:168 RmsProp 52 loss=763.049072 err=763.049072
I 2015-05-26 04:29:31 theanets.trainer:168 RmsProp 53 loss=764.294373 err=764.294373
I 2015-05-26 04:30:23 theanets.trainer:168 RmsProp 54 loss=717.784058 err=717.784058
I 2015-05-26 04:31:15 theanets.trainer:168 RmsProp 55 loss=695.098999 err=695.098999
I 2015-05-26 04:32:06 theanets.trainer:168 RmsProp 56 loss=674.434998 err=674.434998
I 2015-05-26 04:32:57 theanets.trainer:168 RmsProp 57 loss=671.056580 err=671.056580
I 2015-05-26 04:33:49 theanets.trainer:168 RmsProp 58 loss=636.392578 err=636.392578
I 2015-05-26 04:34:40 theanets.trainer:168 RmsProp 59 loss=611.863220 err=611.863220
I 2015-05-26 04:35:33 theanets.trainer:168 RmsProp 60 loss=593.331299 err=593.331299
I 2015-05-26 04:35:34 theanets.trainer:168 validation 6 loss=2194.482422 err=2194.482422 *
I 2015-05-26 04:36:26 theanets.trainer:168 RmsProp 61 loss=581.696411 err=581.696411
I 2015-05-26 04:37:19 theanets.trainer:168 RmsProp 62 loss=561.169617 err=561.169617
I 2015-05-26 04:38:11 theanets.trainer:168 RmsProp 63 loss=553.421448 err=553.421448
I 2015-05-26 04:39:03 theanets.trainer:168 RmsProp 64 loss=531.012512 err=531.012512
I 2015-05-26 04:39:57 theanets.trainer:168 RmsProp 65 loss=505.796173 err=505.796173
I 2015-05-26 04:40:49 theanets.trainer:168 RmsProp 66 loss=486.254608 err=486.254608
I 2015-05-26 04:41:41 theanets.trainer:168 RmsProp 67 loss=491.277405 err=491.277405
I 2015-05-26 04:42:35 theanets.trainer:168 RmsProp 68 loss=478.165009 err=478.165009
I 2015-05-26 04:43:28 theanets.trainer:168 RmsProp 69 loss=448.961029 err=448.961029
I 2015-05-26 04:44:21 theanets.trainer:168 RmsProp 70 loss=444.760529 err=444.760529
I 2015-05-26 04:44:22 theanets.trainer:168 validation 7 loss=1977.953003 err=1977.953003 *
I 2015-05-26 04:45:14 theanets.trainer:168 RmsProp 71 loss=432.203827 err=432.203827
I 2015-05-26 04:46:07 theanets.trainer:168 RmsProp 72 loss=420.681763 err=420.681763
I 2015-05-26 04:47:00 theanets.trainer:168 RmsProp 73 loss=408.751251 err=408.751251
I 2015-05-26 04:47:52 theanets.trainer:168 RmsProp 74 loss=397.307648 err=397.307648
I 2015-05-26 04:48:44 theanets.trainer:168 RmsProp 75 loss=389.138153 err=389.138153
I 2015-05-26 04:49:37 theanets.trainer:168 RmsProp 76 loss=374.828491 err=374.828491
I 2015-05-26 04:50:30 theanets.trainer:168 RmsProp 77 loss=370.177917 err=370.177917
I 2015-05-26 04:51:22 theanets.trainer:168 RmsProp 78 loss=360.295959 err=360.295959
I 2015-05-26 04:52:15 theanets.trainer:168 RmsProp 79 loss=351.966827 err=351.966827
I 2015-05-26 04:53:08 theanets.trainer:168 RmsProp 80 loss=342.815155 err=342.815155
I 2015-05-26 04:53:09 theanets.trainer:168 validation 8 loss=1826.419556 err=1826.419556 *
I 2015-05-26 04:54:00 theanets.trainer:168 RmsProp 81 loss=342.446259 err=342.446259
I 2015-05-26 04:54:52 theanets.trainer:168 RmsProp 82 loss=350.700378 err=350.700378
I 2015-05-26 04:55:43 theanets.trainer:168 RmsProp 83 loss=332.299316 err=332.299316
I 2015-05-26 04:56:33 theanets.trainer:168 RmsProp 84 loss=328.782257 err=328.782257
I 2015-05-26 04:57:24 theanets.trainer:168 RmsProp 85 loss=319.270081 err=319.270081
I 2015-05-26 04:58:15 theanets.trainer:168 RmsProp 86 loss=309.091492 err=309.091492
I 2015-05-26 04:59:06 theanets.trainer:168 RmsProp 87 loss=299.867279 err=299.867279
I 2015-05-26 04:59:57 theanets.trainer:168 RmsProp 88 loss=295.731781 err=295.731781
I 2015-05-26 05:00:47 theanets.trainer:168 RmsProp 89 loss=282.722534 err=282.722534
I 2015-05-26 05:01:39 theanets.trainer:168 RmsProp 90 loss=277.574097 err=277.574097
I 2015-05-26 05:01:40 theanets.trainer:168 validation 9 loss=1784.810913 err=1784.810913 *
I 2015-05-26 05:02:30 theanets.trainer:168 RmsProp 91 loss=271.753265 err=271.753265
I 2015-05-26 05:03:20 theanets.trainer:168 RmsProp 92 loss=265.969055 err=265.969055
I 2015-05-26 05:04:12 theanets.trainer:168 RmsProp 93 loss=264.368866 err=264.368866
I 2015-05-26 05:05:04 theanets.trainer:168 RmsProp 94 loss=262.231659 err=262.231659
I 2015-05-26 05:05:56 theanets.trainer:168 RmsProp 95 loss=254.425308 err=254.425308
I 2015-05-26 05:06:48 theanets.trainer:168 RmsProp 96 loss=250.348938 err=250.348938
I 2015-05-26 05:07:39 theanets.trainer:168 RmsProp 97 loss=243.150696 err=243.150696
I 2015-05-26 05:08:29 theanets.trainer:168 RmsProp 98 loss=246.640518 err=246.640518
I 2015-05-26 05:09:19 theanets.trainer:168 RmsProp 99 loss=244.763809 err=244.763809
I 2015-05-26 05:10:09 theanets.trainer:168 RmsProp 100 loss=234.503006 err=234.503006
I 2015-05-26 05:10:10 theanets.trainer:168 validation 10 loss=1561.385620 err=1561.385620 *
I 2015-05-26 05:11:00 theanets.trainer:168 RmsProp 101 loss=222.661102 err=222.661102
I 2015-05-26 05:11:49 theanets.trainer:168 RmsProp 102 loss=222.342514 err=222.342514
I 2015-05-26 05:12:37 theanets.trainer:168 RmsProp 103 loss=214.596481 err=214.596481
I 2015-05-26 05:13:26 theanets.trainer:168 RmsProp 104 loss=212.016815 err=212.016815
I 2015-05-26 05:14:16 theanets.trainer:168 RmsProp 105 loss=205.998001 err=205.998001
I 2015-05-26 05:15:06 theanets.trainer:168 RmsProp 106 loss=203.296219 err=203.296219
I 2015-05-26 05:15:56 theanets.trainer:168 RmsProp 107 loss=197.778488 err=197.778488
I 2015-05-26 05:16:45 theanets.trainer:168 RmsProp 108 loss=194.437653 err=194.437653
I 2015-05-26 05:17:35 theanets.trainer:168 RmsProp 109 loss=188.344482 err=188.344482
I 2015-05-26 05:18:25 theanets.trainer:168 RmsProp 110 loss=187.227310 err=187.227310
I 2015-05-26 05:18:26 theanets.trainer:168 validation 11 loss=1601.659668 err=1601.659668
I 2015-05-26 05:19:15 theanets.trainer:168 RmsProp 111 loss=182.744308 err=182.744308
I 2015-05-26 05:20:04 theanets.trainer:168 RmsProp 112 loss=177.259460 err=177.259460
I 2015-05-26 05:20:53 theanets.trainer:168 RmsProp 113 loss=174.094452 err=174.094452
I 2015-05-26 05:21:44 theanets.trainer:168 RmsProp 114 loss=172.325912 err=172.325912
I 2015-05-26 05:22:33 theanets.trainer:168 RmsProp 115 loss=165.136871 err=165.136871
I 2015-05-26 05:23:23 theanets.trainer:168 RmsProp 116 loss=162.209457 err=162.209457
I 2015-05-26 05:24:13 theanets.trainer:168 RmsProp 117 loss=159.045517 err=159.045517
I 2015-05-26 05:25:03 theanets.trainer:168 RmsProp 118 loss=157.248779 err=157.248779
I 2015-05-26 05:25:53 theanets.trainer:168 RmsProp 119 loss=153.238831 err=153.238831
I 2015-05-26 05:26:42 theanets.trainer:168 RmsProp 120 loss=149.194336 err=149.194336
I 2015-05-26 05:26:43 theanets.trainer:168 validation 12 loss=1585.642456 err=1585.642456
I 2015-05-26 05:27:33 theanets.trainer:168 RmsProp 121 loss=146.718964 err=146.718964
I 2015-05-26 05:28:23 theanets.trainer:168 RmsProp 122 loss=142.067307 err=142.067307
I 2015-05-26 05:29:13 theanets.trainer:168 RmsProp 123 loss=140.842957 err=140.842957
I 2015-05-26 05:30:03 theanets.trainer:168 RmsProp 124 loss=137.814606 err=137.814606
I 2015-05-26 05:30:53 theanets.trainer:168 RmsProp 125 loss=135.517929 err=135.517929
I 2015-05-26 05:31:44 theanets.trainer:168 RmsProp 126 loss=129.533783 err=129.533783
I 2015-05-26 05:32:33 theanets.trainer:168 RmsProp 127 loss=128.405838 err=128.405838
I 2015-05-26 05:33:24 theanets.trainer:168 RmsProp 128 loss=125.098633 err=125.098633
I 2015-05-26 05:34:13 theanets.trainer:168 RmsProp 129 loss=120.357582 err=120.357582
I 2015-05-26 05:35:04 theanets.trainer:168 RmsProp 130 loss=119.019302 err=119.019302
I 2015-05-26 05:35:05 theanets.trainer:168 validation 13 loss=1455.558594 err=1455.558594 *
I 2015-05-26 05:35:55 theanets.trainer:168 RmsProp 131 loss=118.174492 err=118.174492
I 2015-05-26 05:36:44 theanets.trainer:168 RmsProp 132 loss=112.315956 err=112.315956
I 2015-05-26 05:37:32 theanets.trainer:168 RmsProp 133 loss=110.957367 err=110.957367
I 2015-05-26 05:38:20 theanets.trainer:168 RmsProp 134 loss=110.685951 err=110.685951
I 2015-05-26 05:39:07 theanets.trainer:168 RmsProp 135 loss=107.407440 err=107.407440
I 2015-05-26 05:39:54 theanets.trainer:168 RmsProp 136 loss=104.940025 err=104.940025
I 2015-05-26 05:40:42 theanets.trainer:168 RmsProp 137 loss=103.034996 err=103.034996
I 2015-05-26 05:41:29 theanets.trainer:168 RmsProp 138 loss=99.776176 err=99.776176
I 2015-05-26 05:42:16 theanets.trainer:168 RmsProp 139 loss=98.752975 err=98.752975
I 2015-05-26 05:43:03 theanets.trainer:168 RmsProp 140 loss=98.918129 err=98.918129
I 2015-05-26 05:43:04 theanets.trainer:168 validation 14 loss=1472.185425 err=1472.185425
I 2015-05-26 05:43:52 theanets.trainer:168 RmsProp 141 loss=96.662712 err=96.662712
I 2015-05-26 05:44:39 theanets.trainer:168 RmsProp 142 loss=93.747215 err=93.747215
I 2015-05-26 05:45:26 theanets.trainer:168 RmsProp 143 loss=91.286789 err=91.286789
I 2015-05-26 05:46:14 theanets.trainer:168 RmsProp 144 loss=89.880661 err=89.880661
I 2015-05-26 05:47:02 theanets.trainer:168 RmsProp 145 loss=89.623505 err=89.623505
I 2015-05-26 05:47:50 theanets.trainer:168 RmsProp 146 loss=88.230766 err=88.230766
I 2015-05-26 05:48:38 theanets.trainer:168 RmsProp 147 loss=87.432999 err=87.432999
I 2015-05-26 05:49:25 theanets.trainer:168 RmsProp 148 loss=88.428444 err=88.428444
I 2015-05-26 05:50:13 theanets.trainer:168 RmsProp 149 loss=84.337875 err=84.337875
I 2015-05-26 05:51:01 theanets.trainer:168 RmsProp 150 loss=82.820076 err=82.820076
I 2015-05-26 05:51:02 theanets.trainer:168 validation 15 loss=1446.370972 err=1446.370972 *
I 2015-05-26 05:51:49 theanets.trainer:168 RmsProp 151 loss=80.314873 err=80.314873
I 2015-05-26 05:52:37 theanets.trainer:168 RmsProp 152 loss=79.783363 err=79.783363
I 2015-05-26 05:53:24 theanets.trainer:168 RmsProp 153 loss=77.577248 err=77.577248
I 2015-05-26 05:54:11 theanets.trainer:168 RmsProp 154 loss=76.140579 err=76.140579
I 2015-05-26 05:54:58 theanets.trainer:168 RmsProp 155 loss=73.832886 err=73.832886
I 2015-05-26 05:55:46 theanets.trainer:168 RmsProp 156 loss=73.555794 err=73.555794
I 2015-05-26 05:56:33 theanets.trainer:168 RmsProp 157 loss=75.905411 err=75.905411
I 2015-05-26 05:57:21 theanets.trainer:168 RmsProp 158 loss=74.635712 err=74.635712
I 2015-05-26 05:58:08 theanets.trainer:168 RmsProp 159 loss=71.256927 err=71.256927
I 2015-05-26 05:58:56 theanets.trainer:168 RmsProp 160 loss=70.268143 err=70.268143
I 2015-05-26 05:58:56 theanets.trainer:168 validation 16 loss=1371.812988 err=1371.812988 *
I 2015-05-26 05:59:44 theanets.trainer:168 RmsProp 161 loss=69.056557 err=69.056557
I 2015-05-26 06:00:31 theanets.trainer:168 RmsProp 162 loss=69.100349 err=69.100349
I 2015-05-26 06:01:19 theanets.trainer:168 RmsProp 163 loss=72.805267 err=72.805267
I 2015-05-26 06:02:06 theanets.trainer:168 RmsProp 164 loss=68.383141 err=68.383141
I 2015-05-26 06:02:54 theanets.trainer:168 RmsProp 165 loss=64.417046 err=64.417046
I 2015-05-26 06:03:42 theanets.trainer:168 RmsProp 166 loss=64.015335 err=64.015335
I 2015-05-26 06:04:29 theanets.trainer:168 RmsProp 167 loss=63.839588 err=63.839588
I 2015-05-26 06:05:16 theanets.trainer:168 RmsProp 168 loss=62.275085 err=62.275085
I 2015-05-26 06:06:03 theanets.trainer:168 RmsProp 169 loss=61.926369 err=61.926369
I 2015-05-26 06:06:50 theanets.trainer:168 RmsProp 170 loss=59.005913 err=59.005913
I 2015-05-26 06:06:51 theanets.trainer:168 validation 17 loss=1310.221069 err=1310.221069 *
I 2015-05-26 06:07:38 theanets.trainer:168 RmsProp 171 loss=59.289585 err=59.289585
I 2015-05-26 06:08:24 theanets.trainer:168 RmsProp 172 loss=57.020084 err=57.020084
I 2015-05-26 06:09:11 theanets.trainer:168 RmsProp 173 loss=56.081230 err=56.081230
I 2015-05-26 06:09:59 theanets.trainer:168 RmsProp 174 loss=55.892780 err=55.892780
I 2015-05-26 06:10:46 theanets.trainer:168 RmsProp 175 loss=55.554321 err=55.554321
I 2015-05-26 06:11:33 theanets.trainer:168 RmsProp 176 loss=51.590771 err=51.590771
I 2015-05-26 06:12:21 theanets.trainer:168 RmsProp 177 loss=53.050823 err=53.050823
I 2015-05-26 06:13:09 theanets.trainer:168 RmsProp 178 loss=53.636539 err=53.636539
I 2015-05-26 06:13:58 theanets.trainer:168 RmsProp 179 loss=54.605019 err=54.605019
I 2015-05-26 06:14:45 theanets.trainer:168 RmsProp 180 loss=51.322380 err=51.322380
I 2015-05-26 06:14:46 theanets.trainer:168 validation 18 loss=1331.073853 err=1331.073853
I 2015-05-26 06:15:34 theanets.trainer:168 RmsProp 181 loss=50.598209 err=50.598209
I 2015-05-26 06:16:21 theanets.trainer:168 RmsProp 182 loss=50.021778 err=50.021778
I 2015-05-26 06:17:09 theanets.trainer:168 RmsProp 183 loss=48.105007 err=48.105007
I 2015-05-26 06:17:58 theanets.trainer:168 RmsProp 184 loss=49.035927 err=49.035927
I 2015-05-26 06:18:45 theanets.trainer:168 RmsProp 185 loss=46.984638 err=46.984638
I 2015-05-26 06:19:33 theanets.trainer:168 RmsProp 186 loss=45.403637 err=45.403637
I 2015-05-26 06:20:19 theanets.trainer:168 RmsProp 187 loss=46.923862 err=46.923862
I 2015-05-26 06:21:06 theanets.trainer:168 RmsProp 188 loss=44.953125 err=44.953125
I 2015-05-26 06:21:53 theanets.trainer:168 RmsProp 189 loss=45.609718 err=45.609718
I 2015-05-26 06:22:41 theanets.trainer:168 RmsProp 190 loss=44.068417 err=44.068417
I 2015-05-26 06:22:42 theanets.trainer:168 validation 19 loss=1312.197876 err=1312.197876
I 2015-05-26 06:23:28 theanets.trainer:168 RmsProp 191 loss=41.503052 err=41.503052
I 2015-05-26 06:24:14 theanets.trainer:168 RmsProp 192 loss=43.232346 err=43.232346
I 2015-05-26 06:25:01 theanets.trainer:168 RmsProp 193 loss=43.337208 err=43.337208
I 2015-05-26 06:25:48 theanets.trainer:168 RmsProp 194 loss=39.963734 err=39.963734
I 2015-05-26 06:26:35 theanets.trainer:168 RmsProp 195 loss=44.238834 err=44.238834
I 2015-05-26 06:27:23 theanets.trainer:168 RmsProp 196 loss=44.184589 err=44.184589
I 2015-05-26 06:28:10 theanets.trainer:168 RmsProp 197 loss=37.282799 err=37.282799
I 2015-05-26 06:28:58 theanets.trainer:168 RmsProp 198 loss=36.389500 err=36.389500
I 2015-05-26 06:29:46 theanets.trainer:168 RmsProp 199 loss=34.606911 err=34.606911
I 2015-05-26 06:30:34 theanets.trainer:168 RmsProp 200 loss=33.326031 err=33.326031
I 2015-05-26 06:30:35 theanets.trainer:168 validation 20 loss=1239.038818 err=1239.038818 *
I 2015-05-26 06:31:22 theanets.trainer:168 RmsProp 201 loss=32.652439 err=32.652439
I 2015-05-26 06:32:10 theanets.trainer:168 RmsProp 202 loss=31.869009 err=31.869009
I 2015-05-26 06:32:58 theanets.trainer:168 RmsProp 203 loss=30.552376 err=30.552376
I 2015-05-26 06:33:45 theanets.trainer:168 RmsProp 204 loss=24.397882 err=24.397882
I 2015-05-26 06:34:32 theanets.trainer:168 RmsProp 205 loss=22.233942 err=22.233942
I 2015-05-26 06:35:18 theanets.trainer:168 RmsProp 206 loss=20.441080 err=20.441080
I 2015-05-26 06:36:04 theanets.trainer:168 RmsProp 207 loss=20.744455 err=20.744455
I 2015-05-26 06:36:49 theanets.trainer:168 RmsProp 208 loss=22.691341 err=22.691341
I 2015-05-26 06:37:35 theanets.trainer:168 RmsProp 209 loss=25.382235 err=25.382235
I 2015-05-26 06:38:20 theanets.trainer:168 RmsProp 210 loss=25.056263 err=25.056263
I 2015-05-26 06:38:21 theanets.trainer:168 validation 21 loss=1173.493774 err=1173.493774 *
I 2015-05-26 06:39:07 theanets.trainer:168 RmsProp 211 loss=23.274273 err=23.274273
I 2015-05-26 06:39:53 theanets.trainer:168 RmsProp 212 loss=21.311766 err=21.311766
I 2015-05-26 06:40:36 theanets.trainer:168 RmsProp 213 loss=22.631351 err=22.631351
I 2015-05-26 06:41:20 theanets.trainer:168 RmsProp 214 loss=37.252438 err=37.252438
I 2015-05-26 06:42:03 theanets.trainer:168 RmsProp 215 loss=36.221294 err=36.221294
I 2015-05-26 06:42:45 theanets.trainer:168 RmsProp 216 loss=28.187529 err=28.187529
I 2015-05-26 06:43:27 theanets.trainer:168 RmsProp 217 loss=26.353577 err=26.353577
I 2015-05-26 06:44:10 theanets.trainer:168 RmsProp 218 loss=25.060452 err=25.060452
I 2015-05-26 06:44:53 theanets.trainer:168 RmsProp 219 loss=24.333363 err=24.333363
I 2015-05-26 06:45:36 theanets.trainer:168 RmsProp 220 loss=24.192501 err=24.192501
I 2015-05-26 06:45:37 theanets.trainer:168 validation 22 loss=1273.598022 err=1273.598022
I 2015-05-26 06:46:20 theanets.trainer:168 RmsProp 221 loss=24.239161 err=24.239161
I 2015-05-26 06:47:02 theanets.trainer:168 RmsProp 222 loss=23.387587 err=23.387587
I 2015-05-26 06:47:45 theanets.trainer:168 RmsProp 223 loss=23.541431 err=23.541431
I 2015-05-26 06:48:27 theanets.trainer:168 RmsProp 224 loss=22.808132 err=22.808132
I 2015-05-26 06:49:09 theanets.trainer:168 RmsProp 225 loss=21.878704 err=21.878704
I 2015-05-26 06:49:52 theanets.trainer:168 RmsProp 226 loss=22.161077 err=22.161077
I 2015-05-26 06:50:35 theanets.trainer:168 RmsProp 227 loss=22.615719 err=22.615719
I 2015-05-26 06:51:18 theanets.trainer:168 RmsProp 228 loss=21.516644 err=21.516644
I 2015-05-26 06:52:01 theanets.trainer:168 RmsProp 229 loss=20.994976 err=20.994976
I 2015-05-26 06:52:44 theanets.trainer:168 RmsProp 230 loss=19.492901 err=19.492901
I 2015-05-26 06:52:45 theanets.trainer:168 validation 23 loss=1250.323120 err=1250.323120
I 2015-05-26 06:53:26 theanets.trainer:168 RmsProp 231 loss=19.408960 err=19.408960
I 2015-05-26 06:54:08 theanets.trainer:168 RmsProp 232 loss=17.685509 err=17.685509
I 2015-05-26 06:54:51 theanets.trainer:168 RmsProp 233 loss=20.496157 err=20.496157
I 2015-05-26 06:55:34 theanets.trainer:168 RmsProp 234 loss=18.560125 err=18.560125
I 2015-05-26 06:56:17 theanets.trainer:168 RmsProp 235 loss=16.773214 err=16.773214
I 2015-05-26 06:57:00 theanets.trainer:168 RmsProp 236 loss=18.048174 err=18.048174
I 2015-05-26 06:57:40 theanets.trainer:168 RmsProp 237 loss=16.477301 err=16.477301
I 2015-05-26 06:58:19 theanets.trainer:168 RmsProp 238 loss=15.708149 err=15.708149
I 2015-05-26 06:58:57 theanets.trainer:168 RmsProp 239 loss=16.866201 err=16.866201
I 2015-05-26 06:59:35 theanets.trainer:168 RmsProp 240 loss=15.961851 err=15.961851
I 2015-05-26 06:59:36 theanets.trainer:168 validation 24 loss=1196.128662 err=1196.128662
I 2015-05-26 07:00:13 theanets.trainer:168 RmsProp 241 loss=16.399035 err=16.399035
I 2015-05-26 07:00:50 theanets.trainer:168 RmsProp 242 loss=16.323996 err=16.323996
I 2015-05-26 07:01:27 theanets.trainer:168 RmsProp 243 loss=15.775217 err=15.775217
I 2015-05-26 07:02:06 theanets.trainer:168 RmsProp 244 loss=15.656363 err=15.656363
I 2015-05-26 07:02:45 theanets.trainer:168 RmsProp 245 loss=15.602407 err=15.602407
I 2015-05-26 07:03:23 theanets.trainer:168 RmsProp 246 loss=14.691837 err=14.691837
I 2015-05-26 07:04:03 theanets.trainer:168 RmsProp 247 loss=14.782272 err=14.782272
I 2015-05-26 07:04:41 theanets.trainer:168 RmsProp 248 loss=15.977635 err=15.977635
I 2015-05-26 07:05:19 theanets.trainer:168 RmsProp 249 loss=14.667397 err=14.667397
I 2015-05-26 07:05:56 theanets.trainer:168 RmsProp 250 loss=13.577148 err=13.577148
I 2015-05-26 07:05:57 theanets.trainer:168 validation 25 loss=1193.101807 err=1193.101807
I 2015-05-26 07:06:35 theanets.trainer:168 RmsProp 251 loss=14.089869 err=14.089869
I 2015-05-26 07:07:14 theanets.trainer:168 RmsProp 252 loss=14.269194 err=14.269194
I 2015-05-26 07:07:53 theanets.trainer:168 RmsProp 253 loss=14.064292 err=14.064292
I 2015-05-26 07:08:32 theanets.trainer:168 RmsProp 254 loss=12.991970 err=12.991970
I 2015-05-26 07:09:10 theanets.trainer:168 RmsProp 255 loss=13.149068 err=13.149068
I 2015-05-26 07:09:49 theanets.trainer:168 RmsProp 256 loss=13.743847 err=13.743847
I 2015-05-26 07:10:28 theanets.trainer:168 RmsProp 257 loss=12.955531 err=12.955531
I 2015-05-26 07:11:06 theanets.trainer:168 RmsProp 258 loss=13.271482 err=13.271482
I 2015-05-26 07:11:45 theanets.trainer:168 RmsProp 259 loss=12.761795 err=12.761795
I 2015-05-26 07:12:22 theanets.trainer:168 RmsProp 260 loss=13.151927 err=13.151927
I 2015-05-26 07:12:23 theanets.trainer:168 validation 26 loss=1189.067017 err=1189.067017
I 2015-05-26 07:12:23 theanets.trainer:252 patience elapsed!
I 2015-05-26 07:12:23 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 07:12:23 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 07:12:23 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 07:12:23 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 07:12:23 theanets.main:89 --batch_size = 1024
I 2015-05-26 07:12:23 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 07:12:23 theanets.main:89 --hidden_l1 = None
I 2015-05-26 07:12:23 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 07:12:23 theanets.main:89 --train_batches = 10
I 2015-05-26 07:12:23 theanets.main:89 --valid_batches = 2
I 2015-05-26 07:12:23 theanets.main:89 --weight_l1 = None
I 2015-05-26 07:12:23 theanets.main:89 --weight_l2 = None
I 2015-05-26 07:12:23 theanets.trainer:134 compiling evaluation function
I 2015-05-26 07:12:33 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 07:14:11 theanets.trainer:168 validation 0 loss=2069.392334 err=2069.392334 *
I 2015-05-26 07:14:23 theanets.trainer:168 RmsProp 1 loss=15.737248 err=15.737248
I 2015-05-26 07:14:36 theanets.trainer:168 RmsProp 2 loss=11.086618 err=11.086618
I 2015-05-26 07:14:49 theanets.trainer:168 RmsProp 3 loss=8.765972 err=8.765972
I 2015-05-26 07:15:02 theanets.trainer:168 RmsProp 4 loss=7.413830 err=7.413830
I 2015-05-26 07:15:15 theanets.trainer:168 RmsProp 5 loss=6.663394 err=6.663394
I 2015-05-26 07:15:28 theanets.trainer:168 RmsProp 6 loss=6.009028 err=6.009028
I 2015-05-26 07:15:40 theanets.trainer:168 RmsProp 7 loss=5.443137 err=5.443137
I 2015-05-26 07:15:53 theanets.trainer:168 RmsProp 8 loss=5.102984 err=5.102984
I 2015-05-26 07:16:05 theanets.trainer:168 RmsProp 9 loss=4.627937 err=4.627937
I 2015-05-26 07:16:18 theanets.trainer:168 RmsProp 10 loss=4.462420 err=4.462420
I 2015-05-26 07:16:19 theanets.trainer:168 validation 1 loss=1985.255493 err=1985.255493 *
I 2015-05-26 07:16:31 theanets.trainer:168 RmsProp 11 loss=4.245959 err=4.245959
I 2015-05-26 07:16:44 theanets.trainer:168 RmsProp 12 loss=3.975644 err=3.975644
I 2015-05-26 07:16:57 theanets.trainer:168 RmsProp 13 loss=3.759319 err=3.759319
I 2015-05-26 07:17:10 theanets.trainer:168 RmsProp 14 loss=3.581643 err=3.581643
I 2015-05-26 07:17:22 theanets.trainer:168 RmsProp 15 loss=3.367921 err=3.367921
I 2015-05-26 07:17:35 theanets.trainer:168 RmsProp 16 loss=3.263153 err=3.263153
I 2015-05-26 07:17:48 theanets.trainer:168 RmsProp 17 loss=3.302068 err=3.302068
I 2015-05-26 07:18:00 theanets.trainer:168 RmsProp 18 loss=3.134931 err=3.134931
I 2015-05-26 07:18:13 theanets.trainer:168 RmsProp 19 loss=3.045549 err=3.045549
I 2015-05-26 07:18:25 theanets.trainer:168 RmsProp 20 loss=2.927163 err=2.927163
I 2015-05-26 07:18:26 theanets.trainer:168 validation 2 loss=1946.317993 err=1946.317993 *
I 2015-05-26 07:18:38 theanets.trainer:168 RmsProp 21 loss=2.804168 err=2.804168
I 2015-05-26 07:18:51 theanets.trainer:168 RmsProp 22 loss=2.735678 err=2.735678
I 2015-05-26 07:19:03 theanets.trainer:168 RmsProp 23 loss=2.627877 err=2.627877
I 2015-05-26 07:19:16 theanets.trainer:168 RmsProp 24 loss=2.586086 err=2.586086
I 2015-05-26 07:19:29 theanets.trainer:168 RmsProp 25 loss=2.476298 err=2.476298
I 2015-05-26 07:19:42 theanets.trainer:168 RmsProp 26 loss=2.434086 err=2.434086
I 2015-05-26 07:19:55 theanets.trainer:168 RmsProp 27 loss=2.384821 err=2.384821
I 2015-05-26 07:20:08 theanets.trainer:168 RmsProp 28 loss=2.317012 err=2.317012
I 2015-05-26 07:20:21 theanets.trainer:168 RmsProp 29 loss=2.315694 err=2.315694
I 2015-05-26 07:20:34 theanets.trainer:168 RmsProp 30 loss=2.209927 err=2.209927
I 2015-05-26 07:20:34 theanets.trainer:168 validation 3 loss=1930.658813 err=1930.658813 *
I 2015-05-26 07:20:47 theanets.trainer:168 RmsProp 31 loss=2.158160 err=2.158160
I 2015-05-26 07:21:00 theanets.trainer:168 RmsProp 32 loss=2.147587 err=2.147587
I 2015-05-26 07:21:13 theanets.trainer:168 RmsProp 33 loss=2.104048 err=2.104048
I 2015-05-26 07:21:25 theanets.trainer:168 RmsProp 34 loss=2.029182 err=2.029182
I 2015-05-26 07:21:38 theanets.trainer:168 RmsProp 35 loss=2.022748 err=2.022748
I 2015-05-26 07:21:51 theanets.trainer:168 RmsProp 36 loss=1.953583 err=1.953583
I 2015-05-26 07:22:04 theanets.trainer:168 RmsProp 37 loss=1.889819 err=1.889819
I 2015-05-26 07:22:17 theanets.trainer:168 RmsProp 38 loss=1.894364 err=1.894364
I 2015-05-26 07:22:29 theanets.trainer:168 RmsProp 39 loss=1.819618 err=1.819618
I 2015-05-26 07:22:42 theanets.trainer:168 RmsProp 40 loss=1.807341 err=1.807341
I 2015-05-26 07:22:43 theanets.trainer:168 validation 4 loss=1916.690674 err=1916.690674 *
I 2015-05-26 07:22:55 theanets.trainer:168 RmsProp 41 loss=1.764866 err=1.764866
I 2015-05-26 07:23:08 theanets.trainer:168 RmsProp 42 loss=1.785926 err=1.785926
I 2015-05-26 07:23:21 theanets.trainer:168 RmsProp 43 loss=1.746701 err=1.746701
I 2015-05-26 07:23:34 theanets.trainer:168 RmsProp 44 loss=1.676879 err=1.676879
I 2015-05-26 07:23:47 theanets.trainer:168 RmsProp 45 loss=1.665937 err=1.665937
I 2015-05-26 07:24:00 theanets.trainer:168 RmsProp 46 loss=1.681144 err=1.681144
I 2015-05-26 07:24:14 theanets.trainer:168 RmsProp 47 loss=1.619639 err=1.619639
I 2015-05-26 07:24:27 theanets.trainer:168 RmsProp 48 loss=1.630946 err=1.630946
I 2015-05-26 07:24:39 theanets.trainer:168 RmsProp 49 loss=1.566297 err=1.566297
I 2015-05-26 07:24:52 theanets.trainer:168 RmsProp 50 loss=1.593519 err=1.593519
I 2015-05-26 07:24:52 theanets.trainer:168 validation 5 loss=1902.191406 err=1902.191406 *
I 2015-05-26 07:25:05 theanets.trainer:168 RmsProp 51 loss=1.545103 err=1.545103
I 2015-05-26 07:25:17 theanets.trainer:168 RmsProp 52 loss=1.499727 err=1.499727
I 2015-05-26 07:25:29 theanets.trainer:168 RmsProp 53 loss=1.515587 err=1.515587
I 2015-05-26 07:25:41 theanets.trainer:168 RmsProp 54 loss=1.494278 err=1.494278
I 2015-05-26 07:25:54 theanets.trainer:168 RmsProp 55 loss=1.451745 err=1.451745
I 2015-05-26 07:26:06 theanets.trainer:168 RmsProp 56 loss=1.411340 err=1.411340
I 2015-05-26 07:26:18 theanets.trainer:168 RmsProp 57 loss=1.399004 err=1.399004
I 2015-05-26 07:26:30 theanets.trainer:168 RmsProp 58 loss=1.359371 err=1.359371
I 2015-05-26 07:26:42 theanets.trainer:168 RmsProp 59 loss=1.366175 err=1.366175
I 2015-05-26 07:26:54 theanets.trainer:168 RmsProp 60 loss=1.317847 err=1.317847
I 2015-05-26 07:26:54 theanets.trainer:168 validation 6 loss=1894.029297 err=1894.029297 *
I 2015-05-26 07:27:06 theanets.trainer:168 RmsProp 61 loss=1.316152 err=1.316152
I 2015-05-26 07:27:18 theanets.trainer:168 RmsProp 62 loss=1.342475 err=1.342475
I 2015-05-26 07:27:30 theanets.trainer:168 RmsProp 63 loss=1.311197 err=1.311197
I 2015-05-26 07:27:42 theanets.trainer:168 RmsProp 64 loss=1.277305 err=1.277305
I 2015-05-26 07:27:54 theanets.trainer:168 RmsProp 65 loss=1.271227 err=1.271227
I 2015-05-26 07:28:06 theanets.trainer:168 RmsProp 66 loss=1.264322 err=1.264322
I 2015-05-26 07:28:18 theanets.trainer:168 RmsProp 67 loss=1.199787 err=1.199787
I 2015-05-26 07:28:30 theanets.trainer:168 RmsProp 68 loss=1.227356 err=1.227356
I 2015-05-26 07:28:42 theanets.trainer:168 RmsProp 69 loss=1.202081 err=1.202081
I 2015-05-26 07:28:54 theanets.trainer:168 RmsProp 70 loss=1.185623 err=1.185623
I 2015-05-26 07:28:55 theanets.trainer:168 validation 7 loss=1887.473877 err=1887.473877 *
I 2015-05-26 07:29:06 theanets.trainer:168 RmsProp 71 loss=1.178150 err=1.178150
I 2015-05-26 07:29:18 theanets.trainer:168 RmsProp 72 loss=1.160911 err=1.160911
I 2015-05-26 07:29:30 theanets.trainer:168 RmsProp 73 loss=1.144406 err=1.144406
I 2015-05-26 07:29:42 theanets.trainer:168 RmsProp 74 loss=1.141894 err=1.141894
I 2015-05-26 07:29:55 theanets.trainer:168 RmsProp 75 loss=1.137511 err=1.137511
I 2015-05-26 07:30:07 theanets.trainer:168 RmsProp 76 loss=1.094356 err=1.094356
I 2015-05-26 07:30:19 theanets.trainer:168 RmsProp 77 loss=1.096328 err=1.096328
I 2015-05-26 07:30:31 theanets.trainer:168 RmsProp 78 loss=1.090954 err=1.090954
I 2015-05-26 07:30:43 theanets.trainer:168 RmsProp 79 loss=1.078402 err=1.078402
I 2015-05-26 07:30:55 theanets.trainer:168 RmsProp 80 loss=1.066209 err=1.066209
I 2015-05-26 07:30:55 theanets.trainer:168 validation 8 loss=1882.595337 err=1882.595337 *
I 2015-05-26 07:31:07 theanets.trainer:168 RmsProp 81 loss=1.077805 err=1.077805
I 2015-05-26 07:31:19 theanets.trainer:168 RmsProp 82 loss=1.068061 err=1.068061
I 2015-05-26 07:31:31 theanets.trainer:168 RmsProp 83 loss=1.034482 err=1.034482
I 2015-05-26 07:31:42 theanets.trainer:168 RmsProp 84 loss=1.019808 err=1.019808
I 2015-05-26 07:31:54 theanets.trainer:168 RmsProp 85 loss=1.014565 err=1.014565
I 2015-05-26 07:32:06 theanets.trainer:168 RmsProp 86 loss=0.995008 err=0.995008
I 2015-05-26 07:32:17 theanets.trainer:168 RmsProp 87 loss=1.014456 err=1.014456
I 2015-05-26 07:32:29 theanets.trainer:168 RmsProp 88 loss=0.982977 err=0.982977
I 2015-05-26 07:32:40 theanets.trainer:168 RmsProp 89 loss=1.010050 err=1.010050
I 2015-05-26 07:32:52 theanets.trainer:168 RmsProp 90 loss=0.971981 err=0.971981
I 2015-05-26 07:32:52 theanets.trainer:168 validation 9 loss=1874.245728 err=1874.245728 *
I 2015-05-26 07:33:04 theanets.trainer:168 RmsProp 91 loss=0.988246 err=0.988246
I 2015-05-26 07:33:15 theanets.trainer:168 RmsProp 92 loss=0.948716 err=0.948716
I 2015-05-26 07:33:27 theanets.trainer:168 RmsProp 93 loss=0.968179 err=0.968179
I 2015-05-26 07:33:39 theanets.trainer:168 RmsProp 94 loss=0.924713 err=0.924713
I 2015-05-26 07:33:51 theanets.trainer:168 RmsProp 95 loss=0.931569 err=0.931569
I 2015-05-26 07:34:03 theanets.trainer:168 RmsProp 96 loss=0.922488 err=0.922488
I 2015-05-26 07:34:15 theanets.trainer:168 RmsProp 97 loss=0.912429 err=0.912429
I 2015-05-26 07:34:27 theanets.trainer:168 RmsProp 98 loss=0.923858 err=0.923858
I 2015-05-26 07:34:38 theanets.trainer:168 RmsProp 99 loss=0.902710 err=0.902710
I 2015-05-26 07:34:50 theanets.trainer:168 RmsProp 100 loss=0.917015 err=0.917015
I 2015-05-26 07:34:51 theanets.trainer:168 validation 10 loss=1865.042603 err=1865.042603 *
I 2015-05-26 07:35:02 theanets.trainer:168 RmsProp 101 loss=0.878583 err=0.878583
I 2015-05-26 07:35:14 theanets.trainer:168 RmsProp 102 loss=0.857093 err=0.857093
I 2015-05-26 07:35:26 theanets.trainer:168 RmsProp 103 loss=0.895743 err=0.895743
I 2015-05-26 07:35:38 theanets.trainer:168 RmsProp 104 loss=0.881641 err=0.881641
I 2015-05-26 07:35:49 theanets.trainer:168 RmsProp 105 loss=0.843461 err=0.843461
I 2015-05-26 07:36:01 theanets.trainer:168 RmsProp 106 loss=0.888678 err=0.888678
I 2015-05-26 07:36:13 theanets.trainer:168 RmsProp 107 loss=0.842369 err=0.842369
I 2015-05-26 07:36:25 theanets.trainer:168 RmsProp 108 loss=0.841231 err=0.841231
I 2015-05-26 07:36:37 theanets.trainer:168 RmsProp 109 loss=0.853927 err=0.853927
I 2015-05-26 07:36:49 theanets.trainer:168 RmsProp 110 loss=0.835995 err=0.835995
I 2015-05-26 07:36:49 theanets.trainer:168 validation 11 loss=1865.591797 err=1865.591797
I 2015-05-26 07:37:01 theanets.trainer:168 RmsProp 111 loss=0.814542 err=0.814542
I 2015-05-26 07:37:13 theanets.trainer:168 RmsProp 112 loss=0.795769 err=0.795769
I 2015-05-26 07:37:24 theanets.trainer:168 RmsProp 113 loss=0.807213 err=0.807213
I 2015-05-26 07:37:36 theanets.trainer:168 RmsProp 114 loss=0.788056 err=0.788056
I 2015-05-26 07:37:48 theanets.trainer:168 RmsProp 115 loss=0.789003 err=0.789003
I 2015-05-26 07:38:01 theanets.trainer:168 RmsProp 116 loss=0.795023 err=0.795023
I 2015-05-26 07:38:13 theanets.trainer:168 RmsProp 117 loss=0.778068 err=0.778068
I 2015-05-26 07:38:25 theanets.trainer:168 RmsProp 118 loss=0.798597 err=0.798597
I 2015-05-26 07:38:37 theanets.trainer:168 RmsProp 119 loss=0.801954 err=0.801954
I 2015-05-26 07:38:48 theanets.trainer:168 RmsProp 120 loss=0.767130 err=0.767130
I 2015-05-26 07:38:49 theanets.trainer:168 validation 12 loss=1852.137573 err=1852.137573 *
I 2015-05-26 07:39:01 theanets.trainer:168 RmsProp 121 loss=0.759410 err=0.759410
I 2015-05-26 07:39:13 theanets.trainer:168 RmsProp 122 loss=0.733940 err=0.733940
I 2015-05-26 07:39:25 theanets.trainer:168 RmsProp 123 loss=0.770208 err=0.770208
I 2015-05-26 07:39:37 theanets.trainer:168 RmsProp 124 loss=0.789025 err=0.789025
I 2015-05-26 07:39:49 theanets.trainer:168 RmsProp 125 loss=0.726139 err=0.726139
I 2015-05-26 07:40:01 theanets.trainer:168 RmsProp 126 loss=0.738304 err=0.738304
I 2015-05-26 07:40:14 theanets.trainer:168 RmsProp 127 loss=0.733360 err=0.733360
I 2015-05-26 07:40:27 theanets.trainer:168 RmsProp 128 loss=0.732014 err=0.732014
I 2015-05-26 07:40:39 theanets.trainer:168 RmsProp 129 loss=0.704085 err=0.704085
I 2015-05-26 07:40:52 theanets.trainer:168 RmsProp 130 loss=0.726505 err=0.726505
I 2015-05-26 07:40:52 theanets.trainer:168 validation 13 loss=1844.689087 err=1844.689087 *
I 2015-05-26 07:41:04 theanets.trainer:168 RmsProp 131 loss=0.707379 err=0.707379
I 2015-05-26 07:41:17 theanets.trainer:168 RmsProp 132 loss=0.714760 err=0.714760
I 2015-05-26 07:41:29 theanets.trainer:168 RmsProp 133 loss=0.713854 err=0.713854
I 2015-05-26 07:41:41 theanets.trainer:168 RmsProp 134 loss=0.723978 err=0.723978
I 2015-05-26 07:41:54 theanets.trainer:168 RmsProp 135 loss=0.708866 err=0.708866
I 2015-05-26 07:42:06 theanets.trainer:168 RmsProp 136 loss=0.678002 err=0.678002
I 2015-05-26 07:42:18 theanets.trainer:168 RmsProp 137 loss=0.691361 err=0.691361
I 2015-05-26 07:42:30 theanets.trainer:168 RmsProp 138 loss=0.673589 err=0.673589
I 2015-05-26 07:42:42 theanets.trainer:168 RmsProp 139 loss=0.644354 err=0.644354
I 2015-05-26 07:42:54 theanets.trainer:168 RmsProp 140 loss=0.709377 err=0.709377
I 2015-05-26 07:42:54 theanets.trainer:168 validation 14 loss=1840.546753 err=1840.546753 *
I 2015-05-26 07:43:05 theanets.trainer:168 RmsProp 141 loss=0.706495 err=0.706495
I 2015-05-26 07:43:17 theanets.trainer:168 RmsProp 142 loss=0.657635 err=0.657635
I 2015-05-26 07:43:28 theanets.trainer:168 RmsProp 143 loss=0.659596 err=0.659596
I 2015-05-26 07:43:39 theanets.trainer:168 RmsProp 144 loss=0.673335 err=0.673335
I 2015-05-26 07:43:50 theanets.trainer:168 RmsProp 145 loss=0.648149 err=0.648149
I 2015-05-26 07:44:02 theanets.trainer:168 RmsProp 146 loss=0.645989 err=0.645989
I 2015-05-26 07:44:13 theanets.trainer:168 RmsProp 147 loss=0.630339 err=0.630339
I 2015-05-26 07:44:24 theanets.trainer:168 RmsProp 148 loss=0.643880 err=0.643880
I 2015-05-26 07:44:35 theanets.trainer:168 RmsProp 149 loss=0.631498 err=0.631498
I 2015-05-26 07:44:46 theanets.trainer:168 RmsProp 150 loss=0.633192 err=0.633192
I 2015-05-26 07:44:47 theanets.trainer:168 validation 15 loss=1835.724976 err=1835.724976 *
I 2015-05-26 07:44:58 theanets.trainer:168 RmsProp 151 loss=0.651982 err=0.651982
I 2015-05-26 07:45:08 theanets.trainer:168 RmsProp 152 loss=0.629878 err=0.629878
I 2015-05-26 07:45:20 theanets.trainer:168 RmsProp 153 loss=0.631558 err=0.631558
I 2015-05-26 07:45:31 theanets.trainer:168 RmsProp 154 loss=0.627670 err=0.627670
I 2015-05-26 07:45:42 theanets.trainer:168 RmsProp 155 loss=0.629316 err=0.629316
I 2015-05-26 07:45:53 theanets.trainer:168 RmsProp 156 loss=0.616584 err=0.616584
I 2015-05-26 07:46:05 theanets.trainer:168 RmsProp 157 loss=0.602135 err=0.602135
I 2015-05-26 07:46:16 theanets.trainer:168 RmsProp 158 loss=0.602383 err=0.602383
I 2015-05-26 07:46:27 theanets.trainer:168 RmsProp 159 loss=0.613028 err=0.613028
I 2015-05-26 07:46:38 theanets.trainer:168 RmsProp 160 loss=0.590394 err=0.590394
I 2015-05-26 07:46:39 theanets.trainer:168 validation 16 loss=1831.860229 err=1831.860229 *
I 2015-05-26 07:46:49 theanets.trainer:168 RmsProp 161 loss=0.602782 err=0.602782
I 2015-05-26 07:47:00 theanets.trainer:168 RmsProp 162 loss=0.592895 err=0.592895
I 2015-05-26 07:47:11 theanets.trainer:168 RmsProp 163 loss=0.605995 err=0.605995
I 2015-05-26 07:47:23 theanets.trainer:168 RmsProp 164 loss=0.580948 err=0.580948
I 2015-05-26 07:47:34 theanets.trainer:168 RmsProp 165 loss=0.606945 err=0.606945
I 2015-05-26 07:47:46 theanets.trainer:168 RmsProp 166 loss=0.587558 err=0.587558
I 2015-05-26 07:47:57 theanets.trainer:168 RmsProp 167 loss=0.595268 err=0.595268
I 2015-05-26 07:48:08 theanets.trainer:168 RmsProp 168 loss=0.557814 err=0.557814
I 2015-05-26 07:48:19 theanets.trainer:168 RmsProp 169 loss=0.565441 err=0.565441
I 2015-05-26 07:48:30 theanets.trainer:168 RmsProp 170 loss=0.549889 err=0.549889
I 2015-05-26 07:48:31 theanets.trainer:168 validation 17 loss=1823.549683 err=1823.549683 *
I 2015-05-26 07:48:42 theanets.trainer:168 RmsProp 171 loss=0.585440 err=0.585440
I 2015-05-26 07:48:52 theanets.trainer:168 RmsProp 172 loss=0.568319 err=0.568319
I 2015-05-26 07:49:03 theanets.trainer:168 RmsProp 173 loss=0.549372 err=0.549372
I 2015-05-26 07:49:13 theanets.trainer:168 RmsProp 174 loss=0.544295 err=0.544295
I 2015-05-26 07:49:24 theanets.trainer:168 RmsProp 175 loss=0.597770 err=0.597770
I 2015-05-26 07:49:35 theanets.trainer:168 RmsProp 176 loss=0.590977 err=0.590977
I 2015-05-26 07:49:45 theanets.trainer:168 RmsProp 177 loss=0.535079 err=0.535079
I 2015-05-26 07:49:56 theanets.trainer:168 RmsProp 178 loss=0.566603 err=0.566603
I 2015-05-26 07:50:06 theanets.trainer:168 RmsProp 179 loss=0.548476 err=0.548476
I 2015-05-26 07:50:17 theanets.trainer:168 RmsProp 180 loss=0.551138 err=0.551138
I 2015-05-26 07:50:17 theanets.trainer:168 validation 18 loss=1821.734009 err=1821.734009 *
I 2015-05-26 07:50:27 theanets.trainer:168 RmsProp 181 loss=0.547656 err=0.547656
I 2015-05-26 07:50:38 theanets.trainer:168 RmsProp 182 loss=0.551834 err=0.551834
I 2015-05-26 07:50:49 theanets.trainer:168 RmsProp 183 loss=0.533826 err=0.533826
I 2015-05-26 07:50:59 theanets.trainer:168 RmsProp 184 loss=0.530290 err=0.530290
I 2015-05-26 07:51:10 theanets.trainer:168 RmsProp 185 loss=0.515303 err=0.515303
I 2015-05-26 07:51:21 theanets.trainer:168 RmsProp 186 loss=0.531150 err=0.531150
I 2015-05-26 07:51:31 theanets.trainer:168 RmsProp 187 loss=0.527208 err=0.527208
I 2015-05-26 07:51:41 theanets.trainer:168 RmsProp 188 loss=0.529132 err=0.529132
I 2015-05-26 07:51:52 theanets.trainer:168 RmsProp 189 loss=0.495453 err=0.495453
I 2015-05-26 07:52:03 theanets.trainer:168 RmsProp 190 loss=0.531173 err=0.531173
I 2015-05-26 07:52:03 theanets.trainer:168 validation 19 loss=1812.503296 err=1812.503296 *
I 2015-05-26 07:52:14 theanets.trainer:168 RmsProp 191 loss=0.511399 err=0.511399
I 2015-05-26 07:52:25 theanets.trainer:168 RmsProp 192 loss=0.519443 err=0.519443
I 2015-05-26 07:52:36 theanets.trainer:168 RmsProp 193 loss=0.519197 err=0.519197
I 2015-05-26 07:52:47 theanets.trainer:168 RmsProp 194 loss=0.503546 err=0.503546
I 2015-05-26 07:52:58 theanets.trainer:168 RmsProp 195 loss=0.504587 err=0.504587
I 2015-05-26 07:53:09 theanets.trainer:168 RmsProp 196 loss=0.525664 err=0.525664
I 2015-05-26 07:53:20 theanets.trainer:168 RmsProp 197 loss=0.494908 err=0.494908
I 2015-05-26 07:53:31 theanets.trainer:168 RmsProp 198 loss=0.515669 err=0.515669
I 2015-05-26 07:53:42 theanets.trainer:168 RmsProp 199 loss=0.478987 err=0.478987
I 2015-05-26 07:53:53 theanets.trainer:168 RmsProp 200 loss=0.474767 err=0.474767
I 2015-05-26 07:53:53 theanets.trainer:168 validation 20 loss=1813.178589 err=1813.178589
I 2015-05-26 07:54:04 theanets.trainer:168 RmsProp 201 loss=0.502989 err=0.502989
I 2015-05-26 07:54:15 theanets.trainer:168 RmsProp 202 loss=0.483733 err=0.483733
I 2015-05-26 07:54:26 theanets.trainer:168 RmsProp 203 loss=0.480511 err=0.480511
I 2015-05-26 07:54:37 theanets.trainer:168 RmsProp 204 loss=0.487371 err=0.487371
I 2015-05-26 07:54:47 theanets.trainer:168 RmsProp 205 loss=0.494651 err=0.494651
I 2015-05-26 07:54:58 theanets.trainer:168 RmsProp 206 loss=0.473320 err=0.473320
I 2015-05-26 07:55:09 theanets.trainer:168 RmsProp 207 loss=0.484084 err=0.484084
I 2015-05-26 07:55:20 theanets.trainer:168 RmsProp 208 loss=0.466358 err=0.466358
I 2015-05-26 07:55:31 theanets.trainer:168 RmsProp 209 loss=0.473310 err=0.473310
I 2015-05-26 07:55:42 theanets.trainer:168 RmsProp 210 loss=0.487964 err=0.487964
I 2015-05-26 07:55:42 theanets.trainer:168 validation 21 loss=1807.019531 err=1807.019531 *
I 2015-05-26 07:55:53 theanets.trainer:168 RmsProp 211 loss=0.466451 err=0.466451
I 2015-05-26 07:56:04 theanets.trainer:168 RmsProp 212 loss=0.481208 err=0.481208
I 2015-05-26 07:56:15 theanets.trainer:168 RmsProp 213 loss=0.478999 err=0.478999
I 2015-05-26 07:56:26 theanets.trainer:168 RmsProp 214 loss=0.458248 err=0.458248
I 2015-05-26 07:56:37 theanets.trainer:168 RmsProp 215 loss=0.464799 err=0.464799
I 2015-05-26 07:56:48 theanets.trainer:168 RmsProp 216 loss=0.461639 err=0.461639
I 2015-05-26 07:56:59 theanets.trainer:168 RmsProp 217 loss=0.457214 err=0.457214
I 2015-05-26 07:57:10 theanets.trainer:168 RmsProp 218 loss=0.474245 err=0.474245
I 2015-05-26 07:57:22 theanets.trainer:168 RmsProp 219 loss=0.451927 err=0.451927
I 2015-05-26 07:57:33 theanets.trainer:168 RmsProp 220 loss=0.448465 err=0.448465
I 2015-05-26 07:57:34 theanets.trainer:168 validation 22 loss=1803.145874 err=1803.145874 *
I 2015-05-26 07:57:45 theanets.trainer:168 RmsProp 221 loss=0.454315 err=0.454315
I 2015-05-26 07:57:56 theanets.trainer:168 RmsProp 222 loss=0.446696 err=0.446696
I 2015-05-26 07:58:07 theanets.trainer:168 RmsProp 223 loss=0.451353 err=0.451353
I 2015-05-26 07:58:18 theanets.trainer:168 RmsProp 224 loss=0.453705 err=0.453705
I 2015-05-26 07:58:29 theanets.trainer:168 RmsProp 225 loss=0.428165 err=0.428165
I 2015-05-26 07:58:40 theanets.trainer:168 RmsProp 226 loss=0.466547 err=0.466547
I 2015-05-26 07:58:51 theanets.trainer:168 RmsProp 227 loss=0.444733 err=0.444733
I 2015-05-26 07:59:01 theanets.trainer:168 RmsProp 228 loss=0.445739 err=0.445739
I 2015-05-26 07:59:12 theanets.trainer:168 RmsProp 229 loss=0.440670 err=0.440670
I 2015-05-26 07:59:23 theanets.trainer:168 RmsProp 230 loss=0.436980 err=0.436980
I 2015-05-26 07:59:23 theanets.trainer:168 validation 23 loss=1798.006714 err=1798.006714 *
I 2015-05-26 07:59:34 theanets.trainer:168 RmsProp 231 loss=0.450750 err=0.450750
I 2015-05-26 07:59:45 theanets.trainer:168 RmsProp 232 loss=0.441911 err=0.441911
I 2015-05-26 07:59:56 theanets.trainer:168 RmsProp 233 loss=0.427809 err=0.427809
I 2015-05-26 08:00:07 theanets.trainer:168 RmsProp 234 loss=0.428777 err=0.428777
I 2015-05-26 08:00:18 theanets.trainer:168 RmsProp 235 loss=0.430588 err=0.430588
I 2015-05-26 08:00:29 theanets.trainer:168 RmsProp 236 loss=0.437844 err=0.437844
I 2015-05-26 08:00:41 theanets.trainer:168 RmsProp 237 loss=0.430284 err=0.430284
I 2015-05-26 08:00:52 theanets.trainer:168 RmsProp 238 loss=0.425580 err=0.425580
I 2015-05-26 08:01:04 theanets.trainer:168 RmsProp 239 loss=0.414430 err=0.414430
I 2015-05-26 08:01:15 theanets.trainer:168 RmsProp 240 loss=0.412453 err=0.412453
I 2015-05-26 08:01:16 theanets.trainer:168 validation 24 loss=1795.169556 err=1795.169556 *
I 2015-05-26 08:01:27 theanets.trainer:168 RmsProp 241 loss=0.424596 err=0.424596
I 2015-05-26 08:01:38 theanets.trainer:168 RmsProp 242 loss=0.415302 err=0.415302
I 2015-05-26 08:01:49 theanets.trainer:168 RmsProp 243 loss=0.422090 err=0.422090
I 2015-05-26 08:02:00 theanets.trainer:168 RmsProp 244 loss=0.416422 err=0.416422
I 2015-05-26 08:02:10 theanets.trainer:168 RmsProp 245 loss=0.402674 err=0.402674
I 2015-05-26 08:02:20 theanets.trainer:168 RmsProp 246 loss=0.408849 err=0.408849
I 2015-05-26 08:02:30 theanets.trainer:168 RmsProp 247 loss=0.425766 err=0.425766
I 2015-05-26 08:02:40 theanets.trainer:168 RmsProp 248 loss=0.416396 err=0.416396
I 2015-05-26 08:02:51 theanets.trainer:168 RmsProp 249 loss=0.393232 err=0.393232
I 2015-05-26 08:03:01 theanets.trainer:168 RmsProp 250 loss=0.404416 err=0.404416
I 2015-05-26 08:03:02 theanets.trainer:168 validation 25 loss=1793.957642 err=1793.957642 *
I 2015-05-26 08:03:12 theanets.trainer:168 RmsProp 251 loss=0.392387 err=0.392387
I 2015-05-26 08:03:22 theanets.trainer:168 RmsProp 252 loss=0.395601 err=0.395601
I 2015-05-26 08:03:32 theanets.trainer:168 RmsProp 253 loss=0.421729 err=0.421729
I 2015-05-26 08:03:42 theanets.trainer:168 RmsProp 254 loss=0.422151 err=0.422151
I 2015-05-26 08:03:52 theanets.trainer:168 RmsProp 255 loss=0.387806 err=0.387806
I 2015-05-26 08:04:03 theanets.trainer:168 RmsProp 256 loss=0.399193 err=0.399193
I 2015-05-26 08:04:13 theanets.trainer:168 RmsProp 257 loss=0.408614 err=0.408614
I 2015-05-26 08:04:23 theanets.trainer:168 RmsProp 258 loss=0.402405 err=0.402405
I 2015-05-26 08:04:33 theanets.trainer:168 RmsProp 259 loss=0.390096 err=0.390096
I 2015-05-26 08:04:44 theanets.trainer:168 RmsProp 260 loss=0.377575 err=0.377575
I 2015-05-26 08:04:44 theanets.trainer:168 validation 26 loss=1788.076050 err=1788.076050 *
I 2015-05-26 08:04:54 theanets.trainer:168 RmsProp 261 loss=0.406078 err=0.406078
I 2015-05-26 08:05:05 theanets.trainer:168 RmsProp 262 loss=0.387330 err=0.387330
I 2015-05-26 08:05:16 theanets.trainer:168 RmsProp 263 loss=0.384090 err=0.384090
I 2015-05-26 08:05:26 theanets.trainer:168 RmsProp 264 loss=0.380451 err=0.380451
I 2015-05-26 08:05:36 theanets.trainer:168 RmsProp 265 loss=0.386695 err=0.386695
I 2015-05-26 08:05:46 theanets.trainer:168 RmsProp 266 loss=0.394022 err=0.394022
I 2015-05-26 08:05:56 theanets.trainer:168 RmsProp 267 loss=0.405121 err=0.405121
I 2015-05-26 08:06:07 theanets.trainer:168 RmsProp 268 loss=0.385064 err=0.385064
I 2015-05-26 08:06:17 theanets.trainer:168 RmsProp 269 loss=0.380676 err=0.380676
I 2015-05-26 08:06:27 theanets.trainer:168 RmsProp 270 loss=0.398140 err=0.398140
I 2015-05-26 08:06:28 theanets.trainer:168 validation 27 loss=1787.211304 err=1787.211304 *
I 2015-05-26 08:06:38 theanets.trainer:168 RmsProp 271 loss=0.368134 err=0.368134
I 2015-05-26 08:06:48 theanets.trainer:168 RmsProp 272 loss=0.364822 err=0.364822
I 2015-05-26 08:06:59 theanets.trainer:168 RmsProp 273 loss=0.380578 err=0.380578
I 2015-05-26 08:07:09 theanets.trainer:168 RmsProp 274 loss=0.369632 err=0.369632
I 2015-05-26 08:07:20 theanets.trainer:168 RmsProp 275 loss=0.384237 err=0.384237
I 2015-05-26 08:07:30 theanets.trainer:168 RmsProp 276 loss=0.385769 err=0.385769
I 2015-05-26 08:07:40 theanets.trainer:168 RmsProp 277 loss=0.361151 err=0.361151
I 2015-05-26 08:07:50 theanets.trainer:168 RmsProp 278 loss=0.363426 err=0.363426
I 2015-05-26 08:08:01 theanets.trainer:168 RmsProp 279 loss=0.364426 err=0.364426
I 2015-05-26 08:08:11 theanets.trainer:168 RmsProp 280 loss=0.365822 err=0.365822
I 2015-05-26 08:08:11 theanets.trainer:168 validation 28 loss=1778.958862 err=1778.958862 *
I 2015-05-26 08:08:21 theanets.trainer:168 RmsProp 281 loss=0.377420 err=0.377420
I 2015-05-26 08:08:31 theanets.trainer:168 RmsProp 282 loss=0.364551 err=0.364551
I 2015-05-26 08:08:42 theanets.trainer:168 RmsProp 283 loss=0.360751 err=0.360751
I 2015-05-26 08:08:52 theanets.trainer:168 RmsProp 284 loss=0.363936 err=0.363936
I 2015-05-26 08:09:02 theanets.trainer:168 RmsProp 285 loss=0.353240 err=0.353240
I 2015-05-26 08:09:12 theanets.trainer:168 RmsProp 286 loss=0.352617 err=0.352617
I 2015-05-26 08:09:22 theanets.trainer:168 RmsProp 287 loss=0.355667 err=0.355667
I 2015-05-26 08:09:33 theanets.trainer:168 RmsProp 288 loss=0.391545 err=0.391545
I 2015-05-26 08:09:43 theanets.trainer:168 RmsProp 289 loss=0.357785 err=0.357785
I 2015-05-26 08:09:54 theanets.trainer:168 RmsProp 290 loss=0.354843 err=0.354843
I 2015-05-26 08:09:54 theanets.trainer:168 validation 29 loss=1780.137329 err=1780.137329
I 2015-05-26 08:10:05 theanets.trainer:168 RmsProp 291 loss=0.343892 err=0.343892
I 2015-05-26 08:10:15 theanets.trainer:168 RmsProp 292 loss=0.336740 err=0.336740
I 2015-05-26 08:10:26 theanets.trainer:168 RmsProp 293 loss=0.349410 err=0.349410
I 2015-05-26 08:10:37 theanets.trainer:168 RmsProp 294 loss=0.364237 err=0.364237
I 2015-05-26 08:10:47 theanets.trainer:168 RmsProp 295 loss=0.343686 err=0.343686
I 2015-05-26 08:10:58 theanets.trainer:168 RmsProp 296 loss=0.342703 err=0.342703
I 2015-05-26 08:11:08 theanets.trainer:168 RmsProp 297 loss=0.351175 err=0.351175
I 2015-05-26 08:11:18 theanets.trainer:168 RmsProp 298 loss=0.341414 err=0.341414
I 2015-05-26 08:11:29 theanets.trainer:168 RmsProp 299 loss=0.356966 err=0.356966
I 2015-05-26 08:11:39 theanets.trainer:168 RmsProp 300 loss=0.330449 err=0.330449
I 2015-05-26 08:11:40 theanets.trainer:168 validation 30 loss=1777.692749 err=1777.692749 *
I 2015-05-26 08:11:50 theanets.trainer:168 RmsProp 301 loss=0.337340 err=0.337340
I 2015-05-26 08:11:59 theanets.trainer:168 RmsProp 302 loss=0.343049 err=0.343049
I 2015-05-26 08:12:09 theanets.trainer:168 RmsProp 303 loss=0.358177 err=0.358177
I 2015-05-26 08:12:20 theanets.trainer:168 RmsProp 304 loss=0.342069 err=0.342069
I 2015-05-26 08:12:30 theanets.trainer:168 RmsProp 305 loss=0.332031 err=0.332031
I 2015-05-26 08:12:41 theanets.trainer:168 RmsProp 306 loss=0.339873 err=0.339873
I 2015-05-26 08:12:51 theanets.trainer:168 RmsProp 307 loss=0.332714 err=0.332714
I 2015-05-26 08:13:01 theanets.trainer:168 RmsProp 308 loss=0.348302 err=0.348302
I 2015-05-26 08:13:12 theanets.trainer:168 RmsProp 309 loss=0.331137 err=0.331137
I 2015-05-26 08:13:23 theanets.trainer:168 RmsProp 310 loss=0.335477 err=0.335477
I 2015-05-26 08:13:23 theanets.trainer:168 validation 31 loss=1774.480347 err=1774.480347 *
I 2015-05-26 08:13:34 theanets.trainer:168 RmsProp 311 loss=0.337152 err=0.337152
I 2015-05-26 08:13:44 theanets.trainer:168 RmsProp 312 loss=0.344053 err=0.344053
I 2015-05-26 08:13:54 theanets.trainer:168 RmsProp 313 loss=0.328920 err=0.328920
I 2015-05-26 08:14:04 theanets.trainer:168 RmsProp 314 loss=0.325225 err=0.325225
I 2015-05-26 08:14:14 theanets.trainer:168 RmsProp 315 loss=0.313133 err=0.313133
I 2015-05-26 08:14:25 theanets.trainer:168 RmsProp 316 loss=0.336744 err=0.336744
I 2015-05-26 08:14:35 theanets.trainer:168 RmsProp 317 loss=0.322452 err=0.322452
I 2015-05-26 08:14:45 theanets.trainer:168 RmsProp 318 loss=0.319076 err=0.319076
I 2015-05-26 08:14:55 theanets.trainer:168 RmsProp 319 loss=0.335366 err=0.335366
I 2015-05-26 08:15:06 theanets.trainer:168 RmsProp 320 loss=0.329287 err=0.329287
I 2015-05-26 08:15:06 theanets.trainer:168 validation 32 loss=1771.701172 err=1771.701172 *
I 2015-05-26 08:15:17 theanets.trainer:168 RmsProp 321 loss=0.338466 err=0.338466
I 2015-05-26 08:15:27 theanets.trainer:168 RmsProp 322 loss=0.324008 err=0.324008
I 2015-05-26 08:15:37 theanets.trainer:168 RmsProp 323 loss=0.310281 err=0.310281
I 2015-05-26 08:15:48 theanets.trainer:168 RmsProp 324 loss=0.326201 err=0.326201
I 2015-05-26 08:15:58 theanets.trainer:168 RmsProp 325 loss=0.312364 err=0.312364
I 2015-05-26 08:16:08 theanets.trainer:168 RmsProp 326 loss=0.302048 err=0.302048
I 2015-05-26 08:16:19 theanets.trainer:168 RmsProp 327 loss=0.321067 err=0.321067
I 2015-05-26 08:16:29 theanets.trainer:168 RmsProp 328 loss=0.344558 err=0.344558
I 2015-05-26 08:16:39 theanets.trainer:168 RmsProp 329 loss=0.315406 err=0.315406
I 2015-05-26 08:16:49 theanets.trainer:168 RmsProp 330 loss=0.316024 err=0.316024
I 2015-05-26 08:16:50 theanets.trainer:168 validation 33 loss=1767.765625 err=1767.765625 *
I 2015-05-26 08:17:00 theanets.trainer:168 RmsProp 331 loss=0.320254 err=0.320254
I 2015-05-26 08:17:11 theanets.trainer:168 RmsProp 332 loss=0.316603 err=0.316603
I 2015-05-26 08:17:21 theanets.trainer:168 RmsProp 333 loss=0.315190 err=0.315190
I 2015-05-26 08:17:31 theanets.trainer:168 RmsProp 334 loss=0.306984 err=0.306984
I 2015-05-26 08:17:41 theanets.trainer:168 RmsProp 335 loss=0.318260 err=0.318260
I 2015-05-26 08:17:52 theanets.trainer:168 RmsProp 336 loss=0.313321 err=0.313321
I 2015-05-26 08:18:02 theanets.trainer:168 RmsProp 337 loss=0.323698 err=0.323698
I 2015-05-26 08:18:13 theanets.trainer:168 RmsProp 338 loss=0.318674 err=0.318674
I 2015-05-26 08:18:23 theanets.trainer:168 RmsProp 339 loss=0.314198 err=0.314198
I 2015-05-26 08:18:34 theanets.trainer:168 RmsProp 340 loss=0.307756 err=0.307756
I 2015-05-26 08:18:34 theanets.trainer:168 validation 34 loss=1765.180298 err=1765.180298 *
I 2015-05-26 08:18:44 theanets.trainer:168 RmsProp 341 loss=0.299638 err=0.299638
I 2015-05-26 08:18:55 theanets.trainer:168 RmsProp 342 loss=0.291578 err=0.291578
I 2015-05-26 08:19:05 theanets.trainer:168 RmsProp 343 loss=0.317471 err=0.317471
I 2015-05-26 08:19:16 theanets.trainer:168 RmsProp 344 loss=0.309293 err=0.309293
I 2015-05-26 08:19:27 theanets.trainer:168 RmsProp 345 loss=0.302537 err=0.302537
I 2015-05-26 08:19:37 theanets.trainer:168 RmsProp 346 loss=0.299086 err=0.299086
I 2015-05-26 08:19:48 theanets.trainer:168 RmsProp 347 loss=0.304572 err=0.304572
I 2015-05-26 08:19:59 theanets.trainer:168 RmsProp 348 loss=0.303988 err=0.303988
I 2015-05-26 08:20:09 theanets.trainer:168 RmsProp 349 loss=0.302180 err=0.302180
I 2015-05-26 08:20:19 theanets.trainer:168 RmsProp 350 loss=0.298000 err=0.298000
I 2015-05-26 08:20:20 theanets.trainer:168 validation 35 loss=1763.319946 err=1763.319946 *
I 2015-05-26 08:20:30 theanets.trainer:168 RmsProp 351 loss=0.306574 err=0.306574
I 2015-05-26 08:20:41 theanets.trainer:168 RmsProp 352 loss=0.309592 err=0.309592
I 2015-05-26 08:20:51 theanets.trainer:168 RmsProp 353 loss=0.294584 err=0.294584
I 2015-05-26 08:21:01 theanets.trainer:168 RmsProp 354 loss=0.301640 err=0.301640
I 2015-05-26 08:21:12 theanets.trainer:168 RmsProp 355 loss=0.313030 err=0.313030
I 2015-05-26 08:21:22 theanets.trainer:168 RmsProp 356 loss=0.297018 err=0.297018
I 2015-05-26 08:21:32 theanets.trainer:168 RmsProp 357 loss=0.287522 err=0.287522
I 2015-05-26 08:21:43 theanets.trainer:168 RmsProp 358 loss=0.284926 err=0.284926
I 2015-05-26 08:21:53 theanets.trainer:168 RmsProp 359 loss=0.304847 err=0.304847
I 2015-05-26 08:22:04 theanets.trainer:168 RmsProp 360 loss=0.290204 err=0.290204
I 2015-05-26 08:22:04 theanets.trainer:168 validation 36 loss=1758.541626 err=1758.541626 *
I 2015-05-26 08:22:15 theanets.trainer:168 RmsProp 361 loss=0.294570 err=0.294570
I 2015-05-26 08:22:25 theanets.trainer:168 RmsProp 362 loss=0.294030 err=0.294030
I 2015-05-26 08:22:36 theanets.trainer:168 RmsProp 363 loss=0.295637 err=0.295637
I 2015-05-26 08:22:46 theanets.trainer:168 RmsProp 364 loss=0.285815 err=0.285815
I 2015-05-26 08:22:57 theanets.trainer:168 RmsProp 365 loss=0.284391 err=0.284391
I 2015-05-26 08:23:07 theanets.trainer:168 RmsProp 366 loss=0.285462 err=0.285462
I 2015-05-26 08:23:18 theanets.trainer:168 RmsProp 367 loss=0.286530 err=0.286530
I 2015-05-26 08:23:28 theanets.trainer:168 RmsProp 368 loss=0.293413 err=0.293413
I 2015-05-26 08:23:39 theanets.trainer:168 RmsProp 369 loss=0.306137 err=0.306137
I 2015-05-26 08:23:49 theanets.trainer:168 RmsProp 370 loss=0.276040 err=0.276040
I 2015-05-26 08:23:49 theanets.trainer:168 validation 37 loss=1760.043335 err=1760.043335
I 2015-05-26 08:24:00 theanets.trainer:168 RmsProp 371 loss=0.270167 err=0.270167
I 2015-05-26 08:24:10 theanets.trainer:168 RmsProp 372 loss=0.323820 err=0.323820
I 2015-05-26 08:24:20 theanets.trainer:168 RmsProp 373 loss=0.273831 err=0.273831
I 2015-05-26 08:24:31 theanets.trainer:168 RmsProp 374 loss=0.279349 err=0.279349
I 2015-05-26 08:24:41 theanets.trainer:168 RmsProp 375 loss=0.279962 err=0.279962
I 2015-05-26 08:24:52 theanets.trainer:168 RmsProp 376 loss=0.289134 err=0.289134
I 2015-05-26 08:25:03 theanets.trainer:168 RmsProp 377 loss=0.268453 err=0.268453
I 2015-05-26 08:25:13 theanets.trainer:168 RmsProp 378 loss=0.282367 err=0.282367
I 2015-05-26 08:25:24 theanets.trainer:168 RmsProp 379 loss=0.282956 err=0.282956
I 2015-05-26 08:25:34 theanets.trainer:168 RmsProp 380 loss=0.270365 err=0.270365
I 2015-05-26 08:25:35 theanets.trainer:168 validation 38 loss=1754.618774 err=1754.618774 *
I 2015-05-26 08:25:45 theanets.trainer:168 RmsProp 381 loss=0.293889 err=0.293889
I 2015-05-26 08:25:56 theanets.trainer:168 RmsProp 382 loss=0.275119 err=0.275119
I 2015-05-26 08:26:06 theanets.trainer:168 RmsProp 383 loss=0.273803 err=0.273803
I 2015-05-26 08:26:17 theanets.trainer:168 RmsProp 384 loss=0.264061 err=0.264061
I 2015-05-26 08:26:27 theanets.trainer:168 RmsProp 385 loss=0.298100 err=0.298100
I 2015-05-26 08:26:38 theanets.trainer:168 RmsProp 386 loss=0.268836 err=0.268836
I 2015-05-26 08:26:48 theanets.trainer:168 RmsProp 387 loss=0.272002 err=0.272002
I 2015-05-26 08:26:59 theanets.trainer:168 RmsProp 388 loss=0.274082 err=0.274082
I 2015-05-26 08:27:10 theanets.trainer:168 RmsProp 389 loss=0.275241 err=0.275241
I 2015-05-26 08:27:21 theanets.trainer:168 RmsProp 390 loss=0.261414 err=0.261414
I 2015-05-26 08:27:21 theanets.trainer:168 validation 39 loss=1754.020386 err=1754.020386 *
I 2015-05-26 08:27:32 theanets.trainer:168 RmsProp 391 loss=0.261373 err=0.261373
I 2015-05-26 08:27:43 theanets.trainer:168 RmsProp 392 loss=0.266442 err=0.266442
I 2015-05-26 08:27:53 theanets.trainer:168 RmsProp 393 loss=0.263477 err=0.263477
I 2015-05-26 08:28:03 theanets.trainer:168 RmsProp 394 loss=0.274256 err=0.274256
I 2015-05-26 08:28:14 theanets.trainer:168 RmsProp 395 loss=0.284972 err=0.284972
I 2015-05-26 08:28:24 theanets.trainer:168 RmsProp 396 loss=0.266356 err=0.266356
I 2015-05-26 08:28:35 theanets.trainer:168 RmsProp 397 loss=0.262552 err=0.262552
I 2015-05-26 08:28:45 theanets.trainer:168 RmsProp 398 loss=0.269106 err=0.269106
I 2015-05-26 08:28:56 theanets.trainer:168 RmsProp 399 loss=0.268645 err=0.268645
I 2015-05-26 08:29:06 theanets.trainer:168 RmsProp 400 loss=0.261306 err=0.261306
I 2015-05-26 08:29:07 theanets.trainer:168 validation 40 loss=1752.876953 err=1752.876953 *
I 2015-05-26 08:29:17 theanets.trainer:168 RmsProp 401 loss=0.264876 err=0.264876
I 2015-05-26 08:29:28 theanets.trainer:168 RmsProp 402 loss=0.276395 err=0.276395
I 2015-05-26 08:29:38 theanets.trainer:168 RmsProp 403 loss=0.262916 err=0.262916
I 2015-05-26 08:29:48 theanets.trainer:168 RmsProp 404 loss=0.270104 err=0.270104
I 2015-05-26 08:29:59 theanets.trainer:168 RmsProp 405 loss=0.256006 err=0.256006
I 2015-05-26 08:30:10 theanets.trainer:168 RmsProp 406 loss=0.248066 err=0.248066
I 2015-05-26 08:30:20 theanets.trainer:168 RmsProp 407 loss=0.272584 err=0.272584
I 2015-05-26 08:30:31 theanets.trainer:168 RmsProp 408 loss=0.271233 err=0.271233
I 2015-05-26 08:30:42 theanets.trainer:168 RmsProp 409 loss=0.262061 err=0.262061
I 2015-05-26 08:30:53 theanets.trainer:168 RmsProp 410 loss=0.267327 err=0.267327
I 2015-05-26 08:30:53 theanets.trainer:168 validation 41 loss=1748.847290 err=1748.847290 *
I 2015-05-26 08:31:04 theanets.trainer:168 RmsProp 411 loss=0.249795 err=0.249795
I 2015-05-26 08:31:14 theanets.trainer:168 RmsProp 412 loss=0.240190 err=0.240190
I 2015-05-26 08:31:25 theanets.trainer:168 RmsProp 413 loss=0.273865 err=0.273865
I 2015-05-26 08:31:35 theanets.trainer:168 RmsProp 414 loss=0.245164 err=0.245164
I 2015-05-26 08:31:45 theanets.trainer:168 RmsProp 415 loss=0.255244 err=0.255244
I 2015-05-26 08:31:55 theanets.trainer:168 RmsProp 416 loss=0.254619 err=0.254619
I 2015-05-26 08:32:05 theanets.trainer:168 RmsProp 417 loss=0.249164 err=0.249164
I 2015-05-26 08:32:16 theanets.trainer:168 RmsProp 418 loss=0.256598 err=0.256598
I 2015-05-26 08:32:26 theanets.trainer:168 RmsProp 419 loss=0.249862 err=0.249862
I 2015-05-26 08:32:36 theanets.trainer:168 RmsProp 420 loss=0.255128 err=0.255128
I 2015-05-26 08:32:36 theanets.trainer:168 validation 42 loss=1746.967651 err=1746.967651 *
I 2015-05-26 08:32:46 theanets.trainer:168 RmsProp 421 loss=0.261294 err=0.261294
I 2015-05-26 08:32:56 theanets.trainer:168 RmsProp 422 loss=0.261296 err=0.261296
I 2015-05-26 08:33:06 theanets.trainer:168 RmsProp 423 loss=0.251063 err=0.251063
I 2015-05-26 08:33:16 theanets.trainer:168 RmsProp 424 loss=0.240045 err=0.240045
I 2015-05-26 08:33:26 theanets.trainer:168 RmsProp 425 loss=0.257652 err=0.257652
I 2015-05-26 08:33:35 theanets.trainer:168 RmsProp 426 loss=0.244526 err=0.244526
I 2015-05-26 08:33:45 theanets.trainer:168 RmsProp 427 loss=0.250206 err=0.250206
I 2015-05-26 08:33:55 theanets.trainer:168 RmsProp 428 loss=0.253660 err=0.253660
I 2015-05-26 08:34:05 theanets.trainer:168 RmsProp 429 loss=0.233000 err=0.233000
I 2015-05-26 08:34:15 theanets.trainer:168 RmsProp 430 loss=0.256783 err=0.256783
I 2015-05-26 08:34:16 theanets.trainer:168 validation 43 loss=1745.182617 err=1745.182617 *
I 2015-05-26 08:34:26 theanets.trainer:168 RmsProp 431 loss=0.251807 err=0.251807
I 2015-05-26 08:34:36 theanets.trainer:168 RmsProp 432 loss=0.245899 err=0.245899
I 2015-05-26 08:34:46 theanets.trainer:168 RmsProp 433 loss=0.253851 err=0.253851
I 2015-05-26 08:34:56 theanets.trainer:168 RmsProp 434 loss=0.242813 err=0.242813
I 2015-05-26 08:35:07 theanets.trainer:168 RmsProp 435 loss=0.241864 err=0.241864
I 2015-05-26 08:35:17 theanets.trainer:168 RmsProp 436 loss=0.258409 err=0.258409
I 2015-05-26 08:35:27 theanets.trainer:168 RmsProp 437 loss=0.254115 err=0.254115
I 2015-05-26 08:35:38 theanets.trainer:168 RmsProp 438 loss=0.249388 err=0.249388
I 2015-05-26 08:35:48 theanets.trainer:168 RmsProp 439 loss=0.245651 err=0.245651
I 2015-05-26 08:35:57 theanets.trainer:168 RmsProp 440 loss=0.237232 err=0.237232
I 2015-05-26 08:35:58 theanets.trainer:168 validation 44 loss=1743.635132 err=1743.635132 *
I 2015-05-26 08:36:08 theanets.trainer:168 RmsProp 441 loss=0.225149 err=0.225149
I 2015-05-26 08:36:17 theanets.trainer:168 RmsProp 442 loss=0.254239 err=0.254239
I 2015-05-26 08:36:27 theanets.trainer:168 RmsProp 443 loss=0.234324 err=0.234324
I 2015-05-26 08:36:37 theanets.trainer:168 RmsProp 444 loss=0.247532 err=0.247532
I 2015-05-26 08:36:47 theanets.trainer:168 RmsProp 445 loss=0.260341 err=0.260341
I 2015-05-26 08:36:58 theanets.trainer:168 RmsProp 446 loss=0.236502 err=0.236502
I 2015-05-26 08:37:07 theanets.trainer:168 RmsProp 447 loss=0.234041 err=0.234041
I 2015-05-26 08:37:17 theanets.trainer:168 RmsProp 448 loss=0.252666 err=0.252666
I 2015-05-26 08:37:27 theanets.trainer:168 RmsProp 449 loss=0.239488 err=0.239488
I 2015-05-26 08:37:36 theanets.trainer:168 RmsProp 450 loss=0.238941 err=0.238941
I 2015-05-26 08:37:37 theanets.trainer:168 validation 45 loss=1744.939087 err=1744.939087
I 2015-05-26 08:37:47 theanets.trainer:168 RmsProp 451 loss=0.239420 err=0.239420
I 2015-05-26 08:37:56 theanets.trainer:168 RmsProp 452 loss=0.231151 err=0.231151
I 2015-05-26 08:38:06 theanets.trainer:168 RmsProp 453 loss=0.236446 err=0.236446
I 2015-05-26 08:38:16 theanets.trainer:168 RmsProp 454 loss=0.229822 err=0.229822
I 2015-05-26 08:38:26 theanets.trainer:168 RmsProp 455 loss=0.230456 err=0.230456
I 2015-05-26 08:38:36 theanets.trainer:168 RmsProp 456 loss=0.222559 err=0.222559
I 2015-05-26 08:38:46 theanets.trainer:168 RmsProp 457 loss=0.256101 err=0.256101
I 2015-05-26 08:38:56 theanets.trainer:168 RmsProp 458 loss=0.234432 err=0.234432
I 2015-05-26 08:39:06 theanets.trainer:168 RmsProp 459 loss=0.223310 err=0.223310
I 2015-05-26 08:39:16 theanets.trainer:168 RmsProp 460 loss=0.249973 err=0.249973
I 2015-05-26 08:39:16 theanets.trainer:168 validation 46 loss=1739.346558 err=1739.346558 *
I 2015-05-26 08:39:26 theanets.trainer:168 RmsProp 461 loss=0.239385 err=0.239385
I 2015-05-26 08:39:36 theanets.trainer:168 RmsProp 462 loss=0.218551 err=0.218551
I 2015-05-26 08:39:46 theanets.trainer:168 RmsProp 463 loss=0.237200 err=0.237200
I 2015-05-26 08:39:56 theanets.trainer:168 RmsProp 464 loss=0.226503 err=0.226503
I 2015-05-26 08:40:06 theanets.trainer:168 RmsProp 465 loss=0.225185 err=0.225185
I 2015-05-26 08:40:16 theanets.trainer:168 RmsProp 466 loss=0.236941 err=0.236941
I 2015-05-26 08:40:26 theanets.trainer:168 RmsProp 467 loss=0.228526 err=0.228526
I 2015-05-26 08:40:36 theanets.trainer:168 RmsProp 468 loss=0.223326 err=0.223326
I 2015-05-26 08:40:45 theanets.trainer:168 RmsProp 469 loss=0.223176 err=0.223176
I 2015-05-26 08:40:55 theanets.trainer:168 RmsProp 470 loss=0.227937 err=0.227937
I 2015-05-26 08:40:55 theanets.trainer:168 validation 47 loss=1740.363159 err=1740.363159
I 2015-05-26 08:41:05 theanets.trainer:168 RmsProp 471 loss=0.222026 err=0.222026
I 2015-05-26 08:41:15 theanets.trainer:168 RmsProp 472 loss=0.230284 err=0.230284
I 2015-05-26 08:41:25 theanets.trainer:168 RmsProp 473 loss=0.235546 err=0.235546
I 2015-05-26 08:41:35 theanets.trainer:168 RmsProp 474 loss=0.222835 err=0.222835
I 2015-05-26 08:41:45 theanets.trainer:168 RmsProp 475 loss=0.226781 err=0.226781
I 2015-05-26 08:41:55 theanets.trainer:168 RmsProp 476 loss=0.223066 err=0.223066
I 2015-05-26 08:42:05 theanets.trainer:168 RmsProp 477 loss=0.232626 err=0.232626
I 2015-05-26 08:42:15 theanets.trainer:168 RmsProp 478 loss=0.224866 err=0.224866
I 2015-05-26 08:42:26 theanets.trainer:168 RmsProp 479 loss=0.217580 err=0.217580
I 2015-05-26 08:42:35 theanets.trainer:168 RmsProp 480 loss=0.226244 err=0.226244
I 2015-05-26 08:42:36 theanets.trainer:168 validation 48 loss=1735.104736 err=1735.104736 *
I 2015-05-26 08:42:46 theanets.trainer:168 RmsProp 481 loss=0.224844 err=0.224844
I 2015-05-26 08:42:55 theanets.trainer:168 RmsProp 482 loss=0.229766 err=0.229766
I 2015-05-26 08:43:05 theanets.trainer:168 RmsProp 483 loss=0.219460 err=0.219460
I 2015-05-26 08:43:15 theanets.trainer:168 RmsProp 484 loss=0.223271 err=0.223271
I 2015-05-26 08:43:25 theanets.trainer:168 RmsProp 485 loss=0.220384 err=0.220384
I 2015-05-26 08:43:35 theanets.trainer:168 RmsProp 486 loss=0.223590 err=0.223590
I 2015-05-26 08:43:44 theanets.trainer:168 RmsProp 487 loss=0.217186 err=0.217186
I 2015-05-26 08:43:54 theanets.trainer:168 RmsProp 488 loss=0.216084 err=0.216084
I 2015-05-26 08:44:04 theanets.trainer:168 RmsProp 489 loss=0.229504 err=0.229504
I 2015-05-26 08:44:13 theanets.trainer:168 RmsProp 490 loss=0.212962 err=0.212962
I 2015-05-26 08:44:14 theanets.trainer:168 validation 49 loss=1737.528320 err=1737.528320
I 2015-05-26 08:44:24 theanets.trainer:168 RmsProp 491 loss=0.222920 err=0.222920
I 2015-05-26 08:44:34 theanets.trainer:168 RmsProp 492 loss=0.215527 err=0.215527
I 2015-05-26 08:44:43 theanets.trainer:168 RmsProp 493 loss=0.226954 err=0.226954
I 2015-05-26 08:44:53 theanets.trainer:168 RmsProp 494 loss=0.211248 err=0.211248
I 2015-05-26 08:45:03 theanets.trainer:168 RmsProp 495 loss=0.220935 err=0.220935
I 2015-05-26 08:45:13 theanets.trainer:168 RmsProp 496 loss=0.225752 err=0.225752
I 2015-05-26 08:45:23 theanets.trainer:168 RmsProp 497 loss=0.227603 err=0.227603
I 2015-05-26 08:45:33 theanets.trainer:168 RmsProp 498 loss=0.216359 err=0.216359
I 2015-05-26 08:45:42 theanets.trainer:168 RmsProp 499 loss=0.215718 err=0.215718
I 2015-05-26 08:45:52 theanets.trainer:168 RmsProp 500 loss=0.217528 err=0.217528
I 2015-05-26 08:45:53 theanets.trainer:168 validation 50 loss=1732.328735 err=1732.328735 *
I 2015-05-26 08:46:02 theanets.trainer:168 RmsProp 501 loss=0.206920 err=0.206920
I 2015-05-26 08:46:11 theanets.trainer:168 RmsProp 502 loss=0.222696 err=0.222696
I 2015-05-26 08:46:20 theanets.trainer:168 RmsProp 503 loss=0.211854 err=0.211854
I 2015-05-26 08:46:29 theanets.trainer:168 RmsProp 504 loss=0.209270 err=0.209270
I 2015-05-26 08:46:37 theanets.trainer:168 RmsProp 505 loss=0.222118 err=0.222118
I 2015-05-26 08:46:46 theanets.trainer:168 RmsProp 506 loss=0.223606 err=0.223606
I 2015-05-26 08:46:55 theanets.trainer:168 RmsProp 507 loss=0.210465 err=0.210465
I 2015-05-26 08:47:04 theanets.trainer:168 RmsProp 508 loss=0.204585 err=0.204585
I 2015-05-26 08:47:12 theanets.trainer:168 RmsProp 509 loss=0.230768 err=0.230768
I 2015-05-26 08:47:21 theanets.trainer:168 RmsProp 510 loss=0.211818 err=0.211818
I 2015-05-26 08:47:21 theanets.trainer:168 validation 51 loss=1731.748901 err=1731.748901 *
I 2015-05-26 08:47:30 theanets.trainer:168 RmsProp 511 loss=0.216855 err=0.216855
I 2015-05-26 08:47:38 theanets.trainer:168 RmsProp 512 loss=0.207305 err=0.207305
I 2015-05-26 08:47:47 theanets.trainer:168 RmsProp 513 loss=0.196725 err=0.196725
I 2015-05-26 08:47:56 theanets.trainer:168 RmsProp 514 loss=0.231258 err=0.231258
I 2015-05-26 08:48:05 theanets.trainer:168 RmsProp 515 loss=0.218676 err=0.218676
I 2015-05-26 08:48:14 theanets.trainer:168 RmsProp 516 loss=0.206068 err=0.206068
I 2015-05-26 08:48:22 theanets.trainer:168 RmsProp 517 loss=0.202131 err=0.202131
I 2015-05-26 08:48:31 theanets.trainer:168 RmsProp 518 loss=0.214291 err=0.214291
I 2015-05-26 08:48:40 theanets.trainer:168 RmsProp 519 loss=0.199972 err=0.199972
I 2015-05-26 08:48:49 theanets.trainer:168 RmsProp 520 loss=0.203312 err=0.203312
I 2015-05-26 08:48:49 theanets.trainer:168 validation 52 loss=1727.053101 err=1727.053101 *
I 2015-05-26 08:48:58 theanets.trainer:168 RmsProp 521 loss=0.196302 err=0.196302
I 2015-05-26 08:49:07 theanets.trainer:168 RmsProp 522 loss=0.227180 err=0.227180
I 2015-05-26 08:49:15 theanets.trainer:168 RmsProp 523 loss=0.217985 err=0.217985
I 2015-05-26 08:49:24 theanets.trainer:168 RmsProp 524 loss=0.205011 err=0.205011
I 2015-05-26 08:49:32 theanets.trainer:168 RmsProp 525 loss=0.197133 err=0.197133
I 2015-05-26 08:49:41 theanets.trainer:168 RmsProp 526 loss=0.203247 err=0.203247
I 2015-05-26 08:49:50 theanets.trainer:168 RmsProp 527 loss=0.201247 err=0.201247
I 2015-05-26 08:49:59 theanets.trainer:168 RmsProp 528 loss=0.210795 err=0.210795
I 2015-05-26 08:50:07 theanets.trainer:168 RmsProp 529 loss=0.199698 err=0.199698
I 2015-05-26 08:50:16 theanets.trainer:168 RmsProp 530 loss=0.212112 err=0.212112
I 2015-05-26 08:50:16 theanets.trainer:168 validation 53 loss=1724.786743 err=1724.786743 *
I 2015-05-26 08:50:25 theanets.trainer:168 RmsProp 531 loss=0.199167 err=0.199167
I 2015-05-26 08:50:34 theanets.trainer:168 RmsProp 532 loss=0.197673 err=0.197673
I 2015-05-26 08:50:42 theanets.trainer:168 RmsProp 533 loss=0.207486 err=0.207486
I 2015-05-26 08:50:51 theanets.trainer:168 RmsProp 534 loss=0.196646 err=0.196646
I 2015-05-26 08:50:59 theanets.trainer:168 RmsProp 535 loss=0.206864 err=0.206864
I 2015-05-26 08:51:07 theanets.trainer:168 RmsProp 536 loss=0.209288 err=0.209288
I 2015-05-26 08:51:15 theanets.trainer:168 RmsProp 537 loss=0.213857 err=0.213857
I 2015-05-26 08:51:24 theanets.trainer:168 RmsProp 538 loss=0.189549 err=0.189549
I 2015-05-26 08:51:32 theanets.trainer:168 RmsProp 539 loss=0.210575 err=0.210575
I 2015-05-26 08:51:40 theanets.trainer:168 RmsProp 540 loss=0.206125 err=0.206125
I 2015-05-26 08:51:41 theanets.trainer:168 validation 54 loss=1724.612183 err=1724.612183 *
I 2015-05-26 08:51:49 theanets.trainer:168 RmsProp 541 loss=0.196167 err=0.196167
I 2015-05-26 08:51:57 theanets.trainer:168 RmsProp 542 loss=0.202691 err=0.202691
I 2015-05-26 08:52:05 theanets.trainer:168 RmsProp 543 loss=0.198019 err=0.198019
I 2015-05-26 08:52:13 theanets.trainer:168 RmsProp 544 loss=0.197409 err=0.197409
I 2015-05-26 08:52:21 theanets.trainer:168 RmsProp 545 loss=0.192830 err=0.192830
I 2015-05-26 08:52:29 theanets.trainer:168 RmsProp 546 loss=0.202228 err=0.202228
I 2015-05-26 08:52:37 theanets.trainer:168 RmsProp 547 loss=0.201091 err=0.201091
I 2015-05-26 08:52:45 theanets.trainer:168 RmsProp 548 loss=0.199001 err=0.199001
I 2015-05-26 08:52:53 theanets.trainer:168 RmsProp 549 loss=0.198655 err=0.198655
I 2015-05-26 08:53:01 theanets.trainer:168 RmsProp 550 loss=0.194975 err=0.194975
I 2015-05-26 08:53:01 theanets.trainer:168 validation 55 loss=1723.859009 err=1723.859009 *
I 2015-05-26 08:53:09 theanets.trainer:168 RmsProp 551 loss=0.183942 err=0.183942
I 2015-05-26 08:53:17 theanets.trainer:168 RmsProp 552 loss=0.218027 err=0.218027
I 2015-05-26 08:53:24 theanets.trainer:168 RmsProp 553 loss=0.196582 err=0.196582
I 2015-05-26 08:53:32 theanets.trainer:168 RmsProp 554 loss=0.189144 err=0.189144
I 2015-05-26 08:53:40 theanets.trainer:168 RmsProp 555 loss=0.191706 err=0.191706
I 2015-05-26 08:53:49 theanets.trainer:168 RmsProp 556 loss=0.203045 err=0.203045
I 2015-05-26 08:53:57 theanets.trainer:168 RmsProp 557 loss=0.191431 err=0.191431
I 2015-05-26 08:54:05 theanets.trainer:168 RmsProp 558 loss=0.199670 err=0.199670
I 2015-05-26 08:54:13 theanets.trainer:168 RmsProp 559 loss=0.199087 err=0.199087
I 2015-05-26 08:54:21 theanets.trainer:168 RmsProp 560 loss=0.198854 err=0.198854
I 2015-05-26 08:54:21 theanets.trainer:168 validation 56 loss=1720.712524 err=1720.712524 *
I 2015-05-26 08:54:28 theanets.trainer:168 RmsProp 561 loss=0.203402 err=0.203402
I 2015-05-26 08:54:36 theanets.trainer:168 RmsProp 562 loss=0.183861 err=0.183861
I 2015-05-26 08:54:44 theanets.trainer:168 RmsProp 563 loss=0.194257 err=0.194257
I 2015-05-26 08:54:52 theanets.trainer:168 RmsProp 564 loss=0.191907 err=0.191907
I 2015-05-26 08:54:59 theanets.trainer:168 RmsProp 565 loss=0.196846 err=0.196846
I 2015-05-26 08:55:06 theanets.trainer:168 RmsProp 566 loss=0.188692 err=0.188692
I 2015-05-26 08:55:14 theanets.trainer:168 RmsProp 567 loss=0.184817 err=0.184817
I 2015-05-26 08:55:20 theanets.trainer:168 RmsProp 568 loss=0.195411 err=0.195411
I 2015-05-26 08:55:28 theanets.trainer:168 RmsProp 569 loss=0.194114 err=0.194114
I 2015-05-26 08:55:35 theanets.trainer:168 RmsProp 570 loss=0.192565 err=0.192565
I 2015-05-26 08:55:35 theanets.trainer:168 validation 57 loss=1717.791260 err=1717.791260 *
I 2015-05-26 08:55:43 theanets.trainer:168 RmsProp 571 loss=0.194971 err=0.194971
I 2015-05-26 08:55:51 theanets.trainer:168 RmsProp 572 loss=0.181654 err=0.181654
I 2015-05-26 08:55:58 theanets.trainer:168 RmsProp 573 loss=0.184027 err=0.184027
I 2015-05-26 08:56:06 theanets.trainer:168 RmsProp 574 loss=0.192692 err=0.192692
I 2015-05-26 08:56:13 theanets.trainer:168 RmsProp 575 loss=0.189508 err=0.189508
I 2015-05-26 08:56:20 theanets.trainer:168 RmsProp 576 loss=0.186702 err=0.186702
I 2015-05-26 08:56:27 theanets.trainer:168 RmsProp 577 loss=0.197405 err=0.197405
I 2015-05-26 08:56:35 theanets.trainer:168 RmsProp 578 loss=0.191104 err=0.191104
I 2015-05-26 08:56:42 theanets.trainer:168 RmsProp 579 loss=0.194140 err=0.194140
I 2015-05-26 08:56:49 theanets.trainer:168 RmsProp 580 loss=0.186009 err=0.186009
I 2015-05-26 08:56:49 theanets.trainer:168 validation 58 loss=1716.386719 err=1716.386719 *
I 2015-05-26 08:56:57 theanets.trainer:168 RmsProp 581 loss=0.200751 err=0.200751
I 2015-05-26 08:57:04 theanets.trainer:168 RmsProp 582 loss=0.186687 err=0.186687
I 2015-05-26 08:57:12 theanets.trainer:168 RmsProp 583 loss=0.192220 err=0.192220
I 2015-05-26 08:57:19 theanets.trainer:168 RmsProp 584 loss=0.177024 err=0.177024
I 2015-05-26 08:57:27 theanets.trainer:168 RmsProp 585 loss=0.183477 err=0.183477
I 2015-05-26 08:57:36 theanets.trainer:168 RmsProp 586 loss=0.193588 err=0.193588
I 2015-05-26 08:57:44 theanets.trainer:168 RmsProp 587 loss=0.188895 err=0.188895
I 2015-05-26 08:57:52 theanets.trainer:168 RmsProp 588 loss=0.183503 err=0.183503
I 2015-05-26 08:57:59 theanets.trainer:168 RmsProp 589 loss=0.193061 err=0.193061
I 2015-05-26 08:58:07 theanets.trainer:168 RmsProp 590 loss=0.177569 err=0.177569
I 2015-05-26 08:58:08 theanets.trainer:168 validation 59 loss=1713.796509 err=1713.796509 *
I 2015-05-26 08:58:14 theanets.trainer:168 RmsProp 591 loss=0.191167 err=0.191167
I 2015-05-26 08:58:21 theanets.trainer:168 RmsProp 592 loss=0.184996 err=0.184996
I 2015-05-26 08:58:29 theanets.trainer:168 RmsProp 593 loss=0.182487 err=0.182487
I 2015-05-26 08:58:37 theanets.trainer:168 RmsProp 594 loss=0.180561 err=0.180561
I 2015-05-26 08:58:45 theanets.trainer:168 RmsProp 595 loss=0.183155 err=0.183155
I 2015-05-26 08:58:53 theanets.trainer:168 RmsProp 596 loss=0.171055 err=0.171055
I 2015-05-26 08:58:59 theanets.trainer:168 RmsProp 597 loss=0.204039 err=0.204039
I 2015-05-26 08:59:06 theanets.trainer:168 RmsProp 598 loss=0.180215 err=0.180215
I 2015-05-26 08:59:14 theanets.trainer:168 RmsProp 599 loss=0.194614 err=0.194614
I 2015-05-26 08:59:22 theanets.trainer:168 RmsProp 600 loss=0.171993 err=0.171993
I 2015-05-26 08:59:22 theanets.trainer:168 validation 60 loss=1710.239136 err=1710.239136 *
I 2015-05-26 08:59:30 theanets.trainer:168 RmsProp 601 loss=0.188376 err=0.188376
I 2015-05-26 08:59:37 theanets.trainer:168 RmsProp 602 loss=0.196511 err=0.196511
I 2015-05-26 08:59:44 theanets.trainer:168 RmsProp 603 loss=0.183628 err=0.183628
I 2015-05-26 08:59:51 theanets.trainer:168 RmsProp 604 loss=0.179022 err=0.179022
I 2015-05-26 08:59:59 theanets.trainer:168 RmsProp 605 loss=0.176701 err=0.176701
I 2015-05-26 09:00:07 theanets.trainer:168 RmsProp 606 loss=0.176694 err=0.176694
I 2015-05-26 09:00:14 theanets.trainer:168 RmsProp 607 loss=0.169447 err=0.169447
I 2015-05-26 09:00:22 theanets.trainer:168 RmsProp 608 loss=0.186662 err=0.186662
I 2015-05-26 09:00:30 theanets.trainer:168 RmsProp 609 loss=0.183423 err=0.183423
I 2015-05-26 09:00:38 theanets.trainer:168 RmsProp 610 loss=0.175004 err=0.175004
I 2015-05-26 09:00:38 theanets.trainer:168 validation 61 loss=1712.790283 err=1712.790283
I 2015-05-26 09:00:46 theanets.trainer:168 RmsProp 611 loss=0.183634 err=0.183634
I 2015-05-26 09:00:54 theanets.trainer:168 RmsProp 612 loss=0.172935 err=0.172935
I 2015-05-26 09:01:01 theanets.trainer:168 RmsProp 613 loss=0.204842 err=0.204842
I 2015-05-26 09:01:08 theanets.trainer:168 RmsProp 614 loss=0.191464 err=0.191464
I 2015-05-26 09:01:16 theanets.trainer:168 RmsProp 615 loss=0.174802 err=0.174802
I 2015-05-26 09:01:23 theanets.trainer:168 RmsProp 616 loss=0.172524 err=0.172524
I 2015-05-26 09:01:30 theanets.trainer:168 RmsProp 617 loss=0.182095 err=0.182095
I 2015-05-26 09:01:37 theanets.trainer:168 RmsProp 618 loss=0.176360 err=0.176360
I 2015-05-26 09:01:46 theanets.trainer:168 RmsProp 619 loss=0.168000 err=0.168000
I 2015-05-26 09:01:52 theanets.trainer:168 RmsProp 620 loss=0.173019 err=0.173019
I 2015-05-26 09:01:53 theanets.trainer:168 validation 62 loss=1710.550781 err=1710.550781
I 2015-05-26 09:02:01 theanets.trainer:168 RmsProp 621 loss=0.182104 err=0.182104
I 2015-05-26 09:02:09 theanets.trainer:168 RmsProp 622 loss=0.167369 err=0.167369
I 2015-05-26 09:02:16 theanets.trainer:168 RmsProp 623 loss=0.187924 err=0.187924
I 2015-05-26 09:02:22 theanets.trainer:168 RmsProp 624 loss=0.189235 err=0.189235
I 2015-05-26 09:02:29 theanets.trainer:168 RmsProp 625 loss=0.174789 err=0.174789
I 2015-05-26 09:02:37 theanets.trainer:168 RmsProp 626 loss=0.177038 err=0.177038
I 2015-05-26 09:02:45 theanets.trainer:168 RmsProp 627 loss=0.172776 err=0.172776
I 2015-05-26 09:02:51 theanets.trainer:168 RmsProp 628 loss=0.177468 err=0.177468
I 2015-05-26 09:02:59 theanets.trainer:168 RmsProp 629 loss=0.168976 err=0.168976
I 2015-05-26 09:03:07 theanets.trainer:168 RmsProp 630 loss=0.163293 err=0.163293
I 2015-05-26 09:03:07 theanets.trainer:168 validation 63 loss=1709.015625 err=1709.015625 *
I 2015-05-26 09:03:15 theanets.trainer:168 RmsProp 631 loss=0.194770 err=0.194770
I 2015-05-26 09:03:22 theanets.trainer:168 RmsProp 632 loss=0.196435 err=0.196435
I 2015-05-26 09:03:29 theanets.trainer:168 RmsProp 633 loss=0.168143 err=0.168143
I 2015-05-26 09:03:36 theanets.trainer:168 RmsProp 634 loss=0.169769 err=0.169769
I 2015-05-26 09:03:45 theanets.trainer:168 RmsProp 635 loss=0.174235 err=0.174235
I 2015-05-26 09:03:52 theanets.trainer:168 RmsProp 636 loss=0.183875 err=0.183875
I 2015-05-26 09:03:59 theanets.trainer:168 RmsProp 637 loss=0.169828 err=0.169828
I 2015-05-26 09:04:06 theanets.trainer:168 RmsProp 638 loss=0.174735 err=0.174735
I 2015-05-26 09:04:14 theanets.trainer:168 RmsProp 639 loss=0.166789 err=0.166789
I 2015-05-26 09:04:22 theanets.trainer:168 RmsProp 640 loss=0.179814 err=0.179814
I 2015-05-26 09:04:22 theanets.trainer:168 validation 64 loss=1705.448853 err=1705.448853 *
I 2015-05-26 09:04:29 theanets.trainer:168 RmsProp 641 loss=0.169714 err=0.169714
I 2015-05-26 09:04:37 theanets.trainer:168 RmsProp 642 loss=0.167886 err=0.167886
I 2015-05-26 09:04:44 theanets.trainer:168 RmsProp 643 loss=0.158766 err=0.158766
I 2015-05-26 09:04:51 theanets.trainer:168 RmsProp 644 loss=0.190955 err=0.190955
I 2015-05-26 09:04:59 theanets.trainer:168 RmsProp 645 loss=0.163500 err=0.163500
I 2015-05-26 09:05:06 theanets.trainer:168 RmsProp 646 loss=0.188527 err=0.188527
I 2015-05-26 09:05:14 theanets.trainer:168 RmsProp 647 loss=0.169095 err=0.169095
I 2015-05-26 09:05:21 theanets.trainer:168 RmsProp 648 loss=0.159221 err=0.159221
I 2015-05-26 09:05:28 theanets.trainer:168 RmsProp 649 loss=0.161654 err=0.161654
I 2015-05-26 09:05:35 theanets.trainer:168 RmsProp 650 loss=0.190059 err=0.190059
I 2015-05-26 09:05:36 theanets.trainer:168 validation 65 loss=1705.920288 err=1705.920288
I 2015-05-26 09:05:43 theanets.trainer:168 RmsProp 651 loss=0.162614 err=0.162614
I 2015-05-26 09:05:50 theanets.trainer:168 RmsProp 652 loss=0.163598 err=0.163598
I 2015-05-26 09:05:58 theanets.trainer:168 RmsProp 653 loss=0.172173 err=0.172173
I 2015-05-26 09:06:06 theanets.trainer:168 RmsProp 654 loss=0.172591 err=0.172591
I 2015-05-26 09:06:13 theanets.trainer:168 RmsProp 655 loss=0.158436 err=0.158436
I 2015-05-26 09:06:20 theanets.trainer:168 RmsProp 656 loss=0.176246 err=0.176246
I 2015-05-26 09:06:27 theanets.trainer:168 RmsProp 657 loss=0.163060 err=0.163060
I 2015-05-26 09:06:35 theanets.trainer:168 RmsProp 658 loss=0.169968 err=0.169968
I 2015-05-26 09:06:43 theanets.trainer:168 RmsProp 659 loss=0.156010 err=0.156010
I 2015-05-26 09:06:50 theanets.trainer:168 RmsProp 660 loss=0.167715 err=0.167715
I 2015-05-26 09:06:50 theanets.trainer:168 validation 66 loss=1704.281616 err=1704.281616 *
I 2015-05-26 09:06:59 theanets.trainer:168 RmsProp 661 loss=0.165957 err=0.165957
I 2015-05-26 09:07:06 theanets.trainer:168 RmsProp 662 loss=0.168351 err=0.168351
I 2015-05-26 09:07:14 theanets.trainer:168 RmsProp 663 loss=0.173184 err=0.173184
I 2015-05-26 09:07:21 theanets.trainer:168 RmsProp 664 loss=0.159431 err=0.159431
I 2015-05-26 09:07:29 theanets.trainer:168 RmsProp 665 loss=0.172148 err=0.172148
I 2015-05-26 09:07:37 theanets.trainer:168 RmsProp 666 loss=0.160877 err=0.160877
I 2015-05-26 09:07:45 theanets.trainer:168 RmsProp 667 loss=0.157048 err=0.157048
I 2015-05-26 09:07:53 theanets.trainer:168 RmsProp 668 loss=0.169678 err=0.169678
I 2015-05-26 09:08:01 theanets.trainer:168 RmsProp 669 loss=0.157796 err=0.157796
I 2015-05-26 09:08:09 theanets.trainer:168 RmsProp 670 loss=0.166872 err=0.166872
I 2015-05-26 09:08:09 theanets.trainer:168 validation 67 loss=1701.400269 err=1701.400269 *
I 2015-05-26 09:08:16 theanets.trainer:168 RmsProp 671 loss=0.172886 err=0.172886
I 2015-05-26 09:08:24 theanets.trainer:168 RmsProp 672 loss=0.164216 err=0.164216
I 2015-05-26 09:08:32 theanets.trainer:168 RmsProp 673 loss=0.162205 err=0.162205
I 2015-05-26 09:08:39 theanets.trainer:168 RmsProp 674 loss=0.166687 err=0.166687
I 2015-05-26 09:08:46 theanets.trainer:168 RmsProp 675 loss=0.159910 err=0.159910
I 2015-05-26 09:08:53 theanets.trainer:168 RmsProp 676 loss=0.172355 err=0.172355
I 2015-05-26 09:09:00 theanets.trainer:168 RmsProp 677 loss=0.160598 err=0.160598
I 2015-05-26 09:09:08 theanets.trainer:168 RmsProp 678 loss=0.160544 err=0.160544
I 2015-05-26 09:09:16 theanets.trainer:168 RmsProp 679 loss=0.163747 err=0.163747
I 2015-05-26 09:09:23 theanets.trainer:168 RmsProp 680 loss=0.167551 err=0.167551
I 2015-05-26 09:09:23 theanets.trainer:168 validation 68 loss=1701.634155 err=1701.634155
I 2015-05-26 09:09:31 theanets.trainer:168 RmsProp 681 loss=0.156895 err=0.156895
I 2015-05-26 09:09:39 theanets.trainer:168 RmsProp 682 loss=0.147261 err=0.147261
I 2015-05-26 09:09:46 theanets.trainer:168 RmsProp 683 loss=0.166170 err=0.166170
I 2015-05-26 09:09:54 theanets.trainer:168 RmsProp 684 loss=0.164748 err=0.164748
I 2015-05-26 09:10:01 theanets.trainer:168 RmsProp 685 loss=0.156973 err=0.156973
I 2015-05-26 09:10:08 theanets.trainer:168 RmsProp 686 loss=0.159907 err=0.159907
I 2015-05-26 09:10:15 theanets.trainer:168 RmsProp 687 loss=0.166503 err=0.166503
I 2015-05-26 09:10:23 theanets.trainer:168 RmsProp 688 loss=0.164069 err=0.164069
I 2015-05-26 09:10:32 theanets.trainer:168 RmsProp 689 loss=0.158714 err=0.158714
I 2015-05-26 09:10:39 theanets.trainer:168 RmsProp 690 loss=0.151444 err=0.151444
I 2015-05-26 09:10:40 theanets.trainer:168 validation 69 loss=1699.788330 err=1699.788330 *
I 2015-05-26 09:10:47 theanets.trainer:168 RmsProp 691 loss=0.188818 err=0.188818
I 2015-05-26 09:10:55 theanets.trainer:168 RmsProp 692 loss=0.163862 err=0.163862
I 2015-05-26 09:11:02 theanets.trainer:168 RmsProp 693 loss=0.164892 err=0.164892
I 2015-05-26 09:11:10 theanets.trainer:168 RmsProp 694 loss=0.155007 err=0.155007
I 2015-05-26 09:11:17 theanets.trainer:168 RmsProp 695 loss=0.161689 err=0.161689
I 2015-05-26 09:11:23 theanets.trainer:168 RmsProp 696 loss=0.153836 err=0.153836
I 2015-05-26 09:11:31 theanets.trainer:168 RmsProp 697 loss=0.155476 err=0.155476
I 2015-05-26 09:11:38 theanets.trainer:168 RmsProp 698 loss=0.148664 err=0.148664
I 2015-05-26 09:11:45 theanets.trainer:168 RmsProp 699 loss=0.170314 err=0.170314
I 2015-05-26 09:11:52 theanets.trainer:168 RmsProp 700 loss=0.161114 err=0.161114
I 2015-05-26 09:11:52 theanets.trainer:168 validation 70 loss=1697.129761 err=1697.129761 *
I 2015-05-26 09:12:00 theanets.trainer:168 RmsProp 701 loss=0.152801 err=0.152801
I 2015-05-26 09:12:08 theanets.trainer:168 RmsProp 702 loss=0.170091 err=0.170091
I 2015-05-26 09:12:16 theanets.trainer:168 RmsProp 703 loss=0.160533 err=0.160533
I 2015-05-26 09:12:22 theanets.trainer:168 RmsProp 704 loss=0.160832 err=0.160832
I 2015-05-26 09:12:30 theanets.trainer:168 RmsProp 705 loss=0.150735 err=0.150735
I 2015-05-26 09:12:38 theanets.trainer:168 RmsProp 706 loss=0.165431 err=0.165431
I 2015-05-26 09:12:44 theanets.trainer:168 RmsProp 707 loss=0.157164 err=0.157164
I 2015-05-26 09:12:51 theanets.trainer:168 RmsProp 708 loss=0.154082 err=0.154082
I 2015-05-26 09:12:59 theanets.trainer:168 RmsProp 709 loss=0.153678 err=0.153678
I 2015-05-26 09:13:07 theanets.trainer:168 RmsProp 710 loss=0.162483 err=0.162483
I 2015-05-26 09:13:08 theanets.trainer:168 validation 71 loss=1696.463257 err=1696.463257 *
I 2015-05-26 09:13:15 theanets.trainer:168 RmsProp 711 loss=0.154743 err=0.154743
I 2015-05-26 09:13:22 theanets.trainer:168 RmsProp 712 loss=0.154175 err=0.154175
I 2015-05-26 09:13:29 theanets.trainer:168 RmsProp 713 loss=0.157281 err=0.157281
I 2015-05-26 09:13:36 theanets.trainer:168 RmsProp 714 loss=0.147590 err=0.147590
I 2015-05-26 09:13:43 theanets.trainer:168 RmsProp 715 loss=0.154070 err=0.154070
I 2015-05-26 09:13:50 theanets.trainer:168 RmsProp 716 loss=0.155139 err=0.155139
I 2015-05-26 09:13:57 theanets.trainer:168 RmsProp 717 loss=0.157057 err=0.157057
I 2015-05-26 09:14:04 theanets.trainer:168 RmsProp 718 loss=0.156573 err=0.156573
I 2015-05-26 09:14:11 theanets.trainer:168 RmsProp 719 loss=0.156031 err=0.156031
I 2015-05-26 09:14:18 theanets.trainer:168 RmsProp 720 loss=0.158571 err=0.158571
I 2015-05-26 09:14:18 theanets.trainer:168 validation 72 loss=1696.170776 err=1696.170776 *
I 2015-05-26 09:14:26 theanets.trainer:168 RmsProp 721 loss=0.151098 err=0.151098
I 2015-05-26 09:14:34 theanets.trainer:168 RmsProp 722 loss=0.148718 err=0.148718
I 2015-05-26 09:14:40 theanets.trainer:168 RmsProp 723 loss=0.158114 err=0.158114
I 2015-05-26 09:14:47 theanets.trainer:168 RmsProp 724 loss=0.159876 err=0.159876
I 2015-05-26 09:14:54 theanets.trainer:168 RmsProp 725 loss=0.160987 err=0.160987
I 2015-05-26 09:15:01 theanets.trainer:168 RmsProp 726 loss=0.146288 err=0.146288
I 2015-05-26 09:15:09 theanets.trainer:168 RmsProp 727 loss=0.150357 err=0.150357
I 2015-05-26 09:15:17 theanets.trainer:168 RmsProp 728 loss=0.158065 err=0.158065
I 2015-05-26 09:15:23 theanets.trainer:168 RmsProp 729 loss=0.170586 err=0.170586
I 2015-05-26 09:15:30 theanets.trainer:168 RmsProp 730 loss=0.153105 err=0.153105
I 2015-05-26 09:15:31 theanets.trainer:168 validation 73 loss=1696.293823 err=1696.293823
I 2015-05-26 09:15:38 theanets.trainer:168 RmsProp 731 loss=0.149281 err=0.149281
I 2015-05-26 09:15:44 theanets.trainer:168 RmsProp 732 loss=0.157368 err=0.157368
I 2015-05-26 09:15:51 theanets.trainer:168 RmsProp 733 loss=0.151384 err=0.151384
I 2015-05-26 09:15:58 theanets.trainer:168 RmsProp 734 loss=0.151320 err=0.151320
I 2015-05-26 09:16:05 theanets.trainer:168 RmsProp 735 loss=0.149176 err=0.149176
I 2015-05-26 09:16:12 theanets.trainer:168 RmsProp 736 loss=0.159197 err=0.159197
I 2015-05-26 09:16:19 theanets.trainer:168 RmsProp 737 loss=0.142895 err=0.142895
I 2015-05-26 09:16:27 theanets.trainer:168 RmsProp 738 loss=0.146293 err=0.146293
I 2015-05-26 09:16:34 theanets.trainer:168 RmsProp 739 loss=0.163153 err=0.163153
I 2015-05-26 09:16:41 theanets.trainer:168 RmsProp 740 loss=0.142431 err=0.142431
I 2015-05-26 09:16:41 theanets.trainer:168 validation 74 loss=1691.901245 err=1691.901245 *
I 2015-05-26 09:16:48 theanets.trainer:168 RmsProp 741 loss=0.156785 err=0.156785
I 2015-05-26 09:16:55 theanets.trainer:168 RmsProp 742 loss=0.144018 err=0.144018
I 2015-05-26 09:17:02 theanets.trainer:168 RmsProp 743 loss=0.144266 err=0.144266
I 2015-05-26 09:17:09 theanets.trainer:168 RmsProp 744 loss=0.165313 err=0.165313
I 2015-05-26 09:17:17 theanets.trainer:168 RmsProp 745 loss=0.143211 err=0.143211
I 2015-05-26 09:17:25 theanets.trainer:168 RmsProp 746 loss=0.160333 err=0.160333
I 2015-05-26 09:17:31 theanets.trainer:168 RmsProp 747 loss=0.145826 err=0.145826
I 2015-05-26 09:17:39 theanets.trainer:168 RmsProp 748 loss=0.146896 err=0.146896
I 2015-05-26 09:17:46 theanets.trainer:168 RmsProp 749 loss=0.140892 err=0.140892
I 2015-05-26 09:17:53 theanets.trainer:168 RmsProp 750 loss=0.161526 err=0.161526
I 2015-05-26 09:17:53 theanets.trainer:168 validation 75 loss=1694.011719 err=1694.011719
I 2015-05-26 09:18:00 theanets.trainer:168 RmsProp 751 loss=0.141984 err=0.141984
I 2015-05-26 09:18:08 theanets.trainer:168 RmsProp 752 loss=0.153270 err=0.153270
I 2015-05-26 09:18:15 theanets.trainer:168 RmsProp 753 loss=0.138598 err=0.138598
I 2015-05-26 09:18:22 theanets.trainer:168 RmsProp 754 loss=0.149467 err=0.149467
I 2015-05-26 09:18:30 theanets.trainer:168 RmsProp 755 loss=0.139356 err=0.139356
I 2015-05-26 09:18:37 theanets.trainer:168 RmsProp 756 loss=0.156033 err=0.156033
I 2015-05-26 09:18:44 theanets.trainer:168 RmsProp 757 loss=0.150175 err=0.150175
I 2015-05-26 09:18:52 theanets.trainer:168 RmsProp 758 loss=0.140236 err=0.140236
I 2015-05-26 09:18:59 theanets.trainer:168 RmsProp 759 loss=0.156561 err=0.156561
I 2015-05-26 09:19:06 theanets.trainer:168 RmsProp 760 loss=0.155755 err=0.155755
I 2015-05-26 09:19:06 theanets.trainer:168 validation 76 loss=1690.824219 err=1690.824219 *
I 2015-05-26 09:19:14 theanets.trainer:168 RmsProp 761 loss=0.138990 err=0.138990
I 2015-05-26 09:19:21 theanets.trainer:168 RmsProp 762 loss=0.159090 err=0.159090
I 2015-05-26 09:19:29 theanets.trainer:168 RmsProp 763 loss=0.153997 err=0.153997
I 2015-05-26 09:19:36 theanets.trainer:168 RmsProp 764 loss=0.143788 err=0.143788
I 2015-05-26 09:19:43 theanets.trainer:168 RmsProp 765 loss=0.144479 err=0.144479
I 2015-05-26 09:19:50 theanets.trainer:168 RmsProp 766 loss=0.147066 err=0.147066
I 2015-05-26 09:19:57 theanets.trainer:168 RmsProp 767 loss=0.143032 err=0.143032
I 2015-05-26 09:20:05 theanets.trainer:168 RmsProp 768 loss=0.143001 err=0.143001
I 2015-05-26 09:20:12 theanets.trainer:168 RmsProp 769 loss=0.151187 err=0.151187
I 2015-05-26 09:20:19 theanets.trainer:168 RmsProp 770 loss=0.150815 err=0.150815
I 2015-05-26 09:20:19 theanets.trainer:168 validation 77 loss=1690.648804 err=1690.648804 *
I 2015-05-26 09:20:26 theanets.trainer:168 RmsProp 771 loss=0.144960 err=0.144960
I 2015-05-26 09:20:34 theanets.trainer:168 RmsProp 772 loss=0.149432 err=0.149432
I 2015-05-26 09:20:40 theanets.trainer:168 RmsProp 773 loss=0.133061 err=0.133061
I 2015-05-26 09:20:47 theanets.trainer:168 RmsProp 774 loss=0.148609 err=0.148609
I 2015-05-26 09:20:54 theanets.trainer:168 RmsProp 775 loss=0.146749 err=0.146749
I 2015-05-26 09:21:02 theanets.trainer:168 RmsProp 776 loss=0.146668 err=0.146668
I 2015-05-26 09:21:08 theanets.trainer:168 RmsProp 777 loss=0.138578 err=0.138578
I 2015-05-26 09:21:16 theanets.trainer:168 RmsProp 778 loss=0.149161 err=0.149161
I 2015-05-26 09:21:22 theanets.trainer:168 RmsProp 779 loss=0.150435 err=0.150435
I 2015-05-26 09:21:30 theanets.trainer:168 RmsProp 780 loss=0.138557 err=0.138557
I 2015-05-26 09:21:31 theanets.trainer:168 validation 78 loss=1685.928345 err=1685.928345 *
I 2015-05-26 09:21:38 theanets.trainer:168 RmsProp 781 loss=0.153804 err=0.153804
I 2015-05-26 09:21:45 theanets.trainer:168 RmsProp 782 loss=0.140254 err=0.140254
I 2015-05-26 09:21:52 theanets.trainer:168 RmsProp 783 loss=0.137817 err=0.137817
I 2015-05-26 09:21:59 theanets.trainer:168 RmsProp 784 loss=0.163657 err=0.163657
I 2015-05-26 09:22:05 theanets.trainer:168 RmsProp 785 loss=0.145864 err=0.145864
I 2015-05-26 09:22:12 theanets.trainer:168 RmsProp 786 loss=0.136155 err=0.136155
I 2015-05-26 09:22:19 theanets.trainer:168 RmsProp 787 loss=0.141364 err=0.141364
I 2015-05-26 09:22:26 theanets.trainer:168 RmsProp 788 loss=0.141499 err=0.141499
I 2015-05-26 09:22:34 theanets.trainer:168 RmsProp 789 loss=0.147102 err=0.147102
I 2015-05-26 09:22:41 theanets.trainer:168 RmsProp 790 loss=0.141409 err=0.141409
I 2015-05-26 09:22:42 theanets.trainer:168 validation 79 loss=1687.401733 err=1687.401733
I 2015-05-26 09:22:49 theanets.trainer:168 RmsProp 791 loss=0.134766 err=0.134766
I 2015-05-26 09:22:55 theanets.trainer:168 RmsProp 792 loss=0.150732 err=0.150732
I 2015-05-26 09:23:02 theanets.trainer:168 RmsProp 793 loss=0.140497 err=0.140497
I 2015-05-26 09:23:09 theanets.trainer:168 RmsProp 794 loss=0.148088 err=0.148088
I 2015-05-26 09:23:16 theanets.trainer:168 RmsProp 795 loss=0.131626 err=0.131626
I 2015-05-26 09:23:23 theanets.trainer:168 RmsProp 796 loss=0.146741 err=0.146741
I 2015-05-26 09:23:30 theanets.trainer:168 RmsProp 797 loss=0.139508 err=0.139508
I 2015-05-26 09:23:36 theanets.trainer:168 RmsProp 798 loss=0.137928 err=0.137928
I 2015-05-26 09:23:43 theanets.trainer:168 RmsProp 799 loss=0.144210 err=0.144210
I 2015-05-26 09:23:50 theanets.trainer:168 RmsProp 800 loss=0.149457 err=0.149457
I 2015-05-26 09:23:50 theanets.trainer:168 validation 80 loss=1684.228760 err=1684.228760 *
I 2015-05-26 09:23:57 theanets.trainer:168 RmsProp 801 loss=0.124833 err=0.124833
I 2015-05-26 09:24:04 theanets.trainer:168 RmsProp 802 loss=0.163079 err=0.163079
I 2015-05-26 09:24:10 theanets.trainer:168 RmsProp 803 loss=0.136383 err=0.136383
I 2015-05-26 09:24:17 theanets.trainer:168 RmsProp 804 loss=0.131405 err=0.131405
I 2015-05-26 09:24:24 theanets.trainer:168 RmsProp 805 loss=0.137010 err=0.137010
I 2015-05-26 09:24:30 theanets.trainer:168 RmsProp 806 loss=0.137701 err=0.137701
I 2015-05-26 09:24:37 theanets.trainer:168 RmsProp 807 loss=0.141396 err=0.141396
I 2015-05-26 09:24:43 theanets.trainer:168 RmsProp 808 loss=0.143085 err=0.143085
I 2015-05-26 09:24:50 theanets.trainer:168 RmsProp 809 loss=0.136639 err=0.136639
I 2015-05-26 09:24:58 theanets.trainer:168 RmsProp 810 loss=0.133126 err=0.133126
I 2015-05-26 09:24:58 theanets.trainer:168 validation 81 loss=1687.066040 err=1687.066040
I 2015-05-26 09:25:05 theanets.trainer:168 RmsProp 811 loss=0.134330 err=0.134330
I 2015-05-26 09:25:12 theanets.trainer:168 RmsProp 812 loss=0.141330 err=0.141330
I 2015-05-26 09:25:19 theanets.trainer:168 RmsProp 813 loss=0.128789 err=0.128789
I 2015-05-26 09:25:25 theanets.trainer:168 RmsProp 814 loss=0.144153 err=0.144153
I 2015-05-26 09:25:32 theanets.trainer:168 RmsProp 815 loss=0.146775 err=0.146775
I 2015-05-26 09:25:38 theanets.trainer:168 RmsProp 816 loss=0.128327 err=0.128327
I 2015-05-26 09:25:45 theanets.trainer:168 RmsProp 817 loss=0.129080 err=0.129080
I 2015-05-26 09:25:52 theanets.trainer:168 RmsProp 818 loss=0.139357 err=0.139357
I 2015-05-26 09:25:58 theanets.trainer:168 RmsProp 819 loss=0.127656 err=0.127656
I 2015-05-26 09:26:05 theanets.trainer:168 RmsProp 820 loss=0.138816 err=0.138816
I 2015-05-26 09:26:05 theanets.trainer:168 validation 82 loss=1684.853149 err=1684.853149
I 2015-05-26 09:26:12 theanets.trainer:168 RmsProp 821 loss=0.140280 err=0.140280
I 2015-05-26 09:26:19 theanets.trainer:168 RmsProp 822 loss=0.135597 err=0.135597
I 2015-05-26 09:26:25 theanets.trainer:168 RmsProp 823 loss=0.135558 err=0.135558
I 2015-05-26 09:26:32 theanets.trainer:168 RmsProp 824 loss=0.134079 err=0.134079
I 2015-05-26 09:26:39 theanets.trainer:168 RmsProp 825 loss=0.127670 err=0.127670
I 2015-05-26 09:26:46 theanets.trainer:168 RmsProp 826 loss=0.146733 err=0.146733
I 2015-05-26 09:26:52 theanets.trainer:168 RmsProp 827 loss=0.139520 err=0.139520
I 2015-05-26 09:26:59 theanets.trainer:168 RmsProp 828 loss=0.137263 err=0.137263
I 2015-05-26 09:27:06 theanets.trainer:168 RmsProp 829 loss=0.138498 err=0.138498
I 2015-05-26 09:27:13 theanets.trainer:168 RmsProp 830 loss=0.135698 err=0.135698
I 2015-05-26 09:27:13 theanets.trainer:168 validation 83 loss=1679.568237 err=1679.568237 *
I 2015-05-26 09:27:20 theanets.trainer:168 RmsProp 831 loss=0.135198 err=0.135198
I 2015-05-26 09:27:26 theanets.trainer:168 RmsProp 832 loss=0.138121 err=0.138121
I 2015-05-26 09:27:33 theanets.trainer:168 RmsProp 833 loss=0.121347 err=0.121347
I 2015-05-26 09:27:40 theanets.trainer:168 RmsProp 834 loss=0.161669 err=0.161669
I 2015-05-26 09:27:46 theanets.trainer:168 RmsProp 835 loss=0.135218 err=0.135218
I 2015-05-26 09:27:53 theanets.trainer:168 RmsProp 836 loss=0.133046 err=0.133046
I 2015-05-26 09:28:01 theanets.trainer:168 RmsProp 837 loss=0.130910 err=0.130910
I 2015-05-26 09:28:07 theanets.trainer:168 RmsProp 838 loss=0.147506 err=0.147506
I 2015-05-26 09:28:14 theanets.trainer:168 RmsProp 839 loss=0.133032 err=0.133032
I 2015-05-26 09:28:20 theanets.trainer:168 RmsProp 840 loss=0.129445 err=0.129445
I 2015-05-26 09:28:20 theanets.trainer:168 validation 84 loss=1681.529175 err=1681.529175
I 2015-05-26 09:28:27 theanets.trainer:168 RmsProp 841 loss=0.137126 err=0.137126
I 2015-05-26 09:28:34 theanets.trainer:168 RmsProp 842 loss=0.130769 err=0.130769
I 2015-05-26 09:28:41 theanets.trainer:168 RmsProp 843 loss=0.139592 err=0.139592
I 2015-05-26 09:28:47 theanets.trainer:168 RmsProp 844 loss=0.129070 err=0.129070
I 2015-05-26 09:28:54 theanets.trainer:168 RmsProp 845 loss=0.135121 err=0.135121
I 2015-05-26 09:29:00 theanets.trainer:168 RmsProp 846 loss=0.136995 err=0.136995
I 2015-05-26 09:29:06 theanets.trainer:168 RmsProp 847 loss=0.137637 err=0.137637
I 2015-05-26 09:29:13 theanets.trainer:168 RmsProp 848 loss=0.129521 err=0.129521
I 2015-05-26 09:29:20 theanets.trainer:168 RmsProp 849 loss=0.131704 err=0.131704
I 2015-05-26 09:29:27 theanets.trainer:168 RmsProp 850 loss=0.137021 err=0.137021
I 2015-05-26 09:29:27 theanets.trainer:168 validation 85 loss=1680.154663 err=1680.154663
I 2015-05-26 09:29:34 theanets.trainer:168 RmsProp 851 loss=0.126750 err=0.126750
I 2015-05-26 09:29:40 theanets.trainer:168 RmsProp 852 loss=0.122376 err=0.122376
I 2015-05-26 09:29:47 theanets.trainer:168 RmsProp 853 loss=0.140461 err=0.140461
I 2015-05-26 09:29:53 theanets.trainer:168 RmsProp 854 loss=0.138099 err=0.138099
I 2015-05-26 09:30:00 theanets.trainer:168 RmsProp 855 loss=0.129420 err=0.129420
I 2015-05-26 09:30:07 theanets.trainer:168 RmsProp 856 loss=0.129930 err=0.129930
I 2015-05-26 09:30:13 theanets.trainer:168 RmsProp 857 loss=0.122146 err=0.122146
I 2015-05-26 09:30:20 theanets.trainer:168 RmsProp 858 loss=0.159922 err=0.159922
I 2015-05-26 09:30:26 theanets.trainer:168 RmsProp 859 loss=0.129444 err=0.129444
I 2015-05-26 09:30:34 theanets.trainer:168 RmsProp 860 loss=0.131760 err=0.131760
I 2015-05-26 09:30:34 theanets.trainer:168 validation 86 loss=1678.796875 err=1678.796875 *
I 2015-05-26 09:30:41 theanets.trainer:168 RmsProp 861 loss=0.130235 err=0.130235
I 2015-05-26 09:30:48 theanets.trainer:168 RmsProp 862 loss=0.134641 err=0.134641
I 2015-05-26 09:30:54 theanets.trainer:168 RmsProp 863 loss=0.128134 err=0.128134
I 2015-05-26 09:31:01 theanets.trainer:168 RmsProp 864 loss=0.131535 err=0.131535
I 2015-05-26 09:31:08 theanets.trainer:168 RmsProp 865 loss=0.131234 err=0.131234
I 2015-05-26 09:31:14 theanets.trainer:168 RmsProp 866 loss=0.135870 err=0.135870
I 2015-05-26 09:31:21 theanets.trainer:168 RmsProp 867 loss=0.130486 err=0.130486
I 2015-05-26 09:31:28 theanets.trainer:168 RmsProp 868 loss=0.123454 err=0.123454
I 2015-05-26 09:31:34 theanets.trainer:168 RmsProp 869 loss=0.132864 err=0.132864
I 2015-05-26 09:31:42 theanets.trainer:168 RmsProp 870 loss=0.125531 err=0.125531
I 2015-05-26 09:31:42 theanets.trainer:168 validation 87 loss=1677.763550 err=1677.763550 *
I 2015-05-26 09:31:49 theanets.trainer:168 RmsProp 871 loss=0.122889 err=0.122889
I 2015-05-26 09:31:55 theanets.trainer:168 RmsProp 872 loss=0.137227 err=0.137227
I 2015-05-26 09:32:02 theanets.trainer:168 RmsProp 873 loss=0.125908 err=0.125908
I 2015-05-26 09:32:09 theanets.trainer:168 RmsProp 874 loss=0.122452 err=0.122452
I 2015-05-26 09:32:16 theanets.trainer:168 RmsProp 875 loss=0.131380 err=0.131380
I 2015-05-26 09:32:22 theanets.trainer:168 RmsProp 876 loss=0.128686 err=0.128686
I 2015-05-26 09:32:28 theanets.trainer:168 RmsProp 877 loss=0.130173 err=0.130173
I 2015-05-26 09:32:35 theanets.trainer:168 RmsProp 878 loss=0.121458 err=0.121458
I 2015-05-26 09:32:41 theanets.trainer:168 RmsProp 879 loss=0.126636 err=0.126636
I 2015-05-26 09:32:48 theanets.trainer:168 RmsProp 880 loss=0.131294 err=0.131294
I 2015-05-26 09:32:48 theanets.trainer:168 validation 88 loss=1673.307861 err=1673.307861 *
I 2015-05-26 09:32:55 theanets.trainer:168 RmsProp 881 loss=0.127959 err=0.127959
I 2015-05-26 09:33:01 theanets.trainer:168 RmsProp 882 loss=0.124457 err=0.124457
I 2015-05-26 09:33:08 theanets.trainer:168 RmsProp 883 loss=0.128273 err=0.128273
I 2015-05-26 09:33:15 theanets.trainer:168 RmsProp 884 loss=0.121382 err=0.121382
I 2015-05-26 09:33:21 theanets.trainer:168 RmsProp 885 loss=0.127075 err=0.127075
I 2015-05-26 09:33:29 theanets.trainer:168 RmsProp 886 loss=0.136011 err=0.136011
I 2015-05-26 09:33:35 theanets.trainer:168 RmsProp 887 loss=0.129084 err=0.129084
I 2015-05-26 09:33:42 theanets.trainer:168 RmsProp 888 loss=0.120164 err=0.120164
I 2015-05-26 09:33:48 theanets.trainer:168 RmsProp 889 loss=0.137596 err=0.137596
I 2015-05-26 09:33:55 theanets.trainer:168 RmsProp 890 loss=0.133590 err=0.133590
I 2015-05-26 09:33:55 theanets.trainer:168 validation 89 loss=1676.908813 err=1676.908813
I 2015-05-26 09:34:02 theanets.trainer:168 RmsProp 891 loss=0.115316 err=0.115316
I 2015-05-26 09:34:10 theanets.trainer:168 RmsProp 892 loss=0.136827 err=0.136827
I 2015-05-26 09:34:17 theanets.trainer:168 RmsProp 893 loss=0.117873 err=0.117873
I 2015-05-26 09:34:23 theanets.trainer:168 RmsProp 894 loss=0.124609 err=0.124609
I 2015-05-26 09:34:30 theanets.trainer:168 RmsProp 895 loss=0.127260 err=0.127260
I 2015-05-26 09:34:37 theanets.trainer:168 RmsProp 896 loss=0.134547 err=0.134547
I 2015-05-26 09:34:43 theanets.trainer:168 RmsProp 897 loss=0.125404 err=0.125404
I 2015-05-26 09:34:50 theanets.trainer:168 RmsProp 898 loss=0.121892 err=0.121892
I 2015-05-26 09:34:56 theanets.trainer:168 RmsProp 899 loss=0.123111 err=0.123111
I 2015-05-26 09:35:04 theanets.trainer:168 RmsProp 900 loss=0.123711 err=0.123711
I 2015-05-26 09:35:04 theanets.trainer:168 validation 90 loss=1676.376953 err=1676.376953
I 2015-05-26 09:35:11 theanets.trainer:168 RmsProp 901 loss=0.128455 err=0.128455
I 2015-05-26 09:35:18 theanets.trainer:168 RmsProp 902 loss=0.126139 err=0.126139
I 2015-05-26 09:35:24 theanets.trainer:168 RmsProp 903 loss=0.123367 err=0.123367
I 2015-05-26 09:35:30 theanets.trainer:168 RmsProp 904 loss=0.128050 err=0.128050
I 2015-05-26 09:35:37 theanets.trainer:168 RmsProp 905 loss=0.121059 err=0.121059
I 2015-05-26 09:35:43 theanets.trainer:168 RmsProp 906 loss=0.119712 err=0.119712
I 2015-05-26 09:35:50 theanets.trainer:168 RmsProp 907 loss=0.121437 err=0.121437
I 2015-05-26 09:35:56 theanets.trainer:168 RmsProp 908 loss=0.135783 err=0.135783
I 2015-05-26 09:36:02 theanets.trainer:168 RmsProp 909 loss=0.123823 err=0.123823
I 2015-05-26 09:36:08 theanets.trainer:168 RmsProp 910 loss=0.120636 err=0.120636
I 2015-05-26 09:36:09 theanets.trainer:168 validation 91 loss=1672.913086 err=1672.913086 *
I 2015-05-26 09:36:15 theanets.trainer:168 RmsProp 911 loss=0.131349 err=0.131349
I 2015-05-26 09:36:22 theanets.trainer:168 RmsProp 912 loss=0.126925 err=0.126925
I 2015-05-26 09:36:28 theanets.trainer:168 RmsProp 913 loss=0.125754 err=0.125754
I 2015-05-26 09:36:35 theanets.trainer:168 RmsProp 914 loss=0.117145 err=0.117145
I 2015-05-26 09:36:42 theanets.trainer:168 RmsProp 915 loss=0.119597 err=0.119597
I 2015-05-26 09:36:49 theanets.trainer:168 RmsProp 916 loss=0.135772 err=0.135772
I 2015-05-26 09:36:55 theanets.trainer:168 RmsProp 917 loss=0.122669 err=0.122669
I 2015-05-26 09:37:02 theanets.trainer:168 RmsProp 918 loss=0.111883 err=0.111883
I 2015-05-26 09:37:09 theanets.trainer:168 RmsProp 919 loss=0.141550 err=0.141550
I 2015-05-26 09:37:15 theanets.trainer:168 RmsProp 920 loss=0.125496 err=0.125496
I 2015-05-26 09:37:16 theanets.trainer:168 validation 92 loss=1671.735229 err=1671.735229 *
I 2015-05-26 09:37:23 theanets.trainer:168 RmsProp 921 loss=0.129408 err=0.129408
I 2015-05-26 09:37:29 theanets.trainer:168 RmsProp 922 loss=0.118035 err=0.118035
I 2015-05-26 09:37:36 theanets.trainer:168 RmsProp 923 loss=0.121549 err=0.121549
I 2015-05-26 09:37:43 theanets.trainer:168 RmsProp 924 loss=0.124817 err=0.124817
I 2015-05-26 09:37:50 theanets.trainer:168 RmsProp 925 loss=0.119796 err=0.119796
I 2015-05-26 09:37:57 theanets.trainer:168 RmsProp 926 loss=0.123490 err=0.123490
I 2015-05-26 09:38:04 theanets.trainer:168 RmsProp 927 loss=0.125504 err=0.125504
I 2015-05-26 09:38:11 theanets.trainer:168 RmsProp 928 loss=0.122043 err=0.122043
I 2015-05-26 09:38:18 theanets.trainer:168 RmsProp 929 loss=0.124889 err=0.124889
I 2015-05-26 09:38:24 theanets.trainer:168 RmsProp 930 loss=0.125878 err=0.125878
I 2015-05-26 09:38:25 theanets.trainer:168 validation 93 loss=1672.494751 err=1672.494751
I 2015-05-26 09:38:31 theanets.trainer:168 RmsProp 931 loss=0.123886 err=0.123886
I 2015-05-26 09:38:38 theanets.trainer:168 RmsProp 932 loss=0.118215 err=0.118215
I 2015-05-26 09:38:44 theanets.trainer:168 RmsProp 933 loss=0.115833 err=0.115833
I 2015-05-26 09:38:51 theanets.trainer:168 RmsProp 934 loss=0.124334 err=0.124334
I 2015-05-26 09:38:59 theanets.trainer:168 RmsProp 935 loss=0.125766 err=0.125766
I 2015-05-26 09:39:05 theanets.trainer:168 RmsProp 936 loss=0.117834 err=0.117834
I 2015-05-26 09:39:12 theanets.trainer:168 RmsProp 937 loss=0.121832 err=0.121832
I 2015-05-26 09:39:19 theanets.trainer:168 RmsProp 938 loss=0.119072 err=0.119072
I 2015-05-26 09:39:25 theanets.trainer:168 RmsProp 939 loss=0.130768 err=0.130768
I 2015-05-26 09:39:31 theanets.trainer:168 RmsProp 940 loss=0.127927 err=0.127927
I 2015-05-26 09:39:32 theanets.trainer:168 validation 94 loss=1672.939819 err=1672.939819
I 2015-05-26 09:39:39 theanets.trainer:168 RmsProp 941 loss=0.119590 err=0.119590
I 2015-05-26 09:39:46 theanets.trainer:168 RmsProp 942 loss=0.113943 err=0.113943
I 2015-05-26 09:39:52 theanets.trainer:168 RmsProp 943 loss=0.124588 err=0.124588
I 2015-05-26 09:39:59 theanets.trainer:168 RmsProp 944 loss=0.128736 err=0.128736
I 2015-05-26 09:40:06 theanets.trainer:168 RmsProp 945 loss=0.125138 err=0.125138
I 2015-05-26 09:40:13 theanets.trainer:168 RmsProp 946 loss=0.115632 err=0.115632
I 2015-05-26 09:40:20 theanets.trainer:168 RmsProp 947 loss=0.112445 err=0.112445
I 2015-05-26 09:40:27 theanets.trainer:168 RmsProp 948 loss=0.132254 err=0.132254
I 2015-05-26 09:40:33 theanets.trainer:168 RmsProp 949 loss=0.115826 err=0.115826
I 2015-05-26 09:40:40 theanets.trainer:168 RmsProp 950 loss=0.103529 err=0.103529
I 2015-05-26 09:40:41 theanets.trainer:168 validation 95 loss=1669.639893 err=1669.639893 *
I 2015-05-26 09:40:48 theanets.trainer:168 RmsProp 951 loss=0.137002 err=0.137002
I 2015-05-26 09:40:54 theanets.trainer:168 RmsProp 952 loss=0.122352 err=0.122352
I 2015-05-26 09:41:01 theanets.trainer:168 RmsProp 953 loss=0.123359 err=0.123359
I 2015-05-26 09:41:08 theanets.trainer:168 RmsProp 954 loss=0.115328 err=0.115328
I 2015-05-26 09:41:15 theanets.trainer:168 RmsProp 955 loss=0.126324 err=0.126324
I 2015-05-26 09:41:22 theanets.trainer:168 RmsProp 956 loss=0.117768 err=0.117768
I 2015-05-26 09:41:28 theanets.trainer:168 RmsProp 957 loss=0.110960 err=0.110960
I 2015-05-26 09:41:35 theanets.trainer:168 RmsProp 958 loss=0.113040 err=0.113040
I 2015-05-26 09:41:42 theanets.trainer:168 RmsProp 959 loss=0.126199 err=0.126199
I 2015-05-26 09:41:49 theanets.trainer:168 RmsProp 960 loss=0.125888 err=0.125888
I 2015-05-26 09:41:49 theanets.trainer:168 validation 96 loss=1669.036133 err=1669.036133 *
I 2015-05-26 09:41:56 theanets.trainer:168 RmsProp 961 loss=0.111397 err=0.111397
I 2015-05-26 09:42:02 theanets.trainer:168 RmsProp 962 loss=0.118052 err=0.118052
I 2015-05-26 09:42:09 theanets.trainer:168 RmsProp 963 loss=0.117576 err=0.117576
I 2015-05-26 09:42:16 theanets.trainer:168 RmsProp 964 loss=0.122625 err=0.122625
I 2015-05-26 09:42:22 theanets.trainer:168 RmsProp 965 loss=0.125697 err=0.125697
I 2015-05-26 09:42:29 theanets.trainer:168 RmsProp 966 loss=0.106330 err=0.106330
I 2015-05-26 09:42:35 theanets.trainer:168 RmsProp 967 loss=0.130646 err=0.130646
I 2015-05-26 09:42:42 theanets.trainer:168 RmsProp 968 loss=0.119155 err=0.119155
I 2015-05-26 09:42:48 theanets.trainer:168 RmsProp 969 loss=0.115969 err=0.115969
I 2015-05-26 09:42:54 theanets.trainer:168 RmsProp 970 loss=0.113822 err=0.113822
I 2015-05-26 09:42:55 theanets.trainer:168 validation 97 loss=1668.591187 err=1668.591187 *
I 2015-05-26 09:43:01 theanets.trainer:168 RmsProp 971 loss=0.112766 err=0.112766
I 2015-05-26 09:43:08 theanets.trainer:168 RmsProp 972 loss=0.122687 err=0.122687
I 2015-05-26 09:43:15 theanets.trainer:168 RmsProp 973 loss=0.119632 err=0.119632
I 2015-05-26 09:43:21 theanets.trainer:168 RmsProp 974 loss=0.127487 err=0.127487
I 2015-05-26 09:43:28 theanets.trainer:168 RmsProp 975 loss=0.132757 err=0.132757
I 2015-05-26 09:43:34 theanets.trainer:168 RmsProp 976 loss=0.114886 err=0.114886
I 2015-05-26 09:43:41 theanets.trainer:168 RmsProp 977 loss=0.105563 err=0.105563
I 2015-05-26 09:43:48 theanets.trainer:168 RmsProp 978 loss=0.110990 err=0.110990
I 2015-05-26 09:43:55 theanets.trainer:168 RmsProp 979 loss=0.148013 err=0.148013
I 2015-05-26 09:44:01 theanets.trainer:168 RmsProp 980 loss=0.119749 err=0.119749
I 2015-05-26 09:44:02 theanets.trainer:168 validation 98 loss=1669.403320 err=1669.403320
I 2015-05-26 09:44:08 theanets.trainer:168 RmsProp 981 loss=0.111888 err=0.111888
I 2015-05-26 09:44:16 theanets.trainer:168 RmsProp 982 loss=0.122992 err=0.122992
I 2015-05-26 09:44:23 theanets.trainer:168 RmsProp 983 loss=0.114398 err=0.114398
I 2015-05-26 09:44:30 theanets.trainer:168 RmsProp 984 loss=0.109688 err=0.109688
I 2015-05-26 09:44:36 theanets.trainer:168 RmsProp 985 loss=0.119088 err=0.119088
I 2015-05-26 09:44:43 theanets.trainer:168 RmsProp 986 loss=0.117124 err=0.117124
I 2015-05-26 09:44:50 theanets.trainer:168 RmsProp 987 loss=0.107415 err=0.107415
I 2015-05-26 09:44:57 theanets.trainer:168 RmsProp 988 loss=0.119922 err=0.119922
I 2015-05-26 09:45:03 theanets.trainer:168 RmsProp 989 loss=0.111039 err=0.111039
I 2015-05-26 09:45:10 theanets.trainer:168 RmsProp 990 loss=0.122220 err=0.122220
I 2015-05-26 09:45:10 theanets.trainer:168 validation 99 loss=1665.333374 err=1665.333374 *
I 2015-05-26 09:45:17 theanets.trainer:168 RmsProp 991 loss=0.113560 err=0.113560
I 2015-05-26 09:45:23 theanets.trainer:168 RmsProp 992 loss=0.110586 err=0.110586
I 2015-05-26 09:45:30 theanets.trainer:168 RmsProp 993 loss=0.136297 err=0.136297
I 2015-05-26 09:45:37 theanets.trainer:168 RmsProp 994 loss=0.114306 err=0.114306
I 2015-05-26 09:45:43 theanets.trainer:168 RmsProp 995 loss=0.111875 err=0.111875
I 2015-05-26 09:45:50 theanets.trainer:168 RmsProp 996 loss=0.106279 err=0.106279
I 2015-05-26 09:45:57 theanets.trainer:168 RmsProp 997 loss=0.121869 err=0.121869
I 2015-05-26 09:46:04 theanets.trainer:168 RmsProp 998 loss=0.117877 err=0.117877
I 2015-05-26 09:46:11 theanets.trainer:168 RmsProp 999 loss=0.106980 err=0.106980
I 2015-05-26 09:46:17 theanets.trainer:168 RmsProp 1000 loss=0.113183 err=0.113183
I 2015-05-26 09:46:18 theanets.trainer:168 validation 100 loss=1668.461914 err=1668.461914
I 2015-05-26 09:46:25 theanets.trainer:168 RmsProp 1001 loss=0.116882 err=0.116882
I 2015-05-26 09:46:32 theanets.trainer:168 RmsProp 1002 loss=0.109678 err=0.109678
I 2015-05-26 09:46:39 theanets.trainer:168 RmsProp 1003 loss=0.120072 err=0.120072
I 2015-05-26 09:46:46 theanets.trainer:168 RmsProp 1004 loss=0.118176 err=0.118176
I 2015-05-26 09:46:52 theanets.trainer:168 RmsProp 1005 loss=0.110406 err=0.110406
I 2015-05-26 09:46:59 theanets.trainer:168 RmsProp 1006 loss=0.114065 err=0.114065
I 2015-05-26 09:47:06 theanets.trainer:168 RmsProp 1007 loss=0.112269 err=0.112269
I 2015-05-26 09:47:13 theanets.trainer:168 RmsProp 1008 loss=0.120056 err=0.120056
I 2015-05-26 09:47:20 theanets.trainer:168 RmsProp 1009 loss=0.116592 err=0.116592
I 2015-05-26 09:47:27 theanets.trainer:168 RmsProp 1010 loss=0.115548 err=0.115548
I 2015-05-26 09:47:27 theanets.trainer:168 validation 101 loss=1664.867554 err=1664.867554 *
I 2015-05-26 09:47:34 theanets.trainer:168 RmsProp 1011 loss=0.109419 err=0.109419
I 2015-05-26 09:47:41 theanets.trainer:168 RmsProp 1012 loss=0.112117 err=0.112117
I 2015-05-26 09:47:48 theanets.trainer:168 RmsProp 1013 loss=0.127215 err=0.127215
I 2015-05-26 09:47:54 theanets.trainer:168 RmsProp 1014 loss=0.111509 err=0.111509
I 2015-05-26 09:48:01 theanets.trainer:168 RmsProp 1015 loss=0.113211 err=0.113211
I 2015-05-26 09:48:08 theanets.trainer:168 RmsProp 1016 loss=0.110920 err=0.110920
I 2015-05-26 09:48:14 theanets.trainer:168 RmsProp 1017 loss=0.115401 err=0.115401
I 2015-05-26 09:48:21 theanets.trainer:168 RmsProp 1018 loss=0.111586 err=0.111586
I 2015-05-26 09:48:27 theanets.trainer:168 RmsProp 1019 loss=0.110293 err=0.110293
I 2015-05-26 09:48:33 theanets.trainer:168 RmsProp 1020 loss=0.121784 err=0.121784
I 2015-05-26 09:48:34 theanets.trainer:168 validation 102 loss=1664.020386 err=1664.020386 *
I 2015-05-26 09:48:40 theanets.trainer:168 RmsProp 1021 loss=0.111312 err=0.111312
I 2015-05-26 09:48:47 theanets.trainer:168 RmsProp 1022 loss=0.110363 err=0.110363
I 2015-05-26 09:48:54 theanets.trainer:168 RmsProp 1023 loss=0.106856 err=0.106856
I 2015-05-26 09:49:01 theanets.trainer:168 RmsProp 1024 loss=0.121271 err=0.121271
I 2015-05-26 09:49:08 theanets.trainer:168 RmsProp 1025 loss=0.104872 err=0.104872
I 2015-05-26 09:49:15 theanets.trainer:168 RmsProp 1026 loss=0.112678 err=0.112678
I 2015-05-26 09:49:21 theanets.trainer:168 RmsProp 1027 loss=0.111283 err=0.111283
I 2015-05-26 09:49:27 theanets.trainer:168 RmsProp 1028 loss=0.111241 err=0.111241
I 2015-05-26 09:49:34 theanets.trainer:168 RmsProp 1029 loss=0.115567 err=0.115567
I 2015-05-26 09:49:40 theanets.trainer:168 RmsProp 1030 loss=0.107682 err=0.107682
I 2015-05-26 09:49:41 theanets.trainer:168 validation 103 loss=1662.324585 err=1662.324585 *
I 2015-05-26 09:49:47 theanets.trainer:168 RmsProp 1031 loss=0.096667 err=0.096667
I 2015-05-26 09:49:54 theanets.trainer:168 RmsProp 1032 loss=0.127791 err=0.127791
I 2015-05-26 09:50:01 theanets.trainer:168 RmsProp 1033 loss=0.113828 err=0.113828
I 2015-05-26 09:50:07 theanets.trainer:168 RmsProp 1034 loss=0.107518 err=0.107518
I 2015-05-26 09:50:14 theanets.trainer:168 RmsProp 1035 loss=0.117171 err=0.117171
I 2015-05-26 09:50:20 theanets.trainer:168 RmsProp 1036 loss=0.109899 err=0.109899
I 2015-05-26 09:50:27 theanets.trainer:168 RmsProp 1037 loss=0.116540 err=0.116540
I 2015-05-26 09:50:33 theanets.trainer:168 RmsProp 1038 loss=0.107963 err=0.107963
I 2015-05-26 09:50:40 theanets.trainer:168 RmsProp 1039 loss=0.114411 err=0.114411
I 2015-05-26 09:50:46 theanets.trainer:168 RmsProp 1040 loss=0.103975 err=0.103975
I 2015-05-26 09:50:47 theanets.trainer:168 validation 104 loss=1659.924438 err=1659.924438 *
I 2015-05-26 09:50:54 theanets.trainer:168 RmsProp 1041 loss=0.122053 err=0.122053
I 2015-05-26 09:51:00 theanets.trainer:168 RmsProp 1042 loss=0.100481 err=0.100481
I 2015-05-26 09:51:07 theanets.trainer:168 RmsProp 1043 loss=0.119890 err=0.119890
I 2015-05-26 09:51:13 theanets.trainer:168 RmsProp 1044 loss=0.110395 err=0.110395
I 2015-05-26 09:51:19 theanets.trainer:168 RmsProp 1045 loss=0.111408 err=0.111408
I 2015-05-26 09:51:26 theanets.trainer:168 RmsProp 1046 loss=0.109007 err=0.109007
I 2015-05-26 09:51:33 theanets.trainer:168 RmsProp 1047 loss=0.114318 err=0.114318
I 2015-05-26 09:51:40 theanets.trainer:168 RmsProp 1048 loss=0.111702 err=0.111702
I 2015-05-26 09:51:47 theanets.trainer:168 RmsProp 1049 loss=0.107263 err=0.107263
I 2015-05-26 09:51:54 theanets.trainer:168 RmsProp 1050 loss=0.107441 err=0.107441
I 2015-05-26 09:51:55 theanets.trainer:168 validation 105 loss=1662.398438 err=1662.398438
I 2015-05-26 09:52:01 theanets.trainer:168 RmsProp 1051 loss=0.105767 err=0.105767
I 2015-05-26 09:52:08 theanets.trainer:168 RmsProp 1052 loss=0.104344 err=0.104344
I 2015-05-26 09:52:14 theanets.trainer:168 RmsProp 1053 loss=0.121191 err=0.121191
I 2015-05-26 09:52:20 theanets.trainer:168 RmsProp 1054 loss=0.104391 err=0.104391
I 2015-05-26 09:52:26 theanets.trainer:168 RmsProp 1055 loss=0.108071 err=0.108071
I 2015-05-26 09:52:33 theanets.trainer:168 RmsProp 1056 loss=0.105373 err=0.105373
I 2015-05-26 09:52:39 theanets.trainer:168 RmsProp 1057 loss=0.109053 err=0.109053
I 2015-05-26 09:52:46 theanets.trainer:168 RmsProp 1058 loss=0.108812 err=0.108812
I 2015-05-26 09:52:52 theanets.trainer:168 RmsProp 1059 loss=0.117994 err=0.117994
I 2015-05-26 09:52:59 theanets.trainer:168 RmsProp 1060 loss=0.103620 err=0.103620
I 2015-05-26 09:53:00 theanets.trainer:168 validation 106 loss=1658.714478 err=1658.714478 *
I 2015-05-26 09:53:06 theanets.trainer:168 RmsProp 1061 loss=0.109789 err=0.109789
I 2015-05-26 09:53:13 theanets.trainer:168 RmsProp 1062 loss=0.104481 err=0.104481
I 2015-05-26 09:53:20 theanets.trainer:168 RmsProp 1063 loss=0.108036 err=0.108036
I 2015-05-26 09:53:27 theanets.trainer:168 RmsProp 1064 loss=0.111490 err=0.111490
I 2015-05-26 09:53:34 theanets.trainer:168 RmsProp 1065 loss=0.102672 err=0.102672
I 2015-05-26 09:53:41 theanets.trainer:168 RmsProp 1066 loss=0.116100 err=0.116100
I 2015-05-26 09:53:47 theanets.trainer:168 RmsProp 1067 loss=0.096025 err=0.096025
I 2015-05-26 09:53:54 theanets.trainer:168 RmsProp 1068 loss=0.120813 err=0.120813
I 2015-05-26 09:54:01 theanets.trainer:168 RmsProp 1069 loss=0.114102 err=0.114102
I 2015-05-26 09:54:08 theanets.trainer:168 RmsProp 1070 loss=0.102499 err=0.102499
I 2015-05-26 09:54:08 theanets.trainer:168 validation 107 loss=1659.366821 err=1659.366821
I 2015-05-26 09:54:14 theanets.trainer:168 RmsProp 1071 loss=0.107230 err=0.107230
I 2015-05-26 09:54:20 theanets.trainer:168 RmsProp 1072 loss=0.108882 err=0.108882
I 2015-05-26 09:54:27 theanets.trainer:168 RmsProp 1073 loss=0.105909 err=0.105909
I 2015-05-26 09:54:33 theanets.trainer:168 RmsProp 1074 loss=0.106993 err=0.106993
I 2015-05-26 09:54:40 theanets.trainer:168 RmsProp 1075 loss=0.107348 err=0.107348
I 2015-05-26 09:54:46 theanets.trainer:168 RmsProp 1076 loss=0.100876 err=0.100876
I 2015-05-26 09:54:53 theanets.trainer:168 RmsProp 1077 loss=0.121924 err=0.121924
I 2015-05-26 09:55:00 theanets.trainer:168 RmsProp 1078 loss=0.105847 err=0.105847
I 2015-05-26 09:55:07 theanets.trainer:168 RmsProp 1079 loss=0.106770 err=0.106770
I 2015-05-26 09:55:13 theanets.trainer:168 RmsProp 1080 loss=0.092651 err=0.092651
I 2015-05-26 09:55:14 theanets.trainer:168 validation 108 loss=1658.743164 err=1658.743164
I 2015-05-26 09:55:21 theanets.trainer:168 RmsProp 1081 loss=0.126904 err=0.126904
I 2015-05-26 09:55:28 theanets.trainer:168 RmsProp 1082 loss=0.104621 err=0.104621
I 2015-05-26 09:55:34 theanets.trainer:168 RmsProp 1083 loss=0.103409 err=0.103409
I 2015-05-26 09:55:41 theanets.trainer:168 RmsProp 1084 loss=0.109540 err=0.109540
I 2015-05-26 09:55:48 theanets.trainer:168 RmsProp 1085 loss=0.108333 err=0.108333
I 2015-05-26 09:55:55 theanets.trainer:168 RmsProp 1086 loss=0.104956 err=0.104956
I 2015-05-26 09:56:01 theanets.trainer:168 RmsProp 1087 loss=0.102234 err=0.102234
I 2015-05-26 09:56:08 theanets.trainer:168 RmsProp 1088 loss=0.110567 err=0.110567
I 2015-05-26 09:56:14 theanets.trainer:168 RmsProp 1089 loss=0.105384 err=0.105384
I 2015-05-26 09:56:22 theanets.trainer:168 RmsProp 1090 loss=0.099343 err=0.099343
I 2015-05-26 09:56:22 theanets.trainer:168 validation 109 loss=1658.577393 err=1658.577393 *
I 2015-05-26 09:56:29 theanets.trainer:168 RmsProp 1091 loss=0.112250 err=0.112250
I 2015-05-26 09:56:36 theanets.trainer:168 RmsProp 1092 loss=0.105004 err=0.105004
I 2015-05-26 09:56:42 theanets.trainer:168 RmsProp 1093 loss=0.103667 err=0.103667
I 2015-05-26 09:56:49 theanets.trainer:168 RmsProp 1094 loss=0.109421 err=0.109421
I 2015-05-26 09:56:55 theanets.trainer:168 RmsProp 1095 loss=0.109725 err=0.109725
I 2015-05-26 09:57:01 theanets.trainer:168 RmsProp 1096 loss=0.097882 err=0.097882
I 2015-05-26 09:57:07 theanets.trainer:168 RmsProp 1097 loss=0.106521 err=0.106521
I 2015-05-26 09:57:14 theanets.trainer:168 RmsProp 1098 loss=0.105465 err=0.105465
I 2015-05-26 09:57:20 theanets.trainer:168 RmsProp 1099 loss=0.104148 err=0.104148
I 2015-05-26 09:57:27 theanets.trainer:168 RmsProp 1100 loss=0.100847 err=0.100847
I 2015-05-26 09:57:28 theanets.trainer:168 validation 110 loss=1653.558228 err=1653.558228 *
I 2015-05-26 09:57:34 theanets.trainer:168 RmsProp 1101 loss=0.107898 err=0.107898
I 2015-05-26 09:57:40 theanets.trainer:168 RmsProp 1102 loss=0.118347 err=0.118347
I 2015-05-26 09:57:47 theanets.trainer:168 RmsProp 1103 loss=0.097829 err=0.097829
I 2015-05-26 09:57:53 theanets.trainer:168 RmsProp 1104 loss=0.098909 err=0.098909
I 2015-05-26 09:57:59 theanets.trainer:168 RmsProp 1105 loss=0.107809 err=0.107809
I 2015-05-26 09:58:06 theanets.trainer:168 RmsProp 1106 loss=0.103834 err=0.103834
I 2015-05-26 09:58:13 theanets.trainer:168 RmsProp 1107 loss=0.107826 err=0.107826
I 2015-05-26 09:58:19 theanets.trainer:168 RmsProp 1108 loss=0.103417 err=0.103417
I 2015-05-26 09:58:26 theanets.trainer:168 RmsProp 1109 loss=0.097554 err=0.097554
I 2015-05-26 09:58:33 theanets.trainer:168 RmsProp 1110 loss=0.106053 err=0.106053
I 2015-05-26 09:58:33 theanets.trainer:168 validation 111 loss=1655.149658 err=1655.149658
I 2015-05-26 09:58:40 theanets.trainer:168 RmsProp 1111 loss=0.100673 err=0.100673
I 2015-05-26 09:58:47 theanets.trainer:168 RmsProp 1112 loss=0.107874 err=0.107874
I 2015-05-26 09:58:54 theanets.trainer:168 RmsProp 1113 loss=0.106466 err=0.106466
I 2015-05-26 09:59:00 theanets.trainer:168 RmsProp 1114 loss=0.104487 err=0.104487
I 2015-05-26 09:59:07 theanets.trainer:168 RmsProp 1115 loss=0.101280 err=0.101280
I 2015-05-26 09:59:13 theanets.trainer:168 RmsProp 1116 loss=0.105635 err=0.105635
I 2015-05-26 09:59:20 theanets.trainer:168 RmsProp 1117 loss=0.103868 err=0.103868
I 2015-05-26 09:59:26 theanets.trainer:168 RmsProp 1118 loss=0.098305 err=0.098305
I 2015-05-26 09:59:33 theanets.trainer:168 RmsProp 1119 loss=0.106243 err=0.106243
I 2015-05-26 09:59:40 theanets.trainer:168 RmsProp 1120 loss=0.100210 err=0.100210
I 2015-05-26 09:59:40 theanets.trainer:168 validation 112 loss=1652.939819 err=1652.939819 *
I 2015-05-26 09:59:47 theanets.trainer:168 RmsProp 1121 loss=0.101511 err=0.101511
I 2015-05-26 09:59:54 theanets.trainer:168 RmsProp 1122 loss=0.104220 err=0.104220
I 2015-05-26 10:00:00 theanets.trainer:168 RmsProp 1123 loss=0.111554 err=0.111554
I 2015-05-26 10:00:07 theanets.trainer:168 RmsProp 1124 loss=0.098043 err=0.098043
I 2015-05-26 10:00:14 theanets.trainer:168 RmsProp 1125 loss=0.098348 err=0.098348
I 2015-05-26 10:00:20 theanets.trainer:168 RmsProp 1126 loss=0.116220 err=0.116220
I 2015-05-26 10:00:27 theanets.trainer:168 RmsProp 1127 loss=0.100819 err=0.100819
I 2015-05-26 10:00:33 theanets.trainer:168 RmsProp 1128 loss=0.104424 err=0.104424
I 2015-05-26 10:00:39 theanets.trainer:168 RmsProp 1129 loss=0.099529 err=0.099529
I 2015-05-26 10:00:46 theanets.trainer:168 RmsProp 1130 loss=0.102258 err=0.102258
I 2015-05-26 10:00:47 theanets.trainer:168 validation 113 loss=1650.490234 err=1650.490234 *
I 2015-05-26 10:00:53 theanets.trainer:168 RmsProp 1131 loss=0.096864 err=0.096864
I 2015-05-26 10:01:01 theanets.trainer:168 RmsProp 1132 loss=0.114369 err=0.114369
I 2015-05-26 10:01:07 theanets.trainer:168 RmsProp 1133 loss=0.101964 err=0.101964
I 2015-05-26 10:01:13 theanets.trainer:168 RmsProp 1134 loss=0.097496 err=0.097496
I 2015-05-26 10:01:21 theanets.trainer:168 RmsProp 1135 loss=0.114344 err=0.114344
I 2015-05-26 10:01:27 theanets.trainer:168 RmsProp 1136 loss=0.109211 err=0.109211
I 2015-05-26 10:01:34 theanets.trainer:168 RmsProp 1137 loss=0.101556 err=0.101556
I 2015-05-26 10:01:40 theanets.trainer:168 RmsProp 1138 loss=0.111897 err=0.111897
I 2015-05-26 10:01:48 theanets.trainer:168 RmsProp 1139 loss=0.105110 err=0.105110
I 2015-05-26 10:01:54 theanets.trainer:168 RmsProp 1140 loss=0.101000 err=0.101000
I 2015-05-26 10:01:55 theanets.trainer:168 validation 114 loss=1650.762573 err=1650.762573
I 2015-05-26 10:02:01 theanets.trainer:168 RmsProp 1141 loss=0.104348 err=0.104348
I 2015-05-26 10:02:09 theanets.trainer:168 RmsProp 1142 loss=0.099963 err=0.099963
I 2015-05-26 10:02:15 theanets.trainer:168 RmsProp 1143 loss=0.110275 err=0.110275
I 2015-05-26 10:02:21 theanets.trainer:168 RmsProp 1144 loss=0.094795 err=0.094795
I 2015-05-26 10:02:28 theanets.trainer:168 RmsProp 1145 loss=0.105350 err=0.105350
I 2015-05-26 10:02:36 theanets.trainer:168 RmsProp 1146 loss=0.107137 err=0.107137
I 2015-05-26 10:02:43 theanets.trainer:168 RmsProp 1147 loss=0.104618 err=0.104618
I 2015-05-26 10:02:50 theanets.trainer:168 RmsProp 1148 loss=0.100056 err=0.100056
I 2015-05-26 10:02:57 theanets.trainer:168 RmsProp 1149 loss=0.103657 err=0.103657
I 2015-05-26 10:03:04 theanets.trainer:168 RmsProp 1150 loss=0.094996 err=0.094996
I 2015-05-26 10:03:05 theanets.trainer:168 validation 115 loss=1652.660522 err=1652.660522
I 2015-05-26 10:03:11 theanets.trainer:168 RmsProp 1151 loss=0.096591 err=0.096591
I 2015-05-26 10:03:18 theanets.trainer:168 RmsProp 1152 loss=0.098518 err=0.098518
I 2015-05-26 10:03:25 theanets.trainer:168 RmsProp 1153 loss=0.101377 err=0.101377
I 2015-05-26 10:03:32 theanets.trainer:168 RmsProp 1154 loss=0.097360 err=0.097360
I 2015-05-26 10:03:38 theanets.trainer:168 RmsProp 1155 loss=0.100054 err=0.100054
I 2015-05-26 10:03:46 theanets.trainer:168 RmsProp 1156 loss=0.100194 err=0.100194
I 2015-05-26 10:03:52 theanets.trainer:168 RmsProp 1157 loss=0.103516 err=0.103516
I 2015-05-26 10:03:59 theanets.trainer:168 RmsProp 1158 loss=0.105616 err=0.105616
I 2015-05-26 10:04:05 theanets.trainer:168 RmsProp 1159 loss=0.098093 err=0.098093
I 2015-05-26 10:04:11 theanets.trainer:168 RmsProp 1160 loss=0.101397 err=0.101397
I 2015-05-26 10:04:12 theanets.trainer:168 validation 116 loss=1648.207397 err=1648.207397 *
I 2015-05-26 10:04:17 theanets.trainer:168 RmsProp 1161 loss=0.105366 err=0.105366
I 2015-05-26 10:04:23 theanets.trainer:168 RmsProp 1162 loss=0.092542 err=0.092542
I 2015-05-26 10:04:29 theanets.trainer:168 RmsProp 1163 loss=0.102705 err=0.102705
I 2015-05-26 10:04:35 theanets.trainer:168 RmsProp 1164 loss=0.100938 err=0.100938
I 2015-05-26 10:04:40 theanets.trainer:168 RmsProp 1165 loss=0.094349 err=0.094349
I 2015-05-26 10:04:47 theanets.trainer:168 RmsProp 1166 loss=0.118749 err=0.118749
I 2015-05-26 10:04:52 theanets.trainer:168 RmsProp 1167 loss=0.108715 err=0.108715
I 2015-05-26 10:04:59 theanets.trainer:168 RmsProp 1168 loss=0.089627 err=0.089627
I 2015-05-26 10:05:05 theanets.trainer:168 RmsProp 1169 loss=0.093930 err=0.093930
I 2015-05-26 10:05:11 theanets.trainer:168 RmsProp 1170 loss=0.098408 err=0.098408
I 2015-05-26 10:05:11 theanets.trainer:168 validation 117 loss=1647.358032 err=1647.358032 *
I 2015-05-26 10:05:17 theanets.trainer:168 RmsProp 1171 loss=0.106779 err=0.106779
I 2015-05-26 10:05:22 theanets.trainer:168 RmsProp 1172 loss=0.098826 err=0.098826
I 2015-05-26 10:05:28 theanets.trainer:168 RmsProp 1173 loss=0.096524 err=0.096524
I 2015-05-26 10:05:33 theanets.trainer:168 RmsProp 1174 loss=0.094933 err=0.094933
I 2015-05-26 10:05:39 theanets.trainer:168 RmsProp 1175 loss=0.098172 err=0.098172
I 2015-05-26 10:05:44 theanets.trainer:168 RmsProp 1176 loss=0.097118 err=0.097118
I 2015-05-26 10:05:50 theanets.trainer:168 RmsProp 1177 loss=0.106642 err=0.106642
I 2015-05-26 10:05:55 theanets.trainer:168 RmsProp 1178 loss=0.092742 err=0.092742
I 2015-05-26 10:06:00 theanets.trainer:168 RmsProp 1179 loss=0.106876 err=0.106876
I 2015-05-26 10:06:06 theanets.trainer:168 RmsProp 1180 loss=0.101583 err=0.101583
I 2015-05-26 10:06:07 theanets.trainer:168 validation 118 loss=1648.239136 err=1648.239136
I 2015-05-26 10:06:12 theanets.trainer:168 RmsProp 1181 loss=0.093405 err=0.093405
I 2015-05-26 10:06:18 theanets.trainer:168 RmsProp 1182 loss=0.100950 err=0.100950
I 2015-05-26 10:06:23 theanets.trainer:168 RmsProp 1183 loss=0.096023 err=0.096023
I 2015-05-26 10:06:30 theanets.trainer:168 RmsProp 1184 loss=0.098530 err=0.098530
I 2015-05-26 10:06:35 theanets.trainer:168 RmsProp 1185 loss=0.097295 err=0.097295
I 2015-05-26 10:06:41 theanets.trainer:168 RmsProp 1186 loss=0.099328 err=0.099328
I 2015-05-26 10:06:47 theanets.trainer:168 RmsProp 1187 loss=0.096124 err=0.096124
I 2015-05-26 10:06:53 theanets.trainer:168 RmsProp 1188 loss=0.096807 err=0.096807
I 2015-05-26 10:06:59 theanets.trainer:168 RmsProp 1189 loss=0.097924 err=0.097924
I 2015-05-26 10:07:04 theanets.trainer:168 RmsProp 1190 loss=0.102124 err=0.102124
I 2015-05-26 10:07:05 theanets.trainer:168 validation 119 loss=1647.255127 err=1647.255127 *
I 2015-05-26 10:07:10 theanets.trainer:168 RmsProp 1191 loss=0.098684 err=0.098684
I 2015-05-26 10:07:15 theanets.trainer:168 RmsProp 1192 loss=0.107960 err=0.107960
I 2015-05-26 10:07:21 theanets.trainer:168 RmsProp 1193 loss=0.105131 err=0.105131
I 2015-05-26 10:07:26 theanets.trainer:168 RmsProp 1194 loss=0.094936 err=0.094936
I 2015-05-26 10:07:32 theanets.trainer:168 RmsProp 1195 loss=0.097911 err=0.097911
I 2015-05-26 10:07:37 theanets.trainer:168 RmsProp 1196 loss=0.091223 err=0.091223
I 2015-05-26 10:07:43 theanets.trainer:168 RmsProp 1197 loss=0.103189 err=0.103189
I 2015-05-26 10:07:49 theanets.trainer:168 RmsProp 1198 loss=0.100428 err=0.100428
I 2015-05-26 10:07:56 theanets.trainer:168 RmsProp 1199 loss=0.106960 err=0.106960
I 2015-05-26 10:08:02 theanets.trainer:168 RmsProp 1200 loss=0.097002 err=0.097002
I 2015-05-26 10:08:02 theanets.trainer:168 validation 120 loss=1645.968018 err=1645.968018 *
I 2015-05-26 10:08:08 theanets.trainer:168 RmsProp 1201 loss=0.092780 err=0.092780
I 2015-05-26 10:08:14 theanets.trainer:168 RmsProp 1202 loss=0.103793 err=0.103793
I 2015-05-26 10:08:19 theanets.trainer:168 RmsProp 1203 loss=0.095977 err=0.095977
I 2015-05-26 10:08:26 theanets.trainer:168 RmsProp 1204 loss=0.094929 err=0.094929
I 2015-05-26 10:08:31 theanets.trainer:168 RmsProp 1205 loss=0.091815 err=0.091815
I 2015-05-26 10:08:37 theanets.trainer:168 RmsProp 1206 loss=0.098399 err=0.098399
I 2015-05-26 10:08:43 theanets.trainer:168 RmsProp 1207 loss=0.094290 err=0.094290
I 2015-05-26 10:08:49 theanets.trainer:168 RmsProp 1208 loss=0.106519 err=0.106519
I 2015-05-26 10:08:55 theanets.trainer:168 RmsProp 1209 loss=0.108213 err=0.108213
I 2015-05-26 10:09:00 theanets.trainer:168 RmsProp 1210 loss=0.093442 err=0.093442
I 2015-05-26 10:09:01 theanets.trainer:168 validation 121 loss=1645.019897 err=1645.019897 *
I 2015-05-26 10:09:07 theanets.trainer:168 RmsProp 1211 loss=0.099481 err=0.099481
I 2015-05-26 10:09:13 theanets.trainer:168 RmsProp 1212 loss=0.097807 err=0.097807
I 2015-05-26 10:09:19 theanets.trainer:168 RmsProp 1213 loss=0.084930 err=0.084930
I 2015-05-26 10:09:24 theanets.trainer:168 RmsProp 1214 loss=0.105023 err=0.105023
I 2015-05-26 10:09:30 theanets.trainer:168 RmsProp 1215 loss=0.096540 err=0.096540
I 2015-05-26 10:09:35 theanets.trainer:168 RmsProp 1216 loss=0.101514 err=0.101514
I 2015-05-26 10:09:42 theanets.trainer:168 RmsProp 1217 loss=0.090225 err=0.090225
I 2015-05-26 10:09:47 theanets.trainer:168 RmsProp 1218 loss=0.099804 err=0.099804
I 2015-05-26 10:09:53 theanets.trainer:168 RmsProp 1219 loss=0.102377 err=0.102377
I 2015-05-26 10:09:59 theanets.trainer:168 RmsProp 1220 loss=0.092919 err=0.092919
I 2015-05-26 10:10:00 theanets.trainer:168 validation 122 loss=1644.182861 err=1644.182861 *
I 2015-05-26 10:10:06 theanets.trainer:168 RmsProp 1221 loss=0.091820 err=0.091820
I 2015-05-26 10:10:12 theanets.trainer:168 RmsProp 1222 loss=0.103152 err=0.103152
I 2015-05-26 10:10:17 theanets.trainer:168 RmsProp 1223 loss=0.085326 err=0.085326
I 2015-05-26 10:10:23 theanets.trainer:168 RmsProp 1224 loss=0.100192 err=0.100192
I 2015-05-26 10:10:29 theanets.trainer:168 RmsProp 1225 loss=0.098740 err=0.098740
I 2015-05-26 10:10:34 theanets.trainer:168 RmsProp 1226 loss=0.106349 err=0.106349
I 2015-05-26 10:10:40 theanets.trainer:168 RmsProp 1227 loss=0.095828 err=0.095828
I 2015-05-26 10:10:46 theanets.trainer:168 RmsProp 1228 loss=0.090102 err=0.090102
I 2015-05-26 10:10:52 theanets.trainer:168 RmsProp 1229 loss=0.099186 err=0.099186
I 2015-05-26 10:10:58 theanets.trainer:168 RmsProp 1230 loss=0.099226 err=0.099226
I 2015-05-26 10:10:58 theanets.trainer:168 validation 123 loss=1644.585571 err=1644.585571
I 2015-05-26 10:11:03 theanets.trainer:168 RmsProp 1231 loss=0.101353 err=0.101353
I 2015-05-26 10:11:09 theanets.trainer:168 RmsProp 1232 loss=0.093038 err=0.093038
I 2015-05-26 10:11:14 theanets.trainer:168 RmsProp 1233 loss=0.086507 err=0.086507
I 2015-05-26 10:11:20 theanets.trainer:168 RmsProp 1234 loss=0.113764 err=0.113764
I 2015-05-26 10:11:25 theanets.trainer:168 RmsProp 1235 loss=0.107541 err=0.107541
I 2015-05-26 10:11:31 theanets.trainer:168 RmsProp 1236 loss=0.098526 err=0.098526
I 2015-05-26 10:11:36 theanets.trainer:168 RmsProp 1237 loss=0.085056 err=0.085056
I 2015-05-26 10:11:42 theanets.trainer:168 RmsProp 1238 loss=0.096657 err=0.096657
I 2015-05-26 10:11:47 theanets.trainer:168 RmsProp 1239 loss=0.097141 err=0.097141
I 2015-05-26 10:11:52 theanets.trainer:168 RmsProp 1240 loss=0.092464 err=0.092464
I 2015-05-26 10:11:53 theanets.trainer:168 validation 124 loss=1643.620728 err=1643.620728 *
I 2015-05-26 10:11:58 theanets.trainer:168 RmsProp 1241 loss=0.094560 err=0.094560
I 2015-05-26 10:12:05 theanets.trainer:168 RmsProp 1242 loss=0.095482 err=0.095482
I 2015-05-26 10:12:10 theanets.trainer:168 RmsProp 1243 loss=0.098844 err=0.098844
I 2015-05-26 10:12:16 theanets.trainer:168 RmsProp 1244 loss=0.099262 err=0.099262
I 2015-05-26 10:12:21 theanets.trainer:168 RmsProp 1245 loss=0.096211 err=0.096211
I 2015-05-26 10:12:28 theanets.trainer:168 RmsProp 1246 loss=0.088830 err=0.088830
I 2015-05-26 10:12:33 theanets.trainer:168 RmsProp 1247 loss=0.094578 err=0.094578
I 2015-05-26 10:12:39 theanets.trainer:168 RmsProp 1248 loss=0.097859 err=0.097859
I 2015-05-26 10:12:45 theanets.trainer:168 RmsProp 1249 loss=0.094125 err=0.094125
I 2015-05-26 10:12:51 theanets.trainer:168 RmsProp 1250 loss=0.099600 err=0.099600
I 2015-05-26 10:12:51 theanets.trainer:168 validation 125 loss=1641.668213 err=1641.668213 *
I 2015-05-26 10:12:56 theanets.trainer:168 RmsProp 1251 loss=0.092836 err=0.092836
I 2015-05-26 10:13:02 theanets.trainer:168 RmsProp 1252 loss=0.096630 err=0.096630
I 2015-05-26 10:13:09 theanets.trainer:168 RmsProp 1253 loss=0.092972 err=0.092972
I 2015-05-26 10:13:15 theanets.trainer:168 RmsProp 1254 loss=0.091789 err=0.091789
I 2015-05-26 10:13:21 theanets.trainer:168 RmsProp 1255 loss=0.097187 err=0.097187
I 2015-05-26 10:13:27 theanets.trainer:168 RmsProp 1256 loss=0.089402 err=0.089402
I 2015-05-26 10:13:33 theanets.trainer:168 RmsProp 1257 loss=0.088442 err=0.088442
I 2015-05-26 10:13:40 theanets.trainer:168 RmsProp 1258 loss=0.095767 err=0.095767
I 2015-05-26 10:13:45 theanets.trainer:168 RmsProp 1259 loss=0.102379 err=0.102379
I 2015-05-26 10:13:51 theanets.trainer:168 RmsProp 1260 loss=0.096656 err=0.096656
I 2015-05-26 10:13:51 theanets.trainer:168 validation 126 loss=1641.627319 err=1641.627319 *
I 2015-05-26 10:13:56 theanets.trainer:168 RmsProp 1261 loss=0.092081 err=0.092081
I 2015-05-26 10:14:02 theanets.trainer:168 RmsProp 1262 loss=0.090333 err=0.090333
I 2015-05-26 10:14:08 theanets.trainer:168 RmsProp 1263 loss=0.093727 err=0.093727
I 2015-05-26 10:14:14 theanets.trainer:168 RmsProp 1264 loss=0.090827 err=0.090827
I 2015-05-26 10:14:19 theanets.trainer:168 RmsProp 1265 loss=0.088548 err=0.088548
I 2015-05-26 10:14:25 theanets.trainer:168 RmsProp 1266 loss=0.099252 err=0.099252
I 2015-05-26 10:14:31 theanets.trainer:168 RmsProp 1267 loss=0.094962 err=0.094962
I 2015-05-26 10:14:36 theanets.trainer:168 RmsProp 1268 loss=0.087573 err=0.087573
I 2015-05-26 10:14:42 theanets.trainer:168 RmsProp 1269 loss=0.092857 err=0.092857
I 2015-05-26 10:14:48 theanets.trainer:168 RmsProp 1270 loss=0.089645 err=0.089645
I 2015-05-26 10:14:48 theanets.trainer:168 validation 127 loss=1641.449585 err=1641.449585 *
I 2015-05-26 10:14:54 theanets.trainer:168 RmsProp 1271 loss=0.097139 err=0.097139
I 2015-05-26 10:15:01 theanets.trainer:168 RmsProp 1272 loss=0.089487 err=0.089487
I 2015-05-26 10:15:06 theanets.trainer:168 RmsProp 1273 loss=0.084858 err=0.084858
I 2015-05-26 10:15:12 theanets.trainer:168 RmsProp 1274 loss=0.111507 err=0.111507
I 2015-05-26 10:15:18 theanets.trainer:168 RmsProp 1275 loss=0.088550 err=0.088550
I 2015-05-26 10:15:23 theanets.trainer:168 RmsProp 1276 loss=0.086890 err=0.086890
I 2015-05-26 10:15:29 theanets.trainer:168 RmsProp 1277 loss=0.095534 err=0.095534
I 2015-05-26 10:15:34 theanets.trainer:168 RmsProp 1278 loss=0.087512 err=0.087512
I 2015-05-26 10:15:40 theanets.trainer:168 RmsProp 1279 loss=0.077818 err=0.077818
I 2015-05-26 10:15:46 theanets.trainer:168 RmsProp 1280 loss=0.109921 err=0.109921
I 2015-05-26 10:15:46 theanets.trainer:168 validation 128 loss=1639.822266 err=1639.822266 *
I 2015-05-26 10:15:52 theanets.trainer:168 RmsProp 1281 loss=0.092195 err=0.092195
I 2015-05-26 10:15:58 theanets.trainer:168 RmsProp 1282 loss=0.087947 err=0.087947
I 2015-05-26 10:16:04 theanets.trainer:168 RmsProp 1283 loss=0.080373 err=0.080373
I 2015-05-26 10:16:09 theanets.trainer:168 RmsProp 1284 loss=0.099015 err=0.099015
I 2015-05-26 10:16:15 theanets.trainer:168 RmsProp 1285 loss=0.091590 err=0.091590
I 2015-05-26 10:16:21 theanets.trainer:168 RmsProp 1286 loss=0.089747 err=0.089747
I 2015-05-26 10:16:26 theanets.trainer:168 RmsProp 1287 loss=0.092326 err=0.092326
I 2015-05-26 10:16:33 theanets.trainer:168 RmsProp 1288 loss=0.096083 err=0.096083
I 2015-05-26 10:16:38 theanets.trainer:168 RmsProp 1289 loss=0.101223 err=0.101223
I 2015-05-26 10:16:44 theanets.trainer:168 RmsProp 1290 loss=0.088802 err=0.088802
I 2015-05-26 10:16:44 theanets.trainer:168 validation 129 loss=1641.789917 err=1641.789917
I 2015-05-26 10:16:50 theanets.trainer:168 RmsProp 1291 loss=0.092338 err=0.092338
I 2015-05-26 10:16:55 theanets.trainer:168 RmsProp 1292 loss=0.095273 err=0.095273
I 2015-05-26 10:17:01 theanets.trainer:168 RmsProp 1293 loss=0.085605 err=0.085605
I 2015-05-26 10:17:06 theanets.trainer:168 RmsProp 1294 loss=0.087091 err=0.087091
I 2015-05-26 10:17:12 theanets.trainer:168 RmsProp 1295 loss=0.096675 err=0.096675
I 2015-05-26 10:17:17 theanets.trainer:168 RmsProp 1296 loss=0.087001 err=0.087001
I 2015-05-26 10:17:23 theanets.trainer:168 RmsProp 1297 loss=0.097518 err=0.097518
I 2015-05-26 10:17:28 theanets.trainer:168 RmsProp 1298 loss=0.091148 err=0.091148
I 2015-05-26 10:17:34 theanets.trainer:168 RmsProp 1299 loss=0.094016 err=0.094016
I 2015-05-26 10:17:40 theanets.trainer:168 RmsProp 1300 loss=0.085575 err=0.085575
I 2015-05-26 10:17:40 theanets.trainer:168 validation 130 loss=1638.461792 err=1638.461792 *
I 2015-05-26 10:17:46 theanets.trainer:168 RmsProp 1301 loss=0.102686 err=0.102686
I 2015-05-26 10:17:52 theanets.trainer:168 RmsProp 1302 loss=0.088077 err=0.088077
I 2015-05-26 10:17:57 theanets.trainer:168 RmsProp 1303 loss=0.093875 err=0.093875
I 2015-05-26 10:18:03 theanets.trainer:168 RmsProp 1304 loss=0.085447 err=0.085447
I 2015-05-26 10:18:08 theanets.trainer:168 RmsProp 1305 loss=0.089551 err=0.089551
I 2015-05-26 10:18:13 theanets.trainer:168 RmsProp 1306 loss=0.092910 err=0.092910
I 2015-05-26 10:18:20 theanets.trainer:168 RmsProp 1307 loss=0.087165 err=0.087165
I 2015-05-26 10:18:25 theanets.trainer:168 RmsProp 1308 loss=0.094109 err=0.094109
I 2015-05-26 10:18:31 theanets.trainer:168 RmsProp 1309 loss=0.092417 err=0.092417
I 2015-05-26 10:18:37 theanets.trainer:168 RmsProp 1310 loss=0.090553 err=0.090553
I 2015-05-26 10:18:37 theanets.trainer:168 validation 131 loss=1638.190308 err=1638.190308 *
I 2015-05-26 10:18:43 theanets.trainer:168 RmsProp 1311 loss=0.085921 err=0.085921
I 2015-05-26 10:18:48 theanets.trainer:168 RmsProp 1312 loss=0.090319 err=0.090319
I 2015-05-26 10:18:54 theanets.trainer:168 RmsProp 1313 loss=0.093356 err=0.093356
I 2015-05-26 10:18:59 theanets.trainer:168 RmsProp 1314 loss=0.090370 err=0.090370
I 2015-05-26 10:19:05 theanets.trainer:168 RmsProp 1315 loss=0.086813 err=0.086813
I 2015-05-26 10:19:11 theanets.trainer:168 RmsProp 1316 loss=0.092446 err=0.092446
I 2015-05-26 10:19:16 theanets.trainer:168 RmsProp 1317 loss=0.088553 err=0.088553
I 2015-05-26 10:19:22 theanets.trainer:168 RmsProp 1318 loss=0.076940 err=0.076940
I 2015-05-26 10:19:29 theanets.trainer:168 RmsProp 1319 loss=0.115109 err=0.115109
I 2015-05-26 10:19:34 theanets.trainer:168 RmsProp 1320 loss=0.085817 err=0.085817
I 2015-05-26 10:19:35 theanets.trainer:168 validation 132 loss=1638.525391 err=1638.525391
I 2015-05-26 10:19:40 theanets.trainer:168 RmsProp 1321 loss=0.093995 err=0.093995
I 2015-05-26 10:19:46 theanets.trainer:168 RmsProp 1322 loss=0.090318 err=0.090318
I 2015-05-26 10:19:51 theanets.trainer:168 RmsProp 1323 loss=0.091640 err=0.091640
I 2015-05-26 10:19:57 theanets.trainer:168 RmsProp 1324 loss=0.089274 err=0.089274
I 2015-05-26 10:20:03 theanets.trainer:168 RmsProp 1325 loss=0.103430 err=0.103430
I 2015-05-26 10:20:09 theanets.trainer:168 RmsProp 1326 loss=0.085474 err=0.085474
I 2015-05-26 10:20:14 theanets.trainer:168 RmsProp 1327 loss=0.090293 err=0.090293
I 2015-05-26 10:20:20 theanets.trainer:168 RmsProp 1328 loss=0.088881 err=0.088881
I 2015-05-26 10:20:26 theanets.trainer:168 RmsProp 1329 loss=0.087945 err=0.087945
I 2015-05-26 10:20:32 theanets.trainer:168 RmsProp 1330 loss=0.085339 err=0.085339
I 2015-05-26 10:20:32 theanets.trainer:168 validation 133 loss=1637.165649 err=1637.165649 *
I 2015-05-26 10:20:38 theanets.trainer:168 RmsProp 1331 loss=0.083224 err=0.083224
I 2015-05-26 10:20:43 theanets.trainer:168 RmsProp 1332 loss=0.102397 err=0.102397
I 2015-05-26 10:20:48 theanets.trainer:168 RmsProp 1333 loss=0.085148 err=0.085148
I 2015-05-26 10:20:54 theanets.trainer:168 RmsProp 1334 loss=0.088024 err=0.088024
I 2015-05-26 10:20:59 theanets.trainer:168 RmsProp 1335 loss=0.084652 err=0.084652
I 2015-05-26 10:21:05 theanets.trainer:168 RmsProp 1336 loss=0.096190 err=0.096190
I 2015-05-26 10:21:10 theanets.trainer:168 RmsProp 1337 loss=0.088148 err=0.088148
I 2015-05-26 10:21:16 theanets.trainer:168 RmsProp 1338 loss=0.088730 err=0.088730
I 2015-05-26 10:21:22 theanets.trainer:168 RmsProp 1339 loss=0.095908 err=0.095908
I 2015-05-26 10:21:28 theanets.trainer:168 RmsProp 1340 loss=0.097067 err=0.097067
I 2015-05-26 10:21:28 theanets.trainer:168 validation 134 loss=1637.580078 err=1637.580078
I 2015-05-26 10:21:34 theanets.trainer:168 RmsProp 1341 loss=0.082320 err=0.082320
I 2015-05-26 10:21:39 theanets.trainer:168 RmsProp 1342 loss=0.090794 err=0.090794
I 2015-05-26 10:21:44 theanets.trainer:168 RmsProp 1343 loss=0.088477 err=0.088477
I 2015-05-26 10:21:50 theanets.trainer:168 RmsProp 1344 loss=0.093236 err=0.093236
I 2015-05-26 10:21:55 theanets.trainer:168 RmsProp 1345 loss=0.084693 err=0.084693
I 2015-05-26 10:22:02 theanets.trainer:168 RmsProp 1346 loss=0.085097 err=0.085097
I 2015-05-26 10:22:07 theanets.trainer:168 RmsProp 1347 loss=0.089662 err=0.089662
I 2015-05-26 10:22:13 theanets.trainer:168 RmsProp 1348 loss=0.090598 err=0.090598
I 2015-05-26 10:22:19 theanets.trainer:168 RmsProp 1349 loss=0.085028 err=0.085028
I 2015-05-26 10:22:25 theanets.trainer:168 RmsProp 1350 loss=0.095498 err=0.095498
I 2015-05-26 10:22:25 theanets.trainer:168 validation 135 loss=1637.874268 err=1637.874268
I 2015-05-26 10:22:30 theanets.trainer:168 RmsProp 1351 loss=0.088562 err=0.088562
I 2015-05-26 10:22:36 theanets.trainer:168 RmsProp 1352 loss=0.088810 err=0.088810
I 2015-05-26 10:22:42 theanets.trainer:168 RmsProp 1353 loss=0.079763 err=0.079763
I 2015-05-26 10:22:48 theanets.trainer:168 RmsProp 1354 loss=0.081217 err=0.081217
I 2015-05-26 10:22:55 theanets.trainer:168 RmsProp 1355 loss=0.101528 err=0.101528
I 2015-05-26 10:23:00 theanets.trainer:168 RmsProp 1356 loss=0.090638 err=0.090638
I 2015-05-26 10:23:07 theanets.trainer:168 RmsProp 1357 loss=0.078678 err=0.078678
I 2015-05-26 10:23:13 theanets.trainer:168 RmsProp 1358 loss=0.093738 err=0.093738
I 2015-05-26 10:23:19 theanets.trainer:168 RmsProp 1359 loss=0.092046 err=0.092046
I 2015-05-26 10:23:23 theanets.trainer:168 RmsProp 1360 loss=0.082488 err=0.082488
I 2015-05-26 10:23:24 theanets.trainer:168 validation 136 loss=1635.985352 err=1635.985352 *
I 2015-05-26 10:23:30 theanets.trainer:168 RmsProp 1361 loss=0.091356 err=0.091356
I 2015-05-26 10:23:36 theanets.trainer:168 RmsProp 1362 loss=0.091757 err=0.091757
I 2015-05-26 10:23:42 theanets.trainer:168 RmsProp 1363 loss=0.087837 err=0.087837
I 2015-05-26 10:23:48 theanets.trainer:168 RmsProp 1364 loss=0.086949 err=0.086949
I 2015-05-26 10:23:54 theanets.trainer:168 RmsProp 1365 loss=0.093037 err=0.093037
I 2015-05-26 10:24:00 theanets.trainer:168 RmsProp 1366 loss=0.093348 err=0.093348
I 2015-05-26 10:24:06 theanets.trainer:168 RmsProp 1367 loss=0.081171 err=0.081171
I 2015-05-26 10:24:12 theanets.trainer:168 RmsProp 1368 loss=0.083907 err=0.083907
I 2015-05-26 10:24:18 theanets.trainer:168 RmsProp 1369 loss=0.082640 err=0.082640
I 2015-05-26 10:24:24 theanets.trainer:168 RmsProp 1370 loss=0.085105 err=0.085105
I 2015-05-26 10:24:25 theanets.trainer:168 validation 137 loss=1633.889771 err=1633.889771 *
I 2015-05-26 10:24:30 theanets.trainer:168 RmsProp 1371 loss=0.086250 err=0.086250
I 2015-05-26 10:24:36 theanets.trainer:168 RmsProp 1372 loss=0.093175 err=0.093175
I 2015-05-26 10:24:42 theanets.trainer:168 RmsProp 1373 loss=0.084425 err=0.084425
I 2015-05-26 10:24:47 theanets.trainer:168 RmsProp 1374 loss=0.085695 err=0.085695
I 2015-05-26 10:24:53 theanets.trainer:168 RmsProp 1375 loss=0.082739 err=0.082739
I 2015-05-26 10:24:59 theanets.trainer:168 RmsProp 1376 loss=0.102134 err=0.102134
I 2015-05-26 10:25:05 theanets.trainer:168 RmsProp 1377 loss=0.096007 err=0.096007
I 2015-05-26 10:25:12 theanets.trainer:168 RmsProp 1378 loss=0.083990 err=0.083990
I 2015-05-26 10:25:17 theanets.trainer:168 RmsProp 1379 loss=0.085795 err=0.085795
I 2015-05-26 10:25:23 theanets.trainer:168 RmsProp 1380 loss=0.087554 err=0.087554
I 2015-05-26 10:25:24 theanets.trainer:168 validation 138 loss=1632.121338 err=1632.121338 *
I 2015-05-26 10:25:29 theanets.trainer:168 RmsProp 1381 loss=0.083245 err=0.083245
I 2015-05-26 10:25:35 theanets.trainer:168 RmsProp 1382 loss=0.090043 err=0.090043
I 2015-05-26 10:25:41 theanets.trainer:168 RmsProp 1383 loss=0.081920 err=0.081920
I 2015-05-26 10:25:48 theanets.trainer:168 RmsProp 1384 loss=0.083219 err=0.083219
I 2015-05-26 10:25:53 theanets.trainer:168 RmsProp 1385 loss=0.093022 err=0.093022
I 2015-05-26 10:25:59 theanets.trainer:168 RmsProp 1386 loss=0.087831 err=0.087831
I 2015-05-26 10:26:05 theanets.trainer:168 RmsProp 1387 loss=0.084413 err=0.084413
I 2015-05-26 10:26:10 theanets.trainer:168 RmsProp 1388 loss=0.081025 err=0.081025
I 2015-05-26 10:26:17 theanets.trainer:168 RmsProp 1389 loss=0.085357 err=0.085357
I 2015-05-26 10:26:22 theanets.trainer:168 RmsProp 1390 loss=0.087426 err=0.087426
I 2015-05-26 10:26:23 theanets.trainer:168 validation 139 loss=1632.878662 err=1632.878662
I 2015-05-26 10:26:28 theanets.trainer:168 RmsProp 1391 loss=0.081202 err=0.081202
I 2015-05-26 10:26:33 theanets.trainer:168 RmsProp 1392 loss=0.083011 err=0.083011
I 2015-05-26 10:26:39 theanets.trainer:168 RmsProp 1393 loss=0.080856 err=0.080856
I 2015-05-26 10:26:45 theanets.trainer:168 RmsProp 1394 loss=0.094087 err=0.094087
I 2015-05-26 10:26:51 theanets.trainer:168 RmsProp 1395 loss=0.081511 err=0.081511
I 2015-05-26 10:26:56 theanets.trainer:168 RmsProp 1396 loss=0.085009 err=0.085009
I 2015-05-26 10:27:02 theanets.trainer:168 RmsProp 1397 loss=0.086049 err=0.086049
I 2015-05-26 10:27:08 theanets.trainer:168 RmsProp 1398 loss=0.084290 err=0.084290
I 2015-05-26 10:27:14 theanets.trainer:168 RmsProp 1399 loss=0.083557 err=0.083557
I 2015-05-26 10:27:20 theanets.trainer:168 RmsProp 1400 loss=0.088068 err=0.088068
I 2015-05-26 10:27:21 theanets.trainer:168 validation 140 loss=1631.905884 err=1631.905884 *
I 2015-05-26 10:27:26 theanets.trainer:168 RmsProp 1401 loss=0.090980 err=0.090980
I 2015-05-26 10:27:32 theanets.trainer:168 RmsProp 1402 loss=0.082715 err=0.082715
I 2015-05-26 10:27:38 theanets.trainer:168 RmsProp 1403 loss=0.095939 err=0.095939
I 2015-05-26 10:27:44 theanets.trainer:168 RmsProp 1404 loss=0.082223 err=0.082223
I 2015-05-26 10:27:50 theanets.trainer:168 RmsProp 1405 loss=0.088316 err=0.088316
I 2015-05-26 10:27:56 theanets.trainer:168 RmsProp 1406 loss=0.080446 err=0.080446
I 2015-05-26 10:28:01 theanets.trainer:168 RmsProp 1407 loss=0.103841 err=0.103841
I 2015-05-26 10:28:07 theanets.trainer:168 RmsProp 1408 loss=0.081380 err=0.081380
I 2015-05-26 10:28:13 theanets.trainer:168 RmsProp 1409 loss=0.091069 err=0.091069
I 2015-05-26 10:28:19 theanets.trainer:168 RmsProp 1410 loss=0.086639 err=0.086639
I 2015-05-26 10:28:19 theanets.trainer:168 validation 141 loss=1629.940674 err=1629.940674 *
I 2015-05-26 10:28:25 theanets.trainer:168 RmsProp 1411 loss=0.088185 err=0.088185
I 2015-05-26 10:28:30 theanets.trainer:168 RmsProp 1412 loss=0.082703 err=0.082703
I 2015-05-26 10:28:35 theanets.trainer:168 RmsProp 1413 loss=0.079555 err=0.079555
I 2015-05-26 10:28:41 theanets.trainer:168 RmsProp 1414 loss=0.088490 err=0.088490
I 2015-05-26 10:28:47 theanets.trainer:168 RmsProp 1415 loss=0.080172 err=0.080172
I 2015-05-26 10:28:52 theanets.trainer:168 RmsProp 1416 loss=0.088542 err=0.088542
I 2015-05-26 10:28:58 theanets.trainer:168 RmsProp 1417 loss=0.076078 err=0.076078
I 2015-05-26 10:29:04 theanets.trainer:168 RmsProp 1418 loss=0.085307 err=0.085307
I 2015-05-26 10:29:10 theanets.trainer:168 RmsProp 1419 loss=0.087489 err=0.087489
I 2015-05-26 10:29:15 theanets.trainer:168 RmsProp 1420 loss=0.081597 err=0.081597
I 2015-05-26 10:29:15 theanets.trainer:168 validation 142 loss=1633.428711 err=1633.428711
I 2015-05-26 10:29:21 theanets.trainer:168 RmsProp 1421 loss=0.080561 err=0.080561
I 2015-05-26 10:29:27 theanets.trainer:168 RmsProp 1422 loss=0.087578 err=0.087578
I 2015-05-26 10:29:33 theanets.trainer:168 RmsProp 1423 loss=0.084581 err=0.084581
I 2015-05-26 10:29:39 theanets.trainer:168 RmsProp 1424 loss=0.077449 err=0.077449
I 2015-05-26 10:29:45 theanets.trainer:168 RmsProp 1425 loss=0.088653 err=0.088653
I 2015-05-26 10:29:51 theanets.trainer:168 RmsProp 1426 loss=0.087274 err=0.087274
I 2015-05-26 10:29:56 theanets.trainer:168 RmsProp 1427 loss=0.085987 err=0.085987
I 2015-05-26 10:30:02 theanets.trainer:168 RmsProp 1428 loss=0.080796 err=0.080796
I 2015-05-26 10:30:08 theanets.trainer:168 RmsProp 1429 loss=0.092615 err=0.092615
I 2015-05-26 10:30:14 theanets.trainer:168 RmsProp 1430 loss=0.084831 err=0.084831
I 2015-05-26 10:30:14 theanets.trainer:168 validation 143 loss=1632.744019 err=1632.744019
I 2015-05-26 10:30:19 theanets.trainer:168 RmsProp 1431 loss=0.085176 err=0.085176
I 2015-05-26 10:30:26 theanets.trainer:168 RmsProp 1432 loss=0.083213 err=0.083213
I 2015-05-26 10:30:31 theanets.trainer:168 RmsProp 1433 loss=0.083291 err=0.083291
I 2015-05-26 10:30:37 theanets.trainer:168 RmsProp 1434 loss=0.074693 err=0.074693
I 2015-05-26 10:30:42 theanets.trainer:168 RmsProp 1435 loss=0.087565 err=0.087565
I 2015-05-26 10:30:49 theanets.trainer:168 RmsProp 1436 loss=0.083655 err=0.083655
I 2015-05-26 10:30:54 theanets.trainer:168 RmsProp 1437 loss=0.091681 err=0.091681
I 2015-05-26 10:31:00 theanets.trainer:168 RmsProp 1438 loss=0.088418 err=0.088418
I 2015-05-26 10:31:06 theanets.trainer:168 RmsProp 1439 loss=0.078366 err=0.078366
I 2015-05-26 10:31:11 theanets.trainer:168 RmsProp 1440 loss=0.074777 err=0.074777
I 2015-05-26 10:31:12 theanets.trainer:168 validation 144 loss=1631.711792 err=1631.711792
I 2015-05-26 10:31:17 theanets.trainer:168 RmsProp 1441 loss=0.096364 err=0.096364
I 2015-05-26 10:31:23 theanets.trainer:168 RmsProp 1442 loss=0.091592 err=0.091592
I 2015-05-26 10:31:28 theanets.trainer:168 RmsProp 1443 loss=0.082347 err=0.082347
I 2015-05-26 10:31:34 theanets.trainer:168 RmsProp 1444 loss=0.077080 err=0.077080
I 2015-05-26 10:31:39 theanets.trainer:168 RmsProp 1445 loss=0.094561 err=0.094561
I 2015-05-26 10:31:45 theanets.trainer:168 RmsProp 1446 loss=0.090899 err=0.090899
I 2015-05-26 10:31:51 theanets.trainer:168 RmsProp 1447 loss=0.089548 err=0.089548
I 2015-05-26 10:31:57 theanets.trainer:168 RmsProp 1448 loss=0.081124 err=0.081124
I 2015-05-26 10:32:03 theanets.trainer:168 RmsProp 1449 loss=0.088626 err=0.088626
I 2015-05-26 10:32:09 theanets.trainer:168 RmsProp 1450 loss=0.082249 err=0.082249
I 2015-05-26 10:32:09 theanets.trainer:168 validation 145 loss=1626.909546 err=1626.909546 *
I 2015-05-26 10:32:15 theanets.trainer:168 RmsProp 1451 loss=0.078535 err=0.078535
I 2015-05-26 10:32:21 theanets.trainer:168 RmsProp 1452 loss=0.080757 err=0.080757
I 2015-05-26 10:32:26 theanets.trainer:168 RmsProp 1453 loss=0.087408 err=0.087408
I 2015-05-26 10:32:32 theanets.trainer:168 RmsProp 1454 loss=0.081000 err=0.081000
I 2015-05-26 10:32:39 theanets.trainer:168 RmsProp 1455 loss=0.077875 err=0.077875
I 2015-05-26 10:32:44 theanets.trainer:168 RmsProp 1456 loss=0.082877 err=0.082877
I 2015-05-26 10:32:49 theanets.trainer:168 RmsProp 1457 loss=0.078945 err=0.078945
I 2015-05-26 10:32:55 theanets.trainer:168 RmsProp 1458 loss=0.090066 err=0.090066
I 2015-05-26 10:33:00 theanets.trainer:168 RmsProp 1459 loss=0.087359 err=0.087359
I 2015-05-26 10:33:06 theanets.trainer:168 RmsProp 1460 loss=0.077172 err=0.077172
I 2015-05-26 10:33:07 theanets.trainer:168 validation 146 loss=1627.665771 err=1627.665771
I 2015-05-26 10:33:11 theanets.trainer:168 RmsProp 1461 loss=0.083468 err=0.083468
I 2015-05-26 10:33:17 theanets.trainer:168 RmsProp 1462 loss=0.083771 err=0.083771
I 2015-05-26 10:33:23 theanets.trainer:168 RmsProp 1463 loss=0.095997 err=0.095997
I 2015-05-26 10:33:29 theanets.trainer:168 RmsProp 1464 loss=0.088767 err=0.088767
I 2015-05-26 10:33:35 theanets.trainer:168 RmsProp 1465 loss=0.083430 err=0.083430
I 2015-05-26 10:33:41 theanets.trainer:168 RmsProp 1466 loss=0.076746 err=0.076746
I 2015-05-26 10:33:47 theanets.trainer:168 RmsProp 1467 loss=0.074915 err=0.074915
I 2015-05-26 10:33:53 theanets.trainer:168 RmsProp 1468 loss=0.078347 err=0.078347
I 2015-05-26 10:33:59 theanets.trainer:168 RmsProp 1469 loss=0.093783 err=0.093783
I 2015-05-26 10:34:05 theanets.trainer:168 RmsProp 1470 loss=0.075279 err=0.075279
I 2015-05-26 10:34:05 theanets.trainer:168 validation 147 loss=1625.773560 err=1625.773560 *
I 2015-05-26 10:34:11 theanets.trainer:168 RmsProp 1471 loss=0.085341 err=0.085341
I 2015-05-26 10:34:16 theanets.trainer:168 RmsProp 1472 loss=0.082384 err=0.082384
I 2015-05-26 10:34:22 theanets.trainer:168 RmsProp 1473 loss=0.081193 err=0.081193
I 2015-05-26 10:34:28 theanets.trainer:168 RmsProp 1474 loss=0.077182 err=0.077182
I 2015-05-26 10:34:34 theanets.trainer:168 RmsProp 1475 loss=0.083454 err=0.083454
I 2015-05-26 10:34:40 theanets.trainer:168 RmsProp 1476 loss=0.073609 err=0.073609
I 2015-05-26 10:34:46 theanets.trainer:168 RmsProp 1477 loss=0.083049 err=0.083049
I 2015-05-26 10:34:52 theanets.trainer:168 RmsProp 1478 loss=0.084055 err=0.084055
I 2015-05-26 10:34:58 theanets.trainer:168 RmsProp 1479 loss=0.084007 err=0.084007
I 2015-05-26 10:35:04 theanets.trainer:168 RmsProp 1480 loss=0.072315 err=0.072315
I 2015-05-26 10:35:04 theanets.trainer:168 validation 148 loss=1626.159546 err=1626.159546
I 2015-05-26 10:35:10 theanets.trainer:168 RmsProp 1481 loss=0.089358 err=0.089358
I 2015-05-26 10:35:16 theanets.trainer:168 RmsProp 1482 loss=0.075627 err=0.075627
I 2015-05-26 10:35:21 theanets.trainer:168 RmsProp 1483 loss=0.078911 err=0.078911
I 2015-05-26 10:35:27 theanets.trainer:168 RmsProp 1484 loss=0.075801 err=0.075801
I 2015-05-26 10:35:33 theanets.trainer:168 RmsProp 1485 loss=0.075566 err=0.075566
I 2015-05-26 10:35:39 theanets.trainer:168 RmsProp 1486 loss=0.093929 err=0.093929
I 2015-05-26 10:35:44 theanets.trainer:168 RmsProp 1487 loss=0.087442 err=0.087442
I 2015-05-26 10:35:50 theanets.trainer:168 RmsProp 1488 loss=0.077905 err=0.077905
I 2015-05-26 10:35:56 theanets.trainer:168 RmsProp 1489 loss=0.080472 err=0.080472
I 2015-05-26 10:36:02 theanets.trainer:168 RmsProp 1490 loss=0.078010 err=0.078010
I 2015-05-26 10:36:02 theanets.trainer:168 validation 149 loss=1627.287476 err=1627.287476
I 2015-05-26 10:36:07 theanets.trainer:168 RmsProp 1491 loss=0.074348 err=0.074348
I 2015-05-26 10:36:13 theanets.trainer:168 RmsProp 1492 loss=0.096499 err=0.096499
I 2015-05-26 10:36:19 theanets.trainer:168 RmsProp 1493 loss=0.085422 err=0.085422
I 2015-05-26 10:36:25 theanets.trainer:168 RmsProp 1494 loss=0.072001 err=0.072001
I 2015-05-26 10:36:31 theanets.trainer:168 RmsProp 1495 loss=0.092212 err=0.092212
I 2015-05-26 10:36:37 theanets.trainer:168 RmsProp 1496 loss=0.071929 err=0.071929
I 2015-05-26 10:36:43 theanets.trainer:168 RmsProp 1497 loss=0.083779 err=0.083779
I 2015-05-26 10:36:49 theanets.trainer:168 RmsProp 1498 loss=0.077085 err=0.077085
I 2015-05-26 10:36:55 theanets.trainer:168 RmsProp 1499 loss=0.084348 err=0.084348
I 2015-05-26 10:37:01 theanets.trainer:168 RmsProp 1500 loss=0.078752 err=0.078752
I 2015-05-26 10:37:01 theanets.trainer:168 validation 150 loss=1625.209839 err=1625.209839 *
I 2015-05-26 10:37:07 theanets.trainer:168 RmsProp 1501 loss=0.082764 err=0.082764
I 2015-05-26 10:37:13 theanets.trainer:168 RmsProp 1502 loss=0.074291 err=0.074291
I 2015-05-26 10:37:19 theanets.trainer:168 RmsProp 1503 loss=0.085454 err=0.085454
I 2015-05-26 10:37:24 theanets.trainer:168 RmsProp 1504 loss=0.085794 err=0.085794
I 2015-05-26 10:37:31 theanets.trainer:168 RmsProp 1505 loss=0.080504 err=0.080504
I 2015-05-26 10:37:37 theanets.trainer:168 RmsProp 1506 loss=0.080833 err=0.080833
I 2015-05-26 10:37:43 theanets.trainer:168 RmsProp 1507 loss=0.072871 err=0.072871
I 2015-05-26 10:37:49 theanets.trainer:168 RmsProp 1508 loss=0.069820 err=0.069820
I 2015-05-26 10:37:54 theanets.trainer:168 RmsProp 1509 loss=0.093289 err=0.093289
I 2015-05-26 10:37:59 theanets.trainer:168 RmsProp 1510 loss=0.085721 err=0.085721
I 2015-05-26 10:38:00 theanets.trainer:168 validation 151 loss=1624.393799 err=1624.393799 *
I 2015-05-26 10:38:06 theanets.trainer:168 RmsProp 1511 loss=0.067862 err=0.067862
I 2015-05-26 10:38:11 theanets.trainer:168 RmsProp 1512 loss=0.079957 err=0.079957
I 2015-05-26 10:38:17 theanets.trainer:168 RmsProp 1513 loss=0.084508 err=0.084508
I 2015-05-26 10:38:23 theanets.trainer:168 RmsProp 1514 loss=0.083576 err=0.083576
I 2015-05-26 10:38:29 theanets.trainer:168 RmsProp 1515 loss=0.070747 err=0.070747
I 2015-05-26 10:38:34 theanets.trainer:168 RmsProp 1516 loss=0.078981 err=0.078981
I 2015-05-26 10:38:40 theanets.trainer:168 RmsProp 1517 loss=0.082448 err=0.082448
I 2015-05-26 10:38:45 theanets.trainer:168 RmsProp 1518 loss=0.081323 err=0.081323
I 2015-05-26 10:38:51 theanets.trainer:168 RmsProp 1519 loss=0.077845 err=0.077845
I 2015-05-26 10:38:56 theanets.trainer:168 RmsProp 1520 loss=0.073659 err=0.073659
I 2015-05-26 10:38:57 theanets.trainer:168 validation 152 loss=1622.705444 err=1622.705444 *
I 2015-05-26 10:39:02 theanets.trainer:168 RmsProp 1521 loss=0.095875 err=0.095875
I 2015-05-26 10:39:07 theanets.trainer:168 RmsProp 1522 loss=0.080233 err=0.080233
I 2015-05-26 10:39:13 theanets.trainer:168 RmsProp 1523 loss=0.076557 err=0.076557
I 2015-05-26 10:39:19 theanets.trainer:168 RmsProp 1524 loss=0.076913 err=0.076913
I 2015-05-26 10:39:24 theanets.trainer:168 RmsProp 1525 loss=0.087719 err=0.087719
I 2015-05-26 10:39:30 theanets.trainer:168 RmsProp 1526 loss=0.084428 err=0.084428
I 2015-05-26 10:39:35 theanets.trainer:168 RmsProp 1527 loss=0.071386 err=0.071386
I 2015-05-26 10:39:41 theanets.trainer:168 RmsProp 1528 loss=0.072699 err=0.072699
I 2015-05-26 10:39:47 theanets.trainer:168 RmsProp 1529 loss=0.092176 err=0.092176
I 2015-05-26 10:39:53 theanets.trainer:168 RmsProp 1530 loss=0.070897 err=0.070897
I 2015-05-26 10:39:53 theanets.trainer:168 validation 153 loss=1623.308960 err=1623.308960
I 2015-05-26 10:39:58 theanets.trainer:168 RmsProp 1531 loss=0.095592 err=0.095592
I 2015-05-26 10:40:05 theanets.trainer:168 RmsProp 1532 loss=0.077381 err=0.077381
I 2015-05-26 10:40:10 theanets.trainer:168 RmsProp 1533 loss=0.074568 err=0.074568
I 2015-05-26 10:40:16 theanets.trainer:168 RmsProp 1534 loss=0.075362 err=0.075362
I 2015-05-26 10:40:22 theanets.trainer:168 RmsProp 1535 loss=0.074432 err=0.074432
I 2015-05-26 10:40:28 theanets.trainer:168 RmsProp 1536 loss=0.082917 err=0.082917
I 2015-05-26 10:40:34 theanets.trainer:168 RmsProp 1537 loss=0.074350 err=0.074350
I 2015-05-26 10:40:40 theanets.trainer:168 RmsProp 1538 loss=0.078089 err=0.078089
I 2015-05-26 10:40:46 theanets.trainer:168 RmsProp 1539 loss=0.073885 err=0.073885
I 2015-05-26 10:40:52 theanets.trainer:168 RmsProp 1540 loss=0.085097 err=0.085097
I 2015-05-26 10:40:52 theanets.trainer:168 validation 154 loss=1620.919800 err=1620.919800 *
I 2015-05-26 10:40:58 theanets.trainer:168 RmsProp 1541 loss=0.075260 err=0.075260
I 2015-05-26 10:41:04 theanets.trainer:168 RmsProp 1542 loss=0.081459 err=0.081459
I 2015-05-26 10:41:09 theanets.trainer:168 RmsProp 1543 loss=0.080845 err=0.080845
I 2015-05-26 10:41:15 theanets.trainer:168 RmsProp 1544 loss=0.077783 err=0.077783
I 2015-05-26 10:41:20 theanets.trainer:168 RmsProp 1545 loss=0.073680 err=0.073680
I 2015-05-26 10:41:26 theanets.trainer:168 RmsProp 1546 loss=0.079489 err=0.079489
I 2015-05-26 10:41:32 theanets.trainer:168 RmsProp 1547 loss=0.071438 err=0.071438
I 2015-05-26 10:41:38 theanets.trainer:168 RmsProp 1548 loss=0.069731 err=0.069731
I 2015-05-26 10:41:44 theanets.trainer:168 RmsProp 1549 loss=0.111269 err=0.111269
I 2015-05-26 10:41:50 theanets.trainer:168 RmsProp 1550 loss=0.079289 err=0.079289
I 2015-05-26 10:41:50 theanets.trainer:168 validation 155 loss=1621.367554 err=1621.367554
I 2015-05-26 10:41:56 theanets.trainer:168 RmsProp 1551 loss=0.075094 err=0.075094
I 2015-05-26 10:42:02 theanets.trainer:168 RmsProp 1552 loss=0.074330 err=0.074330
I 2015-05-26 10:42:08 theanets.trainer:168 RmsProp 1553 loss=0.078520 err=0.078520
I 2015-05-26 10:42:14 theanets.trainer:168 RmsProp 1554 loss=0.083112 err=0.083112
I 2015-05-26 10:42:20 theanets.trainer:168 RmsProp 1555 loss=0.071503 err=0.071503
I 2015-05-26 10:42:26 theanets.trainer:168 RmsProp 1556 loss=0.077493 err=0.077493
I 2015-05-26 10:42:31 theanets.trainer:168 RmsProp 1557 loss=0.079218 err=0.079218
I 2015-05-26 10:42:37 theanets.trainer:168 RmsProp 1558 loss=0.076073 err=0.076073
I 2015-05-26 10:42:43 theanets.trainer:168 RmsProp 1559 loss=0.072939 err=0.072939
I 2015-05-26 10:42:49 theanets.trainer:168 RmsProp 1560 loss=0.075529 err=0.075529
I 2015-05-26 10:42:50 theanets.trainer:168 validation 156 loss=1621.880737 err=1621.880737
I 2015-05-26 10:42:56 theanets.trainer:168 RmsProp 1561 loss=0.079159 err=0.079159
I 2015-05-26 10:43:02 theanets.trainer:168 RmsProp 1562 loss=0.085201 err=0.085201
I 2015-05-26 10:43:07 theanets.trainer:168 RmsProp 1563 loss=0.085770 err=0.085770
I 2015-05-26 10:43:13 theanets.trainer:168 RmsProp 1564 loss=0.074787 err=0.074787
I 2015-05-26 10:43:19 theanets.trainer:168 RmsProp 1565 loss=0.082201 err=0.082201
I 2015-05-26 10:43:25 theanets.trainer:168 RmsProp 1566 loss=0.067845 err=0.067845
I 2015-05-26 10:43:31 theanets.trainer:168 RmsProp 1567 loss=0.078585 err=0.078585
I 2015-05-26 10:43:36 theanets.trainer:168 RmsProp 1568 loss=0.082063 err=0.082063
I 2015-05-26 10:43:42 theanets.trainer:168 RmsProp 1569 loss=0.074981 err=0.074981
I 2015-05-26 10:43:48 theanets.trainer:168 RmsProp 1570 loss=0.072966 err=0.072966
I 2015-05-26 10:43:48 theanets.trainer:168 validation 157 loss=1620.599854 err=1620.599854 *
I 2015-05-26 10:43:53 theanets.trainer:168 RmsProp 1571 loss=0.068376 err=0.068376
I 2015-05-26 10:43:59 theanets.trainer:168 RmsProp 1572 loss=0.090516 err=0.090516
I 2015-05-26 10:44:04 theanets.trainer:168 RmsProp 1573 loss=0.076945 err=0.076945
I 2015-05-26 10:44:10 theanets.trainer:168 RmsProp 1574 loss=0.079414 err=0.079414
I 2015-05-26 10:44:16 theanets.trainer:168 RmsProp 1575 loss=0.077861 err=0.077861
I 2015-05-26 10:44:22 theanets.trainer:168 RmsProp 1576 loss=0.073660 err=0.073660
I 2015-05-26 10:44:27 theanets.trainer:168 RmsProp 1577 loss=0.078496 err=0.078496
I 2015-05-26 10:44:33 theanets.trainer:168 RmsProp 1578 loss=0.066668 err=0.066668
I 2015-05-26 10:44:39 theanets.trainer:168 RmsProp 1579 loss=0.094455 err=0.094455
I 2015-05-26 10:44:45 theanets.trainer:168 RmsProp 1580 loss=0.075462 err=0.075462
I 2015-05-26 10:44:45 theanets.trainer:168 validation 158 loss=1618.315308 err=1618.315308 *
I 2015-05-26 10:44:51 theanets.trainer:168 RmsProp 1581 loss=0.073134 err=0.073134
I 2015-05-26 10:44:57 theanets.trainer:168 RmsProp 1582 loss=0.075469 err=0.075469
I 2015-05-26 10:45:02 theanets.trainer:168 RmsProp 1583 loss=0.091285 err=0.091285
I 2015-05-26 10:45:08 theanets.trainer:168 RmsProp 1584 loss=0.074147 err=0.074147
I 2015-05-26 10:45:14 theanets.trainer:168 RmsProp 1585 loss=0.077508 err=0.077508
I 2015-05-26 10:45:19 theanets.trainer:168 RmsProp 1586 loss=0.078008 err=0.078008
I 2015-05-26 10:45:25 theanets.trainer:168 RmsProp 1587 loss=0.073024 err=0.073024
I 2015-05-26 10:45:31 theanets.trainer:168 RmsProp 1588 loss=0.078515 err=0.078515
I 2015-05-26 10:45:37 theanets.trainer:168 RmsProp 1589 loss=0.080705 err=0.080705
I 2015-05-26 10:45:44 theanets.trainer:168 RmsProp 1590 loss=0.069171 err=0.069171
I 2015-05-26 10:45:44 theanets.trainer:168 validation 159 loss=1618.055176 err=1618.055176 *
I 2015-05-26 10:45:50 theanets.trainer:168 RmsProp 1591 loss=0.083864 err=0.083864
I 2015-05-26 10:45:55 theanets.trainer:168 RmsProp 1592 loss=0.075557 err=0.075557
I 2015-05-26 10:46:01 theanets.trainer:168 RmsProp 1593 loss=0.079172 err=0.079172
I 2015-05-26 10:46:07 theanets.trainer:168 RmsProp 1594 loss=0.078935 err=0.078935
I 2015-05-26 10:46:13 theanets.trainer:168 RmsProp 1595 loss=0.076393 err=0.076393
I 2015-05-26 10:46:19 theanets.trainer:168 RmsProp 1596 loss=0.071587 err=0.071587
I 2015-05-26 10:46:25 theanets.trainer:168 RmsProp 1597 loss=0.087156 err=0.087156
I 2015-05-26 10:46:31 theanets.trainer:168 RmsProp 1598 loss=0.069846 err=0.069846
I 2015-05-26 10:46:37 theanets.trainer:168 RmsProp 1599 loss=0.074913 err=0.074913
I 2015-05-26 10:46:43 theanets.trainer:168 RmsProp 1600 loss=0.067658 err=0.067658
I 2015-05-26 10:46:44 theanets.trainer:168 validation 160 loss=1617.257202 err=1617.257202 *
I 2015-05-26 10:46:49 theanets.trainer:168 RmsProp 1601 loss=0.077415 err=0.077415
I 2015-05-26 10:46:56 theanets.trainer:168 RmsProp 1602 loss=0.079801 err=0.079801
I 2015-05-26 10:47:01 theanets.trainer:168 RmsProp 1603 loss=0.070671 err=0.070671
I 2015-05-26 10:47:07 theanets.trainer:168 RmsProp 1604 loss=0.080897 err=0.080897
I 2015-05-26 10:47:13 theanets.trainer:168 RmsProp 1605 loss=0.069778 err=0.069778
I 2015-05-26 10:47:19 theanets.trainer:168 RmsProp 1606 loss=0.083043 err=0.083043
I 2015-05-26 10:47:24 theanets.trainer:168 RmsProp 1607 loss=0.070402 err=0.070402
I 2015-05-26 10:47:31 theanets.trainer:168 RmsProp 1608 loss=0.084390 err=0.084390
I 2015-05-26 10:47:36 theanets.trainer:168 RmsProp 1609 loss=0.070698 err=0.070698
I 2015-05-26 10:47:41 theanets.trainer:168 RmsProp 1610 loss=0.077687 err=0.077687
I 2015-05-26 10:47:42 theanets.trainer:168 validation 161 loss=1618.446899 err=1618.446899
I 2015-05-26 10:47:47 theanets.trainer:168 RmsProp 1611 loss=0.079212 err=0.079212
I 2015-05-26 10:47:53 theanets.trainer:168 RmsProp 1612 loss=0.073235 err=0.073235
I 2015-05-26 10:47:58 theanets.trainer:168 RmsProp 1613 loss=0.081307 err=0.081307
I 2015-05-26 10:48:04 theanets.trainer:168 RmsProp 1614 loss=0.075381 err=0.075381
I 2015-05-26 10:48:10 theanets.trainer:168 RmsProp 1615 loss=0.077702 err=0.077702
I 2015-05-26 10:48:16 theanets.trainer:168 RmsProp 1616 loss=0.070911 err=0.070911
I 2015-05-26 10:48:22 theanets.trainer:168 RmsProp 1617 loss=0.067299 err=0.067299
I 2015-05-26 10:48:28 theanets.trainer:168 RmsProp 1618 loss=0.080683 err=0.080683
I 2015-05-26 10:48:34 theanets.trainer:168 RmsProp 1619 loss=0.081985 err=0.081985
I 2015-05-26 10:48:40 theanets.trainer:168 RmsProp 1620 loss=0.070700 err=0.070700
I 2015-05-26 10:48:40 theanets.trainer:168 validation 162 loss=1619.734009 err=1619.734009
I 2015-05-26 10:48:46 theanets.trainer:168 RmsProp 1621 loss=0.077439 err=0.077439
I 2015-05-26 10:48:51 theanets.trainer:168 RmsProp 1622 loss=0.074006 err=0.074006
I 2015-05-26 10:48:56 theanets.trainer:168 RmsProp 1623 loss=0.076161 err=0.076161
I 2015-05-26 10:49:02 theanets.trainer:168 RmsProp 1624 loss=0.071871 err=0.071871
I 2015-05-26 10:49:08 theanets.trainer:168 RmsProp 1625 loss=0.078560 err=0.078560
I 2015-05-26 10:49:14 theanets.trainer:168 RmsProp 1626 loss=0.073726 err=0.073726
I 2015-05-26 10:49:20 theanets.trainer:168 RmsProp 1627 loss=0.075582 err=0.075582
I 2015-05-26 10:49:26 theanets.trainer:168 RmsProp 1628 loss=0.075351 err=0.075351
I 2015-05-26 10:49:31 theanets.trainer:168 RmsProp 1629 loss=0.069376 err=0.069376
I 2015-05-26 10:49:37 theanets.trainer:168 RmsProp 1630 loss=0.087448 err=0.087448
I 2015-05-26 10:49:37 theanets.trainer:168 validation 163 loss=1615.535156 err=1615.535156 *
I 2015-05-26 10:49:43 theanets.trainer:168 RmsProp 1631 loss=0.075141 err=0.075141
I 2015-05-26 10:49:49 theanets.trainer:168 RmsProp 1632 loss=0.083816 err=0.083816
I 2015-05-26 10:49:55 theanets.trainer:168 RmsProp 1633 loss=0.070615 err=0.070615
I 2015-05-26 10:50:01 theanets.trainer:168 RmsProp 1634 loss=0.076956 err=0.076956
I 2015-05-26 10:50:06 theanets.trainer:168 RmsProp 1635 loss=0.075179 err=0.075179
I 2015-05-26 10:50:12 theanets.trainer:168 RmsProp 1636 loss=0.080653 err=0.080653
I 2015-05-26 10:50:18 theanets.trainer:168 RmsProp 1637 loss=0.067428 err=0.067428
I 2015-05-26 10:50:24 theanets.trainer:168 RmsProp 1638 loss=0.074025 err=0.074025
I 2015-05-26 10:50:29 theanets.trainer:168 RmsProp 1639 loss=0.077522 err=0.077522
I 2015-05-26 10:50:36 theanets.trainer:168 RmsProp 1640 loss=0.076090 err=0.076090
I 2015-05-26 10:50:36 theanets.trainer:168 validation 164 loss=1617.422241 err=1617.422241
I 2015-05-26 10:50:42 theanets.trainer:168 RmsProp 1641 loss=0.073391 err=0.073391
I 2015-05-26 10:50:47 theanets.trainer:168 RmsProp 1642 loss=0.074825 err=0.074825
I 2015-05-26 10:50:53 theanets.trainer:168 RmsProp 1643 loss=0.066631 err=0.066631
I 2015-05-26 10:50:58 theanets.trainer:168 RmsProp 1644 loss=0.077776 err=0.077776
I 2015-05-26 10:51:04 theanets.trainer:168 RmsProp 1645 loss=0.075333 err=0.075333
I 2015-05-26 10:51:11 theanets.trainer:168 RmsProp 1646 loss=0.069701 err=0.069701
I 2015-05-26 10:51:16 theanets.trainer:168 RmsProp 1647 loss=0.075697 err=0.075697
I 2015-05-26 10:51:22 theanets.trainer:168 RmsProp 1648 loss=0.074695 err=0.074695
I 2015-05-26 10:51:28 theanets.trainer:168 RmsProp 1649 loss=0.075745 err=0.075745
I 2015-05-26 10:51:33 theanets.trainer:168 RmsProp 1650 loss=0.075098 err=0.075098
I 2015-05-26 10:51:33 theanets.trainer:168 validation 165 loss=1614.953003 err=1614.953003 *
I 2015-05-26 10:51:39 theanets.trainer:168 RmsProp 1651 loss=0.075199 err=0.075199
I 2015-05-26 10:51:45 theanets.trainer:168 RmsProp 1652 loss=0.072477 err=0.072477
I 2015-05-26 10:51:51 theanets.trainer:168 RmsProp 1653 loss=0.076725 err=0.076725
I 2015-05-26 10:51:57 theanets.trainer:168 RmsProp 1654 loss=0.076607 err=0.076607
I 2015-05-26 10:52:03 theanets.trainer:168 RmsProp 1655 loss=0.072162 err=0.072162
I 2015-05-26 10:52:08 theanets.trainer:168 RmsProp 1656 loss=0.068542 err=0.068542
I 2015-05-26 10:52:13 theanets.trainer:168 RmsProp 1657 loss=0.072752 err=0.072752
I 2015-05-26 10:52:19 theanets.trainer:168 RmsProp 1658 loss=0.069568 err=0.069568
I 2015-05-26 10:52:25 theanets.trainer:168 RmsProp 1659 loss=0.069645 err=0.069645
I 2015-05-26 10:52:32 theanets.trainer:168 RmsProp 1660 loss=0.078650 err=0.078650
I 2015-05-26 10:52:32 theanets.trainer:168 validation 166 loss=1616.235718 err=1616.235718
I 2015-05-26 10:52:38 theanets.trainer:168 RmsProp 1661 loss=0.077368 err=0.077368
I 2015-05-26 10:52:43 theanets.trainer:168 RmsProp 1662 loss=0.065878 err=0.065878
I 2015-05-26 10:52:49 theanets.trainer:168 RmsProp 1663 loss=0.088539 err=0.088539
I 2015-05-26 10:52:55 theanets.trainer:168 RmsProp 1664 loss=0.070637 err=0.070637
I 2015-05-26 10:53:01 theanets.trainer:168 RmsProp 1665 loss=0.075380 err=0.075380
I 2015-05-26 10:53:07 theanets.trainer:168 RmsProp 1666 loss=0.072182 err=0.072182
I 2015-05-26 10:53:13 theanets.trainer:168 RmsProp 1667 loss=0.068843 err=0.068843
I 2015-05-26 10:53:19 theanets.trainer:168 RmsProp 1668 loss=0.063634 err=0.063634
I 2015-05-26 10:53:25 theanets.trainer:168 RmsProp 1669 loss=0.083238 err=0.083238
I 2015-05-26 10:53:30 theanets.trainer:168 RmsProp 1670 loss=0.074733 err=0.074733
I 2015-05-26 10:53:30 theanets.trainer:168 validation 167 loss=1615.798950 err=1615.798950
I 2015-05-26 10:53:36 theanets.trainer:168 RmsProp 1671 loss=0.070735 err=0.070735
I 2015-05-26 10:53:42 theanets.trainer:168 RmsProp 1672 loss=0.081983 err=0.081983
I 2015-05-26 10:53:47 theanets.trainer:168 RmsProp 1673 loss=0.069662 err=0.069662
I 2015-05-26 10:53:54 theanets.trainer:168 RmsProp 1674 loss=0.064260 err=0.064260
I 2015-05-26 10:54:00 theanets.trainer:168 RmsProp 1675 loss=0.085516 err=0.085516
I 2015-05-26 10:54:05 theanets.trainer:168 RmsProp 1676 loss=0.073323 err=0.073323
I 2015-05-26 10:54:11 theanets.trainer:168 RmsProp 1677 loss=0.072509 err=0.072509
I 2015-05-26 10:54:17 theanets.trainer:168 RmsProp 1678 loss=0.074695 err=0.074695
I 2015-05-26 10:54:23 theanets.trainer:168 RmsProp 1679 loss=0.072014 err=0.072014
I 2015-05-26 10:54:28 theanets.trainer:168 RmsProp 1680 loss=0.088611 err=0.088611
I 2015-05-26 10:54:29 theanets.trainer:168 validation 168 loss=1613.738037 err=1613.738037 *
I 2015-05-26 10:54:35 theanets.trainer:168 RmsProp 1681 loss=0.067867 err=0.067867
I 2015-05-26 10:54:41 theanets.trainer:168 RmsProp 1682 loss=0.065113 err=0.065113
I 2015-05-26 10:54:46 theanets.trainer:168 RmsProp 1683 loss=0.075768 err=0.075768
I 2015-05-26 10:54:52 theanets.trainer:168 RmsProp 1684 loss=0.076966 err=0.076966
I 2015-05-26 10:54:58 theanets.trainer:168 RmsProp 1685 loss=0.068706 err=0.068706
I 2015-05-26 10:55:04 theanets.trainer:168 RmsProp 1686 loss=0.076024 err=0.076024
I 2015-05-26 10:55:09 theanets.trainer:168 RmsProp 1687 loss=0.063697 err=0.063697
I 2015-05-26 10:55:15 theanets.trainer:168 RmsProp 1688 loss=0.074848 err=0.074848
I 2015-05-26 10:55:21 theanets.trainer:168 RmsProp 1689 loss=0.073962 err=0.073962
I 2015-05-26 10:55:27 theanets.trainer:168 RmsProp 1690 loss=0.072033 err=0.072033
I 2015-05-26 10:55:28 theanets.trainer:168 validation 169 loss=1614.452515 err=1614.452515
I 2015-05-26 10:55:33 theanets.trainer:168 RmsProp 1691 loss=0.076529 err=0.076529
I 2015-05-26 10:55:39 theanets.trainer:168 RmsProp 1692 loss=0.070501 err=0.070501
I 2015-05-26 10:55:44 theanets.trainer:168 RmsProp 1693 loss=0.073230 err=0.073230
I 2015-05-26 10:55:49 theanets.trainer:168 RmsProp 1694 loss=0.074693 err=0.074693
I 2015-05-26 10:55:55 theanets.trainer:168 RmsProp 1695 loss=0.066722 err=0.066722
I 2015-05-26 10:56:01 theanets.trainer:168 RmsProp 1696 loss=0.072952 err=0.072952
I 2015-05-26 10:56:07 theanets.trainer:168 RmsProp 1697 loss=0.075992 err=0.075992
I 2015-05-26 10:56:13 theanets.trainer:168 RmsProp 1698 loss=0.084167 err=0.084167
I 2015-05-26 10:56:19 theanets.trainer:168 RmsProp 1699 loss=0.069797 err=0.069797
I 2015-05-26 10:56:24 theanets.trainer:168 RmsProp 1700 loss=0.069706 err=0.069706
I 2015-05-26 10:56:25 theanets.trainer:168 validation 170 loss=1612.907471 err=1612.907471 *
I 2015-05-26 10:56:30 theanets.trainer:168 RmsProp 1701 loss=0.070070 err=0.070070
I 2015-05-26 10:56:35 theanets.trainer:168 RmsProp 1702 loss=0.071772 err=0.071772
I 2015-05-26 10:56:41 theanets.trainer:168 RmsProp 1703 loss=0.082022 err=0.082022
I 2015-05-26 10:56:47 theanets.trainer:168 RmsProp 1704 loss=0.075562 err=0.075562
I 2015-05-26 10:56:53 theanets.trainer:168 RmsProp 1705 loss=0.073739 err=0.073739
I 2015-05-26 10:56:59 theanets.trainer:168 RmsProp 1706 loss=0.064682 err=0.064682
I 2015-05-26 10:57:04 theanets.trainer:168 RmsProp 1707 loss=0.073691 err=0.073691
I 2015-05-26 10:57:10 theanets.trainer:168 RmsProp 1708 loss=0.067595 err=0.067595
I 2015-05-26 10:57:16 theanets.trainer:168 RmsProp 1709 loss=0.070638 err=0.070638
I 2015-05-26 10:57:21 theanets.trainer:168 RmsProp 1710 loss=0.071120 err=0.071120
I 2015-05-26 10:57:21 theanets.trainer:168 validation 171 loss=1614.321289 err=1614.321289
I 2015-05-26 10:57:27 theanets.trainer:168 RmsProp 1711 loss=0.070885 err=0.070885
I 2015-05-26 10:57:33 theanets.trainer:168 RmsProp 1712 loss=0.069252 err=0.069252
I 2015-05-26 10:57:39 theanets.trainer:168 RmsProp 1713 loss=0.071473 err=0.071473
I 2015-05-26 10:57:45 theanets.trainer:168 RmsProp 1714 loss=0.069220 err=0.069220
I 2015-05-26 10:57:51 theanets.trainer:168 RmsProp 1715 loss=0.073148 err=0.073148
I 2015-05-26 10:57:57 theanets.trainer:168 RmsProp 1716 loss=0.073276 err=0.073276
I 2015-05-26 10:58:03 theanets.trainer:168 RmsProp 1717 loss=0.071346 err=0.071346
I 2015-05-26 10:58:09 theanets.trainer:168 RmsProp 1718 loss=0.069087 err=0.069087
I 2015-05-26 10:58:15 theanets.trainer:168 RmsProp 1719 loss=0.072133 err=0.072133
I 2015-05-26 10:58:20 theanets.trainer:168 RmsProp 1720 loss=0.081830 err=0.081830
I 2015-05-26 10:58:21 theanets.trainer:168 validation 172 loss=1612.985718 err=1612.985718
I 2015-05-26 10:58:26 theanets.trainer:168 RmsProp 1721 loss=0.066006 err=0.066006
I 2015-05-26 10:58:32 theanets.trainer:168 RmsProp 1722 loss=0.073797 err=0.073797
I 2015-05-26 10:58:37 theanets.trainer:168 RmsProp 1723 loss=0.068666 err=0.068666
I 2015-05-26 10:58:43 theanets.trainer:168 RmsProp 1724 loss=0.068734 err=0.068734
I 2015-05-26 10:58:49 theanets.trainer:168 RmsProp 1725 loss=0.069155 err=0.069155
I 2015-05-26 10:58:55 theanets.trainer:168 RmsProp 1726 loss=0.080827 err=0.080827
I 2015-05-26 10:59:01 theanets.trainer:168 RmsProp 1727 loss=0.068740 err=0.068740
I 2015-05-26 10:59:06 theanets.trainer:168 RmsProp 1728 loss=0.069939 err=0.069939
I 2015-05-26 10:59:11 theanets.trainer:168 RmsProp 1729 loss=0.063995 err=0.063995
I 2015-05-26 10:59:17 theanets.trainer:168 RmsProp 1730 loss=0.071613 err=0.071613
I 2015-05-26 10:59:17 theanets.trainer:168 validation 173 loss=1612.745728 err=1612.745728 *
I 2015-05-26 10:59:23 theanets.trainer:168 RmsProp 1731 loss=0.078866 err=0.078866
I 2015-05-26 10:59:28 theanets.trainer:168 RmsProp 1732 loss=0.065443 err=0.065443
I 2015-05-26 10:59:33 theanets.trainer:168 RmsProp 1733 loss=0.075032 err=0.075032
I 2015-05-26 10:59:39 theanets.trainer:168 RmsProp 1734 loss=0.083069 err=0.083069
I 2015-05-26 10:59:45 theanets.trainer:168 RmsProp 1735 loss=0.067682 err=0.067682
I 2015-05-26 10:59:51 theanets.trainer:168 RmsProp 1736 loss=0.069373 err=0.069373
I 2015-05-26 10:59:56 theanets.trainer:168 RmsProp 1737 loss=0.061912 err=0.061912
I 2015-05-26 11:00:02 theanets.trainer:168 RmsProp 1738 loss=0.082782 err=0.082782
I 2015-05-26 11:00:08 theanets.trainer:168 RmsProp 1739 loss=0.068905 err=0.068905
I 2015-05-26 11:00:14 theanets.trainer:168 RmsProp 1740 loss=0.062205 err=0.062205
I 2015-05-26 11:00:15 theanets.trainer:168 validation 174 loss=1610.303589 err=1610.303589 *
I 2015-05-26 11:00:21 theanets.trainer:168 RmsProp 1741 loss=0.078144 err=0.078144
I 2015-05-26 11:00:26 theanets.trainer:168 RmsProp 1742 loss=0.075133 err=0.075133
I 2015-05-26 11:00:32 theanets.trainer:168 RmsProp 1743 loss=0.073903 err=0.073903
I 2015-05-26 11:00:38 theanets.trainer:168 RmsProp 1744 loss=0.071344 err=0.071344
I 2015-05-26 11:00:44 theanets.trainer:168 RmsProp 1745 loss=0.063008 err=0.063008
I 2015-05-26 11:00:50 theanets.trainer:168 RmsProp 1746 loss=0.068694 err=0.068694
I 2015-05-26 11:00:56 theanets.trainer:168 RmsProp 1747 loss=0.074360 err=0.074360
I 2015-05-26 11:01:01 theanets.trainer:168 RmsProp 1748 loss=0.069568 err=0.069568
I 2015-05-26 11:01:08 theanets.trainer:168 RmsProp 1749 loss=0.073514 err=0.073514
I 2015-05-26 11:01:13 theanets.trainer:168 RmsProp 1750 loss=0.060655 err=0.060655
I 2015-05-26 11:01:14 theanets.trainer:168 validation 175 loss=1611.782104 err=1611.782104
I 2015-05-26 11:01:19 theanets.trainer:168 RmsProp 1751 loss=0.078530 err=0.078530
I 2015-05-26 11:01:26 theanets.trainer:168 RmsProp 1752 loss=0.074090 err=0.074090
I 2015-05-26 11:01:31 theanets.trainer:168 RmsProp 1753 loss=0.069921 err=0.069921
I 2015-05-26 11:01:37 theanets.trainer:168 RmsProp 1754 loss=0.067300 err=0.067300
I 2015-05-26 11:01:43 theanets.trainer:168 RmsProp 1755 loss=0.068989 err=0.068989
I 2015-05-26 11:01:49 theanets.trainer:168 RmsProp 1756 loss=0.073851 err=0.073851
I 2015-05-26 11:01:55 theanets.trainer:168 RmsProp 1757 loss=0.081071 err=0.081071
I 2015-05-26 11:02:00 theanets.trainer:168 RmsProp 1758 loss=0.066933 err=0.066933
I 2015-05-26 11:02:06 theanets.trainer:168 RmsProp 1759 loss=0.069926 err=0.069926
I 2015-05-26 11:02:11 theanets.trainer:168 RmsProp 1760 loss=0.061500 err=0.061500
I 2015-05-26 11:02:12 theanets.trainer:168 validation 176 loss=1610.970337 err=1610.970337
I 2015-05-26 11:02:17 theanets.trainer:168 RmsProp 1761 loss=0.076983 err=0.076983
I 2015-05-26 11:02:24 theanets.trainer:168 RmsProp 1762 loss=0.076016 err=0.076016
I 2015-05-26 11:02:29 theanets.trainer:168 RmsProp 1763 loss=0.076629 err=0.076629
I 2015-05-26 11:02:35 theanets.trainer:168 RmsProp 1764 loss=0.064097 err=0.064097
I 2015-05-26 11:02:40 theanets.trainer:168 RmsProp 1765 loss=0.068906 err=0.068906
I 2015-05-26 11:02:45 theanets.trainer:168 RmsProp 1766 loss=0.063820 err=0.063820
I 2015-05-26 11:02:50 theanets.trainer:168 RmsProp 1767 loss=0.081923 err=0.081923
I 2015-05-26 11:02:55 theanets.trainer:168 RmsProp 1768 loss=0.067078 err=0.067078
I 2015-05-26 11:03:00 theanets.trainer:168 RmsProp 1769 loss=0.069679 err=0.069679
I 2015-05-26 11:03:06 theanets.trainer:168 RmsProp 1770 loss=0.063083 err=0.063083
I 2015-05-26 11:03:06 theanets.trainer:168 validation 177 loss=1607.896484 err=1607.896484 *
I 2015-05-26 11:03:11 theanets.trainer:168 RmsProp 1771 loss=0.069250 err=0.069250
I 2015-05-26 11:03:16 theanets.trainer:168 RmsProp 1772 loss=0.063841 err=0.063841
I 2015-05-26 11:03:21 theanets.trainer:168 RmsProp 1773 loss=0.070462 err=0.070462
I 2015-05-26 11:03:26 theanets.trainer:168 RmsProp 1774 loss=0.070192 err=0.070192
I 2015-05-26 11:03:31 theanets.trainer:168 RmsProp 1775 loss=0.070607 err=0.070607
I 2015-05-26 11:03:37 theanets.trainer:168 RmsProp 1776 loss=0.075750 err=0.075750
I 2015-05-26 11:03:42 theanets.trainer:168 RmsProp 1777 loss=0.068040 err=0.068040
I 2015-05-26 11:03:47 theanets.trainer:168 RmsProp 1778 loss=0.062447 err=0.062447
I 2015-05-26 11:03:52 theanets.trainer:168 RmsProp 1779 loss=0.070058 err=0.070058
I 2015-05-26 11:03:57 theanets.trainer:168 RmsProp 1780 loss=0.063497 err=0.063497
I 2015-05-26 11:03:58 theanets.trainer:168 validation 178 loss=1607.261108 err=1607.261108 *
I 2015-05-26 11:04:02 theanets.trainer:168 RmsProp 1781 loss=0.071102 err=0.071102
I 2015-05-26 11:04:07 theanets.trainer:168 RmsProp 1782 loss=0.067775 err=0.067775
I 2015-05-26 11:04:13 theanets.trainer:168 RmsProp 1783 loss=0.070118 err=0.070118
I 2015-05-26 11:04:18 theanets.trainer:168 RmsProp 1784 loss=0.074433 err=0.074433
I 2015-05-26 11:04:23 theanets.trainer:168 RmsProp 1785 loss=0.071695 err=0.071695
I 2015-05-26 11:04:28 theanets.trainer:168 RmsProp 1786 loss=0.074468 err=0.074468
I 2015-05-26 11:04:33 theanets.trainer:168 RmsProp 1787 loss=0.068502 err=0.068502
I 2015-05-26 11:04:39 theanets.trainer:168 RmsProp 1788 loss=0.065444 err=0.065444
I 2015-05-26 11:04:44 theanets.trainer:168 RmsProp 1789 loss=0.065520 err=0.065520
I 2015-05-26 11:04:49 theanets.trainer:168 RmsProp 1790 loss=0.084267 err=0.084267
I 2015-05-26 11:04:49 theanets.trainer:168 validation 179 loss=1608.338257 err=1608.338257
I 2015-05-26 11:04:53 theanets.trainer:168 RmsProp 1791 loss=0.068327 err=0.068327
I 2015-05-26 11:04:57 theanets.trainer:168 RmsProp 1792 loss=0.062356 err=0.062356
I 2015-05-26 11:05:01 theanets.trainer:168 RmsProp 1793 loss=0.071898 err=0.071898
I 2015-05-26 11:05:05 theanets.trainer:168 RmsProp 1794 loss=0.067563 err=0.067563
I 2015-05-26 11:05:09 theanets.trainer:168 RmsProp 1795 loss=0.065086 err=0.065086
I 2015-05-26 11:05:13 theanets.trainer:168 RmsProp 1796 loss=0.068483 err=0.068483
I 2015-05-26 11:05:17 theanets.trainer:168 RmsProp 1797 loss=0.069483 err=0.069483
I 2015-05-26 11:05:21 theanets.trainer:168 RmsProp 1798 loss=0.067919 err=0.067919
I 2015-05-26 11:05:25 theanets.trainer:168 RmsProp 1799 loss=0.064579 err=0.064579
I 2015-05-26 11:05:29 theanets.trainer:168 RmsProp 1800 loss=0.072891 err=0.072891
I 2015-05-26 11:05:29 theanets.trainer:168 validation 180 loss=1605.033813 err=1605.033813 *
I 2015-05-26 11:05:33 theanets.trainer:168 RmsProp 1801 loss=0.075713 err=0.075713
I 2015-05-26 11:05:37 theanets.trainer:168 RmsProp 1802 loss=0.067386 err=0.067386
I 2015-05-26 11:05:41 theanets.trainer:168 RmsProp 1803 loss=0.063573 err=0.063573
I 2015-05-26 11:05:45 theanets.trainer:168 RmsProp 1804 loss=0.068128 err=0.068128
I 2015-05-26 11:05:49 theanets.trainer:168 RmsProp 1805 loss=0.069592 err=0.069592
I 2015-05-26 11:05:53 theanets.trainer:168 RmsProp 1806 loss=0.069567 err=0.069567
I 2015-05-26 11:05:57 theanets.trainer:168 RmsProp 1807 loss=0.061816 err=0.061816
I 2015-05-26 11:06:01 theanets.trainer:168 RmsProp 1808 loss=0.073452 err=0.073452
I 2015-05-26 11:06:05 theanets.trainer:168 RmsProp 1809 loss=0.073180 err=0.073180
I 2015-05-26 11:06:09 theanets.trainer:168 RmsProp 1810 loss=0.063978 err=0.063978
I 2015-05-26 11:06:09 theanets.trainer:168 validation 181 loss=1605.904419 err=1605.904419
I 2015-05-26 11:06:13 theanets.trainer:168 RmsProp 1811 loss=0.074011 err=0.074011
I 2015-05-26 11:06:17 theanets.trainer:168 RmsProp 1812 loss=0.066989 err=0.066989
I 2015-05-26 11:06:21 theanets.trainer:168 RmsProp 1813 loss=0.065047 err=0.065047
I 2015-05-26 11:06:25 theanets.trainer:168 RmsProp 1814 loss=0.072183 err=0.072183
I 2015-05-26 11:06:29 theanets.trainer:168 RmsProp 1815 loss=0.067965 err=0.067965
I 2015-05-26 11:06:33 theanets.trainer:168 RmsProp 1816 loss=0.066727 err=0.066727
I 2015-05-26 11:06:37 theanets.trainer:168 RmsProp 1817 loss=0.065209 err=0.065209
I 2015-05-26 11:06:40 theanets.trainer:168 RmsProp 1818 loss=0.065037 err=0.065037
I 2015-05-26 11:06:44 theanets.trainer:168 RmsProp 1819 loss=0.077251 err=0.077251
I 2015-05-26 11:06:48 theanets.trainer:168 RmsProp 1820 loss=0.069555 err=0.069555
I 2015-05-26 11:06:49 theanets.trainer:168 validation 182 loss=1605.112793 err=1605.112793
I 2015-05-26 11:06:52 theanets.trainer:168 RmsProp 1821 loss=0.065861 err=0.065861
I 2015-05-26 11:06:56 theanets.trainer:168 RmsProp 1822 loss=0.074190 err=0.074190
I 2015-05-26 11:07:01 theanets.trainer:168 RmsProp 1823 loss=0.065674 err=0.065674
I 2015-05-26 11:07:05 theanets.trainer:168 RmsProp 1824 loss=0.072910 err=0.072910
I 2015-05-26 11:07:09 theanets.trainer:168 RmsProp 1825 loss=0.064531 err=0.064531
I 2015-05-26 11:07:13 theanets.trainer:168 RmsProp 1826 loss=0.062988 err=0.062988
I 2015-05-26 11:07:17 theanets.trainer:168 RmsProp 1827 loss=0.063239 err=0.063239
I 2015-05-26 11:07:21 theanets.trainer:168 RmsProp 1828 loss=0.072896 err=0.072896
I 2015-05-26 11:07:25 theanets.trainer:168 RmsProp 1829 loss=0.067600 err=0.067600
I 2015-05-26 11:07:29 theanets.trainer:168 RmsProp 1830 loss=0.063298 err=0.063298
I 2015-05-26 11:07:29 theanets.trainer:168 validation 183 loss=1606.115601 err=1606.115601
I 2015-05-26 11:07:32 theanets.trainer:168 RmsProp 1831 loss=0.067194 err=0.067194
I 2015-05-26 11:07:37 theanets.trainer:168 RmsProp 1832 loss=0.065201 err=0.065201
I 2015-05-26 11:07:41 theanets.trainer:168 RmsProp 1833 loss=0.059564 err=0.059564
I 2015-05-26 11:07:45 theanets.trainer:168 RmsProp 1834 loss=0.077822 err=0.077822
I 2015-05-26 11:07:49 theanets.trainer:168 RmsProp 1835 loss=0.064062 err=0.064062
I 2015-05-26 11:07:53 theanets.trainer:168 RmsProp 1836 loss=0.058991 err=0.058991
I 2015-05-26 11:07:57 theanets.trainer:168 RmsProp 1837 loss=0.073879 err=0.073879
I 2015-05-26 11:08:01 theanets.trainer:168 RmsProp 1838 loss=0.072632 err=0.072632
I 2015-05-26 11:08:05 theanets.trainer:168 RmsProp 1839 loss=0.059511 err=0.059511
I 2015-05-26 11:08:09 theanets.trainer:168 RmsProp 1840 loss=0.072539 err=0.072539
I 2015-05-26 11:08:09 theanets.trainer:168 validation 184 loss=1604.953613 err=1604.953613 *
I 2015-05-26 11:08:12 theanets.trainer:168 RmsProp 1841 loss=0.073003 err=0.073003
I 2015-05-26 11:08:17 theanets.trainer:168 RmsProp 1842 loss=0.078192 err=0.078192
I 2015-05-26 11:08:21 theanets.trainer:168 RmsProp 1843 loss=0.068668 err=0.068668
I 2015-05-26 11:08:25 theanets.trainer:168 RmsProp 1844 loss=0.063979 err=0.063979
I 2015-05-26 11:08:29 theanets.trainer:168 RmsProp 1845 loss=0.073819 err=0.073819
I 2015-05-26 11:08:33 theanets.trainer:168 RmsProp 1846 loss=0.066685 err=0.066685
I 2015-05-26 11:08:37 theanets.trainer:168 RmsProp 1847 loss=0.066403 err=0.066403
I 2015-05-26 11:08:41 theanets.trainer:168 RmsProp 1848 loss=0.065986 err=0.065986
I 2015-05-26 11:08:45 theanets.trainer:168 RmsProp 1849 loss=0.067040 err=0.067040
I 2015-05-26 11:08:49 theanets.trainer:168 RmsProp 1850 loss=0.060833 err=0.060833
I 2015-05-26 11:08:49 theanets.trainer:168 validation 185 loss=1606.577515 err=1606.577515
I 2015-05-26 11:08:53 theanets.trainer:168 RmsProp 1851 loss=0.080215 err=0.080215
I 2015-05-26 11:08:57 theanets.trainer:168 RmsProp 1852 loss=0.068014 err=0.068014
I 2015-05-26 11:09:01 theanets.trainer:168 RmsProp 1853 loss=0.061598 err=0.061598
I 2015-05-26 11:09:05 theanets.trainer:168 RmsProp 1854 loss=0.067328 err=0.067328
I 2015-05-26 11:09:09 theanets.trainer:168 RmsProp 1855 loss=0.067572 err=0.067572
I 2015-05-26 11:09:13 theanets.trainer:168 RmsProp 1856 loss=0.065738 err=0.065738
I 2015-05-26 11:09:17 theanets.trainer:168 RmsProp 1857 loss=0.063839 err=0.063839
I 2015-05-26 11:09:21 theanets.trainer:168 RmsProp 1858 loss=0.076291 err=0.076291
I 2015-05-26 11:09:25 theanets.trainer:168 RmsProp 1859 loss=0.065928 err=0.065928
I 2015-05-26 11:09:29 theanets.trainer:168 RmsProp 1860 loss=0.061659 err=0.061659
I 2015-05-26 11:09:29 theanets.trainer:168 validation 186 loss=1603.657593 err=1603.657593 *
I 2015-05-26 11:09:33 theanets.trainer:168 RmsProp 1861 loss=0.066719 err=0.066719
I 2015-05-26 11:09:37 theanets.trainer:168 RmsProp 1862 loss=0.062958 err=0.062958
I 2015-05-26 11:09:41 theanets.trainer:168 RmsProp 1863 loss=0.069200 err=0.069200
I 2015-05-26 11:09:45 theanets.trainer:168 RmsProp 1864 loss=0.064164 err=0.064164
I 2015-05-26 11:09:49 theanets.trainer:168 RmsProp 1865 loss=0.067517 err=0.067517
I 2015-05-26 11:09:53 theanets.trainer:168 RmsProp 1866 loss=0.065628 err=0.065628
I 2015-05-26 11:09:57 theanets.trainer:168 RmsProp 1867 loss=0.069877 err=0.069877
I 2015-05-26 11:10:01 theanets.trainer:168 RmsProp 1868 loss=0.066107 err=0.066107
I 2015-05-26 11:10:05 theanets.trainer:168 RmsProp 1869 loss=0.062628 err=0.062628
I 2015-05-26 11:10:09 theanets.trainer:168 RmsProp 1870 loss=0.063688 err=0.063688
I 2015-05-26 11:10:09 theanets.trainer:168 validation 187 loss=1603.411499 err=1603.411499 *
I 2015-05-26 11:10:13 theanets.trainer:168 RmsProp 1871 loss=0.063058 err=0.063058
I 2015-05-26 11:10:17 theanets.trainer:168 RmsProp 1872 loss=0.070440 err=0.070440
I 2015-05-26 11:10:21 theanets.trainer:168 RmsProp 1873 loss=0.061397 err=0.061397
I 2015-05-26 11:10:25 theanets.trainer:168 RmsProp 1874 loss=0.066560 err=0.066560
I 2015-05-26 11:10:29 theanets.trainer:168 RmsProp 1875 loss=0.062876 err=0.062876
I 2015-05-26 11:10:33 theanets.trainer:168 RmsProp 1876 loss=0.061693 err=0.061693
I 2015-05-26 11:10:37 theanets.trainer:168 RmsProp 1877 loss=0.093169 err=0.093169
I 2015-05-26 11:10:41 theanets.trainer:168 RmsProp 1878 loss=0.072037 err=0.072037
I 2015-05-26 11:10:45 theanets.trainer:168 RmsProp 1879 loss=0.054513 err=0.054513
I 2015-05-26 11:10:49 theanets.trainer:168 RmsProp 1880 loss=0.073436 err=0.073436
I 2015-05-26 11:10:49 theanets.trainer:168 validation 188 loss=1600.164917 err=1600.164917 *
I 2015-05-26 11:10:53 theanets.trainer:168 RmsProp 1881 loss=0.066837 err=0.066837
I 2015-05-26 11:10:57 theanets.trainer:168 RmsProp 1882 loss=0.062170 err=0.062170
I 2015-05-26 11:11:01 theanets.trainer:168 RmsProp 1883 loss=0.068676 err=0.068676
I 2015-05-26 11:11:05 theanets.trainer:168 RmsProp 1884 loss=0.066123 err=0.066123
I 2015-05-26 11:11:09 theanets.trainer:168 RmsProp 1885 loss=0.062808 err=0.062808
I 2015-05-26 11:11:13 theanets.trainer:168 RmsProp 1886 loss=0.066325 err=0.066325
I 2015-05-26 11:11:17 theanets.trainer:168 RmsProp 1887 loss=0.064766 err=0.064766
I 2015-05-26 11:11:21 theanets.trainer:168 RmsProp 1888 loss=0.064404 err=0.064404
I 2015-05-26 11:11:25 theanets.trainer:168 RmsProp 1889 loss=0.068441 err=0.068441
I 2015-05-26 11:11:29 theanets.trainer:168 RmsProp 1890 loss=0.061594 err=0.061594
I 2015-05-26 11:11:29 theanets.trainer:168 validation 189 loss=1602.864380 err=1602.864380
I 2015-05-26 11:11:33 theanets.trainer:168 RmsProp 1891 loss=0.065907 err=0.065907
I 2015-05-26 11:11:37 theanets.trainer:168 RmsProp 1892 loss=0.069269 err=0.069269
I 2015-05-26 11:11:41 theanets.trainer:168 RmsProp 1893 loss=0.060506 err=0.060506
I 2015-05-26 11:11:45 theanets.trainer:168 RmsProp 1894 loss=0.066962 err=0.066962
I 2015-05-26 11:11:49 theanets.trainer:168 RmsProp 1895 loss=0.065534 err=0.065534
I 2015-05-26 11:11:53 theanets.trainer:168 RmsProp 1896 loss=0.074544 err=0.074544
I 2015-05-26 11:11:57 theanets.trainer:168 RmsProp 1897 loss=0.066541 err=0.066541
I 2015-05-26 11:12:01 theanets.trainer:168 RmsProp 1898 loss=0.062356 err=0.062356
I 2015-05-26 11:12:05 theanets.trainer:168 RmsProp 1899 loss=0.068965 err=0.068965
I 2015-05-26 11:12:09 theanets.trainer:168 RmsProp 1900 loss=0.061796 err=0.061796
I 2015-05-26 11:12:09 theanets.trainer:168 validation 190 loss=1600.810547 err=1600.810547
I 2015-05-26 11:12:12 theanets.trainer:168 RmsProp 1901 loss=0.059886 err=0.059886
I 2015-05-26 11:12:17 theanets.trainer:168 RmsProp 1902 loss=0.065641 err=0.065641
I 2015-05-26 11:12:21 theanets.trainer:168 RmsProp 1903 loss=0.063521 err=0.063521
I 2015-05-26 11:12:25 theanets.trainer:168 RmsProp 1904 loss=0.066793 err=0.066793
I 2015-05-26 11:12:29 theanets.trainer:168 RmsProp 1905 loss=0.066031 err=0.066031
I 2015-05-26 11:12:33 theanets.trainer:168 RmsProp 1906 loss=0.066766 err=0.066766
I 2015-05-26 11:12:37 theanets.trainer:168 RmsProp 1907 loss=0.062381 err=0.062381
I 2015-05-26 11:12:41 theanets.trainer:168 RmsProp 1908 loss=0.063154 err=0.063154
I 2015-05-26 11:12:45 theanets.trainer:168 RmsProp 1909 loss=0.062608 err=0.062608
I 2015-05-26 11:12:49 theanets.trainer:168 RmsProp 1910 loss=0.062659 err=0.062659
I 2015-05-26 11:12:49 theanets.trainer:168 validation 191 loss=1600.564819 err=1600.564819
I 2015-05-26 11:12:52 theanets.trainer:168 RmsProp 1911 loss=0.063795 err=0.063795
I 2015-05-26 11:12:56 theanets.trainer:168 RmsProp 1912 loss=0.065225 err=0.065225
I 2015-05-26 11:13:01 theanets.trainer:168 RmsProp 1913 loss=0.061107 err=0.061107
I 2015-05-26 11:13:05 theanets.trainer:168 RmsProp 1914 loss=0.062536 err=0.062536
I 2015-05-26 11:13:09 theanets.trainer:168 RmsProp 1915 loss=0.069103 err=0.069103
I 2015-05-26 11:13:13 theanets.trainer:168 RmsProp 1916 loss=0.067004 err=0.067004
I 2015-05-26 11:13:17 theanets.trainer:168 RmsProp 1917 loss=0.063507 err=0.063507
I 2015-05-26 11:13:20 theanets.trainer:168 RmsProp 1918 loss=0.071767 err=0.071767
I 2015-05-26 11:13:24 theanets.trainer:168 RmsProp 1919 loss=0.060331 err=0.060331
I 2015-05-26 11:13:28 theanets.trainer:168 RmsProp 1920 loss=0.066508 err=0.066508
I 2015-05-26 11:13:29 theanets.trainer:168 validation 192 loss=1602.410034 err=1602.410034
I 2015-05-26 11:13:32 theanets.trainer:168 RmsProp 1921 loss=0.082498 err=0.082498
I 2015-05-26 11:13:36 theanets.trainer:168 RmsProp 1922 loss=0.062395 err=0.062395
I 2015-05-26 11:13:40 theanets.trainer:168 RmsProp 1923 loss=0.060267 err=0.060267
I 2015-05-26 11:13:44 theanets.trainer:168 RmsProp 1924 loss=0.063434 err=0.063434
I 2015-05-26 11:13:48 theanets.trainer:168 RmsProp 1925 loss=0.075160 err=0.075160
I 2015-05-26 11:13:53 theanets.trainer:168 RmsProp 1926 loss=0.057213 err=0.057213
I 2015-05-26 11:13:56 theanets.trainer:168 RmsProp 1927 loss=0.068970 err=0.068970
I 2015-05-26 11:14:00 theanets.trainer:168 RmsProp 1928 loss=0.063437 err=0.063437
I 2015-05-26 11:14:04 theanets.trainer:168 RmsProp 1929 loss=0.063487 err=0.063487
I 2015-05-26 11:14:08 theanets.trainer:168 RmsProp 1930 loss=0.059669 err=0.059669
I 2015-05-26 11:14:08 theanets.trainer:168 validation 193 loss=1601.173218 err=1601.173218
I 2015-05-26 11:14:08 theanets.trainer:252 patience elapsed!
I 2015-05-26 11:14:08 theanets.main:237 models_deep_post_code_sep/95111-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saving model
I 2015-05-26 11:14:08 theanets.graph:477 models_deep_post_code_sep/95111-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saved model parameters
