I 2015-05-26 22:05:11 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 22:05:11 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 22:05:11 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95123-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl
I 2015-05-26 22:05:11 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 22:05:11 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 22:05:11 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 22:05:11 theanets.main:89 --batch_size = 1024
I 2015-05-26 22:05:11 theanets.main:89 --gradient_clip = 1
I 2015-05-26 22:05:11 theanets.main:89 --hidden_l1 = None
I 2015-05-26 22:05:11 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 22:05:11 theanets.main:89 --train_batches = 30
I 2015-05-26 22:05:11 theanets.main:89 --valid_batches = 3
I 2015-05-26 22:05:11 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 22:05:11 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 22:05:11 theanets.trainer:134 compiling evaluation function
I 2015-05-26 22:05:29 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 22:08:17 theanets.trainer:168 validation 0 loss=14404.304688 err=14161.981445 *
I 2015-05-26 22:08:49 theanets.trainer:168 RmsProp 1 loss=13232.534180 err=13138.285156
I 2015-05-26 22:09:25 theanets.trainer:168 RmsProp 2 loss=13162.911133 err=13144.076172
I 2015-05-26 22:10:02 theanets.trainer:168 RmsProp 3 loss=13135.016602 err=13122.864258
I 2015-05-26 22:10:39 theanets.trainer:168 RmsProp 4 loss=13043.220703 err=13019.026367
I 2015-05-26 22:11:16 theanets.trainer:168 RmsProp 5 loss=12026.261719 err=11974.752930
I 2015-05-26 22:11:53 theanets.trainer:168 RmsProp 6 loss=10910.196289 err=10832.169922
I 2015-05-26 22:12:29 theanets.trainer:168 RmsProp 7 loss=10320.181641 err=10230.006836
I 2015-05-26 22:13:06 theanets.trainer:168 RmsProp 8 loss=9717.259766 err=9618.782227
I 2015-05-26 22:13:43 theanets.trainer:168 RmsProp 9 loss=9274.597656 err=9164.911133
I 2015-05-26 22:14:21 theanets.trainer:168 RmsProp 10 loss=8739.113281 err=8614.229492
I 2015-05-26 22:14:22 theanets.trainer:168 validation 1 loss=9036.961914 err=8903.682617 *
I 2015-05-26 22:14:59 theanets.trainer:168 RmsProp 11 loss=8668.319336 err=8528.063477
I 2015-05-26 22:15:37 theanets.trainer:168 RmsProp 12 loss=8422.503906 err=8267.485352
I 2015-05-26 22:16:14 theanets.trainer:168 RmsProp 13 loss=8189.927246 err=8020.731934
I 2015-05-26 22:16:52 theanets.trainer:168 RmsProp 14 loss=7896.225098 err=7712.027832
I 2015-05-26 22:17:29 theanets.trainer:168 RmsProp 15 loss=7521.414551 err=7314.437500
I 2015-05-26 22:18:06 theanets.trainer:168 RmsProp 16 loss=7376.354980 err=7151.065918
I 2015-05-26 22:18:42 theanets.trainer:168 RmsProp 17 loss=7220.115723 err=6977.834473
I 2015-05-26 22:19:19 theanets.trainer:168 RmsProp 18 loss=6985.208496 err=6731.160645
I 2015-05-26 22:19:56 theanets.trainer:168 RmsProp 19 loss=6739.360352 err=6471.150391
I 2015-05-26 22:20:33 theanets.trainer:168 RmsProp 20 loss=6440.647461 err=6160.030762
I 2015-05-26 22:20:34 theanets.trainer:168 validation 2 loss=6227.878418 err=5940.526855 *
I 2015-05-26 22:21:11 theanets.trainer:168 RmsProp 21 loss=6068.573730 err=5774.103516
I 2015-05-26 22:21:47 theanets.trainer:168 RmsProp 22 loss=5670.533203 err=5356.852051
I 2015-05-26 22:22:24 theanets.trainer:168 RmsProp 23 loss=5238.437500 err=4910.955078
I 2015-05-26 22:23:01 theanets.trainer:168 RmsProp 24 loss=5020.474121 err=4680.819824
I 2015-05-26 22:23:38 theanets.trainer:168 RmsProp 25 loss=4768.624023 err=4416.745117
I 2015-05-26 22:24:14 theanets.trainer:168 RmsProp 26 loss=4647.436035 err=4281.166016
I 2015-05-26 22:24:51 theanets.trainer:168 RmsProp 27 loss=4470.858398 err=4093.398438
I 2015-05-26 22:25:28 theanets.trainer:168 RmsProp 28 loss=4326.332031 err=3935.933838
I 2015-05-26 22:26:05 theanets.trainer:168 RmsProp 29 loss=4234.087402 err=3830.525879
I 2015-05-26 22:26:42 theanets.trainer:168 RmsProp 30 loss=4074.601562 err=3661.936035
I 2015-05-26 22:26:43 theanets.trainer:168 validation 3 loss=3705.924561 err=3289.910889 *
I 2015-05-26 22:27:20 theanets.trainer:168 RmsProp 31 loss=3951.910156 err=3531.396240
I 2015-05-26 22:27:56 theanets.trainer:168 RmsProp 32 loss=3825.327148 err=3394.794434
I 2015-05-26 22:28:34 theanets.trainer:168 RmsProp 33 loss=3695.415283 err=3255.862793
I 2015-05-26 22:29:12 theanets.trainer:168 RmsProp 34 loss=3592.703125 err=3145.153076
I 2015-05-26 22:29:50 theanets.trainer:168 RmsProp 35 loss=3551.045654 err=3094.555664
I 2015-05-26 22:30:28 theanets.trainer:168 RmsProp 36 loss=3504.743164 err=3037.602051
I 2015-05-26 22:31:06 theanets.trainer:168 RmsProp 37 loss=3437.938477 err=2963.412354
I 2015-05-26 22:31:43 theanets.trainer:168 RmsProp 38 loss=3368.455322 err=2885.682373
I 2015-05-26 22:32:21 theanets.trainer:168 RmsProp 39 loss=3241.208496 err=2752.643799
I 2015-05-26 22:32:58 theanets.trainer:168 RmsProp 40 loss=3179.001709 err=2683.535400
I 2015-05-26 22:32:59 theanets.trainer:168 validation 4 loss=3253.446045 err=2754.484375 *
I 2015-05-26 22:33:36 theanets.trainer:168 RmsProp 41 loss=3084.428223 err=2582.660156
I 2015-05-26 22:34:13 theanets.trainer:168 RmsProp 42 loss=3051.063965 err=2542.863770
I 2015-05-26 22:34:50 theanets.trainer:168 RmsProp 43 loss=3053.274414 err=2536.444336
I 2015-05-26 22:35:27 theanets.trainer:168 RmsProp 44 loss=2941.592285 err=2419.589111
I 2015-05-26 22:36:04 theanets.trainer:168 RmsProp 45 loss=2940.206055 err=2413.464600
I 2015-05-26 22:36:39 theanets.trainer:168 RmsProp 46 loss=2907.208496 err=2373.295654
I 2015-05-26 22:37:16 theanets.trainer:168 RmsProp 47 loss=2840.340332 err=2302.490967
I 2015-05-26 22:37:53 theanets.trainer:168 RmsProp 48 loss=2785.014893 err=2242.398438
I 2015-05-26 22:38:29 theanets.trainer:168 RmsProp 49 loss=2741.754883 err=2194.864014
I 2015-05-26 22:39:06 theanets.trainer:168 RmsProp 50 loss=2708.636475 err=2158.324951
I 2015-05-26 22:39:07 theanets.trainer:168 validation 5 loss=2945.932861 err=2393.761719 *
I 2015-05-26 22:39:43 theanets.trainer:168 RmsProp 51 loss=2670.948730 err=2116.416260
I 2015-05-26 22:40:19 theanets.trainer:168 RmsProp 52 loss=2623.169434 err=2063.226074
I 2015-05-26 22:40:56 theanets.trainer:168 RmsProp 53 loss=2592.792969 err=2028.310547
I 2015-05-26 22:41:32 theanets.trainer:168 RmsProp 54 loss=2583.292969 err=2014.492188
I 2015-05-26 22:42:08 theanets.trainer:168 RmsProp 55 loss=2574.046875 err=1996.994507
I 2015-05-26 22:42:45 theanets.trainer:168 RmsProp 56 loss=2538.599121 err=1958.076782
I 2015-05-26 22:43:22 theanets.trainer:168 RmsProp 57 loss=2556.788086 err=1967.840332
I 2015-05-26 22:43:59 theanets.trainer:168 RmsProp 58 loss=2474.706787 err=1882.180054
I 2015-05-26 22:44:36 theanets.trainer:168 RmsProp 59 loss=2414.503174 err=1822.511108
I 2015-05-26 22:45:14 theanets.trainer:168 RmsProp 60 loss=2391.803223 err=1797.883667
I 2015-05-26 22:45:15 theanets.trainer:168 validation 6 loss=2935.415283 err=2340.154297 *
I 2015-05-26 22:45:52 theanets.trainer:168 RmsProp 61 loss=2350.050049 err=1754.284912
I 2015-05-26 22:46:28 theanets.trainer:168 RmsProp 62 loss=2346.481934 err=1747.803833
I 2015-05-26 22:47:04 theanets.trainer:168 RmsProp 63 loss=2333.952637 err=1730.031494
I 2015-05-26 22:47:41 theanets.trainer:168 RmsProp 64 loss=2322.339111 err=1714.327637
I 2015-05-26 22:48:17 theanets.trainer:168 RmsProp 65 loss=2289.800049 err=1677.064697
I 2015-05-26 22:48:54 theanets.trainer:168 RmsProp 66 loss=2238.461670 err=1623.659668
I 2015-05-26 22:49:30 theanets.trainer:168 RmsProp 67 loss=2213.332764 err=1597.899048
I 2015-05-26 22:50:06 theanets.trainer:168 RmsProp 68 loss=2187.066162 err=1570.828857
I 2015-05-26 22:50:43 theanets.trainer:168 RmsProp 69 loss=2158.513916 err=1541.519775
I 2015-05-26 22:51:21 theanets.trainer:168 RmsProp 70 loss=2148.537354 err=1530.171753
I 2015-05-26 22:51:22 theanets.trainer:168 validation 7 loss=2950.032471 err=2330.760986
I 2015-05-26 22:51:58 theanets.trainer:168 RmsProp 71 loss=2131.246094 err=1511.447632
I 2015-05-26 22:52:35 theanets.trainer:168 RmsProp 72 loss=2097.917969 err=1476.913574
I 2015-05-26 22:53:12 theanets.trainer:168 RmsProp 73 loss=2089.202148 err=1466.686157
I 2015-05-26 22:53:50 theanets.trainer:168 RmsProp 74 loss=2095.218506 err=1471.780762
I 2015-05-26 22:54:29 theanets.trainer:168 RmsProp 75 loss=2063.987549 err=1439.103394
I 2015-05-26 22:55:06 theanets.trainer:168 RmsProp 76 loss=2023.503174 err=1398.362183
I 2015-05-26 22:55:43 theanets.trainer:168 RmsProp 77 loss=1996.059692 err=1370.268921
I 2015-05-26 22:56:20 theanets.trainer:168 RmsProp 78 loss=2008.747925 err=1380.753662
I 2015-05-26 22:56:57 theanets.trainer:168 RmsProp 79 loss=1973.526855 err=1344.250732
I 2015-05-26 22:57:35 theanets.trainer:168 RmsProp 80 loss=1983.270020 err=1353.289795
I 2015-05-26 22:57:36 theanets.trainer:168 validation 8 loss=2763.347900 err=2131.862305 *
I 2015-05-26 22:58:14 theanets.trainer:168 RmsProp 81 loss=1955.464844 err=1323.063232
I 2015-05-26 22:58:51 theanets.trainer:168 RmsProp 82 loss=1960.728271 err=1327.088989
I 2015-05-26 22:59:28 theanets.trainer:168 RmsProp 83 loss=1943.512573 err=1306.475952
I 2015-05-26 23:00:03 theanets.trainer:168 RmsProp 84 loss=1916.942505 err=1279.884766
I 2015-05-26 23:00:39 theanets.trainer:168 RmsProp 85 loss=1907.989624 err=1270.122559
I 2015-05-26 23:01:16 theanets.trainer:168 RmsProp 86 loss=1887.992188 err=1248.032593
I 2015-05-26 23:01:54 theanets.trainer:168 RmsProp 87 loss=1863.182007 err=1223.808350
I 2015-05-26 23:02:31 theanets.trainer:168 RmsProp 88 loss=1845.870728 err=1206.733643
I 2015-05-26 23:03:08 theanets.trainer:168 RmsProp 89 loss=1840.832520 err=1199.721436
I 2015-05-26 23:03:46 theanets.trainer:168 RmsProp 90 loss=1841.982666 err=1199.527832
I 2015-05-26 23:03:47 theanets.trainer:168 validation 9 loss=2728.842041 err=2086.525879 *
I 2015-05-26 23:04:24 theanets.trainer:168 RmsProp 91 loss=1821.991943 err=1179.504028
I 2015-05-26 23:05:00 theanets.trainer:168 RmsProp 92 loss=1829.981079 err=1184.227905
I 2015-05-26 23:05:37 theanets.trainer:168 RmsProp 93 loss=1817.181885 err=1170.945557
I 2015-05-26 23:06:13 theanets.trainer:168 RmsProp 94 loss=1805.104858 err=1157.547119
I 2015-05-26 23:06:49 theanets.trainer:168 RmsProp 95 loss=1802.028442 err=1153.820435
I 2015-05-26 23:07:27 theanets.trainer:168 RmsProp 96 loss=1787.095703 err=1136.916870
I 2015-05-26 23:08:04 theanets.trainer:168 RmsProp 97 loss=1778.519165 err=1127.762085
I 2015-05-26 23:08:42 theanets.trainer:168 RmsProp 98 loss=1760.309814 err=1108.726807
I 2015-05-26 23:09:20 theanets.trainer:168 RmsProp 99 loss=1738.932739 err=1087.007202
I 2015-05-26 23:09:57 theanets.trainer:168 RmsProp 100 loss=1740.472168 err=1088.363403
I 2015-05-26 23:09:58 theanets.trainer:168 validation 10 loss=2718.250732 err=2066.411865 *
I 2015-05-26 23:10:34 theanets.trainer:168 RmsProp 101 loss=1714.679810 err=1062.535034
I 2015-05-26 23:11:10 theanets.trainer:168 RmsProp 102 loss=1695.015869 err=1042.644653
I 2015-05-26 23:11:45 theanets.trainer:168 RmsProp 103 loss=1710.891357 err=1057.588623
I 2015-05-26 23:12:21 theanets.trainer:168 RmsProp 104 loss=1682.917236 err=1028.498779
I 2015-05-26 23:12:58 theanets.trainer:168 RmsProp 105 loss=1678.222778 err=1023.744446
I 2015-05-26 23:13:34 theanets.trainer:168 RmsProp 106 loss=1661.439209 err=1006.813538
I 2015-05-26 23:14:11 theanets.trainer:168 RmsProp 107 loss=1653.590698 err=998.640869
I 2015-05-26 23:14:49 theanets.trainer:168 RmsProp 108 loss=1660.111572 err=1003.508911
I 2015-05-26 23:15:26 theanets.trainer:168 RmsProp 109 loss=1647.320557 err=990.600220
I 2015-05-26 23:16:04 theanets.trainer:168 RmsProp 110 loss=1636.266235 err=980.269714
I 2015-05-26 23:16:04 theanets.trainer:168 validation 11 loss=2652.167480 err=1996.696899 *
I 2015-05-26 23:16:41 theanets.trainer:168 RmsProp 111 loss=1607.270386 err=952.279846
I 2015-05-26 23:17:17 theanets.trainer:168 RmsProp 112 loss=1610.700684 err=955.966003
I 2015-05-26 23:17:53 theanets.trainer:168 RmsProp 113 loss=1599.585571 err=944.386047
I 2015-05-26 23:18:29 theanets.trainer:168 RmsProp 114 loss=1597.818604 err=942.238647
I 2015-05-26 23:19:04 theanets.trainer:168 RmsProp 115 loss=1581.415405 err=925.554077
I 2015-05-26 23:19:39 theanets.trainer:168 RmsProp 116 loss=1587.931274 err=931.599365
I 2015-05-26 23:20:15 theanets.trainer:168 RmsProp 117 loss=1574.187744 err=917.451355
I 2015-05-26 23:20:51 theanets.trainer:168 RmsProp 118 loss=1563.235596 err=906.575012
I 2015-05-26 23:21:26 theanets.trainer:168 RmsProp 119 loss=1554.869995 err=898.535278
I 2015-05-26 23:22:03 theanets.trainer:168 RmsProp 120 loss=1534.997803 err=879.446228
I 2015-05-26 23:22:03 theanets.trainer:168 validation 12 loss=2733.723633 err=2078.529053
I 2015-05-26 23:22:39 theanets.trainer:168 RmsProp 121 loss=1530.234863 err=874.988281
I 2015-05-26 23:23:17 theanets.trainer:168 RmsProp 122 loss=1535.126953 err=879.289917
I 2015-05-26 23:23:54 theanets.trainer:168 RmsProp 123 loss=1509.533203 err=854.051758
I 2015-05-26 23:24:31 theanets.trainer:168 RmsProp 124 loss=1513.075073 err=858.484009
I 2015-05-26 23:25:08 theanets.trainer:168 RmsProp 125 loss=1509.100342 err=853.231750
I 2015-05-26 23:25:44 theanets.trainer:168 RmsProp 126 loss=1507.281006 err=850.941040
I 2015-05-26 23:26:21 theanets.trainer:168 RmsProp 127 loss=1499.318604 err=843.352173
I 2015-05-26 23:26:57 theanets.trainer:168 RmsProp 128 loss=1502.571411 err=846.744934
I 2015-05-26 23:27:34 theanets.trainer:168 RmsProp 129 loss=1495.610229 err=839.061462
I 2015-05-26 23:28:11 theanets.trainer:168 RmsProp 130 loss=1489.108643 err=832.173645
I 2015-05-26 23:28:11 theanets.trainer:168 validation 13 loss=2675.939941 err=2019.047485
I 2015-05-26 23:28:48 theanets.trainer:168 RmsProp 131 loss=1476.461060 err=819.765747
I 2015-05-26 23:29:25 theanets.trainer:168 RmsProp 132 loss=1474.056885 err=816.746704
I 2015-05-26 23:30:02 theanets.trainer:168 RmsProp 133 loss=1463.172241 err=806.134033
I 2015-05-26 23:30:39 theanets.trainer:168 RmsProp 134 loss=1448.968628 err=793.006470
I 2015-05-26 23:31:16 theanets.trainer:168 RmsProp 135 loss=1440.875000 err=785.481018
I 2015-05-26 23:31:52 theanets.trainer:168 RmsProp 136 loss=1446.095703 err=790.078857
I 2015-05-26 23:32:29 theanets.trainer:168 RmsProp 137 loss=1438.831421 err=781.954529
I 2015-05-26 23:33:05 theanets.trainer:168 RmsProp 138 loss=1417.785034 err=761.668579
I 2015-05-26 23:33:41 theanets.trainer:168 RmsProp 139 loss=1415.843750 err=759.970764
I 2015-05-26 23:34:18 theanets.trainer:168 RmsProp 140 loss=1413.498413 err=757.384155
I 2015-05-26 23:34:19 theanets.trainer:168 validation 14 loss=2824.168701 err=2167.133301
I 2015-05-26 23:34:55 theanets.trainer:168 RmsProp 141 loss=1416.726807 err=759.905090
I 2015-05-26 23:35:31 theanets.trainer:168 RmsProp 142 loss=1414.047974 err=756.777588
I 2015-05-26 23:36:07 theanets.trainer:168 RmsProp 143 loss=1399.320312 err=742.160278
I 2015-05-26 23:36:43 theanets.trainer:168 RmsProp 144 loss=1384.962891 err=729.304749
I 2015-05-26 23:37:20 theanets.trainer:168 RmsProp 145 loss=1384.386597 err=728.889465
I 2015-05-26 23:37:57 theanets.trainer:168 RmsProp 146 loss=1376.554565 err=722.219482
I 2015-05-26 23:38:35 theanets.trainer:168 RmsProp 147 loss=1380.450928 err=725.713440
I 2015-05-26 23:39:11 theanets.trainer:168 RmsProp 148 loss=1369.695557 err=715.428894
I 2015-05-26 23:39:47 theanets.trainer:168 RmsProp 149 loss=1359.929932 err=706.584900
I 2015-05-26 23:40:24 theanets.trainer:168 RmsProp 150 loss=1348.646240 err=695.932556
I 2015-05-26 23:40:24 theanets.trainer:168 validation 15 loss=2797.044678 err=2144.624023
I 2015-05-26 23:41:02 theanets.trainer:168 RmsProp 151 loss=1348.478760 err=696.681763
I 2015-05-26 23:41:38 theanets.trainer:168 RmsProp 152 loss=1335.063232 err=684.018921
I 2015-05-26 23:42:16 theanets.trainer:168 RmsProp 153 loss=1343.826294 err=692.244812
I 2015-05-26 23:42:53 theanets.trainer:168 RmsProp 154 loss=1322.739624 err=671.889282
I 2015-05-26 23:43:30 theanets.trainer:168 RmsProp 155 loss=1316.820435 err=666.996277
I 2015-05-26 23:44:07 theanets.trainer:168 RmsProp 156 loss=1324.818726 err=674.955933
I 2015-05-26 23:44:43 theanets.trainer:168 RmsProp 157 loss=1328.600830 err=677.852173
I 2015-05-26 23:45:20 theanets.trainer:168 RmsProp 158 loss=1331.971069 err=681.355225
I 2015-05-26 23:45:57 theanets.trainer:168 RmsProp 159 loss=1315.205444 err=664.129761
I 2015-05-26 23:46:33 theanets.trainer:168 RmsProp 160 loss=1317.651733 err=667.967468
I 2015-05-26 23:46:34 theanets.trainer:168 validation 16 loss=2777.994385 err=2128.582520
I 2015-05-26 23:46:34 theanets.trainer:252 patience elapsed!
I 2015-05-26 23:46:34 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 23:46:34 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 23:46:34 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 23:46:34 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 23:46:34 theanets.main:89 --batch_size = 1024
I 2015-05-26 23:46:34 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 23:46:34 theanets.main:89 --hidden_l1 = None
I 2015-05-26 23:46:34 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 23:46:34 theanets.main:89 --train_batches = 10
I 2015-05-26 23:46:34 theanets.main:89 --valid_batches = 2
I 2015-05-26 23:46:34 theanets.main:89 --weight_l1 = 0.01
I 2015-05-26 23:46:34 theanets.main:89 --weight_l2 = 0.001
I 2015-05-26 23:46:34 theanets.trainer:134 compiling evaluation function
I 2015-05-26 23:46:43 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 23:48:23 theanets.trainer:168 validation 0 loss=2616.738525 err=1961.267944 *
I 2015-05-26 23:48:34 theanets.trainer:168 RmsProp 1 loss=1035.890869 err=384.017059
I 2015-05-26 23:48:44 theanets.trainer:168 RmsProp 2 loss=946.966187 err=298.366852
I 2015-05-26 23:48:55 theanets.trainer:168 RmsProp 3 loss=897.879211 err=251.795410
I 2015-05-26 23:49:06 theanets.trainer:168 RmsProp 4 loss=867.328125 err=223.488861
I 2015-05-26 23:49:17 theanets.trainer:168 RmsProp 5 loss=841.026184 err=199.446686
I 2015-05-26 23:49:28 theanets.trainer:168 RmsProp 6 loss=815.692017 err=176.594482
I 2015-05-26 23:49:39 theanets.trainer:168 RmsProp 7 loss=791.968811 err=155.691406
I 2015-05-26 23:49:50 theanets.trainer:168 RmsProp 8 loss=768.587402 err=135.387756
I 2015-05-26 23:50:01 theanets.trainer:168 RmsProp 9 loss=749.980408 err=120.095360
I 2015-05-26 23:50:12 theanets.trainer:168 RmsProp 10 loss=734.733459 err=108.130783
I 2015-05-26 23:50:13 theanets.trainer:168 validation 1 loss=2356.031250 err=1731.184448 *
I 2015-05-26 23:50:23 theanets.trainer:168 RmsProp 11 loss=719.986694 err=96.562119
I 2015-05-26 23:50:34 theanets.trainer:168 RmsProp 12 loss=711.508911 err=91.333687
I 2015-05-26 23:50:45 theanets.trainer:168 RmsProp 13 loss=699.329346 err=82.573723
I 2015-05-26 23:50:56 theanets.trainer:168 RmsProp 14 loss=691.314148 err=78.020615
I 2015-05-26 23:51:07 theanets.trainer:168 RmsProp 15 loss=682.099487 err=72.381241
I 2015-05-26 23:51:18 theanets.trainer:168 RmsProp 16 loss=673.223389 err=67.225777
I 2015-05-26 23:51:28 theanets.trainer:168 RmsProp 17 loss=666.792786 err=64.413712
I 2015-05-26 23:51:39 theanets.trainer:168 RmsProp 18 loss=658.133606 err=59.185722
I 2015-05-26 23:51:50 theanets.trainer:168 RmsProp 19 loss=652.817444 err=57.341835
I 2015-05-26 23:52:00 theanets.trainer:168 RmsProp 20 loss=646.481323 err=54.502037
I 2015-05-26 23:52:01 theanets.trainer:168 validation 2 loss=2258.552002 err=1668.409790 *
I 2015-05-26 23:52:11 theanets.trainer:168 RmsProp 21 loss=638.657104 err=49.955742
I 2015-05-26 23:52:22 theanets.trainer:168 RmsProp 22 loss=633.408020 err=47.930378
I 2015-05-26 23:52:33 theanets.trainer:168 RmsProp 23 loss=628.905334 err=46.787125
I 2015-05-26 23:52:44 theanets.trainer:168 RmsProp 24 loss=623.203308 err=44.578510
I 2015-05-26 23:52:54 theanets.trainer:168 RmsProp 25 loss=619.124512 err=44.034599
I 2015-05-26 23:53:05 theanets.trainer:168 RmsProp 26 loss=612.491089 err=40.703289
I 2015-05-26 23:53:16 theanets.trainer:168 RmsProp 27 loss=608.099731 err=39.574661
I 2015-05-26 23:53:26 theanets.trainer:168 RmsProp 28 loss=602.038879 err=36.862358
I 2015-05-26 23:53:37 theanets.trainer:168 RmsProp 29 loss=598.066956 err=36.283337
I 2015-05-26 23:53:48 theanets.trainer:168 RmsProp 30 loss=594.803345 err=36.456715
I 2015-05-26 23:53:48 theanets.trainer:168 validation 3 loss=2186.636475 err=1630.092651 *
I 2015-05-26 23:53:59 theanets.trainer:168 RmsProp 31 loss=589.423706 err=34.327934
I 2015-05-26 23:54:10 theanets.trainer:168 RmsProp 32 loss=585.701538 err=33.783195
I 2015-05-26 23:54:21 theanets.trainer:168 RmsProp 33 loss=580.939941 err=32.133118
I 2015-05-26 23:54:32 theanets.trainer:168 RmsProp 34 loss=578.189819 err=32.427460
I 2015-05-26 23:54:43 theanets.trainer:168 RmsProp 35 loss=572.827026 err=30.059982
I 2015-05-26 23:54:54 theanets.trainer:168 RmsProp 36 loss=569.354980 err=29.645687
I 2015-05-26 23:55:05 theanets.trainer:168 RmsProp 37 loss=565.742432 err=29.141270
I 2015-05-26 23:55:16 theanets.trainer:168 RmsProp 38 loss=561.829041 err=28.383280
I 2015-05-26 23:55:27 theanets.trainer:168 RmsProp 39 loss=558.337952 err=27.995224
I 2015-05-26 23:55:38 theanets.trainer:168 RmsProp 40 loss=553.584961 err=26.097647
I 2015-05-26 23:55:39 theanets.trainer:168 validation 4 loss=2141.173828 err=1615.240479 *
I 2015-05-26 23:55:49 theanets.trainer:168 RmsProp 41 loss=550.369446 err=25.753168
I 2015-05-26 23:56:00 theanets.trainer:168 RmsProp 42 loss=547.339905 err=25.698910
I 2015-05-26 23:56:11 theanets.trainer:168 RmsProp 43 loss=543.899536 err=25.221996
I 2015-05-26 23:56:22 theanets.trainer:168 RmsProp 44 loss=539.296326 err=23.495108
I 2015-05-26 23:56:32 theanets.trainer:168 RmsProp 45 loss=536.458618 err=23.578459
I 2015-05-26 23:56:43 theanets.trainer:168 RmsProp 46 loss=532.790222 err=22.847429
I 2015-05-26 23:56:54 theanets.trainer:168 RmsProp 47 loss=529.388062 err=22.283714
I 2015-05-26 23:57:05 theanets.trainer:168 RmsProp 48 loss=525.932495 err=21.614964
I 2015-05-26 23:57:16 theanets.trainer:168 RmsProp 49 loss=523.082336 err=21.580694
I 2015-05-26 23:57:27 theanets.trainer:168 RmsProp 50 loss=520.153503 err=21.435001
I 2015-05-26 23:57:27 theanets.trainer:168 validation 5 loss=2104.447510 err=1607.210205 *
I 2015-05-26 23:57:38 theanets.trainer:168 RmsProp 51 loss=516.816162 err=20.749796
I 2015-05-26 23:57:49 theanets.trainer:168 RmsProp 52 loss=513.254456 err=19.808506
I 2015-05-26 23:57:59 theanets.trainer:168 RmsProp 53 loss=509.940430 err=19.183214
I 2015-05-26 23:58:10 theanets.trainer:168 RmsProp 54 loss=507.487946 err=19.442549
I 2015-05-26 23:58:20 theanets.trainer:168 RmsProp 55 loss=504.160889 err=18.827618
I 2015-05-26 23:58:31 theanets.trainer:168 RmsProp 56 loss=501.694427 err=19.044353
I 2015-05-26 23:58:42 theanets.trainer:168 RmsProp 57 loss=498.463379 err=18.428547
I 2015-05-26 23:58:53 theanets.trainer:168 RmsProp 58 loss=495.704681 err=18.202248
I 2015-05-26 23:59:04 theanets.trainer:168 RmsProp 59 loss=493.048035 err=18.033791
I 2015-05-26 23:59:15 theanets.trainer:168 RmsProp 60 loss=490.121674 err=17.613182
I 2015-05-26 23:59:15 theanets.trainer:168 validation 6 loss=2069.692383 err=1598.537964 *
I 2015-05-26 23:59:26 theanets.trainer:168 RmsProp 61 loss=487.586731 err=17.551683
I 2015-05-26 23:59:37 theanets.trainer:168 RmsProp 62 loss=484.572266 err=16.969166
I 2015-05-26 23:59:48 theanets.trainer:168 RmsProp 63 loss=482.061951 err=16.822887
I 2015-05-26 23:59:59 theanets.trainer:168 RmsProp 64 loss=479.203918 err=16.317787
I 2015-05-27 00:00:10 theanets.trainer:168 RmsProp 65 loss=477.151672 err=16.587534
I 2015-05-27 00:00:21 theanets.trainer:168 RmsProp 66 loss=474.651276 err=16.352839
I 2015-05-27 00:00:32 theanets.trainer:168 RmsProp 67 loss=472.247955 err=16.224529
I 2015-05-27 00:00:43 theanets.trainer:168 RmsProp 68 loss=469.652344 err=15.898811
I 2015-05-27 00:00:54 theanets.trainer:168 RmsProp 69 loss=467.425110 err=15.925158
I 2015-05-27 00:01:05 theanets.trainer:168 RmsProp 70 loss=464.892426 err=15.551417
I 2015-05-27 00:01:06 theanets.trainer:168 validation 7 loss=2037.898926 err=1589.716797 *
I 2015-05-27 00:01:17 theanets.trainer:168 RmsProp 71 loss=462.288757 err=15.054083
I 2015-05-27 00:01:28 theanets.trainer:168 RmsProp 72 loss=459.642090 err=14.559755
I 2015-05-27 00:01:39 theanets.trainer:168 RmsProp 73 loss=457.467346 err=14.593150
I 2015-05-27 00:01:50 theanets.trainer:168 RmsProp 74 loss=455.194397 err=14.501970
I 2015-05-27 00:02:01 theanets.trainer:168 RmsProp 75 loss=453.226868 err=14.644327
I 2015-05-27 00:02:12 theanets.trainer:168 RmsProp 76 loss=450.913177 err=14.396991
I 2015-05-27 00:02:22 theanets.trainer:168 RmsProp 77 loss=448.354736 err=13.907290
I 2015-05-27 00:02:33 theanets.trainer:168 RmsProp 78 loss=446.202393 err=13.804701
I 2015-05-27 00:02:43 theanets.trainer:168 RmsProp 79 loss=444.834076 err=14.469068
I 2015-05-27 00:02:54 theanets.trainer:168 RmsProp 80 loss=442.275635 err=13.883862
I 2015-05-27 00:02:55 theanets.trainer:168 validation 8 loss=2008.210449 err=1580.871582 *
I 2015-05-27 00:03:06 theanets.trainer:168 RmsProp 81 loss=439.951660 err=13.455684
I 2015-05-27 00:03:16 theanets.trainer:168 RmsProp 82 loss=437.719330 err=13.106428
I 2015-05-27 00:03:27 theanets.trainer:168 RmsProp 83 loss=436.369873 err=13.680822
I 2015-05-27 00:03:38 theanets.trainer:168 RmsProp 84 loss=434.147644 err=13.385824
I 2015-05-27 00:03:49 theanets.trainer:168 RmsProp 85 loss=431.847595 err=12.998729
I 2015-05-27 00:04:00 theanets.trainer:168 RmsProp 86 loss=429.606384 err=12.660047
I 2015-05-27 00:04:11 theanets.trainer:168 RmsProp 87 loss=427.705078 err=12.674967
I 2015-05-27 00:04:22 theanets.trainer:168 RmsProp 88 loss=426.449371 err=13.314557
I 2015-05-27 00:04:32 theanets.trainer:168 RmsProp 89 loss=424.392578 err=13.064222
I 2015-05-27 00:04:42 theanets.trainer:168 RmsProp 90 loss=421.549164 err=11.952157
I 2015-05-27 00:04:43 theanets.trainer:168 validation 9 loss=1985.687866 err=1577.031860 *
I 2015-05-27 00:04:54 theanets.trainer:168 RmsProp 91 loss=419.994873 err=12.143202
I 2015-05-27 00:05:04 theanets.trainer:168 RmsProp 92 loss=418.409485 err=12.367395
I 2015-05-27 00:05:15 theanets.trainer:168 RmsProp 93 loss=416.045746 err=11.826259
I 2015-05-27 00:05:25 theanets.trainer:168 RmsProp 94 loss=414.576752 err=12.194567
I 2015-05-27 00:05:36 theanets.trainer:168 RmsProp 95 loss=413.156830 err=12.560440
I 2015-05-27 00:05:47 theanets.trainer:168 RmsProp 96 loss=410.394684 err=11.477746
I 2015-05-27 00:05:57 theanets.trainer:168 RmsProp 97 loss=408.857178 err=11.607821
I 2015-05-27 00:06:08 theanets.trainer:168 RmsProp 98 loss=407.265747 err=11.693785
I 2015-05-27 00:06:18 theanets.trainer:168 RmsProp 99 loss=405.680450 err=11.808737
I 2015-05-27 00:06:29 theanets.trainer:168 RmsProp 100 loss=404.373322 err=12.172103
I 2015-05-27 00:06:30 theanets.trainer:168 validation 10 loss=1958.264771 err=1566.942749 *
I 2015-05-27 00:06:41 theanets.trainer:168 RmsProp 101 loss=401.764465 err=11.151786
I 2015-05-27 00:06:52 theanets.trainer:168 RmsProp 102 loss=400.306549 err=11.289987
I 2015-05-27 00:07:03 theanets.trainer:168 RmsProp 103 loss=398.873871 err=11.485706
I 2015-05-27 00:07:14 theanets.trainer:168 RmsProp 104 loss=397.180603 err=11.416026
I 2015-05-27 00:07:25 theanets.trainer:168 RmsProp 105 loss=395.711029 err=11.539396
I 2015-05-27 00:07:36 theanets.trainer:168 RmsProp 106 loss=393.593689 err=10.954291
I 2015-05-27 00:07:47 theanets.trainer:168 RmsProp 107 loss=391.720276 err=10.574272
I 2015-05-27 00:07:58 theanets.trainer:168 RmsProp 108 loss=390.588531 err=10.938667
I 2015-05-27 00:08:09 theanets.trainer:168 RmsProp 109 loss=388.785767 err=10.646597
I 2015-05-27 00:08:19 theanets.trainer:168 RmsProp 110 loss=387.358582 err=10.736346
I 2015-05-27 00:08:20 theanets.trainer:168 validation 11 loss=1935.871826 err=1560.074219 *
I 2015-05-27 00:08:31 theanets.trainer:168 RmsProp 111 loss=385.491302 err=10.369566
I 2015-05-27 00:08:41 theanets.trainer:168 RmsProp 112 loss=384.293884 err=10.670706
I 2015-05-27 00:08:52 theanets.trainer:168 RmsProp 113 loss=382.448303 err=10.321231
I 2015-05-27 00:09:03 theanets.trainer:168 RmsProp 114 loss=380.745911 err=10.076468
I 2015-05-27 00:09:14 theanets.trainer:168 RmsProp 115 loss=379.741241 err=10.505075
I 2015-05-27 00:09:25 theanets.trainer:168 RmsProp 116 loss=377.748810 err=9.936958
I 2015-05-27 00:09:35 theanets.trainer:168 RmsProp 117 loss=376.434387 err=10.018730
I 2015-05-27 00:09:46 theanets.trainer:168 RmsProp 118 loss=374.912598 err=9.899319
I 2015-05-27 00:09:57 theanets.trainer:168 RmsProp 119 loss=373.199280 err=9.598904
I 2015-05-27 00:10:08 theanets.trainer:168 RmsProp 120 loss=371.997009 err=9.816348
I 2015-05-27 00:10:08 theanets.trainer:168 validation 12 loss=1911.542603 err=1550.146851 *
I 2015-05-27 00:10:19 theanets.trainer:168 RmsProp 121 loss=370.704254 err=9.943815
I 2015-05-27 00:10:30 theanets.trainer:168 RmsProp 122 loss=369.363983 err=10.017984
I 2015-05-27 00:10:40 theanets.trainer:168 RmsProp 123 loss=367.723938 err=9.779110
I 2015-05-27 00:10:51 theanets.trainer:168 RmsProp 124 loss=366.597961 err=10.014408
I 2015-05-27 00:11:01 theanets.trainer:168 RmsProp 125 loss=364.749908 err=9.494266
I 2015-05-27 00:11:12 theanets.trainer:168 RmsProp 126 loss=363.404694 err=9.464162
I 2015-05-27 00:11:22 theanets.trainer:168 RmsProp 127 loss=361.947296 err=9.329714
I 2015-05-27 00:11:32 theanets.trainer:168 RmsProp 128 loss=361.041931 err=9.742928
I 2015-05-27 00:11:43 theanets.trainer:168 RmsProp 129 loss=358.980560 err=8.980969
I 2015-05-27 00:11:53 theanets.trainer:168 RmsProp 130 loss=359.095215 err=10.380820
I 2015-05-27 00:11:54 theanets.trainer:168 validation 13 loss=1891.942627 err=1543.917236 *
I 2015-05-27 00:12:03 theanets.trainer:168 RmsProp 131 loss=356.989807 err=9.504161
I 2015-05-27 00:12:13 theanets.trainer:168 RmsProp 132 loss=355.489532 err=9.197698
I 2015-05-27 00:12:23 theanets.trainer:168 RmsProp 133 loss=354.025543 err=8.948285
I 2015-05-27 00:12:34 theanets.trainer:168 RmsProp 134 loss=353.200623 err=9.356310
I 2015-05-27 00:12:44 theanets.trainer:168 RmsProp 135 loss=351.703308 err=9.081812
I 2015-05-27 00:12:55 theanets.trainer:168 RmsProp 136 loss=350.225647 err=8.817228
I 2015-05-27 00:13:05 theanets.trainer:168 RmsProp 137 loss=349.504822 err=9.320993
I 2015-05-27 00:13:15 theanets.trainer:168 RmsProp 138 loss=347.703644 err=8.722262
I 2015-05-27 00:13:26 theanets.trainer:168 RmsProp 139 loss=346.775269 err=8.988392
I 2015-05-27 00:13:36 theanets.trainer:168 RmsProp 140 loss=345.347595 err=8.734312
I 2015-05-27 00:13:37 theanets.trainer:168 validation 14 loss=1870.746216 err=1534.769897 *
I 2015-05-27 00:13:47 theanets.trainer:168 RmsProp 141 loss=344.432800 err=8.993536
I 2015-05-27 00:13:58 theanets.trainer:168 RmsProp 142 loss=343.344177 err=9.076555
I 2015-05-27 00:14:08 theanets.trainer:168 RmsProp 143 loss=341.718872 err=8.590014
I 2015-05-27 00:14:19 theanets.trainer:168 RmsProp 144 loss=340.181976 err=8.201403
I 2015-05-27 00:14:29 theanets.trainer:168 RmsProp 145 loss=340.277527 err=9.459730
I 2015-05-27 00:14:39 theanets.trainer:168 RmsProp 146 loss=338.461823 err=8.773905
I 2015-05-27 00:14:49 theanets.trainer:168 RmsProp 147 loss=337.355042 err=8.742903
I 2015-05-27 00:15:00 theanets.trainer:168 RmsProp 148 loss=336.512695 err=8.958071
I 2015-05-27 00:15:10 theanets.trainer:168 RmsProp 149 loss=335.163513 err=8.653345
I 2015-05-27 00:15:20 theanets.trainer:168 RmsProp 150 loss=333.671204 err=8.222958
I 2015-05-27 00:15:21 theanets.trainer:168 validation 15 loss=1857.053345 err=1532.197510 *
I 2015-05-27 00:15:31 theanets.trainer:168 RmsProp 151 loss=332.994202 err=8.642355
I 2015-05-27 00:15:41 theanets.trainer:168 RmsProp 152 loss=331.839172 err=8.579476
I 2015-05-27 00:15:51 theanets.trainer:168 RmsProp 153 loss=330.361511 err=8.183649
I 2015-05-27 00:16:01 theanets.trainer:168 RmsProp 154 loss=329.851105 err=8.738822
I 2015-05-27 00:16:11 theanets.trainer:168 RmsProp 155 loss=328.419739 err=8.342305
I 2015-05-27 00:16:21 theanets.trainer:168 RmsProp 156 loss=327.228455 err=8.178700
I 2015-05-27 00:16:32 theanets.trainer:168 RmsProp 157 loss=326.193420 err=8.185903
I 2015-05-27 00:16:42 theanets.trainer:168 RmsProp 158 loss=325.583771 err=8.608546
I 2015-05-27 00:16:52 theanets.trainer:168 RmsProp 159 loss=324.053864 err=8.082262
I 2015-05-27 00:17:02 theanets.trainer:168 RmsProp 160 loss=323.183044 err=8.208549
I 2015-05-27 00:17:03 theanets.trainer:168 validation 16 loss=1840.107910 err=1525.694092 *
I 2015-05-27 00:17:13 theanets.trainer:168 RmsProp 161 loss=322.120636 err=8.153171
I 2015-05-27 00:17:23 theanets.trainer:168 RmsProp 162 loss=320.788147 err=7.820095
I 2015-05-27 00:17:34 theanets.trainer:168 RmsProp 163 loss=320.262817 err=8.296111
I 2015-05-27 00:17:44 theanets.trainer:168 RmsProp 164 loss=319.035278 err=8.053305
I 2015-05-27 00:17:54 theanets.trainer:168 RmsProp 165 loss=317.839539 err=7.826291
I 2015-05-27 00:18:05 theanets.trainer:168 RmsProp 166 loss=317.369568 err=8.329537
I 2015-05-27 00:18:15 theanets.trainer:168 RmsProp 167 loss=316.720337 err=8.636688
I 2015-05-27 00:18:25 theanets.trainer:168 RmsProp 168 loss=314.791199 err=7.621745
I 2015-05-27 00:18:35 theanets.trainer:168 RmsProp 169 loss=314.039154 err=7.772069
I 2015-05-27 00:18:45 theanets.trainer:168 RmsProp 170 loss=313.075500 err=7.738792
I 2015-05-27 00:18:46 theanets.trainer:168 validation 17 loss=1826.515625 err=1521.691406 *
I 2015-05-27 00:18:56 theanets.trainer:168 RmsProp 171 loss=312.172882 err=7.776975
I 2015-05-27 00:19:06 theanets.trainer:168 RmsProp 172 loss=311.025635 err=7.570441
I 2015-05-27 00:19:17 theanets.trainer:168 RmsProp 173 loss=310.564148 err=8.056948
I 2015-05-27 00:19:27 theanets.trainer:168 RmsProp 174 loss=309.936981 err=8.365769
I 2015-05-27 00:19:37 theanets.trainer:168 RmsProp 175 loss=308.102600 err=7.411989
I 2015-05-27 00:19:47 theanets.trainer:168 RmsProp 176 loss=307.479095 err=7.652850
I 2015-05-27 00:19:58 theanets.trainer:168 RmsProp 177 loss=306.717621 err=7.778950
I 2015-05-27 00:20:08 theanets.trainer:168 RmsProp 178 loss=305.866577 err=7.813452
I 2015-05-27 00:20:18 theanets.trainer:168 RmsProp 179 loss=304.393921 err=7.223559
I 2015-05-27 00:20:29 theanets.trainer:168 RmsProp 180 loss=304.273285 err=7.987028
I 2015-05-27 00:20:29 theanets.trainer:168 validation 18 loss=1809.415894 err=1513.607788 *
I 2015-05-27 00:20:40 theanets.trainer:168 RmsProp 181 loss=302.456970 err=7.058656
I 2015-05-27 00:20:50 theanets.trainer:168 RmsProp 182 loss=302.378357 err=7.854838
I 2015-05-27 00:21:01 theanets.trainer:168 RmsProp 183 loss=301.181854 err=7.523923
I 2015-05-27 00:21:11 theanets.trainer:168 RmsProp 184 loss=300.186127 err=7.373229
I 2015-05-27 00:21:21 theanets.trainer:168 RmsProp 185 loss=299.901520 err=7.925892
I 2015-05-27 00:21:32 theanets.trainer:168 RmsProp 186 loss=298.644958 err=7.491224
I 2015-05-27 00:21:42 theanets.trainer:168 RmsProp 187 loss=297.832062 err=7.483641
I 2015-05-27 00:21:52 theanets.trainer:168 RmsProp 188 loss=296.667175 err=7.128314
I 2015-05-27 00:22:03 theanets.trainer:168 RmsProp 189 loss=296.859497 err=8.127784
I 2015-05-27 00:22:13 theanets.trainer:168 RmsProp 190 loss=294.746826 err=6.814271
I 2015-05-27 00:22:14 theanets.trainer:168 validation 19 loss=1797.626587 err=1510.139160 *
I 2015-05-27 00:22:24 theanets.trainer:168 RmsProp 191 loss=294.701172 err=7.559831
I 2015-05-27 00:22:34 theanets.trainer:168 RmsProp 192 loss=293.585297 err=7.231368
I 2015-05-27 00:22:45 theanets.trainer:168 RmsProp 193 loss=292.705872 err=7.143880
I 2015-05-27 00:22:55 theanets.trainer:168 RmsProp 194 loss=291.800385 err=7.038688
I 2015-05-27 00:23:06 theanets.trainer:168 RmsProp 195 loss=291.554504 err=7.591913
I 2015-05-27 00:23:16 theanets.trainer:168 RmsProp 196 loss=290.391205 err=7.209300
I 2015-05-27 00:23:26 theanets.trainer:168 RmsProp 197 loss=289.384308 err=6.968011
I 2015-05-27 00:23:36 theanets.trainer:168 RmsProp 198 loss=289.061340 err=7.408849
I 2015-05-27 00:23:47 theanets.trainer:168 RmsProp 199 loss=287.980438 err=7.088009
I 2015-05-27 00:23:57 theanets.trainer:168 RmsProp 200 loss=287.325073 err=7.188629
I 2015-05-27 00:23:57 theanets.trainer:168 validation 20 loss=1783.715454 err=1503.998413 *
I 2015-05-27 00:24:08 theanets.trainer:168 RmsProp 201 loss=286.645447 err=7.273937
I 2015-05-27 00:24:18 theanets.trainer:168 RmsProp 202 loss=285.855408 err=7.250794
I 2015-05-27 00:24:28 theanets.trainer:168 RmsProp 203 loss=284.666107 err=6.824778
I 2015-05-27 00:24:39 theanets.trainer:168 RmsProp 204 loss=283.857605 err=6.788074
I 2015-05-27 00:24:49 theanets.trainer:168 RmsProp 205 loss=284.052399 err=7.747626
I 2015-05-27 00:24:59 theanets.trainer:168 RmsProp 206 loss=282.224304 err=6.659997
I 2015-05-27 00:25:09 theanets.trainer:168 RmsProp 207 loss=281.598511 err=6.763709
I 2015-05-27 00:25:19 theanets.trainer:168 RmsProp 208 loss=281.315430 err=7.205483
I 2015-05-27 00:25:29 theanets.trainer:168 RmsProp 209 loss=280.160675 err=6.777519
I 2015-05-27 00:25:40 theanets.trainer:168 RmsProp 210 loss=279.596039 err=6.939703
I 2015-05-27 00:25:40 theanets.trainer:168 validation 21 loss=1774.620239 err=1502.356323 *
I 2015-05-27 00:25:50 theanets.trainer:168 RmsProp 211 loss=279.204529 err=7.264190
I 2015-05-27 00:26:01 theanets.trainer:168 RmsProp 212 loss=278.052063 err=6.815835
I 2015-05-27 00:26:11 theanets.trainer:168 RmsProp 213 loss=277.163269 err=6.625730
I 2015-05-27 00:26:21 theanets.trainer:168 RmsProp 214 loss=276.947784 err=7.115015
I 2015-05-27 00:26:31 theanets.trainer:168 RmsProp 215 loss=276.239380 err=7.096349
I 2015-05-27 00:26:41 theanets.trainer:168 RmsProp 216 loss=275.559906 err=7.091540
I 2015-05-27 00:26:51 theanets.trainer:168 RmsProp 217 loss=274.702087 err=6.894764
I 2015-05-27 00:27:01 theanets.trainer:168 RmsProp 218 loss=273.816925 err=6.671695
I 2015-05-27 00:27:10 theanets.trainer:168 RmsProp 219 loss=273.452942 err=6.977278
I 2015-05-27 00:27:20 theanets.trainer:168 RmsProp 220 loss=273.006226 err=7.185333
I 2015-05-27 00:27:21 theanets.trainer:168 validation 22 loss=1764.821777 err=1499.356689 *
I 2015-05-27 00:27:30 theanets.trainer:168 RmsProp 221 loss=271.615326 err=6.438876
I 2015-05-27 00:27:40 theanets.trainer:168 RmsProp 222 loss=271.405212 err=6.871242
I 2015-05-27 00:27:50 theanets.trainer:168 RmsProp 223 loss=270.921692 err=7.033667
I 2015-05-27 00:27:59 theanets.trainer:168 RmsProp 224 loss=269.445862 err=6.208486
I 2015-05-27 00:28:09 theanets.trainer:168 RmsProp 225 loss=269.894196 err=7.297367
I 2015-05-27 00:28:19 theanets.trainer:168 RmsProp 226 loss=268.613220 err=6.659074
I 2015-05-27 00:28:29 theanets.trainer:168 RmsProp 227 loss=267.565338 err=6.244644
I 2015-05-27 00:28:38 theanets.trainer:168 RmsProp 228 loss=267.983734 err=7.296337
I 2015-05-27 00:28:48 theanets.trainer:168 RmsProp 229 loss=266.535889 err=6.481069
I 2015-05-27 00:28:58 theanets.trainer:168 RmsProp 230 loss=266.247162 err=6.817400
I 2015-05-27 00:28:59 theanets.trainer:168 validation 23 loss=1746.900391 err=1487.801392 *
I 2015-05-27 00:29:09 theanets.trainer:168 RmsProp 231 loss=265.975128 err=7.147199
I 2015-05-27 00:29:19 theanets.trainer:168 RmsProp 232 loss=264.564453 err=6.325697
I 2015-05-27 00:29:30 theanets.trainer:168 RmsProp 233 loss=264.216949 err=6.561773
I 2015-05-27 00:29:40 theanets.trainer:168 RmsProp 234 loss=263.680969 err=6.619438
I 2015-05-27 00:29:50 theanets.trainer:168 RmsProp 235 loss=262.761719 err=6.312508
I 2015-05-27 00:30:01 theanets.trainer:168 RmsProp 236 loss=262.486572 err=6.650926
I 2015-05-27 00:30:11 theanets.trainer:168 RmsProp 237 loss=262.198395 err=6.966947
I 2015-05-27 00:30:21 theanets.trainer:168 RmsProp 238 loss=261.186615 err=6.541491
I 2015-05-27 00:30:31 theanets.trainer:168 RmsProp 239 loss=260.462311 err=6.396899
I 2015-05-27 00:30:41 theanets.trainer:168 RmsProp 240 loss=260.029480 err=6.550620
I 2015-05-27 00:30:41 theanets.trainer:168 validation 24 loss=1735.300903 err=1482.140747 *
I 2015-05-27 00:30:51 theanets.trainer:168 RmsProp 241 loss=259.277557 err=6.388393
I 2015-05-27 00:31:02 theanets.trainer:168 RmsProp 242 loss=258.666168 err=6.364199
I 2015-05-27 00:31:12 theanets.trainer:168 RmsProp 243 loss=258.119232 err=6.402211
I 2015-05-27 00:31:22 theanets.trainer:168 RmsProp 244 loss=257.280640 err=6.154684
I 2015-05-27 00:31:32 theanets.trainer:168 RmsProp 245 loss=257.192963 err=6.654376
I 2015-05-27 00:31:42 theanets.trainer:168 RmsProp 246 loss=256.222473 err=6.262628
I 2015-05-27 00:31:52 theanets.trainer:168 RmsProp 247 loss=255.590210 err=6.207102
I 2015-05-27 00:32:03 theanets.trainer:168 RmsProp 248 loss=254.809860 err=6.004847
I 2015-05-27 00:32:13 theanets.trainer:168 RmsProp 249 loss=254.587570 err=6.361461
I 2015-05-27 00:32:23 theanets.trainer:168 RmsProp 250 loss=253.646484 err=6.000781
I 2015-05-27 00:32:23 theanets.trainer:168 validation 25 loss=1730.432983 err=1483.098022 *
I 2015-05-27 00:32:34 theanets.trainer:168 RmsProp 251 loss=253.691376 err=6.614314
I 2015-05-27 00:32:44 theanets.trainer:168 RmsProp 252 loss=252.779755 err=6.257257
I 2015-05-27 00:32:54 theanets.trainer:168 RmsProp 253 loss=251.932526 err=5.964976
I 2015-05-27 00:33:05 theanets.trainer:168 RmsProp 254 loss=251.670319 err=6.256251
I 2015-05-27 00:33:15 theanets.trainer:168 RmsProp 255 loss=250.964142 err=6.101579
I 2015-05-27 00:33:25 theanets.trainer:168 RmsProp 256 loss=250.326614 err=6.016041
I 2015-05-27 00:33:36 theanets.trainer:168 RmsProp 257 loss=250.293823 err=6.525964
I 2015-05-27 00:33:46 theanets.trainer:168 RmsProp 258 loss=249.547729 err=6.315047
I 2015-05-27 00:33:57 theanets.trainer:168 RmsProp 259 loss=248.997040 err=6.290613
I 2015-05-27 00:34:07 theanets.trainer:168 RmsProp 260 loss=248.246140 err=6.062510
I 2015-05-27 00:34:07 theanets.trainer:168 validation 26 loss=1712.308594 err=1470.421509 *
I 2015-05-27 00:34:18 theanets.trainer:168 RmsProp 261 loss=247.799896 err=6.142491
I 2015-05-27 00:34:28 theanets.trainer:168 RmsProp 262 loss=246.997223 err=5.866385
I 2015-05-27 00:34:39 theanets.trainer:168 RmsProp 263 loss=246.897614 err=6.293507
I 2015-05-27 00:34:49 theanets.trainer:168 RmsProp 264 loss=246.171219 err=6.087619
I 2015-05-27 00:34:59 theanets.trainer:168 RmsProp 265 loss=245.588821 err=6.021571
I 2015-05-27 00:35:10 theanets.trainer:168 RmsProp 266 loss=245.625000 err=6.564126
I 2015-05-27 00:35:20 theanets.trainer:168 RmsProp 267 loss=244.394531 err=5.837525
I 2015-05-27 00:35:30 theanets.trainer:168 RmsProp 268 loss=244.208496 err=6.152356
I 2015-05-27 00:35:41 theanets.trainer:168 RmsProp 269 loss=243.642792 err=6.088895
I 2015-05-27 00:35:51 theanets.trainer:168 RmsProp 270 loss=243.226227 err=6.178811
I 2015-05-27 00:35:52 theanets.trainer:168 validation 27 loss=1708.110840 err=1471.325073 *
I 2015-05-27 00:36:02 theanets.trainer:168 RmsProp 271 loss=242.620941 err=6.066066
I 2015-05-27 00:36:12 theanets.trainer:168 RmsProp 272 loss=242.160324 err=6.093283
I 2015-05-27 00:36:22 theanets.trainer:168 RmsProp 273 loss=241.823364 err=6.230467
I 2015-05-27 00:36:32 theanets.trainer:168 RmsProp 274 loss=240.557495 err=5.447778
I 2015-05-27 00:36:42 theanets.trainer:168 RmsProp 275 loss=241.837326 err=7.208014
I 2015-05-27 00:36:53 theanets.trainer:168 RmsProp 276 loss=240.612946 err=6.445168
I 2015-05-27 00:37:03 theanets.trainer:168 RmsProp 277 loss=239.449371 err=5.738912
I 2015-05-27 00:37:13 theanets.trainer:168 RmsProp 278 loss=239.083084 err=5.822485
I 2015-05-27 00:37:23 theanets.trainer:168 RmsProp 279 loss=239.275955 err=6.474139
I 2015-05-27 00:37:34 theanets.trainer:168 RmsProp 280 loss=238.159882 err=5.817380
I 2015-05-27 00:37:34 theanets.trainer:168 validation 28 loss=1702.383789 err=1470.287476 *
I 2015-05-27 00:37:45 theanets.trainer:168 RmsProp 281 loss=237.566742 err=5.685150
I 2015-05-27 00:37:55 theanets.trainer:168 RmsProp 282 loss=237.828461 err=6.407719
I 2015-05-27 00:38:05 theanets.trainer:168 RmsProp 283 loss=236.827881 err=5.870517
I 2015-05-27 00:38:16 theanets.trainer:168 RmsProp 284 loss=236.662720 err=6.163889
I 2015-05-27 00:38:26 theanets.trainer:168 RmsProp 285 loss=235.866943 err=5.821329
I 2015-05-27 00:38:36 theanets.trainer:168 RmsProp 286 loss=235.576614 err=5.978430
I 2015-05-27 00:38:46 theanets.trainer:168 RmsProp 287 loss=235.234222 err=6.082477
I 2015-05-27 00:38:56 theanets.trainer:168 RmsProp 288 loss=234.504883 err=5.801726
I 2015-05-27 00:39:07 theanets.trainer:168 RmsProp 289 loss=234.283966 err=6.020759
I 2015-05-27 00:39:17 theanets.trainer:168 RmsProp 290 loss=233.870682 err=6.040176
I 2015-05-27 00:39:17 theanets.trainer:168 validation 29 loss=1691.089722 err=1463.499756 *
I 2015-05-27 00:39:28 theanets.trainer:168 RmsProp 291 loss=233.089508 err=5.693349
I 2015-05-27 00:39:38 theanets.trainer:168 RmsProp 292 loss=232.595871 err=5.628634
I 2015-05-27 00:39:48 theanets.trainer:168 RmsProp 293 loss=232.391678 err=5.863824
I 2015-05-27 00:39:59 theanets.trainer:168 RmsProp 294 loss=231.688873 err=5.600581
I 2015-05-27 00:40:09 theanets.trainer:168 RmsProp 295 loss=231.590302 err=5.947374
I 2015-05-27 00:40:19 theanets.trainer:168 RmsProp 296 loss=231.055496 err=5.845178
I 2015-05-27 00:40:30 theanets.trainer:168 RmsProp 297 loss=230.574738 err=5.787436
I 2015-05-27 00:40:40 theanets.trainer:168 RmsProp 298 loss=229.936035 err=5.574792
I 2015-05-27 00:40:50 theanets.trainer:168 RmsProp 299 loss=230.116379 err=6.177894
I 2015-05-27 00:41:00 theanets.trainer:168 RmsProp 300 loss=229.386505 err=5.868263
I 2015-05-27 00:41:01 theanets.trainer:168 validation 30 loss=1680.306152 err=1457.015991 *
I 2015-05-27 00:41:11 theanets.trainer:168 RmsProp 301 loss=228.792892 err=5.687499
I 2015-05-27 00:41:21 theanets.trainer:168 RmsProp 302 loss=228.670166 err=5.979223
I 2015-05-27 00:41:31 theanets.trainer:168 RmsProp 303 loss=228.017487 err=5.740252
I 2015-05-27 00:41:41 theanets.trainer:168 RmsProp 304 loss=227.128464 err=5.263451
I 2015-05-27 00:41:52 theanets.trainer:168 RmsProp 305 loss=227.259186 err=5.804550
I 2015-05-27 00:42:02 theanets.trainer:168 RmsProp 306 loss=227.086624 err=6.038033
I 2015-05-27 00:42:12 theanets.trainer:168 RmsProp 307 loss=226.178070 err=5.530406
I 2015-05-27 00:42:22 theanets.trainer:168 RmsProp 308 loss=225.888092 err=5.630602
I 2015-05-27 00:42:32 theanets.trainer:168 RmsProp 309 loss=225.568604 err=5.710461
I 2015-05-27 00:42:43 theanets.trainer:168 RmsProp 310 loss=225.505539 err=6.042517
I 2015-05-27 00:42:43 theanets.trainer:168 validation 31 loss=1669.219360 err=1449.972046 *
I 2015-05-27 00:42:53 theanets.trainer:168 RmsProp 311 loss=224.293289 err=5.230143
I 2015-05-27 00:43:04 theanets.trainer:168 RmsProp 312 loss=224.428833 err=5.763307
I 2015-05-27 00:43:14 theanets.trainer:168 RmsProp 313 loss=223.720306 err=5.456207
I 2015-05-27 00:43:24 theanets.trainer:168 RmsProp 314 loss=223.601593 err=5.735326
I 2015-05-27 00:43:34 theanets.trainer:168 RmsProp 315 loss=222.969894 err=5.498860
I 2015-05-27 00:43:44 theanets.trainer:168 RmsProp 316 loss=222.850632 err=5.768088
I 2015-05-27 00:43:54 theanets.trainer:168 RmsProp 317 loss=222.205643 err=5.517259
I 2015-05-27 00:44:04 theanets.trainer:168 RmsProp 318 loss=221.829590 err=5.528960
I 2015-05-27 00:44:14 theanets.trainer:168 RmsProp 319 loss=221.300995 err=5.395052
I 2015-05-27 00:44:24 theanets.trainer:168 RmsProp 320 loss=221.228882 err=5.705490
I 2015-05-27 00:44:25 theanets.trainer:168 validation 32 loss=1660.393066 err=1445.079468 *
I 2015-05-27 00:44:34 theanets.trainer:168 RmsProp 321 loss=220.638107 err=5.502821
I 2015-05-27 00:44:44 theanets.trainer:168 RmsProp 322 loss=220.695190 err=5.938413
I 2015-05-27 00:44:54 theanets.trainer:168 RmsProp 323 loss=219.820160 err=5.436864
I 2015-05-27 00:45:04 theanets.trainer:168 RmsProp 324 loss=219.545898 err=5.531168
I 2015-05-27 00:45:14 theanets.trainer:168 RmsProp 325 loss=218.976318 err=5.329718
I 2015-05-27 00:45:24 theanets.trainer:168 RmsProp 326 loss=218.946487 err=5.674111
I 2015-05-27 00:45:35 theanets.trainer:168 RmsProp 327 loss=218.687500 err=5.783864
I 2015-05-27 00:45:45 theanets.trainer:168 RmsProp 328 loss=217.862381 err=5.328282
I 2015-05-27 00:45:56 theanets.trainer:168 RmsProp 329 loss=217.593796 err=5.423152
I 2015-05-27 00:46:06 theanets.trainer:168 RmsProp 330 loss=217.638992 err=5.835246
I 2015-05-27 00:46:07 theanets.trainer:168 validation 33 loss=1655.977295 err=1444.377197 *
I 2015-05-27 00:46:17 theanets.trainer:168 RmsProp 331 loss=216.711594 err=5.272648
I 2015-05-27 00:46:27 theanets.trainer:168 RmsProp 332 loss=216.711304 err=5.634627
I 2015-05-27 00:46:38 theanets.trainer:168 RmsProp 333 loss=216.502930 err=5.782794
I 2015-05-27 00:46:48 theanets.trainer:168 RmsProp 334 loss=215.513260 err=5.147383
I 2015-05-27 00:46:59 theanets.trainer:168 RmsProp 335 loss=215.441650 err=5.435760
I 2015-05-27 00:47:09 theanets.trainer:168 RmsProp 336 loss=214.866119 err=5.218786
I 2015-05-27 00:47:20 theanets.trainer:168 RmsProp 337 loss=215.013962 err=5.724698
I 2015-05-27 00:47:31 theanets.trainer:168 RmsProp 338 loss=214.639481 err=5.703212
I 2015-05-27 00:47:41 theanets.trainer:168 RmsProp 339 loss=213.916046 err=5.321334
I 2015-05-27 00:47:52 theanets.trainer:168 RmsProp 340 loss=213.419357 err=5.170446
I 2015-05-27 00:47:52 theanets.trainer:168 validation 34 loss=1646.953369 err=1438.902100 *
I 2015-05-27 00:48:03 theanets.trainer:168 RmsProp 341 loss=213.697601 err=5.793285
I 2015-05-27 00:48:13 theanets.trainer:168 RmsProp 342 loss=213.381912 err=5.818345
I 2015-05-27 00:48:24 theanets.trainer:168 RmsProp 343 loss=212.447067 err=5.216977
I 2015-05-27 00:48:35 theanets.trainer:168 RmsProp 344 loss=212.209839 err=5.320560
I 2015-05-27 00:48:45 theanets.trainer:168 RmsProp 345 loss=211.753220 err=5.209002
I 2015-05-27 00:48:56 theanets.trainer:168 RmsProp 346 loss=211.617035 err=5.409940
I 2015-05-27 00:49:07 theanets.trainer:168 RmsProp 347 loss=211.377716 err=5.507251
I 2015-05-27 00:49:17 theanets.trainer:168 RmsProp 348 loss=210.758423 err=5.224440
I 2015-05-27 00:49:28 theanets.trainer:168 RmsProp 349 loss=210.583496 err=5.389619
I 2015-05-27 00:49:39 theanets.trainer:168 RmsProp 350 loss=210.217407 err=5.358121
I 2015-05-27 00:49:39 theanets.trainer:168 validation 35 loss=1646.707642 err=1442.027222 *
I 2015-05-27 00:49:50 theanets.trainer:168 RmsProp 351 loss=209.808868 err=5.283346
I 2015-05-27 00:50:00 theanets.trainer:168 RmsProp 352 loss=209.615280 err=5.420909
I 2015-05-27 00:50:10 theanets.trainer:168 RmsProp 353 loss=209.374146 err=5.508183
I 2015-05-27 00:50:21 theanets.trainer:168 RmsProp 354 loss=208.614624 err=5.083217
I 2015-05-27 00:50:32 theanets.trainer:168 RmsProp 355 loss=208.863647 err=5.655703
I 2015-05-27 00:50:42 theanets.trainer:168 RmsProp 356 loss=208.009766 err=5.133302
I 2015-05-27 00:50:53 theanets.trainer:168 RmsProp 357 loss=207.969452 err=5.411088
I 2015-05-27 00:51:04 theanets.trainer:168 RmsProp 358 loss=207.215576 err=4.978407
I 2015-05-27 00:51:14 theanets.trainer:168 RmsProp 359 loss=207.397507 err=5.481692
I 2015-05-27 00:51:25 theanets.trainer:168 RmsProp 360 loss=206.771805 err=5.178702
I 2015-05-27 00:51:25 theanets.trainer:168 validation 36 loss=1636.396118 err=1434.975464 *
I 2015-05-27 00:51:35 theanets.trainer:168 RmsProp 361 loss=206.249664 err=4.983715
I 2015-05-27 00:51:46 theanets.trainer:168 RmsProp 362 loss=206.183929 err=5.243163
I 2015-05-27 00:51:56 theanets.trainer:168 RmsProp 363 loss=205.612259 err=4.995231
I 2015-05-27 00:52:06 theanets.trainer:168 RmsProp 364 loss=206.115356 err=5.805475
I 2015-05-27 00:52:17 theanets.trainer:168 RmsProp 365 loss=205.443451 err=5.443198
I 2015-05-27 00:52:27 theanets.trainer:168 RmsProp 366 loss=204.887909 err=5.193455
I 2015-05-27 00:52:38 theanets.trainer:168 RmsProp 367 loss=204.667252 err=5.278241
I 2015-05-27 00:52:48 theanets.trainer:168 RmsProp 368 loss=204.109207 err=5.029806
I 2015-05-27 00:52:59 theanets.trainer:168 RmsProp 369 loss=203.858856 err=5.085673
I 2015-05-27 00:53:09 theanets.trainer:168 RmsProp 370 loss=203.542709 err=5.076618
I 2015-05-27 00:53:10 theanets.trainer:168 validation 37 loss=1634.441650 err=1436.141602 *
I 2015-05-27 00:53:20 theanets.trainer:168 RmsProp 371 loss=203.351089 err=5.190187
I 2015-05-27 00:53:30 theanets.trainer:168 RmsProp 372 loss=203.151443 err=5.291082
I 2015-05-27 00:53:41 theanets.trainer:168 RmsProp 373 loss=202.863129 err=5.298550
I 2015-05-27 00:53:51 theanets.trainer:168 RmsProp 374 loss=202.590088 err=5.323694
I 2015-05-27 00:54:01 theanets.trainer:168 RmsProp 375 loss=201.892838 err=4.929046
I 2015-05-27 00:54:12 theanets.trainer:168 RmsProp 376 loss=201.732651 err=5.067493
I 2015-05-27 00:54:22 theanets.trainer:168 RmsProp 377 loss=201.590118 err=5.227817
I 2015-05-27 00:54:33 theanets.trainer:168 RmsProp 378 loss=201.655411 err=5.588323
I 2015-05-27 00:54:43 theanets.trainer:168 RmsProp 379 loss=200.713409 err=4.934329
I 2015-05-27 00:54:53 theanets.trainer:168 RmsProp 380 loss=200.648224 err=5.162029
I 2015-05-27 00:54:54 theanets.trainer:168 validation 38 loss=1618.939697 err=1423.613525 *
I 2015-05-27 00:55:04 theanets.trainer:168 RmsProp 381 loss=200.296600 err=5.102214
I 2015-05-27 00:55:14 theanets.trainer:168 RmsProp 382 loss=200.074295 err=5.172641
I 2015-05-27 00:55:25 theanets.trainer:168 RmsProp 383 loss=199.677124 err=5.066875
I 2015-05-27 00:55:36 theanets.trainer:168 RmsProp 384 loss=199.417343 err=5.095225
I 2015-05-27 00:55:46 theanets.trainer:168 RmsProp 385 loss=199.387299 err=5.347063
I 2015-05-27 00:55:57 theanets.trainer:168 RmsProp 386 loss=199.209564 err=5.449891
I 2015-05-27 00:56:07 theanets.trainer:168 RmsProp 387 loss=198.321732 err=4.843685
I 2015-05-27 00:56:17 theanets.trainer:168 RmsProp 388 loss=198.382126 err=5.185601
I 2015-05-27 00:56:28 theanets.trainer:168 RmsProp 389 loss=198.267258 err=5.346087
I 2015-05-27 00:56:38 theanets.trainer:168 RmsProp 390 loss=198.050705 err=5.405881
I 2015-05-27 00:56:39 theanets.trainer:168 validation 39 loss=1616.662354 err=1424.161499 *
I 2015-05-27 00:56:49 theanets.trainer:168 RmsProp 391 loss=197.319489 err=4.946022
I 2015-05-27 00:56:59 theanets.trainer:168 RmsProp 392 loss=197.121078 err=5.015419
I 2015-05-27 00:57:09 theanets.trainer:168 RmsProp 393 loss=196.525787 err=4.705165
I 2015-05-27 00:57:20 theanets.trainer:168 RmsProp 394 loss=196.832428 err=5.287304
I 2015-05-27 00:57:30 theanets.trainer:168 RmsProp 395 loss=196.154373 err=4.887278
I 2015-05-27 00:57:41 theanets.trainer:168 RmsProp 396 loss=196.057953 err=5.068875
I 2015-05-27 00:57:51 theanets.trainer:168 RmsProp 397 loss=195.955383 err=5.235386
I 2015-05-27 00:58:02 theanets.trainer:168 RmsProp 398 loss=195.242065 err=4.796626
I 2015-05-27 00:58:12 theanets.trainer:168 RmsProp 399 loss=195.263702 err=5.090523
I 2015-05-27 00:58:22 theanets.trainer:168 RmsProp 400 loss=194.801483 err=4.900870
I 2015-05-27 00:58:23 theanets.trainer:168 validation 40 loss=1611.696533 err=1421.956909 *
I 2015-05-27 00:58:33 theanets.trainer:168 RmsProp 401 loss=194.960175 err=5.327403
I 2015-05-27 00:58:43 theanets.trainer:168 RmsProp 402 loss=194.296753 err=4.929900
I 2015-05-27 00:58:54 theanets.trainer:168 RmsProp 403 loss=194.287659 err=5.176344
I 2015-05-27 00:59:04 theanets.trainer:168 RmsProp 404 loss=193.789688 err=4.940993
I 2015-05-27 00:59:15 theanets.trainer:168 RmsProp 405 loss=194.045624 err=5.457513
I 2015-05-27 00:59:25 theanets.trainer:168 RmsProp 406 loss=193.377502 err=5.045603
I 2015-05-27 00:59:36 theanets.trainer:168 RmsProp 407 loss=192.987091 err=4.912362
I 2015-05-27 00:59:46 theanets.trainer:168 RmsProp 408 loss=192.627625 err=4.812740
I 2015-05-27 00:59:56 theanets.trainer:168 RmsProp 409 loss=192.215027 err=4.662182
I 2015-05-27 01:00:06 theanets.trainer:168 RmsProp 410 loss=192.445572 err=5.156108
I 2015-05-27 01:00:07 theanets.trainer:168 validation 41 loss=1605.685669 err=1418.528564 *
I 2015-05-27 01:00:16 theanets.trainer:168 RmsProp 411 loss=192.270370 err=5.233001
I 2015-05-27 01:00:26 theanets.trainer:168 RmsProp 412 loss=191.057251 err=4.286494
I 2015-05-27 01:00:36 theanets.trainer:168 RmsProp 413 loss=192.417099 err=5.889886
I 2015-05-27 01:00:46 theanets.trainer:168 RmsProp 414 loss=191.071136 err=4.801684
I 2015-05-27 01:00:56 theanets.trainer:168 RmsProp 415 loss=190.969757 err=4.947829
I 2015-05-27 01:01:06 theanets.trainer:168 RmsProp 416 loss=190.644348 err=4.867932
I 2015-05-27 01:01:16 theanets.trainer:168 RmsProp 417 loss=190.449585 err=4.930313
I 2015-05-27 01:01:26 theanets.trainer:168 RmsProp 418 loss=190.416260 err=5.143953
I 2015-05-27 01:01:35 theanets.trainer:168 RmsProp 419 loss=190.070190 err=5.047757
I 2015-05-27 01:01:45 theanets.trainer:168 RmsProp 420 loss=189.670944 err=4.893354
I 2015-05-27 01:01:46 theanets.trainer:168 validation 42 loss=1601.465088 err=1416.817261 *
I 2015-05-27 01:01:56 theanets.trainer:168 RmsProp 421 loss=189.266937 err=4.736820
I 2015-05-27 01:02:06 theanets.trainer:168 RmsProp 422 loss=189.241913 err=4.960498
I 2015-05-27 01:02:16 theanets.trainer:168 RmsProp 423 loss=188.996094 err=4.953756
I 2015-05-27 01:02:27 theanets.trainer:168 RmsProp 424 loss=188.835175 err=5.031335
I 2015-05-27 01:02:37 theanets.trainer:168 RmsProp 425 loss=188.165817 err=4.601411
I 2015-05-27 01:02:47 theanets.trainer:168 RmsProp 426 loss=188.297028 err=4.971855
I 2015-05-27 01:02:58 theanets.trainer:168 RmsProp 427 loss=187.933960 err=4.846930
I 2015-05-27 01:03:09 theanets.trainer:168 RmsProp 428 loss=187.476532 err=4.636412
I 2015-05-27 01:03:19 theanets.trainer:168 RmsProp 429 loss=188.028732 err=5.426431
I 2015-05-27 01:03:29 theanets.trainer:168 RmsProp 430 loss=186.909882 err=4.547775
I 2015-05-27 01:03:30 theanets.trainer:168 validation 43 loss=1595.458862 err=1413.238525 *
I 2015-05-27 01:03:40 theanets.trainer:168 RmsProp 431 loss=187.090317 err=4.967485
I 2015-05-27 01:03:51 theanets.trainer:168 RmsProp 432 loss=187.150909 err=5.256024
I 2015-05-27 01:04:01 theanets.trainer:168 RmsProp 433 loss=186.463730 err=4.798976
I 2015-05-27 01:04:12 theanets.trainer:168 RmsProp 434 loss=186.092880 err=4.654552
I 2015-05-27 01:04:22 theanets.trainer:168 RmsProp 435 loss=186.045197 err=4.836150
I 2015-05-27 01:04:33 theanets.trainer:168 RmsProp 436 loss=186.386780 err=5.402017
I 2015-05-27 01:04:44 theanets.trainer:168 RmsProp 437 loss=185.450317 err=4.695678
I 2015-05-27 01:04:55 theanets.trainer:168 RmsProp 438 loss=185.408585 err=4.884984
I 2015-05-27 01:05:06 theanets.trainer:168 RmsProp 439 loss=184.981888 err=4.685334
I 2015-05-27 01:05:17 theanets.trainer:168 RmsProp 440 loss=184.890594 err=4.820538
I 2015-05-27 01:05:17 theanets.trainer:168 validation 44 loss=1595.984131 err=1416.036987
I 2015-05-27 01:05:28 theanets.trainer:168 RmsProp 441 loss=184.557266 err=4.715592
I 2015-05-27 01:05:38 theanets.trainer:168 RmsProp 442 loss=184.313782 err=4.697658
I 2015-05-27 01:05:49 theanets.trainer:168 RmsProp 443 loss=184.474228 err=5.084928
I 2015-05-27 01:05:59 theanets.trainer:168 RmsProp 444 loss=183.947342 err=4.785449
I 2015-05-27 01:06:10 theanets.trainer:168 RmsProp 445 loss=183.836777 err=4.898792
I 2015-05-27 01:06:20 theanets.trainer:168 RmsProp 446 loss=183.389313 err=4.670689
I 2015-05-27 01:06:31 theanets.trainer:168 RmsProp 447 loss=183.301880 err=4.803185
I 2015-05-27 01:06:41 theanets.trainer:168 RmsProp 448 loss=183.020645 err=4.744870
I 2015-05-27 01:06:52 theanets.trainer:168 RmsProp 449 loss=182.770905 err=4.719102
I 2015-05-27 01:07:02 theanets.trainer:168 RmsProp 450 loss=182.652191 err=4.819918
I 2015-05-27 01:07:03 theanets.trainer:168 validation 45 loss=1586.777832 err=1409.055420 *
I 2015-05-27 01:07:14 theanets.trainer:168 RmsProp 451 loss=182.368744 err=4.754497
I 2015-05-27 01:07:24 theanets.trainer:168 RmsProp 452 loss=182.583374 err=5.184064
I 2015-05-27 01:07:35 theanets.trainer:168 RmsProp 453 loss=181.797195 err=4.612542
I 2015-05-27 01:07:45 theanets.trainer:168 RmsProp 454 loss=181.701599 err=4.732096
I 2015-05-27 01:07:56 theanets.trainer:168 RmsProp 455 loss=181.554550 err=4.796819
I 2015-05-27 01:08:07 theanets.trainer:168 RmsProp 456 loss=180.985199 err=4.442414
I 2015-05-27 01:08:18 theanets.trainer:168 RmsProp 457 loss=181.176376 err=4.848773
I 2015-05-27 01:08:28 theanets.trainer:168 RmsProp 458 loss=181.012970 err=4.898270
I 2015-05-27 01:08:39 theanets.trainer:168 RmsProp 459 loss=180.546112 err=4.647747
I 2015-05-27 01:08:50 theanets.trainer:168 RmsProp 460 loss=180.464813 err=4.777068
I 2015-05-27 01:08:50 theanets.trainer:168 validation 46 loss=1580.477905 err=1404.908569 *
I 2015-05-27 01:09:01 theanets.trainer:168 RmsProp 461 loss=180.222748 err=4.747548
I 2015-05-27 01:09:12 theanets.trainer:168 RmsProp 462 loss=180.183716 err=4.913429
I 2015-05-27 01:09:23 theanets.trainer:168 RmsProp 463 loss=179.730743 err=4.666129
I 2015-05-27 01:09:34 theanets.trainer:168 RmsProp 464 loss=179.363586 err=4.508756
I 2015-05-27 01:09:44 theanets.trainer:168 RmsProp 465 loss=179.321381 err=4.673530
I 2015-05-27 01:09:55 theanets.trainer:168 RmsProp 466 loss=179.403595 err=4.964882
I 2015-05-27 01:10:06 theanets.trainer:168 RmsProp 467 loss=179.078323 err=4.844026
I 2015-05-27 01:10:16 theanets.trainer:168 RmsProp 468 loss=178.702972 err=4.679416
I 2015-05-27 01:10:27 theanets.trainer:168 RmsProp 469 loss=178.450211 err=4.630875
I 2015-05-27 01:10:38 theanets.trainer:168 RmsProp 470 loss=178.239044 err=4.627403
I 2015-05-27 01:10:38 theanets.trainer:168 validation 47 loss=1581.611694 err=1408.114014
I 2015-05-27 01:10:49 theanets.trainer:168 RmsProp 471 loss=177.954010 err=4.549976
I 2015-05-27 01:11:00 theanets.trainer:168 RmsProp 472 loss=177.904785 err=4.705570
I 2015-05-27 01:11:11 theanets.trainer:168 RmsProp 473 loss=177.663422 err=4.673613
I 2015-05-27 01:11:22 theanets.trainer:168 RmsProp 474 loss=177.317108 err=4.526558
I 2015-05-27 01:11:33 theanets.trainer:168 RmsProp 475 loss=177.151703 err=4.562263
I 2015-05-27 01:11:44 theanets.trainer:168 RmsProp 476 loss=177.252472 err=4.861466
I 2015-05-27 01:11:55 theanets.trainer:168 RmsProp 477 loss=176.705338 err=4.516185
I 2015-05-27 01:12:06 theanets.trainer:168 RmsProp 478 loss=176.740067 err=4.753942
I 2015-05-27 01:12:16 theanets.trainer:168 RmsProp 479 loss=176.604813 err=4.815020
I 2015-05-27 01:12:27 theanets.trainer:168 RmsProp 480 loss=175.851303 err=4.260048
I 2015-05-27 01:12:28 theanets.trainer:168 validation 48 loss=1579.676270 err=1408.180542 *
I 2015-05-27 01:12:39 theanets.trainer:168 RmsProp 481 loss=176.217102 err=4.817777
I 2015-05-27 01:12:49 theanets.trainer:168 RmsProp 482 loss=175.605209 err=4.408193
I 2015-05-27 01:13:00 theanets.trainer:168 RmsProp 483 loss=175.828110 err=4.827972
I 2015-05-27 01:13:11 theanets.trainer:168 RmsProp 484 loss=175.182510 err=4.382879
I 2015-05-27 01:13:21 theanets.trainer:168 RmsProp 485 loss=175.021713 err=4.422577
I 2015-05-27 01:13:32 theanets.trainer:168 RmsProp 486 loss=174.926666 err=4.525659
I 2015-05-27 01:13:42 theanets.trainer:168 RmsProp 487 loss=174.720474 err=4.521676
I 2015-05-27 01:13:53 theanets.trainer:168 RmsProp 488 loss=174.598587 err=4.595035
I 2015-05-27 01:14:03 theanets.trainer:168 RmsProp 489 loss=174.404633 err=4.597004
I 2015-05-27 01:14:14 theanets.trainer:168 RmsProp 490 loss=174.080948 err=4.465004
I 2015-05-27 01:14:14 theanets.trainer:168 validation 49 loss=1569.679443 err=1400.176392 *
I 2015-05-27 01:14:24 theanets.trainer:168 RmsProp 491 loss=173.994217 err=4.574214
I 2015-05-27 01:14:35 theanets.trainer:168 RmsProp 492 loss=173.842239 err=4.616304
I 2015-05-27 01:14:45 theanets.trainer:168 RmsProp 493 loss=173.528641 err=4.491535
I 2015-05-27 01:14:56 theanets.trainer:168 RmsProp 494 loss=173.300690 err=4.456016
I 2015-05-27 01:15:06 theanets.trainer:168 RmsProp 495 loss=172.867920 err=4.218930
I 2015-05-27 01:15:16 theanets.trainer:168 RmsProp 496 loss=173.376205 err=4.916358
I 2015-05-27 01:15:26 theanets.trainer:168 RmsProp 497 loss=172.572342 err=4.301520
I 2015-05-27 01:15:37 theanets.trainer:168 RmsProp 498 loss=172.438126 err=4.359145
I 2015-05-27 01:15:47 theanets.trainer:168 RmsProp 499 loss=172.787766 err=4.888238
I 2015-05-27 01:15:57 theanets.trainer:168 RmsProp 500 loss=172.079010 err=4.362397
I 2015-05-27 01:15:58 theanets.trainer:168 validation 50 loss=1565.965576 err=1398.347412 *
I 2015-05-27 01:16:08 theanets.trainer:168 RmsProp 501 loss=171.734329 err=4.207342
I 2015-05-27 01:16:19 theanets.trainer:168 RmsProp 502 loss=172.041412 err=4.698344
I 2015-05-27 01:16:30 theanets.trainer:168 RmsProp 503 loss=171.157623 err=4.007685
I 2015-05-27 01:16:41 theanets.trainer:168 RmsProp 504 loss=172.031219 err=5.064445
I 2015-05-27 01:16:51 theanets.trainer:168 RmsProp 505 loss=171.066254 err=4.285745
I 2015-05-27 01:17:02 theanets.trainer:168 RmsProp 506 loss=171.244263 err=4.644835
I 2015-05-27 01:17:12 theanets.trainer:168 RmsProp 507 loss=170.867859 err=4.454424
I 2015-05-27 01:17:22 theanets.trainer:168 RmsProp 508 loss=170.733307 err=4.504123
I 2015-05-27 01:17:33 theanets.trainer:168 RmsProp 509 loss=170.224258 err=4.178691
I 2015-05-27 01:17:44 theanets.trainer:168 RmsProp 510 loss=170.217010 err=4.356870
I 2015-05-27 01:17:44 theanets.trainer:168 validation 51 loss=1558.207153 err=1392.433594 *
I 2015-05-27 01:17:55 theanets.trainer:168 RmsProp 511 loss=169.856461 err=4.178268
I 2015-05-27 01:18:06 theanets.trainer:168 RmsProp 512 loss=170.629257 err=5.126199
I 2015-05-27 01:18:17 theanets.trainer:168 RmsProp 513 loss=169.701187 err=4.382270
I 2015-05-27 01:18:28 theanets.trainer:168 RmsProp 514 loss=169.490128 err=4.347579
I 2015-05-27 01:18:39 theanets.trainer:168 RmsProp 515 loss=169.450531 err=4.487319
I 2015-05-27 01:18:50 theanets.trainer:168 RmsProp 516 loss=169.154144 err=4.363834
I 2015-05-27 01:19:01 theanets.trainer:168 RmsProp 517 loss=169.192230 err=4.577848
I 2015-05-27 01:19:11 theanets.trainer:168 RmsProp 518 loss=168.936264 err=4.497848
I 2015-05-27 01:19:22 theanets.trainer:168 RmsProp 519 loss=168.464539 err=4.205853
I 2015-05-27 01:19:33 theanets.trainer:168 RmsProp 520 loss=168.871643 err=4.784781
I 2015-05-27 01:19:34 theanets.trainer:168 validation 52 loss=1557.635742 err=1393.647339 *
I 2015-05-27 01:19:44 theanets.trainer:168 RmsProp 521 loss=168.037003 err=4.125442
I 2015-05-27 01:19:55 theanets.trainer:168 RmsProp 522 loss=168.136002 err=4.397143
I 2015-05-27 01:20:06 theanets.trainer:168 RmsProp 523 loss=168.145203 err=4.576678
I 2015-05-27 01:20:18 theanets.trainer:168 RmsProp 524 loss=167.714203 err=4.320996
I 2015-05-27 01:20:29 theanets.trainer:168 RmsProp 525 loss=168.095459 err=4.871979
I 2015-05-27 01:20:39 theanets.trainer:168 RmsProp 526 loss=167.658478 err=4.601029
I 2015-05-27 01:20:50 theanets.trainer:168 RmsProp 527 loss=166.927628 err=4.044112
I 2015-05-27 01:21:01 theanets.trainer:168 RmsProp 528 loss=167.365601 err=4.643454
I 2015-05-27 01:21:11 theanets.trainer:168 RmsProp 529 loss=166.963959 err=4.411427
I 2015-05-27 01:21:21 theanets.trainer:168 RmsProp 530 loss=166.821091 err=4.434467
I 2015-05-27 01:21:22 theanets.trainer:168 validation 53 loss=1554.124512 err=1391.826538 *
I 2015-05-27 01:21:32 theanets.trainer:168 RmsProp 531 loss=166.371735 err=4.150110
I 2015-05-27 01:21:43 theanets.trainer:168 RmsProp 532 loss=166.499023 err=4.442609
I 2015-05-27 01:21:53 theanets.trainer:168 RmsProp 533 loss=165.903152 err=4.023391
I 2015-05-27 01:22:04 theanets.trainer:168 RmsProp 534 loss=165.861755 err=4.154747
I 2015-05-27 01:22:15 theanets.trainer:168 RmsProp 535 loss=165.899780 err=4.360832
I 2015-05-27 01:22:26 theanets.trainer:168 RmsProp 536 loss=165.474274 err=4.109565
I 2015-05-27 01:22:37 theanets.trainer:168 RmsProp 537 loss=166.012924 err=4.812417
I 2015-05-27 01:22:47 theanets.trainer:168 RmsProp 538 loss=165.208435 err=4.178569
I 2015-05-27 01:22:58 theanets.trainer:168 RmsProp 539 loss=165.137115 err=4.274474
I 2015-05-27 01:23:09 theanets.trainer:168 RmsProp 540 loss=165.153351 err=4.451959
I 2015-05-27 01:23:09 theanets.trainer:168 validation 54 loss=1549.442993 err=1388.838745 *
I 2015-05-27 01:23:20 theanets.trainer:168 RmsProp 541 loss=164.729736 err=4.194557
I 2015-05-27 01:23:31 theanets.trainer:168 RmsProp 542 loss=164.766373 err=4.391357
I 2015-05-27 01:23:42 theanets.trainer:168 RmsProp 543 loss=164.347397 err=4.141862
I 2015-05-27 01:23:53 theanets.trainer:168 RmsProp 544 loss=164.348969 err=4.308105
I 2015-05-27 01:24:03 theanets.trainer:168 RmsProp 545 loss=164.075211 err=4.198423
I 2015-05-27 01:24:14 theanets.trainer:168 RmsProp 546 loss=163.817841 err=4.108530
I 2015-05-27 01:24:24 theanets.trainer:168 RmsProp 547 loss=163.469070 err=3.925596
I 2015-05-27 01:24:35 theanets.trainer:168 RmsProp 548 loss=164.016418 err=4.633804
I 2015-05-27 01:24:46 theanets.trainer:168 RmsProp 549 loss=163.356018 err=4.138451
I 2015-05-27 01:24:57 theanets.trainer:168 RmsProp 550 loss=163.455383 err=4.396808
I 2015-05-27 01:24:58 theanets.trainer:168 validation 55 loss=1546.354492 err=1387.385376 *
I 2015-05-27 01:25:08 theanets.trainer:168 RmsProp 551 loss=163.218353 err=4.316885
I 2015-05-27 01:25:19 theanets.trainer:168 RmsProp 552 loss=162.827667 err=4.086559
I 2015-05-27 01:25:30 theanets.trainer:168 RmsProp 553 loss=162.805969 err=4.223622
I 2015-05-27 01:25:40 theanets.trainer:168 RmsProp 554 loss=162.789093 err=4.361995
I 2015-05-27 01:25:51 theanets.trainer:168 RmsProp 555 loss=162.235825 err=3.966670
I 2015-05-27 01:26:02 theanets.trainer:168 RmsProp 556 loss=162.627106 err=4.515797
I 2015-05-27 01:26:13 theanets.trainer:168 RmsProp 557 loss=162.162766 err=4.210595
I 2015-05-27 01:26:23 theanets.trainer:168 RmsProp 558 loss=161.819351 err=4.027650
I 2015-05-27 01:26:34 theanets.trainer:168 RmsProp 559 loss=162.135590 err=4.498542
I 2015-05-27 01:26:44 theanets.trainer:168 RmsProp 560 loss=161.555054 err=4.071211
I 2015-05-27 01:26:45 theanets.trainer:168 validation 56 loss=1536.070679 err=1378.666138 *
I 2015-05-27 01:26:55 theanets.trainer:168 RmsProp 561 loss=161.454056 err=4.126478
I 2015-05-27 01:27:05 theanets.trainer:168 RmsProp 562 loss=161.662140 err=4.490642
I 2015-05-27 01:27:16 theanets.trainer:168 RmsProp 563 loss=161.403473 err=4.383380
I 2015-05-27 01:27:26 theanets.trainer:168 RmsProp 564 loss=160.980377 err=4.118505
I 2015-05-27 01:27:37 theanets.trainer:168 RmsProp 565 loss=161.045731 err=4.330551
I 2015-05-27 01:27:47 theanets.trainer:168 RmsProp 566 loss=160.600067 err=4.034641
I 2015-05-27 01:27:57 theanets.trainer:168 RmsProp 567 loss=160.731354 err=4.320309
I 2015-05-27 01:28:08 theanets.trainer:168 RmsProp 568 loss=160.666412 err=4.402551
I 2015-05-27 01:28:18 theanets.trainer:168 RmsProp 569 loss=160.242218 err=4.131682
I 2015-05-27 01:28:28 theanets.trainer:168 RmsProp 570 loss=160.028961 err=4.071728
I 2015-05-27 01:28:28 theanets.trainer:168 validation 57 loss=1539.832153 err=1383.950073
I 2015-05-27 01:28:39 theanets.trainer:168 RmsProp 571 loss=160.040466 err=4.235119
I 2015-05-27 01:28:49 theanets.trainer:168 RmsProp 572 loss=159.676086 err=4.022354
I 2015-05-27 01:29:00 theanets.trainer:168 RmsProp 573 loss=159.791779 err=4.292443
I 2015-05-27 01:29:11 theanets.trainer:168 RmsProp 574 loss=159.615646 err=4.262549
I 2015-05-27 01:29:21 theanets.trainer:168 RmsProp 575 loss=159.313004 err=4.108883
I 2015-05-27 01:29:31 theanets.trainer:168 RmsProp 576 loss=159.371063 err=4.318876
I 2015-05-27 01:29:41 theanets.trainer:168 RmsProp 577 loss=158.724670 err=3.823680
I 2015-05-27 01:29:52 theanets.trainer:168 RmsProp 578 loss=158.972351 err=4.220173
I 2015-05-27 01:30:03 theanets.trainer:168 RmsProp 579 loss=159.151001 err=4.542523
I 2015-05-27 01:30:13 theanets.trainer:168 RmsProp 580 loss=158.674957 err=4.211360
I 2015-05-27 01:30:14 theanets.trainer:168 validation 58 loss=1532.949097 err=1378.570923 *
I 2015-05-27 01:30:24 theanets.trainer:168 RmsProp 581 loss=158.501526 err=4.182378
I 2015-05-27 01:30:35 theanets.trainer:168 RmsProp 582 loss=158.282745 err=4.109901
I 2015-05-27 01:30:45 theanets.trainer:168 RmsProp 583 loss=157.923126 err=3.896581
I 2015-05-27 01:30:56 theanets.trainer:168 RmsProp 584 loss=157.966034 err=4.082442
I 2015-05-27 01:31:06 theanets.trainer:168 RmsProp 585 loss=157.848694 err=4.112615
I 2015-05-27 01:31:17 theanets.trainer:168 RmsProp 586 loss=157.783783 err=4.190972
I 2015-05-27 01:31:28 theanets.trainer:168 RmsProp 587 loss=157.893967 err=4.444071
I 2015-05-27 01:31:38 theanets.trainer:168 RmsProp 588 loss=157.214432 err=3.912779
I 2015-05-27 01:31:49 theanets.trainer:168 RmsProp 589 loss=157.345078 err=4.190012
I 2015-05-27 01:31:59 theanets.trainer:168 RmsProp 590 loss=157.158676 err=4.141263
I 2015-05-27 01:32:00 theanets.trainer:168 validation 59 loss=1533.145874 err=1380.200073
I 2015-05-27 01:32:10 theanets.trainer:168 RmsProp 591 loss=156.995758 err=4.122874
I 2015-05-27 01:32:21 theanets.trainer:168 RmsProp 592 loss=156.775406 err=4.044873
I 2015-05-27 01:32:32 theanets.trainer:168 RmsProp 593 loss=156.852722 err=4.260474
I 2015-05-27 01:32:42 theanets.trainer:168 RmsProp 594 loss=156.463562 err=4.015597
I 2015-05-27 01:32:53 theanets.trainer:168 RmsProp 595 loss=156.469208 err=4.163958
I 2015-05-27 01:33:03 theanets.trainer:168 RmsProp 596 loss=156.179276 err=4.010494
I 2015-05-27 01:33:13 theanets.trainer:168 RmsProp 597 loss=155.995712 err=3.963641
I 2015-05-27 01:33:24 theanets.trainer:168 RmsProp 598 loss=156.163162 err=4.269255
I 2015-05-27 01:33:35 theanets.trainer:168 RmsProp 599 loss=155.754517 err=4.002439
I 2015-05-27 01:33:46 theanets.trainer:168 RmsProp 600 loss=155.634705 err=4.023981
I 2015-05-27 01:33:46 theanets.trainer:168 validation 60 loss=1522.941406 err=1371.407837 *
I 2015-05-27 01:33:57 theanets.trainer:168 RmsProp 601 loss=155.553101 err=4.085399
I 2015-05-27 01:34:07 theanets.trainer:168 RmsProp 602 loss=155.146027 err=3.818647
I 2015-05-27 01:34:18 theanets.trainer:168 RmsProp 603 loss=155.478577 err=4.286725
I 2015-05-27 01:34:28 theanets.trainer:168 RmsProp 604 loss=154.809113 err=3.765233
I 2015-05-27 01:34:39 theanets.trainer:168 RmsProp 605 loss=155.121338 err=4.215992
I 2015-05-27 01:34:49 theanets.trainer:168 RmsProp 606 loss=154.862518 err=4.100176
I 2015-05-27 01:34:59 theanets.trainer:168 RmsProp 607 loss=154.848236 err=4.218093
I 2015-05-27 01:35:10 theanets.trainer:168 RmsProp 608 loss=154.386353 err=3.892165
I 2015-05-27 01:35:20 theanets.trainer:168 RmsProp 609 loss=154.035126 err=3.679893
I 2015-05-27 01:35:31 theanets.trainer:168 RmsProp 610 loss=154.492584 err=4.271291
I 2015-05-27 01:35:31 theanets.trainer:168 validation 61 loss=1521.248779 err=1371.108032 *
I 2015-05-27 01:35:41 theanets.trainer:168 RmsProp 611 loss=154.055664 err=3.973490
I 2015-05-27 01:35:52 theanets.trainer:168 RmsProp 612 loss=153.917862 err=3.972078
I 2015-05-27 01:36:02 theanets.trainer:168 RmsProp 613 loss=153.865906 err=4.058891
I 2015-05-27 01:36:12 theanets.trainer:168 RmsProp 614 loss=153.783371 err=4.107698
I 2015-05-27 01:36:23 theanets.trainer:168 RmsProp 615 loss=153.564545 err=4.023973
I 2015-05-27 01:36:34 theanets.trainer:168 RmsProp 616 loss=153.537140 err=4.129085
I 2015-05-27 01:36:44 theanets.trainer:168 RmsProp 617 loss=152.985626 err=3.715877
I 2015-05-27 01:36:55 theanets.trainer:168 RmsProp 618 loss=153.387268 err=4.254251
I 2015-05-27 01:37:06 theanets.trainer:168 RmsProp 619 loss=152.812576 err=3.812487
I 2015-05-27 01:37:17 theanets.trainer:168 RmsProp 620 loss=152.594131 err=3.732015
I 2015-05-27 01:37:18 theanets.trainer:168 validation 62 loss=1516.533203 err=1367.733521 *
I 2015-05-27 01:37:28 theanets.trainer:168 RmsProp 621 loss=152.688309 err=3.958401
I 2015-05-27 01:37:39 theanets.trainer:168 RmsProp 622 loss=152.533203 err=3.941228
I 2015-05-27 01:37:49 theanets.trainer:168 RmsProp 623 loss=152.539581 err=4.079454
I 2015-05-27 01:38:00 theanets.trainer:168 RmsProp 624 loss=152.406479 err=4.082350
I 2015-05-27 01:38:11 theanets.trainer:168 RmsProp 625 loss=151.825882 err=3.634651
I 2015-05-27 01:38:22 theanets.trainer:168 RmsProp 626 loss=152.410980 err=4.345470
I 2015-05-27 01:38:33 theanets.trainer:168 RmsProp 627 loss=152.035767 err=4.104402
I 2015-05-27 01:38:44 theanets.trainer:168 RmsProp 628 loss=151.619843 err=3.817791
I 2015-05-27 01:38:54 theanets.trainer:168 RmsProp 629 loss=151.559235 err=3.888992
I 2015-05-27 01:39:05 theanets.trainer:168 RmsProp 630 loss=151.533249 err=3.990410
I 2015-05-27 01:39:05 theanets.trainer:168 validation 63 loss=1516.013916 err=1368.540527 *
I 2015-05-27 01:39:16 theanets.trainer:168 RmsProp 631 loss=151.151154 err=3.739819
I 2015-05-27 01:39:26 theanets.trainer:168 RmsProp 632 loss=151.427429 err=4.146618
I 2015-05-27 01:39:37 theanets.trainer:168 RmsProp 633 loss=151.397751 err=4.240355
I 2015-05-27 01:39:47 theanets.trainer:168 RmsProp 634 loss=150.649902 err=3.626286
I 2015-05-27 01:39:58 theanets.trainer:168 RmsProp 635 loss=150.601044 err=3.703215
I 2015-05-27 01:40:09 theanets.trainer:168 RmsProp 636 loss=151.089432 err=4.321162
I 2015-05-27 01:40:20 theanets.trainer:168 RmsProp 637 loss=150.713043 err=4.067423
I 2015-05-27 01:40:31 theanets.trainer:168 RmsProp 638 loss=150.364670 err=3.849531
I 2015-05-27 01:40:42 theanets.trainer:168 RmsProp 639 loss=150.237305 err=3.850911
I 2015-05-27 01:40:53 theanets.trainer:168 RmsProp 640 loss=150.274628 err=4.015712
I 2015-05-27 01:40:53 theanets.trainer:168 validation 64 loss=1513.966553 err=1367.778809 *
I 2015-05-27 01:41:04 theanets.trainer:168 RmsProp 641 loss=149.934753 err=3.803236
I 2015-05-27 01:41:14 theanets.trainer:168 RmsProp 642 loss=150.522736 err=4.508332
I 2015-05-27 01:41:25 theanets.trainer:168 RmsProp 643 loss=149.495789 err=3.612319
I 2015-05-27 01:41:35 theanets.trainer:168 RmsProp 644 loss=149.628143 err=3.872541
I 2015-05-27 01:41:45 theanets.trainer:168 RmsProp 645 loss=149.581223 err=3.952088
I 2015-05-27 01:41:56 theanets.trainer:168 RmsProp 646 loss=149.223541 err=3.724668
I 2015-05-27 01:42:06 theanets.trainer:168 RmsProp 647 loss=149.440125 err=4.062583
I 2015-05-27 01:42:16 theanets.trainer:168 RmsProp 648 loss=148.933594 err=3.682828
I 2015-05-27 01:42:26 theanets.trainer:168 RmsProp 649 loss=149.068649 err=3.939754
I 2015-05-27 01:42:36 theanets.trainer:168 RmsProp 650 loss=148.594955 err=3.591932
I 2015-05-27 01:42:37 theanets.trainer:168 validation 65 loss=1512.476685 err=1367.545166 *
I 2015-05-27 01:42:46 theanets.trainer:168 RmsProp 651 loss=149.022644 err=4.140007
I 2015-05-27 01:42:56 theanets.trainer:168 RmsProp 652 loss=148.373215 err=3.616827
I 2015-05-27 01:43:06 theanets.trainer:168 RmsProp 653 loss=148.506378 err=3.874713
I 2015-05-27 01:43:16 theanets.trainer:168 RmsProp 654 loss=148.568573 err=4.060418
I 2015-05-27 01:43:26 theanets.trainer:168 RmsProp 655 loss=148.571274 err=4.185816
I 2015-05-27 01:43:37 theanets.trainer:168 RmsProp 656 loss=148.058899 err=3.793957
I 2015-05-27 01:43:47 theanets.trainer:168 RmsProp 657 loss=147.770844 err=3.631210
I 2015-05-27 01:43:57 theanets.trainer:168 RmsProp 658 loss=148.062469 err=4.045675
I 2015-05-27 01:44:07 theanets.trainer:168 RmsProp 659 loss=147.548645 err=3.648905
I 2015-05-27 01:44:17 theanets.trainer:168 RmsProp 660 loss=147.770905 err=3.991383
I 2015-05-27 01:44:17 theanets.trainer:168 validation 66 loss=1503.580688 err=1359.859253 *
I 2015-05-27 01:44:27 theanets.trainer:168 RmsProp 661 loss=147.181656 err=3.525724
I 2015-05-27 01:44:38 theanets.trainer:168 RmsProp 662 loss=147.597687 err=4.061919
I 2015-05-27 01:44:48 theanets.trainer:168 RmsProp 663 loss=147.171127 err=3.756287
I 2015-05-27 01:44:58 theanets.trainer:168 RmsProp 664 loss=147.217743 err=3.925051
I 2015-05-27 01:45:08 theanets.trainer:168 RmsProp 665 loss=146.947189 err=3.776362
I 2015-05-27 01:45:18 theanets.trainer:168 RmsProp 666 loss=146.557053 err=3.513727
I 2015-05-27 01:45:28 theanets.trainer:168 RmsProp 667 loss=146.914139 err=3.991912
I 2015-05-27 01:45:39 theanets.trainer:168 RmsProp 668 loss=146.991379 err=4.183787
I 2015-05-27 01:45:49 theanets.trainer:168 RmsProp 669 loss=146.117523 err=3.431907
I 2015-05-27 01:46:00 theanets.trainer:168 RmsProp 670 loss=146.481140 err=3.914411
I 2015-05-27 01:46:00 theanets.trainer:168 validation 67 loss=1510.150024 err=1367.641602
I 2015-05-27 01:46:10 theanets.trainer:168 RmsProp 671 loss=146.358582 err=3.906224
I 2015-05-27 01:46:21 theanets.trainer:168 RmsProp 672 loss=146.374298 err=4.037823
I 2015-05-27 01:46:31 theanets.trainer:168 RmsProp 673 loss=145.896362 err=3.678321
I 2015-05-27 01:46:41 theanets.trainer:168 RmsProp 674 loss=145.919571 err=3.821515
I 2015-05-27 01:46:51 theanets.trainer:168 RmsProp 675 loss=145.644974 err=3.666205
I 2015-05-27 01:47:01 theanets.trainer:168 RmsProp 676 loss=145.752899 err=3.894028
I 2015-05-27 01:47:11 theanets.trainer:168 RmsProp 677 loss=145.275391 err=3.537444
I 2015-05-27 01:47:21 theanets.trainer:168 RmsProp 678 loss=145.382080 err=3.760611
I 2015-05-27 01:47:31 theanets.trainer:168 RmsProp 679 loss=144.979706 err=3.479587
I 2015-05-27 01:47:41 theanets.trainer:168 RmsProp 680 loss=145.113739 err=3.731020
I 2015-05-27 01:47:42 theanets.trainer:168 validation 68 loss=1505.125732 err=1363.815552
I 2015-05-27 01:47:52 theanets.trainer:168 RmsProp 681 loss=145.168503 err=3.903393
I 2015-05-27 01:48:02 theanets.trainer:168 RmsProp 682 loss=144.925201 err=3.777039
I 2015-05-27 01:48:12 theanets.trainer:168 RmsProp 683 loss=145.391388 err=4.354844
I 2015-05-27 01:48:22 theanets.trainer:168 RmsProp 684 loss=144.435822 err=3.511852
I 2015-05-27 01:48:32 theanets.trainer:168 RmsProp 685 loss=144.773605 err=3.965115
I 2015-05-27 01:48:42 theanets.trainer:168 RmsProp 686 loss=144.251205 err=3.558676
I 2015-05-27 01:48:52 theanets.trainer:168 RmsProp 687 loss=144.544846 err=3.968713
I 2015-05-27 01:49:03 theanets.trainer:168 RmsProp 688 loss=144.122833 err=3.658017
I 2015-05-27 01:49:13 theanets.trainer:168 RmsProp 689 loss=143.822495 err=3.473586
I 2015-05-27 01:49:23 theanets.trainer:168 RmsProp 690 loss=144.101562 err=3.870203
I 2015-05-27 01:49:23 theanets.trainer:168 validation 69 loss=1495.014404 err=1354.841797 *
I 2015-05-27 01:49:33 theanets.trainer:168 RmsProp 691 loss=143.857910 err=3.739021
I 2015-05-27 01:49:43 theanets.trainer:168 RmsProp 692 loss=143.656342 err=3.654069
I 2015-05-27 01:49:53 theanets.trainer:168 RmsProp 693 loss=143.519073 err=3.632151
I 2015-05-27 01:50:03 theanets.trainer:168 RmsProp 694 loss=143.698166 err=3.919613
I 2015-05-27 01:50:13 theanets.trainer:168 RmsProp 695 loss=143.377213 err=3.713364
I 2015-05-27 01:50:23 theanets.trainer:168 RmsProp 696 loss=143.306122 err=3.753935
I 2015-05-27 01:50:32 theanets.trainer:168 RmsProp 697 loss=143.355255 err=3.916882
I 2015-05-27 01:50:42 theanets.trainer:168 RmsProp 698 loss=142.939880 err=3.610934
I 2015-05-27 01:50:52 theanets.trainer:168 RmsProp 699 loss=142.732025 err=3.520299
I 2015-05-27 01:51:01 theanets.trainer:168 RmsProp 700 loss=143.143875 err=4.037232
I 2015-05-27 01:51:02 theanets.trainer:168 validation 70 loss=1499.775757 err=1360.725220
I 2015-05-27 01:51:12 theanets.trainer:168 RmsProp 701 loss=142.489365 err=3.495750
I 2015-05-27 01:51:22 theanets.trainer:168 RmsProp 702 loss=142.640915 err=3.762202
I 2015-05-27 01:51:32 theanets.trainer:168 RmsProp 703 loss=142.244736 err=3.475612
I 2015-05-27 01:51:43 theanets.trainer:168 RmsProp 704 loss=142.547241 err=3.889467
I 2015-05-27 01:51:53 theanets.trainer:168 RmsProp 705 loss=142.305267 err=3.760503
I 2015-05-27 01:52:03 theanets.trainer:168 RmsProp 706 loss=142.005157 err=3.574136
I 2015-05-27 01:52:13 theanets.trainer:168 RmsProp 707 loss=141.975586 err=3.657332
I 2015-05-27 01:52:24 theanets.trainer:168 RmsProp 708 loss=141.949997 err=3.743889
I 2015-05-27 01:52:34 theanets.trainer:168 RmsProp 709 loss=141.534531 err=3.440739
I 2015-05-27 01:52:44 theanets.trainer:168 RmsProp 710 loss=141.609192 err=3.621004
I 2015-05-27 01:52:45 theanets.trainer:168 validation 71 loss=1497.420044 err=1359.487671
I 2015-05-27 01:52:54 theanets.trainer:168 RmsProp 711 loss=141.617279 err=3.743423
I 2015-05-27 01:53:04 theanets.trainer:168 RmsProp 712 loss=141.384781 err=3.620986
I 2015-05-27 01:53:14 theanets.trainer:168 RmsProp 713 loss=141.161926 err=3.512658
I 2015-05-27 01:53:24 theanets.trainer:168 RmsProp 714 loss=141.255661 err=3.720438
I 2015-05-27 01:53:34 theanets.trainer:168 RmsProp 715 loss=141.052078 err=3.625552
I 2015-05-27 01:53:44 theanets.trainer:168 RmsProp 716 loss=140.805054 err=3.494387
I 2015-05-27 01:53:54 theanets.trainer:168 RmsProp 717 loss=141.061142 err=3.864120
I 2015-05-27 01:54:04 theanets.trainer:168 RmsProp 718 loss=140.481796 err=3.395928
I 2015-05-27 01:54:14 theanets.trainer:168 RmsProp 719 loss=140.838242 err=3.863010
I 2015-05-27 01:54:24 theanets.trainer:168 RmsProp 720 loss=140.866913 err=3.996240
I 2015-05-27 01:54:25 theanets.trainer:168 validation 72 loss=1490.654419 err=1353.843628 *
I 2015-05-27 01:54:35 theanets.trainer:168 RmsProp 721 loss=140.259995 err=3.501078
I 2015-05-27 01:54:45 theanets.trainer:168 RmsProp 722 loss=140.194183 err=3.547101
I 2015-05-27 01:54:55 theanets.trainer:168 RmsProp 723 loss=140.347244 err=3.804284
I 2015-05-27 01:55:04 theanets.trainer:168 RmsProp 724 loss=140.319397 err=3.877585
I 2015-05-27 01:55:14 theanets.trainer:168 RmsProp 725 loss=139.744858 err=3.412773
I 2015-05-27 01:55:24 theanets.trainer:168 RmsProp 726 loss=139.913040 err=3.687687
I 2015-05-27 01:55:35 theanets.trainer:168 RmsProp 727 loss=139.568161 err=3.451307
I 2015-05-27 01:55:45 theanets.trainer:168 RmsProp 728 loss=139.915283 err=3.904124
I 2015-05-27 01:55:55 theanets.trainer:168 RmsProp 729 loss=139.405182 err=3.504494
I 2015-05-27 01:56:04 theanets.trainer:168 RmsProp 730 loss=139.513290 err=3.719959
I 2015-05-27 01:56:05 theanets.trainer:168 validation 73 loss=1483.971191 err=1348.224976 *
I 2015-05-27 01:56:15 theanets.trainer:168 RmsProp 731 loss=139.742950 err=4.050012
I 2015-05-27 01:56:25 theanets.trainer:168 RmsProp 732 loss=139.016693 err=3.435090
I 2015-05-27 01:56:35 theanets.trainer:168 RmsProp 733 loss=139.067200 err=3.586907
I 2015-05-27 01:56:45 theanets.trainer:168 RmsProp 734 loss=139.049881 err=3.674713
I 2015-05-27 01:56:55 theanets.trainer:168 RmsProp 735 loss=139.056107 err=3.785969
I 2015-05-27 01:57:05 theanets.trainer:168 RmsProp 736 loss=138.444183 err=3.281394
I 2015-05-27 01:57:16 theanets.trainer:168 RmsProp 737 loss=138.710388 err=3.652457
I 2015-05-27 01:57:26 theanets.trainer:168 RmsProp 738 loss=138.733795 err=3.782482
I 2015-05-27 01:57:36 theanets.trainer:168 RmsProp 739 loss=138.783417 err=3.931478
I 2015-05-27 01:57:47 theanets.trainer:168 RmsProp 740 loss=138.235992 err=3.485767
I 2015-05-27 01:57:47 theanets.trainer:168 validation 74 loss=1482.361938 err=1347.676636 *
I 2015-05-27 01:57:57 theanets.trainer:168 RmsProp 741 loss=138.252609 err=3.614158
I 2015-05-27 01:58:07 theanets.trainer:168 RmsProp 742 loss=137.987122 err=3.453659
I 2015-05-27 01:58:17 theanets.trainer:168 RmsProp 743 loss=137.895599 err=3.466120
I 2015-05-27 01:58:27 theanets.trainer:168 RmsProp 744 loss=137.818115 err=3.493651
I 2015-05-27 01:58:38 theanets.trainer:168 RmsProp 745 loss=138.148560 err=3.925606
I 2015-05-27 01:58:48 theanets.trainer:168 RmsProp 746 loss=137.536926 err=3.422043
I 2015-05-27 01:58:58 theanets.trainer:168 RmsProp 747 loss=137.517380 err=3.506591
I 2015-05-27 01:59:09 theanets.trainer:168 RmsProp 748 loss=137.359238 err=3.448648
I 2015-05-27 01:59:19 theanets.trainer:168 RmsProp 749 loss=137.513031 err=3.705631
I 2015-05-27 01:59:29 theanets.trainer:168 RmsProp 750 loss=137.632401 err=3.925603
I 2015-05-27 01:59:30 theanets.trainer:168 validation 75 loss=1478.115234 err=1344.464478 *
I 2015-05-27 01:59:40 theanets.trainer:168 RmsProp 751 loss=137.087830 err=3.482547
I 2015-05-27 01:59:50 theanets.trainer:168 RmsProp 752 loss=136.874222 err=3.369183
I 2015-05-27 02:00:00 theanets.trainer:168 RmsProp 753 loss=137.042450 err=3.643908
I 2015-05-27 02:00:10 theanets.trainer:168 RmsProp 754 loss=136.832672 err=3.534551
I 2015-05-27 02:00:20 theanets.trainer:168 RmsProp 755 loss=136.605957 err=3.414663
I 2015-05-27 02:00:30 theanets.trainer:168 RmsProp 756 loss=136.772141 err=3.677324
I 2015-05-27 02:00:41 theanets.trainer:168 RmsProp 757 loss=136.494781 err=3.501287
I 2015-05-27 02:00:52 theanets.trainer:168 RmsProp 758 loss=136.391296 err=3.501820
I 2015-05-27 02:01:02 theanets.trainer:168 RmsProp 759 loss=136.275604 err=3.488734
I 2015-05-27 02:01:12 theanets.trainer:168 RmsProp 760 loss=136.345398 err=3.662059
I 2015-05-27 02:01:13 theanets.trainer:168 validation 76 loss=1481.230103 err=1348.600342
I 2015-05-27 02:01:23 theanets.trainer:168 RmsProp 761 loss=136.375580 err=3.790757
I 2015-05-27 02:01:33 theanets.trainer:168 RmsProp 762 loss=135.960556 err=3.478148
I 2015-05-27 02:01:43 theanets.trainer:168 RmsProp 763 loss=135.826019 err=3.445405
I 2015-05-27 02:01:53 theanets.trainer:168 RmsProp 764 loss=136.050522 err=3.768967
I 2015-05-27 02:02:03 theanets.trainer:168 RmsProp 765 loss=135.768158 err=3.588097
I 2015-05-27 02:02:13 theanets.trainer:168 RmsProp 766 loss=135.582123 err=3.498273
I 2015-05-27 02:02:23 theanets.trainer:168 RmsProp 767 loss=135.592148 err=3.608591
I 2015-05-27 02:02:34 theanets.trainer:168 RmsProp 768 loss=135.350632 err=3.465412
I 2015-05-27 02:02:44 theanets.trainer:168 RmsProp 769 loss=135.419006 err=3.633863
I 2015-05-27 02:02:55 theanets.trainer:168 RmsProp 770 loss=135.044754 err=3.361624
I 2015-05-27 02:02:55 theanets.trainer:168 validation 77 loss=1471.674683 err=1340.044678 *
I 2015-05-27 02:03:05 theanets.trainer:168 RmsProp 771 loss=135.298859 err=3.716569
I 2015-05-27 02:03:15 theanets.trainer:168 RmsProp 772 loss=135.226410 err=3.742860
I 2015-05-27 02:03:26 theanets.trainer:168 RmsProp 773 loss=134.932419 err=3.546972
I 2015-05-27 02:03:36 theanets.trainer:168 RmsProp 774 loss=134.578201 err=3.292342
I 2015-05-27 02:03:46 theanets.trainer:168 RmsProp 775 loss=135.160492 err=3.967962
I 2015-05-27 02:03:57 theanets.trainer:168 RmsProp 776 loss=134.525055 err=3.434970
I 2015-05-27 02:04:07 theanets.trainer:168 RmsProp 777 loss=134.462006 err=3.464877
I 2015-05-27 02:04:17 theanets.trainer:168 RmsProp 778 loss=134.263321 err=3.364002
I 2015-05-27 02:04:28 theanets.trainer:168 RmsProp 779 loss=134.516068 err=3.715581
I 2015-05-27 02:04:38 theanets.trainer:168 RmsProp 780 loss=134.225128 err=3.521078
I 2015-05-27 02:04:38 theanets.trainer:168 validation 78 loss=1470.976318 err=1340.327026 *
I 2015-05-27 02:04:49 theanets.trainer:168 RmsProp 781 loss=134.082275 err=3.476657
I 2015-05-27 02:04:59 theanets.trainer:168 RmsProp 782 loss=134.209320 err=3.701490
I 2015-05-27 02:05:10 theanets.trainer:168 RmsProp 783 loss=133.891083 err=3.482677
I 2015-05-27 02:05:20 theanets.trainer:168 RmsProp 784 loss=133.849091 err=3.533838
I 2015-05-27 02:05:31 theanets.trainer:168 RmsProp 785 loss=133.726410 err=3.509297
I 2015-05-27 02:05:41 theanets.trainer:168 RmsProp 786 loss=133.596832 err=3.476481
I 2015-05-27 02:05:52 theanets.trainer:168 RmsProp 787 loss=133.380463 err=3.354862
I 2015-05-27 02:06:02 theanets.trainer:168 RmsProp 788 loss=133.612091 err=3.682126
I 2015-05-27 02:06:13 theanets.trainer:168 RmsProp 789 loss=133.218460 err=3.384595
I 2015-05-27 02:06:23 theanets.trainer:168 RmsProp 790 loss=133.273300 err=3.534798
I 2015-05-27 02:06:23 theanets.trainer:168 validation 79 loss=1472.080200 err=1342.395020
I 2015-05-27 02:06:34 theanets.trainer:168 RmsProp 791 loss=133.366241 err=3.722387
I 2015-05-27 02:06:44 theanets.trainer:168 RmsProp 792 loss=132.918564 err=3.374296
I 2015-05-27 02:06:54 theanets.trainer:168 RmsProp 793 loss=132.809738 err=3.364090
I 2015-05-27 02:07:05 theanets.trainer:168 RmsProp 794 loss=133.070786 err=3.718771
I 2015-05-27 02:07:15 theanets.trainer:168 RmsProp 795 loss=132.656937 err=3.405804
I 2015-05-27 02:07:26 theanets.trainer:168 RmsProp 796 loss=132.481110 err=3.328444
I 2015-05-27 02:07:36 theanets.trainer:168 RmsProp 797 loss=132.787430 err=3.731505
I 2015-05-27 02:07:46 theanets.trainer:168 RmsProp 798 loss=132.193527 err=3.235121
I 2015-05-27 02:07:56 theanets.trainer:168 RmsProp 799 loss=132.296295 err=3.434956
I 2015-05-27 02:08:07 theanets.trainer:168 RmsProp 800 loss=132.519836 err=3.750037
I 2015-05-27 02:08:07 theanets.trainer:168 validation 80 loss=1463.180298 err=1334.456055 *
I 2015-05-27 02:08:17 theanets.trainer:168 RmsProp 801 loss=132.246826 err=3.571788
I 2015-05-27 02:08:28 theanets.trainer:168 RmsProp 802 loss=131.902817 err=3.326233
I 2015-05-27 02:08:38 theanets.trainer:168 RmsProp 803 loss=132.126617 err=3.646169
I 2015-05-27 02:08:48 theanets.trainer:168 RmsProp 804 loss=132.008377 err=3.618881
I 2015-05-27 02:08:59 theanets.trainer:168 RmsProp 805 loss=131.689514 err=3.392269
I 2015-05-27 02:09:09 theanets.trainer:168 RmsProp 806 loss=131.588165 err=3.386452
I 2015-05-27 02:09:19 theanets.trainer:168 RmsProp 807 loss=131.676285 err=3.572454
I 2015-05-27 02:09:30 theanets.trainer:168 RmsProp 808 loss=131.450317 err=3.438229
I 2015-05-27 02:09:40 theanets.trainer:168 RmsProp 809 loss=131.237686 err=3.320895
I 2015-05-27 02:09:50 theanets.trainer:168 RmsProp 810 loss=131.263901 err=3.442772
I 2015-05-27 02:09:50 theanets.trainer:168 validation 81 loss=1461.658813 err=1333.885620 *
I 2015-05-27 02:10:00 theanets.trainer:168 RmsProp 811 loss=131.189545 err=3.461873
I 2015-05-27 02:10:10 theanets.trainer:168 RmsProp 812 loss=131.288483 err=3.653234
I 2015-05-27 02:10:20 theanets.trainer:168 RmsProp 813 loss=131.077713 err=3.532741
I 2015-05-27 02:10:30 theanets.trainer:168 RmsProp 814 loss=130.733582 err=3.282106
I 2015-05-27 02:10:40 theanets.trainer:168 RmsProp 815 loss=131.031830 err=3.671812
I 2015-05-27 02:10:50 theanets.trainer:168 RmsProp 816 loss=131.073212 err=3.800538
I 2015-05-27 02:11:01 theanets.trainer:168 RmsProp 817 loss=130.353134 err=3.172865
I 2015-05-27 02:11:11 theanets.trainer:168 RmsProp 818 loss=130.502350 err=3.414297
I 2015-05-27 02:11:21 theanets.trainer:168 RmsProp 819 loss=130.651413 err=3.652377
I 2015-05-27 02:11:31 theanets.trainer:168 RmsProp 820 loss=130.460724 err=3.550359
I 2015-05-27 02:11:32 theanets.trainer:168 validation 82 loss=1457.019897 err=1330.167603 *
I 2015-05-27 02:11:42 theanets.trainer:168 RmsProp 821 loss=129.779617 err=2.966556
I 2015-05-27 02:11:52 theanets.trainer:168 RmsProp 822 loss=130.496796 err=3.765721
I 2015-05-27 02:12:03 theanets.trainer:168 RmsProp 823 loss=130.189728 err=3.550720
I 2015-05-27 02:12:13 theanets.trainer:168 RmsProp 824 loss=130.173279 err=3.627407
I 2015-05-27 02:12:23 theanets.trainer:168 RmsProp 825 loss=129.969147 err=3.513498
I 2015-05-27 02:12:33 theanets.trainer:168 RmsProp 826 loss=129.515961 err=3.150711
I 2015-05-27 02:12:44 theanets.trainer:168 RmsProp 827 loss=129.993866 err=3.716086
I 2015-05-27 02:12:54 theanets.trainer:168 RmsProp 828 loss=129.543488 err=3.352785
I 2015-05-27 02:13:05 theanets.trainer:168 RmsProp 829 loss=129.154770 err=3.052624
I 2015-05-27 02:13:15 theanets.trainer:168 RmsProp 830 loss=130.021133 err=4.005273
I 2015-05-27 02:13:16 theanets.trainer:168 validation 83 loss=1457.738281 err=1331.769531
I 2015-05-27 02:13:26 theanets.trainer:168 RmsProp 831 loss=129.568390 err=3.641100
I 2015-05-27 02:13:36 theanets.trainer:168 RmsProp 832 loss=129.239090 err=3.403693
I 2015-05-27 02:13:46 theanets.trainer:168 RmsProp 833 loss=129.155426 err=3.407747
I 2015-05-27 02:13:57 theanets.trainer:168 RmsProp 834 loss=128.954819 err=3.300297
I 2015-05-27 02:14:07 theanets.trainer:168 RmsProp 835 loss=129.227585 err=3.659796
I 2015-05-27 02:14:17 theanets.trainer:168 RmsProp 836 loss=128.987473 err=3.505188
I 2015-05-27 02:14:27 theanets.trainer:168 RmsProp 837 loss=128.720367 err=3.325223
I 2015-05-27 02:14:37 theanets.trainer:168 RmsProp 838 loss=129.254791 err=3.939416
I 2015-05-27 02:14:47 theanets.trainer:168 RmsProp 839 loss=128.542816 err=3.316031
I 2015-05-27 02:14:57 theanets.trainer:168 RmsProp 840 loss=128.640579 err=3.499906
I 2015-05-27 02:14:58 theanets.trainer:168 validation 84 loss=1455.150269 err=1330.054565 *
I 2015-05-27 02:15:08 theanets.trainer:168 RmsProp 841 loss=128.381744 err=3.326633
I 2015-05-27 02:15:18 theanets.trainer:168 RmsProp 842 loss=128.350586 err=3.385127
I 2015-05-27 02:15:28 theanets.trainer:168 RmsProp 843 loss=128.029755 err=3.154248
I 2015-05-27 02:15:38 theanets.trainer:168 RmsProp 844 loss=128.681885 err=3.888997
I 2015-05-27 02:15:48 theanets.trainer:168 RmsProp 845 loss=128.239792 err=3.529167
I 2015-05-27 02:15:57 theanets.trainer:168 RmsProp 846 loss=127.832092 err=3.210333
I 2015-05-27 02:16:06 theanets.trainer:168 RmsProp 847 loss=127.932518 err=3.397489
I 2015-05-27 02:16:15 theanets.trainer:168 RmsProp 848 loss=127.793015 err=3.345725
I 2015-05-27 02:16:23 theanets.trainer:168 RmsProp 849 loss=127.627403 err=3.269326
I 2015-05-27 02:16:31 theanets.trainer:168 RmsProp 850 loss=127.549599 err=3.279161
I 2015-05-27 02:16:31 theanets.trainer:168 validation 85 loss=1454.498657 err=1330.276123 *
I 2015-05-27 02:16:39 theanets.trainer:168 RmsProp 851 loss=127.622910 err=3.443110
I 2015-05-27 02:16:47 theanets.trainer:168 RmsProp 852 loss=127.511368 err=3.417766
I 2015-05-27 02:16:55 theanets.trainer:168 RmsProp 853 loss=127.332497 err=3.326532
I 2015-05-27 02:17:03 theanets.trainer:168 RmsProp 854 loss=127.284081 err=3.366149
I 2015-05-27 02:17:11 theanets.trainer:168 RmsProp 855 loss=127.286682 err=3.453707
I 2015-05-27 02:17:19 theanets.trainer:168 RmsProp 856 loss=127.132812 err=3.384132
I 2015-05-27 02:17:27 theanets.trainer:168 RmsProp 857 loss=127.020790 err=3.357144
I 2015-05-27 02:17:36 theanets.trainer:168 RmsProp 858 loss=126.815895 err=3.239929
I 2015-05-27 02:17:43 theanets.trainer:168 RmsProp 859 loss=126.852638 err=3.363134
I 2015-05-27 02:17:51 theanets.trainer:168 RmsProp 860 loss=127.336388 err=3.922810
I 2015-05-27 02:17:51 theanets.trainer:168 validation 86 loss=1450.058838 err=1326.698120 *
I 2015-05-27 02:17:59 theanets.trainer:168 RmsProp 861 loss=126.512718 err=3.184516
I 2015-05-27 02:18:06 theanets.trainer:168 RmsProp 862 loss=126.719482 err=3.472874
I 2015-05-27 02:18:13 theanets.trainer:168 RmsProp 863 loss=126.789940 err=3.622340
I 2015-05-27 02:18:21 theanets.trainer:168 RmsProp 864 loss=126.288841 err=3.205436
I 2015-05-27 02:18:28 theanets.trainer:168 RmsProp 865 loss=126.779991 err=3.778849
I 2015-05-27 02:18:35 theanets.trainer:168 RmsProp 866 loss=126.183884 err=3.267178
I 2015-05-27 02:18:42 theanets.trainer:168 RmsProp 867 loss=125.943642 err=3.114636
I 2015-05-27 02:18:50 theanets.trainer:168 RmsProp 868 loss=126.728355 err=3.977210
I 2015-05-27 02:18:58 theanets.trainer:168 RmsProp 869 loss=125.750916 err=3.086426
I 2015-05-27 02:19:05 theanets.trainer:168 RmsProp 870 loss=126.027565 err=3.443468
I 2015-05-27 02:19:06 theanets.trainer:168 validation 87 loss=1452.249023 err=1329.694946
I 2015-05-27 02:19:13 theanets.trainer:168 RmsProp 871 loss=126.036682 err=3.529749
I 2015-05-27 02:19:20 theanets.trainer:168 RmsProp 872 loss=125.455994 err=3.036759
I 2015-05-27 02:19:27 theanets.trainer:168 RmsProp 873 loss=126.006577 err=3.669846
I 2015-05-27 02:19:35 theanets.trainer:168 RmsProp 874 loss=125.742226 err=3.483258
I 2015-05-27 02:19:43 theanets.trainer:168 RmsProp 875 loss=125.787766 err=3.608479
I 2015-05-27 02:19:51 theanets.trainer:168 RmsProp 876 loss=125.450607 err=3.353577
I 2015-05-27 02:19:59 theanets.trainer:168 RmsProp 877 loss=125.323631 err=3.307724
I 2015-05-27 02:20:07 theanets.trainer:168 RmsProp 878 loss=125.587242 err=3.648355
I 2015-05-27 02:20:15 theanets.trainer:168 RmsProp 879 loss=125.462318 err=3.603696
I 2015-05-27 02:20:22 theanets.trainer:168 RmsProp 880 loss=125.001511 err=3.220517
I 2015-05-27 02:20:23 theanets.trainer:168 validation 88 loss=1442.255859 err=1320.523315 *
I 2015-05-27 02:20:31 theanets.trainer:168 RmsProp 881 loss=125.137978 err=3.438101
I 2015-05-27 02:20:39 theanets.trainer:168 RmsProp 882 loss=124.907104 err=3.292635
I 2015-05-27 02:20:47 theanets.trainer:168 RmsProp 883 loss=124.920998 err=3.384745
I 2015-05-27 02:20:55 theanets.trainer:168 RmsProp 884 loss=124.976486 err=3.520718
I 2015-05-27 02:21:03 theanets.trainer:168 RmsProp 885 loss=124.678940 err=3.297211
I 2015-05-27 02:21:11 theanets.trainer:168 RmsProp 886 loss=124.562172 err=3.261322
I 2015-05-27 02:21:19 theanets.trainer:168 RmsProp 887 loss=124.535057 err=3.318988
I 2015-05-27 02:21:27 theanets.trainer:168 RmsProp 888 loss=124.620461 err=3.487115
I 2015-05-27 02:21:34 theanets.trainer:168 RmsProp 889 loss=124.404503 err=3.348881
I 2015-05-27 02:21:41 theanets.trainer:168 RmsProp 890 loss=124.640518 err=3.660793
I 2015-05-27 02:21:42 theanets.trainer:168 validation 89 loss=1435.219482 err=1314.282593 *
I 2015-05-27 02:21:49 theanets.trainer:168 RmsProp 891 loss=124.183571 err=3.282626
I 2015-05-27 02:21:57 theanets.trainer:168 RmsProp 892 loss=124.230446 err=3.408393
I 2015-05-27 02:22:04 theanets.trainer:168 RmsProp 893 loss=123.922852 err=3.185341
I 2015-05-27 02:22:11 theanets.trainer:168 RmsProp 894 loss=124.011002 err=3.355328
I 2015-05-27 02:22:20 theanets.trainer:168 RmsProp 895 loss=123.922165 err=3.341442
I 2015-05-27 02:22:28 theanets.trainer:168 RmsProp 896 loss=123.850609 err=3.346119
I 2015-05-27 02:22:35 theanets.trainer:168 RmsProp 897 loss=123.286697 err=2.864630
I 2015-05-27 02:22:43 theanets.trainer:168 RmsProp 898 loss=124.352341 err=4.005082
I 2015-05-27 02:22:51 theanets.trainer:168 RmsProp 899 loss=123.750572 err=3.479755
I 2015-05-27 02:22:59 theanets.trainer:168 RmsProp 900 loss=123.459656 err=3.270404
I 2015-05-27 02:22:59 theanets.trainer:168 validation 90 loss=1434.573608 err=1314.426514 *
I 2015-05-27 02:23:07 theanets.trainer:168 RmsProp 901 loss=123.489700 err=3.380653
I 2015-05-27 02:23:15 theanets.trainer:168 RmsProp 902 loss=123.444565 err=3.413636
I 2015-05-27 02:23:23 theanets.trainer:168 RmsProp 903 loss=123.123314 err=3.171432
I 2015-05-27 02:23:30 theanets.trainer:168 RmsProp 904 loss=123.179100 err=3.301439
I 2015-05-27 02:23:37 theanets.trainer:168 RmsProp 905 loss=123.119263 err=3.317935
I 2015-05-27 02:23:44 theanets.trainer:168 RmsProp 906 loss=123.212631 err=3.484518
I 2015-05-27 02:23:51 theanets.trainer:168 RmsProp 907 loss=123.104149 err=3.454053
I 2015-05-27 02:23:59 theanets.trainer:168 RmsProp 908 loss=123.027306 err=3.453612
I 2015-05-27 02:24:07 theanets.trainer:168 RmsProp 909 loss=123.014931 err=3.517616
I 2015-05-27 02:24:15 theanets.trainer:168 RmsProp 910 loss=122.686424 err=3.261631
I 2015-05-27 02:24:16 theanets.trainer:168 validation 91 loss=1434.955933 err=1315.575806
I 2015-05-27 02:24:23 theanets.trainer:168 RmsProp 911 loss=122.738197 err=3.390226
I 2015-05-27 02:24:30 theanets.trainer:168 RmsProp 912 loss=122.778542 err=3.508689
I 2015-05-27 02:24:38 theanets.trainer:168 RmsProp 913 loss=122.139465 err=2.947832
I 2015-05-27 02:24:46 theanets.trainer:168 RmsProp 914 loss=123.087082 err=3.965425
I 2015-05-27 02:24:54 theanets.trainer:168 RmsProp 915 loss=122.240883 err=3.196131
I 2015-05-27 02:25:02 theanets.trainer:168 RmsProp 916 loss=122.303429 err=3.334457
I 2015-05-27 02:25:09 theanets.trainer:168 RmsProp 917 loss=122.271240 err=3.377095
I 2015-05-27 02:25:15 theanets.trainer:168 RmsProp 918 loss=122.444458 err=3.620609
I 2015-05-27 02:25:23 theanets.trainer:168 RmsProp 919 loss=122.225464 err=3.478805
I 2015-05-27 02:25:29 theanets.trainer:168 RmsProp 920 loss=121.931435 err=3.255565
I 2015-05-27 02:25:30 theanets.trainer:168 validation 92 loss=1426.052368 err=1307.421753 *
I 2015-05-27 02:25:37 theanets.trainer:168 RmsProp 921 loss=121.994949 err=3.397302
I 2015-05-27 02:25:44 theanets.trainer:168 RmsProp 922 loss=121.905067 err=3.382608
I 2015-05-27 02:25:52 theanets.trainer:168 RmsProp 923 loss=121.491722 err=3.046428
I 2015-05-27 02:25:59 theanets.trainer:168 RmsProp 924 loss=121.702660 err=3.330894
I 2015-05-27 02:26:07 theanets.trainer:168 RmsProp 925 loss=121.670448 err=3.372247
I 2015-05-27 02:26:15 theanets.trainer:168 RmsProp 926 loss=121.578697 err=3.355483
I 2015-05-27 02:26:22 theanets.trainer:168 RmsProp 927 loss=121.454468 err=3.306443
I 2015-05-27 02:26:28 theanets.trainer:168 RmsProp 928 loss=121.280861 err=3.208910
I 2015-05-27 02:26:35 theanets.trainer:168 RmsProp 929 loss=121.236740 err=3.234399
I 2015-05-27 02:26:41 theanets.trainer:168 RmsProp 930 loss=121.220741 err=3.294069
I 2015-05-27 02:26:41 theanets.trainer:168 validation 93 loss=1425.942383 err=1308.046875 *
I 2015-05-27 02:26:47 theanets.trainer:168 RmsProp 931 loss=121.145874 err=3.294749
I 2015-05-27 02:26:54 theanets.trainer:168 RmsProp 932 loss=121.040359 err=3.263982
I 2015-05-27 02:27:00 theanets.trainer:168 RmsProp 933 loss=121.071754 err=3.372940
I 2015-05-27 02:27:05 theanets.trainer:168 RmsProp 934 loss=120.752525 err=3.127629
I 2015-05-27 02:27:11 theanets.trainer:168 RmsProp 935 loss=120.897949 err=3.346959
I 2015-05-27 02:27:18 theanets.trainer:168 RmsProp 936 loss=120.840591 err=3.359112
I 2015-05-27 02:27:24 theanets.trainer:168 RmsProp 937 loss=120.680054 err=3.275737
I 2015-05-27 02:27:30 theanets.trainer:168 RmsProp 938 loss=120.483727 err=3.154042
I 2015-05-27 02:27:36 theanets.trainer:168 RmsProp 939 loss=120.859756 err=3.602962
I 2015-05-27 02:27:42 theanets.trainer:168 RmsProp 940 loss=120.362534 err=3.178519
I 2015-05-27 02:27:43 theanets.trainer:168 validation 94 loss=1420.689209 err=1303.544678 *
I 2015-05-27 02:27:49 theanets.trainer:168 RmsProp 941 loss=120.547958 err=3.433039
I 2015-05-27 02:27:55 theanets.trainer:168 RmsProp 942 loss=120.170425 err=3.131281
I 2015-05-27 02:28:01 theanets.trainer:168 RmsProp 943 loss=120.177711 err=3.208464
I 2015-05-27 02:28:07 theanets.trainer:168 RmsProp 944 loss=120.310776 err=3.414301
I 2015-05-27 02:28:14 theanets.trainer:168 RmsProp 945 loss=120.107872 err=3.284238
I 2015-05-27 02:28:20 theanets.trainer:168 RmsProp 946 loss=119.945694 err=3.198488
I 2015-05-27 02:28:25 theanets.trainer:168 RmsProp 947 loss=119.921875 err=3.249802
I 2015-05-27 02:28:31 theanets.trainer:168 RmsProp 948 loss=119.726295 err=3.131737
I 2015-05-27 02:28:37 theanets.trainer:168 RmsProp 949 loss=120.221756 err=3.694138
I 2015-05-27 02:28:43 theanets.trainer:168 RmsProp 950 loss=119.411011 err=2.959354
I 2015-05-27 02:28:44 theanets.trainer:168 validation 95 loss=1422.050171 err=1305.642212
I 2015-05-27 02:28:50 theanets.trainer:168 RmsProp 951 loss=119.545326 err=3.167095
I 2015-05-27 02:28:57 theanets.trainer:168 RmsProp 952 loss=119.738708 err=3.427555
I 2015-05-27 02:29:03 theanets.trainer:168 RmsProp 953 loss=119.819275 err=3.577821
I 2015-05-27 02:29:09 theanets.trainer:168 RmsProp 954 loss=119.612991 err=3.442595
I 2015-05-27 02:29:15 theanets.trainer:168 RmsProp 955 loss=119.441185 err=3.343322
I 2015-05-27 02:29:21 theanets.trainer:168 RmsProp 956 loss=119.024643 err=2.997779
I 2015-05-27 02:29:27 theanets.trainer:168 RmsProp 957 loss=119.137535 err=3.178536
I 2015-05-27 02:29:33 theanets.trainer:168 RmsProp 958 loss=119.532425 err=3.643466
I 2015-05-27 02:29:39 theanets.trainer:168 RmsProp 959 loss=119.255417 err=3.439474
I 2015-05-27 02:29:45 theanets.trainer:168 RmsProp 960 loss=119.068947 err=3.325157
I 2015-05-27 02:29:45 theanets.trainer:168 validation 96 loss=1414.778564 err=1299.077393 *
I 2015-05-27 02:29:51 theanets.trainer:168 RmsProp 961 loss=118.667068 err=2.997371
I 2015-05-27 02:29:57 theanets.trainer:168 RmsProp 962 loss=118.770096 err=3.172931
I 2015-05-27 02:30:03 theanets.trainer:168 RmsProp 963 loss=118.339500 err=2.817957
I 2015-05-27 02:30:09 theanets.trainer:168 RmsProp 964 loss=119.019913 err=3.562870
I 2015-05-27 02:30:16 theanets.trainer:168 RmsProp 965 loss=118.398422 err=3.021953
I 2015-05-27 02:30:22 theanets.trainer:168 RmsProp 966 loss=119.003738 err=3.696882
I 2015-05-27 02:30:28 theanets.trainer:168 RmsProp 967 loss=117.896095 err=2.663097
I 2015-05-27 02:30:34 theanets.trainer:168 RmsProp 968 loss=118.878197 err=3.713862
I 2015-05-27 02:30:41 theanets.trainer:168 RmsProp 969 loss=118.600174 err=3.500717
I 2015-05-27 02:30:47 theanets.trainer:168 RmsProp 970 loss=118.253311 err=3.225960
I 2015-05-27 02:30:47 theanets.trainer:168 validation 97 loss=1411.656006 err=1296.672607 *
I 2015-05-27 02:30:53 theanets.trainer:168 RmsProp 971 loss=118.249290 err=3.292314
I 2015-05-27 02:30:59 theanets.trainer:168 RmsProp 972 loss=118.176346 err=3.292506
I 2015-05-27 02:31:05 theanets.trainer:168 RmsProp 973 loss=117.956070 err=3.141674
I 2015-05-27 02:31:11 theanets.trainer:168 RmsProp 974 loss=117.919044 err=3.173610
I 2015-05-27 02:31:17 theanets.trainer:168 RmsProp 975 loss=117.976852 err=3.303315
I 2015-05-27 02:31:23 theanets.trainer:168 RmsProp 976 loss=117.775612 err=3.172393
I 2015-05-27 02:31:29 theanets.trainer:168 RmsProp 977 loss=117.823509 err=3.288342
I 2015-05-27 02:31:35 theanets.trainer:168 RmsProp 978 loss=117.727921 err=3.259565
I 2015-05-27 02:31:41 theanets.trainer:168 RmsProp 979 loss=117.606155 err=3.209206
I 2015-05-27 02:31:47 theanets.trainer:168 RmsProp 980 loss=117.492897 err=3.164644
I 2015-05-27 02:31:47 theanets.trainer:168 validation 98 loss=1408.931396 err=1294.649414 *
I 2015-05-27 02:31:53 theanets.trainer:168 RmsProp 981 loss=117.586594 err=3.332384
I 2015-05-27 02:31:59 theanets.trainer:168 RmsProp 982 loss=117.587318 err=3.399744
I 2015-05-27 02:32:06 theanets.trainer:168 RmsProp 983 loss=117.147034 err=3.029972
I 2015-05-27 02:32:12 theanets.trainer:168 RmsProp 984 loss=117.402931 err=3.356475
I 2015-05-27 02:32:18 theanets.trainer:168 RmsProp 985 loss=117.163574 err=3.185266
I 2015-05-27 02:32:25 theanets.trainer:168 RmsProp 986 loss=117.047302 err=3.138179
I 2015-05-27 02:32:30 theanets.trainer:168 RmsProp 987 loss=117.035141 err=3.191893
I 2015-05-27 02:32:37 theanets.trainer:168 RmsProp 988 loss=116.990883 err=3.217803
I 2015-05-27 02:32:43 theanets.trainer:168 RmsProp 989 loss=116.931839 err=3.225699
I 2015-05-27 02:32:49 theanets.trainer:168 RmsProp 990 loss=116.747147 err=3.109997
I 2015-05-27 02:32:50 theanets.trainer:168 validation 99 loss=1406.721802 err=1293.126465 *
I 2015-05-27 02:32:55 theanets.trainer:168 RmsProp 991 loss=116.847572 err=3.280420
I 2015-05-27 02:33:01 theanets.trainer:168 RmsProp 992 loss=116.780197 err=3.279061
I 2015-05-27 02:33:07 theanets.trainer:168 RmsProp 993 loss=116.594055 err=3.165601
I 2015-05-27 02:33:13 theanets.trainer:168 RmsProp 994 loss=116.594337 err=3.234293
I 2015-05-27 02:33:19 theanets.trainer:168 RmsProp 995 loss=116.443436 err=3.147335
I 2015-05-27 02:33:25 theanets.trainer:168 RmsProp 996 loss=116.500107 err=3.269970
I 2015-05-27 02:33:31 theanets.trainer:168 RmsProp 997 loss=116.726891 err=3.560118
I 2015-05-27 02:33:37 theanets.trainer:168 RmsProp 998 loss=116.375229 err=3.277169
I 2015-05-27 02:33:42 theanets.trainer:168 RmsProp 999 loss=116.024857 err=2.996814
I 2015-05-27 02:33:49 theanets.trainer:168 RmsProp 1000 loss=116.578102 err=3.611701
I 2015-05-27 02:33:49 theanets.trainer:168 validation 100 loss=1405.223999 err=1292.293579 *
I 2015-05-27 02:33:55 theanets.trainer:168 RmsProp 1001 loss=115.935143 err=3.035410
I 2015-05-27 02:34:01 theanets.trainer:168 RmsProp 1002 loss=115.804199 err=2.973924
I 2015-05-27 02:34:07 theanets.trainer:168 RmsProp 1003 loss=116.389099 err=3.617084
I 2015-05-27 02:34:13 theanets.trainer:168 RmsProp 1004 loss=115.738403 err=3.037204
I 2015-05-27 02:34:19 theanets.trainer:168 RmsProp 1005 loss=115.991722 err=3.358369
I 2015-05-27 02:34:25 theanets.trainer:168 RmsProp 1006 loss=115.849075 err=3.279777
I 2015-05-27 02:34:31 theanets.trainer:168 RmsProp 1007 loss=115.597977 err=3.096023
I 2015-05-27 02:34:37 theanets.trainer:168 RmsProp 1008 loss=115.658630 err=3.222451
I 2015-05-27 02:34:44 theanets.trainer:168 RmsProp 1009 loss=115.315186 err=2.942560
I 2015-05-27 02:34:51 theanets.trainer:168 RmsProp 1010 loss=115.592186 err=3.285201
I 2015-05-27 02:34:51 theanets.trainer:168 validation 101 loss=1396.694580 err=1284.423706 *
I 2015-05-27 02:34:57 theanets.trainer:168 RmsProp 1011 loss=115.602524 err=3.358437
I 2015-05-27 02:35:03 theanets.trainer:168 RmsProp 1012 loss=115.849464 err=3.666255
I 2015-05-27 02:35:09 theanets.trainer:168 RmsProp 1013 loss=115.141556 err=3.025774
I 2015-05-27 02:35:14 theanets.trainer:168 RmsProp 1014 loss=115.232788 err=3.183853
I 2015-05-27 02:35:20 theanets.trainer:168 RmsProp 1015 loss=115.139442 err=3.153683
I 2015-05-27 02:35:26 theanets.trainer:168 RmsProp 1016 loss=115.281311 err=3.359987
I 2015-05-27 02:35:33 theanets.trainer:168 RmsProp 1017 loss=114.974754 err=3.120465
I 2015-05-27 02:35:38 theanets.trainer:168 RmsProp 1018 loss=114.932274 err=3.143803
I 2015-05-27 02:35:45 theanets.trainer:168 RmsProp 1019 loss=114.901207 err=3.180921
I 2015-05-27 02:35:51 theanets.trainer:168 RmsProp 1020 loss=114.905106 err=3.245621
I 2015-05-27 02:35:51 theanets.trainer:168 validation 102 loss=1399.884277 err=1288.253906
I 2015-05-27 02:35:57 theanets.trainer:168 RmsProp 1021 loss=115.127548 err=3.531468
I 2015-05-27 02:36:04 theanets.trainer:168 RmsProp 1022 loss=114.550453 err=3.021404
I 2015-05-27 02:36:10 theanets.trainer:168 RmsProp 1023 loss=114.730530 err=3.267787
I 2015-05-27 02:36:16 theanets.trainer:168 RmsProp 1024 loss=114.675293 err=3.275436
I 2015-05-27 02:36:23 theanets.trainer:168 RmsProp 1025 loss=114.290039 err=2.952348
I 2015-05-27 02:36:29 theanets.trainer:168 RmsProp 1026 loss=114.553490 err=3.284190
I 2015-05-27 02:36:35 theanets.trainer:168 RmsProp 1027 loss=114.397865 err=3.189788
I 2015-05-27 02:36:41 theanets.trainer:168 RmsProp 1028 loss=114.494339 err=3.351661
I 2015-05-27 02:36:47 theanets.trainer:168 RmsProp 1029 loss=114.365341 err=3.287274
I 2015-05-27 02:36:53 theanets.trainer:168 RmsProp 1030 loss=114.132126 err=3.116337
I 2015-05-27 02:36:53 theanets.trainer:168 validation 103 loss=1388.885376 err=1277.911743 *
I 2015-05-27 02:36:59 theanets.trainer:168 RmsProp 1031 loss=114.142578 err=3.190700
I 2015-05-27 02:37:06 theanets.trainer:168 RmsProp 1032 loss=113.869896 err=2.978075
I 2015-05-27 02:37:12 theanets.trainer:168 RmsProp 1033 loss=113.952530 err=3.127698
I 2015-05-27 02:37:18 theanets.trainer:168 RmsProp 1034 loss=114.367126 err=3.603202
I 2015-05-27 02:37:25 theanets.trainer:168 RmsProp 1035 loss=114.062111 err=3.362272
I 2015-05-27 02:37:30 theanets.trainer:168 RmsProp 1036 loss=113.734421 err=3.099069
I 2015-05-27 02:37:37 theanets.trainer:168 RmsProp 1037 loss=113.639366 err=3.064943
I 2015-05-27 02:37:43 theanets.trainer:168 RmsProp 1038 loss=113.732468 err=3.222505
I 2015-05-27 02:37:50 theanets.trainer:168 RmsProp 1039 loss=113.630447 err=3.182184
I 2015-05-27 02:37:57 theanets.trainer:168 RmsProp 1040 loss=113.467079 err=3.082901
I 2015-05-27 02:37:57 theanets.trainer:168 validation 104 loss=1386.556519 err=1276.199463 *
I 2015-05-27 02:38:03 theanets.trainer:168 RmsProp 1041 loss=113.529564 err=3.203935
I 2015-05-27 02:38:09 theanets.trainer:168 RmsProp 1042 loss=113.511940 err=3.249242
I 2015-05-27 02:38:14 theanets.trainer:168 RmsProp 1043 loss=113.352249 err=3.151160
I 2015-05-27 02:38:21 theanets.trainer:168 RmsProp 1044 loss=113.137840 err=3.002978
I 2015-05-27 02:38:27 theanets.trainer:168 RmsProp 1045 loss=113.302078 err=3.230862
I 2015-05-27 02:38:34 theanets.trainer:168 RmsProp 1046 loss=113.468773 err=3.457649
I 2015-05-27 02:38:40 theanets.trainer:168 RmsProp 1047 loss=113.089294 err=3.140424
I 2015-05-27 02:38:46 theanets.trainer:168 RmsProp 1048 loss=113.323105 err=3.430176
I 2015-05-27 02:38:52 theanets.trainer:168 RmsProp 1049 loss=112.735596 err=2.906780
I 2015-05-27 02:38:59 theanets.trainer:168 RmsProp 1050 loss=113.056274 err=3.287636
I 2015-05-27 02:38:59 theanets.trainer:168 validation 105 loss=1390.675171 err=1280.923096
I 2015-05-27 02:39:05 theanets.trainer:168 RmsProp 1051 loss=112.755577 err=3.045144
I 2015-05-27 02:39:12 theanets.trainer:168 RmsProp 1052 loss=112.864304 err=3.215456
I 2015-05-27 02:39:18 theanets.trainer:168 RmsProp 1053 loss=113.086594 err=3.495172
I 2015-05-27 02:39:24 theanets.trainer:168 RmsProp 1054 loss=112.738525 err=3.211089
I 2015-05-27 02:39:31 theanets.trainer:168 RmsProp 1055 loss=112.633766 err=3.166935
I 2015-05-27 02:39:37 theanets.trainer:168 RmsProp 1056 loss=112.540359 err=3.138781
I 2015-05-27 02:39:44 theanets.trainer:168 RmsProp 1057 loss=112.520226 err=3.174463
I 2015-05-27 02:39:50 theanets.trainer:168 RmsProp 1058 loss=112.466812 err=3.179627
I 2015-05-27 02:39:56 theanets.trainer:168 RmsProp 1059 loss=112.297058 err=3.070077
I 2015-05-27 02:40:02 theanets.trainer:168 RmsProp 1060 loss=112.373489 err=3.204639
I 2015-05-27 02:40:03 theanets.trainer:168 validation 106 loss=1381.739380 err=1272.603882 *
I 2015-05-27 02:40:09 theanets.trainer:168 RmsProp 1061 loss=111.977562 err=2.874749
I 2015-05-27 02:40:15 theanets.trainer:168 RmsProp 1062 loss=112.274170 err=3.230739
I 2015-05-27 02:40:21 theanets.trainer:168 RmsProp 1063 loss=112.497093 err=3.512596
I 2015-05-27 02:40:26 theanets.trainer:168 RmsProp 1064 loss=111.955948 err=3.033868
I 2015-05-27 02:40:32 theanets.trainer:168 RmsProp 1065 loss=111.405823 err=2.548466
I 2015-05-27 02:40:38 theanets.trainer:168 RmsProp 1066 loss=112.631859 err=3.828271
I 2015-05-27 02:40:44 theanets.trainer:168 RmsProp 1067 loss=111.811523 err=3.069350
I 2015-05-27 02:40:50 theanets.trainer:168 RmsProp 1068 loss=111.767578 err=3.090542
I 2015-05-27 02:40:56 theanets.trainer:168 RmsProp 1069 loss=111.912521 err=3.290539
I 2015-05-27 02:41:02 theanets.trainer:168 RmsProp 1070 loss=111.733719 err=3.171707
I 2015-05-27 02:41:03 theanets.trainer:168 validation 107 loss=1377.266968 err=1268.744263 *
I 2015-05-27 02:41:09 theanets.trainer:168 RmsProp 1071 loss=111.650108 err=3.149576
I 2015-05-27 02:41:15 theanets.trainer:168 RmsProp 1072 loss=111.494553 err=3.053355
I 2015-05-27 02:41:21 theanets.trainer:168 RmsProp 1073 loss=111.561035 err=3.181191
I 2015-05-27 02:41:27 theanets.trainer:168 RmsProp 1074 loss=111.434425 err=3.108015
I 2015-05-27 02:41:33 theanets.trainer:168 RmsProp 1075 loss=111.333694 err=3.068000
I 2015-05-27 02:41:39 theanets.trainer:168 RmsProp 1076 loss=111.810776 err=3.596831
I 2015-05-27 02:41:45 theanets.trainer:168 RmsProp 1077 loss=111.184120 err=3.033484
I 2015-05-27 02:41:52 theanets.trainer:168 RmsProp 1078 loss=110.999001 err=2.907220
I 2015-05-27 02:41:58 theanets.trainer:168 RmsProp 1079 loss=111.384621 err=3.351805
I 2015-05-27 02:42:04 theanets.trainer:168 RmsProp 1080 loss=111.059914 err=3.087802
I 2015-05-27 02:42:04 theanets.trainer:168 validation 108 loss=1376.182007 err=1268.232666 *
I 2015-05-27 02:42:10 theanets.trainer:168 RmsProp 1081 loss=110.912025 err=2.996574
I 2015-05-27 02:42:17 theanets.trainer:168 RmsProp 1082 loss=111.012062 err=3.155639
I 2015-05-27 02:42:23 theanets.trainer:168 RmsProp 1083 loss=111.221008 err=3.417262
I 2015-05-27 02:42:29 theanets.trainer:168 RmsProp 1084 loss=110.783287 err=3.039306
I 2015-05-27 02:42:35 theanets.trainer:168 RmsProp 1085 loss=110.499596 err=2.816192
I 2015-05-27 02:42:42 theanets.trainer:168 RmsProp 1086 loss=111.340317 err=3.708724
I 2015-05-27 02:42:48 theanets.trainer:168 RmsProp 1087 loss=110.707298 err=3.134037
I 2015-05-27 02:42:54 theanets.trainer:168 RmsProp 1088 loss=110.548523 err=3.033980
I 2015-05-27 02:43:00 theanets.trainer:168 RmsProp 1089 loss=110.411911 err=2.958346
I 2015-05-27 02:43:06 theanets.trainer:168 RmsProp 1090 loss=110.853981 err=3.453849
I 2015-05-27 02:43:07 theanets.trainer:168 validation 109 loss=1378.716675 err=1271.342773
I 2015-05-27 02:43:13 theanets.trainer:168 RmsProp 1091 loss=110.242630 err=2.902515
I 2015-05-27 02:43:19 theanets.trainer:168 RmsProp 1092 loss=110.500832 err=3.216092
I 2015-05-27 02:43:25 theanets.trainer:168 RmsProp 1093 loss=110.546738 err=3.317336
I 2015-05-27 02:43:31 theanets.trainer:168 RmsProp 1094 loss=110.058365 err=2.890500
I 2015-05-27 02:43:37 theanets.trainer:168 RmsProp 1095 loss=110.452316 err=3.337426
I 2015-05-27 02:43:43 theanets.trainer:168 RmsProp 1096 loss=110.447227 err=3.390602
I 2015-05-27 02:43:49 theanets.trainer:168 RmsProp 1097 loss=110.007607 err=3.007240
I 2015-05-27 02:43:55 theanets.trainer:168 RmsProp 1098 loss=110.160912 err=3.217537
I 2015-05-27 02:44:01 theanets.trainer:168 RmsProp 1099 loss=110.133255 err=3.242000
I 2015-05-27 02:44:07 theanets.trainer:168 RmsProp 1100 loss=109.848083 err=3.015994
I 2015-05-27 02:44:07 theanets.trainer:168 validation 110 loss=1370.316040 err=1263.515259 *
I 2015-05-27 02:44:13 theanets.trainer:168 RmsProp 1101 loss=109.905373 err=3.131311
I 2015-05-27 02:44:19 theanets.trainer:168 RmsProp 1102 loss=109.824867 err=3.103611
I 2015-05-27 02:44:25 theanets.trainer:168 RmsProp 1103 loss=109.645958 err=2.983165
I 2015-05-27 02:44:31 theanets.trainer:168 RmsProp 1104 loss=109.783936 err=3.177872
I 2015-05-27 02:44:37 theanets.trainer:168 RmsProp 1105 loss=109.465164 err=2.920365
I 2015-05-27 02:44:43 theanets.trainer:168 RmsProp 1106 loss=109.721970 err=3.230297
I 2015-05-27 02:44:50 theanets.trainer:168 RmsProp 1107 loss=109.297607 err=2.865588
I 2015-05-27 02:44:56 theanets.trainer:168 RmsProp 1108 loss=109.780319 err=3.405679
I 2015-05-27 02:45:03 theanets.trainer:168 RmsProp 1109 loss=109.269066 err=2.948305
I 2015-05-27 02:45:09 theanets.trainer:168 RmsProp 1110 loss=109.395218 err=3.133438
I 2015-05-27 02:45:09 theanets.trainer:168 validation 111 loss=1365.253052 err=1259.019775 *
I 2015-05-27 02:45:15 theanets.trainer:168 RmsProp 1111 loss=109.250145 err=3.044627
I 2015-05-27 02:45:21 theanets.trainer:168 RmsProp 1112 loss=109.305954 err=3.153553
I 2015-05-27 02:45:27 theanets.trainer:168 RmsProp 1113 loss=109.065506 err=2.965440
I 2015-05-27 02:45:33 theanets.trainer:168 RmsProp 1114 loss=109.296242 err=3.248042
I 2015-05-27 02:45:39 theanets.trainer:168 RmsProp 1115 loss=108.990746 err=3.000724
I 2015-05-27 02:45:45 theanets.trainer:168 RmsProp 1116 loss=108.989075 err=3.059986
I 2015-05-27 02:45:51 theanets.trainer:168 RmsProp 1117 loss=109.017700 err=3.146321
I 2015-05-27 02:45:57 theanets.trainer:168 RmsProp 1118 loss=108.884560 err=3.069927
I 2015-05-27 02:46:03 theanets.trainer:168 RmsProp 1119 loss=108.889992 err=3.131760
I 2015-05-27 02:46:10 theanets.trainer:168 RmsProp 1120 loss=108.710854 err=3.006155
I 2015-05-27 02:46:10 theanets.trainer:168 validation 112 loss=1362.062134 err=1256.390991 *
I 2015-05-27 02:46:16 theanets.trainer:168 RmsProp 1121 loss=108.836098 err=3.187540
I 2015-05-27 02:46:22 theanets.trainer:168 RmsProp 1122 loss=108.608032 err=3.017587
I 2015-05-27 02:46:28 theanets.trainer:168 RmsProp 1123 loss=108.757217 err=3.219690
I 2015-05-27 02:46:34 theanets.trainer:168 RmsProp 1124 loss=108.438828 err=2.958082
I 2015-05-27 02:46:40 theanets.trainer:168 RmsProp 1125 loss=108.218605 err=2.796741
I 2015-05-27 02:46:46 theanets.trainer:168 RmsProp 1126 loss=108.380264 err=3.013231
I 2015-05-27 02:46:52 theanets.trainer:168 RmsProp 1127 loss=108.864037 err=3.545846
I 2015-05-27 02:46:58 theanets.trainer:168 RmsProp 1128 loss=108.536667 err=3.273410
I 2015-05-27 02:47:04 theanets.trainer:168 RmsProp 1129 loss=108.350632 err=3.144237
I 2015-05-27 02:47:10 theanets.trainer:168 RmsProp 1130 loss=108.338905 err=3.182608
I 2015-05-27 02:47:11 theanets.trainer:168 validation 113 loss=1361.999512 err=1256.877808 *
I 2015-05-27 02:47:17 theanets.trainer:168 RmsProp 1131 loss=108.057907 err=2.958367
I 2015-05-27 02:47:23 theanets.trainer:168 RmsProp 1132 loss=108.082108 err=3.032439
I 2015-05-27 02:47:29 theanets.trainer:168 RmsProp 1133 loss=108.346474 err=3.352627
I 2015-05-27 02:47:35 theanets.trainer:168 RmsProp 1134 loss=108.246750 err=3.307472
I 2015-05-27 02:47:41 theanets.trainer:168 RmsProp 1135 loss=107.757591 err=2.874304
I 2015-05-27 02:47:47 theanets.trainer:168 RmsProp 1136 loss=107.578232 err=2.751857
I 2015-05-27 02:47:54 theanets.trainer:168 RmsProp 1137 loss=108.006325 err=3.230062
I 2015-05-27 02:48:00 theanets.trainer:168 RmsProp 1138 loss=107.813316 err=3.090169
I 2015-05-27 02:48:06 theanets.trainer:168 RmsProp 1139 loss=107.782143 err=3.113874
I 2015-05-27 02:48:12 theanets.trainer:168 RmsProp 1140 loss=107.510742 err=2.902347
I 2015-05-27 02:48:13 theanets.trainer:168 validation 114 loss=1357.525879 err=1252.933716 *
I 2015-05-27 02:48:18 theanets.trainer:168 RmsProp 1141 loss=108.042786 err=3.481802
I 2015-05-27 02:48:24 theanets.trainer:168 RmsProp 1142 loss=107.598228 err=3.092073
I 2015-05-27 02:48:30 theanets.trainer:168 RmsProp 1143 loss=107.494461 err=3.043101
I 2015-05-27 02:48:36 theanets.trainer:168 RmsProp 1144 loss=107.555580 err=3.153445
I 2015-05-27 02:48:42 theanets.trainer:168 RmsProp 1145 loss=107.272423 err=2.928882
I 2015-05-27 02:48:48 theanets.trainer:168 RmsProp 1146 loss=107.521767 err=3.230122
I 2015-05-27 02:48:54 theanets.trainer:168 RmsProp 1147 loss=107.160255 err=2.924984
I 2015-05-27 02:49:00 theanets.trainer:168 RmsProp 1148 loss=107.270874 err=3.085869
I 2015-05-27 02:49:06 theanets.trainer:168 RmsProp 1149 loss=107.315247 err=3.185196
I 2015-05-27 02:49:13 theanets.trainer:168 RmsProp 1150 loss=106.931107 err=2.857501
I 2015-05-27 02:49:13 theanets.trainer:168 validation 115 loss=1360.075562 err=1256.026245
I 2015-05-27 02:49:19 theanets.trainer:168 RmsProp 1151 loss=107.129837 err=3.105958
I 2015-05-27 02:49:25 theanets.trainer:168 RmsProp 1152 loss=107.269547 err=3.299670
I 2015-05-27 02:49:31 theanets.trainer:168 RmsProp 1153 loss=106.691139 err=2.774883
I 2015-05-27 02:49:37 theanets.trainer:168 RmsProp 1154 loss=106.850830 err=2.988843
I 2015-05-27 02:49:43 theanets.trainer:168 RmsProp 1155 loss=106.856934 err=3.050606
I 2015-05-27 02:49:50 theanets.trainer:168 RmsProp 1156 loss=106.863144 err=3.108078
I 2015-05-27 02:49:55 theanets.trainer:168 RmsProp 1157 loss=106.817734 err=3.117870
I 2015-05-27 02:50:01 theanets.trainer:168 RmsProp 1158 loss=106.603149 err=2.955010
I 2015-05-27 02:50:07 theanets.trainer:168 RmsProp 1159 loss=106.557823 err=2.964613
I 2015-05-27 02:50:13 theanets.trainer:168 RmsProp 1160 loss=106.874512 err=3.331078
I 2015-05-27 02:50:13 theanets.trainer:168 validation 116 loss=1356.760742 err=1253.243408 *
I 2015-05-27 02:50:19 theanets.trainer:168 RmsProp 1161 loss=106.489342 err=3.000264
I 2015-05-27 02:50:26 theanets.trainer:168 RmsProp 1162 loss=106.678329 err=3.240335
I 2015-05-27 02:50:32 theanets.trainer:168 RmsProp 1163 loss=106.507370 err=3.122983
I 2015-05-27 02:50:38 theanets.trainer:168 RmsProp 1164 loss=106.124733 err=2.794424
I 2015-05-27 02:50:44 theanets.trainer:168 RmsProp 1165 loss=106.622574 err=3.340121
I 2015-05-27 02:50:50 theanets.trainer:168 RmsProp 1166 loss=106.289490 err=3.063451
I 2015-05-27 02:50:56 theanets.trainer:168 RmsProp 1167 loss=106.182213 err=3.008070
I 2015-05-27 02:51:02 theanets.trainer:168 RmsProp 1168 loss=106.246017 err=3.123510
I 2015-05-27 02:51:08 theanets.trainer:168 RmsProp 1169 loss=105.819374 err=2.752290
I 2015-05-27 02:51:14 theanets.trainer:168 RmsProp 1170 loss=106.043800 err=3.032669
I 2015-05-27 02:51:14 theanets.trainer:168 validation 117 loss=1353.913818 err=1250.929077 *
I 2015-05-27 02:51:20 theanets.trainer:168 RmsProp 1171 loss=105.942307 err=2.984650
I 2015-05-27 02:51:26 theanets.trainer:168 RmsProp 1172 loss=106.259781 err=3.345973
I 2015-05-27 02:51:32 theanets.trainer:168 RmsProp 1173 loss=106.081566 err=3.219198
I 2015-05-27 02:51:39 theanets.trainer:168 RmsProp 1174 loss=105.726929 err=2.917240
I 2015-05-27 02:51:45 theanets.trainer:168 RmsProp 1175 loss=105.504044 err=2.750680
I 2015-05-27 02:51:51 theanets.trainer:168 RmsProp 1176 loss=105.723953 err=3.021726
I 2015-05-27 02:51:57 theanets.trainer:168 RmsProp 1177 loss=105.854309 err=3.200282
I 2015-05-27 02:52:04 theanets.trainer:168 RmsProp 1178 loss=105.527260 err=2.927729
I 2015-05-27 02:52:10 theanets.trainer:168 RmsProp 1179 loss=105.518723 err=2.972759
I 2015-05-27 02:52:16 theanets.trainer:168 RmsProp 1180 loss=105.589439 err=3.096437
I 2015-05-27 02:52:16 theanets.trainer:168 validation 118 loss=1350.503296 err=1248.033813 *
I 2015-05-27 02:52:22 theanets.trainer:168 RmsProp 1181 loss=105.448135 err=3.004631
I 2015-05-27 02:52:28 theanets.trainer:168 RmsProp 1182 loss=105.700768 err=3.306742
I 2015-05-27 02:52:34 theanets.trainer:168 RmsProp 1183 loss=104.955956 err=2.612359
I 2015-05-27 02:52:41 theanets.trainer:168 RmsProp 1184 loss=105.498428 err=3.206881
I 2015-05-27 02:52:47 theanets.trainer:168 RmsProp 1185 loss=105.168900 err=2.933445
I 2015-05-27 02:52:53 theanets.trainer:168 RmsProp 1186 loss=105.353378 err=3.165104
I 2015-05-27 02:52:58 theanets.trainer:168 RmsProp 1187 loss=105.391541 err=3.249751
I 2015-05-27 02:53:05 theanets.trainer:168 RmsProp 1188 loss=105.300537 err=3.207257
I 2015-05-27 02:53:11 theanets.trainer:168 RmsProp 1189 loss=105.194252 err=3.154608
I 2015-05-27 02:53:17 theanets.trainer:168 RmsProp 1190 loss=104.947205 err=2.958296
I 2015-05-27 02:53:18 theanets.trainer:168 validation 119 loss=1340.954590 err=1238.985596 *
I 2015-05-27 02:53:24 theanets.trainer:168 RmsProp 1191 loss=104.972740 err=3.034321
I 2015-05-27 02:53:30 theanets.trainer:168 RmsProp 1192 loss=104.725388 err=2.841543
I 2015-05-27 02:53:36 theanets.trainer:168 RmsProp 1193 loss=105.143417 err=3.305010
I 2015-05-27 02:53:42 theanets.trainer:168 RmsProp 1194 loss=104.907883 err=3.122508
I 2015-05-27 02:53:48 theanets.trainer:168 RmsProp 1195 loss=104.545616 err=2.811798
I 2015-05-27 02:53:54 theanets.trainer:168 RmsProp 1196 loss=105.145615 err=3.457570
I 2015-05-27 02:54:00 theanets.trainer:168 RmsProp 1197 loss=104.803696 err=3.162857
I 2015-05-27 02:54:06 theanets.trainer:168 RmsProp 1198 loss=104.970055 err=3.376455
I 2015-05-27 02:54:12 theanets.trainer:168 RmsProp 1199 loss=104.394936 err=2.855440
I 2015-05-27 02:54:19 theanets.trainer:168 RmsProp 1200 loss=104.543579 err=3.054553
I 2015-05-27 02:54:19 theanets.trainer:168 validation 120 loss=1342.946777 err=1241.480835
I 2015-05-27 02:54:26 theanets.trainer:168 RmsProp 1201 loss=104.427452 err=2.987918
I 2015-05-27 02:54:32 theanets.trainer:168 RmsProp 1202 loss=104.341782 err=2.953308
I 2015-05-27 02:54:38 theanets.trainer:168 RmsProp 1203 loss=104.684288 err=3.344797
I 2015-05-27 02:54:45 theanets.trainer:168 RmsProp 1204 loss=104.287621 err=2.995347
I 2015-05-27 02:54:51 theanets.trainer:168 RmsProp 1205 loss=104.112198 err=2.870548
I 2015-05-27 02:54:57 theanets.trainer:168 RmsProp 1206 loss=104.714294 err=3.519728
I 2015-05-27 02:55:04 theanets.trainer:168 RmsProp 1207 loss=104.120911 err=2.973686
I 2015-05-27 02:55:10 theanets.trainer:168 RmsProp 1208 loss=104.172203 err=3.073820
I 2015-05-27 02:55:15 theanets.trainer:168 RmsProp 1209 loss=104.006554 err=2.958633
I 2015-05-27 02:55:22 theanets.trainer:168 RmsProp 1210 loss=104.016342 err=3.014109
I 2015-05-27 02:55:23 theanets.trainer:168 validation 121 loss=1341.491089 err=1240.515991
I 2015-05-27 02:55:28 theanets.trainer:168 RmsProp 1211 loss=103.990921 err=3.034606
I 2015-05-27 02:55:34 theanets.trainer:168 RmsProp 1212 loss=103.786484 err=2.883247
I 2015-05-27 02:55:40 theanets.trainer:168 RmsProp 1213 loss=104.152390 err=3.296375
I 2015-05-27 02:55:47 theanets.trainer:168 RmsProp 1214 loss=103.812607 err=3.006813
I 2015-05-27 02:55:52 theanets.trainer:168 RmsProp 1215 loss=103.912941 err=3.156941
I 2015-05-27 02:55:58 theanets.trainer:168 RmsProp 1216 loss=103.634544 err=2.926852
I 2015-05-27 02:56:05 theanets.trainer:168 RmsProp 1217 loss=103.352272 err=2.695174
I 2015-05-27 02:56:11 theanets.trainer:168 RmsProp 1218 loss=103.862167 err=3.252527
I 2015-05-27 02:56:17 theanets.trainer:168 RmsProp 1219 loss=103.444931 err=2.880512
I 2015-05-27 02:56:23 theanets.trainer:168 RmsProp 1220 loss=103.715736 err=3.202176
I 2015-05-27 02:56:24 theanets.trainer:168 validation 122 loss=1331.768433 err=1231.286743 *
I 2015-05-27 02:56:30 theanets.trainer:168 RmsProp 1221 loss=103.409729 err=2.947112
I 2015-05-27 02:56:36 theanets.trainer:168 RmsProp 1222 loss=103.304588 err=2.886235
I 2015-05-27 02:56:42 theanets.trainer:168 RmsProp 1223 loss=103.589905 err=3.220203
I 2015-05-27 02:56:48 theanets.trainer:168 RmsProp 1224 loss=103.271866 err=2.953153
I 2015-05-27 02:56:54 theanets.trainer:168 RmsProp 1225 loss=103.119339 err=2.850085
I 2015-05-27 02:57:00 theanets.trainer:168 RmsProp 1226 loss=103.272827 err=3.051561
I 2015-05-27 02:57:06 theanets.trainer:168 RmsProp 1227 loss=103.506851 err=3.330277
I 2015-05-27 02:57:11 theanets.trainer:168 RmsProp 1228 loss=103.228905 err=3.100867
I 2015-05-27 02:57:18 theanets.trainer:168 RmsProp 1229 loss=103.174240 err=3.099156
I 2015-05-27 02:57:24 theanets.trainer:168 RmsProp 1230 loss=103.077805 err=3.048139
I 2015-05-27 02:57:24 theanets.trainer:168 validation 123 loss=1331.639648 err=1231.636719 *
I 2015-05-27 02:57:30 theanets.trainer:168 RmsProp 1231 loss=102.908615 err=2.929654
I 2015-05-27 02:57:36 theanets.trainer:168 RmsProp 1232 loss=102.929733 err=2.996419
I 2015-05-27 02:57:43 theanets.trainer:168 RmsProp 1233 loss=103.061989 err=3.176324
I 2015-05-27 02:57:49 theanets.trainer:168 RmsProp 1234 loss=102.817932 err=2.979958
I 2015-05-27 02:57:56 theanets.trainer:168 RmsProp 1235 loss=102.756302 err=2.968050
I 2015-05-27 02:58:02 theanets.trainer:168 RmsProp 1236 loss=102.840736 err=3.100196
I 2015-05-27 02:58:07 theanets.trainer:168 RmsProp 1237 loss=102.681717 err=2.989395
I 2015-05-27 02:58:14 theanets.trainer:168 RmsProp 1238 loss=102.733597 err=3.090347
I 2015-05-27 02:58:20 theanets.trainer:168 RmsProp 1239 loss=102.563843 err=2.968531
I 2015-05-27 02:58:26 theanets.trainer:168 RmsProp 1240 loss=102.899612 err=3.348670
I 2015-05-27 02:58:26 theanets.trainer:168 validation 124 loss=1329.541504 err=1230.027222 *
I 2015-05-27 02:58:32 theanets.trainer:168 RmsProp 1241 loss=102.306168 err=2.803994
I 2015-05-27 02:58:38 theanets.trainer:168 RmsProp 1242 loss=102.404785 err=2.952425
I 2015-05-27 02:58:44 theanets.trainer:168 RmsProp 1243 loss=102.613785 err=3.205035
I 2015-05-27 02:58:50 theanets.trainer:168 RmsProp 1244 loss=102.108986 err=2.749578
I 2015-05-27 02:58:56 theanets.trainer:168 RmsProp 1245 loss=102.509438 err=3.200401
I 2015-05-27 02:59:03 theanets.trainer:168 RmsProp 1246 loss=102.071762 err=2.809873
I 2015-05-27 02:59:09 theanets.trainer:168 RmsProp 1247 loss=102.140335 err=2.923659
I 2015-05-27 02:59:15 theanets.trainer:168 RmsProp 1248 loss=102.065483 err=2.896396
I 2015-05-27 02:59:21 theanets.trainer:168 RmsProp 1249 loss=102.332985 err=3.210363
I 2015-05-27 02:59:27 theanets.trainer:168 RmsProp 1250 loss=102.018410 err=2.944132
I 2015-05-27 02:59:28 theanets.trainer:168 validation 125 loss=1325.986084 err=1226.940796 *
I 2015-05-27 02:59:34 theanets.trainer:168 RmsProp 1251 loss=101.888466 err=2.864159
I 2015-05-27 02:59:41 theanets.trainer:168 RmsProp 1252 loss=102.277672 err=3.297559
I 2015-05-27 02:59:46 theanets.trainer:168 RmsProp 1253 loss=101.743629 err=2.810260
I 2015-05-27 02:59:52 theanets.trainer:168 RmsProp 1254 loss=101.817474 err=2.935258
I 2015-05-27 02:59:59 theanets.trainer:168 RmsProp 1255 loss=101.698654 err=2.862224
I 2015-05-27 03:00:06 theanets.trainer:168 RmsProp 1256 loss=101.932358 err=3.137338
I 2015-05-27 03:00:12 theanets.trainer:168 RmsProp 1257 loss=101.835464 err=3.090203
I 2015-05-27 03:00:18 theanets.trainer:168 RmsProp 1258 loss=101.610474 err=2.913937
I 2015-05-27 03:00:24 theanets.trainer:168 RmsProp 1259 loss=101.815895 err=3.167210
I 2015-05-27 03:00:31 theanets.trainer:168 RmsProp 1260 loss=101.784386 err=3.179879
I 2015-05-27 03:00:32 theanets.trainer:168 validation 126 loss=1324.104858 err=1225.519897 *
I 2015-05-27 03:00:37 theanets.trainer:168 RmsProp 1261 loss=101.524185 err=2.962109
I 2015-05-27 03:00:43 theanets.trainer:168 RmsProp 1262 loss=101.423622 err=2.912318
I 2015-05-27 03:00:49 theanets.trainer:168 RmsProp 1263 loss=101.503494 err=3.041220
I 2015-05-27 03:00:55 theanets.trainer:168 RmsProp 1264 loss=101.323067 err=2.909270
I 2015-05-27 03:01:01 theanets.trainer:168 RmsProp 1265 loss=101.347122 err=2.977532
I 2015-05-27 03:01:07 theanets.trainer:168 RmsProp 1266 loss=101.294472 err=2.971678
I 2015-05-27 03:01:13 theanets.trainer:168 RmsProp 1267 loss=100.967926 err=2.693096
I 2015-05-27 03:01:18 theanets.trainer:168 RmsProp 1268 loss=100.981613 err=2.752075
I 2015-05-27 03:01:24 theanets.trainer:168 RmsProp 1269 loss=101.227592 err=3.046845
I 2015-05-27 03:01:30 theanets.trainer:168 RmsProp 1270 loss=101.241676 err=3.109210
I 2015-05-27 03:01:30 theanets.trainer:168 validation 127 loss=1319.633789 err=1221.531128 *
I 2015-05-27 03:01:36 theanets.trainer:168 RmsProp 1271 loss=101.193893 err=3.105564
I 2015-05-27 03:01:41 theanets.trainer:168 RmsProp 1272 loss=100.925217 err=2.881455
I 2015-05-27 03:01:47 theanets.trainer:168 RmsProp 1273 loss=101.071930 err=3.073556
I 2015-05-27 03:01:53 theanets.trainer:168 RmsProp 1274 loss=101.062553 err=3.107816
I 2015-05-27 03:01:58 theanets.trainer:168 RmsProp 1275 loss=100.836105 err=2.929837
I 2015-05-27 03:02:04 theanets.trainer:168 RmsProp 1276 loss=101.130409 err=3.269716
I 2015-05-27 03:02:10 theanets.trainer:168 RmsProp 1277 loss=100.793808 err=2.980201
I 2015-05-27 03:02:15 theanets.trainer:168 RmsProp 1278 loss=100.660088 err=2.892442
I 2015-05-27 03:02:22 theanets.trainer:168 RmsProp 1279 loss=100.734825 err=3.012357
I 2015-05-27 03:02:27 theanets.trainer:168 RmsProp 1280 loss=100.527161 err=2.850905
I 2015-05-27 03:02:28 theanets.trainer:168 validation 128 loss=1322.816162 err=1225.162476
I 2015-05-27 03:02:33 theanets.trainer:168 RmsProp 1281 loss=100.774193 err=3.139733
I 2015-05-27 03:02:39 theanets.trainer:168 RmsProp 1282 loss=100.471558 err=2.882238
I 2015-05-27 03:02:44 theanets.trainer:168 RmsProp 1283 loss=100.576187 err=3.034701
I 2015-05-27 03:02:50 theanets.trainer:168 RmsProp 1284 loss=100.666199 err=3.167137
I 2015-05-27 03:02:55 theanets.trainer:168 RmsProp 1285 loss=100.372299 err=2.919387
I 2015-05-27 03:03:01 theanets.trainer:168 RmsProp 1286 loss=100.077309 err=2.670809
I 2015-05-27 03:03:07 theanets.trainer:168 RmsProp 1287 loss=100.728477 err=3.362888
I 2015-05-27 03:03:13 theanets.trainer:168 RmsProp 1288 loss=100.244347 err=2.925478
I 2015-05-27 03:03:18 theanets.trainer:168 RmsProp 1289 loss=100.173630 err=2.898749
I 2015-05-27 03:03:24 theanets.trainer:168 RmsProp 1290 loss=100.296860 err=3.066866
I 2015-05-27 03:03:24 theanets.trainer:168 validation 129 loss=1318.490234 err=1221.277344 *
I 2015-05-27 03:03:30 theanets.trainer:168 RmsProp 1291 loss=100.357880 err=3.169982
I 2015-05-27 03:03:35 theanets.trainer:168 RmsProp 1292 loss=100.202705 err=3.056962
I 2015-05-27 03:03:41 theanets.trainer:168 RmsProp 1293 loss=99.898849 err=2.794335
I 2015-05-27 03:03:47 theanets.trainer:168 RmsProp 1294 loss=100.001549 err=2.945395
I 2015-05-27 03:03:52 theanets.trainer:168 RmsProp 1295 loss=100.085617 err=3.074034
I 2015-05-27 03:03:58 theanets.trainer:168 RmsProp 1296 loss=99.923042 err=2.957120
I 2015-05-27 03:04:04 theanets.trainer:168 RmsProp 1297 loss=100.004639 err=3.081011
I 2015-05-27 03:04:09 theanets.trainer:168 RmsProp 1298 loss=99.444824 err=2.567636
I 2015-05-27 03:04:15 theanets.trainer:168 RmsProp 1299 loss=100.364059 err=3.529605
I 2015-05-27 03:04:21 theanets.trainer:168 RmsProp 1300 loss=99.878883 err=3.086809
I 2015-05-27 03:04:21 theanets.trainer:168 validation 130 loss=1311.610107 err=1214.847046 *
I 2015-05-27 03:04:27 theanets.trainer:168 RmsProp 1301 loss=99.635925 err=2.887477
I 2015-05-27 03:04:33 theanets.trainer:168 RmsProp 1302 loss=99.675674 err=2.970644
I 2015-05-27 03:04:39 theanets.trainer:168 RmsProp 1303 loss=99.827026 err=3.165186
I 2015-05-27 03:04:45 theanets.trainer:168 RmsProp 1304 loss=99.767235 err=3.146037
I 2015-05-27 03:04:51 theanets.trainer:168 RmsProp 1305 loss=99.288223 err=2.710227
I 2015-05-27 03:04:57 theanets.trainer:168 RmsProp 1306 loss=99.561638 err=3.030027
I 2015-05-27 03:05:03 theanets.trainer:168 RmsProp 1307 loss=99.496605 err=3.007561
I 2015-05-27 03:05:09 theanets.trainer:168 RmsProp 1308 loss=99.536110 err=3.090795
I 2015-05-27 03:05:13 theanets.trainer:168 RmsProp 1309 loss=99.065376 err=2.665459
I 2015-05-27 03:05:18 theanets.trainer:168 RmsProp 1310 loss=99.449356 err=3.090051
I 2015-05-27 03:05:19 theanets.trainer:168 validation 131 loss=1310.640503 err=1214.308594 *
I 2015-05-27 03:05:23 theanets.trainer:168 RmsProp 1311 loss=99.401131 err=3.084117
I 2015-05-27 03:05:28 theanets.trainer:168 RmsProp 1312 loss=99.285774 err=3.014181
I 2015-05-27 03:05:33 theanets.trainer:168 RmsProp 1313 loss=99.412651 err=3.186630
I 2015-05-27 03:05:38 theanets.trainer:168 RmsProp 1314 loss=99.170509 err=2.986358
I 2015-05-27 03:05:42 theanets.trainer:168 RmsProp 1315 loss=99.315872 err=3.170465
I 2015-05-27 03:05:47 theanets.trainer:168 RmsProp 1316 loss=98.992996 err=2.890041
I 2015-05-27 03:05:52 theanets.trainer:168 RmsProp 1317 loss=98.949997 err=2.890222
I 2015-05-27 03:05:56 theanets.trainer:168 RmsProp 1318 loss=99.006065 err=2.988520
I 2015-05-27 03:06:01 theanets.trainer:168 RmsProp 1319 loss=98.960121 err=2.983929
I 2015-05-27 03:06:06 theanets.trainer:168 RmsProp 1320 loss=98.712456 err=2.783120
I 2015-05-27 03:06:07 theanets.trainer:168 validation 132 loss=1313.750000 err=1217.840210
I 2015-05-27 03:06:11 theanets.trainer:168 RmsProp 1321 loss=98.884903 err=2.999274
I 2015-05-27 03:06:16 theanets.trainer:168 RmsProp 1322 loss=99.018158 err=3.173613
I 2015-05-27 03:06:20 theanets.trainer:168 RmsProp 1323 loss=98.719810 err=2.916660
I 2015-05-27 03:06:25 theanets.trainer:168 RmsProp 1324 loss=98.890503 err=3.124254
I 2015-05-27 03:06:31 theanets.trainer:168 RmsProp 1325 loss=98.467827 err=2.746710
I 2015-05-27 03:06:37 theanets.trainer:168 RmsProp 1326 loss=98.537849 err=2.862480
I 2015-05-27 03:06:43 theanets.trainer:168 RmsProp 1327 loss=99.170540 err=3.533901
I 2015-05-27 03:06:48 theanets.trainer:168 RmsProp 1328 loss=98.263283 err=2.668865
I 2015-05-27 03:06:54 theanets.trainer:168 RmsProp 1329 loss=98.396461 err=2.845931
I 2015-05-27 03:06:59 theanets.trainer:168 RmsProp 1330 loss=98.475601 err=2.969163
I 2015-05-27 03:07:00 theanets.trainer:168 validation 133 loss=1307.257080 err=1211.779663 *
I 2015-05-27 03:07:05 theanets.trainer:168 RmsProp 1331 loss=98.411247 err=2.948660
I 2015-05-27 03:07:10 theanets.trainer:168 RmsProp 1332 loss=98.316116 err=2.898923
I 2015-05-27 03:07:16 theanets.trainer:168 RmsProp 1333 loss=98.476929 err=3.100416
I 2015-05-27 03:07:21 theanets.trainer:168 RmsProp 1334 loss=98.289650 err=2.950814
I 2015-05-27 03:07:27 theanets.trainer:168 RmsProp 1335 loss=98.185898 err=2.891509
I 2015-05-27 03:07:33 theanets.trainer:168 RmsProp 1336 loss=98.179420 err=2.930322
I 2015-05-27 03:07:39 theanets.trainer:168 RmsProp 1337 loss=98.311043 err=3.101720
I 2015-05-27 03:07:45 theanets.trainer:168 RmsProp 1338 loss=98.021622 err=2.856112
I 2015-05-27 03:07:51 theanets.trainer:168 RmsProp 1339 loss=98.156387 err=3.035970
I 2015-05-27 03:07:57 theanets.trainer:168 RmsProp 1340 loss=97.897148 err=2.820300
I 2015-05-27 03:07:57 theanets.trainer:168 validation 134 loss=1304.502319 err=1209.447021 *
I 2015-05-27 03:08:03 theanets.trainer:168 RmsProp 1341 loss=98.020927 err=2.985553
I 2015-05-27 03:08:08 theanets.trainer:168 RmsProp 1342 loss=98.048668 err=3.049122
I 2015-05-27 03:08:14 theanets.trainer:168 RmsProp 1343 loss=98.011475 err=3.050077
I 2015-05-27 03:08:20 theanets.trainer:168 RmsProp 1344 loss=97.547585 err=2.631974
I 2015-05-27 03:08:26 theanets.trainer:168 RmsProp 1345 loss=97.986107 err=3.108523
I 2015-05-27 03:08:32 theanets.trainer:168 RmsProp 1346 loss=97.579025 err=2.744221
I 2015-05-27 03:08:38 theanets.trainer:168 RmsProp 1347 loss=97.898605 err=3.107073
I 2015-05-27 03:08:44 theanets.trainer:168 RmsProp 1348 loss=97.672760 err=2.924060
I 2015-05-27 03:08:49 theanets.trainer:168 RmsProp 1349 loss=97.965446 err=3.258392
I 2015-05-27 03:08:55 theanets.trainer:168 RmsProp 1350 loss=97.480751 err=2.818256
I 2015-05-27 03:08:55 theanets.trainer:168 validation 135 loss=1300.624756 err=1205.991089 *
I 2015-05-27 03:09:00 theanets.trainer:168 RmsProp 1351 loss=97.471161 err=2.851553
I 2015-05-27 03:09:07 theanets.trainer:168 RmsProp 1352 loss=97.492935 err=2.910811
I 2015-05-27 03:09:13 theanets.trainer:168 RmsProp 1353 loss=97.364609 err=2.824736
I 2015-05-27 03:09:19 theanets.trainer:168 RmsProp 1354 loss=97.605042 err=3.103673
I 2015-05-27 03:09:25 theanets.trainer:168 RmsProp 1355 loss=97.170357 err=2.713272
I 2015-05-27 03:09:30 theanets.trainer:168 RmsProp 1356 loss=97.170761 err=2.757292
I 2015-05-27 03:09:36 theanets.trainer:168 RmsProp 1357 loss=97.201553 err=2.828956
I 2015-05-27 03:09:42 theanets.trainer:168 RmsProp 1358 loss=97.204361 err=2.873744
I 2015-05-27 03:09:48 theanets.trainer:168 RmsProp 1359 loss=97.369011 err=3.078264
I 2015-05-27 03:09:54 theanets.trainer:168 RmsProp 1360 loss=97.219315 err=2.967689
I 2015-05-27 03:09:54 theanets.trainer:168 validation 136 loss=1303.061646 err=1208.829346
I 2015-05-27 03:10:00 theanets.trainer:168 RmsProp 1361 loss=97.143761 err=2.931695
I 2015-05-27 03:10:05 theanets.trainer:168 RmsProp 1362 loss=96.972473 err=2.803754
I 2015-05-27 03:10:11 theanets.trainer:168 RmsProp 1363 loss=97.135452 err=3.006306
I 2015-05-27 03:10:17 theanets.trainer:168 RmsProp 1364 loss=96.982994 err=2.895894
I 2015-05-27 03:10:23 theanets.trainer:168 RmsProp 1365 loss=96.965065 err=2.917887
I 2015-05-27 03:10:29 theanets.trainer:168 RmsProp 1366 loss=96.836433 err=2.832572
I 2015-05-27 03:10:34 theanets.trainer:168 RmsProp 1367 loss=97.040749 err=3.074718
I 2015-05-27 03:10:40 theanets.trainer:168 RmsProp 1368 loss=96.810898 err=2.885255
I 2015-05-27 03:10:46 theanets.trainer:168 RmsProp 1369 loss=96.925957 err=3.042067
I 2015-05-27 03:10:52 theanets.trainer:168 RmsProp 1370 loss=96.770607 err=2.923680
I 2015-05-27 03:10:53 theanets.trainer:168 validation 137 loss=1301.172852 err=1207.349609
I 2015-05-27 03:10:58 theanets.trainer:168 RmsProp 1371 loss=96.749100 err=2.942169
I 2015-05-27 03:11:04 theanets.trainer:168 RmsProp 1372 loss=96.852966 err=3.088068
I 2015-05-27 03:11:11 theanets.trainer:168 RmsProp 1373 loss=96.517685 err=2.789557
I 2015-05-27 03:11:17 theanets.trainer:168 RmsProp 1374 loss=96.540596 err=2.854754
I 2015-05-27 03:11:23 theanets.trainer:168 RmsProp 1375 loss=96.672989 err=3.028386
I 2015-05-27 03:11:29 theanets.trainer:168 RmsProp 1376 loss=96.661659 err=3.059248
I 2015-05-27 03:11:35 theanets.trainer:168 RmsProp 1377 loss=96.902161 err=3.333596
I 2015-05-27 03:11:41 theanets.trainer:168 RmsProp 1378 loss=96.403381 err=2.875898
I 2015-05-27 03:11:46 theanets.trainer:168 RmsProp 1379 loss=96.217163 err=2.731215
I 2015-05-27 03:11:52 theanets.trainer:168 RmsProp 1380 loss=96.449379 err=3.007129
I 2015-05-27 03:11:53 theanets.trainer:168 validation 138 loss=1296.196167 err=1202.780273 *
I 2015-05-27 03:11:58 theanets.trainer:168 RmsProp 1381 loss=96.297516 err=2.897411
I 2015-05-27 03:12:04 theanets.trainer:168 RmsProp 1382 loss=96.372154 err=3.010102
I 2015-05-27 03:12:09 theanets.trainer:168 RmsProp 1383 loss=96.042648 err=2.719694
I 2015-05-27 03:12:15 theanets.trainer:168 RmsProp 1384 loss=96.069359 err=2.788101
I 2015-05-27 03:12:20 theanets.trainer:168 RmsProp 1385 loss=96.249916 err=3.008224
I 2015-05-27 03:12:26 theanets.trainer:168 RmsProp 1386 loss=95.936325 err=2.734520
I 2015-05-27 03:12:31 theanets.trainer:168 RmsProp 1387 loss=96.125229 err=2.962225
I 2015-05-27 03:12:38 theanets.trainer:168 RmsProp 1388 loss=96.202782 err=3.077456
I 2015-05-27 03:12:44 theanets.trainer:168 RmsProp 1389 loss=95.915421 err=2.826392
I 2015-05-27 03:12:50 theanets.trainer:168 RmsProp 1390 loss=96.197716 err=3.150225
I 2015-05-27 03:12:50 theanets.trainer:168 validation 139 loss=1292.475830 err=1199.446899 *
I 2015-05-27 03:12:56 theanets.trainer:168 RmsProp 1391 loss=95.785011 err=2.780145
I 2015-05-27 03:13:02 theanets.trainer:168 RmsProp 1392 loss=95.862717 err=2.899166
I 2015-05-27 03:13:09 theanets.trainer:168 RmsProp 1393 loss=95.982918 err=3.055208
I 2015-05-27 03:13:15 theanets.trainer:168 RmsProp 1394 loss=95.673462 err=2.789187
I 2015-05-27 03:13:21 theanets.trainer:168 RmsProp 1395 loss=96.227921 err=3.380043
I 2015-05-27 03:13:27 theanets.trainer:168 RmsProp 1396 loss=95.360512 err=2.549519
I 2015-05-27 03:13:32 theanets.trainer:168 RmsProp 1397 loss=95.792702 err=3.023877
I 2015-05-27 03:13:38 theanets.trainer:168 RmsProp 1398 loss=95.528419 err=2.797863
I 2015-05-27 03:13:44 theanets.trainer:168 RmsProp 1399 loss=95.685905 err=2.994220
I 2015-05-27 03:13:50 theanets.trainer:168 RmsProp 1400 loss=95.509880 err=2.855823
I 2015-05-27 03:13:50 theanets.trainer:168 validation 140 loss=1296.207275 err=1203.574097
I 2015-05-27 03:13:56 theanets.trainer:168 RmsProp 1401 loss=95.518005 err=2.904348
I 2015-05-27 03:14:01 theanets.trainer:168 RmsProp 1402 loss=95.455666 err=2.882371
I 2015-05-27 03:14:07 theanets.trainer:168 RmsProp 1403 loss=95.490250 err=2.954430
I 2015-05-27 03:14:12 theanets.trainer:168 RmsProp 1404 loss=95.697342 err=3.198125
I 2015-05-27 03:14:18 theanets.trainer:168 RmsProp 1405 loss=95.490181 err=3.024354
I 2015-05-27 03:14:23 theanets.trainer:168 RmsProp 1406 loss=95.396835 err=2.972098
I 2015-05-27 03:14:29 theanets.trainer:168 RmsProp 1407 loss=95.086464 err=2.705330
I 2015-05-27 03:14:36 theanets.trainer:168 RmsProp 1408 loss=95.143799 err=2.802460
I 2015-05-27 03:14:42 theanets.trainer:168 RmsProp 1409 loss=95.444229 err=3.140049
I 2015-05-27 03:14:48 theanets.trainer:168 RmsProp 1410 loss=95.081680 err=2.810730
I 2015-05-27 03:14:48 theanets.trainer:168 validation 141 loss=1289.107300 err=1196.854736 *
I 2015-05-27 03:14:54 theanets.trainer:168 RmsProp 1411 loss=94.977310 err=2.745191
I 2015-05-27 03:15:00 theanets.trainer:168 RmsProp 1412 loss=95.258926 err=3.066458
I 2015-05-27 03:15:07 theanets.trainer:168 RmsProp 1413 loss=95.027397 err=2.874714
I 2015-05-27 03:15:12 theanets.trainer:168 RmsProp 1414 loss=95.020401 err=2.905049
I 2015-05-27 03:15:18 theanets.trainer:168 RmsProp 1415 loss=95.079659 err=3.003626
I 2015-05-27 03:15:24 theanets.trainer:168 RmsProp 1416 loss=94.836441 err=2.797493
I 2015-05-27 03:15:31 theanets.trainer:168 RmsProp 1417 loss=94.803314 err=2.800317
I 2015-05-27 03:15:37 theanets.trainer:168 RmsProp 1418 loss=95.034172 err=3.070239
I 2015-05-27 03:15:43 theanets.trainer:168 RmsProp 1419 loss=94.636894 err=2.712731
I 2015-05-27 03:15:48 theanets.trainer:168 RmsProp 1420 loss=94.707497 err=2.823066
I 2015-05-27 03:15:49 theanets.trainer:168 validation 142 loss=1285.938110 err=1194.072632 *
I 2015-05-27 03:15:55 theanets.trainer:168 RmsProp 1421 loss=94.684113 err=2.837273
I 2015-05-27 03:16:00 theanets.trainer:168 RmsProp 1422 loss=94.715622 err=2.905299
I 2015-05-27 03:16:06 theanets.trainer:168 RmsProp 1423 loss=94.793877 err=3.020080
I 2015-05-27 03:16:12 theanets.trainer:168 RmsProp 1424 loss=94.799507 err=3.061155
I 2015-05-27 03:16:18 theanets.trainer:168 RmsProp 1425 loss=94.201683 err=2.504640
I 2015-05-27 03:16:24 theanets.trainer:168 RmsProp 1426 loss=94.945259 err=3.279806
I 2015-05-27 03:16:30 theanets.trainer:168 RmsProp 1427 loss=94.526146 err=2.903612
I 2015-05-27 03:16:36 theanets.trainer:168 RmsProp 1428 loss=94.767410 err=3.179061
I 2015-05-27 03:16:42 theanets.trainer:168 RmsProp 1429 loss=94.252510 err=2.702595
I 2015-05-27 03:16:49 theanets.trainer:168 RmsProp 1430 loss=94.459335 err=2.949063
I 2015-05-27 03:16:49 theanets.trainer:168 validation 143 loss=1290.558228 err=1199.061157
I 2015-05-27 03:16:55 theanets.trainer:168 RmsProp 1431 loss=94.294533 err=2.820832
I 2015-05-27 03:17:01 theanets.trainer:168 RmsProp 1432 loss=94.244316 err=2.808639
I 2015-05-27 03:17:07 theanets.trainer:168 RmsProp 1433 loss=94.774849 err=3.371073
I 2015-05-27 03:17:13 theanets.trainer:168 RmsProp 1434 loss=94.144295 err=2.778603
I 2015-05-27 03:17:20 theanets.trainer:168 RmsProp 1435 loss=94.461075 err=3.131697
I 2015-05-27 03:17:26 theanets.trainer:168 RmsProp 1436 loss=94.065598 err=2.773364
I 2015-05-27 03:17:31 theanets.trainer:168 RmsProp 1437 loss=94.072647 err=2.822004
I 2015-05-27 03:17:37 theanets.trainer:168 RmsProp 1438 loss=94.190964 err=2.973242
I 2015-05-27 03:17:43 theanets.trainer:168 RmsProp 1439 loss=93.996719 err=2.815356
I 2015-05-27 03:17:48 theanets.trainer:168 RmsProp 1440 loss=94.151810 err=3.008418
I 2015-05-27 03:17:48 theanets.trainer:168 validation 144 loss=1284.718506 err=1193.583618 *
I 2015-05-27 03:17:54 theanets.trainer:168 RmsProp 1441 loss=94.188431 err=3.082494
I 2015-05-27 03:18:00 theanets.trainer:168 RmsProp 1442 loss=93.988724 err=2.919786
I 2015-05-27 03:18:06 theanets.trainer:168 RmsProp 1443 loss=93.765396 err=2.735915
I 2015-05-27 03:18:12 theanets.trainer:168 RmsProp 1444 loss=93.800705 err=2.811165
I 2015-05-27 03:18:19 theanets.trainer:168 RmsProp 1445 loss=93.920334 err=2.964461
I 2015-05-27 03:18:25 theanets.trainer:168 RmsProp 1446 loss=93.629440 err=2.711433
I 2015-05-27 03:18:31 theanets.trainer:168 RmsProp 1447 loss=93.764526 err=2.880831
I 2015-05-27 03:18:38 theanets.trainer:168 RmsProp 1448 loss=93.529602 err=2.687455
I 2015-05-27 03:18:44 theanets.trainer:168 RmsProp 1449 loss=93.778183 err=2.969236
I 2015-05-27 03:18:50 theanets.trainer:168 RmsProp 1450 loss=93.729309 err=2.954100
I 2015-05-27 03:18:51 theanets.trainer:168 validation 145 loss=1279.154419 err=1188.400269 *
I 2015-05-27 03:18:56 theanets.trainer:168 RmsProp 1451 loss=93.486908 err=2.750932
I 2015-05-27 03:19:02 theanets.trainer:168 RmsProp 1452 loss=93.793373 err=3.089866
I 2015-05-27 03:19:09 theanets.trainer:168 RmsProp 1453 loss=93.701103 err=3.035162
I 2015-05-27 03:19:15 theanets.trainer:168 RmsProp 1454 loss=93.322632 err=2.696269
I 2015-05-27 03:19:21 theanets.trainer:168 RmsProp 1455 loss=93.404129 err=2.820566
I 2015-05-27 03:19:27 theanets.trainer:168 RmsProp 1456 loss=93.480759 err=2.929011
I 2015-05-27 03:19:32 theanets.trainer:168 RmsProp 1457 loss=93.338783 err=2.819279
I 2015-05-27 03:19:38 theanets.trainer:168 RmsProp 1458 loss=93.300613 err=2.820211
I 2015-05-27 03:19:44 theanets.trainer:168 RmsProp 1459 loss=93.496414 err=3.049437
I 2015-05-27 03:19:50 theanets.trainer:168 RmsProp 1460 loss=93.387619 err=2.979289
I 2015-05-27 03:19:51 theanets.trainer:168 validation 146 loss=1281.537598 err=1191.146851
I 2015-05-27 03:19:56 theanets.trainer:168 RmsProp 1461 loss=93.482086 err=3.107812
I 2015-05-27 03:20:02 theanets.trainer:168 RmsProp 1462 loss=93.162842 err=2.824750
I 2015-05-27 03:20:07 theanets.trainer:168 RmsProp 1463 loss=93.107330 err=2.805811
I 2015-05-27 03:20:13 theanets.trainer:168 RmsProp 1464 loss=92.831612 err=2.567177
I 2015-05-27 03:20:18 theanets.trainer:168 RmsProp 1465 loss=93.339523 err=3.112087
I 2015-05-27 03:20:24 theanets.trainer:168 RmsProp 1466 loss=93.095955 err=2.904906
I 2015-05-27 03:20:29 theanets.trainer:168 RmsProp 1467 loss=92.894173 err=2.743017
I 2015-05-27 03:20:35 theanets.trainer:168 RmsProp 1468 loss=93.275223 err=3.153846
I 2015-05-27 03:20:41 theanets.trainer:168 RmsProp 1469 loss=92.541840 err=2.463643
I 2015-05-27 03:20:47 theanets.trainer:168 RmsProp 1470 loss=92.849312 err=2.806940
I 2015-05-27 03:20:47 theanets.trainer:168 validation 147 loss=1278.364624 err=1188.335327 *
I 2015-05-27 03:20:53 theanets.trainer:168 RmsProp 1471 loss=93.282822 err=3.273945
I 2015-05-27 03:20:59 theanets.trainer:168 RmsProp 1472 loss=92.878708 err=2.904603
I 2015-05-27 03:21:04 theanets.trainer:168 RmsProp 1473 loss=92.639816 err=2.702707
I 2015-05-27 03:21:10 theanets.trainer:168 RmsProp 1474 loss=92.781700 err=2.883219
I 2015-05-27 03:21:16 theanets.trainer:168 RmsProp 1475 loss=92.912903 err=3.045589
I 2015-05-27 03:21:21 theanets.trainer:168 RmsProp 1476 loss=92.584755 err=2.755925
I 2015-05-27 03:21:27 theanets.trainer:168 RmsProp 1477 loss=92.636421 err=2.845737
I 2015-05-27 03:21:32 theanets.trainer:168 RmsProp 1478 loss=92.629898 err=2.875177
I 2015-05-27 03:21:38 theanets.trainer:168 RmsProp 1479 loss=92.627419 err=2.905573
I 2015-05-27 03:21:42 theanets.trainer:168 RmsProp 1480 loss=92.345222 err=2.658759
I 2015-05-27 03:21:43 theanets.trainer:168 validation 148 loss=1277.565552 err=1187.903687 *
I 2015-05-27 03:21:47 theanets.trainer:168 RmsProp 1481 loss=92.428001 err=2.779971
I 2015-05-27 03:21:52 theanets.trainer:168 RmsProp 1482 loss=92.488388 err=2.877079
I 2015-05-27 03:21:57 theanets.trainer:168 RmsProp 1483 loss=92.521866 err=2.944786
I 2015-05-27 03:22:02 theanets.trainer:168 RmsProp 1484 loss=92.503098 err=2.961188
I 2015-05-27 03:22:07 theanets.trainer:168 RmsProp 1485 loss=92.260506 err=2.756660
I 2015-05-27 03:22:11 theanets.trainer:168 RmsProp 1486 loss=92.103149 err=2.635099
I 2015-05-27 03:22:15 theanets.trainer:168 RmsProp 1487 loss=92.425667 err=2.988148
I 2015-05-27 03:22:19 theanets.trainer:168 RmsProp 1488 loss=92.195618 err=2.796385
I 2015-05-27 03:22:24 theanets.trainer:168 RmsProp 1489 loss=92.227394 err=2.861988
I 2015-05-27 03:22:28 theanets.trainer:168 RmsProp 1490 loss=92.289780 err=2.960657
I 2015-05-27 03:22:28 theanets.trainer:168 validation 149 loss=1276.379272 err=1187.071167 *
I 2015-05-27 03:22:32 theanets.trainer:168 RmsProp 1491 loss=92.233696 err=2.938926
I 2015-05-27 03:22:37 theanets.trainer:168 RmsProp 1492 loss=92.028160 err=2.770552
I 2015-05-27 03:22:42 theanets.trainer:168 RmsProp 1493 loss=92.012955 err=2.792504
I 2015-05-27 03:22:47 theanets.trainer:168 RmsProp 1494 loss=92.045021 err=2.861172
I 2015-05-27 03:22:52 theanets.trainer:168 RmsProp 1495 loss=92.142136 err=2.992441
I 2015-05-27 03:22:57 theanets.trainer:168 RmsProp 1496 loss=91.701622 err=2.587821
I 2015-05-27 03:23:02 theanets.trainer:168 RmsProp 1497 loss=92.135536 err=3.058321
I 2015-05-27 03:23:07 theanets.trainer:168 RmsProp 1498 loss=91.577141 err=2.534913
I 2015-05-27 03:23:13 theanets.trainer:168 RmsProp 1499 loss=92.120796 err=3.111961
I 2015-05-27 03:23:18 theanets.trainer:168 RmsProp 1500 loss=92.105652 err=3.127200
I 2015-05-27 03:23:18 theanets.trainer:168 validation 150 loss=1276.290039 err=1187.323486 *
I 2015-05-27 03:23:23 theanets.trainer:168 RmsProp 1501 loss=91.481369 err=2.540414
I 2015-05-27 03:23:28 theanets.trainer:168 RmsProp 1502 loss=92.232376 err=3.325551
I 2015-05-27 03:23:33 theanets.trainer:168 RmsProp 1503 loss=91.519760 err=2.647069
I 2015-05-27 03:23:38 theanets.trainer:168 RmsProp 1504 loss=91.645798 err=2.809205
I 2015-05-27 03:23:43 theanets.trainer:168 RmsProp 1505 loss=91.643478 err=2.841206
I 2015-05-27 03:23:49 theanets.trainer:168 RmsProp 1506 loss=91.647865 err=2.881839
I 2015-05-27 03:23:53 theanets.trainer:168 RmsProp 1507 loss=91.604797 err=2.874809
I 2015-05-27 03:23:58 theanets.trainer:168 RmsProp 1508 loss=91.435829 err=2.737243
I 2015-05-27 03:24:03 theanets.trainer:168 RmsProp 1509 loss=91.657639 err=2.993410
I 2015-05-27 03:24:08 theanets.trainer:168 RmsProp 1510 loss=91.536781 err=2.904209
I 2015-05-27 03:24:08 theanets.trainer:168 validation 151 loss=1268.341431 err=1179.731689 *
I 2015-05-27 03:24:13 theanets.trainer:168 RmsProp 1511 loss=91.341354 err=2.743436
I 2015-05-27 03:24:18 theanets.trainer:168 RmsProp 1512 loss=91.365891 err=2.802248
I 2015-05-27 03:24:23 theanets.trainer:168 RmsProp 1513 loss=91.388519 err=2.861096
I 2015-05-27 03:24:28 theanets.trainer:168 RmsProp 1514 loss=91.357407 err=2.865461
I 2015-05-27 03:24:34 theanets.trainer:168 RmsProp 1515 loss=91.301208 err=2.844953
I 2015-05-27 03:24:39 theanets.trainer:168 RmsProp 1516 loss=91.519936 err=3.095829
I 2015-05-27 03:24:44 theanets.trainer:168 RmsProp 1517 loss=90.833916 err=2.446848
I 2015-05-27 03:24:49 theanets.trainer:168 RmsProp 1518 loss=91.276566 err=2.926427
I 2015-05-27 03:24:54 theanets.trainer:168 RmsProp 1519 loss=91.260574 err=2.944698
I 2015-05-27 03:24:59 theanets.trainer:168 RmsProp 1520 loss=90.982422 err=2.700457
I 2015-05-27 03:25:00 theanets.trainer:168 validation 152 loss=1266.594849 err=1178.340210 *
I 2015-05-27 03:25:04 theanets.trainer:168 RmsProp 1521 loss=91.008522 err=2.762616
I 2015-05-27 03:25:10 theanets.trainer:168 RmsProp 1522 loss=90.850136 err=2.637830
I 2015-05-27 03:25:15 theanets.trainer:168 RmsProp 1523 loss=91.092087 err=2.910503
I 2015-05-27 03:25:20 theanets.trainer:168 RmsProp 1524 loss=91.390572 err=3.238799
I 2015-05-27 03:25:25 theanets.trainer:168 RmsProp 1525 loss=90.791672 err=2.674872
I 2015-05-27 03:25:30 theanets.trainer:168 RmsProp 1526 loss=90.655952 err=2.576020
I 2015-05-27 03:25:35 theanets.trainer:168 RmsProp 1527 loss=91.214935 err=3.167560
I 2015-05-27 03:25:40 theanets.trainer:168 RmsProp 1528 loss=90.899376 err=2.889228
I 2015-05-27 03:25:46 theanets.trainer:168 RmsProp 1529 loss=90.862701 err=2.884207
I 2015-05-27 03:25:51 theanets.trainer:168 RmsProp 1530 loss=90.686996 err=2.740122
I 2015-05-27 03:25:51 theanets.trainer:168 validation 153 loss=1264.646362 err=1176.716431 *
I 2015-05-27 03:25:56 theanets.trainer:168 RmsProp 1531 loss=90.682014 err=2.769518
I 2015-05-27 03:26:01 theanets.trainer:168 RmsProp 1532 loss=90.992249 err=3.113125
I 2015-05-27 03:26:06 theanets.trainer:168 RmsProp 1533 loss=90.630760 err=2.785077
I 2015-05-27 03:26:11 theanets.trainer:168 RmsProp 1534 loss=90.552597 err=2.742846
I 2015-05-27 03:26:17 theanets.trainer:168 RmsProp 1535 loss=90.915932 err=3.140106
I 2015-05-27 03:26:22 theanets.trainer:168 RmsProp 1536 loss=90.775986 err=3.028076
I 2015-05-27 03:26:27 theanets.trainer:168 RmsProp 1537 loss=90.339256 err=2.623891
I 2015-05-27 03:26:32 theanets.trainer:168 RmsProp 1538 loss=90.509346 err=2.827510
I 2015-05-27 03:26:37 theanets.trainer:168 RmsProp 1539 loss=90.586319 err=2.939373
I 2015-05-27 03:26:42 theanets.trainer:168 RmsProp 1540 loss=90.429939 err=2.814549
I 2015-05-27 03:26:43 theanets.trainer:168 validation 154 loss=1263.006714 err=1175.406128 *
I 2015-05-27 03:26:47 theanets.trainer:168 RmsProp 1541 loss=90.486671 err=2.905768
I 2015-05-27 03:26:53 theanets.trainer:168 RmsProp 1542 loss=90.195938 err=2.651641
I 2015-05-27 03:26:58 theanets.trainer:168 RmsProp 1543 loss=90.295937 err=2.782473
I 2015-05-27 03:27:03 theanets.trainer:168 RmsProp 1544 loss=90.254807 err=2.775555
I 2015-05-27 03:27:08 theanets.trainer:168 RmsProp 1545 loss=90.399704 err=2.950666
I 2015-05-27 03:27:13 theanets.trainer:168 RmsProp 1546 loss=90.233360 err=2.816043
I 2015-05-27 03:27:18 theanets.trainer:168 RmsProp 1547 loss=90.134323 err=2.752359
I 2015-05-27 03:27:24 theanets.trainer:168 RmsProp 1548 loss=90.107056 err=2.761774
I 2015-05-27 03:27:29 theanets.trainer:168 RmsProp 1549 loss=90.259544 err=2.947210
I 2015-05-27 03:27:34 theanets.trainer:168 RmsProp 1550 loss=89.957840 err=2.676063
I 2015-05-27 03:27:35 theanets.trainer:168 validation 155 loss=1262.849243 err=1175.584473 *
I 2015-05-27 03:27:39 theanets.trainer:168 RmsProp 1551 loss=90.160416 err=2.910494
I 2015-05-27 03:27:44 theanets.trainer:168 RmsProp 1552 loss=90.165970 err=2.948812
I 2015-05-27 03:27:49 theanets.trainer:168 RmsProp 1553 loss=90.009315 err=2.829236
I 2015-05-27 03:27:54 theanets.trainer:168 RmsProp 1554 loss=89.952629 err=2.804279
I 2015-05-27 03:28:00 theanets.trainer:168 RmsProp 1555 loss=89.592346 err=2.477210
I 2015-05-27 03:28:04 theanets.trainer:168 RmsProp 1556 loss=90.266891 err=3.178245
I 2015-05-27 03:28:10 theanets.trainer:168 RmsProp 1557 loss=90.049057 err=2.990140
I 2015-05-27 03:28:15 theanets.trainer:168 RmsProp 1558 loss=89.889671 err=2.865679
I 2015-05-27 03:28:20 theanets.trainer:168 RmsProp 1559 loss=89.641220 err=2.655616
I 2015-05-27 03:28:25 theanets.trainer:168 RmsProp 1560 loss=89.865410 err=2.913378
I 2015-05-27 03:28:26 theanets.trainer:168 validation 156 loss=1259.011841 err=1172.073120 *
I 2015-05-27 03:28:30 theanets.trainer:168 RmsProp 1561 loss=89.630585 err=2.708836
I 2015-05-27 03:28:36 theanets.trainer:168 RmsProp 1562 loss=89.758026 err=2.865663
I 2015-05-27 03:28:41 theanets.trainer:168 RmsProp 1563 loss=89.231705 err=2.374992
I 2015-05-27 03:28:46 theanets.trainer:168 RmsProp 1564 loss=90.186447 err=3.356057
I 2015-05-27 03:28:51 theanets.trainer:168 RmsProp 1565 loss=89.687233 err=2.892254
I 2015-05-27 03:28:56 theanets.trainer:168 RmsProp 1566 loss=89.702072 err=2.942482
I 2015-05-27 03:29:01 theanets.trainer:168 RmsProp 1567 loss=89.458885 err=2.732060
I 2015-05-27 03:29:06 theanets.trainer:168 RmsProp 1568 loss=89.350685 err=2.656153
I 2015-05-27 03:29:11 theanets.trainer:168 RmsProp 1569 loss=89.455887 err=2.791518
I 2015-05-27 03:29:17 theanets.trainer:168 RmsProp 1570 loss=89.620155 err=2.982972
I 2015-05-27 03:29:17 theanets.trainer:168 validation 157 loss=1255.067993 err=1168.450684 *
I 2015-05-27 03:29:22 theanets.trainer:168 RmsProp 1571 loss=89.285873 err=2.680277
I 2015-05-27 03:29:27 theanets.trainer:168 RmsProp 1572 loss=89.344879 err=2.774094
I 2015-05-27 03:29:32 theanets.trainer:168 RmsProp 1573 loss=89.387009 err=2.847359
I 2015-05-27 03:29:37 theanets.trainer:168 RmsProp 1574 loss=89.293854 err=2.789222
I 2015-05-27 03:29:42 theanets.trainer:168 RmsProp 1575 loss=89.108376 err=2.637149
I 2015-05-27 03:29:46 theanets.trainer:168 RmsProp 1576 loss=89.437576 err=2.995104
I 2015-05-27 03:29:51 theanets.trainer:168 RmsProp 1577 loss=89.062935 err=2.653974
I 2015-05-27 03:29:55 theanets.trainer:168 RmsProp 1578 loss=89.143158 err=2.765381
I 2015-05-27 03:30:00 theanets.trainer:168 RmsProp 1579 loss=89.055344 err=2.708429
I 2015-05-27 03:30:04 theanets.trainer:168 RmsProp 1580 loss=89.270676 err=2.955739
I 2015-05-27 03:30:04 theanets.trainer:168 validation 158 loss=1256.021973 err=1169.719849
I 2015-05-27 03:30:09 theanets.trainer:168 RmsProp 1581 loss=88.923347 err=2.642787
I 2015-05-27 03:30:14 theanets.trainer:168 RmsProp 1582 loss=89.028259 err=2.778165
I 2015-05-27 03:30:19 theanets.trainer:168 RmsProp 1583 loss=88.876480 err=2.659968
I 2015-05-27 03:30:25 theanets.trainer:168 RmsProp 1584 loss=89.135506 err=2.950988
I 2015-05-27 03:30:30 theanets.trainer:168 RmsProp 1585 loss=88.917809 err=2.762473
I 2015-05-27 03:30:35 theanets.trainer:168 RmsProp 1586 loss=88.975952 err=2.854730
I 2015-05-27 03:30:40 theanets.trainer:168 RmsProp 1587 loss=88.895988 err=2.805603
I 2015-05-27 03:30:45 theanets.trainer:168 RmsProp 1588 loss=88.933067 err=2.873976
I 2015-05-27 03:30:50 theanets.trainer:168 RmsProp 1589 loss=88.883400 err=2.856346
I 2015-05-27 03:30:56 theanets.trainer:168 RmsProp 1590 loss=88.597954 err=2.606219
I 2015-05-27 03:30:56 theanets.trainer:168 validation 159 loss=1254.165405 err=1168.194092 *
I 2015-05-27 03:31:01 theanets.trainer:168 RmsProp 1591 loss=88.837387 err=2.877238
I 2015-05-27 03:31:06 theanets.trainer:168 RmsProp 1592 loss=89.037460 err=3.106819
I 2015-05-27 03:31:11 theanets.trainer:168 RmsProp 1593 loss=88.509903 err=2.614781
I 2015-05-27 03:31:16 theanets.trainer:168 RmsProp 1594 loss=88.969223 err=3.100822
I 2015-05-27 03:31:21 theanets.trainer:168 RmsProp 1595 loss=88.557373 err=2.722776
I 2015-05-27 03:31:27 theanets.trainer:168 RmsProp 1596 loss=88.559799 err=2.753767
I 2015-05-27 03:31:32 theanets.trainer:168 RmsProp 1597 loss=88.549149 err=2.772174
I 2015-05-27 03:31:37 theanets.trainer:168 RmsProp 1598 loss=88.466393 err=2.723664
I 2015-05-27 03:31:42 theanets.trainer:168 RmsProp 1599 loss=88.640755 err=2.926122
I 2015-05-27 03:31:47 theanets.trainer:168 RmsProp 1600 loss=88.306961 err=2.627918
I 2015-05-27 03:31:48 theanets.trainer:168 validation 160 loss=1256.829102 err=1171.165039
I 2015-05-27 03:31:52 theanets.trainer:168 RmsProp 1601 loss=88.944305 err=3.291817
I 2015-05-27 03:31:58 theanets.trainer:168 RmsProp 1602 loss=88.535049 err=2.912514
I 2015-05-27 03:32:03 theanets.trainer:168 RmsProp 1603 loss=88.228279 err=2.636531
I 2015-05-27 03:32:08 theanets.trainer:168 RmsProp 1604 loss=88.446396 err=2.882738
I 2015-05-27 03:32:13 theanets.trainer:168 RmsProp 1605 loss=88.110329 err=2.579147
I 2015-05-27 03:32:18 theanets.trainer:168 RmsProp 1606 loss=88.432030 err=2.933033
I 2015-05-27 03:32:23 theanets.trainer:168 RmsProp 1607 loss=88.194321 err=2.725229
I 2015-05-27 03:32:28 theanets.trainer:168 RmsProp 1608 loss=88.313995 err=2.874713
I 2015-05-27 03:32:34 theanets.trainer:168 RmsProp 1609 loss=88.437653 err=3.028724
I 2015-05-27 03:32:39 theanets.trainer:168 RmsProp 1610 loss=88.163506 err=2.786165
I 2015-05-27 03:32:39 theanets.trainer:168 validation 161 loss=1249.907837 err=1164.541260 *
I 2015-05-27 03:32:44 theanets.trainer:168 RmsProp 1611 loss=88.452835 err=3.104369
I 2015-05-27 03:32:49 theanets.trainer:168 RmsProp 1612 loss=88.069618 err=2.751403
I 2015-05-27 03:32:54 theanets.trainer:168 RmsProp 1613 loss=88.173775 err=2.885467
I 2015-05-27 03:32:59 theanets.trainer:168 RmsProp 1614 loss=88.019852 err=2.769050
I 2015-05-27 03:33:04 theanets.trainer:168 RmsProp 1615 loss=87.969162 err=2.745060
I 2015-05-27 03:33:09 theanets.trainer:168 RmsProp 1616 loss=87.730324 err=2.542407
I 2015-05-27 03:33:14 theanets.trainer:168 RmsProp 1617 loss=88.210800 err=3.048536
I 2015-05-27 03:33:19 theanets.trainer:168 RmsProp 1618 loss=87.627579 err=2.496958
I 2015-05-27 03:33:25 theanets.trainer:168 RmsProp 1619 loss=88.031052 err=2.930812
I 2015-05-27 03:33:30 theanets.trainer:168 RmsProp 1620 loss=87.757858 err=2.688897
I 2015-05-27 03:33:30 theanets.trainer:168 validation 162 loss=1247.375366 err=1162.327148 *
I 2015-05-27 03:33:35 theanets.trainer:168 RmsProp 1621 loss=87.769051 err=2.729626
I 2015-05-27 03:33:40 theanets.trainer:168 RmsProp 1622 loss=87.791031 err=2.781043
I 2015-05-27 03:33:45 theanets.trainer:168 RmsProp 1623 loss=87.642014 err=2.664027
I 2015-05-27 03:33:50 theanets.trainer:168 RmsProp 1624 loss=88.233704 err=3.281337
I 2015-05-27 03:33:55 theanets.trainer:168 RmsProp 1625 loss=87.497772 err=2.583651
I 2015-05-27 03:34:01 theanets.trainer:168 RmsProp 1626 loss=87.531998 err=2.651368
I 2015-05-27 03:34:06 theanets.trainer:168 RmsProp 1627 loss=87.587326 err=2.734497
I 2015-05-27 03:34:10 theanets.trainer:168 RmsProp 1628 loss=87.436668 err=2.612532
I 2015-05-27 03:34:15 theanets.trainer:168 RmsProp 1629 loss=87.861351 err=3.061589
I 2015-05-27 03:34:19 theanets.trainer:168 RmsProp 1630 loss=87.524704 err=2.758415
I 2015-05-27 03:34:19 theanets.trainer:168 validation 163 loss=1247.592896 err=1162.848511
I 2015-05-27 03:34:24 theanets.trainer:168 RmsProp 1631 loss=87.382805 err=2.650874
I 2015-05-27 03:34:28 theanets.trainer:168 RmsProp 1632 loss=87.595245 err=2.890811
I 2015-05-27 03:34:33 theanets.trainer:168 RmsProp 1633 loss=87.381989 err=2.709517
I 2015-05-27 03:34:38 theanets.trainer:168 RmsProp 1634 loss=87.386520 err=2.740550
I 2015-05-27 03:34:43 theanets.trainer:168 RmsProp 1635 loss=87.322639 err=2.711562
I 2015-05-27 03:34:48 theanets.trainer:168 RmsProp 1636 loss=87.527710 err=2.942049
I 2015-05-27 03:34:53 theanets.trainer:168 RmsProp 1637 loss=87.253456 err=2.700453
I 2015-05-27 03:34:59 theanets.trainer:168 RmsProp 1638 loss=87.343925 err=2.823001
I 2015-05-27 03:35:03 theanets.trainer:168 RmsProp 1639 loss=87.213425 err=2.722262
I 2015-05-27 03:35:08 theanets.trainer:168 RmsProp 1640 loss=87.125534 err=2.664861
I 2015-05-27 03:35:09 theanets.trainer:168 validation 164 loss=1247.564453 err=1163.116089
I 2015-05-27 03:35:13 theanets.trainer:168 RmsProp 1641 loss=87.302200 err=2.870099
I 2015-05-27 03:35:18 theanets.trainer:168 RmsProp 1642 loss=87.006248 err=2.606452
I 2015-05-27 03:35:23 theanets.trainer:168 RmsProp 1643 loss=87.321526 err=2.951388
I 2015-05-27 03:35:29 theanets.trainer:168 RmsProp 1644 loss=87.242851 err=2.898880
I 2015-05-27 03:35:34 theanets.trainer:168 RmsProp 1645 loss=87.212059 err=2.894071
I 2015-05-27 03:35:39 theanets.trainer:168 RmsProp 1646 loss=87.107483 err=2.819887
I 2015-05-27 03:35:44 theanets.trainer:168 RmsProp 1647 loss=87.218056 err=2.962805
I 2015-05-27 03:35:49 theanets.trainer:168 RmsProp 1648 loss=86.991440 err=2.763812
I 2015-05-27 03:35:54 theanets.trainer:168 RmsProp 1649 loss=86.946815 err=2.749653
I 2015-05-27 03:35:59 theanets.trainer:168 RmsProp 1650 loss=86.930054 err=2.762613
I 2015-05-27 03:35:59 theanets.trainer:168 validation 165 loss=1245.972900 err=1161.815796 *
I 2015-05-27 03:36:04 theanets.trainer:168 RmsProp 1651 loss=86.779526 err=2.643654
I 2015-05-27 03:36:09 theanets.trainer:168 RmsProp 1652 loss=87.172775 err=3.061826
I 2015-05-27 03:36:14 theanets.trainer:168 RmsProp 1653 loss=86.721558 err=2.642140
I 2015-05-27 03:36:20 theanets.trainer:168 RmsProp 1654 loss=86.900124 err=2.849766
I 2015-05-27 03:36:25 theanets.trainer:168 RmsProp 1655 loss=86.733383 err=2.710633
I 2015-05-27 03:36:30 theanets.trainer:168 RmsProp 1656 loss=86.674713 err=2.681518
I 2015-05-27 03:36:35 theanets.trainer:168 RmsProp 1657 loss=86.667381 err=2.702969
I 2015-05-27 03:36:40 theanets.trainer:168 RmsProp 1658 loss=86.726585 err=2.795188
I 2015-05-27 03:36:45 theanets.trainer:168 RmsProp 1659 loss=86.726219 err=2.822841
I 2015-05-27 03:36:51 theanets.trainer:168 RmsProp 1660 loss=86.746437 err=2.868753
I 2015-05-27 03:36:51 theanets.trainer:168 validation 166 loss=1243.052612 err=1159.191528 *
I 2015-05-27 03:36:56 theanets.trainer:168 RmsProp 1661 loss=86.435257 err=2.584565
I 2015-05-27 03:37:01 theanets.trainer:168 RmsProp 1662 loss=86.576225 err=2.752348
I 2015-05-27 03:37:06 theanets.trainer:168 RmsProp 1663 loss=86.824043 err=3.031139
I 2015-05-27 03:37:11 theanets.trainer:168 RmsProp 1664 loss=86.553513 err=2.790322
I 2015-05-27 03:37:16 theanets.trainer:168 RmsProp 1665 loss=86.614212 err=2.881033
I 2015-05-27 03:37:21 theanets.trainer:168 RmsProp 1666 loss=86.311066 err=2.606281
I 2015-05-27 03:37:26 theanets.trainer:168 RmsProp 1667 loss=86.468140 err=2.791302
I 2015-05-27 03:37:32 theanets.trainer:168 RmsProp 1668 loss=86.354630 err=2.708094
I 2015-05-27 03:37:37 theanets.trainer:168 RmsProp 1669 loss=86.339081 err=2.721159
I 2015-05-27 03:37:42 theanets.trainer:168 RmsProp 1670 loss=86.206581 err=2.619120
I 2015-05-27 03:37:43 theanets.trainer:168 validation 167 loss=1245.672363 err=1162.098999
I 2015-05-27 03:37:47 theanets.trainer:168 RmsProp 1671 loss=86.390656 err=2.829169
I 2015-05-27 03:37:52 theanets.trainer:168 RmsProp 1672 loss=86.429474 err=2.896284
I 2015-05-27 03:37:58 theanets.trainer:168 RmsProp 1673 loss=86.235214 err=2.730125
I 2015-05-27 03:38:03 theanets.trainer:168 RmsProp 1674 loss=86.348831 err=2.873214
I 2015-05-27 03:38:08 theanets.trainer:168 RmsProp 1675 loss=86.225670 err=2.779150
I 2015-05-27 03:38:13 theanets.trainer:168 RmsProp 1676 loss=86.244347 err=2.825128
I 2015-05-27 03:38:17 theanets.trainer:168 RmsProp 1677 loss=85.884079 err=2.498053
I 2015-05-27 03:38:21 theanets.trainer:168 RmsProp 1678 loss=86.163612 err=2.805056
I 2015-05-27 03:38:25 theanets.trainer:168 RmsProp 1679 loss=86.007095 err=2.679443
I 2015-05-27 03:38:30 theanets.trainer:168 RmsProp 1680 loss=85.932617 err=2.632360
I 2015-05-27 03:38:30 theanets.trainer:168 validation 168 loss=1242.682373 err=1159.394043 *
I 2015-05-27 03:38:34 theanets.trainer:168 RmsProp 1681 loss=86.319664 err=3.043492
I 2015-05-27 03:38:38 theanets.trainer:168 RmsProp 1682 loss=86.032181 err=2.788388
I 2015-05-27 03:38:42 theanets.trainer:168 RmsProp 1683 loss=86.164268 err=2.946305
I 2015-05-27 03:38:46 theanets.trainer:168 RmsProp 1684 loss=86.044708 err=2.855100
I 2015-05-27 03:38:50 theanets.trainer:168 RmsProp 1685 loss=85.786240 err=2.626405
I 2015-05-27 03:38:54 theanets.trainer:168 RmsProp 1686 loss=85.919830 err=2.790110
I 2015-05-27 03:38:58 theanets.trainer:168 RmsProp 1687 loss=85.850052 err=2.747743
I 2015-05-27 03:39:02 theanets.trainer:168 RmsProp 1688 loss=85.675949 err=2.601498
I 2015-05-27 03:39:06 theanets.trainer:168 RmsProp 1689 loss=85.853966 err=2.807155
I 2015-05-27 03:39:10 theanets.trainer:168 RmsProp 1690 loss=86.002449 err=2.980580
I 2015-05-27 03:39:11 theanets.trainer:168 validation 169 loss=1239.034912 err=1156.031982 *
I 2015-05-27 03:39:14 theanets.trainer:168 RmsProp 1691 loss=85.628586 err=2.637219
I 2015-05-27 03:39:18 theanets.trainer:168 RmsProp 1692 loss=85.761681 err=2.798151
I 2015-05-27 03:39:22 theanets.trainer:168 RmsProp 1693 loss=85.447533 err=2.516258
I 2015-05-27 03:39:26 theanets.trainer:168 RmsProp 1694 loss=85.864845 err=2.960043
I 2015-05-27 03:39:30 theanets.trainer:168 RmsProp 1695 loss=85.480988 err=2.602015
I 2015-05-27 03:39:34 theanets.trainer:168 RmsProp 1696 loss=85.707352 err=2.858770
I 2015-05-27 03:39:38 theanets.trainer:168 RmsProp 1697 loss=85.504456 err=2.681289
I 2015-05-27 03:39:42 theanets.trainer:168 RmsProp 1698 loss=85.440910 err=2.648072
I 2015-05-27 03:39:46 theanets.trainer:168 RmsProp 1699 loss=85.563675 err=2.794512
I 2015-05-27 03:39:51 theanets.trainer:168 RmsProp 1700 loss=85.661880 err=2.922333
I 2015-05-27 03:39:51 theanets.trainer:168 validation 170 loss=1235.333496 err=1152.604858 *
I 2015-05-27 03:39:54 theanets.trainer:168 RmsProp 1701 loss=85.400352 err=2.690541
I 2015-05-27 03:39:58 theanets.trainer:168 RmsProp 1702 loss=85.342361 err=2.662957
I 2015-05-27 03:40:02 theanets.trainer:168 RmsProp 1703 loss=85.359756 err=2.710613
I 2015-05-27 03:40:06 theanets.trainer:168 RmsProp 1704 loss=85.304077 err=2.679141
I 2015-05-27 03:40:10 theanets.trainer:168 RmsProp 1705 loss=85.397514 err=2.801989
I 2015-05-27 03:40:14 theanets.trainer:168 RmsProp 1706 loss=85.511696 err=2.940591
I 2015-05-27 03:40:18 theanets.trainer:168 RmsProp 1707 loss=85.014938 err=2.476798
I 2015-05-27 03:40:22 theanets.trainer:168 RmsProp 1708 loss=85.240417 err=2.728223
I 2015-05-27 03:40:26 theanets.trainer:168 RmsProp 1709 loss=85.315109 err=2.828469
I 2015-05-27 03:40:30 theanets.trainer:168 RmsProp 1710 loss=85.336487 err=2.875375
I 2015-05-27 03:40:31 theanets.trainer:168 validation 171 loss=1234.032471 err=1151.578979 *
I 2015-05-27 03:40:35 theanets.trainer:168 RmsProp 1711 loss=85.129494 err=2.697903
I 2015-05-27 03:40:39 theanets.trainer:168 RmsProp 1712 loss=85.379784 err=2.978306
I 2015-05-27 03:40:43 theanets.trainer:168 RmsProp 1713 loss=85.267822 err=2.893107
I 2015-05-27 03:40:47 theanets.trainer:168 RmsProp 1714 loss=85.059753 err=2.711940
I 2015-05-27 03:40:51 theanets.trainer:168 RmsProp 1715 loss=85.085304 err=2.762516
I 2015-05-27 03:40:55 theanets.trainer:168 RmsProp 1716 loss=85.196983 err=2.900310
I 2015-05-27 03:40:59 theanets.trainer:168 RmsProp 1717 loss=84.902161 err=2.633502
I 2015-05-27 03:41:03 theanets.trainer:168 RmsProp 1718 loss=85.227066 err=2.983733
I 2015-05-27 03:41:07 theanets.trainer:168 RmsProp 1719 loss=85.022072 err=2.806830
I 2015-05-27 03:41:11 theanets.trainer:168 RmsProp 1720 loss=84.760231 err=2.570739
I 2015-05-27 03:41:12 theanets.trainer:168 validation 172 loss=1231.004517 err=1148.834595 *
I 2015-05-27 03:41:16 theanets.trainer:168 RmsProp 1721 loss=84.979004 err=2.816809
I 2015-05-27 03:41:20 theanets.trainer:168 RmsProp 1722 loss=84.973137 err=2.839902
I 2015-05-27 03:41:24 theanets.trainer:168 RmsProp 1723 loss=84.803947 err=2.697534
I 2015-05-27 03:41:28 theanets.trainer:168 RmsProp 1724 loss=85.114243 err=3.032672
I 2015-05-27 03:41:32 theanets.trainer:168 RmsProp 1725 loss=84.779861 err=2.727319
I 2015-05-27 03:41:36 theanets.trainer:168 RmsProp 1726 loss=84.825554 err=2.802389
I 2015-05-27 03:41:40 theanets.trainer:168 RmsProp 1727 loss=84.634697 err=2.639064
I 2015-05-27 03:41:44 theanets.trainer:168 RmsProp 1728 loss=84.665863 err=2.700778
I 2015-05-27 03:41:48 theanets.trainer:168 RmsProp 1729 loss=84.681503 err=2.737519
I 2015-05-27 03:41:52 theanets.trainer:168 RmsProp 1730 loss=84.678055 err=2.762866
I 2015-05-27 03:41:53 theanets.trainer:168 validation 173 loss=1230.049805 err=1148.153687 *
I 2015-05-27 03:41:56 theanets.trainer:168 RmsProp 1731 loss=84.703575 err=2.815670
I 2015-05-27 03:42:00 theanets.trainer:168 RmsProp 1732 loss=84.453819 err=2.591427
I 2015-05-27 03:42:04 theanets.trainer:168 RmsProp 1733 loss=84.569901 err=2.738087
I 2015-05-27 03:42:08 theanets.trainer:168 RmsProp 1734 loss=84.527847 err=2.724565
I 2015-05-27 03:42:12 theanets.trainer:168 RmsProp 1735 loss=84.884132 err=3.103571
I 2015-05-27 03:42:16 theanets.trainer:168 RmsProp 1736 loss=84.436508 err=2.683622
I 2015-05-27 03:42:20 theanets.trainer:168 RmsProp 1737 loss=84.587875 err=2.862689
I 2015-05-27 03:42:24 theanets.trainer:168 RmsProp 1738 loss=84.285416 err=2.586699
I 2015-05-27 03:42:28 theanets.trainer:168 RmsProp 1739 loss=84.571495 err=2.894816
I 2015-05-27 03:42:32 theanets.trainer:168 RmsProp 1740 loss=84.085442 err=2.440082
I 2015-05-27 03:42:32 theanets.trainer:168 validation 174 loss=1230.872681 err=1149.240234
I 2015-05-27 03:42:36 theanets.trainer:168 RmsProp 1741 loss=84.619186 err=3.002276
I 2015-05-27 03:42:40 theanets.trainer:168 RmsProp 1742 loss=84.196342 err=2.603943
I 2015-05-27 03:42:44 theanets.trainer:168 RmsProp 1743 loss=84.070053 err=2.506924
I 2015-05-27 03:42:48 theanets.trainer:168 RmsProp 1744 loss=84.610748 err=3.072537
I 2015-05-27 03:42:52 theanets.trainer:168 RmsProp 1745 loss=84.483780 err=2.970098
I 2015-05-27 03:42:56 theanets.trainer:168 RmsProp 1746 loss=84.056206 err=2.573496
I 2015-05-27 03:43:00 theanets.trainer:168 RmsProp 1747 loss=84.169632 err=2.716622
I 2015-05-27 03:43:05 theanets.trainer:168 RmsProp 1748 loss=84.325974 err=2.898944
I 2015-05-27 03:43:09 theanets.trainer:168 RmsProp 1749 loss=83.991493 err=2.590188
I 2015-05-27 03:43:13 theanets.trainer:168 RmsProp 1750 loss=84.039291 err=2.664719
I 2015-05-27 03:43:13 theanets.trainer:168 validation 175 loss=1232.760010 err=1151.396240
I 2015-05-27 03:43:17 theanets.trainer:168 RmsProp 1751 loss=84.274712 err=2.924877
I 2015-05-27 03:43:21 theanets.trainer:168 RmsProp 1752 loss=83.907494 err=2.589251
I 2015-05-27 03:43:25 theanets.trainer:168 RmsProp 1753 loss=84.184402 err=2.889724
I 2015-05-27 03:43:29 theanets.trainer:168 RmsProp 1754 loss=84.152786 err=2.884620
I 2015-05-27 03:43:33 theanets.trainer:168 RmsProp 1755 loss=83.878860 err=2.639121
I 2015-05-27 03:43:37 theanets.trainer:168 RmsProp 1756 loss=84.043777 err=2.834030
I 2015-05-27 03:43:42 theanets.trainer:168 RmsProp 1757 loss=83.854622 err=2.670336
I 2015-05-27 03:43:46 theanets.trainer:168 RmsProp 1758 loss=83.878616 err=2.720964
I 2015-05-27 03:43:50 theanets.trainer:168 RmsProp 1759 loss=84.084930 err=2.949638
I 2015-05-27 03:43:54 theanets.trainer:168 RmsProp 1760 loss=83.573479 err=2.466907
I 2015-05-27 03:43:54 theanets.trainer:168 validation 176 loss=1228.523804 err=1147.439453 *
I 2015-05-27 03:43:58 theanets.trainer:168 RmsProp 1761 loss=83.790657 err=2.712702
I 2015-05-27 03:44:02 theanets.trainer:168 RmsProp 1762 loss=83.728439 err=2.674261
I 2015-05-27 03:44:06 theanets.trainer:168 RmsProp 1763 loss=83.815651 err=2.788531
I 2015-05-27 03:44:10 theanets.trainer:168 RmsProp 1764 loss=83.794495 err=2.793547
I 2015-05-27 03:44:14 theanets.trainer:168 RmsProp 1765 loss=83.501129 err=2.527946
I 2015-05-27 03:44:18 theanets.trainer:168 RmsProp 1766 loss=83.677345 err=2.733005
I 2015-05-27 03:44:22 theanets.trainer:168 RmsProp 1767 loss=83.761681 err=2.841128
I 2015-05-27 03:44:26 theanets.trainer:168 RmsProp 1768 loss=83.483536 err=2.588995
I 2015-05-27 03:44:30 theanets.trainer:168 RmsProp 1769 loss=84.052887 err=3.179600
I 2015-05-27 03:44:34 theanets.trainer:168 RmsProp 1770 loss=83.506897 err=2.662685
I 2015-05-27 03:44:35 theanets.trainer:168 validation 177 loss=1227.108276 err=1146.280884 *
I 2015-05-27 03:44:39 theanets.trainer:168 RmsProp 1771 loss=83.300804 err=2.485428
I 2015-05-27 03:44:42 theanets.trainer:168 RmsProp 1772 loss=83.584206 err=2.795317
I 2015-05-27 03:44:47 theanets.trainer:168 RmsProp 1773 loss=83.697586 err=2.934468
I 2015-05-27 03:44:51 theanets.trainer:168 RmsProp 1774 loss=83.429085 err=2.690545
I 2015-05-27 03:44:55 theanets.trainer:168 RmsProp 1775 loss=83.403625 err=2.693639
I 2015-05-27 03:44:58 theanets.trainer:168 RmsProp 1776 loss=83.401993 err=2.718544
I 2015-05-27 03:45:00 theanets.trainer:168 RmsProp 1777 loss=83.507378 err=2.851010
I 2015-05-27 03:45:03 theanets.trainer:168 RmsProp 1778 loss=83.210045 err=2.579879
I 2015-05-27 03:45:06 theanets.trainer:168 RmsProp 1779 loss=83.446495 err=2.841969
I 2015-05-27 03:45:09 theanets.trainer:168 RmsProp 1780 loss=83.199356 err=2.620107
I 2015-05-27 03:45:09 theanets.trainer:168 validation 178 loss=1223.639282 err=1143.075195 *
I 2015-05-27 03:45:12 theanets.trainer:168 RmsProp 1781 loss=83.332466 err=2.779692
I 2015-05-27 03:45:15 theanets.trainer:168 RmsProp 1782 loss=83.099503 err=2.574006
I 2015-05-27 03:45:17 theanets.trainer:168 RmsProp 1783 loss=83.260704 err=2.763072
I 2015-05-27 03:45:20 theanets.trainer:168 RmsProp 1784 loss=83.055344 err=2.585782
I 2015-05-27 03:45:23 theanets.trainer:168 RmsProp 1785 loss=83.270256 err=2.824605
I 2015-05-27 03:45:25 theanets.trainer:168 RmsProp 1786 loss=83.183273 err=2.765507
I 2015-05-27 03:45:28 theanets.trainer:168 RmsProp 1787 loss=83.017570 err=2.626517
I 2015-05-27 03:45:30 theanets.trainer:168 RmsProp 1788 loss=83.185776 err=2.816680
I 2015-05-27 03:45:33 theanets.trainer:168 RmsProp 1789 loss=82.986954 err=2.646298
I 2015-05-27 03:45:35 theanets.trainer:168 RmsProp 1790 loss=82.953697 err=2.639968
I 2015-05-27 03:45:35 theanets.trainer:168 validation 179 loss=1224.175171 err=1143.869751
I 2015-05-27 03:45:38 theanets.trainer:168 RmsProp 1791 loss=82.976303 err=2.689555
I 2015-05-27 03:45:40 theanets.trainer:168 RmsProp 1792 loss=82.476456 err=2.216166
I 2015-05-27 03:45:43 theanets.trainer:168 RmsProp 1793 loss=83.608612 err=3.369144
I 2015-05-27 03:45:45 theanets.trainer:168 RmsProp 1794 loss=82.757507 err=2.548338
I 2015-05-27 03:45:48 theanets.trainer:168 RmsProp 1795 loss=82.822662 err=2.642508
I 2015-05-27 03:45:50 theanets.trainer:168 RmsProp 1796 loss=82.714752 err=2.558015
I 2015-05-27 03:45:53 theanets.trainer:168 RmsProp 1797 loss=82.745956 err=2.612152
I 2015-05-27 03:45:55 theanets.trainer:168 RmsProp 1798 loss=82.823662 err=2.715301
I 2015-05-27 03:45:57 theanets.trainer:168 RmsProp 1799 loss=82.853035 err=2.765701
I 2015-05-27 03:46:00 theanets.trainer:168 RmsProp 1800 loss=82.570198 err=2.511437
I 2015-05-27 03:46:00 theanets.trainer:168 validation 180 loss=1222.857300 err=1142.819946 *
I 2015-05-27 03:46:02 theanets.trainer:168 RmsProp 1801 loss=82.872543 err=2.841052
I 2015-05-27 03:46:05 theanets.trainer:168 RmsProp 1802 loss=82.616867 err=2.613877
I 2015-05-27 03:46:07 theanets.trainer:168 RmsProp 1803 loss=82.876152 err=2.900209
I 2015-05-27 03:46:10 theanets.trainer:168 RmsProp 1804 loss=82.564384 err=2.612461
I 2015-05-27 03:46:12 theanets.trainer:168 RmsProp 1805 loss=82.565994 err=2.639561
I 2015-05-27 03:46:14 theanets.trainer:168 RmsProp 1806 loss=82.600281 err=2.699568
I 2015-05-27 03:46:17 theanets.trainer:168 RmsProp 1807 loss=82.615784 err=2.740756
I 2015-05-27 03:46:19 theanets.trainer:168 RmsProp 1808 loss=83.040749 err=3.185401
I 2015-05-27 03:46:22 theanets.trainer:168 RmsProp 1809 loss=82.363998 err=2.537302
I 2015-05-27 03:46:24 theanets.trainer:168 RmsProp 1810 loss=82.493111 err=2.694985
I 2015-05-27 03:46:24 theanets.trainer:168 validation 181 loss=1221.498413 err=1141.717407 *
I 2015-05-27 03:46:27 theanets.trainer:168 RmsProp 1811 loss=82.546326 err=2.774477
I 2015-05-27 03:46:29 theanets.trainer:168 RmsProp 1812 loss=82.383850 err=2.635575
I 2015-05-27 03:46:31 theanets.trainer:168 RmsProp 1813 loss=82.377304 err=2.655184
I 2015-05-27 03:46:34 theanets.trainer:168 RmsProp 1814 loss=82.486862 err=2.787911
I 2015-05-27 03:46:36 theanets.trainer:168 RmsProp 1815 loss=82.265526 err=2.593123
I 2015-05-27 03:46:39 theanets.trainer:168 RmsProp 1816 loss=82.354622 err=2.707812
I 2015-05-27 03:46:41 theanets.trainer:168 RmsProp 1817 loss=82.235863 err=2.616517
I 2015-05-27 03:46:43 theanets.trainer:168 RmsProp 1818 loss=82.399124 err=2.802047
I 2015-05-27 03:46:46 theanets.trainer:168 RmsProp 1819 loss=82.677910 err=3.103703
I 2015-05-27 03:46:48 theanets.trainer:168 RmsProp 1820 loss=82.095367 err=2.548522
I 2015-05-27 03:46:48 theanets.trainer:168 validation 182 loss=1224.041138 err=1144.508423
I 2015-05-27 03:46:51 theanets.trainer:168 RmsProp 1821 loss=82.035568 err=2.515773
I 2015-05-27 03:46:53 theanets.trainer:168 RmsProp 1822 loss=82.397385 err=2.899537
I 2015-05-27 03:46:56 theanets.trainer:168 RmsProp 1823 loss=82.097519 err=2.625568
I 2015-05-27 03:46:58 theanets.trainer:168 RmsProp 1824 loss=82.294273 err=2.844995
I 2015-05-27 03:47:00 theanets.trainer:168 RmsProp 1825 loss=81.762756 err=2.342333
I 2015-05-27 03:47:03 theanets.trainer:168 RmsProp 1826 loss=82.396179 err=2.999921
I 2015-05-27 03:47:05 theanets.trainer:168 RmsProp 1827 loss=82.189171 err=2.818552
I 2015-05-27 03:47:08 theanets.trainer:168 RmsProp 1828 loss=82.155930 err=2.807215
I 2015-05-27 03:47:10 theanets.trainer:168 RmsProp 1829 loss=81.941223 err=2.621027
I 2015-05-27 03:47:12 theanets.trainer:168 RmsProp 1830 loss=81.993546 err=2.696556
I 2015-05-27 03:47:13 theanets.trainer:168 validation 183 loss=1225.319336 err=1146.032471
I 2015-05-27 03:47:15 theanets.trainer:168 RmsProp 1831 loss=82.016060 err=2.745234
I 2015-05-27 03:47:17 theanets.trainer:168 RmsProp 1832 loss=81.904465 err=2.658507
I 2015-05-27 03:47:20 theanets.trainer:168 RmsProp 1833 loss=81.982109 err=2.760499
I 2015-05-27 03:47:22 theanets.trainer:168 RmsProp 1834 loss=81.909134 err=2.709276
I 2015-05-27 03:47:25 theanets.trainer:168 RmsProp 1835 loss=81.842361 err=2.667830
I 2015-05-27 03:47:27 theanets.trainer:168 RmsProp 1836 loss=81.838394 err=2.691078
I 2015-05-27 03:47:29 theanets.trainer:168 RmsProp 1837 loss=81.750107 err=2.624609
I 2015-05-27 03:47:32 theanets.trainer:168 RmsProp 1838 loss=81.772461 err=2.675048
I 2015-05-27 03:47:34 theanets.trainer:168 RmsProp 1839 loss=81.908340 err=2.832253
I 2015-05-27 03:47:37 theanets.trainer:168 RmsProp 1840 loss=81.651672 err=2.601501
I 2015-05-27 03:47:37 theanets.trainer:168 validation 184 loss=1218.289429 err=1139.257690 *
I 2015-05-27 03:47:39 theanets.trainer:168 RmsProp 1841 loss=81.752563 err=2.727487
I 2015-05-27 03:47:42 theanets.trainer:168 RmsProp 1842 loss=81.668472 err=2.668480
I 2015-05-27 03:47:44 theanets.trainer:168 RmsProp 1843 loss=81.819923 err=2.845467
I 2015-05-27 03:47:46 theanets.trainer:168 RmsProp 1844 loss=81.510147 err=2.559042
I 2015-05-27 03:47:49 theanets.trainer:168 RmsProp 1845 loss=81.560623 err=2.637369
I 2015-05-27 03:47:51 theanets.trainer:168 RmsProp 1846 loss=81.776634 err=2.871807
I 2015-05-27 03:47:54 theanets.trainer:168 RmsProp 1847 loss=81.456482 err=2.579904
I 2015-05-27 03:47:56 theanets.trainer:168 RmsProp 1848 loss=81.484360 err=2.633328
I 2015-05-27 03:47:58 theanets.trainer:168 RmsProp 1849 loss=81.829033 err=3.000241
I 2015-05-27 03:48:01 theanets.trainer:168 RmsProp 1850 loss=80.985901 err=2.185233
I 2015-05-27 03:48:01 theanets.trainer:168 validation 185 loss=1219.546631 err=1140.747192
I 2015-05-27 03:48:03 theanets.trainer:168 RmsProp 1851 loss=81.947891 err=3.166595
I 2015-05-27 03:48:06 theanets.trainer:168 RmsProp 1852 loss=81.464005 err=2.711956
I 2015-05-27 03:48:08 theanets.trainer:168 RmsProp 1853 loss=81.135864 err=2.411316
I 2015-05-27 03:48:11 theanets.trainer:168 RmsProp 1854 loss=81.127151 err=2.426488
I 2015-05-27 03:48:13 theanets.trainer:168 RmsProp 1855 loss=81.558563 err=2.878146
I 2015-05-27 03:48:16 theanets.trainer:168 RmsProp 1856 loss=81.518211 err=2.864253
I 2015-05-27 03:48:18 theanets.trainer:168 RmsProp 1857 loss=81.525642 err=2.896983
I 2015-05-27 03:48:21 theanets.trainer:168 RmsProp 1858 loss=81.070259 err=2.469229
I 2015-05-27 03:48:23 theanets.trainer:168 RmsProp 1859 loss=81.388023 err=2.808962
I 2015-05-27 03:48:26 theanets.trainer:168 RmsProp 1860 loss=81.293961 err=2.734906
I 2015-05-27 03:48:26 theanets.trainer:168 validation 186 loss=1217.589844 err=1139.034424 *
I 2015-05-27 03:48:29 theanets.trainer:168 RmsProp 1861 loss=81.289886 err=2.753991
I 2015-05-27 03:48:32 theanets.trainer:168 RmsProp 1862 loss=81.118103 err=2.607347
I 2015-05-27 03:48:34 theanets.trainer:168 RmsProp 1863 loss=81.177162 err=2.689860
I 2015-05-27 03:48:37 theanets.trainer:168 RmsProp 1864 loss=81.227097 err=2.765206
I 2015-05-27 03:48:40 theanets.trainer:168 RmsProp 1865 loss=81.250465 err=2.811807
I 2015-05-27 03:48:42 theanets.trainer:168 RmsProp 1866 loss=80.960938 err=2.545124
I 2015-05-27 03:48:45 theanets.trainer:168 RmsProp 1867 loss=81.081337 err=2.689798
I 2015-05-27 03:48:48 theanets.trainer:168 RmsProp 1868 loss=81.119476 err=2.754853
I 2015-05-27 03:48:51 theanets.trainer:168 RmsProp 1869 loss=80.882797 err=2.545381
I 2015-05-27 03:48:54 theanets.trainer:168 RmsProp 1870 loss=81.229187 err=2.913545
I 2015-05-27 03:48:54 theanets.trainer:168 validation 187 loss=1222.435547 err=1144.133179
I 2015-05-27 03:48:57 theanets.trainer:168 RmsProp 1871 loss=81.224487 err=2.930659
I 2015-05-27 03:49:00 theanets.trainer:168 RmsProp 1872 loss=80.886742 err=2.619256
I 2015-05-27 03:49:03 theanets.trainer:168 RmsProp 1873 loss=81.029762 err=2.787115
I 2015-05-27 03:49:06 theanets.trainer:168 RmsProp 1874 loss=80.984779 err=2.763402
I 2015-05-27 03:49:09 theanets.trainer:168 RmsProp 1875 loss=80.860001 err=2.663804
I 2015-05-27 03:49:12 theanets.trainer:168 RmsProp 1876 loss=80.838043 err=2.667209
I 2015-05-27 03:49:14 theanets.trainer:168 RmsProp 1877 loss=80.915550 err=2.768801
I 2015-05-27 03:49:16 theanets.trainer:168 RmsProp 1878 loss=80.602921 err=2.483520
I 2015-05-27 03:49:19 theanets.trainer:168 RmsProp 1879 loss=80.742882 err=2.643811
I 2015-05-27 03:49:21 theanets.trainer:168 RmsProp 1880 loss=80.905869 err=2.830151
I 2015-05-27 03:49:21 theanets.trainer:168 validation 188 loss=1214.845703 err=1136.779419 *
I 2015-05-27 03:49:24 theanets.trainer:168 RmsProp 1881 loss=80.706406 err=2.649665
I 2015-05-27 03:49:26 theanets.trainer:168 RmsProp 1882 loss=80.732590 err=2.702360
I 2015-05-27 03:49:29 theanets.trainer:168 RmsProp 1883 loss=80.889168 err=2.883335
I 2015-05-27 03:49:31 theanets.trainer:168 RmsProp 1884 loss=80.539108 err=2.558087
I 2015-05-27 03:49:33 theanets.trainer:168 RmsProp 1885 loss=80.632919 err=2.677632
I 2015-05-27 03:49:36 theanets.trainer:168 RmsProp 1886 loss=80.744179 err=2.812267
I 2015-05-27 03:49:38 theanets.trainer:168 RmsProp 1887 loss=80.406143 err=2.500700
I 2015-05-27 03:49:41 theanets.trainer:168 RmsProp 1888 loss=80.515762 err=2.631633
I 2015-05-27 03:49:43 theanets.trainer:168 RmsProp 1889 loss=80.631874 err=2.773849
I 2015-05-27 03:49:45 theanets.trainer:168 RmsProp 1890 loss=80.328812 err=2.493865
I 2015-05-27 03:49:46 theanets.trainer:168 validation 189 loss=1221.948853 err=1144.111816
I 2015-05-27 03:49:48 theanets.trainer:168 RmsProp 1891 loss=80.964104 err=3.148135
I 2015-05-27 03:49:50 theanets.trainer:168 RmsProp 1892 loss=80.370743 err=2.579687
I 2015-05-27 03:49:53 theanets.trainer:168 RmsProp 1893 loss=80.412453 err=2.645275
I 2015-05-27 03:49:55 theanets.trainer:168 RmsProp 1894 loss=80.362831 err=2.620009
I 2015-05-27 03:49:58 theanets.trainer:168 RmsProp 1895 loss=80.347267 err=2.628484
I 2015-05-27 03:50:00 theanets.trainer:168 RmsProp 1896 loss=80.237289 err=2.542514
I 2015-05-27 03:50:02 theanets.trainer:168 RmsProp 1897 loss=80.521187 err=2.847199
I 2015-05-27 03:50:05 theanets.trainer:168 RmsProp 1898 loss=80.072151 err=2.423308
I 2015-05-27 03:50:07 theanets.trainer:168 RmsProp 1899 loss=80.473129 err=2.847386
I 2015-05-27 03:50:10 theanets.trainer:168 RmsProp 1900 loss=80.273811 err=2.669850
I 2015-05-27 03:50:10 theanets.trainer:168 validation 190 loss=1215.427002 err=1137.842651
I 2015-05-27 03:50:12 theanets.trainer:168 RmsProp 1901 loss=80.282631 err=2.704983
I 2015-05-27 03:50:15 theanets.trainer:168 RmsProp 1902 loss=80.784531 err=3.224981
I 2015-05-27 03:50:17 theanets.trainer:168 RmsProp 1903 loss=80.292404 err=2.757398
I 2015-05-27 03:50:19 theanets.trainer:168 RmsProp 1904 loss=80.097122 err=2.588241
I 2015-05-27 03:50:22 theanets.trainer:168 RmsProp 1905 loss=80.236923 err=2.753217
I 2015-05-27 03:50:24 theanets.trainer:168 RmsProp 1906 loss=80.199432 err=2.739800
I 2015-05-27 03:50:27 theanets.trainer:168 RmsProp 1907 loss=80.035240 err=2.601743
I 2015-05-27 03:50:29 theanets.trainer:168 RmsProp 1908 loss=79.941444 err=2.531676
I 2015-05-27 03:50:31 theanets.trainer:168 RmsProp 1909 loss=80.149834 err=2.760979
I 2015-05-27 03:50:34 theanets.trainer:168 RmsProp 1910 loss=79.989563 err=2.625109
I 2015-05-27 03:50:34 theanets.trainer:168 validation 191 loss=1220.023315 err=1142.671265
I 2015-05-27 03:50:37 theanets.trainer:168 RmsProp 1911 loss=80.080772 err=2.734872
I 2015-05-27 03:50:39 theanets.trainer:168 RmsProp 1912 loss=80.107437 err=2.782668
I 2015-05-27 03:50:41 theanets.trainer:168 RmsProp 1913 loss=79.907455 err=2.610974
I 2015-05-27 03:50:44 theanets.trainer:168 RmsProp 1914 loss=79.907478 err=2.635511
I 2015-05-27 03:50:46 theanets.trainer:168 RmsProp 1915 loss=79.884537 err=2.633958
I 2015-05-27 03:50:48 theanets.trainer:168 RmsProp 1916 loss=80.003036 err=2.774976
I 2015-05-27 03:50:51 theanets.trainer:168 RmsProp 1917 loss=79.895256 err=2.691753
I 2015-05-27 03:50:53 theanets.trainer:168 RmsProp 1918 loss=79.934708 err=2.751459
I 2015-05-27 03:50:56 theanets.trainer:168 RmsProp 1919 loss=79.967957 err=2.803907
I 2015-05-27 03:50:58 theanets.trainer:168 RmsProp 1920 loss=79.700798 err=2.562012
I 2015-05-27 03:50:58 theanets.trainer:168 validation 192 loss=1214.227783 err=1137.099976 *
I 2015-05-27 03:51:01 theanets.trainer:168 RmsProp 1921 loss=79.803009 err=2.688901
I 2015-05-27 03:51:03 theanets.trainer:168 RmsProp 1922 loss=79.666809 err=2.580344
I 2015-05-27 03:51:06 theanets.trainer:168 RmsProp 1923 loss=79.810776 err=2.744510
I 2015-05-27 03:51:09 theanets.trainer:168 RmsProp 1924 loss=80.018593 err=2.971430
I 2015-05-27 03:51:12 theanets.trainer:168 RmsProp 1925 loss=79.388077 err=2.364748
I 2015-05-27 03:51:14 theanets.trainer:168 RmsProp 1926 loss=79.675995 err=2.676269
I 2015-05-27 03:51:17 theanets.trainer:168 RmsProp 1927 loss=80.006340 err=3.028428
I 2015-05-27 03:51:20 theanets.trainer:168 RmsProp 1928 loss=79.714737 err=2.761364
I 2015-05-27 03:51:23 theanets.trainer:168 RmsProp 1929 loss=79.613655 err=2.688373
I 2015-05-27 03:51:25 theanets.trainer:168 RmsProp 1930 loss=79.474777 err=2.568181
I 2015-05-27 03:51:25 theanets.trainer:168 validation 193 loss=1213.080200 err=1136.189697 *
I 2015-05-27 03:51:28 theanets.trainer:168 RmsProp 1931 loss=79.606056 err=2.719779
I 2015-05-27 03:51:30 theanets.trainer:168 RmsProp 1932 loss=79.489830 err=2.625640
I 2015-05-27 03:51:32 theanets.trainer:168 RmsProp 1933 loss=79.712379 err=2.873579
I 2015-05-27 03:51:35 theanets.trainer:168 RmsProp 1934 loss=79.415756 err=2.602397
I 2015-05-27 03:51:37 theanets.trainer:168 RmsProp 1935 loss=79.360703 err=2.570766
I 2015-05-27 03:51:40 theanets.trainer:168 RmsProp 1936 loss=79.474991 err=2.708523
I 2015-05-27 03:51:42 theanets.trainer:168 RmsProp 1937 loss=79.216423 err=2.473317
I 2015-05-27 03:51:44 theanets.trainer:168 RmsProp 1938 loss=79.669853 err=2.945462
I 2015-05-27 03:51:47 theanets.trainer:168 RmsProp 1939 loss=79.352501 err=2.650638
I 2015-05-27 03:51:49 theanets.trainer:168 RmsProp 1940 loss=79.190437 err=2.512818
I 2015-05-27 03:51:49 theanets.trainer:168 validation 194 loss=1215.661621 err=1138.995972
I 2015-05-27 03:51:52 theanets.trainer:168 RmsProp 1941 loss=79.332802 err=2.676986
I 2015-05-27 03:51:54 theanets.trainer:168 RmsProp 1942 loss=79.405510 err=2.771765
I 2015-05-27 03:51:57 theanets.trainer:168 RmsProp 1943 loss=79.180984 err=2.573745
I 2015-05-27 03:51:59 theanets.trainer:168 RmsProp 1944 loss=79.490112 err=2.902019
I 2015-05-27 03:52:01 theanets.trainer:168 RmsProp 1945 loss=79.439117 err=2.874425
I 2015-05-27 03:52:04 theanets.trainer:168 RmsProp 1946 loss=79.066696 err=2.524464
I 2015-05-27 03:52:06 theanets.trainer:168 RmsProp 1947 loss=79.191879 err=2.675172
I 2015-05-27 03:52:09 theanets.trainer:168 RmsProp 1948 loss=78.993690 err=2.498862
I 2015-05-27 03:52:12 theanets.trainer:168 RmsProp 1949 loss=79.075104 err=2.604271
I 2015-05-27 03:52:15 theanets.trainer:168 RmsProp 1950 loss=79.136719 err=2.683356
I 2015-05-27 03:52:16 theanets.trainer:168 validation 195 loss=1217.725586 err=1141.270020
I 2015-05-27 03:52:18 theanets.trainer:168 RmsProp 1951 loss=79.403419 err=2.967476
I 2015-05-27 03:52:21 theanets.trainer:168 RmsProp 1952 loss=79.001617 err=2.591405
I 2015-05-27 03:52:24 theanets.trainer:168 RmsProp 1953 loss=79.027054 err=2.641199
I 2015-05-27 03:52:27 theanets.trainer:168 RmsProp 1954 loss=79.172523 err=2.807738
I 2015-05-27 03:52:30 theanets.trainer:168 RmsProp 1955 loss=78.917587 err=2.579314
I 2015-05-27 03:52:33 theanets.trainer:168 RmsProp 1956 loss=79.001167 err=2.686141
I 2015-05-27 03:52:36 theanets.trainer:168 RmsProp 1957 loss=78.767624 err=2.478258
I 2015-05-27 03:52:38 theanets.trainer:168 RmsProp 1958 loss=79.086494 err=2.818329
I 2015-05-27 03:52:41 theanets.trainer:168 RmsProp 1959 loss=78.898399 err=2.651373
I 2015-05-27 03:52:43 theanets.trainer:168 RmsProp 1960 loss=78.859962 err=2.635524
I 2015-05-27 03:52:44 theanets.trainer:168 validation 196 loss=1211.478027 err=1135.266357 *
I 2015-05-27 03:52:46 theanets.trainer:168 RmsProp 1961 loss=78.928513 err=2.725590
I 2015-05-27 03:52:48 theanets.trainer:168 RmsProp 1962 loss=78.758011 err=2.581049
I 2015-05-27 03:52:51 theanets.trainer:168 RmsProp 1963 loss=78.845871 err=2.688802
I 2015-05-27 03:52:53 theanets.trainer:168 RmsProp 1964 loss=78.782150 err=2.648715
I 2015-05-27 03:52:56 theanets.trainer:168 RmsProp 1965 loss=78.814774 err=2.698736
I 2015-05-27 03:52:58 theanets.trainer:168 RmsProp 1966 loss=78.738670 err=2.645621
I 2015-05-27 03:53:00 theanets.trainer:168 RmsProp 1967 loss=78.750259 err=2.681447
I 2015-05-27 03:53:03 theanets.trainer:168 RmsProp 1968 loss=78.528854 err=2.487225
I 2015-05-27 03:53:05 theanets.trainer:168 RmsProp 1969 loss=78.622597 err=2.604395
I 2015-05-27 03:53:08 theanets.trainer:168 RmsProp 1970 loss=78.742622 err=2.742186
I 2015-05-27 03:53:08 theanets.trainer:168 validation 197 loss=1210.632690 err=1134.647827 *
I 2015-05-27 03:53:10 theanets.trainer:168 RmsProp 1971 loss=78.619934 err=2.642127
I 2015-05-27 03:53:13 theanets.trainer:168 RmsProp 1972 loss=78.666801 err=2.708241
I 2015-05-27 03:53:15 theanets.trainer:168 RmsProp 1973 loss=78.607391 err=2.673030
I 2015-05-27 03:53:17 theanets.trainer:168 RmsProp 1974 loss=78.496773 err=2.585016
I 2015-05-27 03:53:20 theanets.trainer:168 RmsProp 1975 loss=78.346275 err=2.458895
I 2015-05-27 03:53:22 theanets.trainer:168 RmsProp 1976 loss=78.643394 err=2.778866
I 2015-05-27 03:53:25 theanets.trainer:168 RmsProp 1977 loss=78.449554 err=2.603126
I 2015-05-27 03:53:27 theanets.trainer:168 RmsProp 1978 loss=78.437538 err=2.615373
I 2015-05-27 03:53:29 theanets.trainer:168 RmsProp 1979 loss=78.554558 err=2.750588
I 2015-05-27 03:53:32 theanets.trainer:168 RmsProp 1980 loss=78.523285 err=2.741292
I 2015-05-27 03:53:32 theanets.trainer:168 validation 198 loss=1208.758301 err=1132.986694 *
I 2015-05-27 03:53:34 theanets.trainer:168 RmsProp 1981 loss=78.308464 err=2.552574
I 2015-05-27 03:53:37 theanets.trainer:168 RmsProp 1982 loss=78.371506 err=2.639151
I 2015-05-27 03:53:39 theanets.trainer:168 RmsProp 1983 loss=78.312103 err=2.603906
I 2015-05-27 03:53:42 theanets.trainer:168 RmsProp 1984 loss=78.447365 err=2.757602
I 2015-05-27 03:53:44 theanets.trainer:168 RmsProp 1985 loss=78.465790 err=2.791919
I 2015-05-27 03:53:46 theanets.trainer:168 RmsProp 1986 loss=78.385559 err=2.734584
I 2015-05-27 03:53:49 theanets.trainer:168 RmsProp 1987 loss=78.165237 err=2.540512
I 2015-05-27 03:53:51 theanets.trainer:168 RmsProp 1988 loss=78.472137 err=2.870835
I 2015-05-27 03:53:54 theanets.trainer:168 RmsProp 1989 loss=78.308304 err=2.731977
I 2015-05-27 03:53:56 theanets.trainer:168 RmsProp 1990 loss=78.190651 err=2.636890
I 2015-05-27 03:53:56 theanets.trainer:168 validation 199 loss=1207.569946 err=1132.026123 *
I 2015-05-27 03:53:59 theanets.trainer:168 RmsProp 1991 loss=78.318192 err=2.784304
I 2015-05-27 03:54:01 theanets.trainer:168 RmsProp 1992 loss=78.025894 err=2.513189
I 2015-05-27 03:54:03 theanets.trainer:168 RmsProp 1993 loss=78.055527 err=2.560732
I 2015-05-27 03:54:06 theanets.trainer:168 RmsProp 1994 loss=78.118385 err=2.646044
I 2015-05-27 03:54:08 theanets.trainer:168 RmsProp 1995 loss=78.056274 err=2.610162
I 2015-05-27 03:54:11 theanets.trainer:168 RmsProp 1996 loss=78.106888 err=2.681571
I 2015-05-27 03:54:13 theanets.trainer:168 RmsProp 1997 loss=78.149475 err=2.741734
I 2015-05-27 03:54:15 theanets.trainer:168 RmsProp 1998 loss=77.863564 err=2.476113
I 2015-05-27 03:54:18 theanets.trainer:168 RmsProp 1999 loss=78.357773 err=2.994343
I 2015-05-27 03:54:20 theanets.trainer:168 RmsProp 2000 loss=78.044189 err=2.703900
I 2015-05-27 03:54:20 theanets.trainer:168 validation 200 loss=1213.279663 err=1137.950562
I 2015-05-27 03:54:23 theanets.trainer:168 RmsProp 2001 loss=77.725471 err=2.411000
I 2015-05-27 03:54:25 theanets.trainer:168 RmsProp 2002 loss=77.972466 err=2.678733
I 2015-05-27 03:54:28 theanets.trainer:168 RmsProp 2003 loss=77.952301 err=2.680213
I 2015-05-27 03:54:30 theanets.trainer:168 RmsProp 2004 loss=77.886429 err=2.634057
I 2015-05-27 03:54:32 theanets.trainer:168 RmsProp 2005 loss=78.065239 err=2.832378
I 2015-05-27 03:54:35 theanets.trainer:168 RmsProp 2006 loss=77.895576 err=2.685429
I 2015-05-27 03:54:37 theanets.trainer:168 RmsProp 2007 loss=77.691360 err=2.505502
I 2015-05-27 03:54:40 theanets.trainer:168 RmsProp 2008 loss=77.753204 err=2.590818
I 2015-05-27 03:54:42 theanets.trainer:168 RmsProp 2009 loss=77.804184 err=2.662379
I 2015-05-27 03:54:44 theanets.trainer:168 RmsProp 2010 loss=77.803200 err=2.683874
I 2015-05-27 03:54:45 theanets.trainer:168 validation 201 loss=1212.135498 err=1137.024170
I 2015-05-27 03:54:47 theanets.trainer:168 RmsProp 2011 loss=77.854156 err=2.754565
I 2015-05-27 03:54:49 theanets.trainer:168 RmsProp 2012 loss=77.431938 err=2.353906
I 2015-05-27 03:54:52 theanets.trainer:168 RmsProp 2013 loss=77.728622 err=2.673723
I 2015-05-27 03:54:54 theanets.trainer:168 RmsProp 2014 loss=77.996117 err=2.958053
I 2015-05-27 03:54:57 theanets.trainer:168 RmsProp 2015 loss=77.515625 err=2.502892
I 2015-05-27 03:54:59 theanets.trainer:168 RmsProp 2016 loss=77.614792 err=2.621908
I 2015-05-27 03:55:01 theanets.trainer:168 RmsProp 2017 loss=77.419289 err=2.449124
I 2015-05-27 03:55:04 theanets.trainer:168 RmsProp 2018 loss=77.634514 err=2.688503
I 2015-05-27 03:55:06 theanets.trainer:168 RmsProp 2019 loss=77.824829 err=2.897542
I 2015-05-27 03:55:09 theanets.trainer:168 RmsProp 2020 loss=77.616302 err=2.709524
I 2015-05-27 03:55:09 theanets.trainer:168 validation 202 loss=1208.825806 err=1133.926880
I 2015-05-27 03:55:11 theanets.trainer:168 RmsProp 2021 loss=77.585617 err=2.696637
I 2015-05-27 03:55:14 theanets.trainer:168 RmsProp 2022 loss=77.457474 err=2.595049
I 2015-05-27 03:55:16 theanets.trainer:168 RmsProp 2023 loss=77.437248 err=2.592391
I 2015-05-27 03:55:18 theanets.trainer:168 RmsProp 2024 loss=77.493141 err=2.668648
I 2015-05-27 03:55:21 theanets.trainer:168 RmsProp 2025 loss=77.412094 err=2.613188
I 2015-05-27 03:55:23 theanets.trainer:168 RmsProp 2026 loss=77.700745 err=2.918418
I 2015-05-27 03:55:26 theanets.trainer:168 RmsProp 2027 loss=77.553848 err=2.793668
I 2015-05-27 03:55:28 theanets.trainer:168 RmsProp 2028 loss=77.320854 err=2.579127
I 2015-05-27 03:55:30 theanets.trainer:168 RmsProp 2029 loss=77.231270 err=2.514508
I 2015-05-27 03:55:33 theanets.trainer:168 RmsProp 2030 loss=77.414810 err=2.717911
I 2015-05-27 03:55:33 theanets.trainer:168 validation 203 loss=1205.274658 err=1130.579712 *
I 2015-05-27 03:55:35 theanets.trainer:168 RmsProp 2031 loss=77.073616 err=2.396215
I 2015-05-27 03:55:38 theanets.trainer:168 RmsProp 2032 loss=77.609818 err=2.953117
I 2015-05-27 03:55:40 theanets.trainer:168 RmsProp 2033 loss=77.240402 err=2.605889
I 2015-05-27 03:55:43 theanets.trainer:168 RmsProp 2034 loss=77.085587 err=2.475845
I 2015-05-27 03:55:45 theanets.trainer:168 RmsProp 2035 loss=77.238174 err=2.647705
I 2015-05-27 03:55:47 theanets.trainer:168 RmsProp 2036 loss=77.210854 err=2.643503
I 2015-05-27 03:55:50 theanets.trainer:168 RmsProp 2037 loss=77.165039 err=2.617009
I 2015-05-27 03:55:52 theanets.trainer:168 RmsProp 2038 loss=77.661407 err=3.131601
I 2015-05-27 03:55:55 theanets.trainer:168 RmsProp 2039 loss=76.962479 err=2.455949
I 2015-05-27 03:55:57 theanets.trainer:168 RmsProp 2040 loss=77.402756 err=2.915998
I 2015-05-27 03:55:58 theanets.trainer:168 validation 204 loss=1206.419922 err=1131.944580
I 2015-05-27 03:56:00 theanets.trainer:168 RmsProp 2041 loss=76.860176 err=2.395545
I 2015-05-27 03:56:03 theanets.trainer:168 RmsProp 2042 loss=77.158188 err=2.716165
I 2015-05-27 03:56:05 theanets.trainer:168 RmsProp 2043 loss=77.090248 err=2.670466
I 2015-05-27 03:56:08 theanets.trainer:168 RmsProp 2044 loss=76.981750 err=2.580377
I 2015-05-27 03:56:10 theanets.trainer:168 RmsProp 2045 loss=76.834564 err=2.455415
I 2015-05-27 03:56:13 theanets.trainer:168 RmsProp 2046 loss=77.178329 err=2.819185
I 2015-05-27 03:56:15 theanets.trainer:168 RmsProp 2047 loss=76.868423 err=2.532010
I 2015-05-27 03:56:18 theanets.trainer:168 RmsProp 2048 loss=77.173767 err=2.856835
I 2015-05-27 03:56:20 theanets.trainer:168 RmsProp 2049 loss=76.881798 err=2.587497
I 2015-05-27 03:56:23 theanets.trainer:168 RmsProp 2050 loss=76.693657 err=2.416303
I 2015-05-27 03:56:23 theanets.trainer:168 validation 205 loss=1203.248047 err=1128.974243 *
I 2015-05-27 03:56:25 theanets.trainer:168 RmsProp 2051 loss=77.167336 err=2.906954
I 2015-05-27 03:56:28 theanets.trainer:168 RmsProp 2052 loss=76.807114 err=2.572872
I 2015-05-27 03:56:30 theanets.trainer:168 RmsProp 2053 loss=76.792007 err=2.580066
I 2015-05-27 03:56:33 theanets.trainer:168 RmsProp 2054 loss=76.970291 err=2.778553
I 2015-05-27 03:56:35 theanets.trainer:168 RmsProp 2055 loss=76.684303 err=2.517119
I 2015-05-27 03:56:37 theanets.trainer:168 RmsProp 2056 loss=76.846779 err=2.697809
I 2015-05-27 03:56:40 theanets.trainer:168 RmsProp 2057 loss=76.714462 err=2.584635
I 2015-05-27 03:56:42 theanets.trainer:168 RmsProp 2058 loss=76.745804 err=2.638918
I 2015-05-27 03:56:45 theanets.trainer:168 RmsProp 2059 loss=76.752785 err=2.666378
I 2015-05-27 03:56:47 theanets.trainer:168 RmsProp 2060 loss=76.681618 err=2.616056
I 2015-05-27 03:56:47 theanets.trainer:168 validation 206 loss=1202.992065 err=1128.938599 *
I 2015-05-27 03:56:50 theanets.trainer:168 RmsProp 2061 loss=76.526840 err=2.483236
I 2015-05-27 03:56:52 theanets.trainer:168 RmsProp 2062 loss=76.643570 err=2.620772
I 2015-05-27 03:56:54 theanets.trainer:168 RmsProp 2063 loss=76.594307 err=2.588343
I 2015-05-27 03:56:57 theanets.trainer:168 RmsProp 2064 loss=76.706116 err=2.722046
I 2015-05-27 03:56:59 theanets.trainer:168 RmsProp 2065 loss=76.427139 err=2.464316
I 2015-05-27 03:57:02 theanets.trainer:168 RmsProp 2066 loss=76.816971 err=2.868744
I 2015-05-27 03:57:04 theanets.trainer:168 RmsProp 2067 loss=76.389473 err=2.466753
I 2015-05-27 03:57:06 theanets.trainer:168 RmsProp 2068 loss=76.818008 err=2.914384
I 2015-05-27 03:57:09 theanets.trainer:168 RmsProp 2069 loss=76.683556 err=2.803302
I 2015-05-27 03:57:11 theanets.trainer:168 RmsProp 2070 loss=76.559021 err=2.700589
I 2015-05-27 03:57:12 theanets.trainer:168 validation 207 loss=1203.960083 err=1130.109009
I 2015-05-27 03:57:14 theanets.trainer:168 RmsProp 2071 loss=76.571793 err=2.733624
I 2015-05-27 03:57:16 theanets.trainer:168 RmsProp 2072 loss=76.460777 err=2.642189
I 2015-05-27 03:57:19 theanets.trainer:168 RmsProp 2073 loss=76.323692 err=2.527562
I 2015-05-27 03:57:21 theanets.trainer:168 RmsProp 2074 loss=76.364479 err=2.587823
I 2015-05-27 03:57:23 theanets.trainer:168 RmsProp 2075 loss=76.393631 err=2.635353
I 2015-05-27 03:57:26 theanets.trainer:168 RmsProp 2076 loss=76.436157 err=2.700066
I 2015-05-27 03:57:28 theanets.trainer:168 RmsProp 2077 loss=76.237160 err=2.517941
I 2015-05-27 03:57:31 theanets.trainer:168 RmsProp 2078 loss=76.298721 err=2.601774
I 2015-05-27 03:57:33 theanets.trainer:168 RmsProp 2079 loss=76.301437 err=2.622259
I 2015-05-27 03:57:35 theanets.trainer:168 RmsProp 2080 loss=76.402512 err=2.741563
I 2015-05-27 03:57:36 theanets.trainer:168 validation 208 loss=1200.716797 err=1127.067261 *
I 2015-05-27 03:57:38 theanets.trainer:168 RmsProp 2081 loss=76.532288 err=2.889903
I 2015-05-27 03:57:40 theanets.trainer:168 RmsProp 2082 loss=75.915199 err=2.299092
I 2015-05-27 03:57:43 theanets.trainer:168 RmsProp 2083 loss=76.411087 err=2.814194
I 2015-05-27 03:57:45 theanets.trainer:168 RmsProp 2084 loss=76.367432 err=2.789766
I 2015-05-27 03:57:48 theanets.trainer:168 RmsProp 2085 loss=76.296127 err=2.738602
I 2015-05-27 03:57:50 theanets.trainer:168 RmsProp 2086 loss=75.927139 err=2.391559
I 2015-05-27 03:57:52 theanets.trainer:168 RmsProp 2087 loss=76.137360 err=2.622639
I 2015-05-27 03:57:55 theanets.trainer:168 RmsProp 2088 loss=76.312454 err=2.814905
I 2015-05-27 03:57:57 theanets.trainer:168 RmsProp 2089 loss=75.907829 err=2.428774
I 2015-05-27 03:58:00 theanets.trainer:168 RmsProp 2090 loss=76.300957 err=2.842771
I 2015-05-27 03:58:00 theanets.trainer:168 validation 209 loss=1202.672241 err=1129.225952
I 2015-05-27 03:58:02 theanets.trainer:168 RmsProp 2091 loss=76.046249 err=2.610077
I 2015-05-27 03:58:05 theanets.trainer:168 RmsProp 2092 loss=75.934013 err=2.518193
I 2015-05-27 03:58:07 theanets.trainer:168 RmsProp 2093 loss=76.150742 err=2.754916
I 2015-05-27 03:58:09 theanets.trainer:168 RmsProp 2094 loss=76.027435 err=2.648742
I 2015-05-27 03:58:12 theanets.trainer:168 RmsProp 2095 loss=75.842026 err=2.485713
I 2015-05-27 03:58:14 theanets.trainer:168 RmsProp 2096 loss=76.105118 err=2.766452
I 2015-05-27 03:58:17 theanets.trainer:168 RmsProp 2097 loss=75.818138 err=2.503201
I 2015-05-27 03:58:19 theanets.trainer:168 RmsProp 2098 loss=76.184151 err=2.886578
I 2015-05-27 03:58:22 theanets.trainer:168 RmsProp 2099 loss=75.806152 err=2.526664
I 2015-05-27 03:58:24 theanets.trainer:168 RmsProp 2100 loss=75.727859 err=2.470610
I 2015-05-27 03:58:24 theanets.trainer:168 validation 210 loss=1203.878784 err=1130.632568
I 2015-05-27 03:58:27 theanets.trainer:168 RmsProp 2101 loss=75.823303 err=2.588084
I 2015-05-27 03:58:29 theanets.trainer:168 RmsProp 2102 loss=76.014801 err=2.794041
I 2015-05-27 03:58:31 theanets.trainer:168 RmsProp 2103 loss=75.652321 err=2.450691
I 2015-05-27 03:58:34 theanets.trainer:168 RmsProp 2104 loss=75.836121 err=2.656854
I 2015-05-27 03:58:36 theanets.trainer:168 RmsProp 2105 loss=75.691116 err=2.533755
I 2015-05-27 03:58:39 theanets.trainer:168 RmsProp 2106 loss=75.933884 err=2.797097
I 2015-05-27 03:58:41 theanets.trainer:168 RmsProp 2107 loss=75.888687 err=2.769156
I 2015-05-27 03:58:43 theanets.trainer:168 RmsProp 2108 loss=75.654335 err=2.552231
I 2015-05-27 03:58:46 theanets.trainer:168 RmsProp 2109 loss=75.751755 err=2.668139
I 2015-05-27 03:58:48 theanets.trainer:168 RmsProp 2110 loss=75.941681 err=2.873952
I 2015-05-27 03:58:48 theanets.trainer:168 validation 211 loss=1202.747070 err=1129.691284
I 2015-05-27 03:58:51 theanets.trainer:168 RmsProp 2111 loss=75.805862 err=2.759603
I 2015-05-27 03:58:53 theanets.trainer:168 RmsProp 2112 loss=75.764236 err=2.737370
I 2015-05-27 03:58:56 theanets.trainer:168 RmsProp 2113 loss=75.463013 err=2.458862
I 2015-05-27 03:58:58 theanets.trainer:168 RmsProp 2114 loss=75.556229 err=2.573630
I 2015-05-27 03:59:01 theanets.trainer:168 RmsProp 2115 loss=75.484047 err=2.523507
I 2015-05-27 03:59:03 theanets.trainer:168 RmsProp 2116 loss=75.685570 err=2.742808
I 2015-05-27 03:59:06 theanets.trainer:168 RmsProp 2117 loss=75.711800 err=2.783064
I 2015-05-27 03:59:09 theanets.trainer:168 RmsProp 2118 loss=75.326065 err=2.420301
I 2015-05-27 03:59:11 theanets.trainer:168 RmsProp 2119 loss=75.443283 err=2.556218
I 2015-05-27 03:59:14 theanets.trainer:168 RmsProp 2120 loss=75.345322 err=2.477543
I 2015-05-27 03:59:14 theanets.trainer:168 validation 212 loss=1198.820190 err=1125.967651 *
I 2015-05-27 03:59:16 theanets.trainer:168 RmsProp 2121 loss=75.675919 err=2.824327
I 2015-05-27 03:59:19 theanets.trainer:168 RmsProp 2122 loss=75.399620 err=2.569108
I 2015-05-27 03:59:21 theanets.trainer:168 RmsProp 2123 loss=75.489090 err=2.680794
I 2015-05-27 03:59:24 theanets.trainer:168 RmsProp 2124 loss=75.331741 err=2.544454
I 2015-05-27 03:59:27 theanets.trainer:168 RmsProp 2125 loss=75.530823 err=2.763180
I 2015-05-27 03:59:29 theanets.trainer:168 RmsProp 2126 loss=75.762184 err=3.008791
I 2015-05-27 03:59:32 theanets.trainer:168 RmsProp 2127 loss=74.953506 err=2.223073
I 2015-05-27 03:59:34 theanets.trainer:168 RmsProp 2128 loss=75.832870 err=3.116412
I 2015-05-27 03:59:37 theanets.trainer:168 RmsProp 2129 loss=75.212524 err=2.519857
I 2015-05-27 03:59:39 theanets.trainer:168 RmsProp 2130 loss=75.264122 err=2.592485
I 2015-05-27 03:59:40 theanets.trainer:168 validation 213 loss=1200.139282 err=1127.478271
I 2015-05-27 03:59:42 theanets.trainer:168 RmsProp 2131 loss=75.297684 err=2.646280
I 2015-05-27 03:59:45 theanets.trainer:168 RmsProp 2132 loss=75.285774 err=2.652781
I 2015-05-27 03:59:47 theanets.trainer:168 RmsProp 2133 loss=75.264221 err=2.648840
I 2015-05-27 03:59:50 theanets.trainer:168 RmsProp 2134 loss=75.360054 err=2.763035
I 2015-05-27 03:59:52 theanets.trainer:168 RmsProp 2135 loss=75.111610 err=2.533184
I 2015-05-27 03:59:55 theanets.trainer:168 RmsProp 2136 loss=75.008789 err=2.447523
I 2015-05-27 03:59:57 theanets.trainer:168 RmsProp 2137 loss=75.172577 err=2.632447
I 2015-05-27 04:00:00 theanets.trainer:168 RmsProp 2138 loss=75.204613 err=2.682573
I 2015-05-27 04:00:02 theanets.trainer:168 RmsProp 2139 loss=74.940384 err=2.439902
I 2015-05-27 04:00:05 theanets.trainer:168 RmsProp 2140 loss=75.172539 err=2.691214
I 2015-05-27 04:00:05 theanets.trainer:168 validation 214 loss=1199.454590 err=1126.991577
I 2015-05-27 04:00:07 theanets.trainer:168 RmsProp 2141 loss=75.175674 err=2.715345
I 2015-05-27 04:00:09 theanets.trainer:168 RmsProp 2142 loss=75.022743 err=2.581503
I 2015-05-27 04:00:11 theanets.trainer:168 RmsProp 2143 loss=74.943176 err=2.521138
I 2015-05-27 04:00:13 theanets.trainer:168 RmsProp 2144 loss=75.285431 err=2.880719
I 2015-05-27 04:00:15 theanets.trainer:168 RmsProp 2145 loss=74.777054 err=2.389112
I 2015-05-27 04:00:17 theanets.trainer:168 RmsProp 2146 loss=75.042923 err=2.675641
I 2015-05-27 04:00:19 theanets.trainer:168 RmsProp 2147 loss=75.061203 err=2.709758
I 2015-05-27 04:00:21 theanets.trainer:168 RmsProp 2148 loss=74.830078 err=2.502564
I 2015-05-27 04:00:23 theanets.trainer:168 RmsProp 2149 loss=74.996292 err=2.686147
I 2015-05-27 04:00:24 theanets.trainer:168 RmsProp 2150 loss=74.955521 err=2.661176
I 2015-05-27 04:00:25 theanets.trainer:168 validation 215 loss=1196.584595 err=1124.303345 *
I 2015-05-27 04:00:27 theanets.trainer:168 RmsProp 2151 loss=74.760117 err=2.485328
I 2015-05-27 04:00:28 theanets.trainer:168 RmsProp 2152 loss=74.700867 err=2.447696
I 2015-05-27 04:00:30 theanets.trainer:168 RmsProp 2153 loss=75.006081 err=2.770715
I 2015-05-27 04:00:32 theanets.trainer:168 RmsProp 2154 loss=74.868172 err=2.649805
I 2015-05-27 04:00:34 theanets.trainer:168 RmsProp 2155 loss=74.817123 err=2.618149
I 2015-05-27 04:00:36 theanets.trainer:168 RmsProp 2156 loss=74.744202 err=2.561789
I 2015-05-27 04:00:38 theanets.trainer:168 RmsProp 2157 loss=74.771454 err=2.610079
I 2015-05-27 04:00:40 theanets.trainer:168 RmsProp 2158 loss=74.700821 err=2.559019
I 2015-05-27 04:00:42 theanets.trainer:168 RmsProp 2159 loss=74.798080 err=2.672737
I 2015-05-27 04:00:44 theanets.trainer:168 RmsProp 2160 loss=74.641235 err=2.536749
I 2015-05-27 04:00:44 theanets.trainer:168 validation 216 loss=1201.908203 err=1129.813232
I 2015-05-27 04:00:46 theanets.trainer:168 RmsProp 2161 loss=74.780716 err=2.694010
I 2015-05-27 04:00:48 theanets.trainer:168 RmsProp 2162 loss=74.599289 err=2.535550
I 2015-05-27 04:00:49 theanets.trainer:168 RmsProp 2163 loss=74.841431 err=2.793564
I 2015-05-27 04:00:51 theanets.trainer:168 RmsProp 2164 loss=74.638969 err=2.604790
I 2015-05-27 04:00:53 theanets.trainer:168 RmsProp 2165 loss=74.603569 err=2.590590
I 2015-05-27 04:00:55 theanets.trainer:168 RmsProp 2166 loss=74.829849 err=2.832514
I 2015-05-27 04:00:57 theanets.trainer:168 RmsProp 2167 loss=74.753098 err=2.774168
I 2015-05-27 04:00:59 theanets.trainer:168 RmsProp 2168 loss=74.517876 err=2.557500
I 2015-05-27 04:01:01 theanets.trainer:168 RmsProp 2169 loss=74.561241 err=2.623208
I 2015-05-27 04:01:03 theanets.trainer:168 RmsProp 2170 loss=74.452950 err=2.533948
I 2015-05-27 04:01:03 theanets.trainer:168 validation 217 loss=1201.563110 err=1129.652100
I 2015-05-27 04:01:05 theanets.trainer:168 RmsProp 2171 loss=74.664085 err=2.761867
I 2015-05-27 04:01:06 theanets.trainer:168 RmsProp 2172 loss=74.367439 err=2.479471
I 2015-05-27 04:01:08 theanets.trainer:168 RmsProp 2173 loss=74.596695 err=2.728118
I 2015-05-27 04:01:10 theanets.trainer:168 RmsProp 2174 loss=74.493561 err=2.646132
I 2015-05-27 04:01:12 theanets.trainer:168 RmsProp 2175 loss=74.301262 err=2.472276
I 2015-05-27 04:01:14 theanets.trainer:168 RmsProp 2176 loss=74.506310 err=2.694251
I 2015-05-27 04:01:16 theanets.trainer:168 RmsProp 2177 loss=74.412796 err=2.619671
I 2015-05-27 04:01:18 theanets.trainer:168 RmsProp 2178 loss=74.136772 err=2.364626
I 2015-05-27 04:01:20 theanets.trainer:168 RmsProp 2179 loss=74.386810 err=2.633259
I 2015-05-27 04:01:21 theanets.trainer:168 RmsProp 2180 loss=74.620468 err=2.883882
I 2015-05-27 04:01:22 theanets.trainer:168 validation 218 loss=1199.407349 err=1127.682251
I 2015-05-27 04:01:24 theanets.trainer:168 RmsProp 2181 loss=74.257195 err=2.537703
I 2015-05-27 04:01:25 theanets.trainer:168 RmsProp 2182 loss=74.305046 err=2.606447
I 2015-05-27 04:01:27 theanets.trainer:168 RmsProp 2183 loss=74.205040 err=2.525305
I 2015-05-27 04:01:29 theanets.trainer:168 RmsProp 2184 loss=74.198814 err=2.539796
I 2015-05-27 04:01:31 theanets.trainer:168 RmsProp 2185 loss=74.209328 err=2.567719
I 2015-05-27 04:01:33 theanets.trainer:168 RmsProp 2186 loss=74.166100 err=2.542692
I 2015-05-27 04:01:35 theanets.trainer:168 RmsProp 2187 loss=74.209778 err=2.602343
I 2015-05-27 04:01:37 theanets.trainer:168 RmsProp 2188 loss=74.123756 err=2.536795
I 2015-05-27 04:01:39 theanets.trainer:168 RmsProp 2189 loss=74.238693 err=2.671331
I 2015-05-27 04:01:40 theanets.trainer:168 RmsProp 2190 loss=74.029984 err=2.479023
I 2015-05-27 04:01:41 theanets.trainer:168 validation 219 loss=1199.534180 err=1127.991577
I 2015-05-27 04:01:42 theanets.trainer:168 RmsProp 2191 loss=74.213478 err=2.675963
I 2015-05-27 04:01:44 theanets.trainer:168 RmsProp 2192 loss=74.058105 err=2.541223
I 2015-05-27 04:01:46 theanets.trainer:168 RmsProp 2193 loss=74.047028 err=2.550391
I 2015-05-27 04:01:48 theanets.trainer:168 RmsProp 2194 loss=74.200035 err=2.717439
I 2015-05-27 04:01:50 theanets.trainer:168 RmsProp 2195 loss=74.069473 err=2.602506
I 2015-05-27 04:01:52 theanets.trainer:168 RmsProp 2196 loss=73.974731 err=2.528971
I 2015-05-27 04:01:54 theanets.trainer:168 RmsProp 2197 loss=74.304825 err=2.874462
I 2015-05-27 04:01:56 theanets.trainer:168 RmsProp 2198 loss=74.331581 err=2.915663
I 2015-05-27 04:01:58 theanets.trainer:168 RmsProp 2199 loss=74.025780 err=2.631241
I 2015-05-27 04:01:59 theanets.trainer:168 RmsProp 2200 loss=73.880798 err=2.510481
I 2015-05-27 04:02:00 theanets.trainer:168 validation 220 loss=1199.169312 err=1127.802612
I 2015-05-27 04:02:00 theanets.trainer:252 patience elapsed!
I 2015-05-27 04:02:00 theanets.main:237 models_deep_post_code_sep/95123-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saving model
I 2015-05-27 04:02:00 theanets.graph:477 models_deep_post_code_sep/95123-models-sep_san_jose_realtor_200_100.conf-1024-None-0.01-0.001.pkl: saved model parameters
