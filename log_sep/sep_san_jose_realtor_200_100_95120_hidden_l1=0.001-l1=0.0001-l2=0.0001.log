I 2015-05-26 03:35:25 theanets.layers:465 layer in: out:0 -> 1000, linear, 0 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_fw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1_bw: in.out:1000 -> 100, logistic, 440700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm1: in.out:1000 -> 200, logistic, 881400 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_fw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2_bw: bdlstm1.out:200 -> 50, logistic, 50350 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer bdlstm2: bdlstm1.out:200 -> 100, logistic, 100700 parameters
I 2015-05-26 03:35:25 theanets.layers:465 layer out: bdlstm2.out:100 -> 1, linear, 101 parameters
I 2015-05-26 03:35:25 theanets.graph:145 network has 982201 total parameters
models_deep_post_code_sep/95120-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl
I 2015-05-26 03:35:25 theanets.dataset:133 valid: 3 mini-batches from callable
I 2015-05-26 03:35:25 theanets.dataset:133 train: 30 mini-batches from callable
I 2015-05-26 03:35:25 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 03:35:25 theanets.main:89 --batch_size = 1024
I 2015-05-26 03:35:25 theanets.main:89 --gradient_clip = 1
I 2015-05-26 03:35:25 theanets.main:89 --hidden_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --learning_rate = 0.001
I 2015-05-26 03:35:25 theanets.main:89 --train_batches = 30
I 2015-05-26 03:35:25 theanets.main:89 --valid_batches = 3
I 2015-05-26 03:35:25 theanets.main:89 --weight_l1 = None
I 2015-05-26 03:35:25 theanets.main:89 --weight_l2 = None
I 2015-05-26 03:35:25 theanets.trainer:134 compiling evaluation function
I 2015-05-26 03:35:40 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 03:38:47 theanets.trainer:168 validation 0 loss=14155.497070 err=14155.497070 *
I 2015-05-26 03:39:43 theanets.trainer:168 RmsProp 1 loss=13224.631836 err=13224.631836
I 2015-05-26 03:40:42 theanets.trainer:168 RmsProp 2 loss=13053.889648 err=13053.889648
I 2015-05-26 03:41:42 theanets.trainer:168 RmsProp 3 loss=12440.388672 err=12440.388672
I 2015-05-26 03:42:40 theanets.trainer:168 RmsProp 4 loss=10730.856445 err=10730.856445
I 2015-05-26 03:43:39 theanets.trainer:168 RmsProp 5 loss=9995.406250 err=9995.406250
I 2015-05-26 03:44:37 theanets.trainer:168 RmsProp 6 loss=9279.019531 err=9279.019531
I 2015-05-26 03:45:35 theanets.trainer:168 RmsProp 7 loss=8340.414062 err=8340.414062
I 2015-05-26 03:46:34 theanets.trainer:168 RmsProp 8 loss=7433.163574 err=7433.163574
I 2015-05-26 03:47:33 theanets.trainer:168 RmsProp 9 loss=6847.032715 err=6847.032715
I 2015-05-26 03:48:32 theanets.trainer:168 RmsProp 10 loss=6326.406738 err=6326.406738
I 2015-05-26 03:48:33 theanets.trainer:168 validation 1 loss=5148.565918 err=5148.565918 *
I 2015-05-26 03:49:31 theanets.trainer:168 RmsProp 11 loss=5866.434082 err=5866.434082
I 2015-05-26 03:50:30 theanets.trainer:168 RmsProp 12 loss=5467.174316 err=5467.174316
I 2015-05-26 03:51:30 theanets.trainer:168 RmsProp 13 loss=5093.271973 err=5093.271973
I 2015-05-26 03:52:30 theanets.trainer:168 RmsProp 14 loss=4883.946777 err=4883.946777
I 2015-05-26 03:53:30 theanets.trainer:168 RmsProp 15 loss=4702.358398 err=4702.358398
I 2015-05-26 03:54:30 theanets.trainer:168 RmsProp 16 loss=4499.937500 err=4499.937500
I 2015-05-26 03:55:29 theanets.trainer:168 RmsProp 17 loss=4307.541504 err=4307.541504
I 2015-05-26 03:56:30 theanets.trainer:168 RmsProp 18 loss=4099.967773 err=4099.967773
I 2015-05-26 03:57:30 theanets.trainer:168 RmsProp 19 loss=3888.292725 err=3888.292725
I 2015-05-26 03:58:30 theanets.trainer:168 RmsProp 20 loss=3644.297607 err=3644.297607
I 2015-05-26 03:58:31 theanets.trainer:168 validation 2 loss=3256.356201 err=3256.356201 *
I 2015-05-26 03:59:30 theanets.trainer:168 RmsProp 21 loss=3444.162354 err=3444.162354
I 2015-05-26 04:00:29 theanets.trainer:168 RmsProp 22 loss=3270.730225 err=3270.730225
I 2015-05-26 04:01:29 theanets.trainer:168 RmsProp 23 loss=3109.320312 err=3109.320312
I 2015-05-26 04:02:29 theanets.trainer:168 RmsProp 24 loss=2984.313232 err=2984.313232
I 2015-05-26 04:03:29 theanets.trainer:168 RmsProp 25 loss=2951.811279 err=2951.811279
I 2015-05-26 04:04:29 theanets.trainer:168 RmsProp 26 loss=2761.540771 err=2761.540771
I 2015-05-26 04:05:28 theanets.trainer:168 RmsProp 27 loss=2611.636475 err=2611.636475
I 2015-05-26 04:06:28 theanets.trainer:168 RmsProp 28 loss=2514.213135 err=2514.213135
I 2015-05-26 04:07:27 theanets.trainer:168 RmsProp 29 loss=2352.937256 err=2352.937256
I 2015-05-26 04:08:27 theanets.trainer:168 RmsProp 30 loss=2295.092529 err=2295.092529
I 2015-05-26 04:08:28 theanets.trainer:168 validation 3 loss=2379.537354 err=2379.537354 *
I 2015-05-26 04:09:27 theanets.trainer:168 RmsProp 31 loss=2244.415527 err=2244.415527
I 2015-05-26 04:10:26 theanets.trainer:168 RmsProp 32 loss=2176.219482 err=2176.219482
I 2015-05-26 04:11:25 theanets.trainer:168 RmsProp 33 loss=2103.421143 err=2103.421143
I 2015-05-26 04:12:23 theanets.trainer:168 RmsProp 34 loss=2056.696289 err=2056.696289
I 2015-05-26 04:13:20 theanets.trainer:168 RmsProp 35 loss=2141.738281 err=2141.738281
I 2015-05-26 04:14:16 theanets.trainer:168 RmsProp 36 loss=2136.895508 err=2136.895508
I 2015-05-26 04:15:11 theanets.trainer:168 RmsProp 37 loss=1912.963989 err=1912.963989
I 2015-05-26 04:16:06 theanets.trainer:168 RmsProp 38 loss=1820.336792 err=1820.336792
I 2015-05-26 04:17:01 theanets.trainer:168 RmsProp 39 loss=1729.726929 err=1729.726929
I 2015-05-26 04:17:57 theanets.trainer:168 RmsProp 40 loss=1667.151489 err=1667.151489
I 2015-05-26 04:17:58 theanets.trainer:168 validation 4 loss=2166.851562 err=2166.851562 *
I 2015-05-26 04:18:53 theanets.trainer:168 RmsProp 41 loss=1638.195801 err=1638.195801
I 2015-05-26 04:19:49 theanets.trainer:168 RmsProp 42 loss=1533.728516 err=1533.728516
I 2015-05-26 04:20:44 theanets.trainer:168 RmsProp 43 loss=1480.976074 err=1480.976074
I 2015-05-26 04:21:41 theanets.trainer:168 RmsProp 44 loss=1429.763428 err=1429.763428
I 2015-05-26 04:22:36 theanets.trainer:168 RmsProp 45 loss=1379.470581 err=1379.470581
I 2015-05-26 04:23:27 theanets.trainer:168 RmsProp 46 loss=1331.738159 err=1331.738159
I 2015-05-26 04:24:19 theanets.trainer:168 RmsProp 47 loss=1354.903564 err=1354.903564
I 2015-05-26 04:25:11 theanets.trainer:168 RmsProp 48 loss=1279.733521 err=1279.733521
I 2015-05-26 04:26:03 theanets.trainer:168 RmsProp 49 loss=1301.884644 err=1301.884644
I 2015-05-26 04:26:56 theanets.trainer:168 RmsProp 50 loss=1208.577026 err=1208.577026
I 2015-05-26 04:26:57 theanets.trainer:168 validation 5 loss=1875.154175 err=1875.154175 *
I 2015-05-26 04:27:48 theanets.trainer:168 RmsProp 51 loss=1160.803955 err=1160.803955
I 2015-05-26 04:28:39 theanets.trainer:168 RmsProp 52 loss=1157.873169 err=1157.873169
I 2015-05-26 04:29:30 theanets.trainer:168 RmsProp 53 loss=1156.376587 err=1156.376587
I 2015-05-26 04:30:22 theanets.trainer:168 RmsProp 54 loss=1150.007446 err=1150.007446
I 2015-05-26 04:31:14 theanets.trainer:168 RmsProp 55 loss=1284.927368 err=1284.927368
I 2015-05-26 04:32:05 theanets.trainer:168 RmsProp 56 loss=1210.095459 err=1210.095459
I 2015-05-26 04:32:56 theanets.trainer:168 RmsProp 57 loss=1053.269531 err=1053.269531
I 2015-05-26 04:33:48 theanets.trainer:168 RmsProp 58 loss=1021.317566 err=1021.317566
I 2015-05-26 04:34:40 theanets.trainer:168 RmsProp 59 loss=991.451050 err=991.451050
I 2015-05-26 04:35:32 theanets.trainer:168 RmsProp 60 loss=958.338318 err=958.338318
I 2015-05-26 04:35:33 theanets.trainer:168 validation 6 loss=1697.381226 err=1697.381226 *
I 2015-05-26 04:36:25 theanets.trainer:168 RmsProp 61 loss=935.325745 err=935.325745
I 2015-05-26 04:37:17 theanets.trainer:168 RmsProp 62 loss=919.311401 err=919.311401
I 2015-05-26 04:38:09 theanets.trainer:168 RmsProp 63 loss=901.290222 err=901.290222
I 2015-05-26 04:39:01 theanets.trainer:168 RmsProp 64 loss=861.315979 err=861.315979
I 2015-05-26 04:39:55 theanets.trainer:168 RmsProp 65 loss=837.071289 err=837.071289
I 2015-05-26 04:40:47 theanets.trainer:168 RmsProp 66 loss=823.974609 err=823.974609
I 2015-05-26 04:41:40 theanets.trainer:168 RmsProp 67 loss=798.286377 err=798.286377
I 2015-05-26 04:42:33 theanets.trainer:168 RmsProp 68 loss=772.956665 err=772.956665
I 2015-05-26 04:43:26 theanets.trainer:168 RmsProp 69 loss=745.044739 err=745.044739
I 2015-05-26 04:44:19 theanets.trainer:168 RmsProp 70 loss=750.735352 err=750.735352
I 2015-05-26 04:44:20 theanets.trainer:168 validation 7 loss=1618.136108 err=1618.136108 *
I 2015-05-26 04:45:13 theanets.trainer:168 RmsProp 71 loss=731.828125 err=731.828125
I 2015-05-26 04:46:05 theanets.trainer:168 RmsProp 72 loss=737.175110 err=737.175110
I 2015-05-26 04:46:58 theanets.trainer:168 RmsProp 73 loss=697.464661 err=697.464661
I 2015-05-26 04:47:50 theanets.trainer:168 RmsProp 74 loss=696.924072 err=696.924072
I 2015-05-26 04:48:43 theanets.trainer:168 RmsProp 75 loss=695.509827 err=695.509827
I 2015-05-26 04:49:35 theanets.trainer:168 RmsProp 76 loss=649.735352 err=649.735352
I 2015-05-26 04:50:28 theanets.trainer:168 RmsProp 77 loss=635.508789 err=635.508789
I 2015-05-26 04:51:20 theanets.trainer:168 RmsProp 78 loss=620.870667 err=620.870667
I 2015-05-26 04:52:13 theanets.trainer:168 RmsProp 79 loss=599.139893 err=599.139893
I 2015-05-26 04:53:06 theanets.trainer:168 RmsProp 80 loss=584.922058 err=584.922058
I 2015-05-26 04:53:07 theanets.trainer:168 validation 8 loss=1439.719360 err=1439.719360 *
I 2015-05-26 04:53:59 theanets.trainer:168 RmsProp 81 loss=571.128174 err=571.128174
I 2015-05-26 04:54:50 theanets.trainer:168 RmsProp 82 loss=564.382812 err=564.382812
I 2015-05-26 04:55:41 theanets.trainer:168 RmsProp 83 loss=540.292603 err=540.292603
I 2015-05-26 04:56:32 theanets.trainer:168 RmsProp 84 loss=526.407043 err=526.407043
I 2015-05-26 04:57:22 theanets.trainer:168 RmsProp 85 loss=516.983093 err=516.983093
I 2015-05-26 04:58:13 theanets.trainer:168 RmsProp 86 loss=513.790222 err=513.790222
I 2015-05-26 04:59:04 theanets.trainer:168 RmsProp 87 loss=496.677795 err=496.677795
I 2015-05-26 04:59:55 theanets.trainer:168 RmsProp 88 loss=470.019409 err=470.019409
I 2015-05-26 05:00:46 theanets.trainer:168 RmsProp 89 loss=468.772461 err=468.772461
I 2015-05-26 05:01:37 theanets.trainer:168 RmsProp 90 loss=462.992767 err=462.992767
I 2015-05-26 05:01:38 theanets.trainer:168 validation 9 loss=1252.785522 err=1252.785522 *
I 2015-05-26 05:02:28 theanets.trainer:168 RmsProp 91 loss=443.114716 err=443.114716
I 2015-05-26 05:03:19 theanets.trainer:168 RmsProp 92 loss=438.304565 err=438.304565
I 2015-05-26 05:04:11 theanets.trainer:168 RmsProp 93 loss=422.050781 err=422.050781
I 2015-05-26 05:05:02 theanets.trainer:168 RmsProp 94 loss=414.566559 err=414.566559
I 2015-05-26 05:05:54 theanets.trainer:168 RmsProp 95 loss=411.029114 err=411.029114
I 2015-05-26 05:06:46 theanets.trainer:168 RmsProp 96 loss=409.880249 err=409.880249
I 2015-05-26 05:07:38 theanets.trainer:168 RmsProp 97 loss=405.456024 err=405.456024
I 2015-05-26 05:08:28 theanets.trainer:168 RmsProp 98 loss=386.661713 err=386.661713
I 2015-05-26 05:09:18 theanets.trainer:168 RmsProp 99 loss=391.212036 err=391.212036
I 2015-05-26 05:10:08 theanets.trainer:168 RmsProp 100 loss=379.376678 err=379.376678
I 2015-05-26 05:10:09 theanets.trainer:168 validation 10 loss=1226.103882 err=1226.103882 *
I 2015-05-26 05:10:58 theanets.trainer:168 RmsProp 101 loss=374.159332 err=374.159332
I 2015-05-26 05:11:47 theanets.trainer:168 RmsProp 102 loss=380.098083 err=380.098083
I 2015-05-26 05:12:36 theanets.trainer:168 RmsProp 103 loss=361.053650 err=361.053650
I 2015-05-26 05:13:24 theanets.trainer:168 RmsProp 104 loss=339.204254 err=339.204254
I 2015-05-26 05:14:14 theanets.trainer:168 RmsProp 105 loss=337.747620 err=337.747620
I 2015-05-26 05:15:04 theanets.trainer:168 RmsProp 106 loss=336.673035 err=336.673035
I 2015-05-26 05:15:54 theanets.trainer:168 RmsProp 107 loss=324.322968 err=324.322968
I 2015-05-26 05:16:44 theanets.trainer:168 RmsProp 108 loss=318.159973 err=318.159973
I 2015-05-26 05:17:34 theanets.trainer:168 RmsProp 109 loss=306.985809 err=306.985809
I 2015-05-26 05:18:23 theanets.trainer:168 RmsProp 110 loss=297.843964 err=297.843964
I 2015-05-26 05:18:24 theanets.trainer:168 validation 11 loss=1218.609619 err=1218.609619 *
I 2015-05-26 05:19:13 theanets.trainer:168 RmsProp 111 loss=293.841736 err=293.841736
I 2015-05-26 05:20:03 theanets.trainer:168 RmsProp 112 loss=284.315491 err=284.315491
I 2015-05-26 05:20:52 theanets.trainer:168 RmsProp 113 loss=282.188141 err=282.188141
I 2015-05-26 05:21:42 theanets.trainer:168 RmsProp 114 loss=274.922180 err=274.922180
I 2015-05-26 05:22:32 theanets.trainer:168 RmsProp 115 loss=271.625153 err=271.625153
I 2015-05-26 05:23:22 theanets.trainer:168 RmsProp 116 loss=258.190063 err=258.190063
I 2015-05-26 05:24:12 theanets.trainer:168 RmsProp 117 loss=267.365570 err=267.365570
I 2015-05-26 05:25:02 theanets.trainer:168 RmsProp 118 loss=254.523499 err=254.523499
I 2015-05-26 05:25:52 theanets.trainer:168 RmsProp 119 loss=248.647537 err=248.647537
I 2015-05-26 05:26:41 theanets.trainer:168 RmsProp 120 loss=250.011688 err=250.011688
I 2015-05-26 05:26:42 theanets.trainer:168 validation 12 loss=1217.564575 err=1217.564575 *
I 2015-05-26 05:27:31 theanets.trainer:168 RmsProp 121 loss=240.505692 err=240.505692
I 2015-05-26 05:28:22 theanets.trainer:168 RmsProp 122 loss=236.612518 err=236.612518
I 2015-05-26 05:29:12 theanets.trainer:168 RmsProp 123 loss=235.736023 err=235.736023
I 2015-05-26 05:30:02 theanets.trainer:168 RmsProp 124 loss=225.613754 err=225.613754
I 2015-05-26 05:30:52 theanets.trainer:168 RmsProp 125 loss=223.955551 err=223.955551
I 2015-05-26 05:31:43 theanets.trainer:168 RmsProp 126 loss=222.601105 err=222.601105
I 2015-05-26 05:32:32 theanets.trainer:168 RmsProp 127 loss=216.381363 err=216.381363
I 2015-05-26 05:33:22 theanets.trainer:168 RmsProp 128 loss=212.752930 err=212.752930
I 2015-05-26 05:34:12 theanets.trainer:168 RmsProp 129 loss=213.686508 err=213.686508
I 2015-05-26 05:35:03 theanets.trainer:168 RmsProp 130 loss=204.489685 err=204.489685
I 2015-05-26 05:35:04 theanets.trainer:168 validation 13 loss=1166.872681 err=1166.872681 *
I 2015-05-26 05:35:54 theanets.trainer:168 RmsProp 131 loss=201.828049 err=201.828049
I 2015-05-26 05:36:43 theanets.trainer:168 RmsProp 132 loss=190.780075 err=190.780075
I 2015-05-26 05:37:31 theanets.trainer:168 RmsProp 133 loss=185.626770 err=185.626770
I 2015-05-26 05:38:19 theanets.trainer:168 RmsProp 134 loss=188.307129 err=188.307129
I 2015-05-26 05:39:06 theanets.trainer:168 RmsProp 135 loss=178.290634 err=178.290634
I 2015-05-26 05:39:53 theanets.trainer:168 RmsProp 136 loss=181.983551 err=181.983551
I 2015-05-26 05:40:41 theanets.trainer:168 RmsProp 137 loss=177.403625 err=177.403625
I 2015-05-26 05:41:28 theanets.trainer:168 RmsProp 138 loss=170.703400 err=170.703400
I 2015-05-26 05:42:15 theanets.trainer:168 RmsProp 139 loss=167.331360 err=167.331360
I 2015-05-26 05:43:02 theanets.trainer:168 RmsProp 140 loss=161.327698 err=161.327698
I 2015-05-26 05:43:03 theanets.trainer:168 validation 14 loss=1089.548462 err=1089.548462 *
I 2015-05-26 05:43:50 theanets.trainer:168 RmsProp 141 loss=159.567352 err=159.567352
I 2015-05-26 05:44:38 theanets.trainer:168 RmsProp 142 loss=163.196426 err=163.196426
I 2015-05-26 05:45:25 theanets.trainer:168 RmsProp 143 loss=156.012054 err=156.012054
I 2015-05-26 05:46:12 theanets.trainer:168 RmsProp 144 loss=150.782471 err=150.782471
I 2015-05-26 05:47:00 theanets.trainer:168 RmsProp 145 loss=154.514236 err=154.514236
I 2015-05-26 05:47:48 theanets.trainer:168 RmsProp 146 loss=150.347672 err=150.347672
I 2015-05-26 05:48:36 theanets.trainer:168 RmsProp 147 loss=144.155807 err=144.155807
I 2015-05-26 05:49:24 theanets.trainer:168 RmsProp 148 loss=145.226242 err=145.226242
I 2015-05-26 05:50:12 theanets.trainer:168 RmsProp 149 loss=139.814499 err=139.814499
I 2015-05-26 05:51:00 theanets.trainer:168 RmsProp 150 loss=133.906601 err=133.906601
I 2015-05-26 05:51:01 theanets.trainer:168 validation 15 loss=1125.977295 err=1125.977295
I 2015-05-26 05:51:48 theanets.trainer:168 RmsProp 151 loss=127.588341 err=127.588341
I 2015-05-26 05:52:35 theanets.trainer:168 RmsProp 152 loss=124.776192 err=124.776192
I 2015-05-26 05:53:22 theanets.trainer:168 RmsProp 153 loss=126.357101 err=126.357101
I 2015-05-26 05:54:09 theanets.trainer:168 RmsProp 154 loss=125.560005 err=125.560005
I 2015-05-26 05:54:56 theanets.trainer:168 RmsProp 155 loss=122.919434 err=122.919434
I 2015-05-26 05:55:44 theanets.trainer:168 RmsProp 156 loss=115.809731 err=115.809731
I 2015-05-26 05:56:32 theanets.trainer:168 RmsProp 157 loss=114.593788 err=114.593788
I 2015-05-26 05:57:19 theanets.trainer:168 RmsProp 158 loss=111.296257 err=111.296257
I 2015-05-26 05:58:07 theanets.trainer:168 RmsProp 159 loss=109.381783 err=109.381783
I 2015-05-26 05:58:54 theanets.trainer:168 RmsProp 160 loss=107.435692 err=107.435692
I 2015-05-26 05:58:55 theanets.trainer:168 validation 16 loss=1135.203369 err=1135.203369
I 2015-05-26 05:59:42 theanets.trainer:168 RmsProp 161 loss=106.269676 err=106.269676
I 2015-05-26 06:00:30 theanets.trainer:168 RmsProp 162 loss=103.690681 err=103.690681
I 2015-05-26 06:01:17 theanets.trainer:168 RmsProp 163 loss=101.248749 err=101.248749
I 2015-05-26 06:02:05 theanets.trainer:168 RmsProp 164 loss=97.989586 err=97.989586
I 2015-05-26 06:02:52 theanets.trainer:168 RmsProp 165 loss=97.419304 err=97.419304
I 2015-05-26 06:03:40 theanets.trainer:168 RmsProp 166 loss=99.508987 err=99.508987
I 2015-05-26 06:04:27 theanets.trainer:168 RmsProp 167 loss=96.182915 err=96.182915
I 2015-05-26 06:05:14 theanets.trainer:168 RmsProp 168 loss=91.788132 err=91.788132
I 2015-05-26 06:06:01 theanets.trainer:168 RmsProp 169 loss=89.039772 err=89.039772
I 2015-05-26 06:06:48 theanets.trainer:168 RmsProp 170 loss=86.745865 err=86.745865
I 2015-05-26 06:06:49 theanets.trainer:168 validation 17 loss=1083.991821 err=1083.991821 *
I 2015-05-26 06:07:35 theanets.trainer:168 RmsProp 171 loss=86.074722 err=86.074722
I 2015-05-26 06:08:21 theanets.trainer:168 RmsProp 172 loss=84.170250 err=84.170250
I 2015-05-26 06:09:09 theanets.trainer:168 RmsProp 173 loss=81.620171 err=81.620171
I 2015-05-26 06:09:56 theanets.trainer:168 RmsProp 174 loss=81.391380 err=81.391380
I 2015-05-26 06:10:43 theanets.trainer:168 RmsProp 175 loss=83.159531 err=83.159531
I 2015-05-26 06:11:31 theanets.trainer:168 RmsProp 176 loss=78.725365 err=78.725365
I 2015-05-26 06:12:19 theanets.trainer:168 RmsProp 177 loss=77.838417 err=77.838417
I 2015-05-26 06:13:07 theanets.trainer:168 RmsProp 178 loss=77.795036 err=77.795036
I 2015-05-26 06:13:55 theanets.trainer:168 RmsProp 179 loss=74.798691 err=74.798691
I 2015-05-26 06:14:43 theanets.trainer:168 RmsProp 180 loss=72.708786 err=72.708786
I 2015-05-26 06:14:44 theanets.trainer:168 validation 18 loss=1048.804565 err=1048.804565 *
I 2015-05-26 06:15:30 theanets.trainer:168 RmsProp 181 loss=73.200035 err=73.200035
I 2015-05-26 06:16:18 theanets.trainer:168 RmsProp 182 loss=72.154175 err=72.154175
I 2015-05-26 06:17:06 theanets.trainer:168 RmsProp 183 loss=71.588348 err=71.588348
I 2015-05-26 06:17:54 theanets.trainer:168 RmsProp 184 loss=67.664131 err=67.664131
I 2015-05-26 06:18:42 theanets.trainer:168 RmsProp 185 loss=67.423073 err=67.423073
I 2015-05-26 06:19:29 theanets.trainer:168 RmsProp 186 loss=65.625687 err=65.625687
I 2015-05-26 06:20:16 theanets.trainer:168 RmsProp 187 loss=65.195221 err=65.195221
I 2015-05-26 06:21:02 theanets.trainer:168 RmsProp 188 loss=64.874870 err=64.874870
I 2015-05-26 06:21:50 theanets.trainer:168 RmsProp 189 loss=64.076393 err=64.076393
I 2015-05-26 06:22:37 theanets.trainer:168 RmsProp 190 loss=62.754112 err=62.754112
I 2015-05-26 06:22:39 theanets.trainer:168 validation 19 loss=1120.487305 err=1120.487305
I 2015-05-26 06:23:25 theanets.trainer:168 RmsProp 191 loss=60.738892 err=60.738892
I 2015-05-26 06:24:11 theanets.trainer:168 RmsProp 192 loss=59.872807 err=59.872807
I 2015-05-26 06:24:57 theanets.trainer:168 RmsProp 193 loss=58.998947 err=58.998947
I 2015-05-26 06:25:45 theanets.trainer:168 RmsProp 194 loss=56.390129 err=56.390129
I 2015-05-26 06:26:32 theanets.trainer:168 RmsProp 195 loss=56.439316 err=56.439316
I 2015-05-26 06:27:19 theanets.trainer:168 RmsProp 196 loss=54.598335 err=54.598335
I 2015-05-26 06:28:06 theanets.trainer:168 RmsProp 197 loss=53.555443 err=53.555443
I 2015-05-26 06:28:54 theanets.trainer:168 RmsProp 198 loss=52.994934 err=52.994934
I 2015-05-26 06:29:42 theanets.trainer:168 RmsProp 199 loss=51.766808 err=51.766808
I 2015-05-26 06:30:30 theanets.trainer:168 RmsProp 200 loss=51.699150 err=51.699150
I 2015-05-26 06:30:31 theanets.trainer:168 validation 20 loss=1162.125366 err=1162.125366
I 2015-05-26 06:31:18 theanets.trainer:168 RmsProp 201 loss=52.312122 err=52.312122
I 2015-05-26 06:32:06 theanets.trainer:168 RmsProp 202 loss=49.093685 err=49.093685
I 2015-05-26 06:32:54 theanets.trainer:168 RmsProp 203 loss=49.391102 err=49.391102
I 2015-05-26 06:33:42 theanets.trainer:168 RmsProp 204 loss=46.332294 err=46.332294
I 2015-05-26 06:34:29 theanets.trainer:168 RmsProp 205 loss=46.830956 err=46.830956
I 2015-05-26 06:35:14 theanets.trainer:168 RmsProp 206 loss=47.759823 err=47.759823
I 2015-05-26 06:36:00 theanets.trainer:168 RmsProp 207 loss=46.881306 err=46.881306
I 2015-05-26 06:36:45 theanets.trainer:168 RmsProp 208 loss=45.030388 err=45.030388
I 2015-05-26 06:37:31 theanets.trainer:168 RmsProp 209 loss=45.364124 err=45.364124
I 2015-05-26 06:38:17 theanets.trainer:168 RmsProp 210 loss=44.468399 err=44.468399
I 2015-05-26 06:38:18 theanets.trainer:168 validation 21 loss=1184.570190 err=1184.570190
I 2015-05-26 06:39:03 theanets.trainer:168 RmsProp 211 loss=43.207874 err=43.207874
I 2015-05-26 06:39:49 theanets.trainer:168 RmsProp 212 loss=41.624832 err=41.624832
I 2015-05-26 06:40:33 theanets.trainer:168 RmsProp 213 loss=41.093021 err=41.093021
I 2015-05-26 06:41:17 theanets.trainer:168 RmsProp 214 loss=39.863487 err=39.863487
I 2015-05-26 06:42:00 theanets.trainer:168 RmsProp 215 loss=40.867771 err=40.867771
I 2015-05-26 06:42:42 theanets.trainer:168 RmsProp 216 loss=39.228264 err=39.228264
I 2015-05-26 06:43:24 theanets.trainer:168 RmsProp 217 loss=38.613705 err=38.613705
I 2015-05-26 06:44:07 theanets.trainer:168 RmsProp 218 loss=38.782707 err=38.782707
I 2015-05-26 06:44:50 theanets.trainer:168 RmsProp 219 loss=36.597057 err=36.597057
I 2015-05-26 06:45:33 theanets.trainer:168 RmsProp 220 loss=35.580326 err=35.580326
I 2015-05-26 06:45:34 theanets.trainer:168 validation 22 loss=1209.698486 err=1209.698486
I 2015-05-26 06:46:17 theanets.trainer:168 RmsProp 221 loss=34.305248 err=34.305248
I 2015-05-26 06:47:00 theanets.trainer:168 RmsProp 222 loss=37.221245 err=37.221245
I 2015-05-26 06:47:42 theanets.trainer:168 RmsProp 223 loss=35.257484 err=35.257484
I 2015-05-26 06:48:24 theanets.trainer:168 RmsProp 224 loss=35.155083 err=35.155083
I 2015-05-26 06:49:07 theanets.trainer:168 RmsProp 225 loss=33.741589 err=33.741589
I 2015-05-26 06:49:49 theanets.trainer:168 RmsProp 226 loss=33.405041 err=33.405041
I 2015-05-26 06:50:32 theanets.trainer:168 RmsProp 227 loss=32.266716 err=32.266716
I 2015-05-26 06:51:15 theanets.trainer:168 RmsProp 228 loss=31.285742 err=31.285742
I 2015-05-26 06:51:59 theanets.trainer:168 RmsProp 229 loss=30.673117 err=30.673117
I 2015-05-26 06:52:41 theanets.trainer:168 RmsProp 230 loss=29.375101 err=29.375101
I 2015-05-26 06:52:42 theanets.trainer:168 validation 23 loss=1181.475586 err=1181.475586
I 2015-05-26 06:52:42 theanets.trainer:252 patience elapsed!
I 2015-05-26 06:52:42 theanets.dataset:133 valid: 2 mini-batches from callable
I 2015-05-26 06:52:42 theanets.dataset:133 train: 10 mini-batches from callable
I 2015-05-26 06:52:42 theanets.main:87 creating trainer <class 'theanets.trainer.RmsProp'>
I 2015-05-26 06:52:42 theanets.main:89 --algorithms = rmsprop
I 2015-05-26 06:52:42 theanets.main:89 --batch_size = 1024
I 2015-05-26 06:52:42 theanets.main:89 --gradient_clip = 100000.0
I 2015-05-26 06:52:42 theanets.main:89 --hidden_l1 = None
I 2015-05-26 06:52:42 theanets.main:89 --learning_rate = 0.0001
I 2015-05-26 06:52:42 theanets.main:89 --train_batches = 10
I 2015-05-26 06:52:42 theanets.main:89 --valid_batches = 2
I 2015-05-26 06:52:42 theanets.main:89 --weight_l1 = None
I 2015-05-26 06:52:42 theanets.main:89 --weight_l2 = None
I 2015-05-26 06:52:43 theanets.trainer:134 compiling evaluation function
I 2015-05-26 06:52:52 theanets.trainer:294 compiling RmsProp learning function
I 2015-05-26 06:54:33 theanets.trainer:168 validation 0 loss=1148.231079 err=1148.231079 *
I 2015-05-26 06:54:47 theanets.trainer:168 RmsProp 1 loss=64.777245 err=64.777245
I 2015-05-26 06:55:02 theanets.trainer:168 RmsProp 2 loss=41.072517 err=41.072517
I 2015-05-26 06:55:16 theanets.trainer:168 RmsProp 3 loss=30.646275 err=30.646275
I 2015-05-26 06:55:30 theanets.trainer:168 RmsProp 4 loss=25.227945 err=25.227945
I 2015-05-26 06:55:44 theanets.trainer:168 RmsProp 5 loss=21.239756 err=21.239756
I 2015-05-26 06:55:59 theanets.trainer:168 RmsProp 6 loss=18.248938 err=18.248938
I 2015-05-26 06:56:13 theanets.trainer:168 RmsProp 7 loss=16.116505 err=16.116505
I 2015-05-26 06:56:28 theanets.trainer:168 RmsProp 8 loss=13.834183 err=13.834183
I 2015-05-26 06:56:42 theanets.trainer:168 RmsProp 9 loss=12.006107 err=12.006107
I 2015-05-26 06:56:57 theanets.trainer:168 RmsProp 10 loss=10.463065 err=10.463065
I 2015-05-26 06:56:57 theanets.trainer:168 validation 1 loss=952.481628 err=952.481628 *
I 2015-05-26 06:57:11 theanets.trainer:168 RmsProp 11 loss=9.394180 err=9.394180
I 2015-05-26 06:57:24 theanets.trainer:168 RmsProp 12 loss=8.938931 err=8.938931
I 2015-05-26 06:57:38 theanets.trainer:168 RmsProp 13 loss=7.962483 err=7.962483
I 2015-05-26 06:57:51 theanets.trainer:168 RmsProp 14 loss=7.287155 err=7.287155
I 2015-05-26 06:58:04 theanets.trainer:168 RmsProp 15 loss=6.914707 err=6.914707
I 2015-05-26 06:58:17 theanets.trainer:168 RmsProp 16 loss=6.385776 err=6.385776
I 2015-05-26 06:58:29 theanets.trainer:168 RmsProp 17 loss=6.227417 err=6.227417
I 2015-05-26 06:58:42 theanets.trainer:168 RmsProp 18 loss=5.732406 err=5.732406
I 2015-05-26 06:58:55 theanets.trainer:168 RmsProp 19 loss=5.395331 err=5.395331
I 2015-05-26 06:59:07 theanets.trainer:168 RmsProp 20 loss=5.301866 err=5.301866
I 2015-05-26 06:59:08 theanets.trainer:168 validation 2 loss=921.021423 err=921.021423 *
I 2015-05-26 06:59:21 theanets.trainer:168 RmsProp 21 loss=4.898540 err=4.898540
I 2015-05-26 06:59:33 theanets.trainer:168 RmsProp 22 loss=4.776073 err=4.776073
I 2015-05-26 06:59:46 theanets.trainer:168 RmsProp 23 loss=4.521222 err=4.521222
I 2015-05-26 06:59:58 theanets.trainer:168 RmsProp 24 loss=4.365866 err=4.365866
I 2015-05-26 07:00:11 theanets.trainer:168 RmsProp 25 loss=4.164219 err=4.164219
I 2015-05-26 07:00:23 theanets.trainer:168 RmsProp 26 loss=3.983140 err=3.983140
I 2015-05-26 07:00:36 theanets.trainer:168 RmsProp 27 loss=4.019876 err=4.019876
I 2015-05-26 07:00:48 theanets.trainer:168 RmsProp 28 loss=3.722855 err=3.722855
I 2015-05-26 07:01:00 theanets.trainer:168 RmsProp 29 loss=3.661476 err=3.661476
I 2015-05-26 07:01:13 theanets.trainer:168 RmsProp 30 loss=3.515769 err=3.515769
I 2015-05-26 07:01:13 theanets.trainer:168 validation 3 loss=902.180298 err=902.180298 *
I 2015-05-26 07:01:25 theanets.trainer:168 RmsProp 31 loss=3.511055 err=3.511055
I 2015-05-26 07:01:38 theanets.trainer:168 RmsProp 32 loss=3.364782 err=3.364782
I 2015-05-26 07:01:51 theanets.trainer:168 RmsProp 33 loss=3.150709 err=3.150709
I 2015-05-26 07:02:04 theanets.trainer:168 RmsProp 34 loss=3.130799 err=3.130799
I 2015-05-26 07:02:17 theanets.trainer:168 RmsProp 35 loss=3.088982 err=3.088982
I 2015-05-26 07:02:30 theanets.trainer:168 RmsProp 36 loss=2.988440 err=2.988440
I 2015-05-26 07:02:43 theanets.trainer:168 RmsProp 37 loss=2.849711 err=2.849711
I 2015-05-26 07:02:56 theanets.trainer:168 RmsProp 38 loss=2.797945 err=2.797945
I 2015-05-26 07:03:08 theanets.trainer:168 RmsProp 39 loss=2.783474 err=2.783474
I 2015-05-26 07:03:21 theanets.trainer:168 RmsProp 40 loss=2.692852 err=2.692852
I 2015-05-26 07:03:22 theanets.trainer:168 validation 4 loss=891.127747 err=891.127747 *
I 2015-05-26 07:03:35 theanets.trainer:168 RmsProp 41 loss=2.617808 err=2.617808
I 2015-05-26 07:03:48 theanets.trainer:168 RmsProp 42 loss=2.532119 err=2.532119
I 2015-05-26 07:04:01 theanets.trainer:168 RmsProp 43 loss=2.483007 err=2.483007
I 2015-05-26 07:04:14 theanets.trainer:168 RmsProp 44 loss=2.442729 err=2.442729
I 2015-05-26 07:04:27 theanets.trainer:168 RmsProp 45 loss=2.399459 err=2.399459
I 2015-05-26 07:04:39 theanets.trainer:168 RmsProp 46 loss=2.407060 err=2.407060
I 2015-05-26 07:04:52 theanets.trainer:168 RmsProp 47 loss=2.282552 err=2.282552
I 2015-05-26 07:05:05 theanets.trainer:168 RmsProp 48 loss=2.292561 err=2.292561
I 2015-05-26 07:05:17 theanets.trainer:168 RmsProp 49 loss=2.205032 err=2.205032
I 2015-05-26 07:05:30 theanets.trainer:168 RmsProp 50 loss=2.158501 err=2.158501
I 2015-05-26 07:05:31 theanets.trainer:168 validation 5 loss=881.747498 err=881.747498 *
I 2015-05-26 07:05:43 theanets.trainer:168 RmsProp 51 loss=2.224916 err=2.224916
I 2015-05-26 07:05:56 theanets.trainer:168 RmsProp 52 loss=2.060769 err=2.060769
I 2015-05-26 07:06:08 theanets.trainer:168 RmsProp 53 loss=2.112039 err=2.112039
I 2015-05-26 07:06:21 theanets.trainer:168 RmsProp 54 loss=2.058137 err=2.058137
I 2015-05-26 07:06:33 theanets.trainer:168 RmsProp 55 loss=1.970110 err=1.970110
I 2015-05-26 07:06:46 theanets.trainer:168 RmsProp 56 loss=2.047054 err=2.047054
I 2015-05-26 07:06:59 theanets.trainer:168 RmsProp 57 loss=1.969071 err=1.969071
I 2015-05-26 07:07:12 theanets.trainer:168 RmsProp 58 loss=1.852863 err=1.852863
I 2015-05-26 07:07:25 theanets.trainer:168 RmsProp 59 loss=1.913680 err=1.913680
I 2015-05-26 07:07:39 theanets.trainer:168 RmsProp 60 loss=1.873140 err=1.873140
I 2015-05-26 07:07:39 theanets.trainer:168 validation 6 loss=874.322388 err=874.322388 *
I 2015-05-26 07:07:52 theanets.trainer:168 RmsProp 61 loss=1.775635 err=1.775635
I 2015-05-26 07:08:05 theanets.trainer:168 RmsProp 62 loss=1.796694 err=1.796694
I 2015-05-26 07:08:18 theanets.trainer:168 RmsProp 63 loss=1.763181 err=1.763181
I 2015-05-26 07:08:31 theanets.trainer:168 RmsProp 64 loss=1.753470 err=1.753470
I 2015-05-26 07:08:44 theanets.trainer:168 RmsProp 65 loss=1.686255 err=1.686255
I 2015-05-26 07:08:57 theanets.trainer:168 RmsProp 66 loss=1.696768 err=1.696768
I 2015-05-26 07:09:10 theanets.trainer:168 RmsProp 67 loss=1.696186 err=1.696186
I 2015-05-26 07:09:22 theanets.trainer:168 RmsProp 68 loss=1.635944 err=1.635944
I 2015-05-26 07:09:35 theanets.trainer:168 RmsProp 69 loss=1.626493 err=1.626493
I 2015-05-26 07:09:48 theanets.trainer:168 RmsProp 70 loss=1.611758 err=1.611758
I 2015-05-26 07:09:49 theanets.trainer:168 validation 7 loss=867.013672 err=867.013672 *
I 2015-05-26 07:10:02 theanets.trainer:168 RmsProp 71 loss=1.568890 err=1.568890
I 2015-05-26 07:10:14 theanets.trainer:168 RmsProp 72 loss=1.565220 err=1.565220
I 2015-05-26 07:10:27 theanets.trainer:168 RmsProp 73 loss=1.505205 err=1.505205
I 2015-05-26 07:10:40 theanets.trainer:168 RmsProp 74 loss=1.507328 err=1.507328
I 2015-05-26 07:10:53 theanets.trainer:168 RmsProp 75 loss=1.517215 err=1.517215
I 2015-05-26 07:11:06 theanets.trainer:168 RmsProp 76 loss=1.460566 err=1.460566
I 2015-05-26 07:11:19 theanets.trainer:168 RmsProp 77 loss=1.466738 err=1.466738
I 2015-05-26 07:11:32 theanets.trainer:168 RmsProp 78 loss=1.489150 err=1.489150
I 2015-05-26 07:11:45 theanets.trainer:168 RmsProp 79 loss=1.391627 err=1.391627
I 2015-05-26 07:11:58 theanets.trainer:168 RmsProp 80 loss=1.417418 err=1.417418
I 2015-05-26 07:11:58 theanets.trainer:168 validation 8 loss=862.923462 err=862.923462 *
I 2015-05-26 07:12:11 theanets.trainer:168 RmsProp 81 loss=1.389868 err=1.389868
I 2015-05-26 07:12:23 theanets.trainer:168 RmsProp 82 loss=1.409708 err=1.409708
I 2015-05-26 07:12:35 theanets.trainer:168 RmsProp 83 loss=1.382404 err=1.382404
I 2015-05-26 07:12:48 theanets.trainer:168 RmsProp 84 loss=1.348380 err=1.348380
I 2015-05-26 07:13:00 theanets.trainer:168 RmsProp 85 loss=1.316748 err=1.316748
I 2015-05-26 07:13:12 theanets.trainer:168 RmsProp 86 loss=1.338539 err=1.338539
I 2015-05-26 07:13:24 theanets.trainer:168 RmsProp 87 loss=1.416565 err=1.416565
I 2015-05-26 07:13:36 theanets.trainer:168 RmsProp 88 loss=1.255576 err=1.255576
I 2015-05-26 07:13:49 theanets.trainer:168 RmsProp 89 loss=1.271079 err=1.271079
I 2015-05-26 07:14:01 theanets.trainer:168 RmsProp 90 loss=1.311205 err=1.311205
I 2015-05-26 07:14:01 theanets.trainer:168 validation 9 loss=858.281860 err=858.281860 *
I 2015-05-26 07:14:14 theanets.trainer:168 RmsProp 91 loss=1.262644 err=1.262644
I 2015-05-26 07:14:26 theanets.trainer:168 RmsProp 92 loss=1.248928 err=1.248928
I 2015-05-26 07:14:39 theanets.trainer:168 RmsProp 93 loss=1.193511 err=1.193511
I 2015-05-26 07:14:52 theanets.trainer:168 RmsProp 94 loss=1.259332 err=1.259332
I 2015-05-26 07:15:04 theanets.trainer:168 RmsProp 95 loss=1.218568 err=1.218568
I 2015-05-26 07:15:17 theanets.trainer:168 RmsProp 96 loss=1.214267 err=1.214267
I 2015-05-26 07:15:30 theanets.trainer:168 RmsProp 97 loss=1.175688 err=1.175688
I 2015-05-26 07:15:43 theanets.trainer:168 RmsProp 98 loss=1.139210 err=1.139210
I 2015-05-26 07:15:55 theanets.trainer:168 RmsProp 99 loss=1.269961 err=1.269961
I 2015-05-26 07:16:08 theanets.trainer:168 RmsProp 100 loss=1.222183 err=1.222183
I 2015-05-26 07:16:08 theanets.trainer:168 validation 10 loss=854.362732 err=854.362732 *
I 2015-05-26 07:16:21 theanets.trainer:168 RmsProp 101 loss=1.142427 err=1.142427
I 2015-05-26 07:16:34 theanets.trainer:168 RmsProp 102 loss=1.066718 err=1.066718
I 2015-05-26 07:16:47 theanets.trainer:168 RmsProp 103 loss=1.148409 err=1.148409
I 2015-05-26 07:16:59 theanets.trainer:168 RmsProp 104 loss=1.088284 err=1.088284
I 2015-05-26 07:17:12 theanets.trainer:168 RmsProp 105 loss=1.118105 err=1.118105
I 2015-05-26 07:17:25 theanets.trainer:168 RmsProp 106 loss=1.125526 err=1.125526
I 2015-05-26 07:17:38 theanets.trainer:168 RmsProp 107 loss=1.085491 err=1.085491
I 2015-05-26 07:17:50 theanets.trainer:168 RmsProp 108 loss=1.071940 err=1.071940
I 2015-05-26 07:18:03 theanets.trainer:168 RmsProp 109 loss=1.074492 err=1.074492
I 2015-05-26 07:18:15 theanets.trainer:168 RmsProp 110 loss=1.029673 err=1.029673
I 2015-05-26 07:18:16 theanets.trainer:168 validation 11 loss=848.059998 err=848.059998 *
I 2015-05-26 07:18:29 theanets.trainer:168 RmsProp 111 loss=1.049374 err=1.049374
I 2015-05-26 07:18:41 theanets.trainer:168 RmsProp 112 loss=1.007617 err=1.007617
I 2015-05-26 07:18:53 theanets.trainer:168 RmsProp 113 loss=1.123554 err=1.123554
I 2015-05-26 07:19:06 theanets.trainer:168 RmsProp 114 loss=1.055111 err=1.055111
I 2015-05-26 07:19:19 theanets.trainer:168 RmsProp 115 loss=1.020482 err=1.020482
I 2015-05-26 07:19:32 theanets.trainer:168 RmsProp 116 loss=0.984263 err=0.984263
I 2015-05-26 07:19:45 theanets.trainer:168 RmsProp 117 loss=0.974361 err=0.974361
I 2015-05-26 07:19:58 theanets.trainer:168 RmsProp 118 loss=1.023707 err=1.023707
I 2015-05-26 07:20:11 theanets.trainer:168 RmsProp 119 loss=0.955548 err=0.955548
I 2015-05-26 07:20:24 theanets.trainer:168 RmsProp 120 loss=1.059641 err=1.059641
I 2015-05-26 07:20:25 theanets.trainer:168 validation 12 loss=845.811462 err=845.811462 *
I 2015-05-26 07:20:37 theanets.trainer:168 RmsProp 121 loss=0.963409 err=0.963409
I 2015-05-26 07:20:50 theanets.trainer:168 RmsProp 122 loss=0.968672 err=0.968672
I 2015-05-26 07:21:03 theanets.trainer:168 RmsProp 123 loss=0.961862 err=0.961862
I 2015-05-26 07:21:16 theanets.trainer:168 RmsProp 124 loss=0.962362 err=0.962362
I 2015-05-26 07:21:28 theanets.trainer:168 RmsProp 125 loss=0.921595 err=0.921595
I 2015-05-26 07:21:41 theanets.trainer:168 RmsProp 126 loss=0.969230 err=0.969230
I 2015-05-26 07:21:54 theanets.trainer:168 RmsProp 127 loss=0.904850 err=0.904850
I 2015-05-26 07:22:06 theanets.trainer:168 RmsProp 128 loss=0.919111 err=0.919111
I 2015-05-26 07:22:19 theanets.trainer:168 RmsProp 129 loss=0.898707 err=0.898707
I 2015-05-26 07:22:32 theanets.trainer:168 RmsProp 130 loss=0.946504 err=0.946504
I 2015-05-26 07:22:32 theanets.trainer:168 validation 13 loss=841.385193 err=841.385193 *
I 2015-05-26 07:22:45 theanets.trainer:168 RmsProp 131 loss=0.910091 err=0.910091
I 2015-05-26 07:22:58 theanets.trainer:168 RmsProp 132 loss=0.910903 err=0.910903
I 2015-05-26 07:23:11 theanets.trainer:168 RmsProp 133 loss=0.900566 err=0.900566
I 2015-05-26 07:23:23 theanets.trainer:168 RmsProp 134 loss=0.835245 err=0.835245
I 2015-05-26 07:23:36 theanets.trainer:168 RmsProp 135 loss=0.961159 err=0.961159
I 2015-05-26 07:23:50 theanets.trainer:168 RmsProp 136 loss=0.913202 err=0.913202
I 2015-05-26 07:24:02 theanets.trainer:168 RmsProp 137 loss=0.819230 err=0.819230
I 2015-05-26 07:24:16 theanets.trainer:168 RmsProp 138 loss=0.858530 err=0.858530
I 2015-05-26 07:24:29 theanets.trainer:168 RmsProp 139 loss=0.872231 err=0.872231
I 2015-05-26 07:24:41 theanets.trainer:168 RmsProp 140 loss=0.841063 err=0.841063
I 2015-05-26 07:24:42 theanets.trainer:168 validation 14 loss=836.385742 err=836.385742 *
I 2015-05-26 07:24:54 theanets.trainer:168 RmsProp 141 loss=0.854797 err=0.854797
I 2015-05-26 07:25:07 theanets.trainer:168 RmsProp 142 loss=0.867952 err=0.867952
I 2015-05-26 07:25:19 theanets.trainer:168 RmsProp 143 loss=0.835066 err=0.835066
I 2015-05-26 07:25:31 theanets.trainer:168 RmsProp 144 loss=0.840354 err=0.840354
I 2015-05-26 07:25:43 theanets.trainer:168 RmsProp 145 loss=0.816636 err=0.816636
I 2015-05-26 07:25:56 theanets.trainer:168 RmsProp 146 loss=0.833164 err=0.833164
I 2015-05-26 07:26:08 theanets.trainer:168 RmsProp 147 loss=0.818124 err=0.818124
I 2015-05-26 07:26:20 theanets.trainer:168 RmsProp 148 loss=0.802535 err=0.802535
I 2015-05-26 07:26:32 theanets.trainer:168 RmsProp 149 loss=0.804690 err=0.804690
I 2015-05-26 07:26:44 theanets.trainer:168 RmsProp 150 loss=0.801990 err=0.801990
I 2015-05-26 07:26:44 theanets.trainer:168 validation 15 loss=833.349426 err=833.349426 *
I 2015-05-26 07:26:56 theanets.trainer:168 RmsProp 151 loss=0.782027 err=0.782027
I 2015-05-26 07:27:08 theanets.trainer:168 RmsProp 152 loss=0.789621 err=0.789621
I 2015-05-26 07:27:20 theanets.trainer:168 RmsProp 153 loss=0.787302 err=0.787302
I 2015-05-26 07:27:32 theanets.trainer:168 RmsProp 154 loss=0.787783 err=0.787783
I 2015-05-26 07:27:44 theanets.trainer:168 RmsProp 155 loss=0.752985 err=0.752985
I 2015-05-26 07:27:56 theanets.trainer:168 RmsProp 156 loss=0.812142 err=0.812142
I 2015-05-26 07:28:08 theanets.trainer:168 RmsProp 157 loss=0.791434 err=0.791434
I 2015-05-26 07:28:20 theanets.trainer:168 RmsProp 158 loss=0.771408 err=0.771408
I 2015-05-26 07:28:32 theanets.trainer:168 RmsProp 159 loss=0.746709 err=0.746709
I 2015-05-26 07:28:44 theanets.trainer:168 RmsProp 160 loss=0.771989 err=0.771989
I 2015-05-26 07:28:45 theanets.trainer:168 validation 16 loss=828.662415 err=828.662415 *
I 2015-05-26 07:28:57 theanets.trainer:168 RmsProp 161 loss=0.745972 err=0.745972
I 2015-05-26 07:29:08 theanets.trainer:168 RmsProp 162 loss=0.720850 err=0.720850
I 2015-05-26 07:29:20 theanets.trainer:168 RmsProp 163 loss=0.757215 err=0.757215
I 2015-05-26 07:29:32 theanets.trainer:168 RmsProp 164 loss=0.739838 err=0.739838
I 2015-05-26 07:29:44 theanets.trainer:168 RmsProp 165 loss=0.709660 err=0.709660
I 2015-05-26 07:29:56 theanets.trainer:168 RmsProp 166 loss=0.740867 err=0.740867
I 2015-05-26 07:30:09 theanets.trainer:168 RmsProp 167 loss=0.757811 err=0.757811
I 2015-05-26 07:30:21 theanets.trainer:168 RmsProp 168 loss=0.704116 err=0.704116
I 2015-05-26 07:30:32 theanets.trainer:168 RmsProp 169 loss=0.702140 err=0.702140
I 2015-05-26 07:30:44 theanets.trainer:168 RmsProp 170 loss=0.743050 err=0.743050
I 2015-05-26 07:30:45 theanets.trainer:168 validation 17 loss=828.658386 err=828.658386 *
I 2015-05-26 07:30:57 theanets.trainer:168 RmsProp 171 loss=0.721950 err=0.721950
I 2015-05-26 07:31:09 theanets.trainer:168 RmsProp 172 loss=0.693599 err=0.693599
I 2015-05-26 07:31:20 theanets.trainer:168 RmsProp 173 loss=0.699393 err=0.699393
I 2015-05-26 07:31:32 theanets.trainer:168 RmsProp 174 loss=0.737042 err=0.737042
I 2015-05-26 07:31:44 theanets.trainer:168 RmsProp 175 loss=0.708224 err=0.708224
I 2015-05-26 07:31:55 theanets.trainer:168 RmsProp 176 loss=0.663595 err=0.663595
I 2015-05-26 07:32:07 theanets.trainer:168 RmsProp 177 loss=0.695910 err=0.695910
I 2015-05-26 07:32:18 theanets.trainer:168 RmsProp 178 loss=0.676054 err=0.676054
I 2015-05-26 07:32:30 theanets.trainer:168 RmsProp 179 loss=0.707441 err=0.707441
I 2015-05-26 07:32:41 theanets.trainer:168 RmsProp 180 loss=0.657857 err=0.657857
I 2015-05-26 07:32:42 theanets.trainer:168 validation 18 loss=826.343872 err=826.343872 *
I 2015-05-26 07:32:53 theanets.trainer:168 RmsProp 181 loss=0.681530 err=0.681530
I 2015-05-26 07:33:04 theanets.trainer:168 RmsProp 182 loss=0.682039 err=0.682039
I 2015-05-26 07:33:16 theanets.trainer:168 RmsProp 183 loss=0.682316 err=0.682316
I 2015-05-26 07:33:28 theanets.trainer:168 RmsProp 184 loss=0.665969 err=0.665969
I 2015-05-26 07:33:40 theanets.trainer:168 RmsProp 185 loss=0.666185 err=0.666185
I 2015-05-26 07:33:52 theanets.trainer:168 RmsProp 186 loss=0.650354 err=0.650354
I 2015-05-26 07:34:04 theanets.trainer:168 RmsProp 187 loss=0.665546 err=0.665546
I 2015-05-26 07:34:16 theanets.trainer:168 RmsProp 188 loss=0.657206 err=0.657206
I 2015-05-26 07:34:27 theanets.trainer:168 RmsProp 189 loss=0.615474 err=0.615474
I 2015-05-26 07:34:39 theanets.trainer:168 RmsProp 190 loss=0.661988 err=0.661988
I 2015-05-26 07:34:40 theanets.trainer:168 validation 19 loss=823.212402 err=823.212402 *
I 2015-05-26 07:34:52 theanets.trainer:168 RmsProp 191 loss=0.658282 err=0.658282
I 2015-05-26 07:35:03 theanets.trainer:168 RmsProp 192 loss=0.640607 err=0.640607
I 2015-05-26 07:35:15 theanets.trainer:168 RmsProp 193 loss=0.627856 err=0.627856
I 2015-05-26 07:35:27 theanets.trainer:168 RmsProp 194 loss=0.637448 err=0.637448
I 2015-05-26 07:35:39 theanets.trainer:168 RmsProp 195 loss=0.617212 err=0.617212
I 2015-05-26 07:35:51 theanets.trainer:168 RmsProp 196 loss=0.598927 err=0.598927
I 2015-05-26 07:36:02 theanets.trainer:168 RmsProp 197 loss=0.701880 err=0.701880
I 2015-05-26 07:36:14 theanets.trainer:168 RmsProp 198 loss=0.646041 err=0.646041
I 2015-05-26 07:36:26 theanets.trainer:168 RmsProp 199 loss=0.574835 err=0.574835
I 2015-05-26 07:36:38 theanets.trainer:168 RmsProp 200 loss=0.627395 err=0.627395
I 2015-05-26 07:36:39 theanets.trainer:168 validation 20 loss=821.491028 err=821.491028 *
I 2015-05-26 07:36:50 theanets.trainer:168 RmsProp 201 loss=0.598390 err=0.598390
I 2015-05-26 07:37:02 theanets.trainer:168 RmsProp 202 loss=0.613312 err=0.613312
I 2015-05-26 07:37:14 theanets.trainer:168 RmsProp 203 loss=0.603318 err=0.603318
I 2015-05-26 07:37:26 theanets.trainer:168 RmsProp 204 loss=0.612711 err=0.612711
I 2015-05-26 07:37:38 theanets.trainer:168 RmsProp 205 loss=0.605787 err=0.605787
I 2015-05-26 07:37:50 theanets.trainer:168 RmsProp 206 loss=0.585413 err=0.585413
I 2015-05-26 07:38:02 theanets.trainer:168 RmsProp 207 loss=0.612992 err=0.612992
I 2015-05-26 07:38:14 theanets.trainer:168 RmsProp 208 loss=0.575587 err=0.575587
I 2015-05-26 07:38:26 theanets.trainer:168 RmsProp 209 loss=0.605620 err=0.605620
I 2015-05-26 07:38:38 theanets.trainer:168 RmsProp 210 loss=0.585198 err=0.585198
I 2015-05-26 07:38:38 theanets.trainer:168 validation 21 loss=816.599915 err=816.599915 *
I 2015-05-26 07:38:50 theanets.trainer:168 RmsProp 211 loss=0.587033 err=0.587033
I 2015-05-26 07:39:02 theanets.trainer:168 RmsProp 212 loss=0.600162 err=0.600162
I 2015-05-26 07:39:14 theanets.trainer:168 RmsProp 213 loss=0.563984 err=0.563984
I 2015-05-26 07:39:26 theanets.trainer:168 RmsProp 214 loss=0.587404 err=0.587404
I 2015-05-26 07:39:38 theanets.trainer:168 RmsProp 215 loss=0.563934 err=0.563934
I 2015-05-26 07:39:50 theanets.trainer:168 RmsProp 216 loss=0.569104 err=0.569104
I 2015-05-26 07:40:03 theanets.trainer:168 RmsProp 217 loss=0.576168 err=0.576168
I 2015-05-26 07:40:15 theanets.trainer:168 RmsProp 218 loss=0.582377 err=0.582377
I 2015-05-26 07:40:28 theanets.trainer:168 RmsProp 219 loss=0.541716 err=0.541716
I 2015-05-26 07:40:40 theanets.trainer:168 RmsProp 220 loss=0.561217 err=0.561217
I 2015-05-26 07:40:41 theanets.trainer:168 validation 22 loss=815.052429 err=815.052429 *
I 2015-05-26 07:40:53 theanets.trainer:168 RmsProp 221 loss=0.564894 err=0.564894
I 2015-05-26 07:41:05 theanets.trainer:168 RmsProp 222 loss=0.575683 err=0.575683
I 2015-05-26 07:41:17 theanets.trainer:168 RmsProp 223 loss=0.547601 err=0.547601
I 2015-05-26 07:41:30 theanets.trainer:168 RmsProp 224 loss=0.557112 err=0.557112
I 2015-05-26 07:41:42 theanets.trainer:168 RmsProp 225 loss=0.544156 err=0.544156
I 2015-05-26 07:41:54 theanets.trainer:168 RmsProp 226 loss=0.552213 err=0.552213
I 2015-05-26 07:42:07 theanets.trainer:168 RmsProp 227 loss=0.570631 err=0.570631
I 2015-05-26 07:42:19 theanets.trainer:168 RmsProp 228 loss=0.535542 err=0.535542
I 2015-05-26 07:42:31 theanets.trainer:168 RmsProp 229 loss=0.512833 err=0.512833
I 2015-05-26 07:42:43 theanets.trainer:168 RmsProp 230 loss=0.569450 err=0.569450
I 2015-05-26 07:42:43 theanets.trainer:168 validation 23 loss=812.366272 err=812.366272 *
I 2015-05-26 07:42:55 theanets.trainer:168 RmsProp 231 loss=0.548761 err=0.548761
I 2015-05-26 07:43:07 theanets.trainer:168 RmsProp 232 loss=0.521146 err=0.521146
I 2015-05-26 07:43:18 theanets.trainer:168 RmsProp 233 loss=0.521501 err=0.521501
I 2015-05-26 07:43:29 theanets.trainer:168 RmsProp 234 loss=0.556354 err=0.556354
I 2015-05-26 07:43:40 theanets.trainer:168 RmsProp 235 loss=0.519858 err=0.519858
I 2015-05-26 07:43:52 theanets.trainer:168 RmsProp 236 loss=0.519803 err=0.519803
I 2015-05-26 07:44:03 theanets.trainer:168 RmsProp 237 loss=0.530936 err=0.530936
I 2015-05-26 07:44:14 theanets.trainer:168 RmsProp 238 loss=0.516913 err=0.516913
I 2015-05-26 07:44:25 theanets.trainer:168 RmsProp 239 loss=0.513287 err=0.513287
I 2015-05-26 07:44:36 theanets.trainer:168 RmsProp 240 loss=0.535478 err=0.535478
I 2015-05-26 07:44:37 theanets.trainer:168 validation 24 loss=810.524109 err=810.524109 *
I 2015-05-26 07:44:48 theanets.trainer:168 RmsProp 241 loss=0.518045 err=0.518045
I 2015-05-26 07:44:59 theanets.trainer:168 RmsProp 242 loss=0.487330 err=0.487330
I 2015-05-26 07:45:10 theanets.trainer:168 RmsProp 243 loss=0.560257 err=0.560257
I 2015-05-26 07:45:21 theanets.trainer:168 RmsProp 244 loss=0.496269 err=0.496269
I 2015-05-26 07:45:32 theanets.trainer:168 RmsProp 245 loss=0.475271 err=0.475271
I 2015-05-26 07:45:43 theanets.trainer:168 RmsProp 246 loss=0.646113 err=0.646113
I 2015-05-26 07:45:54 theanets.trainer:168 RmsProp 247 loss=0.505262 err=0.505262
I 2015-05-26 07:46:06 theanets.trainer:168 RmsProp 248 loss=0.506801 err=0.506801
I 2015-05-26 07:46:17 theanets.trainer:168 RmsProp 249 loss=0.480452 err=0.480452
I 2015-05-26 07:46:28 theanets.trainer:168 RmsProp 250 loss=0.506853 err=0.506853
I 2015-05-26 07:46:29 theanets.trainer:168 validation 25 loss=809.870056 err=809.870056 *
I 2015-05-26 07:46:40 theanets.trainer:168 RmsProp 251 loss=0.496798 err=0.496798
I 2015-05-26 07:46:50 theanets.trainer:168 RmsProp 252 loss=0.477973 err=0.477973
I 2015-05-26 07:47:01 theanets.trainer:168 RmsProp 253 loss=0.492160 err=0.492160
I 2015-05-26 07:47:12 theanets.trainer:168 RmsProp 254 loss=0.495773 err=0.495773
I 2015-05-26 07:47:24 theanets.trainer:168 RmsProp 255 loss=0.513552 err=0.513552
I 2015-05-26 07:47:36 theanets.trainer:168 RmsProp 256 loss=0.468108 err=0.468108
I 2015-05-26 07:47:47 theanets.trainer:168 RmsProp 257 loss=0.491328 err=0.491328
I 2015-05-26 07:47:58 theanets.trainer:168 RmsProp 258 loss=0.486798 err=0.486798
I 2015-05-26 07:48:09 theanets.trainer:168 RmsProp 259 loss=0.467382 err=0.467382
I 2015-05-26 07:48:20 theanets.trainer:168 RmsProp 260 loss=0.516905 err=0.516905
I 2015-05-26 07:48:21 theanets.trainer:168 validation 26 loss=806.664978 err=806.664978 *
I 2015-05-26 07:48:31 theanets.trainer:168 RmsProp 261 loss=0.471965 err=0.471965
I 2015-05-26 07:48:42 theanets.trainer:168 RmsProp 262 loss=0.459200 err=0.459200
I 2015-05-26 07:48:53 theanets.trainer:168 RmsProp 263 loss=0.507179 err=0.507179
I 2015-05-26 07:49:03 theanets.trainer:168 RmsProp 264 loss=0.470341 err=0.470341
I 2015-05-26 07:49:14 theanets.trainer:168 RmsProp 265 loss=0.480066 err=0.480066
I 2015-05-26 07:49:25 theanets.trainer:168 RmsProp 266 loss=0.500307 err=0.500307
I 2015-05-26 07:49:35 theanets.trainer:168 RmsProp 267 loss=0.461875 err=0.461875
I 2015-05-26 07:49:46 theanets.trainer:168 RmsProp 268 loss=0.463158 err=0.463158
I 2015-05-26 07:49:56 theanets.trainer:168 RmsProp 269 loss=0.481493 err=0.481493
I 2015-05-26 07:50:07 theanets.trainer:168 RmsProp 270 loss=0.472801 err=0.472801
I 2015-05-26 07:50:07 theanets.trainer:168 validation 27 loss=805.152588 err=805.152588 *
I 2015-05-26 07:50:18 theanets.trainer:168 RmsProp 271 loss=0.451039 err=0.451039
I 2015-05-26 07:50:28 theanets.trainer:168 RmsProp 272 loss=0.490159 err=0.490159
I 2015-05-26 07:50:38 theanets.trainer:168 RmsProp 273 loss=0.459024 err=0.459024
I 2015-05-26 07:50:49 theanets.trainer:168 RmsProp 274 loss=0.456828 err=0.456828
I 2015-05-26 07:51:00 theanets.trainer:168 RmsProp 275 loss=0.465235 err=0.465235
I 2015-05-26 07:51:10 theanets.trainer:168 RmsProp 276 loss=0.477863 err=0.477863
I 2015-05-26 07:51:21 theanets.trainer:168 RmsProp 277 loss=0.454699 err=0.454699
I 2015-05-26 07:51:32 theanets.trainer:168 RmsProp 278 loss=0.440632 err=0.440632
I 2015-05-26 07:51:42 theanets.trainer:168 RmsProp 279 loss=0.476928 err=0.476928
I 2015-05-26 07:51:53 theanets.trainer:168 RmsProp 280 loss=0.548588 err=0.548588
I 2015-05-26 07:51:53 theanets.trainer:168 validation 28 loss=806.800415 err=806.800415
I 2015-05-26 07:52:04 theanets.trainer:168 RmsProp 281 loss=0.454044 err=0.454044
I 2015-05-26 07:52:15 theanets.trainer:168 RmsProp 282 loss=0.450067 err=0.450067
I 2015-05-26 07:52:26 theanets.trainer:168 RmsProp 283 loss=0.454561 err=0.454561
I 2015-05-26 07:52:37 theanets.trainer:168 RmsProp 284 loss=0.425892 err=0.425892
I 2015-05-26 07:52:48 theanets.trainer:168 RmsProp 285 loss=0.482052 err=0.482052
I 2015-05-26 07:52:59 theanets.trainer:168 RmsProp 286 loss=0.462489 err=0.462489
I 2015-05-26 07:53:10 theanets.trainer:168 RmsProp 287 loss=0.420737 err=0.420737
I 2015-05-26 07:53:21 theanets.trainer:168 RmsProp 288 loss=0.453467 err=0.453467
I 2015-05-26 07:53:32 theanets.trainer:168 RmsProp 289 loss=0.463066 err=0.463066
I 2015-05-26 07:53:43 theanets.trainer:168 RmsProp 290 loss=0.424222 err=0.424222
I 2015-05-26 07:53:43 theanets.trainer:168 validation 29 loss=802.321899 err=802.321899 *
I 2015-05-26 07:53:54 theanets.trainer:168 RmsProp 291 loss=0.399112 err=0.399112
I 2015-05-26 07:54:05 theanets.trainer:168 RmsProp 292 loss=0.517413 err=0.517413
I 2015-05-26 07:54:16 theanets.trainer:168 RmsProp 293 loss=0.481087 err=0.481087
I 2015-05-26 07:54:27 theanets.trainer:168 RmsProp 294 loss=0.426640 err=0.426640
I 2015-05-26 07:54:38 theanets.trainer:168 RmsProp 295 loss=0.417156 err=0.417156
I 2015-05-26 07:54:49 theanets.trainer:168 RmsProp 296 loss=0.423060 err=0.423060
I 2015-05-26 07:54:59 theanets.trainer:168 RmsProp 297 loss=0.438552 err=0.438552
I 2015-05-26 07:55:10 theanets.trainer:168 RmsProp 298 loss=0.405720 err=0.405720
I 2015-05-26 07:55:21 theanets.trainer:168 RmsProp 299 loss=0.427633 err=0.427633
I 2015-05-26 07:55:32 theanets.trainer:168 RmsProp 300 loss=0.423630 err=0.423630
I 2015-05-26 07:55:33 theanets.trainer:168 validation 30 loss=800.585632 err=800.585632 *
I 2015-05-26 07:55:43 theanets.trainer:168 RmsProp 301 loss=0.423591 err=0.423591
I 2015-05-26 07:55:54 theanets.trainer:168 RmsProp 302 loss=0.430903 err=0.430903
I 2015-05-26 07:56:04 theanets.trainer:168 RmsProp 303 loss=0.429135 err=0.429135
I 2015-05-26 07:56:16 theanets.trainer:168 RmsProp 304 loss=0.411294 err=0.411294
I 2015-05-26 07:56:27 theanets.trainer:168 RmsProp 305 loss=0.407961 err=0.407961
I 2015-05-26 07:56:38 theanets.trainer:168 RmsProp 306 loss=0.450969 err=0.450969
I 2015-05-26 07:56:49 theanets.trainer:168 RmsProp 307 loss=0.389914 err=0.389914
I 2015-05-26 07:57:00 theanets.trainer:168 RmsProp 308 loss=0.464067 err=0.464067
I 2015-05-26 07:57:11 theanets.trainer:168 RmsProp 309 loss=0.436124 err=0.436124
I 2015-05-26 07:57:23 theanets.trainer:168 RmsProp 310 loss=0.408225 err=0.408225
I 2015-05-26 07:57:23 theanets.trainer:168 validation 31 loss=800.141418 err=800.141418 *
I 2015-05-26 07:57:35 theanets.trainer:168 RmsProp 311 loss=0.404145 err=0.404145
I 2015-05-26 07:57:46 theanets.trainer:168 RmsProp 312 loss=0.414298 err=0.414298
I 2015-05-26 07:57:57 theanets.trainer:168 RmsProp 313 loss=0.446481 err=0.446481
I 2015-05-26 07:58:09 theanets.trainer:168 RmsProp 314 loss=0.410459 err=0.410459
I 2015-05-26 07:58:20 theanets.trainer:168 RmsProp 315 loss=0.384560 err=0.384560
I 2015-05-26 07:58:30 theanets.trainer:168 RmsProp 316 loss=0.418232 err=0.418232
I 2015-05-26 07:58:41 theanets.trainer:168 RmsProp 317 loss=0.409125 err=0.409125
I 2015-05-26 07:58:52 theanets.trainer:168 RmsProp 318 loss=0.400072 err=0.400072
I 2015-05-26 07:59:03 theanets.trainer:168 RmsProp 319 loss=0.385068 err=0.385068
I 2015-05-26 07:59:13 theanets.trainer:168 RmsProp 320 loss=0.431668 err=0.431668
I 2015-05-26 07:59:14 theanets.trainer:168 validation 32 loss=798.447876 err=798.447876 *
I 2015-05-26 07:59:25 theanets.trainer:168 RmsProp 321 loss=0.404218 err=0.404218
I 2015-05-26 07:59:35 theanets.trainer:168 RmsProp 322 loss=0.382385 err=0.382385
I 2015-05-26 07:59:46 theanets.trainer:168 RmsProp 323 loss=0.392427 err=0.392427
I 2015-05-26 07:59:57 theanets.trainer:168 RmsProp 324 loss=0.379528 err=0.379528
I 2015-05-26 08:00:08 theanets.trainer:168 RmsProp 325 loss=0.409262 err=0.409262
I 2015-05-26 08:00:19 theanets.trainer:168 RmsProp 326 loss=0.425869 err=0.425869
I 2015-05-26 08:00:31 theanets.trainer:168 RmsProp 327 loss=0.371719 err=0.371719
I 2015-05-26 08:00:42 theanets.trainer:168 RmsProp 328 loss=0.401744 err=0.401744
I 2015-05-26 08:00:53 theanets.trainer:168 RmsProp 329 loss=0.385922 err=0.385922
I 2015-05-26 08:01:05 theanets.trainer:168 RmsProp 330 loss=0.390651 err=0.390651
I 2015-05-26 08:01:06 theanets.trainer:168 validation 33 loss=797.711731 err=797.711731 *
I 2015-05-26 08:01:17 theanets.trainer:168 RmsProp 331 loss=0.415095 err=0.415095
I 2015-05-26 08:01:28 theanets.trainer:168 RmsProp 332 loss=0.428631 err=0.428631
I 2015-05-26 08:01:39 theanets.trainer:168 RmsProp 333 loss=0.365593 err=0.365593
I 2015-05-26 08:01:49 theanets.trainer:168 RmsProp 334 loss=0.386009 err=0.386009
I 2015-05-26 08:02:00 theanets.trainer:168 RmsProp 335 loss=0.378412 err=0.378412
I 2015-05-26 08:02:10 theanets.trainer:168 RmsProp 336 loss=0.403336 err=0.403336
I 2015-05-26 08:02:20 theanets.trainer:168 RmsProp 337 loss=0.372265 err=0.372265
I 2015-05-26 08:02:30 theanets.trainer:168 RmsProp 338 loss=0.383738 err=0.383738
I 2015-05-26 08:02:41 theanets.trainer:168 RmsProp 339 loss=0.398986 err=0.398986
I 2015-05-26 08:02:51 theanets.trainer:168 RmsProp 340 loss=0.369793 err=0.369793
I 2015-05-26 08:02:52 theanets.trainer:168 validation 34 loss=793.673645 err=793.673645 *
I 2015-05-26 08:03:02 theanets.trainer:168 RmsProp 341 loss=0.366211 err=0.366211
I 2015-05-26 08:03:13 theanets.trainer:168 RmsProp 342 loss=0.399546 err=0.399546
I 2015-05-26 08:03:23 theanets.trainer:168 RmsProp 343 loss=0.367513 err=0.367513
I 2015-05-26 08:03:33 theanets.trainer:168 RmsProp 344 loss=0.352818 err=0.352818
I 2015-05-26 08:03:43 theanets.trainer:168 RmsProp 345 loss=0.380226 err=0.380226
I 2015-05-26 08:03:54 theanets.trainer:168 RmsProp 346 loss=0.383241 err=0.383241
I 2015-05-26 08:04:04 theanets.trainer:168 RmsProp 347 loss=0.390410 err=0.390410
I 2015-05-26 08:04:14 theanets.trainer:168 RmsProp 348 loss=0.387897 err=0.387897
I 2015-05-26 08:04:24 theanets.trainer:168 RmsProp 349 loss=0.364953 err=0.364953
I 2015-05-26 08:04:35 theanets.trainer:168 RmsProp 350 loss=0.372297 err=0.372297
I 2015-05-26 08:04:35 theanets.trainer:168 validation 35 loss=793.090759 err=793.090759 *
I 2015-05-26 08:04:45 theanets.trainer:168 RmsProp 351 loss=0.351628 err=0.351628
I 2015-05-26 08:04:56 theanets.trainer:168 RmsProp 352 loss=0.378357 err=0.378357
I 2015-05-26 08:05:06 theanets.trainer:168 RmsProp 353 loss=0.350927 err=0.350927
I 2015-05-26 08:05:17 theanets.trainer:168 RmsProp 354 loss=0.402773 err=0.402773
I 2015-05-26 08:05:27 theanets.trainer:168 RmsProp 355 loss=0.366948 err=0.366948
I 2015-05-26 08:05:37 theanets.trainer:168 RmsProp 356 loss=0.351567 err=0.351567
I 2015-05-26 08:05:47 theanets.trainer:168 RmsProp 357 loss=0.355205 err=0.355205
I 2015-05-26 08:05:57 theanets.trainer:168 RmsProp 358 loss=0.377057 err=0.377057
I 2015-05-26 08:06:08 theanets.trainer:168 RmsProp 359 loss=0.355593 err=0.355593
I 2015-05-26 08:06:18 theanets.trainer:168 RmsProp 360 loss=0.360274 err=0.360274
I 2015-05-26 08:06:18 theanets.trainer:168 validation 36 loss=792.097839 err=792.097839 *
I 2015-05-26 08:06:28 theanets.trainer:168 RmsProp 361 loss=0.372889 err=0.372889
I 2015-05-26 08:06:39 theanets.trainer:168 RmsProp 362 loss=0.349655 err=0.349655
I 2015-05-26 08:06:49 theanets.trainer:168 RmsProp 363 loss=0.374184 err=0.374184
I 2015-05-26 08:07:00 theanets.trainer:168 RmsProp 364 loss=0.378969 err=0.378969
I 2015-05-26 08:07:10 theanets.trainer:168 RmsProp 365 loss=0.345086 err=0.345086
I 2015-05-26 08:07:20 theanets.trainer:168 RmsProp 366 loss=0.344881 err=0.344881
I 2015-05-26 08:07:30 theanets.trainer:168 RmsProp 367 loss=0.350008 err=0.350008
I 2015-05-26 08:07:40 theanets.trainer:168 RmsProp 368 loss=0.382390 err=0.382390
I 2015-05-26 08:07:50 theanets.trainer:168 RmsProp 369 loss=0.337045 err=0.337045
I 2015-05-26 08:08:01 theanets.trainer:168 RmsProp 370 loss=0.329432 err=0.329432
I 2015-05-26 08:08:01 theanets.trainer:168 validation 37 loss=789.584595 err=789.584595 *
I 2015-05-26 08:08:11 theanets.trainer:168 RmsProp 371 loss=0.387833 err=0.387833
I 2015-05-26 08:08:21 theanets.trainer:168 RmsProp 372 loss=0.354487 err=0.354487
I 2015-05-26 08:08:31 theanets.trainer:168 RmsProp 373 loss=0.328370 err=0.328370
I 2015-05-26 08:08:42 theanets.trainer:168 RmsProp 374 loss=0.372681 err=0.372681
I 2015-05-26 08:08:52 theanets.trainer:168 RmsProp 375 loss=0.336662 err=0.336662
I 2015-05-26 08:09:02 theanets.trainer:168 RmsProp 376 loss=0.382868 err=0.382868
I 2015-05-26 08:09:12 theanets.trainer:168 RmsProp 377 loss=0.336540 err=0.336540
I 2015-05-26 08:09:23 theanets.trainer:168 RmsProp 378 loss=0.360275 err=0.360275
I 2015-05-26 08:09:33 theanets.trainer:168 RmsProp 379 loss=0.341260 err=0.341260
I 2015-05-26 08:09:44 theanets.trainer:168 RmsProp 380 loss=0.342314 err=0.342314
I 2015-05-26 08:09:44 theanets.trainer:168 validation 38 loss=789.817627 err=789.817627
I 2015-05-26 08:09:55 theanets.trainer:168 RmsProp 381 loss=0.344036 err=0.344036
I 2015-05-26 08:10:05 theanets.trainer:168 RmsProp 382 loss=0.341143 err=0.341143
I 2015-05-26 08:10:16 theanets.trainer:168 RmsProp 383 loss=0.324159 err=0.324159
I 2015-05-26 08:10:26 theanets.trainer:168 RmsProp 384 loss=0.358782 err=0.358782
I 2015-05-26 08:10:37 theanets.trainer:168 RmsProp 385 loss=0.318543 err=0.318543
I 2015-05-26 08:10:48 theanets.trainer:168 RmsProp 386 loss=0.380815 err=0.380815
I 2015-05-26 08:10:58 theanets.trainer:168 RmsProp 387 loss=0.344105 err=0.344105
I 2015-05-26 08:11:09 theanets.trainer:168 RmsProp 388 loss=0.323865 err=0.323865
I 2015-05-26 08:11:19 theanets.trainer:168 RmsProp 389 loss=0.339998 err=0.339998
I 2015-05-26 08:11:29 theanets.trainer:168 RmsProp 390 loss=0.326989 err=0.326989
I 2015-05-26 08:11:30 theanets.trainer:168 validation 39 loss=788.872131 err=788.872131 *
I 2015-05-26 08:11:40 theanets.trainer:168 RmsProp 391 loss=0.331231 err=0.331231
I 2015-05-26 08:11:50 theanets.trainer:168 RmsProp 392 loss=0.322711 err=0.322711
I 2015-05-26 08:12:00 theanets.trainer:168 RmsProp 393 loss=0.328583 err=0.328583
I 2015-05-26 08:12:10 theanets.trainer:168 RmsProp 394 loss=0.352521 err=0.352521
I 2015-05-26 08:12:20 theanets.trainer:168 RmsProp 395 loss=0.337365 err=0.337365
I 2015-05-26 08:12:31 theanets.trainer:168 RmsProp 396 loss=0.325335 err=0.325335
I 2015-05-26 08:12:41 theanets.trainer:168 RmsProp 397 loss=0.361721 err=0.361721
I 2015-05-26 08:12:52 theanets.trainer:168 RmsProp 398 loss=0.372862 err=0.372862
I 2015-05-26 08:13:02 theanets.trainer:168 RmsProp 399 loss=0.329316 err=0.329316
I 2015-05-26 08:13:13 theanets.trainer:168 RmsProp 400 loss=0.319355 err=0.319355
I 2015-05-26 08:13:14 theanets.trainer:168 validation 40 loss=787.336121 err=787.336121 *
I 2015-05-26 08:13:24 theanets.trainer:168 RmsProp 401 loss=0.291327 err=0.291327
I 2015-05-26 08:13:35 theanets.trainer:168 RmsProp 402 loss=0.385155 err=0.385155
I 2015-05-26 08:13:46 theanets.trainer:168 RmsProp 403 loss=0.332076 err=0.332076
I 2015-05-26 08:13:56 theanets.trainer:168 RmsProp 404 loss=0.318056 err=0.318056
I 2015-05-26 08:14:06 theanets.trainer:168 RmsProp 405 loss=0.344909 err=0.344909
I 2015-05-26 08:14:16 theanets.trainer:168 RmsProp 406 loss=0.322009 err=0.322009
I 2015-05-26 08:14:26 theanets.trainer:168 RmsProp 407 loss=0.295979 err=0.295979
I 2015-05-26 08:14:37 theanets.trainer:168 RmsProp 408 loss=0.375737 err=0.375737
I 2015-05-26 08:14:47 theanets.trainer:168 RmsProp 409 loss=0.300728 err=0.300728
I 2015-05-26 08:14:57 theanets.trainer:168 RmsProp 410 loss=0.319257 err=0.319257
I 2015-05-26 08:14:58 theanets.trainer:168 validation 41 loss=788.377380 err=788.377380
I 2015-05-26 08:15:08 theanets.trainer:168 RmsProp 411 loss=0.330318 err=0.330318
I 2015-05-26 08:15:18 theanets.trainer:168 RmsProp 412 loss=0.307231 err=0.307231
I 2015-05-26 08:15:28 theanets.trainer:168 RmsProp 413 loss=0.302819 err=0.302819
I 2015-05-26 08:15:39 theanets.trainer:168 RmsProp 414 loss=0.386363 err=0.386363
I 2015-05-26 08:15:49 theanets.trainer:168 RmsProp 415 loss=0.308365 err=0.308365
I 2015-05-26 08:15:59 theanets.trainer:168 RmsProp 416 loss=0.274473 err=0.274473
I 2015-05-26 08:16:09 theanets.trainer:168 RmsProp 417 loss=0.433108 err=0.433108
I 2015-05-26 08:16:20 theanets.trainer:168 RmsProp 418 loss=0.338473 err=0.338473
I 2015-05-26 08:16:30 theanets.trainer:168 RmsProp 419 loss=0.292757 err=0.292757
I 2015-05-26 08:16:40 theanets.trainer:168 RmsProp 420 loss=0.296563 err=0.296563
I 2015-05-26 08:16:41 theanets.trainer:168 validation 42 loss=786.052734 err=786.052734 *
I 2015-05-26 08:16:51 theanets.trainer:168 RmsProp 421 loss=0.309536 err=0.309536
I 2015-05-26 08:17:01 theanets.trainer:168 RmsProp 422 loss=0.320532 err=0.320532
I 2015-05-26 08:17:12 theanets.trainer:168 RmsProp 423 loss=0.308673 err=0.308673
I 2015-05-26 08:17:22 theanets.trainer:168 RmsProp 424 loss=0.301155 err=0.301155
I 2015-05-26 08:17:32 theanets.trainer:168 RmsProp 425 loss=0.320148 err=0.320148
I 2015-05-26 08:17:42 theanets.trainer:168 RmsProp 426 loss=0.302103 err=0.302103
I 2015-05-26 08:17:52 theanets.trainer:168 RmsProp 427 loss=0.309002 err=0.309002
I 2015-05-26 08:18:03 theanets.trainer:168 RmsProp 428 loss=0.310005 err=0.310005
I 2015-05-26 08:18:13 theanets.trainer:168 RmsProp 429 loss=0.294104 err=0.294104
I 2015-05-26 08:18:24 theanets.trainer:168 RmsProp 430 loss=0.310992 err=0.310992
I 2015-05-26 08:18:24 theanets.trainer:168 validation 43 loss=784.791504 err=784.791504 *
I 2015-05-26 08:18:34 theanets.trainer:168 RmsProp 431 loss=0.300751 err=0.300751
I 2015-05-26 08:18:44 theanets.trainer:168 RmsProp 432 loss=0.320277 err=0.320277
I 2015-05-26 08:18:55 theanets.trainer:168 RmsProp 433 loss=0.291960 err=0.291960
I 2015-05-26 08:19:05 theanets.trainer:168 RmsProp 434 loss=0.306489 err=0.306489
I 2015-05-26 08:19:16 theanets.trainer:168 RmsProp 435 loss=0.301293 err=0.301293
I 2015-05-26 08:19:27 theanets.trainer:168 RmsProp 436 loss=0.306978 err=0.306978
I 2015-05-26 08:19:37 theanets.trainer:168 RmsProp 437 loss=0.329304 err=0.329304
I 2015-05-26 08:19:48 theanets.trainer:168 RmsProp 438 loss=0.306645 err=0.306645
I 2015-05-26 08:19:58 theanets.trainer:168 RmsProp 439 loss=0.275222 err=0.275222
I 2015-05-26 08:20:09 theanets.trainer:168 RmsProp 440 loss=0.370552 err=0.370552
I 2015-05-26 08:20:09 theanets.trainer:168 validation 44 loss=782.709900 err=782.709900 *
I 2015-05-26 08:20:19 theanets.trainer:168 RmsProp 441 loss=0.320111 err=0.320111
I 2015-05-26 08:20:30 theanets.trainer:168 RmsProp 442 loss=0.270330 err=0.270330
I 2015-05-26 08:20:40 theanets.trainer:168 RmsProp 443 loss=0.309438 err=0.309438
I 2015-05-26 08:20:51 theanets.trainer:168 RmsProp 444 loss=0.291896 err=0.291896
I 2015-05-26 08:21:01 theanets.trainer:168 RmsProp 445 loss=0.326699 err=0.326699
I 2015-05-26 08:21:11 theanets.trainer:168 RmsProp 446 loss=0.298563 err=0.298563
I 2015-05-26 08:21:22 theanets.trainer:168 RmsProp 447 loss=0.271028 err=0.271028
I 2015-05-26 08:21:32 theanets.trainer:168 RmsProp 448 loss=0.324214 err=0.324214
I 2015-05-26 08:21:42 theanets.trainer:168 RmsProp 449 loss=0.315641 err=0.315641
I 2015-05-26 08:21:53 theanets.trainer:168 RmsProp 450 loss=0.291648 err=0.291648
I 2015-05-26 08:21:53 theanets.trainer:168 validation 45 loss=780.895813 err=780.895813 *
I 2015-05-26 08:22:04 theanets.trainer:168 RmsProp 451 loss=0.296285 err=0.296285
I 2015-05-26 08:22:14 theanets.trainer:168 RmsProp 452 loss=0.270088 err=0.270088
I 2015-05-26 08:22:24 theanets.trainer:168 RmsProp 453 loss=0.302238 err=0.302238
I 2015-05-26 08:22:35 theanets.trainer:168 RmsProp 454 loss=0.295562 err=0.295562
I 2015-05-26 08:22:45 theanets.trainer:168 RmsProp 455 loss=0.298387 err=0.298387
I 2015-05-26 08:22:56 theanets.trainer:168 RmsProp 456 loss=0.285996 err=0.285996
I 2015-05-26 08:23:06 theanets.trainer:168 RmsProp 457 loss=0.286980 err=0.286980
I 2015-05-26 08:23:17 theanets.trainer:168 RmsProp 458 loss=0.294908 err=0.294908
I 2015-05-26 08:23:27 theanets.trainer:168 RmsProp 459 loss=0.307819 err=0.307819
I 2015-05-26 08:23:38 theanets.trainer:168 RmsProp 460 loss=0.257985 err=0.257985
I 2015-05-26 08:23:38 theanets.trainer:168 validation 46 loss=778.723572 err=778.723572 *
I 2015-05-26 08:23:48 theanets.trainer:168 RmsProp 461 loss=0.369917 err=0.369917
I 2015-05-26 08:23:59 theanets.trainer:168 RmsProp 462 loss=0.281177 err=0.281177
I 2015-05-26 08:24:09 theanets.trainer:168 RmsProp 463 loss=0.283108 err=0.283108
I 2015-05-26 08:24:19 theanets.trainer:168 RmsProp 464 loss=0.297849 err=0.297849
I 2015-05-26 08:24:30 theanets.trainer:168 RmsProp 465 loss=0.292821 err=0.292821
I 2015-05-26 08:24:40 theanets.trainer:168 RmsProp 466 loss=0.294160 err=0.294160
I 2015-05-26 08:24:51 theanets.trainer:168 RmsProp 467 loss=0.277959 err=0.277959
I 2015-05-26 08:25:02 theanets.trainer:168 RmsProp 468 loss=0.286176 err=0.286176
I 2015-05-26 08:25:12 theanets.trainer:168 RmsProp 469 loss=0.250053 err=0.250053
I 2015-05-26 08:25:23 theanets.trainer:168 RmsProp 470 loss=0.336106 err=0.336106
I 2015-05-26 08:25:23 theanets.trainer:168 validation 47 loss=778.912537 err=778.912537
I 2015-05-26 08:25:34 theanets.trainer:168 RmsProp 471 loss=0.447973 err=0.447973
I 2015-05-26 08:25:44 theanets.trainer:168 RmsProp 472 loss=0.291048 err=0.291048
I 2015-05-26 08:25:54 theanets.trainer:168 RmsProp 473 loss=0.255408 err=0.255408
I 2015-05-26 08:26:05 theanets.trainer:168 RmsProp 474 loss=0.259200 err=0.259200
I 2015-05-26 08:26:16 theanets.trainer:168 RmsProp 475 loss=0.328208 err=0.328208
I 2015-05-26 08:26:26 theanets.trainer:168 RmsProp 476 loss=0.287382 err=0.287382
I 2015-05-26 08:26:37 theanets.trainer:168 RmsProp 477 loss=0.276112 err=0.276112
I 2015-05-26 08:26:47 theanets.trainer:168 RmsProp 478 loss=0.287175 err=0.287175
I 2015-05-26 08:26:58 theanets.trainer:168 RmsProp 479 loss=0.252604 err=0.252604
I 2015-05-26 08:27:09 theanets.trainer:168 RmsProp 480 loss=0.294678 err=0.294678
I 2015-05-26 08:27:09 theanets.trainer:168 validation 48 loss=778.290466 err=778.290466 *
I 2015-05-26 08:27:20 theanets.trainer:168 RmsProp 481 loss=0.276449 err=0.276449
I 2015-05-26 08:27:31 theanets.trainer:168 RmsProp 482 loss=0.292354 err=0.292354
I 2015-05-26 08:27:42 theanets.trainer:168 RmsProp 483 loss=0.279108 err=0.279108
I 2015-05-26 08:27:52 theanets.trainer:168 RmsProp 484 loss=0.277988 err=0.277988
I 2015-05-26 08:28:03 theanets.trainer:168 RmsProp 485 loss=0.290212 err=0.290212
I 2015-05-26 08:28:13 theanets.trainer:168 RmsProp 486 loss=0.293121 err=0.293121
I 2015-05-26 08:28:23 theanets.trainer:168 RmsProp 487 loss=0.272299 err=0.272299
I 2015-05-26 08:28:34 theanets.trainer:168 RmsProp 488 loss=0.283441 err=0.283441
I 2015-05-26 08:28:44 theanets.trainer:168 RmsProp 489 loss=0.282441 err=0.282441
I 2015-05-26 08:28:55 theanets.trainer:168 RmsProp 490 loss=0.268528 err=0.268528
I 2015-05-26 08:28:56 theanets.trainer:168 validation 49 loss=776.675476 err=776.675476 *
I 2015-05-26 08:29:06 theanets.trainer:168 RmsProp 491 loss=0.268759 err=0.268759
I 2015-05-26 08:29:16 theanets.trainer:168 RmsProp 492 loss=0.269622 err=0.269622
I 2015-05-26 08:29:27 theanets.trainer:168 RmsProp 493 loss=0.272273 err=0.272273
I 2015-05-26 08:29:37 theanets.trainer:168 RmsProp 494 loss=0.273835 err=0.273835
I 2015-05-26 08:29:48 theanets.trainer:168 RmsProp 495 loss=0.259617 err=0.259617
I 2015-05-26 08:29:58 theanets.trainer:168 RmsProp 496 loss=0.317601 err=0.317601
I 2015-05-26 08:30:09 theanets.trainer:168 RmsProp 497 loss=0.282494 err=0.282494
I 2015-05-26 08:30:19 theanets.trainer:168 RmsProp 498 loss=0.280015 err=0.280015
I 2015-05-26 08:30:30 theanets.trainer:168 RmsProp 499 loss=0.258452 err=0.258452
I 2015-05-26 08:30:41 theanets.trainer:168 RmsProp 500 loss=0.261156 err=0.261156
I 2015-05-26 08:30:42 theanets.trainer:168 validation 50 loss=775.389832 err=775.389832 *
I 2015-05-26 08:30:52 theanets.trainer:168 RmsProp 501 loss=0.305018 err=0.305018
I 2015-05-26 08:31:03 theanets.trainer:168 RmsProp 502 loss=0.286212 err=0.286212
I 2015-05-26 08:31:14 theanets.trainer:168 RmsProp 503 loss=0.243089 err=0.243089
I 2015-05-26 08:31:24 theanets.trainer:168 RmsProp 504 loss=0.274707 err=0.274707
I 2015-05-26 08:31:34 theanets.trainer:168 RmsProp 505 loss=0.276703 err=0.276703
I 2015-05-26 08:31:44 theanets.trainer:168 RmsProp 506 loss=0.264219 err=0.264219
I 2015-05-26 08:31:54 theanets.trainer:168 RmsProp 507 loss=0.276338 err=0.276338
I 2015-05-26 08:32:04 theanets.trainer:168 RmsProp 508 loss=0.255669 err=0.255669
I 2015-05-26 08:32:14 theanets.trainer:168 RmsProp 509 loss=0.266321 err=0.266321
I 2015-05-26 08:32:24 theanets.trainer:168 RmsProp 510 loss=0.256950 err=0.256950
I 2015-05-26 08:32:24 theanets.trainer:168 validation 51 loss=774.135864 err=774.135864 *
I 2015-05-26 08:32:34 theanets.trainer:168 RmsProp 511 loss=0.273649 err=0.273649
I 2015-05-26 08:32:44 theanets.trainer:168 RmsProp 512 loss=0.260262 err=0.260262
I 2015-05-26 08:32:54 theanets.trainer:168 RmsProp 513 loss=0.247555 err=0.247555
I 2015-05-26 08:33:04 theanets.trainer:168 RmsProp 514 loss=0.270257 err=0.270257
I 2015-05-26 08:33:14 theanets.trainer:168 RmsProp 515 loss=0.257494 err=0.257494
I 2015-05-26 08:33:24 theanets.trainer:168 RmsProp 516 loss=0.261608 err=0.261608
I 2015-05-26 08:33:34 theanets.trainer:168 RmsProp 517 loss=0.268185 err=0.268185
I 2015-05-26 08:33:44 theanets.trainer:168 RmsProp 518 loss=0.251988 err=0.251988
I 2015-05-26 08:33:54 theanets.trainer:168 RmsProp 519 loss=0.261861 err=0.261861
I 2015-05-26 08:34:04 theanets.trainer:168 RmsProp 520 loss=0.274874 err=0.274874
I 2015-05-26 08:34:05 theanets.trainer:168 validation 52 loss=774.030884 err=774.030884 *
I 2015-05-26 08:34:15 theanets.trainer:168 RmsProp 521 loss=0.265832 err=0.265832
I 2015-05-26 08:34:25 theanets.trainer:168 RmsProp 522 loss=0.256508 err=0.256508
I 2015-05-26 08:34:35 theanets.trainer:168 RmsProp 523 loss=0.247765 err=0.247765
I 2015-05-26 08:34:45 theanets.trainer:168 RmsProp 524 loss=0.241256 err=0.241256
I 2015-05-26 08:34:55 theanets.trainer:168 RmsProp 525 loss=0.319078 err=0.319078
I 2015-05-26 08:35:06 theanets.trainer:168 RmsProp 526 loss=0.248371 err=0.248371
I 2015-05-26 08:35:16 theanets.trainer:168 RmsProp 527 loss=0.222294 err=0.222294
I 2015-05-26 08:35:26 theanets.trainer:168 RmsProp 528 loss=0.294341 err=0.294341
I 2015-05-26 08:35:37 theanets.trainer:168 RmsProp 529 loss=0.250613 err=0.250613
I 2015-05-26 08:35:47 theanets.trainer:168 RmsProp 530 loss=0.243378 err=0.243378
I 2015-05-26 08:35:47 theanets.trainer:168 validation 53 loss=773.208923 err=773.208923 *
I 2015-05-26 08:35:57 theanets.trainer:168 RmsProp 531 loss=0.265111 err=0.265111
I 2015-05-26 08:36:07 theanets.trainer:168 RmsProp 532 loss=0.257936 err=0.257936
I 2015-05-26 08:36:17 theanets.trainer:168 RmsProp 533 loss=0.245515 err=0.245515
I 2015-05-26 08:36:27 theanets.trainer:168 RmsProp 534 loss=0.252947 err=0.252947
I 2015-05-26 08:36:37 theanets.trainer:168 RmsProp 535 loss=0.235087 err=0.235087
I 2015-05-26 08:36:47 theanets.trainer:168 RmsProp 536 loss=0.264827 err=0.264827
I 2015-05-26 08:36:57 theanets.trainer:168 RmsProp 537 loss=0.241777 err=0.241777
I 2015-05-26 08:37:07 theanets.trainer:168 RmsProp 538 loss=0.292681 err=0.292681
I 2015-05-26 08:37:17 theanets.trainer:168 RmsProp 539 loss=0.261977 err=0.261977
I 2015-05-26 08:37:27 theanets.trainer:168 RmsProp 540 loss=0.242489 err=0.242489
I 2015-05-26 08:37:27 theanets.trainer:168 validation 54 loss=772.645813 err=772.645813 *
I 2015-05-26 08:37:37 theanets.trainer:168 RmsProp 541 loss=0.250395 err=0.250395
I 2015-05-26 08:37:47 theanets.trainer:168 RmsProp 542 loss=0.251697 err=0.251697
I 2015-05-26 08:37:56 theanets.trainer:168 RmsProp 543 loss=0.242375 err=0.242375
I 2015-05-26 08:38:06 theanets.trainer:168 RmsProp 544 loss=0.276902 err=0.276902
I 2015-05-26 08:38:16 theanets.trainer:168 RmsProp 545 loss=0.234891 err=0.234891
I 2015-05-26 08:38:26 theanets.trainer:168 RmsProp 546 loss=0.253535 err=0.253535
I 2015-05-26 08:38:36 theanets.trainer:168 RmsProp 547 loss=0.252562 err=0.252562
I 2015-05-26 08:38:46 theanets.trainer:168 RmsProp 548 loss=0.226739 err=0.226739
I 2015-05-26 08:38:56 theanets.trainer:168 RmsProp 549 loss=0.296556 err=0.296556
I 2015-05-26 08:39:06 theanets.trainer:168 RmsProp 550 loss=0.257322 err=0.257322
I 2015-05-26 08:39:07 theanets.trainer:168 validation 55 loss=772.335144 err=772.335144 *
I 2015-05-26 08:39:17 theanets.trainer:168 RmsProp 551 loss=0.226080 err=0.226080
I 2015-05-26 08:39:26 theanets.trainer:168 RmsProp 552 loss=0.251500 err=0.251500
I 2015-05-26 08:39:36 theanets.trainer:168 RmsProp 553 loss=0.258897 err=0.258897
I 2015-05-26 08:39:46 theanets.trainer:168 RmsProp 554 loss=0.236106 err=0.236106
I 2015-05-26 08:39:56 theanets.trainer:168 RmsProp 555 loss=0.245483 err=0.245483
I 2015-05-26 08:40:06 theanets.trainer:168 RmsProp 556 loss=0.223422 err=0.223422
I 2015-05-26 08:40:16 theanets.trainer:168 RmsProp 557 loss=0.276647 err=0.276647
I 2015-05-26 08:40:26 theanets.trainer:168 RmsProp 558 loss=0.242997 err=0.242997
I 2015-05-26 08:40:36 theanets.trainer:168 RmsProp 559 loss=0.260117 err=0.260117
I 2015-05-26 08:40:46 theanets.trainer:168 RmsProp 560 loss=0.248591 err=0.248591
I 2015-05-26 08:40:47 theanets.trainer:168 validation 56 loss=770.402283 err=770.402283 *
I 2015-05-26 08:40:56 theanets.trainer:168 RmsProp 561 loss=0.252461 err=0.252461
I 2015-05-26 08:41:06 theanets.trainer:168 RmsProp 562 loss=0.222485 err=0.222485
I 2015-05-26 08:41:15 theanets.trainer:168 RmsProp 563 loss=0.273249 err=0.273249
I 2015-05-26 08:41:25 theanets.trainer:168 RmsProp 564 loss=0.238896 err=0.238896
I 2015-05-26 08:41:35 theanets.trainer:168 RmsProp 565 loss=0.242900 err=0.242900
I 2015-05-26 08:41:45 theanets.trainer:168 RmsProp 566 loss=0.242070 err=0.242070
I 2015-05-26 08:41:55 theanets.trainer:168 RmsProp 567 loss=0.225804 err=0.225804
I 2015-05-26 08:42:05 theanets.trainer:168 RmsProp 568 loss=0.253515 err=0.253515
I 2015-05-26 08:42:15 theanets.trainer:168 RmsProp 569 loss=0.235539 err=0.235539
I 2015-05-26 08:42:26 theanets.trainer:168 RmsProp 570 loss=0.233924 err=0.233924
I 2015-05-26 08:42:26 theanets.trainer:168 validation 57 loss=768.082336 err=768.082336 *
I 2015-05-26 08:42:36 theanets.trainer:168 RmsProp 571 loss=0.255652 err=0.255652
I 2015-05-26 08:42:46 theanets.trainer:168 RmsProp 572 loss=0.258579 err=0.258579
I 2015-05-26 08:42:56 theanets.trainer:168 RmsProp 573 loss=0.250378 err=0.250378
I 2015-05-26 08:43:06 theanets.trainer:168 RmsProp 574 loss=0.211798 err=0.211798
I 2015-05-26 08:43:16 theanets.trainer:168 RmsProp 575 loss=0.281642 err=0.281642
I 2015-05-26 08:43:26 theanets.trainer:168 RmsProp 576 loss=0.256692 err=0.256692
I 2015-05-26 08:43:36 theanets.trainer:168 RmsProp 577 loss=0.218011 err=0.218011
I 2015-05-26 08:43:46 theanets.trainer:168 RmsProp 578 loss=0.256387 err=0.256387
I 2015-05-26 08:43:55 theanets.trainer:168 RmsProp 579 loss=0.236201 err=0.236201
I 2015-05-26 08:44:05 theanets.trainer:168 RmsProp 580 loss=0.227137 err=0.227137
I 2015-05-26 08:44:05 theanets.trainer:168 validation 58 loss=768.773376 err=768.773376
I 2015-05-26 08:44:15 theanets.trainer:168 RmsProp 581 loss=0.247528 err=0.247528
I 2015-05-26 08:44:25 theanets.trainer:168 RmsProp 582 loss=0.228637 err=0.228637
I 2015-05-26 08:44:35 theanets.trainer:168 RmsProp 583 loss=0.226651 err=0.226651
I 2015-05-26 08:44:45 theanets.trainer:168 RmsProp 584 loss=0.257029 err=0.257029
I 2015-05-26 08:44:54 theanets.trainer:168 RmsProp 585 loss=0.230056 err=0.230056
I 2015-05-26 08:45:04 theanets.trainer:168 RmsProp 586 loss=0.224493 err=0.224493
I 2015-05-26 08:45:14 theanets.trainer:168 RmsProp 587 loss=0.258217 err=0.258217
I 2015-05-26 08:45:24 theanets.trainer:168 RmsProp 588 loss=0.240160 err=0.240160
I 2015-05-26 08:45:34 theanets.trainer:168 RmsProp 589 loss=0.225892 err=0.225892
I 2015-05-26 08:45:44 theanets.trainer:168 RmsProp 590 loss=0.231213 err=0.231213
I 2015-05-26 08:45:44 theanets.trainer:168 validation 59 loss=768.368652 err=768.368652
I 2015-05-26 08:45:54 theanets.trainer:168 RmsProp 591 loss=0.245897 err=0.245897
I 2015-05-26 08:46:03 theanets.trainer:168 RmsProp 592 loss=0.219326 err=0.219326
I 2015-05-26 08:46:12 theanets.trainer:168 RmsProp 593 loss=0.232846 err=0.232846
I 2015-05-26 08:46:21 theanets.trainer:168 RmsProp 594 loss=0.243953 err=0.243953
I 2015-05-26 08:46:30 theanets.trainer:168 RmsProp 595 loss=0.224816 err=0.224816
I 2015-05-26 08:46:39 theanets.trainer:168 RmsProp 596 loss=0.222643 err=0.222643
I 2015-05-26 08:46:47 theanets.trainer:168 RmsProp 597 loss=0.254274 err=0.254274
I 2015-05-26 08:46:56 theanets.trainer:168 RmsProp 598 loss=0.246147 err=0.246147
I 2015-05-26 08:47:05 theanets.trainer:168 RmsProp 599 loss=0.232216 err=0.232216
I 2015-05-26 08:47:14 theanets.trainer:168 RmsProp 600 loss=0.223191 err=0.223191
I 2015-05-26 08:47:14 theanets.trainer:168 validation 60 loss=767.568726 err=767.568726 *
I 2015-05-26 08:47:23 theanets.trainer:168 RmsProp 601 loss=0.229166 err=0.229166
I 2015-05-26 08:47:31 theanets.trainer:168 RmsProp 602 loss=0.224500 err=0.224500
I 2015-05-26 08:47:40 theanets.trainer:168 RmsProp 603 loss=0.221520 err=0.221520
I 2015-05-26 08:47:49 theanets.trainer:168 RmsProp 604 loss=0.229693 err=0.229693
I 2015-05-26 08:47:57 theanets.trainer:168 RmsProp 605 loss=0.229053 err=0.229053
I 2015-05-26 08:48:06 theanets.trainer:168 RmsProp 606 loss=0.239381 err=0.239381
I 2015-05-26 08:48:15 theanets.trainer:168 RmsProp 607 loss=0.245163 err=0.245163
I 2015-05-26 08:48:24 theanets.trainer:168 RmsProp 608 loss=0.248944 err=0.248944
I 2015-05-26 08:48:33 theanets.trainer:168 RmsProp 609 loss=0.219944 err=0.219944
I 2015-05-26 08:48:41 theanets.trainer:168 RmsProp 610 loss=0.237544 err=0.237544
I 2015-05-26 08:48:42 theanets.trainer:168 validation 61 loss=765.894348 err=765.894348 *
I 2015-05-26 08:48:51 theanets.trainer:168 RmsProp 611 loss=0.215604 err=0.215604
I 2015-05-26 08:49:00 theanets.trainer:168 RmsProp 612 loss=0.252823 err=0.252823
I 2015-05-26 08:49:08 theanets.trainer:168 RmsProp 613 loss=0.224909 err=0.224909
I 2015-05-26 08:49:17 theanets.trainer:168 RmsProp 614 loss=0.207787 err=0.207787
I 2015-05-26 08:49:26 theanets.trainer:168 RmsProp 615 loss=0.236547 err=0.236547
I 2015-05-26 08:49:34 theanets.trainer:168 RmsProp 616 loss=0.235366 err=0.235366
I 2015-05-26 08:49:43 theanets.trainer:168 RmsProp 617 loss=0.214151 err=0.214151
I 2015-05-26 08:49:52 theanets.trainer:168 RmsProp 618 loss=0.229483 err=0.229483
I 2015-05-26 08:50:00 theanets.trainer:168 RmsProp 619 loss=0.214974 err=0.214974
I 2015-05-26 08:50:09 theanets.trainer:168 RmsProp 620 loss=0.231701 err=0.231701
I 2015-05-26 08:50:09 theanets.trainer:168 validation 62 loss=766.342590 err=766.342590
I 2015-05-26 08:50:18 theanets.trainer:168 RmsProp 621 loss=0.223562 err=0.223562
I 2015-05-26 08:50:26 theanets.trainer:168 RmsProp 622 loss=0.228147 err=0.228147
I 2015-05-26 08:50:35 theanets.trainer:168 RmsProp 623 loss=0.221285 err=0.221285
I 2015-05-26 08:50:44 theanets.trainer:168 RmsProp 624 loss=0.231392 err=0.231392
I 2015-05-26 08:50:52 theanets.trainer:168 RmsProp 625 loss=0.213974 err=0.213974
I 2015-05-26 08:51:00 theanets.trainer:168 RmsProp 626 loss=0.224472 err=0.224472
I 2015-05-26 08:51:08 theanets.trainer:168 RmsProp 627 loss=0.232501 err=0.232501
I 2015-05-26 08:51:16 theanets.trainer:168 RmsProp 628 loss=0.211586 err=0.211586
I 2015-05-26 08:51:24 theanets.trainer:168 RmsProp 629 loss=0.220091 err=0.220091
I 2015-05-26 08:51:33 theanets.trainer:168 RmsProp 630 loss=0.226982 err=0.226982
I 2015-05-26 08:51:33 theanets.trainer:168 validation 63 loss=764.310181 err=764.310181 *
I 2015-05-26 08:51:41 theanets.trainer:168 RmsProp 631 loss=0.223110 err=0.223110
I 2015-05-26 08:51:49 theanets.trainer:168 RmsProp 632 loss=0.227138 err=0.227138
I 2015-05-26 08:51:57 theanets.trainer:168 RmsProp 633 loss=0.215079 err=0.215079
I 2015-05-26 08:52:05 theanets.trainer:168 RmsProp 634 loss=0.221307 err=0.221307
I 2015-05-26 08:52:13 theanets.trainer:168 RmsProp 635 loss=0.207352 err=0.207352
I 2015-05-26 08:52:21 theanets.trainer:168 RmsProp 636 loss=0.219975 err=0.219975
I 2015-05-26 08:52:29 theanets.trainer:168 RmsProp 637 loss=0.233632 err=0.233632
I 2015-05-26 08:52:37 theanets.trainer:168 RmsProp 638 loss=0.213922 err=0.213922
I 2015-05-26 08:52:45 theanets.trainer:168 RmsProp 639 loss=0.213864 err=0.213864
I 2015-05-26 08:52:53 theanets.trainer:168 RmsProp 640 loss=0.204371 err=0.204371
I 2015-05-26 08:52:53 theanets.trainer:168 validation 64 loss=764.908142 err=764.908142
I 2015-05-26 08:53:01 theanets.trainer:168 RmsProp 641 loss=0.241498 err=0.241498
I 2015-05-26 08:53:09 theanets.trainer:168 RmsProp 642 loss=0.218976 err=0.218976
I 2015-05-26 08:53:17 theanets.trainer:168 RmsProp 643 loss=0.219263 err=0.219263
I 2015-05-26 08:53:25 theanets.trainer:168 RmsProp 644 loss=0.223173 err=0.223173
I 2015-05-26 08:53:33 theanets.trainer:168 RmsProp 645 loss=0.212845 err=0.212845
I 2015-05-26 08:53:41 theanets.trainer:168 RmsProp 646 loss=0.181080 err=0.181080
I 2015-05-26 08:53:50 theanets.trainer:168 RmsProp 647 loss=0.324941 err=0.324941
I 2015-05-26 08:53:58 theanets.trainer:168 RmsProp 648 loss=0.255036 err=0.255036
I 2015-05-26 08:54:06 theanets.trainer:168 RmsProp 649 loss=0.197475 err=0.197475
I 2015-05-26 08:54:13 theanets.trainer:168 RmsProp 650 loss=0.200298 err=0.200298
I 2015-05-26 08:54:13 theanets.trainer:168 validation 65 loss=764.239197 err=764.239197 *
I 2015-05-26 08:54:21 theanets.trainer:168 RmsProp 651 loss=0.225216 err=0.225216
I 2015-05-26 08:54:28 theanets.trainer:168 RmsProp 652 loss=0.212143 err=0.212143
I 2015-05-26 08:54:36 theanets.trainer:168 RmsProp 653 loss=0.217416 err=0.217416
I 2015-05-26 08:54:44 theanets.trainer:168 RmsProp 654 loss=0.206652 err=0.206652
I 2015-05-26 08:54:52 theanets.trainer:168 RmsProp 655 loss=0.197009 err=0.197009
I 2015-05-26 08:55:00 theanets.trainer:168 RmsProp 656 loss=0.243286 err=0.243286
I 2015-05-26 08:55:07 theanets.trainer:168 RmsProp 657 loss=0.221414 err=0.221414
I 2015-05-26 08:55:15 theanets.trainer:168 RmsProp 658 loss=0.204167 err=0.204167
I 2015-05-26 08:55:22 theanets.trainer:168 RmsProp 659 loss=0.196537 err=0.196537
I 2015-05-26 08:55:30 theanets.trainer:168 RmsProp 660 loss=0.237947 err=0.237947
I 2015-05-26 08:55:31 theanets.trainer:168 validation 66 loss=763.107239 err=763.107239 *
I 2015-05-26 08:55:38 theanets.trainer:168 RmsProp 661 loss=0.196700 err=0.196700
I 2015-05-26 08:55:46 theanets.trainer:168 RmsProp 662 loss=0.210623 err=0.210623
I 2015-05-26 08:55:53 theanets.trainer:168 RmsProp 663 loss=0.204904 err=0.204904
I 2015-05-26 08:56:00 theanets.trainer:168 RmsProp 664 loss=0.215810 err=0.215810
I 2015-05-26 08:56:08 theanets.trainer:168 RmsProp 665 loss=0.193335 err=0.193335
I 2015-05-26 08:56:15 theanets.trainer:168 RmsProp 666 loss=0.239622 err=0.239622
I 2015-05-26 08:56:23 theanets.trainer:168 RmsProp 667 loss=0.213976 err=0.213976
I 2015-05-26 08:56:31 theanets.trainer:168 RmsProp 668 loss=0.210964 err=0.210964
I 2015-05-26 08:56:40 theanets.trainer:168 RmsProp 669 loss=0.201255 err=0.201255
I 2015-05-26 08:56:48 theanets.trainer:168 RmsProp 670 loss=0.229763 err=0.229763
I 2015-05-26 08:56:48 theanets.trainer:168 validation 67 loss=762.386414 err=762.386414 *
I 2015-05-26 08:56:56 theanets.trainer:168 RmsProp 671 loss=0.208301 err=0.208301
I 2015-05-26 08:57:03 theanets.trainer:168 RmsProp 672 loss=0.209579 err=0.209579
I 2015-05-26 08:57:10 theanets.trainer:168 RmsProp 673 loss=0.208199 err=0.208199
I 2015-05-26 08:57:18 theanets.trainer:168 RmsProp 674 loss=0.194283 err=0.194283
I 2015-05-26 08:57:26 theanets.trainer:168 RmsProp 675 loss=0.220830 err=0.220830
I 2015-05-26 08:57:34 theanets.trainer:168 RmsProp 676 loss=0.197200 err=0.197200
I 2015-05-26 08:57:41 theanets.trainer:168 RmsProp 677 loss=0.212751 err=0.212751
I 2015-05-26 08:57:49 theanets.trainer:168 RmsProp 678 loss=0.234655 err=0.234655
I 2015-05-26 08:57:57 theanets.trainer:168 RmsProp 679 loss=0.202916 err=0.202916
I 2015-05-26 08:58:04 theanets.trainer:168 RmsProp 680 loss=0.190937 err=0.190937
I 2015-05-26 08:58:04 theanets.trainer:168 validation 68 loss=762.419373 err=762.419373
I 2015-05-26 08:58:12 theanets.trainer:168 RmsProp 681 loss=0.208908 err=0.208908
I 2015-05-26 08:58:19 theanets.trainer:168 RmsProp 682 loss=0.197682 err=0.197682
I 2015-05-26 08:58:26 theanets.trainer:168 RmsProp 683 loss=0.222725 err=0.222725
I 2015-05-26 08:58:35 theanets.trainer:168 RmsProp 684 loss=0.242231 err=0.242231
I 2015-05-26 08:58:43 theanets.trainer:168 RmsProp 685 loss=0.195985 err=0.195985
I 2015-05-26 08:58:51 theanets.trainer:168 RmsProp 686 loss=0.208695 err=0.208695
I 2015-05-26 08:58:58 theanets.trainer:168 RmsProp 687 loss=0.210292 err=0.210292
I 2015-05-26 08:59:06 theanets.trainer:168 RmsProp 688 loss=0.210168 err=0.210168
I 2015-05-26 08:59:14 theanets.trainer:168 RmsProp 689 loss=0.211007 err=0.211007
I 2015-05-26 08:59:23 theanets.trainer:168 RmsProp 690 loss=0.205454 err=0.205454
I 2015-05-26 08:59:23 theanets.trainer:168 validation 69 loss=761.519165 err=761.519165 *
I 2015-05-26 08:59:30 theanets.trainer:168 RmsProp 691 loss=0.186906 err=0.186906
I 2015-05-26 08:59:37 theanets.trainer:168 RmsProp 692 loss=0.224945 err=0.224945
I 2015-05-26 08:59:45 theanets.trainer:168 RmsProp 693 loss=0.192270 err=0.192270
I 2015-05-26 08:59:53 theanets.trainer:168 RmsProp 694 loss=0.206296 err=0.206296
I 2015-05-26 09:00:01 theanets.trainer:168 RmsProp 695 loss=0.192658 err=0.192658
I 2015-05-26 09:00:09 theanets.trainer:168 RmsProp 696 loss=0.208567 err=0.208567
I 2015-05-26 09:00:17 theanets.trainer:168 RmsProp 697 loss=0.204385 err=0.204385
I 2015-05-26 09:00:25 theanets.trainer:168 RmsProp 698 loss=0.200538 err=0.200538
I 2015-05-26 09:00:32 theanets.trainer:168 RmsProp 699 loss=0.216476 err=0.216476
I 2015-05-26 09:00:40 theanets.trainer:168 RmsProp 700 loss=0.191886 err=0.191886
I 2015-05-26 09:00:40 theanets.trainer:168 validation 70 loss=759.756958 err=759.756958 *
I 2015-05-26 09:00:48 theanets.trainer:168 RmsProp 701 loss=0.202678 err=0.202678
I 2015-05-26 09:00:56 theanets.trainer:168 RmsProp 702 loss=0.206218 err=0.206218
I 2015-05-26 09:01:04 theanets.trainer:168 RmsProp 703 loss=0.193328 err=0.193328
I 2015-05-26 09:01:12 theanets.trainer:168 RmsProp 704 loss=0.203877 err=0.203877
I 2015-05-26 09:01:20 theanets.trainer:168 RmsProp 705 loss=0.195598 err=0.195598
I 2015-05-26 09:01:28 theanets.trainer:168 RmsProp 706 loss=0.200185 err=0.200185
I 2015-05-26 09:01:35 theanets.trainer:168 RmsProp 707 loss=0.196042 err=0.196042
I 2015-05-26 09:01:43 theanets.trainer:168 RmsProp 708 loss=0.199814 err=0.199814
I 2015-05-26 09:01:51 theanets.trainer:168 RmsProp 709 loss=0.177569 err=0.177569
I 2015-05-26 09:01:59 theanets.trainer:168 RmsProp 710 loss=0.204560 err=0.204560
I 2015-05-26 09:02:00 theanets.trainer:168 validation 71 loss=759.075134 err=759.075134 *
I 2015-05-26 09:02:07 theanets.trainer:168 RmsProp 711 loss=0.200874 err=0.200874
I 2015-05-26 09:02:14 theanets.trainer:168 RmsProp 712 loss=0.194596 err=0.194596
I 2015-05-26 09:02:21 theanets.trainer:168 RmsProp 713 loss=0.213238 err=0.213238
I 2015-05-26 09:02:28 theanets.trainer:168 RmsProp 714 loss=0.197801 err=0.197801
I 2015-05-26 09:02:36 theanets.trainer:168 RmsProp 715 loss=0.189668 err=0.189668
I 2015-05-26 09:02:44 theanets.trainer:168 RmsProp 716 loss=0.190206 err=0.190206
I 2015-05-26 09:02:52 theanets.trainer:168 RmsProp 717 loss=0.202167 err=0.202167
I 2015-05-26 09:03:00 theanets.trainer:168 RmsProp 718 loss=0.202946 err=0.202946
I 2015-05-26 09:03:08 theanets.trainer:168 RmsProp 719 loss=0.212179 err=0.212179
I 2015-05-26 09:03:15 theanets.trainer:168 RmsProp 720 loss=0.198235 err=0.198235
I 2015-05-26 09:03:16 theanets.trainer:168 validation 72 loss=758.137329 err=758.137329 *
I 2015-05-26 09:03:23 theanets.trainer:168 RmsProp 721 loss=0.196194 err=0.196194
I 2015-05-26 09:03:31 theanets.trainer:168 RmsProp 722 loss=0.195153 err=0.195153
I 2015-05-26 09:03:39 theanets.trainer:168 RmsProp 723 loss=0.179219 err=0.179219
I 2015-05-26 09:03:47 theanets.trainer:168 RmsProp 724 loss=0.199990 err=0.199990
I 2015-05-26 09:03:54 theanets.trainer:168 RmsProp 725 loss=0.193674 err=0.193674
I 2015-05-26 09:04:02 theanets.trainer:168 RmsProp 726 loss=0.206463 err=0.206463
I 2015-05-26 09:04:10 theanets.trainer:168 RmsProp 727 loss=0.187960 err=0.187960
I 2015-05-26 09:04:18 theanets.trainer:168 RmsProp 728 loss=0.192606 err=0.192606
I 2015-05-26 09:04:26 theanets.trainer:168 RmsProp 729 loss=0.198012 err=0.198012
I 2015-05-26 09:04:33 theanets.trainer:168 RmsProp 730 loss=0.184981 err=0.184981
I 2015-05-26 09:04:34 theanets.trainer:168 validation 73 loss=759.979492 err=759.979492
I 2015-05-26 09:04:41 theanets.trainer:168 RmsProp 731 loss=0.199106 err=0.199106
I 2015-05-26 09:04:49 theanets.trainer:168 RmsProp 732 loss=0.188418 err=0.188418
I 2015-05-26 09:04:56 theanets.trainer:168 RmsProp 733 loss=0.191794 err=0.191794
I 2015-05-26 09:05:04 theanets.trainer:168 RmsProp 734 loss=0.193638 err=0.193638
I 2015-05-26 09:05:12 theanets.trainer:168 RmsProp 735 loss=0.187648 err=0.187648
I 2015-05-26 09:05:20 theanets.trainer:168 RmsProp 736 loss=0.207347 err=0.207347
I 2015-05-26 09:05:28 theanets.trainer:168 RmsProp 737 loss=0.201254 err=0.201254
I 2015-05-26 09:05:35 theanets.trainer:168 RmsProp 738 loss=0.209448 err=0.209448
I 2015-05-26 09:05:43 theanets.trainer:168 RmsProp 739 loss=0.175678 err=0.175678
I 2015-05-26 09:05:50 theanets.trainer:168 RmsProp 740 loss=0.197918 err=0.197918
I 2015-05-26 09:05:51 theanets.trainer:168 validation 74 loss=756.949402 err=756.949402 *
I 2015-05-26 09:05:58 theanets.trainer:168 RmsProp 741 loss=0.190891 err=0.190891
I 2015-05-26 09:06:06 theanets.trainer:168 RmsProp 742 loss=0.189917 err=0.189917
I 2015-05-26 09:06:14 theanets.trainer:168 RmsProp 743 loss=0.197471 err=0.197471
I 2015-05-26 09:06:22 theanets.trainer:168 RmsProp 744 loss=0.199086 err=0.199086
I 2015-05-26 09:06:30 theanets.trainer:168 RmsProp 745 loss=0.190349 err=0.190349
I 2015-05-26 09:06:38 theanets.trainer:168 RmsProp 746 loss=0.183984 err=0.183984
I 2015-05-26 09:06:46 theanets.trainer:168 RmsProp 747 loss=0.206948 err=0.206948
I 2015-05-26 09:06:54 theanets.trainer:168 RmsProp 748 loss=0.185597 err=0.185597
I 2015-05-26 09:07:03 theanets.trainer:168 RmsProp 749 loss=0.183676 err=0.183676
I 2015-05-26 09:07:10 theanets.trainer:168 RmsProp 750 loss=0.194323 err=0.194323
I 2015-05-26 09:07:11 theanets.trainer:168 validation 75 loss=755.882996 err=755.882996 *
I 2015-05-26 09:07:18 theanets.trainer:168 RmsProp 751 loss=0.183536 err=0.183536
I 2015-05-26 09:07:26 theanets.trainer:168 RmsProp 752 loss=0.182943 err=0.182943
I 2015-05-26 09:07:33 theanets.trainer:168 RmsProp 753 loss=0.191254 err=0.191254
I 2015-05-26 09:07:41 theanets.trainer:168 RmsProp 754 loss=0.176139 err=0.176139
I 2015-05-26 09:07:49 theanets.trainer:168 RmsProp 755 loss=0.192978 err=0.192978
I 2015-05-26 09:07:57 theanets.trainer:168 RmsProp 756 loss=0.188827 err=0.188827
I 2015-05-26 09:08:05 theanets.trainer:168 RmsProp 757 loss=0.180461 err=0.180461
I 2015-05-26 09:08:13 theanets.trainer:168 RmsProp 758 loss=0.196790 err=0.196790
I 2015-05-26 09:08:20 theanets.trainer:168 RmsProp 759 loss=0.184222 err=0.184222
I 2015-05-26 09:08:28 theanets.trainer:168 RmsProp 760 loss=0.177475 err=0.177475
I 2015-05-26 09:08:28 theanets.trainer:168 validation 76 loss=756.223083 err=756.223083
I 2015-05-26 09:08:36 theanets.trainer:168 RmsProp 761 loss=0.184839 err=0.184839
I 2015-05-26 09:08:43 theanets.trainer:168 RmsProp 762 loss=0.202938 err=0.202938
I 2015-05-26 09:08:51 theanets.trainer:168 RmsProp 763 loss=0.187157 err=0.187157
I 2015-05-26 09:08:59 theanets.trainer:168 RmsProp 764 loss=0.185237 err=0.185237
I 2015-05-26 09:09:06 theanets.trainer:168 RmsProp 765 loss=0.179041 err=0.179041
I 2015-05-26 09:09:13 theanets.trainer:168 RmsProp 766 loss=0.198252 err=0.198252
I 2015-05-26 09:09:21 theanets.trainer:168 RmsProp 767 loss=0.186349 err=0.186349
I 2015-05-26 09:09:29 theanets.trainer:168 RmsProp 768 loss=0.192088 err=0.192088
I 2015-05-26 09:09:37 theanets.trainer:168 RmsProp 769 loss=0.178384 err=0.178384
I 2015-05-26 09:09:45 theanets.trainer:168 RmsProp 770 loss=0.187280 err=0.187280
I 2015-05-26 09:09:45 theanets.trainer:168 validation 77 loss=754.113220 err=754.113220 *
I 2015-05-26 09:09:52 theanets.trainer:168 RmsProp 771 loss=0.184633 err=0.184633
I 2015-05-26 09:10:00 theanets.trainer:168 RmsProp 772 loss=0.200413 err=0.200413
I 2015-05-26 09:10:08 theanets.trainer:168 RmsProp 773 loss=0.176098 err=0.176098
I 2015-05-26 09:10:16 theanets.trainer:168 RmsProp 774 loss=0.182586 err=0.182586
I 2015-05-26 09:10:23 theanets.trainer:168 RmsProp 775 loss=0.179405 err=0.179405
I 2015-05-26 09:10:32 theanets.trainer:168 RmsProp 776 loss=0.183112 err=0.183112
I 2015-05-26 09:10:40 theanets.trainer:168 RmsProp 777 loss=0.181546 err=0.181546
I 2015-05-26 09:10:48 theanets.trainer:168 RmsProp 778 loss=0.183317 err=0.183317
I 2015-05-26 09:10:56 theanets.trainer:168 RmsProp 779 loss=0.186545 err=0.186545
I 2015-05-26 09:11:04 theanets.trainer:168 RmsProp 780 loss=0.186787 err=0.186787
I 2015-05-26 09:11:04 theanets.trainer:168 validation 78 loss=754.725769 err=754.725769
I 2015-05-26 09:11:11 theanets.trainer:168 RmsProp 781 loss=0.187521 err=0.187521
I 2015-05-26 09:11:18 theanets.trainer:168 RmsProp 782 loss=0.174243 err=0.174243
I 2015-05-26 09:11:25 theanets.trainer:168 RmsProp 783 loss=0.193955 err=0.193955
I 2015-05-26 09:11:32 theanets.trainer:168 RmsProp 784 loss=0.173604 err=0.173604
I 2015-05-26 09:11:40 theanets.trainer:168 RmsProp 785 loss=0.172507 err=0.172507
I 2015-05-26 09:11:47 theanets.trainer:168 RmsProp 786 loss=0.178184 err=0.178184
I 2015-05-26 09:11:54 theanets.trainer:168 RmsProp 787 loss=0.191313 err=0.191313
I 2015-05-26 09:12:02 theanets.trainer:168 RmsProp 788 loss=0.169580 err=0.169580
I 2015-05-26 09:12:09 theanets.trainer:168 RmsProp 789 loss=0.195020 err=0.195020
I 2015-05-26 09:12:17 theanets.trainer:168 RmsProp 790 loss=0.170699 err=0.170699
I 2015-05-26 09:12:18 theanets.trainer:168 validation 79 loss=754.047546 err=754.047546 *
I 2015-05-26 09:12:25 theanets.trainer:168 RmsProp 791 loss=0.178109 err=0.178109
I 2015-05-26 09:12:33 theanets.trainer:168 RmsProp 792 loss=0.165651 err=0.165651
I 2015-05-26 09:12:41 theanets.trainer:168 RmsProp 793 loss=0.202608 err=0.202608
I 2015-05-26 09:12:48 theanets.trainer:168 RmsProp 794 loss=0.176547 err=0.176547
I 2015-05-26 09:12:55 theanets.trainer:168 RmsProp 795 loss=0.179879 err=0.179879
I 2015-05-26 09:13:03 theanets.trainer:168 RmsProp 796 loss=0.168270 err=0.168270
I 2015-05-26 09:13:11 theanets.trainer:168 RmsProp 797 loss=0.176127 err=0.176127
I 2015-05-26 09:13:19 theanets.trainer:168 RmsProp 798 loss=0.206218 err=0.206218
I 2015-05-26 09:13:26 theanets.trainer:168 RmsProp 799 loss=0.166652 err=0.166652
I 2015-05-26 09:13:34 theanets.trainer:168 RmsProp 800 loss=0.171655 err=0.171655
I 2015-05-26 09:13:35 theanets.trainer:168 validation 80 loss=754.410278 err=754.410278
I 2015-05-26 09:13:41 theanets.trainer:168 RmsProp 801 loss=0.198370 err=0.198370
I 2015-05-26 09:13:48 theanets.trainer:168 RmsProp 802 loss=0.157092 err=0.157092
I 2015-05-26 09:13:55 theanets.trainer:168 RmsProp 803 loss=0.187726 err=0.187726
I 2015-05-26 09:14:02 theanets.trainer:168 RmsProp 804 loss=0.177785 err=0.177785
I 2015-05-26 09:14:09 theanets.trainer:168 RmsProp 805 loss=0.179191 err=0.179191
I 2015-05-26 09:14:16 theanets.trainer:168 RmsProp 806 loss=0.175639 err=0.175639
I 2015-05-26 09:14:23 theanets.trainer:168 RmsProp 807 loss=0.176422 err=0.176422
I 2015-05-26 09:14:31 theanets.trainer:168 RmsProp 808 loss=0.169290 err=0.169290
I 2015-05-26 09:14:39 theanets.trainer:168 RmsProp 809 loss=0.175660 err=0.175660
I 2015-05-26 09:14:46 theanets.trainer:168 RmsProp 810 loss=0.182695 err=0.182695
I 2015-05-26 09:14:46 theanets.trainer:168 validation 81 loss=753.192810 err=753.192810 *
I 2015-05-26 09:14:53 theanets.trainer:168 RmsProp 811 loss=0.185114 err=0.185114
I 2015-05-26 09:15:01 theanets.trainer:168 RmsProp 812 loss=0.153166 err=0.153166
I 2015-05-26 09:15:09 theanets.trainer:168 RmsProp 813 loss=0.250876 err=0.250876
I 2015-05-26 09:15:17 theanets.trainer:168 RmsProp 814 loss=0.213020 err=0.213020
I 2015-05-26 09:15:25 theanets.trainer:168 RmsProp 815 loss=0.163635 err=0.163635
I 2015-05-26 09:15:32 theanets.trainer:168 RmsProp 816 loss=0.164604 err=0.164604
I 2015-05-26 09:15:39 theanets.trainer:168 RmsProp 817 loss=0.176166 err=0.176166
I 2015-05-26 09:15:46 theanets.trainer:168 RmsProp 818 loss=0.191720 err=0.191720
I 2015-05-26 09:15:53 theanets.trainer:168 RmsProp 819 loss=0.203792 err=0.203792
I 2015-05-26 09:16:00 theanets.trainer:168 RmsProp 820 loss=0.165901 err=0.165901
I 2015-05-26 09:16:01 theanets.trainer:168 validation 82 loss=752.220642 err=752.220642 *
I 2015-05-26 09:16:07 theanets.trainer:168 RmsProp 821 loss=0.185121 err=0.185121
I 2015-05-26 09:16:15 theanets.trainer:168 RmsProp 822 loss=0.159978 err=0.159978
I 2015-05-26 09:16:22 theanets.trainer:168 RmsProp 823 loss=0.198684 err=0.198684
I 2015-05-26 09:16:29 theanets.trainer:168 RmsProp 824 loss=0.181268 err=0.181268
I 2015-05-26 09:16:37 theanets.trainer:168 RmsProp 825 loss=0.157559 err=0.157559
I 2015-05-26 09:16:45 theanets.trainer:168 RmsProp 826 loss=0.190428 err=0.190428
I 2015-05-26 09:16:53 theanets.trainer:168 RmsProp 827 loss=0.178691 err=0.178691
I 2015-05-26 09:17:00 theanets.trainer:168 RmsProp 828 loss=0.161656 err=0.161656
I 2015-05-26 09:17:08 theanets.trainer:168 RmsProp 829 loss=0.175663 err=0.175663
I 2015-05-26 09:17:16 theanets.trainer:168 RmsProp 830 loss=0.185233 err=0.185233
I 2015-05-26 09:17:16 theanets.trainer:168 validation 83 loss=751.380554 err=751.380554 *
I 2015-05-26 09:17:23 theanets.trainer:168 RmsProp 831 loss=0.171982 err=0.171982
I 2015-05-26 09:17:31 theanets.trainer:168 RmsProp 832 loss=0.160896 err=0.160896
I 2015-05-26 09:17:38 theanets.trainer:168 RmsProp 833 loss=0.158352 err=0.158352
I 2015-05-26 09:17:46 theanets.trainer:168 RmsProp 834 loss=0.229467 err=0.229467
I 2015-05-26 09:17:53 theanets.trainer:168 RmsProp 835 loss=0.169442 err=0.169442
I 2015-05-26 09:18:01 theanets.trainer:168 RmsProp 836 loss=0.155360 err=0.155360
I 2015-05-26 09:18:08 theanets.trainer:168 RmsProp 837 loss=0.181073 err=0.181073
I 2015-05-26 09:18:16 theanets.trainer:168 RmsProp 838 loss=0.173076 err=0.173076
I 2015-05-26 09:18:23 theanets.trainer:168 RmsProp 839 loss=0.156880 err=0.156880
I 2015-05-26 09:18:31 theanets.trainer:168 RmsProp 840 loss=0.173408 err=0.173408
I 2015-05-26 09:18:32 theanets.trainer:168 validation 84 loss=750.977356 err=750.977356 *
I 2015-05-26 09:18:39 theanets.trainer:168 RmsProp 841 loss=0.172691 err=0.172691
I 2015-05-26 09:18:46 theanets.trainer:168 RmsProp 842 loss=0.170042 err=0.170042
I 2015-05-26 09:18:54 theanets.trainer:168 RmsProp 843 loss=0.179249 err=0.179249
I 2015-05-26 09:19:01 theanets.trainer:168 RmsProp 844 loss=0.171330 err=0.171330
I 2015-05-26 09:19:08 theanets.trainer:168 RmsProp 845 loss=0.164051 err=0.164051
I 2015-05-26 09:19:16 theanets.trainer:168 RmsProp 846 loss=0.168023 err=0.168023
I 2015-05-26 09:19:23 theanets.trainer:168 RmsProp 847 loss=0.182572 err=0.182572
I 2015-05-26 09:19:30 theanets.trainer:168 RmsProp 848 loss=0.175267 err=0.175267
I 2015-05-26 09:19:37 theanets.trainer:168 RmsProp 849 loss=0.171509 err=0.171509
I 2015-05-26 09:19:45 theanets.trainer:168 RmsProp 850 loss=0.183055 err=0.183055
I 2015-05-26 09:19:45 theanets.trainer:168 validation 85 loss=751.025879 err=751.025879
I 2015-05-26 09:19:52 theanets.trainer:168 RmsProp 851 loss=0.164856 err=0.164856
I 2015-05-26 09:19:59 theanets.trainer:168 RmsProp 852 loss=0.170224 err=0.170224
I 2015-05-26 09:20:06 theanets.trainer:168 RmsProp 853 loss=0.151646 err=0.151646
I 2015-05-26 09:20:14 theanets.trainer:168 RmsProp 854 loss=0.176790 err=0.176790
I 2015-05-26 09:20:22 theanets.trainer:168 RmsProp 855 loss=0.176645 err=0.176645
I 2015-05-26 09:20:29 theanets.trainer:168 RmsProp 856 loss=0.160342 err=0.160342
I 2015-05-26 09:20:37 theanets.trainer:168 RmsProp 857 loss=0.175413 err=0.175413
I 2015-05-26 09:20:44 theanets.trainer:168 RmsProp 858 loss=0.154980 err=0.154980
I 2015-05-26 09:20:51 theanets.trainer:168 RmsProp 859 loss=0.185512 err=0.185512
I 2015-05-26 09:20:58 theanets.trainer:168 RmsProp 860 loss=0.170943 err=0.170943
I 2015-05-26 09:20:58 theanets.trainer:168 validation 86 loss=749.468872 err=749.468872 *
I 2015-05-26 09:21:06 theanets.trainer:168 RmsProp 861 loss=0.161692 err=0.161692
I 2015-05-26 09:21:13 theanets.trainer:168 RmsProp 862 loss=0.159617 err=0.159617
I 2015-05-26 09:21:20 theanets.trainer:168 RmsProp 863 loss=0.170190 err=0.170190
I 2015-05-26 09:21:28 theanets.trainer:168 RmsProp 864 loss=0.158920 err=0.158920
I 2015-05-26 09:21:35 theanets.trainer:168 RmsProp 865 loss=0.168919 err=0.168919
I 2015-05-26 09:21:42 theanets.trainer:168 RmsProp 866 loss=0.166180 err=0.166180
I 2015-05-26 09:21:50 theanets.trainer:168 RmsProp 867 loss=0.180479 err=0.180479
I 2015-05-26 09:21:57 theanets.trainer:168 RmsProp 868 loss=0.144480 err=0.144480
I 2015-05-26 09:22:04 theanets.trainer:168 RmsProp 869 loss=0.200741 err=0.200741
I 2015-05-26 09:22:11 theanets.trainer:168 RmsProp 870 loss=0.167331 err=0.167331
I 2015-05-26 09:22:12 theanets.trainer:168 validation 87 loss=748.886597 err=748.886597 *
I 2015-05-26 09:22:18 theanets.trainer:168 RmsProp 871 loss=0.154244 err=0.154244
I 2015-05-26 09:22:26 theanets.trainer:168 RmsProp 872 loss=0.165881 err=0.165881
I 2015-05-26 09:22:33 theanets.trainer:168 RmsProp 873 loss=0.174441 err=0.174441
I 2015-05-26 09:22:41 theanets.trainer:168 RmsProp 874 loss=0.163069 err=0.163069
I 2015-05-26 09:22:47 theanets.trainer:168 RmsProp 875 loss=0.164542 err=0.164542
I 2015-05-26 09:22:54 theanets.trainer:168 RmsProp 876 loss=0.148112 err=0.148112
I 2015-05-26 09:23:01 theanets.trainer:168 RmsProp 877 loss=0.169641 err=0.169641
I 2015-05-26 09:23:08 theanets.trainer:168 RmsProp 878 loss=0.166674 err=0.166674
I 2015-05-26 09:23:14 theanets.trainer:168 RmsProp 879 loss=0.164113 err=0.164113
I 2015-05-26 09:23:21 theanets.trainer:168 RmsProp 880 loss=0.172547 err=0.172547
I 2015-05-26 09:23:21 theanets.trainer:168 validation 88 loss=748.929382 err=748.929382
I 2015-05-26 09:23:28 theanets.trainer:168 RmsProp 881 loss=0.165893 err=0.165893
I 2015-05-26 09:23:35 theanets.trainer:168 RmsProp 882 loss=0.157480 err=0.157480
I 2015-05-26 09:23:42 theanets.trainer:168 RmsProp 883 loss=0.154089 err=0.154089
I 2015-05-26 09:23:50 theanets.trainer:168 RmsProp 884 loss=0.176467 err=0.176467
I 2015-05-26 09:23:56 theanets.trainer:168 RmsProp 885 loss=0.175724 err=0.175724
I 2015-05-26 09:24:03 theanets.trainer:168 RmsProp 886 loss=0.152257 err=0.152257
I 2015-05-26 09:24:10 theanets.trainer:168 RmsProp 887 loss=0.142980 err=0.142980
I 2015-05-26 09:24:17 theanets.trainer:168 RmsProp 888 loss=0.150426 err=0.150426
I 2015-05-26 09:24:24 theanets.trainer:168 RmsProp 889 loss=0.173067 err=0.173067
I 2015-05-26 09:24:31 theanets.trainer:168 RmsProp 890 loss=0.163447 err=0.163447
I 2015-05-26 09:24:32 theanets.trainer:168 validation 89 loss=749.226868 err=749.226868
I 2015-05-26 09:24:38 theanets.trainer:168 RmsProp 891 loss=0.159421 err=0.159421
I 2015-05-26 09:24:45 theanets.trainer:168 RmsProp 892 loss=0.161390 err=0.161390
I 2015-05-26 09:24:52 theanets.trainer:168 RmsProp 893 loss=0.150349 err=0.150349
I 2015-05-26 09:24:58 theanets.trainer:168 RmsProp 894 loss=0.182831 err=0.182831
I 2015-05-26 09:25:05 theanets.trainer:168 RmsProp 895 loss=0.174594 err=0.174594
I 2015-05-26 09:25:12 theanets.trainer:168 RmsProp 896 loss=0.168889 err=0.168889
I 2015-05-26 09:25:19 theanets.trainer:168 RmsProp 897 loss=0.168373 err=0.168373
I 2015-05-26 09:25:25 theanets.trainer:168 RmsProp 898 loss=0.149912 err=0.149912
I 2015-05-26 09:25:32 theanets.trainer:168 RmsProp 899 loss=0.161280 err=0.161280
I 2015-05-26 09:25:39 theanets.trainer:168 RmsProp 900 loss=0.163605 err=0.163605
I 2015-05-26 09:25:39 theanets.trainer:168 validation 90 loss=747.980896 err=747.980896 *
I 2015-05-26 09:25:46 theanets.trainer:168 RmsProp 901 loss=0.152447 err=0.152447
I 2015-05-26 09:25:53 theanets.trainer:168 RmsProp 902 loss=0.159095 err=0.159095
I 2015-05-26 09:26:00 theanets.trainer:168 RmsProp 903 loss=0.169487 err=0.169487
I 2015-05-26 09:26:06 theanets.trainer:168 RmsProp 904 loss=0.154734 err=0.154734
I 2015-05-26 09:26:12 theanets.trainer:168 RmsProp 905 loss=0.168846 err=0.168846
I 2015-05-26 09:26:19 theanets.trainer:168 RmsProp 906 loss=0.173779 err=0.173779
I 2015-05-26 09:26:26 theanets.trainer:168 RmsProp 907 loss=0.167742 err=0.167742
I 2015-05-26 09:26:32 theanets.trainer:168 RmsProp 908 loss=0.152638 err=0.152638
I 2015-05-26 09:26:40 theanets.trainer:168 RmsProp 909 loss=0.155688 err=0.155688
I 2015-05-26 09:26:46 theanets.trainer:168 RmsProp 910 loss=0.163470 err=0.163470
I 2015-05-26 09:26:47 theanets.trainer:168 validation 91 loss=747.409973 err=747.409973 *
I 2015-05-26 09:26:53 theanets.trainer:168 RmsProp 911 loss=0.158817 err=0.158817
I 2015-05-26 09:27:00 theanets.trainer:168 RmsProp 912 loss=0.155749 err=0.155749
I 2015-05-26 09:27:07 theanets.trainer:168 RmsProp 913 loss=0.151884 err=0.151884
I 2015-05-26 09:27:14 theanets.trainer:168 RmsProp 914 loss=0.159614 err=0.159614
I 2015-05-26 09:27:21 theanets.trainer:168 RmsProp 915 loss=0.160524 err=0.160524
I 2015-05-26 09:27:28 theanets.trainer:168 RmsProp 916 loss=0.170151 err=0.170151
I 2015-05-26 09:27:35 theanets.trainer:168 RmsProp 917 loss=0.143543 err=0.143543
I 2015-05-26 09:27:42 theanets.trainer:168 RmsProp 918 loss=0.189575 err=0.189575
I 2015-05-26 09:27:49 theanets.trainer:168 RmsProp 919 loss=0.197032 err=0.197032
I 2015-05-26 09:27:56 theanets.trainer:168 RmsProp 920 loss=0.137525 err=0.137525
I 2015-05-26 09:27:56 theanets.trainer:168 validation 92 loss=746.044067 err=746.044067 *
I 2015-05-26 09:28:03 theanets.trainer:168 RmsProp 921 loss=0.160788 err=0.160788
I 2015-05-26 09:28:10 theanets.trainer:168 RmsProp 922 loss=0.164855 err=0.164855
I 2015-05-26 09:28:17 theanets.trainer:168 RmsProp 923 loss=0.161005 err=0.161005
I 2015-05-26 09:28:25 theanets.trainer:168 RmsProp 924 loss=0.149023 err=0.149023
I 2015-05-26 09:28:32 theanets.trainer:168 RmsProp 925 loss=0.157667 err=0.157667
I 2015-05-26 09:28:39 theanets.trainer:168 RmsProp 926 loss=0.147498 err=0.147498
I 2015-05-26 09:28:46 theanets.trainer:168 RmsProp 927 loss=0.164280 err=0.164280
I 2015-05-26 09:28:52 theanets.trainer:168 RmsProp 928 loss=0.166341 err=0.166341
I 2015-05-26 09:28:59 theanets.trainer:168 RmsProp 929 loss=0.143891 err=0.143891
I 2015-05-26 09:29:05 theanets.trainer:168 RmsProp 930 loss=0.153493 err=0.153493
I 2015-05-26 09:29:06 theanets.trainer:168 validation 93 loss=746.653137 err=746.653137
I 2015-05-26 09:29:12 theanets.trainer:168 RmsProp 931 loss=0.152093 err=0.152093
I 2015-05-26 09:29:18 theanets.trainer:168 RmsProp 932 loss=0.170510 err=0.170510
I 2015-05-26 09:29:25 theanets.trainer:168 RmsProp 933 loss=0.164432 err=0.164432
I 2015-05-26 09:29:32 theanets.trainer:168 RmsProp 934 loss=0.141635 err=0.141635
I 2015-05-26 09:29:39 theanets.trainer:168 RmsProp 935 loss=0.164635 err=0.164635
I 2015-05-26 09:29:46 theanets.trainer:168 RmsProp 936 loss=0.137983 err=0.137983
I 2015-05-26 09:29:52 theanets.trainer:168 RmsProp 937 loss=0.178494 err=0.178494
I 2015-05-26 09:29:59 theanets.trainer:168 RmsProp 938 loss=0.160356 err=0.160356
I 2015-05-26 09:30:06 theanets.trainer:168 RmsProp 939 loss=0.144006 err=0.144006
I 2015-05-26 09:30:13 theanets.trainer:168 RmsProp 940 loss=0.157915 err=0.157915
I 2015-05-26 09:30:13 theanets.trainer:168 validation 94 loss=745.402588 err=745.402588 *
I 2015-05-26 09:30:20 theanets.trainer:168 RmsProp 941 loss=0.172799 err=0.172799
I 2015-05-26 09:30:27 theanets.trainer:168 RmsProp 942 loss=0.157775 err=0.157775
I 2015-05-26 09:30:34 theanets.trainer:168 RmsProp 943 loss=0.146611 err=0.146611
I 2015-05-26 09:30:41 theanets.trainer:168 RmsProp 944 loss=0.155421 err=0.155421
I 2015-05-26 09:30:47 theanets.trainer:168 RmsProp 945 loss=0.163421 err=0.163421
I 2015-05-26 09:30:54 theanets.trainer:168 RmsProp 946 loss=0.150368 err=0.150368
I 2015-05-26 09:31:01 theanets.trainer:168 RmsProp 947 loss=0.158219 err=0.158219
I 2015-05-26 09:31:08 theanets.trainer:168 RmsProp 948 loss=0.146365 err=0.146365
I 2015-05-26 09:31:14 theanets.trainer:168 RmsProp 949 loss=0.152435 err=0.152435
I 2015-05-26 09:31:21 theanets.trainer:168 RmsProp 950 loss=0.167734 err=0.167734
I 2015-05-26 09:31:22 theanets.trainer:168 validation 95 loss=744.316223 err=744.316223 *
I 2015-05-26 09:31:28 theanets.trainer:168 RmsProp 951 loss=0.135273 err=0.135273
I 2015-05-26 09:31:35 theanets.trainer:168 RmsProp 952 loss=0.161315 err=0.161315
I 2015-05-26 09:31:42 theanets.trainer:168 RmsProp 953 loss=0.151598 err=0.151598
I 2015-05-26 09:31:49 theanets.trainer:168 RmsProp 954 loss=0.154183 err=0.154183
I 2015-05-26 09:31:56 theanets.trainer:168 RmsProp 955 loss=0.147520 err=0.147520
I 2015-05-26 09:32:03 theanets.trainer:168 RmsProp 956 loss=0.146531 err=0.146531
I 2015-05-26 09:32:10 theanets.trainer:168 RmsProp 957 loss=0.165291 err=0.165291
I 2015-05-26 09:32:16 theanets.trainer:168 RmsProp 958 loss=0.133259 err=0.133259
I 2015-05-26 09:32:23 theanets.trainer:168 RmsProp 959 loss=0.154021 err=0.154021
I 2015-05-26 09:32:29 theanets.trainer:168 RmsProp 960 loss=0.167072 err=0.167072
I 2015-05-26 09:32:30 theanets.trainer:168 validation 96 loss=744.499817 err=744.499817
I 2015-05-26 09:32:37 theanets.trainer:168 RmsProp 961 loss=0.159253 err=0.159253
I 2015-05-26 09:32:43 theanets.trainer:168 RmsProp 962 loss=0.131444 err=0.131444
I 2015-05-26 09:32:50 theanets.trainer:168 RmsProp 963 loss=0.180202 err=0.180202
I 2015-05-26 09:32:56 theanets.trainer:168 RmsProp 964 loss=0.148676 err=0.148676
I 2015-05-26 09:33:03 theanets.trainer:168 RmsProp 965 loss=0.152638 err=0.152638
I 2015-05-26 09:33:10 theanets.trainer:168 RmsProp 966 loss=0.124080 err=0.124080
I 2015-05-26 09:33:16 theanets.trainer:168 RmsProp 967 loss=0.226168 err=0.226168
I 2015-05-26 09:33:23 theanets.trainer:168 RmsProp 968 loss=0.177343 err=0.177343
I 2015-05-26 09:33:30 theanets.trainer:168 RmsProp 969 loss=0.142355 err=0.142355
I 2015-05-26 09:33:37 theanets.trainer:168 RmsProp 970 loss=0.132699 err=0.132699
I 2015-05-26 09:33:37 theanets.trainer:168 validation 97 loss=744.465271 err=744.465271
I 2015-05-26 09:33:44 theanets.trainer:168 RmsProp 971 loss=0.157090 err=0.157090
I 2015-05-26 09:33:50 theanets.trainer:168 RmsProp 972 loss=0.151470 err=0.151470
I 2015-05-26 09:33:57 theanets.trainer:168 RmsProp 973 loss=0.146334 err=0.146334
I 2015-05-26 09:34:03 theanets.trainer:168 RmsProp 974 loss=0.145833 err=0.145833
I 2015-05-26 09:34:10 theanets.trainer:168 RmsProp 975 loss=0.141795 err=0.141795
I 2015-05-26 09:34:17 theanets.trainer:168 RmsProp 976 loss=0.160192 err=0.160192
I 2015-05-26 09:34:25 theanets.trainer:168 RmsProp 977 loss=0.150140 err=0.150140
I 2015-05-26 09:34:31 theanets.trainer:168 RmsProp 978 loss=0.148295 err=0.148295
I 2015-05-26 09:34:38 theanets.trainer:168 RmsProp 979 loss=0.145524 err=0.145524
I 2015-05-26 09:34:44 theanets.trainer:168 RmsProp 980 loss=0.155565 err=0.155565
I 2015-05-26 09:34:45 theanets.trainer:168 validation 98 loss=743.937134 err=743.937134 *
I 2015-05-26 09:34:52 theanets.trainer:168 RmsProp 981 loss=0.153124 err=0.153124
I 2015-05-26 09:34:59 theanets.trainer:168 RmsProp 982 loss=0.140807 err=0.140807
I 2015-05-26 09:35:06 theanets.trainer:168 RmsProp 983 loss=0.173717 err=0.173717
I 2015-05-26 09:35:12 theanets.trainer:168 RmsProp 984 loss=0.165104 err=0.165104
I 2015-05-26 09:35:19 theanets.trainer:168 RmsProp 985 loss=0.131909 err=0.131909
I 2015-05-26 09:35:26 theanets.trainer:168 RmsProp 986 loss=0.150746 err=0.150746
I 2015-05-26 09:35:33 theanets.trainer:168 RmsProp 987 loss=0.169829 err=0.169829
I 2015-05-26 09:35:39 theanets.trainer:168 RmsProp 988 loss=0.131364 err=0.131364
I 2015-05-26 09:35:46 theanets.trainer:168 RmsProp 989 loss=0.158859 err=0.158859
I 2015-05-26 09:35:53 theanets.trainer:168 RmsProp 990 loss=0.136640 err=0.136640
I 2015-05-26 09:35:53 theanets.trainer:168 validation 99 loss=743.809692 err=743.809692 *
I 2015-05-26 09:35:59 theanets.trainer:168 RmsProp 991 loss=0.163910 err=0.163910
I 2015-05-26 09:36:06 theanets.trainer:168 RmsProp 992 loss=0.149757 err=0.149757
I 2015-05-26 09:36:13 theanets.trainer:168 RmsProp 993 loss=0.149073 err=0.149073
I 2015-05-26 09:36:20 theanets.trainer:168 RmsProp 994 loss=0.138976 err=0.138976
I 2015-05-26 09:36:27 theanets.trainer:168 RmsProp 995 loss=0.154833 err=0.154833
I 2015-05-26 09:36:33 theanets.trainer:168 RmsProp 996 loss=0.146420 err=0.146420
I 2015-05-26 09:36:40 theanets.trainer:168 RmsProp 997 loss=0.169821 err=0.169821
I 2015-05-26 09:36:47 theanets.trainer:168 RmsProp 998 loss=0.148007 err=0.148007
I 2015-05-26 09:36:53 theanets.trainer:168 RmsProp 999 loss=0.143214 err=0.143214
I 2015-05-26 09:37:00 theanets.trainer:168 RmsProp 1000 loss=0.140880 err=0.140880
I 2015-05-26 09:37:00 theanets.trainer:168 validation 100 loss=742.886047 err=742.886047 *
I 2015-05-26 09:37:07 theanets.trainer:168 RmsProp 1001 loss=0.147283 err=0.147283
I 2015-05-26 09:37:13 theanets.trainer:168 RmsProp 1002 loss=0.134378 err=0.134378
I 2015-05-26 09:37:20 theanets.trainer:168 RmsProp 1003 loss=0.155499 err=0.155499
I 2015-05-26 09:37:27 theanets.trainer:168 RmsProp 1004 loss=0.147689 err=0.147689
I 2015-05-26 09:37:34 theanets.trainer:168 RmsProp 1005 loss=0.141689 err=0.141689
I 2015-05-26 09:37:41 theanets.trainer:168 RmsProp 1006 loss=0.146650 err=0.146650
I 2015-05-26 09:37:47 theanets.trainer:168 RmsProp 1007 loss=0.157160 err=0.157160
I 2015-05-26 09:37:53 theanets.trainer:168 RmsProp 1008 loss=0.153186 err=0.153186
I 2015-05-26 09:38:00 theanets.trainer:168 RmsProp 1009 loss=0.148595 err=0.148595
I 2015-05-26 09:38:06 theanets.trainer:168 RmsProp 1010 loss=0.144874 err=0.144874
I 2015-05-26 09:38:07 theanets.trainer:168 validation 101 loss=742.798157 err=742.798157 *
I 2015-05-26 09:38:13 theanets.trainer:168 RmsProp 1011 loss=0.135816 err=0.135816
I 2015-05-26 09:38:21 theanets.trainer:168 RmsProp 1012 loss=0.150744 err=0.150744
I 2015-05-26 09:38:27 theanets.trainer:168 RmsProp 1013 loss=0.114857 err=0.114857
I 2015-05-26 09:38:34 theanets.trainer:168 RmsProp 1014 loss=0.195672 err=0.195672
I 2015-05-26 09:38:41 theanets.trainer:168 RmsProp 1015 loss=0.143479 err=0.143479
I 2015-05-26 09:38:48 theanets.trainer:168 RmsProp 1016 loss=0.139384 err=0.139384
I 2015-05-26 09:38:54 theanets.trainer:168 RmsProp 1017 loss=0.145597 err=0.145597
I 2015-05-26 09:39:01 theanets.trainer:168 RmsProp 1018 loss=0.136764 err=0.136764
I 2015-05-26 09:39:08 theanets.trainer:168 RmsProp 1019 loss=0.133795 err=0.133795
I 2015-05-26 09:39:15 theanets.trainer:168 RmsProp 1020 loss=0.147767 err=0.147767
I 2015-05-26 09:39:15 theanets.trainer:168 validation 102 loss=741.509155 err=741.509155 *
I 2015-05-26 09:39:22 theanets.trainer:168 RmsProp 1021 loss=0.162972 err=0.162972
I 2015-05-26 09:39:29 theanets.trainer:168 RmsProp 1022 loss=0.139592 err=0.139592
I 2015-05-26 09:39:36 theanets.trainer:168 RmsProp 1023 loss=0.148025 err=0.148025
I 2015-05-26 09:39:43 theanets.trainer:168 RmsProp 1024 loss=0.155722 err=0.155722
I 2015-05-26 09:39:50 theanets.trainer:168 RmsProp 1025 loss=0.133219 err=0.133219
I 2015-05-26 09:39:56 theanets.trainer:168 RmsProp 1026 loss=0.148662 err=0.148662
I 2015-05-26 09:40:03 theanets.trainer:168 RmsProp 1027 loss=0.142523 err=0.142523
I 2015-05-26 09:40:10 theanets.trainer:168 RmsProp 1028 loss=0.125859 err=0.125859
I 2015-05-26 09:40:16 theanets.trainer:168 RmsProp 1029 loss=0.164514 err=0.164514
I 2015-05-26 09:40:22 theanets.trainer:168 RmsProp 1030 loss=0.124111 err=0.124111
I 2015-05-26 09:40:23 theanets.trainer:168 validation 103 loss=741.860107 err=741.860107
I 2015-05-26 09:40:30 theanets.trainer:168 RmsProp 1031 loss=0.161613 err=0.161613
I 2015-05-26 09:40:37 theanets.trainer:168 RmsProp 1032 loss=0.150816 err=0.150816
I 2015-05-26 09:40:44 theanets.trainer:168 RmsProp 1033 loss=0.134028 err=0.134028
I 2015-05-26 09:40:50 theanets.trainer:168 RmsProp 1034 loss=0.147926 err=0.147926
I 2015-05-26 09:40:57 theanets.trainer:168 RmsProp 1035 loss=0.131651 err=0.131651
I 2015-05-26 09:41:05 theanets.trainer:168 RmsProp 1036 loss=0.154865 err=0.154865
I 2015-05-26 09:41:12 theanets.trainer:168 RmsProp 1037 loss=0.157647 err=0.157647
I 2015-05-26 09:41:19 theanets.trainer:168 RmsProp 1038 loss=0.131289 err=0.131289
I 2015-05-26 09:41:25 theanets.trainer:168 RmsProp 1039 loss=0.153613 err=0.153613
I 2015-05-26 09:41:31 theanets.trainer:168 RmsProp 1040 loss=0.146379 err=0.146379
I 2015-05-26 09:41:32 theanets.trainer:168 validation 104 loss=742.855591 err=742.855591
I 2015-05-26 09:41:38 theanets.trainer:168 RmsProp 1041 loss=0.139801 err=0.139801
I 2015-05-26 09:41:45 theanets.trainer:168 RmsProp 1042 loss=0.135663 err=0.135663
I 2015-05-26 09:41:52 theanets.trainer:168 RmsProp 1043 loss=0.148460 err=0.148460
I 2015-05-26 09:41:58 theanets.trainer:168 RmsProp 1044 loss=0.128861 err=0.128861
I 2015-05-26 09:42:05 theanets.trainer:168 RmsProp 1045 loss=0.149379 err=0.149379
I 2015-05-26 09:42:12 theanets.trainer:168 RmsProp 1046 loss=0.140637 err=0.140637
I 2015-05-26 09:42:19 theanets.trainer:168 RmsProp 1047 loss=0.144035 err=0.144035
I 2015-05-26 09:42:25 theanets.trainer:168 RmsProp 1048 loss=0.148165 err=0.148165
I 2015-05-26 09:42:32 theanets.trainer:168 RmsProp 1049 loss=0.147240 err=0.147240
I 2015-05-26 09:42:38 theanets.trainer:168 RmsProp 1050 loss=0.135093 err=0.135093
I 2015-05-26 09:42:39 theanets.trainer:168 validation 105 loss=740.846985 err=740.846985 *
I 2015-05-26 09:42:45 theanets.trainer:168 RmsProp 1051 loss=0.146424 err=0.146424
I 2015-05-26 09:42:52 theanets.trainer:168 RmsProp 1052 loss=0.139055 err=0.139055
I 2015-05-26 09:42:59 theanets.trainer:168 RmsProp 1053 loss=0.142230 err=0.142230
I 2015-05-26 09:43:05 theanets.trainer:168 RmsProp 1054 loss=0.144841 err=0.144841
I 2015-05-26 09:43:12 theanets.trainer:168 RmsProp 1055 loss=0.137479 err=0.137479
I 2015-05-26 09:43:19 theanets.trainer:168 RmsProp 1056 loss=0.133196 err=0.133196
I 2015-05-26 09:43:26 theanets.trainer:168 RmsProp 1057 loss=0.131533 err=0.131533
I 2015-05-26 09:43:32 theanets.trainer:168 RmsProp 1058 loss=0.130277 err=0.130277
I 2015-05-26 09:43:39 theanets.trainer:168 RmsProp 1059 loss=0.148307 err=0.148307
I 2015-05-26 09:43:45 theanets.trainer:168 RmsProp 1060 loss=0.159282 err=0.159282
I 2015-05-26 09:43:45 theanets.trainer:168 validation 106 loss=740.484314 err=740.484314 *
I 2015-05-26 09:43:52 theanets.trainer:168 RmsProp 1061 loss=0.123444 err=0.123444
I 2015-05-26 09:43:58 theanets.trainer:168 RmsProp 1062 loss=0.148285 err=0.148285
I 2015-05-26 09:44:05 theanets.trainer:168 RmsProp 1063 loss=0.115590 err=0.115590
I 2015-05-26 09:44:12 theanets.trainer:168 RmsProp 1064 loss=0.163544 err=0.163544
I 2015-05-26 09:44:18 theanets.trainer:168 RmsProp 1065 loss=0.134757 err=0.134757
I 2015-05-26 09:44:24 theanets.trainer:168 RmsProp 1066 loss=0.145884 err=0.145884
I 2015-05-26 09:44:32 theanets.trainer:168 RmsProp 1067 loss=0.135041 err=0.135041
I 2015-05-26 09:44:39 theanets.trainer:168 RmsProp 1068 loss=0.144105 err=0.144105
I 2015-05-26 09:44:46 theanets.trainer:168 RmsProp 1069 loss=0.140591 err=0.140591
I 2015-05-26 09:44:53 theanets.trainer:168 RmsProp 1070 loss=0.141279 err=0.141279
I 2015-05-26 09:44:54 theanets.trainer:168 validation 107 loss=741.510010 err=741.510010
I 2015-05-26 09:45:00 theanets.trainer:168 RmsProp 1071 loss=0.153736 err=0.153736
I 2015-05-26 09:45:06 theanets.trainer:168 RmsProp 1072 loss=0.136299 err=0.136299
I 2015-05-26 09:45:13 theanets.trainer:168 RmsProp 1073 loss=0.128685 err=0.128685
I 2015-05-26 09:45:20 theanets.trainer:168 RmsProp 1074 loss=0.145497 err=0.145497
I 2015-05-26 09:45:27 theanets.trainer:168 RmsProp 1075 loss=0.160384 err=0.160384
I 2015-05-26 09:45:34 theanets.trainer:168 RmsProp 1076 loss=0.134108 err=0.134108
I 2015-05-26 09:45:40 theanets.trainer:168 RmsProp 1077 loss=0.146259 err=0.146259
I 2015-05-26 09:45:47 theanets.trainer:168 RmsProp 1078 loss=0.135654 err=0.135654
I 2015-05-26 09:45:53 theanets.trainer:168 RmsProp 1079 loss=0.135347 err=0.135347
I 2015-05-26 09:46:00 theanets.trainer:168 RmsProp 1080 loss=0.135799 err=0.135799
I 2015-05-26 09:46:01 theanets.trainer:168 validation 108 loss=739.859985 err=739.859985 *
I 2015-05-26 09:46:07 theanets.trainer:168 RmsProp 1081 loss=0.150215 err=0.150215
I 2015-05-26 09:46:15 theanets.trainer:168 RmsProp 1082 loss=0.146355 err=0.146355
I 2015-05-26 09:46:21 theanets.trainer:168 RmsProp 1083 loss=0.119179 err=0.119179
I 2015-05-26 09:46:27 theanets.trainer:168 RmsProp 1084 loss=0.134407 err=0.134407
I 2015-05-26 09:46:35 theanets.trainer:168 RmsProp 1085 loss=0.157109 err=0.157109
I 2015-05-26 09:46:41 theanets.trainer:168 RmsProp 1086 loss=0.121601 err=0.121601
I 2015-05-26 09:46:48 theanets.trainer:168 RmsProp 1087 loss=0.139295 err=0.139295
I 2015-05-26 09:46:54 theanets.trainer:168 RmsProp 1088 loss=0.136677 err=0.136677
I 2015-05-26 09:47:01 theanets.trainer:168 RmsProp 1089 loss=0.137944 err=0.137944
I 2015-05-26 09:47:07 theanets.trainer:168 RmsProp 1090 loss=0.128780 err=0.128780
I 2015-05-26 09:47:08 theanets.trainer:168 validation 109 loss=740.219421 err=740.219421
I 2015-05-26 09:47:14 theanets.trainer:168 RmsProp 1091 loss=0.134478 err=0.134478
I 2015-05-26 09:47:20 theanets.trainer:168 RmsProp 1092 loss=0.131616 err=0.131616
I 2015-05-26 09:47:27 theanets.trainer:168 RmsProp 1093 loss=0.142318 err=0.142318
I 2015-05-26 09:47:34 theanets.trainer:168 RmsProp 1094 loss=0.139099 err=0.139099
I 2015-05-26 09:47:41 theanets.trainer:168 RmsProp 1095 loss=0.132452 err=0.132452
I 2015-05-26 09:47:48 theanets.trainer:168 RmsProp 1096 loss=0.126296 err=0.126296
I 2015-05-26 09:47:55 theanets.trainer:168 RmsProp 1097 loss=0.146598 err=0.146598
I 2015-05-26 09:48:01 theanets.trainer:168 RmsProp 1098 loss=0.139423 err=0.139423
I 2015-05-26 09:48:08 theanets.trainer:168 RmsProp 1099 loss=0.135113 err=0.135113
I 2015-05-26 09:48:15 theanets.trainer:168 RmsProp 1100 loss=0.131659 err=0.131659
I 2015-05-26 09:48:15 theanets.trainer:168 validation 110 loss=739.312012 err=739.312012 *
I 2015-05-26 09:48:21 theanets.trainer:168 RmsProp 1101 loss=0.140994 err=0.140994
I 2015-05-26 09:48:29 theanets.trainer:168 RmsProp 1102 loss=0.121016 err=0.121016
I 2015-05-26 09:48:35 theanets.trainer:168 RmsProp 1103 loss=0.156333 err=0.156333
I 2015-05-26 09:48:42 theanets.trainer:168 RmsProp 1104 loss=0.130339 err=0.130339
I 2015-05-26 09:48:49 theanets.trainer:168 RmsProp 1105 loss=0.135630 err=0.135630
I 2015-05-26 09:48:55 theanets.trainer:168 RmsProp 1106 loss=0.130309 err=0.130309
I 2015-05-26 09:49:02 theanets.trainer:168 RmsProp 1107 loss=0.151790 err=0.151790
I 2015-05-26 09:49:09 theanets.trainer:168 RmsProp 1108 loss=0.134841 err=0.134841
I 2015-05-26 09:49:16 theanets.trainer:168 RmsProp 1109 loss=0.124719 err=0.124719
I 2015-05-26 09:49:23 theanets.trainer:168 RmsProp 1110 loss=0.142016 err=0.142016
I 2015-05-26 09:49:23 theanets.trainer:168 validation 111 loss=738.842102 err=738.842102 *
I 2015-05-26 09:49:29 theanets.trainer:168 RmsProp 1111 loss=0.131616 err=0.131616
I 2015-05-26 09:49:36 theanets.trainer:168 RmsProp 1112 loss=0.144777 err=0.144777
I 2015-05-26 09:49:42 theanets.trainer:168 RmsProp 1113 loss=0.143739 err=0.143739
I 2015-05-26 09:49:49 theanets.trainer:168 RmsProp 1114 loss=0.130389 err=0.130389
I 2015-05-26 09:49:55 theanets.trainer:168 RmsProp 1115 loss=0.134001 err=0.134001
I 2015-05-26 09:50:02 theanets.trainer:168 RmsProp 1116 loss=0.133261 err=0.133261
I 2015-05-26 09:50:09 theanets.trainer:168 RmsProp 1117 loss=0.136736 err=0.136736
I 2015-05-26 09:50:15 theanets.trainer:168 RmsProp 1118 loss=0.125775 err=0.125775
I 2015-05-26 09:50:22 theanets.trainer:168 RmsProp 1119 loss=0.131067 err=0.131067
I 2015-05-26 09:50:29 theanets.trainer:168 RmsProp 1120 loss=0.147348 err=0.147348
I 2015-05-26 09:50:29 theanets.trainer:168 validation 112 loss=738.709106 err=738.709106 *
I 2015-05-26 09:50:36 theanets.trainer:168 RmsProp 1121 loss=0.128660 err=0.128660
I 2015-05-26 09:50:43 theanets.trainer:168 RmsProp 1122 loss=0.132324 err=0.132324
I 2015-05-26 09:50:49 theanets.trainer:168 RmsProp 1123 loss=0.132100 err=0.132100
I 2015-05-26 09:50:56 theanets.trainer:168 RmsProp 1124 loss=0.137623 err=0.137623
I 2015-05-26 09:51:03 theanets.trainer:168 RmsProp 1125 loss=0.125431 err=0.125431
I 2015-05-26 09:51:09 theanets.trainer:168 RmsProp 1126 loss=0.133332 err=0.133332
I 2015-05-26 09:51:16 theanets.trainer:168 RmsProp 1127 loss=0.131274 err=0.131274
I 2015-05-26 09:51:23 theanets.trainer:168 RmsProp 1128 loss=0.116761 err=0.116761
I 2015-05-26 09:51:30 theanets.trainer:168 RmsProp 1129 loss=0.162098 err=0.162098
I 2015-05-26 09:51:36 theanets.trainer:168 RmsProp 1130 loss=0.129725 err=0.129725
I 2015-05-26 09:51:37 theanets.trainer:168 validation 113 loss=739.086365 err=739.086365
I 2015-05-26 09:51:44 theanets.trainer:168 RmsProp 1131 loss=0.122630 err=0.122630
I 2015-05-26 09:51:50 theanets.trainer:168 RmsProp 1132 loss=0.140058 err=0.140058
I 2015-05-26 09:51:56 theanets.trainer:168 RmsProp 1133 loss=0.134379 err=0.134379
I 2015-05-26 09:52:03 theanets.trainer:168 RmsProp 1134 loss=0.123657 err=0.123657
I 2015-05-26 09:52:10 theanets.trainer:168 RmsProp 1135 loss=0.127144 err=0.127144
I 2015-05-26 09:52:17 theanets.trainer:168 RmsProp 1136 loss=0.129042 err=0.129042
I 2015-05-26 09:52:24 theanets.trainer:168 RmsProp 1137 loss=0.131341 err=0.131341
I 2015-05-26 09:52:31 theanets.trainer:168 RmsProp 1138 loss=0.139944 err=0.139944
I 2015-05-26 09:52:37 theanets.trainer:168 RmsProp 1139 loss=0.127215 err=0.127215
I 2015-05-26 09:52:44 theanets.trainer:168 RmsProp 1140 loss=0.121035 err=0.121035
I 2015-05-26 09:52:44 theanets.trainer:168 validation 114 loss=736.750366 err=736.750366 *
I 2015-05-26 09:52:51 theanets.trainer:168 RmsProp 1141 loss=0.145062 err=0.145062
I 2015-05-26 09:52:58 theanets.trainer:168 RmsProp 1142 loss=0.132965 err=0.132965
I 2015-05-26 09:53:05 theanets.trainer:168 RmsProp 1143 loss=0.125781 err=0.125781
I 2015-05-26 09:53:11 theanets.trainer:168 RmsProp 1144 loss=0.136786 err=0.136786
I 2015-05-26 09:53:19 theanets.trainer:168 RmsProp 1145 loss=0.130378 err=0.130378
I 2015-05-26 09:53:25 theanets.trainer:168 RmsProp 1146 loss=0.132804 err=0.132804
I 2015-05-26 09:53:32 theanets.trainer:168 RmsProp 1147 loss=0.118483 err=0.118483
I 2015-05-26 09:53:39 theanets.trainer:168 RmsProp 1148 loss=0.135852 err=0.135852
I 2015-05-26 09:53:46 theanets.trainer:168 RmsProp 1149 loss=0.120589 err=0.120589
I 2015-05-26 09:53:53 theanets.trainer:168 RmsProp 1150 loss=0.172921 err=0.172921
I 2015-05-26 09:53:54 theanets.trainer:168 validation 115 loss=735.801941 err=735.801941 *
I 2015-05-26 09:54:00 theanets.trainer:168 RmsProp 1151 loss=0.130126 err=0.130126
I 2015-05-26 09:54:07 theanets.trainer:168 RmsProp 1152 loss=0.116573 err=0.116573
I 2015-05-26 09:54:13 theanets.trainer:168 RmsProp 1153 loss=0.131278 err=0.131278
I 2015-05-26 09:54:20 theanets.trainer:168 RmsProp 1154 loss=0.125232 err=0.125232
I 2015-05-26 09:54:27 theanets.trainer:168 RmsProp 1155 loss=0.135916 err=0.135916
I 2015-05-26 09:54:33 theanets.trainer:168 RmsProp 1156 loss=0.128992 err=0.128992
I 2015-05-26 09:54:39 theanets.trainer:168 RmsProp 1157 loss=0.145975 err=0.145975
I 2015-05-26 09:54:46 theanets.trainer:168 RmsProp 1158 loss=0.125228 err=0.125228
I 2015-05-26 09:54:53 theanets.trainer:168 RmsProp 1159 loss=0.120751 err=0.120751
I 2015-05-26 09:54:59 theanets.trainer:168 RmsProp 1160 loss=0.135264 err=0.135264
I 2015-05-26 09:55:00 theanets.trainer:168 validation 116 loss=734.699036 err=734.699036 *
I 2015-05-26 09:55:07 theanets.trainer:168 RmsProp 1161 loss=0.124138 err=0.124138
I 2015-05-26 09:55:13 theanets.trainer:168 RmsProp 1162 loss=0.135668 err=0.135668
I 2015-05-26 09:55:21 theanets.trainer:168 RmsProp 1163 loss=0.127406 err=0.127406
I 2015-05-26 09:55:28 theanets.trainer:168 RmsProp 1164 loss=0.126418 err=0.126418
I 2015-05-26 09:55:35 theanets.trainer:168 RmsProp 1165 loss=0.131223 err=0.131223
I 2015-05-26 09:55:41 theanets.trainer:168 RmsProp 1166 loss=0.123686 err=0.123686
I 2015-05-26 09:55:48 theanets.trainer:168 RmsProp 1167 loss=0.142477 err=0.142477
I 2015-05-26 09:55:55 theanets.trainer:168 RmsProp 1168 loss=0.128814 err=0.128814
I 2015-05-26 09:56:02 theanets.trainer:168 RmsProp 1169 loss=0.124132 err=0.124132
I 2015-05-26 09:56:09 theanets.trainer:168 RmsProp 1170 loss=0.127660 err=0.127660
I 2015-05-26 09:56:09 theanets.trainer:168 validation 117 loss=733.751587 err=733.751587 *
I 2015-05-26 09:56:16 theanets.trainer:168 RmsProp 1171 loss=0.128004 err=0.128004
I 2015-05-26 09:56:23 theanets.trainer:168 RmsProp 1172 loss=0.138586 err=0.138586
I 2015-05-26 09:56:30 theanets.trainer:168 RmsProp 1173 loss=0.147926 err=0.147926
I 2015-05-26 09:56:37 theanets.trainer:168 RmsProp 1174 loss=0.131697 err=0.131697
I 2015-05-26 09:56:44 theanets.trainer:168 RmsProp 1175 loss=0.118413 err=0.118413
I 2015-05-26 09:56:51 theanets.trainer:168 RmsProp 1176 loss=0.131034 err=0.131034
I 2015-05-26 09:56:58 theanets.trainer:168 RmsProp 1177 loss=0.129664 err=0.129664
I 2015-05-26 09:57:05 theanets.trainer:168 RmsProp 1178 loss=0.129703 err=0.129703
I 2015-05-26 09:57:11 theanets.trainer:168 RmsProp 1179 loss=0.127704 err=0.127704
I 2015-05-26 09:57:18 theanets.trainer:168 RmsProp 1180 loss=0.121985 err=0.121985
I 2015-05-26 09:57:18 theanets.trainer:168 validation 118 loss=731.811646 err=731.811646 *
I 2015-05-26 09:57:26 theanets.trainer:168 RmsProp 1181 loss=0.132077 err=0.132077
I 2015-05-26 09:57:32 theanets.trainer:168 RmsProp 1182 loss=0.120720 err=0.120720
I 2015-05-26 09:57:39 theanets.trainer:168 RmsProp 1183 loss=0.137575 err=0.137575
I 2015-05-26 09:57:47 theanets.trainer:168 RmsProp 1184 loss=0.128761 err=0.128761
I 2015-05-26 09:57:54 theanets.trainer:168 RmsProp 1185 loss=0.130177 err=0.130177
I 2015-05-26 09:58:00 theanets.trainer:168 RmsProp 1186 loss=0.129048 err=0.129048
I 2015-05-26 09:58:07 theanets.trainer:168 RmsProp 1187 loss=0.130869 err=0.130869
I 2015-05-26 09:58:14 theanets.trainer:168 RmsProp 1188 loss=0.123696 err=0.123696
I 2015-05-26 09:58:21 theanets.trainer:168 RmsProp 1189 loss=0.128713 err=0.128713
I 2015-05-26 09:58:28 theanets.trainer:168 RmsProp 1190 loss=0.114927 err=0.114927
I 2015-05-26 09:58:28 theanets.trainer:168 validation 119 loss=731.654602 err=731.654602 *
I 2015-05-26 09:58:35 theanets.trainer:168 RmsProp 1191 loss=0.127839 err=0.127839
I 2015-05-26 09:58:42 theanets.trainer:168 RmsProp 1192 loss=0.128500 err=0.128500
I 2015-05-26 09:58:49 theanets.trainer:168 RmsProp 1193 loss=0.132092 err=0.132092
I 2015-05-26 09:58:56 theanets.trainer:168 RmsProp 1194 loss=0.120499 err=0.120499
I 2015-05-26 09:59:03 theanets.trainer:168 RmsProp 1195 loss=0.123416 err=0.123416
I 2015-05-26 09:59:10 theanets.trainer:168 RmsProp 1196 loss=0.124396 err=0.124396
I 2015-05-26 09:59:17 theanets.trainer:168 RmsProp 1197 loss=0.127316 err=0.127316
I 2015-05-26 09:59:23 theanets.trainer:168 RmsProp 1198 loss=0.126079 err=0.126079
I 2015-05-26 09:59:30 theanets.trainer:168 RmsProp 1199 loss=0.125235 err=0.125235
I 2015-05-26 09:59:37 theanets.trainer:168 RmsProp 1200 loss=0.126881 err=0.126881
I 2015-05-26 09:59:37 theanets.trainer:168 validation 120 loss=733.736145 err=733.736145
I 2015-05-26 09:59:44 theanets.trainer:168 RmsProp 1201 loss=0.119410 err=0.119410
I 2015-05-26 09:59:51 theanets.trainer:168 RmsProp 1202 loss=0.124381 err=0.124381
I 2015-05-26 09:59:58 theanets.trainer:168 RmsProp 1203 loss=0.141405 err=0.141405
I 2015-05-26 10:00:05 theanets.trainer:168 RmsProp 1204 loss=0.117385 err=0.117385
I 2015-05-26 10:00:12 theanets.trainer:168 RmsProp 1205 loss=0.128643 err=0.128643
I 2015-05-26 10:00:19 theanets.trainer:168 RmsProp 1206 loss=0.118702 err=0.118702
I 2015-05-26 10:00:26 theanets.trainer:168 RmsProp 1207 loss=0.125577 err=0.125577
I 2015-05-26 10:00:32 theanets.trainer:168 RmsProp 1208 loss=0.109411 err=0.109411
I 2015-05-26 10:00:39 theanets.trainer:168 RmsProp 1209 loss=0.135630 err=0.135630
I 2015-05-26 10:00:45 theanets.trainer:168 RmsProp 1210 loss=0.114981 err=0.114981
I 2015-05-26 10:00:45 theanets.trainer:168 validation 121 loss=732.009583 err=732.009583
I 2015-05-26 10:00:52 theanets.trainer:168 RmsProp 1211 loss=0.125378 err=0.125378
I 2015-05-26 10:00:58 theanets.trainer:168 RmsProp 1212 loss=0.128875 err=0.128875
I 2015-05-26 10:01:06 theanets.trainer:168 RmsProp 1213 loss=0.108704 err=0.108704
I 2015-05-26 10:01:13 theanets.trainer:168 RmsProp 1214 loss=0.146238 err=0.146238
I 2015-05-26 10:01:19 theanets.trainer:168 RmsProp 1215 loss=0.113805 err=0.113805
I 2015-05-26 10:01:26 theanets.trainer:168 RmsProp 1216 loss=0.135085 err=0.135085
I 2015-05-26 10:01:34 theanets.trainer:168 RmsProp 1217 loss=0.118916 err=0.118916
I 2015-05-26 10:01:41 theanets.trainer:168 RmsProp 1218 loss=0.124328 err=0.124328
I 2015-05-26 10:01:48 theanets.trainer:168 RmsProp 1219 loss=0.124888 err=0.124888
I 2015-05-26 10:01:55 theanets.trainer:168 RmsProp 1220 loss=0.120153 err=0.120153
I 2015-05-26 10:01:55 theanets.trainer:168 validation 122 loss=733.464294 err=733.464294
I 2015-05-26 10:02:02 theanets.trainer:168 RmsProp 1221 loss=0.131816 err=0.131816
I 2015-05-26 10:02:09 theanets.trainer:168 RmsProp 1222 loss=0.119973 err=0.119973
I 2015-05-26 10:02:15 theanets.trainer:168 RmsProp 1223 loss=0.123859 err=0.123859
I 2015-05-26 10:02:21 theanets.trainer:168 RmsProp 1224 loss=0.121440 err=0.121440
I 2015-05-26 10:02:28 theanets.trainer:168 RmsProp 1225 loss=0.124721 err=0.124721
I 2015-05-26 10:02:34 theanets.trainer:168 RmsProp 1226 loss=0.107628 err=0.107628
I 2015-05-26 10:02:42 theanets.trainer:168 RmsProp 1227 loss=0.140079 err=0.140079
I 2015-05-26 10:02:49 theanets.trainer:168 RmsProp 1228 loss=0.127465 err=0.127465
I 2015-05-26 10:02:56 theanets.trainer:168 RmsProp 1229 loss=0.125529 err=0.125529
I 2015-05-26 10:03:02 theanets.trainer:168 RmsProp 1230 loss=0.110731 err=0.110731
I 2015-05-26 10:03:03 theanets.trainer:168 validation 123 loss=731.722229 err=731.722229
I 2015-05-26 10:03:09 theanets.trainer:168 RmsProp 1231 loss=0.125821 err=0.125821
I 2015-05-26 10:03:16 theanets.trainer:168 RmsProp 1232 loss=0.120674 err=0.120674
I 2015-05-26 10:03:23 theanets.trainer:168 RmsProp 1233 loss=0.121482 err=0.121482
I 2015-05-26 10:03:30 theanets.trainer:168 RmsProp 1234 loss=0.109034 err=0.109034
I 2015-05-26 10:03:36 theanets.trainer:168 RmsProp 1235 loss=0.125154 err=0.125154
I 2015-05-26 10:03:43 theanets.trainer:168 RmsProp 1236 loss=0.124764 err=0.124764
I 2015-05-26 10:03:49 theanets.trainer:168 RmsProp 1237 loss=0.119950 err=0.119950
I 2015-05-26 10:03:55 theanets.trainer:168 RmsProp 1238 loss=0.120217 err=0.120217
I 2015-05-26 10:04:02 theanets.trainer:168 RmsProp 1239 loss=0.126541 err=0.126541
I 2015-05-26 10:04:08 theanets.trainer:168 RmsProp 1240 loss=0.115465 err=0.115465
I 2015-05-26 10:04:09 theanets.trainer:168 validation 124 loss=731.874573 err=731.874573
I 2015-05-26 10:04:09 theanets.trainer:252 patience elapsed!
I 2015-05-26 10:04:09 theanets.main:237 models_deep_post_code_sep/95120-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saving model
I 2015-05-26 10:04:09 theanets.graph:477 models_deep_post_code_sep/95120-models-sep_san_jose_realtor_200_100.conf-1024-None-None-None.pkl: saved model parameters
